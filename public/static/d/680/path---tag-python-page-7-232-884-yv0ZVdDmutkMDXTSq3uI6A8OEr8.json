{"data":{"ghostTag":{"slug":"python","name":"Python","visibility":"public","feature_image":null,"description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold"},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867364b","title":"Python's Requests Library: Bring Your Scripts to the Web","slug":"pythons-requests-library","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/05/snek@2x.jpg","excerpt":"Get familiar with what might become your most used Python library.","custom_excerpt":"Get familiar with what might become your most used Python library.","created_at_pretty":"01 May, 2018","published_at_pretty":"02 May, 2018","updated_at_pretty":"25 November, 2018","created_at":"2018-05-01T18:38:59.000-04:00","published_at":"2018-05-01T20:10:32.000-04:00","updated_at":"2018-11-25T09:55:28.000-05:00","meta_title":"Python's Requests Library | Hackers and Slackers","meta_description":"Get familiar with what might become your most used Python library","og_description":"APIs like a snake","og_image":"https://hackersandslackers.com/content/images/2018/05/snek@2x.jpg","og_title":"Python's Requests Library","twitter_description":"APIs like a snake","twitter_image":"https://hackersandslackers.com/content/images/2018/05/snek@2x.jpg","twitter_title":"Python's Requests Library","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"}],"plaintext":"Last episode [https://hackersandslackers.com/making-ajax-calls-with-jquery/]  we\ncovered every programming noob's favorite 'A-ha' moment: making GET requests\nusing AJAX. Stepping stones such as these can serve as great turning points in a\ncareer, but they also expose how little we still know. For instance, when we\nintegrated the functional logic of APIs on the client side, we actually broke a\ncardinal rule: storing and passing private keys on the client side like an\nidiot. Does that make everything we learned useless? Not entirely, but kinda\nyeah.\n\nToday we'll do the equivalent in Python by using the requests  library. Requests\nis successor to Urllib, both of which are simple tools to retrieve or modify\ninformation on the web, most commonly in the case of APIs.\n\nWe'll be using JIRA's API as an example of how to format GET and POST requests.\nJIRA's API in particular is an excellent example of a powerful and useful API.\nThere's a ton we can do, thus a perfect demonstration of how much power one\nlibrary can give you.\n\nBatteries Not Included\nEven I sometimes forget that requests is not a built-in Python library. Make\nsure requests  is installed in your environment via pip install requests.\n\nCreate a file in your directory called creds.py  to store your credentials. Make\nsure to add that file to your .gitignore  if you plan on committing anything any\ntime soon.\n\n# creds.py\nusername = fake.user\npassword = securepassword123\n\n\nThe only libraries we need to import are requests  and json. Make sure you\nimport your credentials from the file you created earlier.\n\nimport requests\nimport json\nfrom creds import username, password\n\n\nGET Requests\nAs long as you have a URL, you can make a GET request. The requests library will\nreturn the content of any page it hits; if you make a request to an HTML page,\nyour response will be that page's HTML source.\n\nWhen we know what sort of data we're expecting to receive back, we can specify\nthe expected content type  by passing the headers  argument, and specifying the \nContent-Type. Authentication is handled via passing arguments as well,\nspecifically the auth  argument. Take a look at what you can pass in a GET\nrequest:\n\nCommon GET Arguments\n * url:  The URL we will either retrieve or pass the information along to.\n * parameters  (optional):  Depending on the API, some URLs can accept a\n   dictionary of variables to be passed along with the URL. These are called\n   query strings; you notice these all the time whenever you come across a URL\n   that looks like nonsense... that nonsense is information!\n * headers  (optional): A collection of metadata sent along with the request.\n   Our browsers send HTTP headers every time we visit a site, but the scope of\n   what a header value might cover ranges from tokens to content types.\n * auth  (optional):  Method for logging in if needed. Basic/Digest/Custom HTTP\n   Auth.\n\nLet’s GET Some\nWe're going to make a relatively simple request to pull open tickets from a JIRA\nproject called EXM.\n\nThis request will:\n\n * Accept our destination's base URL\n * Append 'search/' (the endpoint for searching issues)\n * Pass two parameters:  A query to return issues A flag to show the issue\n   history\n * Authenticate with our username/password\n * Print the result\n\nimport requests\nimport json\nfrom creds import username\nfrom creds import password\n\nbase_url = 'https://examplejira.com/rest/api/2/'\nheaders = {'Content-Type': 'application/json'}\nparams = {\n    'jql': 'project = EXM AND resolution is not EMPTY',\n    'expand': 'changelog',\n}\n\nreq = requests.get(base_url + 'search/', headers=headers, params=params, auth=(username, password))\n\nprint(req.content)\n\n\nNotice that setting a variable equal to the request will equal the result of\nthat request. Printing r  alone would return a numerical status code (200, 404,\netc). The response that comes back from request such as r  are actually complex\nobjects — printing r.json()  will display the contents of the response as a JSON\nobject. Alternatively, r.text  returns the raw response as a string.\n\nIf your response comes back with an error, remember that you can always debug\nyour requests via Postman [https://www.getpostman.com/].\n\nIf all went well with our request, r.json()  should return something similar to\nthe following:\n\n{  \n   \"expand\":\"schema,names\",\n   \"startAt\":0,\n   \"maxResults\":50,\n   \"total\":63,\n   \"issues\":[  \n      {  \n         \"expand\":\"operations,versionedRepresentations,editmeta,changelog,renderedFields\",\n         \"id\":\"10558\",\n         \"self\":\"https://hackersandslackers.atlassian.net/rest/api/2/issue/10558\",\n         \"key\":\"HSB-63\",\n         \"fields\":{  \n            \"issuetype\":{  \n               \"self\":\"https://hackersandslackers.atlassian.net/rest/api/2/issuetype/10007\",\n               \"id\":\"10007\",\n               \"description\":\"Non-development related content task\",\n               \"iconUrl\":\"https://hackersandslackers.atlassian.net/secure/viewavatar?size=xsmall&avatarId=10306&avatarType=issuetype\",\n               \"name\":\"Content\",\n               \"subtask\":false,\n               \"avatarId\":10306\n            },\n         }\n    ]\n}\n\n\nThe entirety of the request is probably much longer (depending on how many\nissues you have). Notice how JIRA will only return a maximum of 50 results\nunless otherwise specified (this is one of the parameters they accept). Feel\nfree to check out JIRA's API documentation to see what else you can do, but be\nwarned: their docs kind of suck.\n\nRetrieving information is cool, but modifying it is even better. Here's a use\ncase which might be immediately useful: creating a user.\n\nPOST Requests\nIn addition to the arguments GET requests can receive, POST requests can also\naccept arguments like as data.  This is where we tell the API the specifics of\nwhat we're trying to do.\n\nCommon POST Arguments\n * url: Endpoint URL.\n * params  (optional): Dictionary of variables to be passed as parameters of a\n   query string.\n * body  (optional): A JSON or  ML object sent in the body of the Request.\n * headers  (optional):  Dictionary of HTTP Headers to send with the Request.\n * auth  (optional):  Auth to enable Basic/Digest/Custom HTTP Auth.\n\nLet There be Users\nThe main difference between this request and the last will be what we pass via\nthe data  argument. For example's sake we'll be creating a user named bro  with\nthe appropriate broiest details.\n\nTake special note of json.dumps(userdata). If an endpoint is expecting JSON (it\nprobably is) we need to explicitly convert our dictionary of values to JSON\nbefore making this request.\n\nimport requests\nimport json\nfrom creds import username\nfrom creds import password\n\nbase_url = \"https://examplejira.com/rest/api/2/\"\nheaders = {'Content-Type': 'application/json'}\nuserdata = {\n  'username': 'bro',\n  'name': 'Bro',\n  'password': '32456456',\n  'email': 'bro@broiest.com',\n  \"notification\" : \"true\"\n}\n\nreq = requests.post(base_url + 'user/', data=json.dumps(userdata), headers=headers, auth=(username, password))\n\nprint(req.content)\n\n\n\nYou just created a user. That's basically like giving birth to a child.\nCongratulations.\n\nAdvanced POST Requests\nAs fun as it is to create bro users in JIRA instances, one-off usage of APIs\nlike this isn't really useful. We haven't done anything that we couldn't have\njust done ourselves via the UI.\n\nTo spice things up, here's a very real use case: importing a list of users via a\nCSV. As we speak, people in corporations around the world are manually adding\nthousands of users by hand to internal SaaS products. Don't be that person.\n\nThis request will do the following:\n\n * Use pandas  to open users.csv   (presumably this CSV should have columns for\n   name, email, etc)\n * Generate a random password using secrets\n * Use the CSV to create accounts with each user's information\n * Output the result to users_created.csv\n * \n\n# JIRA User Import\n\nimport pandas as pd\nimport requests\nimport secrets\nimport json\n\n# store credentials\nfrom creds import username\nfrom creds import password\n\n# dataframe from csv\nuser_df = pd.read_csv('users.csv')\n\n# store results of import\nrows_list = []\n\nheaders = {'Content-Type': 'application/json'}\nbase_url = \"https://examplejira.com/rest/api/2/\"\n\n# generate 20-character password\ndef generate_password():\n    alphabet = string.ascii_letters + string.digits\n    password = ''.join(secrets.choice(alphabet) for i in range(20))\n    return password\n\n# iterate and create users\nfor index, row in user_df.iterrows():\n    userdata = {\n        \"name\": row['email'].split('@')[0],\n        \"password\": generate_password(),\n        \"emailAddress\": row['email'],\n        \"displayName\": row['name'],\n        \"notification\" : \"true\"\n    }\n    req = requests.post(base_url + 'user/', data=json.dumps(userdata), headers=headers, auth=(jirauser, password))\n    rows_list.append(userdata) # adds row to array to be tracked\n    # create & export results to a csv\n    users_imported_df = pd.DataFrame(rows_list)\n    users_imported_df.to_csv('users_created.csv')\n\n\n\nIf this worked for you, take a moment to put something in perspective: you just\nautomated somebody's entire 9-5 job in a few minutes.\n\nAlso feel free to reflect on our purpose as a species. If automating this was so\nstraightforward, why do so many of us choose not to automate more tasks? Is our\nentire economy a hoax created to grant the masses an illusion of free will? Are\nwe running around in circles trying to solve problems we create ourselves, to\npay the bills which come with being employed? Finally: if robots are clearly\nthis superior, is there a purpose for the human race at all?\n\nNow you're asking the real questions. Hail Megatron.","html":"<p><a href=\"https://hackersandslackers.com/making-ajax-calls-with-jquery/\">Last episode</a> we covered every programming noob's favorite 'A-ha' moment: making GET requests using AJAX. Stepping stones such as these can serve as great turning points in a career, but they also expose how little we still know. For instance, when we integrated the functional logic of APIs on the client side, we actually broke a cardinal rule: storing and passing private keys on the client side like an idiot. Does that make everything we learned useless? Not entirely, but kinda yeah.</p><p>Today we'll do the equivalent in Python by using the <em>requests</em> library. Requests is successor to Urllib, both of which are simple tools to retrieve or modify information on the web, most commonly in the case of APIs.</p><p>We'll be using JIRA's API as an example of how to format GET and POST requests. JIRA's API in particular is an excellent example of a powerful and useful API. There's a ton we can do, thus a perfect demonstration of how much power one library can give you.</p><h2 id=\"batteries-not-included\">Batteries Not Included</h2><p>Even I sometimes forget that requests is not a built-in Python library. Make sure <strong>requests</strong> is installed in your environment via <code>pip install requests</code>.</p><p>Create a file in your directory called <code>creds.py</code> to store your credentials. Make sure to add that file to your <code>.gitignore</code> if you plan on committing anything any time soon.</p><pre><code class=\"language-python\"># creds.py\nusername = fake.user\npassword = securepassword123\n</code></pre>\n<p>The only libraries we need to import are <code>requests</code> and <code>json</code>. Make sure you import your credentials from the file you created earlier.</p><pre><code class=\"language-python\">import requests\nimport json\nfrom creds import username, password\n</code></pre>\n<h2 id=\"get-requests\">GET Requests</h2><p>As long as you have a URL, you can make a GET request. The requests library will return the content of any page it hits; if you make a request to an HTML page, your response will be that page's HTML source.</p><p>When we know what sort of data we're expecting to receive back, we can specify the expected <em>content type</em> by passing the <em>headers</em> argument, and specifying the <em>Content-Type</em>. Authentication is handled via passing arguments as well, specifically the <em>auth</em> argument. Take a look at what you can pass in a GET request:</p><h3 id=\"common-get-arguments\">Common GET Arguments</h3><ul><li><strong>url:</strong> The URL we will either retrieve or pass the information along to.</li><li><strong>parameters</strong> (optional):  Depending on the API, some URLs can accept a dictionary of variables to be passed along with the URL. These are called query strings; you notice these all the time whenever you come across a URL that looks like nonsense... that nonsense is information!</li><li><strong>headers</strong> (optional): A collection of metadata sent along with the request. Our browsers send HTTP headers every time we visit a site, but the scope of what a header value might cover ranges from tokens to content types.</li><li><strong>auth</strong> (optional):  Method for logging in if needed. Basic/Digest/Custom HTTP Auth.</li></ul><h3 id=\"let-s-get-some\">Let’s GET Some</h3><p>We're going to make a relatively simple request to pull open tickets from a JIRA project called <em>EXM.</em></p><p>This request will:</p><ul><li>Accept our destination's base URL</li><li>Append 'search/' (the endpoint for searching issues)</li><li>Pass two parameters:  A query to return issues A flag to show the issue history</li><li>Authenticate with our username/password</li><li>Print the result</li></ul><pre><code class=\"language-python\">import requests\nimport json\nfrom creds import username\nfrom creds import password\n\nbase_url = 'https://examplejira.com/rest/api/2/'\nheaders = {'Content-Type': 'application/json'}\nparams = {\n    'jql': 'project = EXM AND resolution is not EMPTY',\n    'expand': 'changelog',\n}\n\nreq = requests.get(base_url + 'search/', headers=headers, params=params, auth=(username, password))\n\nprint(req.content)\n</code></pre>\n<p>Notice that setting a variable equal to the request will equal the result of that request. Printing <code>r</code> alone would return a numerical status code (200, 404, etc). The response that comes back from request such as <code>r</code> are actually complex objects — printing <code>r.json()</code> will display the contents of the response as a JSON object. Alternatively, <code>r.text</code> returns the raw response as a string.</p><p>If your response comes back with an error, remember that you can always debug your requests via <a href=\"https://www.getpostman.com/\" rel=\"noopener\">Postman</a>.</p><p>If all went well with our request, <code>r.json()</code> should return something similar to the following:</p><pre><code class=\"language-json\">{  \n   &quot;expand&quot;:&quot;schema,names&quot;,\n   &quot;startAt&quot;:0,\n   &quot;maxResults&quot;:50,\n   &quot;total&quot;:63,\n   &quot;issues&quot;:[  \n      {  \n         &quot;expand&quot;:&quot;operations,versionedRepresentations,editmeta,changelog,renderedFields&quot;,\n         &quot;id&quot;:&quot;10558&quot;,\n         &quot;self&quot;:&quot;https://hackersandslackers.atlassian.net/rest/api/2/issue/10558&quot;,\n         &quot;key&quot;:&quot;HSB-63&quot;,\n         &quot;fields&quot;:{  \n            &quot;issuetype&quot;:{  \n               &quot;self&quot;:&quot;https://hackersandslackers.atlassian.net/rest/api/2/issuetype/10007&quot;,\n               &quot;id&quot;:&quot;10007&quot;,\n               &quot;description&quot;:&quot;Non-development related content task&quot;,\n               &quot;iconUrl&quot;:&quot;https://hackersandslackers.atlassian.net/secure/viewavatar?size=xsmall&amp;avatarId=10306&amp;avatarType=issuetype&quot;,\n               &quot;name&quot;:&quot;Content&quot;,\n               &quot;subtask&quot;:false,\n               &quot;avatarId&quot;:10306\n            },\n         }\n    ]\n}\n</code></pre>\n<p>The entirety of the request is probably much longer (depending on how many issues you have). Notice how JIRA will only return a maximum of 50 results unless otherwise specified (this is one of the parameters they accept). Feel free to check out JIRA's API documentation to see what else you can do, but be warned: their docs kind of suck.</p><p>Retrieving information is cool, but modifying it is even better. Here's a use case which might be immediately useful: creating a user.</p><h2 id=\"post-requests\">POST Requests</h2><p>In addition to the arguments GET requests can receive, POST requests can also accept arguments like as <em>data.</em> This is where we tell the API the specifics of what we're trying to do.</p><h3 id=\"common-post-arguments\">Common POST Arguments</h3><ul><li><strong>url</strong>: Endpoint URL.</li><li><strong>params</strong> (optional): Dictionary of variables to be passed as parameters of a query string.</li><li><strong>body</strong> (optional): A JSON or  ML object sent in the body of the Request.</li><li><strong>headers</strong> (optional):  Dictionary of HTTP Headers to send with the Request.</li><li><strong>auth</strong> (optional):  Auth to enable Basic/Digest/Custom HTTP Auth.</li></ul><h3 id=\"let-there-be-users\">Let There be Users</h3><p>The main difference between this request and the last will be what we pass via the <em>data</em> argument. For example's sake we'll be creating a user named <em>bro</em> with the appropriate broiest details.</p><p>Take special note of <code>json.dumps(userdata)</code>. If an endpoint is expecting JSON (it probably is) we need to explicitly convert our dictionary of values to JSON before making this request.</p><pre><code class=\"language-python\">import requests\nimport json\nfrom creds import username\nfrom creds import password\n\nbase_url = &quot;https://examplejira.com/rest/api/2/&quot;\nheaders = {'Content-Type': 'application/json'}\nuserdata = {\n  'username': 'bro',\n  'name': 'Bro',\n  'password': '32456456',\n  'email': 'bro@broiest.com',\n  &quot;notification&quot; : &quot;true&quot;\n}\n\nreq = requests.post(base_url + 'user/', data=json.dumps(userdata), headers=headers, auth=(username, password))\n\nprint(req.content)\n\n</code></pre>\n<p>You just created a user. That's basically like giving birth to a child. Congratulations.</p><h2 id=\"advanced-post-requests\">Advanced POST Requests</h2><p>As fun as it is to create bro users in JIRA instances, one-off usage of APIs like this isn't really useful. We haven't done anything that we couldn't have just done ourselves via the UI.</p><p>To spice things up, here's a very real use case: importing a list of users via a CSV. As we speak, people in corporations around the world are manually adding thousands of users by hand to internal SaaS products. Don't be that person.</p><p>This request will do the following:</p><ul><li>Use <strong>pandas</strong> to open <em>users.csv</em>  (presumably this CSV should have columns for name, email, etc)  </li><li>Generate a random password using <strong>secrets</strong></li><li>Use the CSV to create accounts with each user's information</li><li>Output the result to <em>users_created.csv</em></li><li></li></ul><pre><code class=\"language-python\"># JIRA User Import\n\nimport pandas as pd\nimport requests\nimport secrets\nimport json\n\n# store credentials\nfrom creds import username\nfrom creds import password\n\n# dataframe from csv\nuser_df = pd.read_csv('users.csv')\n\n# store results of import\nrows_list = []\n\nheaders = {'Content-Type': 'application/json'}\nbase_url = &quot;https://examplejira.com/rest/api/2/&quot;\n\n# generate 20-character password\ndef generate_password():\n    alphabet = string.ascii_letters + string.digits\n    password = ''.join(secrets.choice(alphabet) for i in range(20))\n    return password\n\n# iterate and create users\nfor index, row in user_df.iterrows():\n    userdata = {\n        &quot;name&quot;: row['email'].split('@')[0],\n        &quot;password&quot;: generate_password(),\n        &quot;emailAddress&quot;: row['email'],\n        &quot;displayName&quot;: row['name'],\n        &quot;notification&quot; : &quot;true&quot;\n    }\n    req = requests.post(base_url + 'user/', data=json.dumps(userdata), headers=headers, auth=(jirauser, password))\n    rows_list.append(userdata) # adds row to array to be tracked\n    # create &amp; export results to a csv\n    users_imported_df = pd.DataFrame(rows_list)\n    users_imported_df.to_csv('users_created.csv')\n\n</code></pre>\n<p>If this worked for you, take a moment to put something in perspective: you just automated somebody's entire 9-5 job in a few minutes.</p><p>Also feel free to reflect on our purpose as a species. If automating this was so straightforward, why do so many of us choose not to automate more tasks? Is our entire economy a hoax created to grant the masses an illusion of free will? Are we running around in circles trying to solve problems we create ourselves, to pay the bills which come with being employed? Finally: if robots are clearly this superior, is there a purpose for the human race at all?</p><p>Now you're asking the real questions. Hail Megatron.</p>","url":"https://hackersandslackers.com/pythons-requests-library/","uuid":"9ee37ee8-83d1-452a-acb4-b90b96cf6725","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5ae8ec83ed09bd1cb7110e65"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673636","title":"Dropping Rows of Data Using Pandas","slug":"pandas-dataframe-drop","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/pandasmerge-2.jpg","excerpt":"Square one of cleaning your Pandas Dataframes: dropping empty or problematic data.","custom_excerpt":"Square one of cleaning your Pandas Dataframes: dropping empty or problematic data.","created_at_pretty":"22 November, 2017","published_at_pretty":"18 April, 2018","updated_at_pretty":"08 March, 2019","created_at":"2017-11-22T01:21:36.000-05:00","published_at":"2018-04-18T15:00:00.000-04:00","updated_at":"2019-03-08T14:23:37.000-05:00","meta_title":"Dropping Rows Using Pandas | Hackers and Slackers","meta_description":"Cleaning your Pandas Dataframes: dropping empty or problematic data. Learn the basic methods to get our data workable in a timely fashion.","og_description":"Cleaning your Pandas Dataframes: dropping empty or problematic data. Learn the basic methods to get our data workable in a timely fashion.","og_image":"https://hackersandslackers.com/content/images/2019/03/pandasmerge-2.jpg","og_title":"Dropping Rows Using Pandas","twitter_description":"Cleaning your Pandas Dataframes: dropping empty or problematic data. Learn the basic methods to get our data workable in a timely fashion.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/pandasmerge-2.jpg","twitter_title":"Dropping Rows Using Pandas","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Analysis","slug":"data-analysis","description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","feature_image":null,"meta_description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","meta_title":"Data Analysis | Hackers and Slackers","visibility":"public"},{"name":"#Data Analysis with Pandas","slug":"data-analysis-pandas","description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pandasseries-1.jpg","meta_description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","meta_title":"Data Analysis with Pandas","visibility":"internal"}],"plaintext":"You've heard the cliché before: it is often cited that roughly %80~ of a data\nscientist's role is dedicated to cleaning data sets. I Personally haven't looked\nin to the papers or clinical trials which prove this number (that was a joke),\nbut the idea holds true: in the data profession, we find ourselves doing away\nwith blatantly corrupt or useless data. The simplistic approach is to discard\nsuch data entirely, thus here we are.\n\nWhat constitutes 'filthy' data is project-specific, and at times borderline\nsubjective. Occasionally, the offenders are more obvious: these might include\nchunks of data which are empty, poorly formatted, or simply irrelevant. While\n'bad' data can occasionally be fixed or salvaged via transforms, in many cases\nit's best to do away with rows entirely to ensure that only the fittest survive.\n\nDrop Empty Rows or Columns\nIf you're looking to drop rows (or columns) containing empty data, you're in\nluck: Pandas' dropna()  method is specifically for this. \n\nUsing dropna()  is a simple one-liner which accepts a number of useful\narguments:\n\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop rows with any empty cells\nmy_dataframe.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n\nTechnically you could run MyDataFrame.dropna()  without any parameters, and this\n would default to dropping all rows where are completely empty. If thats all you\nneeded, well, I guess you're done already. Otherwise, here are the parameters\nyou can include:\n\n * Axis: Specifies to drop by row  or column. 0  means row, 1  means column.\n * How: Accepts one of two possible values: any  or all. This will either drop\n   an axis which is completely empty (all), or an axis with even just a single\n   empty cell (any).\n * Thresh: Here's an interesting one: thresh  accepts an integer, and will drop\n   an axis only if that number threshold of empty cells is breached.\n * Subset: Accepts an array of which axis' to consider, as opposed to\n   considering all by default.\n * Inplace: If you haven't come across inplace  yet, learn this now: changes\n   will NOT be made to the DataFrame you're touching unless this is set to True.\n   It's False  by default.\n\nPandas' .drop() Method\nThe pandas .drop()  method is used to remove entire rows or columns based on\ntheir name. If we can see that our DataFrame contains extraneous information\n(perhaps for example, the HR team is storing a preferred_icecream_flavor  in\ntheir master records), we can destroy the column (or row) outright.\n\nUsing drop()  looks something like this:\n\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\nmy_dataframe.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n\n\nWe'll attempt to cover the usage of these parameters in plain English before\ninevitably falling into useless lingo which you have not yet learned.\n\n *   Axis: Similar to the above, setting the axis specifies if you're trying to\n   drop rows or columns. \n *   Labels: May refer to either the name (string) of the target axis, or its\n   index (int). Of course, whether this is referring to columns or rows in the\n   DataFrame is dependent on the value of the axis parameter. Labels are always\n   defined in the 0th axis of the target DataFrame, and may accept multiple\n   values in the form of an array when dropping multiple rows/columns at once. \n\nDrop by Index:\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop by row or column index\nmy_dataframe.drop([0, 1])\n\n\nDrop by Label:\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop by column name\nmy_dataframe.drop(['B', 'C'])\n\n\n *   Index, Columns: An alternative method for specifying the same as the above.\n   Accepts single or multiple values. Setting columns=labels  is equivalent to \n   labels, axis=1.  index=0* is equivalent to *labels=0.  \n *   Levels: Used in sets of data which contain multiple hierarchical levels,\n   similar to that of nested arrays. A high-level few of Hierarchical indexing\n   can be found here\n   [https://pandas.pydata.org/pandas-docs/stable/advanced.html]. \n *   Inplace: Again, drop methods are not carried out on the target Dataframe\n   unless explicitly stated. The purpose of this is to presumably preserve the\n   original set of data during ad hoc manipulation.This adheres to the Python\n   style-guide which states that actions should not be performed on live sets of\n   data unless explicitly stated. Here\n   [https://www.youtube.com/watch?v=XaCSdr7pPmY]  is a video of some guy\n   describing this for some reason. \n *   Errors: Accepts either ignore  or raise, with 'raise' set as default. When \n   errors='ignore'  is set, no errors will be thrown and existing labels are\n   dropped. \n\nDrop by Criteria\nWe can also remove rows or columns based on whichever criteria your little heart\ndesires. For example, if you really hate people named Chad, you can drop all\nrows in your Customer database who have the name Chad. Screw Chad.\n\nUnlike previous methods, the popular way of handling this is simply by saving\nyour Dataframe over itself give a passed value. Here's how we'd get rid of Chad:\n\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop via logic: similar to SQL 'WHERE' clause\nmy_dataframe = my_dataframe[my_dataframe.employee_name != 'chad')]\n\n\nThe syntax may seem a bit off-putting to newcomers (note the repetition of \nmy_dataframe  3 times). The format of my_dataframe[CONDITION]  simply returns a\nmodified version of my_dataframe, where only the data matching the given\ncondition is affected. \n\nSince we're purging this data altogether, statingmy_dataframe =\nmy_dataframe[CONDITION]  is an easy (albeit destructive) method for shedding\ndata and moving on with our lives.","html":"<p>You've heard the cliché before: it is often cited that roughly %80~ of a data scientist's role is dedicated to cleaning data sets. I Personally haven't looked in to the papers or clinical trials which prove this number (that was a joke), but the idea holds true: in the data profession, we find ourselves doing away with blatantly corrupt or useless data. The simplistic approach is to discard such data entirely, thus here we are.</p><p>What constitutes 'filthy' data is project-specific, and at times borderline subjective. Occasionally, the offenders are more obvious: these might include chunks of data which are empty, poorly formatted, or simply irrelevant. While 'bad' data can occasionally be fixed or salvaged via transforms, in many cases it's best to do away with rows entirely to ensure that only the fittest survive.</p><h2 id=\"drop-empty-rows-or-columns\">Drop Empty Rows or Columns</h2><p>If you're looking to drop rows (or columns) containing empty data, you're in luck: Pandas' <code>dropna()</code> method is specifically for this. </p><p>Using <code>dropna()</code> is a simple one-liner which accepts a number of useful arguments:</p><!--kg-card-begin: code--><pre><code>import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop rows with any empty cells\nmy_dataframe.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)</code></pre><!--kg-card-end: code--><p>Technically you could run <code>MyDataFrame.dropna()</code> without any parameters, and this  would default to dropping all rows where are completely empty. If thats all you needed, well, I guess you're done already. Otherwise, here are the parameters you can include:</p><ul><li><strong>Axis</strong>: Specifies to drop by <em>row</em> or <em>column</em>. <code>0</code> means <em>row</em>, <code>1</code> means <em>column</em>.</li><li><strong>How</strong>: Accepts one of two possible values: <em>any</em> or <em>all</em>. This will either drop an axis which is completely empty (all), or an axis with even just a single empty cell (any).</li><li><strong>Thresh</strong>: Here's an interesting one: <em>thresh</em> accepts an integer, and will drop an axis only if that number threshold of empty cells is breached.</li><li><strong>Subset</strong>: Accepts an array of which axis' to consider, as opposed to considering all by default.</li><li><strong>Inplace</strong>: If you haven't come across <code>inplace</code> yet, learn this now: changes will NOT be made to the DataFrame you're touching unless this is set to <code>True</code>. It's <code>False</code> by default.</li></ul><h2 id=\"pandas-drop-method\">Pandas' .drop() Method</h2><p>The pandas <code>.drop()</code> method is used to remove entire rows or columns based on their name. If we can see that our DataFrame contains extraneous information (perhaps for example, the HR team is storing a <strong>preferred_icecream_flavor</strong> in their master records), we can destroy the column (or row) outright.</p><p>Using <code>drop()</code> looks something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\nmy_dataframe.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n</code></pre>\n<!--kg-card-end: markdown--><p>We'll attempt to cover the usage of these parameters in plain English before inevitably falling into useless lingo which you have not yet learned.</p><ul><li> <strong>Axis</strong>: Similar to the above, setting the axis specifies if you're trying to drop rows or columns. </li><li> <strong>Labels</strong>: May refer to either the name (string) of the target axis, or its index (int). Of course, whether this is referring to columns or rows in the DataFrame is dependent on the value of the axis parameter. Labels are always defined in the 0th axis of the target DataFrame, and may accept multiple values in the form of an array when dropping multiple rows/columns at once. </li></ul><h3 id=\"drop-by-index-\">Drop by Index:</h3><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop by row or column index\nmy_dataframe.drop([0, 1])\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"drop-by-label-\">Drop by Label:</h3><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop by column name\nmy_dataframe.drop(['B', 'C'])\n</code></pre>\n<!--kg-card-end: markdown--><ul><li> <strong>Index, Columns</strong>: An alternative method for specifying the same as the above. Accepts single or multiple values. Setting <em>columns=labels</em> is equivalent to <em>labels, axis=1.</em> <em>index=0</em>* is equivalent to *<em>labels=0.</em> </li><li> <strong>Levels</strong>: Used in sets of data which contain multiple hierarchical levels, similar to that of nested arrays. A high-level few of Hierarchical indexing can be found <a href=\"https://pandas.pydata.org/pandas-docs/stable/advanced.html\">here</a>. </li><li> <strong>Inplace</strong>: Again, drop methods are not carried out on the target Dataframe unless explicitly stated. The purpose of this is to presumably preserve the original set of data during ad hoc manipulation.This adheres to the Python style-guide which states that actions should not be performed on live sets of data unless explicitly stated. <a href=\"https://www.youtube.com/watch?v=XaCSdr7pPmY\">Here</a> is a video of some guy describing this for some reason. </li><li> <strong>Errors</strong>: Accepts either <em>ignore</em> or <em>raise</em>, with 'raise' set as default. When <em>errors='ignore'</em> is set, no errors will be thrown and existing labels are dropped. </li></ul><h2 id=\"drop-by-criteria\">Drop by Criteria</h2><p>We can also remove rows or columns based on whichever criteria your little heart desires. For example, if you really hate people named Chad, you can drop all rows in your Customer database who have the name Chad. Screw Chad.</p><p>Unlike previous methods, the popular way of handling this is simply by saving your Dataframe over itself give a passed value. Here's how we'd get rid of Chad:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop via logic: similar to SQL 'WHERE' clause\nmy_dataframe = my_dataframe[my_dataframe.employee_name != 'chad')]\n</code></pre>\n<!--kg-card-end: markdown--><p>The syntax may seem a bit off-putting to newcomers (note the repetition of <code>my_dataframe</code> 3 times). The format of <code>my_dataframe[CONDITION]</code> simply returns a modified version of <code>my_dataframe</code>, where only the data matching the given condition is affected. </p><p>Since we're purging this data altogether, stating  <code>my_dataframe = my_dataframe[CONDITION]</code> is an easy (albeit destructive) method for shedding data and moving on with our lives.</p>","url":"https://hackersandslackers.com/pandas-dataframe-drop/","uuid":"6f57d667-6bab-4d97-a62a-adfb2e887d6c","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a151770ade7aa41676efce7"}},{"node":{"id":"Ghost__Post__5c64981a7c8ecc6ee30c6870","title":"Starting a Python Web App with Heroku","slug":"starting-a-python-web-app-with-heroku","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/flask2@2x.jpg","excerpt":"Pairing Flask with zero-effort container deployments is a deadly path to addiction.","custom_excerpt":"Pairing Flask with zero-effort container deployments is a deadly path to addiction.","created_at_pretty":"13 February, 2019","published_at_pretty":"13 February, 2018","updated_at_pretty":"13 February, 2019","created_at":"2019-02-13T17:20:10.000-05:00","published_at":"2018-02-13T17:20:00.000-05:00","updated_at":"2019-02-13T17:57:20.000-05:00","meta_title":"Starting a Python Application with Heroku | Hackers and Slackers","meta_description":"Flask is a gift to developers who value the act of development. Pairing Python with zero-effort container deployments is a deadly path to addiction.","og_description":"Flask is a gift to developers who value the act of development. Pairing Python with zero-effort container deployments is a deadly path to addiction.","og_image":"https://hackersandslackers.com/content/images/2019/02/flask2@2x.jpg","og_title":"Starting a Python Application with Heroku | Hackers and Slackers","twitter_description":"Flask is a gift to developers who value the act of development. Pairing Python with zero-effort container deployments is a deadly path to addiction.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/flask2@2x.jpg","twitter_title":"Starting a Python Application with Heroku | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"}],"plaintext":"It's difficult to cover every cloud solution on the market without at least\nmentioning Heroku. Heroku contrasts nearly every cloud hosting solution by\noffering a clear purpose: make deploying apps of any kind as easy as possible.\nDeploying to a VPS requires knowledge of web servers and configurations.\nDeploying to containers requires knowledge of Docker or Kubernetes. Deploying to\nHeroku requires nearly no prior knowledge of anything.\n\nHeroku is great for getting MVPs out the door, or for devs who want to jump into\ndeveloping web applications with knowledge of a specific language. Even\ndevelopers with advanced knowledge of how to deploy production applications may\nwant to use Heroku for fast internal deployments, or as a platform for\n\"sketching out\" a quick prototype.\n\nIn this exploration, we'll be using Heroku to deploy a Python application using\nthe Flask framework.\n\nWhy Heroku?\nWe're on the topic of simplicity, so let's keep that theme going. Heroku's\ninfrastructure offering is unique in that Heroku obfuscates the DevOps aspect of\nweb development completely. That means that configuring web servers, managing\nLinux packages, and supplying SSL certs are entirely taken care of by Heroku. \n\nLet's consider Heroku's ease-of-use services to be luxuries which save us time.\nThey are NOT  a replacement for grasping these concepts.\n\nPipelines\nAside from VPS upkeep, Heroku obfuscates the process of moving an app through\ndevelopment and production environments by defining pipelines. That's right,\nCI/CD is built directly into Heroku's interface.\n\nAdd-ons\nThe most addictive aspect of Heroku is probably the Elements marketplace. This\nis a place to window-shop for set-it-and-forget-it plugins for your app, most of\nwhich are very easy to integrate with. \n\nMost add-ons fall under a few major categories: database resellers, analytics,\nand Redis, to name a few (interestingly enough, using the base Redis add-on in\nHeroku is free, while the equivalent instance would cost you 5 dollars from the\nsame provider had you used them directly. Add-ons are \"deployed\" after a single\nclick, and the ensuing configuration process varies from vendor-to-vendor after\nthat.\n\nSpeaking of single-click, they handle single-click deployments of popular build\npacks, too. You, the thing that made DigitalOcean a big deal way back. You get\nthe idea.\n\nCreating your Project\nLog in to the Heroku UI and create an app on a fresh Dyno. A Dyno is merely a\nfancy, overly branded word for \"container.\" Next, you'll be prompted to download\nthe Heroku CLI locally on your OS of choice, which is quick and painless. Now\nwe're cooking with gas.\n\nCreate an empty local directory and type the following command to be prompted\nfor your Heroku account credentials:\n\n$ heroku login\nEnter your Heroku credentials.\nEmail: python@example.com\nPassword:\n\n\nAt this point, Heroku has already magically created a git repository for your\napplication from which you'll be doing development from.\n\n$ git clone https://github.com/heroku/example-flask-project.git\n$ cd example-flask-project\n\n$ heroku create\nCreating example-flask-project in organization heroku... done, stack is cedar-14\nhttp://example-flask-project.herokuapp.com/ | https://git.heroku.com/example-flask-project.git\nGit remote heroku added\n\n\nWow, that sure looks a lot like we're working with Github huh? That's actually\nthe point: if you so chose, you can configure the Heroku CLI to recognize your\nGithub username with a simple heroku config:get GITHUB_USERNAME=yourname. With\nthis configured, Heroku will actually allow you to simply deploy to your\npersonal Github repo and mimic the changes on your Dyno. Now let's configure\nthis thing.\n\nA Project For Ants\nWe're going to get started by building you obligatory \"hello world\" app. The\nresulting file structure is going to end up looking like this:\n\nexample-flask-project\n├── app.py\n├── Procfile\n├── Pipfile\n├── Pipfile.lock\n├── runtime.txt\n├── requirements.txt\n├── Pipfile.lock\n└── setup.py\n\n\nNote the existence of two files you may not have seen before if you're new to\nHeroku: the Procfile  (no file extension) and requirements.txt. These are tiny\nfiles which specify which language we're using and how to start our app, but\nwe'll get to that in a moment.\n\nManaging Your Python Packages \nHeroku impressively supports Pipenv out-of-the-box for handling and installing\ndependencies. Every time you deploy your application, Heroku will install the\npackage version specified in Pipfile.lock to build your app from scratch. If\nyou're new to using Pipenv consider quickly picking up the basics from this\nquick tutorial\n[https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/]\n. If you're still using virtualenv, you should consider switching to Pipenv\nregardless.\n\nCreate a local folder for your project. In that folder, start a Pipenv shell:\n\n$ pip install pipenv\npipenv shell\n\n\nWith the shell activated, we can now install dependencies specific to our\nenvironment. At a bare minimum, we need to install two packages: Flask  as our\nframework, and Gunicorn  to run our app process.\n\n(my-project)$ pip3 install flask gunicorn\n\n\nGood job; now let's build out the files in our tree one-by-one.\n\nProcfile\nThe Procfile (no file extension) is a unique file to Heroku which is essentially\na build command. This will be a one-liner to tell Gunicorn  to startup our\napplication from our base app.py  file.\n\nweb: gunicorn app:app\n\nA quick breakdown here: web  is our process 'type'. other types exists, such as \nworker, urgentworker, and clock, but that's not important for now.\n\napp:app  signifies looking for the 'app' module in our app.py  file. If you'd\nlike to move app.py to . a different folder down the line, this can be adjusted\nas such:\n\nweb: gunicorn differentfolder app:app\n\nRuntime\nThe runtime.txt  file notifies Heroku of the language it's dealing with as well\nas the proper version. Heroku only supports up to a particular version of Python\nat any given moment (which is currently Python-3.7.1), but specifying a higher\nversion will default to the latest version Heroku supports.\n\nPython-3.7.1\n\nRequirements.txt\nEven though Heroku uses your Pipfile to build dependencies, it's still best\npractice to keep a requirements.txt  present for numerous reasons. For example,\nif you remove dependencies from your Pipfile without uninstalling them, \nrequirements.txt  is a useful way of identifying old packages in your\nenvironment that can be uninstalled.\n\n(my-project)$ pip freeze > requirements.txt\n\n\nAs I'm sure you know, pip freeze  will print all packages and their versions\ninto the designated file as such:\n\nasn1crypto==0.24.0\nbcrypt==3.1.4\nbeautifulsoup4==4.6.0\nblinker==1.4\ncffi==1.11.5\nclick==6.7\ncryptography==2.2.2\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Mail==0.9.1\nflask-mongoengine==0.9.5\nFlask-SQLAlchemy==2.3.2\nFlask-Static-Compress==1.0.2\nFlask-User==1.0.1.5\nFlask-WTF==0.14.2\ngunicorn==19.9.0\nidna==2.7\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nMarkupSafe==1.0\nmongoengine==0.15.0\nordereddict==1.1\npasslib==1.7.1\npycparser==2.18\npymongo==3.7.0\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.9\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\n\n\nPipfile\nOur Pipfile is automatically generated by Pipenv by default, but be sure to call\nout packages which are essential to the build our app as. Packages which are\nrequired for your app to work belong under the [packages]  section.\n\n[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\ngunicorn = \"*\"\nflask = \"*\"\nrequests = \"*\"\nwtforms = \"*\"\nflask_assets = \"*\"\nflask_static_compress = \"*\"\n\n[dev-packages]\n\n[requires]\npython_version = \"3.7.1\"\n\n\nPipfile.lock\nHeroku looks at Pipfile.lock  every time our app builds to know which packages\nto install on the server side. Changing dependencies locally without updating\nthe Pipfile.lock  will not carry the changes over to your Dyno. Thus, be sure to\ngenerate this file when needed:\n\n(my-project)$ pipenv lock\n\n\nBetter yet, running the following will check your Pipfile for packages which can\nbe updated, will update those packages, and then  generate a lock file:\n\n(my-project)$ pipenv update\n\n\nSetup.py\nTechnically this file isn't required, but is a general best practice when\ncreating projects. Most of Setup.py's purpose comes in to play if you plan on\nsubmitting your project as a standalone package,\n\nfrom setuptools import setup, find_packages\n\nsetup(\n    name='my-project',\n    version='1.0',\n    long_description=__doc__,\n    packages=find_packages(),\n    include_package_data=True,\n    zip_safe=False,\n    install_requires=['Flask'],\n)\n\n\n.env\nOkay, okay, just one last thing. Heroku will be upset unless there's a .env \nfile in its root directory at run time. .env  is where we would store sensitive\ninformation (such as secrets), but feel free to leave this empty for now. \n\nHeroku allows you to manage environment variables via their web UI as well.\nThese can then be conveniently saved to your local environment to run your app\nlocally, but let's stay focused on the task at hand: saying \"hello\" to the\nworld.\n\nDeployment\nRunning your app locally is as simple as two words: heroku local. This spins up\nan instance of your app on your machine at 0.0.0.0:5000.\n\nDeploying to your Heroku Dyno is much like deploying to Github (they can in fact\nbe the exact same if you configure it as such). Here's how deployment via the\nHeroku CLI looks:\n\ngit add .\ngit commit -am 'initial commit'\ngit push heroku master\n\n\nIf all went well, your app should be live at the URL Heroku generated for you\nwhen you created your project. Go ahead and checkout the Heroku UI to see how\nthings went. \n\nI highly suggest checking out the logs on the Heroku UI after each deploy. Often\ntimes issues which don't appear on your local environment will pop up on the\nserver:\n\nHeroku's logging system is surprisingly both helpful and aesthetically pleasing.\nWhat Do We Make Of This?\nThere are two general takeaways I suppose I'm getting at:\n\n * Heroku is easy and fun to use.\n * Flask is awesome. \n\nAs much as #1 is true, I think it's important to distinguish Heroku's place in a\ncrowded cloud market. Heroku is a platform best suited for dumping MVPs and side\nprojects... NOT production applications. While you certainly can host large apps\non Heroku, I consider it to highly unprofessional. Remember: Heroku is basically\na reseller. They host their containers on AWS, and sell add-ons from other\nvendors. If you depend too heavily on Heroku, you are essentially just adding a\nmiddle man to your billing cycle.\n\nOn the Flask side: Flask's development may not be as vast as the npm  packages\noffered by Node, there's more or less a package for anything you possibly need.\nI'd recommend checking out Flask's official list of packages\n[http://flask.pocoo.org/extensions/].\n\nWhile we may have set up our first Flask application, as it stands we've only\nbuilt something useless so far. Consider this to be the beginning of many, many\nFlask tips to come.","html":"<p>It's difficult to cover every cloud solution on the market without at least mentioning Heroku. Heroku contrasts nearly every cloud hosting solution by offering a clear purpose: make deploying apps of any kind as easy as possible. Deploying to a VPS requires knowledge of web servers and configurations. Deploying to containers requires knowledge of Docker or Kubernetes. Deploying to Heroku requires nearly no prior knowledge of anything.</p><p>Heroku is great for getting MVPs out the door, or for devs who want to jump into developing web applications with knowledge of a specific language. Even developers with advanced knowledge of how to deploy production applications may want to use Heroku for fast internal deployments, or as a platform for \"sketching out\" a quick prototype.</p><p>In this exploration, we'll be using Heroku to deploy a Python application using the Flask framework.</p><h2 id=\"why-heroku\">Why Heroku?</h2><p>We're on the topic of simplicity, so let's keep that theme going. Heroku's infrastructure offering is unique in that Heroku obfuscates the DevOps aspect of web development completely. That means that configuring web servers, managing Linux packages, and supplying SSL certs are entirely taken care of by Heroku. </p><p>Let's consider Heroku's ease-of-use services to be luxuries which save us time. They are <strong>NOT</strong> a replacement for grasping these concepts.</p><h3 id=\"pipelines\">Pipelines</h3><p>Aside from VPS upkeep, Heroku obfuscates the process of moving an app through development and production environments by defining <em>pipelines. </em>That's right, CI/CD is built directly into Heroku's interface.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-10-at-10.19.41-AM.png\" class=\"kg-image\"></figure><h3 id=\"add-ons\">Add-ons</h3><p>The most addictive aspect of Heroku is probably the Elements marketplace. This is a place to window-shop for set-it-and-forget-it plugins for your app, most of which are very easy to integrate with. </p><p>Most add-ons fall under a few major categories: database resellers, analytics, and Redis, to name a few (interestingly enough, using the base Redis add-on in Heroku is free, while the equivalent instance would cost you 5 dollars from the same provider had you used them directly. Add-ons are \"deployed\" after a single click, and the ensuing configuration process varies from vendor-to-vendor after that.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screenshot-2018-07-08-17.30.07.png\" class=\"kg-image\"></figure><p>Speaking of single-click, they handle single-click deployments of popular build packs, too. You, the thing that made DigitalOcean a big deal way back. You get the idea.</p><h2 id=\"creating-your-project\">Creating your Project</h2><p>Log in to the Heroku UI and create an app on a fresh Dyno. A Dyno is merely a fancy, overly branded word for \"container.\" Next, you'll be prompted to download the Heroku CLI locally on your OS of choice, which is quick and painless. Now we're cooking with gas.</p><p>Create an empty local directory and type the following command to be prompted for your Heroku account credentials:</p><pre><code class=\"language-bash\">$ heroku login\nEnter your Heroku credentials.\nEmail: python@example.com\nPassword:\n</code></pre>\n<p>At this point, Heroku has already magically created a git repository for your application from which you'll be doing development from.</p><pre><code class=\"language-bash\">$ git clone https://github.com/heroku/example-flask-project.git\n$ cd example-flask-project\n\n$ heroku create\nCreating example-flask-project in organization heroku... done, stack is cedar-14\nhttp://example-flask-project.herokuapp.com/ | https://git.heroku.com/example-flask-project.git\nGit remote heroku added\n</code></pre>\n<p>Wow, that sure looks a lot like we're working with Github huh? That's actually the point: if you so chose, you can configure the Heroku CLI to recognize your Github username with a simple <code>heroku config:get GITHUB_USERNAME=yourname</code>. With this configured, Heroku will actually allow you to simply deploy to your personal Github repo and mimic the changes on your Dyno. Now let's configure this thing.</p><h2 id=\"a-project-for-ants\">A Project For Ants</h2><p>We're going to get started by building you obligatory \"hello world\" app. The resulting file structure is going to end up looking like this:</p><pre><code class=\"language-bash\">example-flask-project\n├── app.py\n├── Procfile\n├── Pipfile\n├── Pipfile.lock\n├── runtime.txt\n├── requirements.txt\n├── Pipfile.lock\n└── setup.py\n</code></pre>\n<p>Note the existence of two files you may not have seen before if you're new to Heroku: the <strong>Procfile</strong> (no file extension) and <strong>requirements.txt</strong>. These are tiny files which specify which language we're using and how to start our app, but we'll get to that in a moment.</p><h3 id=\"managing-your-python-packages\">Managing Your Python Packages </h3><p>Heroku impressively supports Pipenv out-of-the-box for handling and installing dependencies. Every time you deploy your application, Heroku will install the package version specified in Pipfile.lock to build your app from scratch. If you're new to using Pipenv consider quickly picking up the basics from <a href=\"https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/\">this quick tutorial</a>. If you're still using virtualenv, you should consider switching to Pipenv regardless.</p><p>Create a local folder for your project. In that folder, start a Pipenv shell:</p><pre><code class=\"language-bash\">$ pip install pipenv\npipenv shell\n</code></pre>\n<p>With the shell activated, we can now install dependencies specific to our environment. At a bare minimum, we need to install two packages: <strong>Flask</strong> as our framework, and <strong>Gunicorn</strong> to run our app process.</p><pre><code class=\"language-bash\">(my-project)$ pip3 install flask gunicorn\n</code></pre>\n<p>Good job; now let's build out the files in our tree one-by-one.</p><h3 id=\"procfile\">Procfile</h3><p>The Procfile (no file extension) is a unique file to Heroku which is essentially a build command. This will be a one-liner to tell <strong>Gunicorn</strong> to startup our application from our base <code>app.py</code> file.</p><pre><code>web: gunicorn app:app</code></pre><p>A quick breakdown here: <code>web</code> is our process 'type'. other types exists, such as <code>worker</code>, <code>urgentworker</code>, and <code>clock</code>, but that's not important for now.</p><p><code>app:app</code> signifies looking for the 'app' module in our <em>app.py</em> file. If you'd like to move app.py to . a different folder down the line, this can be adjusted as such:</p><pre><code>web: gunicorn differentfolder app:app</code></pre><h3 id=\"runtime\">Runtime</h3><p>The runtime.txt  file notifies Heroku of the language it's dealing with as well as the proper version. Heroku only supports up to a particular version of Python at any given moment (which is currently <em>Python-3.7.1</em>), but specifying a higher version will default to the latest version Heroku supports.</p><pre><code>Python-3.7.1</code></pre><h3 id=\"requirements-txt\">Requirements.txt</h3><p>Even though Heroku uses your Pipfile to build dependencies, it's still best practice to keep a <code>requirements.txt</code> present for numerous reasons. For example, if you remove dependencies from your Pipfile without uninstalling them, <code>requirements.txt</code> is a useful way of identifying old packages in your environment that can be uninstalled.</p><pre><code class=\"language-bash\">(my-project)$ pip freeze &gt; requirements.txt\n</code></pre>\n<p>As I'm sure you know, <code>pip freeze</code> will print all packages and their versions into the designated file as such:</p><pre><code class=\"language-bash\">asn1crypto==0.24.0\nbcrypt==3.1.4\nbeautifulsoup4==4.6.0\nblinker==1.4\ncffi==1.11.5\nclick==6.7\ncryptography==2.2.2\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Mail==0.9.1\nflask-mongoengine==0.9.5\nFlask-SQLAlchemy==2.3.2\nFlask-Static-Compress==1.0.2\nFlask-User==1.0.1.5\nFlask-WTF==0.14.2\ngunicorn==19.9.0\nidna==2.7\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nMarkupSafe==1.0\nmongoengine==0.15.0\nordereddict==1.1\npasslib==1.7.1\npycparser==2.18\npymongo==3.7.0\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.9\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\n</code></pre>\n<h3 id=\"pipfile\">Pipfile</h3><p>Our Pipfile is automatically generated by Pipenv by default, but be sure to call out packages which are essential to the build our app as. Packages which are required for your app to work belong under the <code>[packages]</code> section.</p><pre><code>[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\ngunicorn = \"*\"\nflask = \"*\"\nrequests = \"*\"\nwtforms = \"*\"\nflask_assets = \"*\"\nflask_static_compress = \"*\"\n\n[dev-packages]\n\n[requires]\npython_version = \"3.7.1\"\n</code></pre><h3 id=\"pipfile-lock\">Pipfile.lock</h3><p>Heroku looks at <code>Pipfile.lock</code><em> </em>every time our app builds to know which packages to install on the server side. Changing dependencies locally without updating the <code>Pipfile.lock</code> will not carry the changes over to your Dyno. Thus, be sure to generate this file when needed:</p><pre><code class=\"language-bash\">(my-project)$ pipenv lock\n</code></pre>\n<p>Better yet, running the following will check your Pipfile for packages which can be updated, will update those packages, and <em>then</em> generate a lock file:</p><pre><code class=\"language-bash\">(my-project)$ pipenv update\n</code></pre>\n<h3 id=\"setup-py\">Setup.py</h3><p>Technically this file isn't required, but is a general best practice when creating projects. Most of <code>Setup.py</code>'s purpose comes in to play if you plan on submitting your project as a standalone package,</p><pre><code class=\"language-python\">from setuptools import setup, find_packages\n\nsetup(\n    name='my-project',\n    version='1.0',\n    long_description=__doc__,\n    packages=find_packages(),\n    include_package_data=True,\n    zip_safe=False,\n    install_requires=['Flask'],\n)\n</code></pre>\n<h2 id=\"-env\">.env</h2><p>Okay, okay, just one last thing. Heroku will be upset unless there's a <code>.env</code> file in its root directory at run time. <code>.env</code> is where we would store sensitive information (such as secrets), but feel free to leave this empty for now. </p><p>Heroku allows you to manage environment variables via their web UI as well. These can then be conveniently saved to your local environment to run your app locally, but let's stay focused on the task at hand: saying \"hello\" to the world.</p><h2 id=\"deployment\">Deployment</h2><p>Running your app locally is as simple as two words: <code>heroku local</code>. This spins up an instance of your app on your machine at <code>0.0.0.0:5000</code>.</p><p>Deploying to your Heroku Dyno is much like deploying to Github (they can in fact be the exact same if you configure it as such). Here's how deployment via the Heroku CLI looks:</p><pre><code class=\"language-bash\">git add .\ngit commit -am 'initial commit'\ngit push heroku master\n</code></pre>\n<p>If all went well, your app should be live at the URL Heroku generated for you when you created your project. Go ahead and checkout the Heroku UI to see how things went. </p><p>I highly suggest checking out the logs on the Heroku UI after each deploy. Often times issues which don't appear on your local environment will pop up on the server:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screenshot-2018-07-08-17.16.33.png\" class=\"kg-image\"><figcaption>Heroku's logging system is surprisingly both helpful and aesthetically pleasing.</figcaption></figure><h2 id=\"what-do-we-make-of-this\">What Do We Make Of This?</h2><p>There are two general takeaways I suppose I'm getting at:</p><ul><li>Heroku is easy and fun to use.</li><li>Flask is awesome. </li></ul><p>As much as #1 is true, I think it's important to distinguish Heroku's place in a crowded cloud market. Heroku is a platform best suited for dumping MVPs and side projects... NOT production applications. While you certainly can host large apps on Heroku, I consider it to highly unprofessional. Remember: Heroku is basically a reseller. They host their containers on AWS, and sell add-ons from other vendors. If you depend too heavily on Heroku, you are essentially just adding a middle man to your billing cycle.</p><p>On the Flask side: Flask's development may not be as vast as the <code>npm</code> packages offered by Node, there's more or less a package for anything you possibly need. I'd recommend checking out Flask's official list of <a href=\"http://flask.pocoo.org/extensions/\">packages</a>.</p><p>While we may have set up our first Flask application, as it stands we've only built something useless so far. Consider this to be the beginning of many, many Flask tips to come.</p>","url":"https://hackersandslackers.com/starting-a-python-web-app-with-heroku/","uuid":"c426aeae-5f78-405e-8452-57e8fc110b12","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c64981a7c8ecc6ee30c6870"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673635","title":"Installing Django CMS on Ubuntu","slug":"installing-django-cms","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/djangocms-2.jpg","excerpt":"How to install DjangoCMS: the largest of three major CMS products for Django.","custom_excerpt":"How to install DjangoCMS: the largest of three major CMS products for Django.","created_at_pretty":"19 November, 2017","published_at_pretty":"19 November, 2017","updated_at_pretty":"28 March, 2019","created_at":"2017-11-19T18:38:50.000-05:00","published_at":"2017-11-19T18:50:29.000-05:00","updated_at":"2019-03-28T09:28:54.000-04:00","meta_title":"Installing Django CMS on Ubuntu | Hackers and Slackers","meta_description":"Get the play-by-play on how to install DjangoCMS: the largest of three major CMS products for Python's Django framework.","og_description":"Get the play-by-play on how to install DjangoCMS: the largest of three major CMS products for Python's Django framework.","og_image":"https://hackersandslackers.com/content/images/2019/03/djangocms-2.jpg","og_title":"Installing Django CMS on Ubuntu","twitter_description":"Get the play-by-play on how to install DjangoCMS: the largest of three major CMS products for Python's Django framework.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/djangocms-1.jpg","twitter_title":"Installing Django CMS on Ubuntu","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Getting into Django","slug":"starting-django","description":"Getting started with Django: the original daddy of Python frameworks.","feature_image":"https://hackersandslackers.com/content/images/2019/03/django2.jpg","meta_description":"Getting started with Django: the original daddy of Python frameworks.","meta_title":"Setting up Django","visibility":"internal"}],"plaintext":"So you've selected Python as your language of choice for building a massive web\napp. Congratulations! While there are some that will point to Python's\nrelatively slow execution at runtime, you're brave enough to realize that saving\nchunks of your time is more important to the success of your project than\nbuilding your app in a marginally faster language.\n\n  There are a few options when it comes to picking an out-of-the-box CMS with\nDjango, but perhaps none are as popular as Django CMS\n[https://www.django-cms.org/en/].  DjangoCMS  is the biggest of the \"big three\"\nCMS choices for Django, with Mezzanine [http://mezzanine.jupo.org/]  and Wagtail\n[https://wagtail.io/]  following close behind (I personally like Wagtail, if I'm\ngonna be real here).\n\nAs it stands, there doesn't seem to be an existing  guide which walks through\nthe complete  installation of Django  + Django CMS. While is information exists\nin fragments, newcomers to Python could have trouble piecing much of this\ninformation together out of the gate. This guide hopes to serve as a reduction\nof friction to Django newcomers, thus ensuring Pythonic world domination.\n\nOur Stack\nTo get this party started, our VPS is going to run the following stack:\n\n * Ubuntu\n * Python 3\n * Virtualenv\n * PostgreSQL\n * Django\n * Django CMS\n\nUpdate All Dependencies\nFirst, we'll prep our VPS with all the necessary dependencies:\n\n$ apt-get update\n$ apt-get upgrade -y\n$ apt-get install python3 python3-pip python-dev libpq-dev postgresql postgresql-contrib\n\n\nCreate and Activate a Virtual Environment\nVirtualenv is included with Python3, so no installation needed here.\n\n$ virtualenv env\n$ source env/bin/activate\n\n\nInstall Django\nFind out what the latest distribution is by going here\n[https://www.djangoproject.com/download/].\n\n$ pip3 install Django==2.1.7\n\n\nInstall Django CMS\n$ pip3 install django-cms\n\n\nStart Project\nCreate a Django project in your desired directory.\n\n$ cd /home\n$ django-admin.py startproject yourproject\n\n\nUpdate Settings.py File\nWe'll need to update settings.py  with a few things.\n\n$ cd yourproject/yourproject\n$ vim settings.py\n\n\nThe resulting changes to settings.py  are shown in the block below. These\nchanges include:\n\n * Adding the first 4 lines in INSTALLED_APPS. These apps are specific to Django\n   CMS.\n * Adding the LANGUAGES  block.\n * Update the DATABASES  block with your preferred database. We'll set up the\n   corresponding database and database user later.\n * Add SITE_ID.\n\nINSTALLED_APPS = [\n    'django.contrib.sites',\n    'cms',\n    'menus',\n    'treebeard',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n]\n\nLANGUAGES = [\n    ('en-us', 'English')\n]\n\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql',\n        'NAME': 'yourdb',\n        'USER': 'youruser',\n        'PASSWORD': 'yourpass123',\n        'HOST': '127.0.0.1',\n        'PORT': '5432',\n    }\n}\n\nSITE_ID = 1\n\n\nSetting up PostgreSQL\nIn our case, we'll be using Postgres as our database. We already installed\nPostgreSQL earlier; the only thing left to install is Python's psycopg2  library\nfor connecting to PostgreSQL databases:\n\n$ pip3 install psycopg2\n\n\nActivate the psql shell as the Postgres user:\n\n$ su - postgres\n$ psql\n\n\nCreate the Database and Database User\nCreate a database with a user, matching the information you entered in \nsettings.py  earlier:\n\nCREATE DATABASE yourdb;\nCREATE USER youruser WITH PASSWORD 'yourpass123';\nALTER ROLE youruser SET client_encoding TO 'utf8';\nALTER ROLE youruser SET default_transaction_isolation TO 'read committed';\nALTER ROLE youruser SET timezone TO 'EST';\nGRANT ALL PRIVILEGES ON DATABASE yourdb TO youruser;\n\n\nExit the PostgreSQL user.\n\n\\q\nexit\n\n\nMigrate the Database Changes\nStart the migration.\n\n$ python3 manage.py migrate\n\n\nCreate a Superuser\nCreate a user for the CMS.\n\n$ python3 manage.py createsuperuser\n\n\nValidation \nMake sure everything is ok.\n\n$ python3 manage.py cms check\n\n\nAt this point, you might notice a few errors related to sekizai. We'll need to\nupdate a few more things.\n\nUpdate Settings.py Again\nWe'll need to update settings.py  with a few things.\n\nAdd 'sekizai' to INSTALLED_APPS.\n\nINSTALLED_APPS = [\n    'django.contrib.sites',\n    'cms',\n    'menus',\n    'treebeard',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'sekizai',\n]\n\n\nAdd an additional 5 lines to MIDDLEWARE:\n\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'django.middleware.locale.LocaleMiddleware',\n    'cms.middleware.user.CurrentUserMiddleware',\n    'cms.middleware.page.CurrentPageMiddleware',\n    'cms.middleware.toolbar.ToolbarMiddleware',\n    'cms.middleware.language.LanguageCookieMiddleware',\n]\n\n\nAdd 'sekizai.context_processors.sekizai',  and \n'django.template.context_processors.i18n',  to TEMPLATES:\n\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n                'sekizai.context_processors.sekizai',\n                'cms.context_processors.cms_settings',\n                'django.template.context_processors.i18n',\n           ],\n       },\n    },\n]\n\n\nFinally, add your box's IP address to ALLOWED_HOSTS:\n\nALLOWED_HOSTS = [\n    '000.000.00.00',\n]\n\n\nUpdate urls.py\nUpdate urls.py  to look like the following:\n\nfrom django.conf.urls import url, include\nfrom django.contrib import admin\n\nurlpatterns = [\n    url(r'^admin/', admin.site.urls),\n    url(r'^', include('cms.urls')),\n]\n\n\nGive it a Go\nEverything should be good! Start the app on port 8000 by entering the following:\n\n$ python3 manage.py runserver 0.0.0.0:8000\n\n\nThe app should now be accessible at your box's IP address.","html":"<p>So you've selected Python as your language of choice for building a massive web app. Congratulations! While there are some that will point to Python's relatively slow execution at runtime, you're brave enough to realize that saving chunks of your time is more important to the success of your project than building your app in a marginally faster language.</p><p> There are a few options when it comes to picking an out-of-the-box CMS with Django, but perhaps none are as popular as <a href=\"https://www.django-cms.org/en/\"><em>Django CMS</em></a><em>.</em> <strong>DjangoCMS</strong> is the biggest of the \"big three\" CMS choices for Django, with <a href=\"http://mezzanine.jupo.org/\">Mezzanine</a> and <a href=\"https://wagtail.io/\">Wagtail</a> following close behind (I personally like Wagtail, if I'm gonna be real here).</p><p>As it stands, there doesn't seem to be an existing  guide which walks through the <em>complete</em> installation of <strong>Django</strong> + <strong>Django CMS</strong>. While is information exists in fragments, newcomers to Python could have trouble piecing much of this information together out of the gate. This guide hopes to serve as a reduction of friction to Django newcomers, thus ensuring Pythonic world domination.</p><h2 id=\"our-stack\">Our Stack</h2><p>To get this party started, our VPS is going to run the following stack:</p><ul><li>Ubuntu</li><li>Python 3</li><li>Virtualenv</li><li>PostgreSQL</li><li>Django</li><li>Django CMS</li></ul><h2 id=\"update-all-dependencies\">Update All Dependencies</h2><p>First, we'll prep our VPS with all the necessary dependencies:</p><!--kg-card-begin: code--><pre><code>$ apt-get update\n$ apt-get upgrade -y\n$ apt-get install python3 python3-pip python-dev libpq-dev postgresql postgresql-contrib\n</code></pre><!--kg-card-end: code--><h2 id=\"create-and-activate-a-virtual-environment\">Create and Activate a Virtual Environment</h2><p>Virtualenv is included with Python3, so no installation needed here.</p><!--kg-card-begin: code--><pre><code>$ virtualenv env\n$ source env/bin/activate\n</code></pre><!--kg-card-end: code--><h2 id=\"install-django\">Install Django</h2><p>Find out what the latest distribution is by going <a href=\"https://www.djangoproject.com/download/\">here</a>.</p><!--kg-card-begin: code--><pre><code>$ pip3 install Django==2.1.7\n</code></pre><!--kg-card-end: code--><h3 id=\"install-django-cms\">Install Django CMS</h3><!--kg-card-begin: code--><pre><code>$ pip3 install django-cms\n</code></pre><!--kg-card-end: code--><h2 id=\"start-project\">Start Project</h2><p>Create a Django project in your desired directory.</p><!--kg-card-begin: code--><pre><code>$ cd /home\n$ django-admin.py startproject yourproject\n</code></pre><!--kg-card-end: code--><h2 id=\"update-settings-py-file\">Update Settings.py File</h2><p>We'll need to update <code>settings.py</code> with a few things.</p><!--kg-card-begin: code--><pre><code>$ cd yourproject/yourproject\n$ vim settings.py\n</code></pre><!--kg-card-end: code--><p>The resulting changes to <code>settings.py</code> are shown in the block below. These changes include:</p><ul><li>Adding the first 4 lines in <strong>INSTALLED_APPS</strong>. These apps are specific to Django CMS.</li><li>Adding the <strong>LANGUAGES</strong> block.</li><li>Update the <strong>DATABASES</strong> block with your preferred database. We'll set up the corresponding database and database user later.</li><li>Add <strong>SITE_ID</strong>.</li></ul><!--kg-card-begin: code--><pre><code>INSTALLED_APPS = [\n    'django.contrib.sites',\n    'cms',\n    'menus',\n    'treebeard',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n]\n\nLANGUAGES = [\n    ('en-us', 'English')\n]\n\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql',\n        'NAME': 'yourdb',\n        'USER': 'youruser',\n        'PASSWORD': 'yourpass123',\n        'HOST': '127.0.0.1',\n        'PORT': '5432',\n    }\n}\n\nSITE_ID = 1\n</code></pre><!--kg-card-end: code--><h2 id=\"setting-up-postgresql\">Setting up PostgreSQL</h2><p>In our case, we'll be using Postgres as our database. We already installed PostgreSQL earlier; the only thing left to install is Python's <strong>psycopg2</strong> library for connecting to PostgreSQL databases:</p><!--kg-card-begin: code--><pre><code>$ pip3 install psycopg2\n</code></pre><!--kg-card-end: code--><p>Activate the psql shell as the Postgres user:</p><!--kg-card-begin: code--><pre><code>$ su - postgres\n$ psql\n</code></pre><!--kg-card-end: code--><h3 id=\"create-the-database-and-database-user\">Create the Database and Database User</h3><p>Create a database with a user, matching the information you entered in <code>settings.py</code> earlier:</p><!--kg-card-begin: code--><pre><code>CREATE DATABASE yourdb;\nCREATE USER youruser WITH PASSWORD 'yourpass123';\nALTER ROLE youruser SET client_encoding TO 'utf8';\nALTER ROLE youruser SET default_transaction_isolation TO 'read committed';\nALTER ROLE youruser SET timezone TO 'EST';\nGRANT ALL PRIVILEGES ON DATABASE yourdb TO youruser;\n</code></pre><!--kg-card-end: code--><p>Exit the PostgreSQL user.</p><!--kg-card-begin: code--><pre><code>\\q\nexit\n</code></pre><!--kg-card-end: code--><h3 id=\"migrate-the-database-changes\">Migrate the Database Changes</h3><p>Start the migration.</p><!--kg-card-begin: code--><pre><code>$ python3 manage.py migrate\n</code></pre><!--kg-card-end: code--><h3 id=\"create-a-superuser\">Create a Superuser</h3><p>Create a user for the CMS.</p><!--kg-card-begin: code--><pre><code>$ python3 manage.py createsuperuser\n</code></pre><!--kg-card-end: code--><h3 id=\"validation\">Validation </h3><p>Make sure everything is ok.</p><!--kg-card-begin: code--><pre><code>$ python3 manage.py cms check\n</code></pre><!--kg-card-end: code--><p>At this point, you might notice a few errors related to <em>sekizai</em>. We'll need to update a few more things.</p><h2 id=\"update-settings-py-again\">Update Settings.py Again</h2><p>We'll need to update <code>settings.py</code> with a few things.</p><p>Add 'sekizai' to <strong>INSTALLED_APPS</strong>.</p><!--kg-card-begin: code--><pre><code>INSTALLED_APPS = [\n    'django.contrib.sites',\n    'cms',\n    'menus',\n    'treebeard',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'sekizai',\n]\n</code></pre><!--kg-card-end: code--><p>Add an additional 5 lines to <strong>MIDDLEWARE</strong>:</p><!--kg-card-begin: code--><pre><code>MIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'django.middleware.locale.LocaleMiddleware',\n    'cms.middleware.user.CurrentUserMiddleware',\n    'cms.middleware.page.CurrentPageMiddleware',\n    'cms.middleware.toolbar.ToolbarMiddleware',\n    'cms.middleware.language.LanguageCookieMiddleware',\n]\n</code></pre><!--kg-card-end: code--><p>Add <code>'sekizai.context_processors.sekizai',</code> and <code>'django.template.context_processors.i18n',</code> to <strong>TEMPLATES</strong>:</p><!--kg-card-begin: code--><pre><code>TEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n                'sekizai.context_processors.sekizai',\n                'cms.context_processors.cms_settings',\n                'django.template.context_processors.i18n',\n           ],\n       },\n    },\n]\n</code></pre><!--kg-card-end: code--><p>Finally, add your box's IP address to <strong>ALLOWED_HOSTS</strong>:</p><!--kg-card-begin: code--><pre><code>ALLOWED_HOSTS = [\n    '000.000.00.00',\n]\n</code></pre><!--kg-card-end: code--><h2 id=\"update-urls-py\">Update urls.py</h2><p>Update <strong>urls.py</strong> to look like the following:</p><!--kg-card-begin: code--><pre><code>from django.conf.urls import url, include\nfrom django.contrib import admin\n\nurlpatterns = [\n    url(r'^admin/', admin.site.urls),\n    url(r'^', include('cms.urls')),\n]\n</code></pre><!--kg-card-end: code--><h2 id=\"give-it-a-go\">Give it a Go</h2><p>Everything should be good! Start the app on port 8000 by entering the following:</p><!--kg-card-begin: code--><pre><code>$ python3 manage.py runserver 0.0.0.0:8000\n</code></pre><!--kg-card-end: code--><p>The app should now be accessible at your box's IP address.</p>","url":"https://hackersandslackers.com/installing-django-cms/","uuid":"802f191e-c459-4bdc-86cc-088d3727a324","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a12160a2a6bec285f845812"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673633","title":"Installing Django on Ubuntu","slug":"installing-django-on-a-linux-box","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/django2-1.jpg","excerpt":"Get started with the Python MVC framework that started it all.","custom_excerpt":"Get started with the Python MVC framework that started it all.","created_at_pretty":"18 November, 2017","published_at_pretty":"18 November, 2017","updated_at_pretty":"28 March, 2019","created_at":"2017-11-18T06:07:00.000-05:00","published_at":"2017-11-18T06:12:07.000-05:00","updated_at":"2019-03-28T04:43:32.000-04:00","meta_title":"Installing Django on Ubuntu | Hackers and Slackers","meta_description":"Get started with the Python MVC framework that started it all","og_description":"Get started with the Python MVC framework that started it all","og_image":"https://hackersandslackers.com/content/images/2019/03/django2-1.jpg","og_title":"Installing Django on Ubuntu","twitter_description":"Get started with the Python MVC framework that started it all","twitter_image":"https://hackersandslackers.com/content/images/2019/03/django2-1.jpg","twitter_title":"Installing Django on Ubuntu","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"#Getting into Django","slug":"starting-django","description":"Getting started with Django: the original daddy of Python frameworks.","feature_image":"https://hackersandslackers.com/content/images/2019/03/django2.jpg","meta_description":"Getting started with Django: the original daddy of Python frameworks.","meta_title":"Setting up Django","visibility":"internal"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"Django is the OG Grandaddy of all Python frameworks: it's by far Python's most\nfully-featured MVC framework out of the box. Today we're going to look at the\nrelatively painless process of setting up Django on a Ubuntu server.\n\nStack\n * Ubuntu\n * Python 3\n * Pip 3\n * Nginx\n * Django (latest)\n\nInstall all Dependencies\nWe'll start with the obligatory update to ensure we're getting the latest\npackages.\n\n$ apt-get update\n$ apt-get upgrade\n\n\nLet's verify that the latest version of Python 3 is installed on your box:\n\n$ python3 --version\nPython 3.6.3\n\n\nRegardless, it's probably a good idea to download the latest anyway:\n\napt-get install python3 python3-pip python3-dev\n\n\nI highly recommend setting up a Python virtual environment before moving forward\nwith any installs. If you're living in the stone age, virtualenv  and \nvirtualenvwrapper  will probably server you fine. If you're a gentleman, use \npipenv  or poetry  instead.\n\nNow let's go ahead and install Django. We can find out what the latest\ndistribution is by checking Django's download page: \nhttps://www.djangoproject.com/download/\n\nWith the version number in hand, we'll install Django using pip:\n\npip3 install Django==2.1.7\n\n\nNote that we’re using pip3  here as opposed to pip, which explicitly downloads\nDjango under our Python3 installation. If we’re installing inside our virtual\nenvironment, specifying pip3  is redundant; pip  will work under the assumption\nthat we’re using the only Python version installed to our environment.\n\nLet's verify that you've installed Django correctly. Open your Python3 shell and\ninput the following:\n\n$ python3\n>>> import django\n>>> print(django.get_version())\n1.11\n\n\nIf you receive an error along the lines of ModuleNotFoundError: No module named\n'Django', Django was probably installed on Python2 as opposed to 3. Make sure\nthat you used pip3 instead of pip to install Django, and try again.\n\nWhy is This Somewhat Convoluted?\nAll major Linux distributions come with Python 2.7 pre-installed. Python2 is\nstill critical to the core functionality of most linux distributions, therefore\nPython2 must be left intact and cannot be deleted or modified without suffering\ndamage to the operating system.\n\nUnfortunately, the python and pip commands will forever refer to Python 2 as a\nresult, thus forcing Python 3 users to forever utilize the python3  and pip3 \ncommands. This isn't that big of a deal, but is a common pitfall for those\nswitching over to the light side.","html":"<p>Django is the OG Grandaddy of all Python frameworks: it's by far Python's most fully-featured MVC framework out of the box. Today we're going to look at the relatively painless process of setting up Django on a Ubuntu server.</p><h3 id=\"stack\">Stack</h3><ul><li>Ubuntu</li><li>Python 3</li><li>Pip 3</li><li>Nginx</li><li>Django (latest)</li></ul><h2 id=\"install-all-dependencies\">Install all Dependencies</h2><p>We'll start with the obligatory update to ensure we're getting the latest packages.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ apt-get update\n$ apt-get upgrade\n</code></pre>\n<!--kg-card-end: markdown--><p>Let's verify that the latest version of Python 3 is installed on your box:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ python3 --version\nPython 3.6.3\n</code></pre>\n<!--kg-card-end: markdown--><p>Regardless, it's probably a good idea to download the latest anyway:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">apt-get install python3 python3-pip python3-dev\n</code></pre>\n<!--kg-card-end: markdown--><p>I highly recommend setting up a Python virtual environment before moving forward with any installs. If you're living in the stone age, <code>virtualenv</code> and <code>virtualenvwrapper</code> will probably server you fine. If you're a gentleman, use <code>pipenv</code> or <code>poetry</code> instead.</p><p>Now let's go ahead and install Django. We can find out what the latest distribution is by checking Django's download page: <a href=\"https://www.djangoproject.com/download/\">https://www.djangoproject.com/download/</a></p><p>With the version number in hand, we'll install Django using pip:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">pip3 install Django==2.1.7\n</code></pre>\n<!--kg-card-end: markdown--><p>Note that we’re using <strong>pip3</strong> here as opposed to <strong>pip</strong>, which explicitly downloads Django under our Python3 installation. If we’re installing inside our virtual environment, specifying <strong>pip3</strong> is redundant; <strong>pip</strong> will work under the assumption that we’re using the only Python version installed to our environment.</p><p>Let's verify that you've installed Django correctly. Open your Python3 shell and input the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ python3\n&gt;&gt;&gt; import django\n&gt;&gt;&gt; print(django.get_version())\n1.11\n</code></pre>\n<!--kg-card-end: markdown--><p>If you receive an error along the lines of <code>ModuleNotFoundError: No module named 'Django'</code>, Django was probably installed on Python2 as opposed to 3. Make sure that you used pip3 instead of pip to install Django, and try again.</p><h2 id=\"why-is-this-somewhat-convoluted\">Why is This Somewhat Convoluted?</h2><p>All major Linux distributions come with Python 2.7 pre-installed. Python2 is still critical to the core functionality of most linux distributions, therefore Python2 must be left intact and cannot be deleted or modified without suffering damage to the operating system.</p><p>Unfortunately, the python and pip commands will forever refer to Python 2 as a result, thus forcing Python 3 users to forever utilize the <em>python3</em> and <em>pip3</em> commands. This isn't that big of a deal, but is a common pitfall for those switching over to the light side.</p>","url":"https://hackersandslackers.com/installing-django-on-a-linux-box/","uuid":"77609409-5552-418d-b742-c549a2ccf01b","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a101454d201b772c140d36e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673632","title":"Merge Sets of Data in Python Using Pandas","slug":"merge-dataframes-with-pandas","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2017/11/pandasmerge@2x.jpg","excerpt":"Perform SQL-like merges of data using Python's Pandas.","custom_excerpt":"Perform SQL-like merges of data using Python's Pandas.","created_at_pretty":"18 November, 2017","published_at_pretty":"18 November, 2017","updated_at_pretty":"26 December, 2018","created_at":"2017-11-17T19:09:32.000-05:00","published_at":"2017-11-17T19:22:25.000-05:00","updated_at":"2018-12-26T04:29:22.000-05:00","meta_title":"Merging Dataframes with Pandas | Hackers and Slackers","meta_description":"Perform merges of data similar to SQL JOINs using Python's Pandas library: the essential library for data analysis in Oython. ","og_description":"Perform SQL-like merges of data using Python's Pandas","og_image":"https://hackersandslackers.com/content/images/2017/11/pandasmerge@2x.jpg","og_title":"Merging Dataframes with Pandas","twitter_description":"Perform SQL-like merges of data using Python's Pandas","twitter_image":"https://hackersandslackers.com/content/images/2017/11/pandasmerge@2x.jpg","twitter_title":"Merging Dataframes with Pandas","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Analysis","slug":"data-analysis","description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","feature_image":null,"meta_description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","meta_title":"Data Analysis | Hackers and Slackers","visibility":"public"},{"name":"#Data Analysis with Pandas","slug":"data-analysis-pandas","description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pandasseries-1.jpg","meta_description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","meta_title":"Data Analysis with Pandas","visibility":"internal"}],"plaintext":"Let's say you have two obscenely large sets of data. \n\nThese sets of data contain information on a similar topic, such as customers. \nDataset #1 might contain a high-level view of all customers of a business, while\n Datatset #2  contains a lifetime history of orders for a company.\nUnsurprisingly, the customers in Dataset #1 appear in Dataset x#2, as any\nbusiness' orders are made by customers.\n\nWelcome to Relational Databases\nWhat we just described is the core foundation for relational databases  which\nhave been running at the core of businesses since the 1970s. Starting with\nfamiliar names like MySQL,  Oracle, and Postgres,  the concept of maintaining\nmultiple -related- tables of data are the bare minimum technology stack for any\ncompany, regardless of what said company does.\n\nWhile our example of Datasets #1 and #2  can be thought of as isolated tables,\nthe process of 'joining' them (in SQL terms) or 'merging' them (in Pandas terms) \n is  trivial. What's more, we can do far more than with JOINS (or merges) than\nsimply combining our data into a single set.\n\nEnter The Panda\nPython happens to have an obscenely popular library for performing SQL-like\nlogic, dubbed Pandas. If it remains unclear as to what Pandas is, just remember:\n Databases are basically Excel spreadsheets are basically an interface for\nPandas. The technicality of that explanation may be horrendous to those who\nunderstand the differences, but the fundamental truth remains: we're dealing\nwith information, inside of cells, on a two-dimensional grid. When you hear the\nnext idiot spew a catch phrase like \"data is the new oil\", the \"data\" they're\nreferring to is akin to that sick Excel sheet you made at work.\n\nScenario: Finding Mismatches in Data\nThis scenario actually stems from a real-life example which, sure enough, was my\nfirst encounter with Pandas. One could argue I owe much 0f my data career to a\n3am Google Hangout with Snkia.\n\nIn our scenario, our company has signed up for a very expensive software product\nwhich charges by individual license. To our surprise, the number of licenses for\nthis software totaled over 1000  seats!  After giving this data a quick glance,\nhowever, it's clear that many of these employees have actually been terminated,\nthus resulting in unspeakable loss in revenue. \n\nThe good news is we have another dataset called active employees (aka: employees\nwhich have not been terminated... yet). So, how do we use these two sets of data\nto determine which software licenses are valid? First, let's look at the types \nof ways we can merge data in Pandas.\n\nTerminology\nMERGE\nSets of data can be merged in a number of ways. Merges can either be used to\nfind similarities in two Dataframes and merge associated information, or may be\nentirely non-destructive in the way that two sets of data are merged.\n\nKEY\nIn many cases (such as the one in this tutorial) you'd likely want to merge two\nDataframes based on the value of a key. A key is the authoritative column by\nwhich the Dataframes will be merged. When merging Dataframes in this way, keys\nwill stay in tact as an identifier while the values of columns in the same row\nassociated to that key.\n\nThis type of merge can be used when two Dataframes hold differing fields for\nsimilar rows. If Dataframe 1 contains the phone numbers of customers by name,\nand Dataframe 2 contains emails of a similar grouping of people, these two may\nbe merged to create a single collection of data with all of this information.\n\nAXIS\nA parameter of pandas functions which determines whether the function should be\nrun against a Dataframe's columns or rows. An axis of 0 determines that the\naction will be taken on a per-row basis, where an axis of 1 denotes column.\n\nFor example, performing a drop with axis 0 on key X will drop the row where\nvalue of a cell is equal to X.\n\nLEFT/RIGHT MERGE\nAn example of a left/right merge can be seen below:\n\nJoin on keys found in left Dataframe.The two data frames above hold similar keys\nwith different associated information per axis, thus the result is a combination\nof these two Dataframes where the keys remain intact.\n\n\"Left\" or \"right\" refer to the left or right Dataframes above. If the keys from\nboth Dataframes do not match 1-to-1, specifying a left/right merge determines\nwhich Dataframe's keys will be considered the authority to be preserved in the\nmerge.\n\nJoin on keys found in right Dataframe.INNER MERGE\nAn inner merge will merge two Dataframes based on overlap of values between keys\nin both Dataframes:\n\nJoin on keys found in right Dataframe.OUTER MERGE\nAn outer merge will preserve the most data by not dropping keys which are\nuncommon to both Dataframes. Keys which exist in a single Dataframe will be\nadded to the resulting Dataframe, with empty values populated for any columns\nbrought in by the other Dataframe:\n\nBack to our Scenario: Merging Two Dataframes via Left Merge\nLet's get it going. Enter the iPython shell.\n\nImport Pandas and read both of your CSV files.\n\nimport pandas as pd\n\ndf = pd.read_csv(\"csv1.csv\")  \ndf2 = pd.read_csv(\"csv2.csv\")\n\n\nThe above opens the CSVs as Dataframes recognizable by pandas.\nNext, we'll merge the two CSV files.\n\nHow  specifies the type of merge, and on  specifies the column to merge by\n(key). The key must be present in both Dataframes.\n\nFor the purpose of this exercise we'll be merging left, as that is the CSV which\ncontains the keys we'd like to maintain.\n\nmergedDF = df2.merge(df, how=“left”, on=\"email\")\n\nprint(mergedDF)\n\n\nThis should return a dataset of all common rows, with columns from both CSVs\nincluded in the merge.\n\nScenario 2: Missing Data\nBefore we go, let's toss in another scenario for good measure.\n\nThis time around we have two datasets which should actually probably be a single\ndataset. Dataset #1  contains all customers once again, but for some reason, \nDataset #1  contains email address where set Dataset #2  does not. Similarly, \nDataset #2  contains addresses which are  missing in Dataset #1. We assume there\nis no reason to keep these sets of data isolated other than human error.\n\nIn the case where we are confident that employees exist in both datasets but\ncontain different information, performing an inner  merge will join these two\nsets by a key such as customer ID or email. If all goes well, the final dataset\nshould equal the same number of rows found in both Datasets #1 and #2.\n\nDocumentation\nFor more on merging, check out the official Pandas documentation here\n[https://pandas.pydata.org/pandas-docs/stable/merging.html].","html":"<style>\n    img {\n        border: 0 !important;\n    }\n </style>   <p>Let's say you have two obscenely large sets of data. </p><p>These sets of data contain information on a similar topic, such as customers. <strong>Dataset #1 </strong>might contain a high-level view of all customers of a business, while <strong>Datatset #2</strong> contains a lifetime history of orders for a company. Unsurprisingly, the customers in Dataset #1 appear in Dataset x#2, as any business' orders are made by customers.</p><h2 id=\"welcome-to-relational-databases\">Welcome to Relational Databases</h2><p>What we just described is the core foundation for <em>relational databases</em> which have been running at the core of businesses since the 1970s. Starting with familiar names like <strong>MySQL</strong>,<strong> Oracle</strong>, and <strong>Postgres,</strong> the concept of maintaining multiple -<em>related- </em>tables of data are the bare minimum technology stack for any company, regardless of what said company does.</p><p>While our example of <strong>Datasets #1 and #2</strong> can be thought of as isolated tables, the process of 'joining' them <em>(in SQL terms) </em>or 'merging' them <em>(in Pandas terms)</em> is  trivial. What's more, we can do far more than with JOINS (or merges) than simply combining our data into a single set.</p><h3 id=\"enter-the-panda\">Enter The Panda</h3><p>Python happens to have an obscenely popular library for performing SQL-like logic, dubbed <strong>Pandas. </strong>If it remains unclear as to what Pandas is, just remember: <em>Databases are basically Excel spreadsheets are basically an interface for Pandas</em>. The technicality of that explanation may be horrendous to those who understand the differences, but the fundamental truth remains: we're dealing with information, inside of cells, on a two-dimensional grid. When you hear the next idiot spew a catch phrase like <em>\"data is the new oil\"</em>, the \"data\" they're referring to is akin to that sick Excel sheet you made at work.</p><h3 id=\"scenario-finding-mismatches-in-data\">Scenario: Finding Mismatches in Data</h3><p>This scenario actually stems from a real-life example which, sure enough, was my first encounter with Pandas. One could argue I owe much 0f my data career to a 3am Google Hangout with Snkia.</p><p>In our scenario, our company has signed up for a very expensive software product which charges by individual license. To our surprise, the number of licenses for this software totaled <strong>over 1000</strong> seats!<strong> </strong>After giving this data a quick glance, however, it's clear that many of these employees have actually been terminated, thus resulting in unspeakable loss in revenue. </p><p>The good news is we have another dataset called <em>active employees </em>(aka: employees which have not been terminated... yet). So, how do we use these two sets of data to determine which software licenses are valid? First, let's look at the <em>types</em> of ways we can merge data in Pandas.</p><h2 id=\"terminology\">Terminology</h2><h3 id=\"merge\">MERGE</h3><p>Sets of data can be merged in a number of ways. Merges can either be used to find similarities in two Dataframes and merge associated information, or may be entirely non-destructive in the way that two sets of data are merged.</p><h3 id=\"key\">KEY</h3><p>In many cases (such as the one in this tutorial) you'd likely want to merge two Dataframes based on the value of a key. A key is the authoritative column by which the Dataframes will be merged. When merging Dataframes in this way, keys will stay in tact as an identifier while the values of columns in the same row associated to that key.</p><p>This type of merge can be used when two Dataframes hold differing fields for similar rows. If Dataframe 1 contains the phone numbers of customers by name, and Dataframe 2 contains emails of a similar grouping of people, these two may be merged to create a single collection of data with all of this information.</p><h3 id=\"axis\">AXIS</h3><p>A parameter of pandas functions which determines whether the function should be run against a Dataframe's columns or rows. An axis of 0 determines that the action will be taken on a per-row basis, where an axis of 1 denotes column.</p><p>For example, performing a drop with axis 0 on key X will drop the row where value of a cell is equal to X.</p><h3 id=\"left-right-merge\">LEFT/RIGHT MERGE</h3><p>An example of a left/right merge can be seen below:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/pandasleftjoin.png\" class=\"kg-image\"><figcaption>Join on keys found in left Dataframe.</figcaption></figure><p>The two data frames above hold similar keys with different associated information per axis, thus the result is a combination of these two Dataframes where the keys remain intact.</p><p>\"Left\" or \"right\" refer to the left or right Dataframes above. If the keys from both Dataframes do not match 1-to-1, specifying a left/right merge determines which Dataframe's keys will be considered the authority to be preserved in the merge.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/pandasrightjoin.png\" class=\"kg-image\"><figcaption>Join on keys found in right Dataframe.</figcaption></figure><h3 id=\"inner-merge\">INNER MERGE</h3><p>An inner merge will merge two Dataframes based on overlap of values between keys in both Dataframes:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/pandasinnerjoin.png\" class=\"kg-image\"><figcaption>Join on keys found in right Dataframe.</figcaption></figure><h3 id=\"outer-merge\">OUTER MERGE</h3><p>An outer merge will preserve the most data by not dropping keys which are uncommon to both Dataframes. Keys which exist in a single Dataframe will be added to the resulting Dataframe, with empty values populated for any columns brought in by the other Dataframe:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/pandasouterjoin.png\" class=\"kg-image\"></figure><h2 id=\"back-to-our-scenario-merging-two-dataframes-via-left-merge\">Back to our Scenario: Merging Two Dataframes via Left Merge</h2><p>Let's get it going. Enter the iPython shell.</p><p>Import Pandas and read both of your CSV files.</p><pre><code class=\"language-python\">import pandas as pd\n\ndf = pd.read_csv(&quot;csv1.csv&quot;)  \ndf2 = pd.read_csv(&quot;csv2.csv&quot;)\n</code></pre>\n<p>The above opens the CSVs as Dataframes recognizable by pandas.<br>Next, we'll merge the two CSV files.</p><p><strong>How</strong> specifies the type of merge, and <strong>on</strong> specifies the column to merge by (key). The key must be present in both Dataframes.</p><p>For the purpose of this exercise we'll be merging left, as that is the CSV which contains the keys we'd like to maintain.</p><pre><code class=\"language-python\">mergedDF = df2.merge(df, how=“left”, on=&quot;email&quot;)\n\nprint(mergedDF)\n</code></pre>\n<p>This should return a dataset of all common rows, with columns from both CSVs included in the merge.</p><h2 id=\"scenario-2-missing-data\">Scenario 2: Missing Data</h2><p>Before we go, let's toss in another scenario for good measure.</p><p>This time around we have two datasets which should actually probably be a single dataset. <strong>Dataset #1</strong> contains all customers once again, but for some reason, <strong>Dataset #1</strong> contains email address where set <strong>Dataset #2</strong> does not. Similarly, <strong>Dataset #2</strong> contains addresses which are  missing in <strong>Dataset #1</strong>. We assume there is no reason to keep these sets of data isolated other than human error.</p><p>In the case where we are confident that employees exist in both datasets but contain different information, performing an <em>inner</em> merge will join these two sets by a key such as customer ID or email. If all goes well, the final dataset should equal the same number of rows found in both <strong>Datasets #1 and #2</strong>.</p><h2 id=\"documentation\">Documentation</h2><p>For more on merging, check out the official Pandas documentation <a href=\"https://pandas.pydata.org/pandas-docs/stable/merging.html\">here</a>.</p>","url":"https://hackersandslackers.com/merge-dataframes-with-pandas/","uuid":"d2c59476-d879-484c-b719-55f53b3d4980","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a0f7a3ce38d612cc8261316"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867362f","title":"Generating Tree Hierarchies with Treelib","slug":"creating-trees-in-treelib","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2017/11/tree7@2x.jpg","excerpt":"Using Python to visualize file hierarchies as trees.","custom_excerpt":"Using Python to visualize file hierarchies as trees.","created_at_pretty":"17 November, 2017","published_at_pretty":"17 November, 2017","updated_at_pretty":"28 March, 2019","created_at":"2017-11-17T15:45:10.000-05:00","published_at":"2017-11-17T15:56:40.000-05:00","updated_at":"2019-03-28T05:02:39.000-04:00","meta_title":"Tree Hierarchies with Treelib | Hackers and Slackers","meta_description":"Treelib is a Python library that allows you to create a visual tree hierarchy: a simple plaintext representation of parent-child relationships.","og_description":"Treelib is a Python library that allows you to create a visual tree hierarchy: a simple plaintext representation of parent-child relationships.","og_image":"https://hackersandslackers.com/content/images/2017/11/tree7@2x.jpg","og_title":"Tree Hierarchies with Treelib","twitter_description":"Treelib is a Python library that allows you to create a visual tree hierarchy: a simple plaintext representation of parent-child relationships.","twitter_image":"https://hackersandslackers.com/content/images/2017/11/tree7@2x.jpg","twitter_title":"Tree Hierarchies with Treelib","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"The first part of understanding any type of software is taking a glance at its\nfile structure. It may seem like an outlandish and redundant statement to make\nto a generation who grew up on GUIs. GitHub is essentially no more than a GUI\nfor Git, so it’s unsurprisingly that one of the largest company to follow a\nsimilar business model recently bought Github for millions. \n\nAll that said, a question remains: how do we being to understand closed source\napplications? If we can’t see the structure behind an app, I suppose we’ll have\nto build this model ourselves.\n\nTreelib [https://treelib.readthedocs.io/en/latest/]  is a Python library that\nallows you to create a visual tree hierarchy: a simple plaintext representation\nof parent-child relationships.\n\nAside from scraping and mapping the intellectual property of others, Treelib\ncomes in handy in situations where we have access to flat information (like a\ndatabase table) where rows actually relate to one another (such as monolithic\ncontent-heavy site).\n\nTreelib prints results like this: \n\nHarry\n├── Bill\n│   └── n1\n│       ├── n2\n│       └── n3\n└── Jane\n    ├── Diane\n    │   └── Mary\n    └── Mark \n\n\nIt’s is a simple library, and only requires knowledge of a few lines of code in\norder to be used effectively. What’s more, we’re not simply spitting out flat\nuseless data; we're storing these node relationships in memory. If needed, the\ntrees we build can be modified or used for other the future.\n\nWhere da Treez At?\nInstall the Treelib package:\n\npip install treelib\n\n\nIn your project, import Treelib:\n\n# trees.py\nimport from treelib import Node, Tree\n\n\nCreate a Tree with a Parent Node\nThe first step in utilizing Treelib is to create a tree object. We need to give\nour tree a name - this is essentially creating the top-level node that all other\nnodes will stem from. \n\nIn createNode(x, y), X is the value which will be displayed in the node, while Y\nis the unique identifier for that node. Children will be added to this parent\nnode by referencing the unique identifier.\n\nNote that in trees created with TreeLib, unique identifiers may only occur once.\nTherefore it is good to follow a sort of GUI system for identifying nodes.\n\n# tree.py\n\n# Create tree object\ntree = Tree() \n\n# Create the base node\ntree.create_node(\"Confluence\", \"confluence\") \n\n\nCreate Child Nodes\nThe last necessary part of creating a tree is, of course, populating the\nresulting children.\n\nWe will once again use create_node to add additional nodes, but these nodes will\nbe associated with parents via parent=”x”. This will locate existing nodes in\nthe tree by ID and associate these new nodes to that parent. This is why IDs\nmust be unique for each node in the tree.\n\n# tree.py\ntree.create_node(spaceName, id, parent=\"confluence\")\n\n\nView the Tree\nFinally, you'll want to view the fruits of your labor:\n\nprint(tree.show())\n\n\nWay to go Johnny Appleseed, that’s pretty much the gist of it. There are\nadditional features in the way Trees can be parse, and the way that nodes store\nadditional data.\n\nCheck the official documentation [https://treelib.readthedocs.io/en/latest/] \nfor a full list of features.\n\nBonus Round\nIf all you care about is printing the file structure of a current directory with\nzero interest in working with the actual data, you’re in luck (at least on Mac,\nhell if I know anything about Windows).\n\nUnix systems come with a package named tree  which does just what we want. On\nMac OSX, we can install tree  using Homebrew:\n\n$ brew install tree\n\n\nGo ahead and explore the various features of tree, such as writing to files or\neven doing so on a schedule. For now, here's some basic usage:\n\n$ tree -v -L 1 --charset utf-8","html":"<p>The first part of understanding any type of software is taking a glance at its file structure. It may seem like an outlandish and redundant statement to make to a generation who grew up on GUIs. GitHub is essentially no more than a GUI for Git, so it’s unsurprisingly that one of the largest company to follow a similar business model recently bought Github for millions. </p><p>All that said, a question remains: how do we being to understand closed source applications? If we can’t see the structure behind an app, I suppose we’ll have to build this model ourselves.</p><p><strong><a href=\"https://treelib.readthedocs.io/en/latest/\">Treelib</a></strong> is a Python library that allows you to create a visual tree hierarchy: a simple plaintext representation of parent-child relationships.</p><p>Aside from scraping and mapping the intellectual property of others, Treelib comes in handy in situations where we have access to flat information (like a database table) where rows actually relate to one another (such as monolithic content-heavy site).</p><p>Treelib prints results like this: </p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">Harry\n├── Bill\n│   └── n1\n│       ├── n2\n│       └── n3\n└── Jane\n    ├── Diane\n    │   └── Mary\n    └── Mark \n</code></pre>\n<!--kg-card-end: markdown--><p>It’s is a simple library, and only requires knowledge of a few lines of code in order to be used effectively. What’s more, we’re not simply spitting out flat useless data; we're storing these node relationships in memory. If needed, the trees we build can be modified or used for other the future.</p><h2 id=\"where-da-treez-at\">Where da Treez At?</h2><p>Install the Treelib package:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">pip install treelib\n</code></pre>\n<!--kg-card-end: markdown--><p>In your project, import Treelib:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># trees.py\nimport from treelib import Node, Tree\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"create-a-tree-with-a-parent-node\">Create a Tree with a Parent Node</h3><p>The first step in utilizing Treelib is to create a tree object. We need to give our tree a name - this is essentially creating the top-level node that all other nodes will stem from. </p><p>In createNode(x, y), X is the value which will be displayed in the node, while Y is the unique identifier for that node. Children will be added to this parent node by referencing the unique identifier.</p><p>Note that in trees created with TreeLib, unique identifiers may only occur once. Therefore it is good to follow a sort of GUI system for identifying nodes.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># tree.py\n\n# Create tree object\ntree = Tree() \n\n# Create the base node\ntree.create_node(&quot;Confluence&quot;, &quot;confluence&quot;) \n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"create-child-nodes\">Create Child Nodes</h2><p>The last necessary part of creating a tree is, of course, populating the resulting children.</p><p>We will once again use create_node to add additional nodes, but these nodes will be associated with parents via parent=”x”. This will locate existing nodes in the tree by ID and associate these new nodes to that parent. This is why IDs must be unique for each node in the tree.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># tree.py\ntree.create_node(spaceName, id, parent=&quot;confluence&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"view-the-tree\">View the Tree</h3><p>Finally, you'll want to view the fruits of your labor:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">print(tree.show())\n</code></pre>\n<!--kg-card-end: markdown--><p>Way to go Johnny Appleseed, that’s pretty much the gist of it. There are additional features in the way Trees can be parse, and the way that nodes store additional data.</p><p>Check the <a href=\"https://treelib.readthedocs.io/en/latest/\">official documentation</a> for a full list of features.</p><h2 id=\"bonus-round\">Bonus Round</h2><p>If all you care about is printing the file structure of a current directory with zero interest in working with the actual data, you’re in luck (at least on Mac, hell if I know anything about Windows).</p><p>Unix systems come with a package named <strong>tree</strong> which does just what we want. On Mac OSX, we can install <strong>tree</strong> using Homebrew:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ brew install tree\n</code></pre>\n<!--kg-card-end: markdown--><p>Go ahead and explore the various features of tree, such as writing to files or even doing so on a schedule. For now, here's some basic usage:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ tree -v -L 1 --charset utf-8\n</code></pre>\n<!--kg-card-end: markdown-->","url":"https://hackersandslackers.com/creating-trees-in-treelib/","uuid":"f0c176ee-c88a-443c-a7b7-b5c5e7c5b9f7","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a0f4a56e38d612cc826130d"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867363f","title":"Another \"Intro to Data Analysis in Python Using Pandas\" Post","slug":"intro-to-data-analysis-in-python-using-pandas","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/intropandas-1-4@2x.jpg","excerpt":"Obligatory Pandas tutorial by a questionably qualified stranger.","custom_excerpt":"Obligatory Pandas tutorial by a questionably qualified stranger.","created_at_pretty":"19 April, 2018","published_at_pretty":"16 November, 2017","updated_at_pretty":"10 April, 2019","created_at":"2018-04-18T21:18:27.000-04:00","published_at":"2017-11-16T10:52:00.000-05:00","updated_at":"2019-04-10T10:33:17.000-04:00","meta_title":"Intro to Data Analysis in Python Using Pandas | Hackers and Slackers","meta_description":"Obligatory introduction to Pandas by a questionably qualified stranger. Learn the anatomy of a DataFrame, how to load data, and selecting subsets of data.","og_description":"Obligatory introduction to Pandas by a questionably qualified stranger. Learn the anatomy of a DataFrame, how to load data, and selecting subsets of data.","og_image":"https://hackersandslackers.com/content/images/2019/02/intropandas-1-4@2x.jpg","og_title":"Intro to Data Analysis in Python Using Pandas","twitter_description":"Obligatory introduction to Pandas by a questionably qualified stranger. Learn the anatomy of a DataFrame, how to load data, and selecting subsets of data.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/intropandas-1-4@2x.jpg","twitter_title":"Intro to Data Analysis in Python Using Pandas","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"#Data Analysis with Pandas","slug":"data-analysis-pandas","description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pandasseries-1.jpg","meta_description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","meta_title":"Data Analysis with Pandas","visibility":"internal"},{"name":"Data Analysis","slug":"data-analysis","description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","feature_image":null,"meta_description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","meta_title":"Data Analysis | Hackers and Slackers","visibility":"public"}],"plaintext":"Let’s face it: the last thing the world needs is another “Intro to Pandas” post.\nAnybody strange enough to read this blog surely had the same reaction to\ndiscovering Pandas as I did: a manic euphoria that can only be described as love\nat first sight. We wanted to tell the world, and that we did. A lot. Yet here I\nam, about to helplessly sing cliche praises one more time. \n\nI’m a prisoner of circumstance here. As it turns out, the vast (and I mean vast)\nmajority of our fans have a raging Pandas addiction. They come to our humble\nmom-and-pop shop here at Hackers and Slackers foaming at the mouth, going on\nraging benders for all Pandas-related content. If I had half a brain, I’d rename\nthis site Pandas and Pandas  and delete all non-Pandas-related content. Talk\nabout cash money. \n\nAs a middle-ground, I’ve decided to do a bit of housekeeping. My previous “Intro\nto Pandas” post was an unflattering belligerent mess jotted into a Confluence\ninstance long ago during a Friday night  pregame. That mess snuck its way on to\nthis blog, and has gone unnoticed for a year now. I've decided that this\nprobably wasn't the best way to open up a series about the most influential\nPython library of all time. We're going to try this again... For the Pandas.\n\nIntro to Pandas Rereleased: in IMAX 8k 4D \nPandas is used to analyze and modify tabular data in Python. When we say\n“tabular data,” we mean any instance in life where data is represented in a\ntable format. Excel, SQL databases, shitty HTML tables.... they’ve all been the\nsame thing with different syntax this whole time. Pandas can achieve anything\nthat any other table can. \n\nIf you’re reasonably green to data analysis and are experiencing the \n“oh-my-God-all-data-professions-are-kinda-just-Excel”  realization as we speak,\nfeel free to take a moment. Great, that’s behind us now.\n\nThe Anatomy of a DataFrame\nTabular data in Pandas is referred to as a “DataFrame.” We can’t call everything \n “tables-” otherwise, our choice of vague terminology would grow horribly\nconfusing when we refer to data in different systems. Between you and me though,\nDataFrames are basically tables.\n\nSo how do we represent two-dimensional data via command line: a concept which\ninherently interprets and displays information one-dimensionally? \n\n\"Oh nothing, we think it's cute.\"DataFrames consist of individual parts which\nare easy-to-understand at face value. It’s the complexity of these things\ntogether, creating a sum greater than the whole of its parts, which fuels the\nseemingly endless power of DataFrames. If we want any  hope of contributing to\nthe field of Data Science, we need to not only understand the terminology but at\nleast be aware of core concepts of what a DataFrame is beneath the hood. This\nunderstanding is what separates engineers from Excel monkeys. \n\nEngineers\n1\nWinExcel Nerds\n0\nLoseParts of a DataFrame\nWere you expecting this post just to be a bunch of one-liners in Pandas? Good, I\nhope you're disappointed. Strap yourself in, we might actually learn something\ntoday. Class is now in session, baby. Let's break apart what makes a DataFrame,\npiece-by-piece:\n\nThe most basic description of any table would be a collection of columns and \nrows. Despite looking at a two-dimensional grid, columns are in fact very\ndifferent from rows. Unlike rows, all data in a column  typically abides by the\nsame data type. In the above example, any value saved in the startTime  column\nwill always be a time. Rows, on the other hand, are simply an entry- an instance\nof a \"thing\", where each thing is described by attributes stored horizontally\nacross columns.\n\nThis seems like really elementary stuff, but I mention it for a reason. By our\ndefinition, columns  are more pivotal to structuring a table than rows, because\neven empty columns have meaning, whereas an empty row with no columns will\nalways equal infinite nothingness. Rows are made up of values in columns, not\nthe other way around. Thus, columns in Pandas are actually their own type of\nobject called a Series. \n\n * Series' are objects native to Pandas (and Numpy) which refer to\n   one-dimensional sequences of data. Another example of a one-dimensional\n   sequence of data could be an array, but series' are much more than arrays:\n   they're a class of their own for many powerful reasons, which we'll see in a\n   moment.\n * Axis  refers to the 'direction' of a series, or in other words \"column\" or\n   \"row\". A series with an axis of 0  is a row, whereas a series with an axis of\n    1  is a column. \n * A series contains labels, which are given visual names for a row/column\n   specifying labels allows us to call upon any labeled series in the same way\n   we would access a value in a Python dictionary. For instance, accessing \n   dataframe['awayTeamName']  returns the entire column matching the header \n   \"awayTeamName\".\n * Every row and column has a numerical index. Most of the time, a row's label \n   will be equivalent to the row's index. While it's common practice to define\n   headers for columns, columns have indexes as well, which simply aren't shown.\n   In this regard, Series share an attribute with lists/arrays, in that they are\n   a collection of indexed values\n\nConsider the last two points: we just described a series to work the same way as\na Python dictionary, but also the same way as a Python list. That's right:\nseries' objects are like the biracial offspring of lists and dicts. We can\naccess any column by either its name or its index, and the same goes for rows.\nEven if we rip a column out from a DataFrame, each cell in that series will\nstill retain the row labels for every cell. This means we can say things like \nget me column #3, and then find me the value for whatever was in the row labeled\n\"Y\".  Of course, this works in the reverse as well. It's crazy how things get\nexponentially more powerful and complicated when we add entire dimensions, isn't\nit?\n\nLoading Data Into Pandas\nIf you've made it this far, you've earned the right to start getting hands-on.\nLuckily, Pandas has plenty of methods to load tabular data into DataFrames,\nregardless if you're using static files, SQL, or quirkier methods, Pandas has\nyou covered. Here are some of my favorite examples:\n\nimport pandas as pd\n\n# Reads a local CSV file.\ncsv_df = pd.read_csv('data.csv')\n\n# Similar to above\nexcel_df = pd.read_excel('data.xlsx')\n\n# Creating tabular data from non-tabular JSON\njson_df = pd.read_json('data.json')\n\n# Direct db access utilizing SQLAlchemy\nread_sql = read_sql('SELECT * FROM blah', conn=sqlalchemy_engine)\n\n# My personal ridiculous favorite: HTML table to DataFrame.\nread_html = read_html('examplePageWithTable.html')\n\n# The strength of Google BigQuery: already officially supported by Pandas\nread_gbq = read_gbq('SELECT * FROM test_dataset.test_table', projectid)\n\n\nAll of these achieve the same result of creating a DataFrame. No matter what\nhorrible data sources you may have been forced to inherit, Pandas is here to\nhelp. Pandas knows our pain. Pandas is love. Pandas is life.\n\nWith data loaded, let's see how we can apply our new knowledge of series'  to\ninteract with out data.\n\nFinding Data in Our Dataframe\nPandas has a method for finding a series by label, as well as a separate method\nfor finding a series by index. These methods are .iloc  and .loc, respectively.\nLet's say our DataFrame from the example above is stored as a variable named \nbaseball_df. To get the values of a column by name, we would do the following:\n\nbaseball_df = baseball_df.iloc['homeTeamName']\nprint(baseball_df)\n\n\nThis would return the following:\n\n0   Cubs\n1   Indians\n2   Padres\n3   Diamondbacks\n4   Giants\n5   Blue Jays\n6   Reds\n7   Cubs\n8   Rockies\n9   Yankees\nName: homeTeamName, dtype: object\n\n\nThat's our column! We can see the row labels being listed alongside each row's\nvalue. Told ya so. Getting a column will also return the column's dtype, or data\ntype. Data types can be set on columns explicitly. If they aren't, Pandas will\ngenerally either default to detecting that the data in the column is a float \n(returned for any column which only holds numerical values, despite number of\ndecimal points) or an 'object', which is a fancy catch-all meaning \"fuck if I\nknow, there's letters and shit in there, it could be anything probably.\" Pandas\ndoesn't try hard on its own to discern the types of data in each field.\n\nIf you're thinking ahead, you might see a looming conflict of interest with iloc\n. Since we've established that columns and rows are the same, and we're\naccessing series' based on criteria that is met by both  columns and rows (every\ntable has a first row and a first column), how does Pandas know what we want\nwith .loc()? Short answer: It doesn't, so it just returns both! \n\nbaseball_df = baseball_df.loc[3]\nprint(baseball_df)\n\n\n    homeTeamName    awayTeamName   startTime      duration_minutes\n0   Cubs            Reds           18:20:00 UTC   188\n1   Indians         Astros         18:20:00 UTC   194\n2   Padres          Giants         18:20:00 UTC   185\n3   Diamondbacks    Brewers        18:20:00 UTC   211\n\n\nAhhh, a 4x4 grid! This does, in fact, satisfy what we asked for- albiet in a\nclever, intentional way. \"Clever and intentional\"  is actually a great way to\ndescribe Pandas as a library. This combination of ease and power is what makes\nPandas so magnetic to curious newcomers. \n\nWant another example? How about leveraging the unique attributes of series'  to\nsplice DataFrames as though they were arrays?\n\nsliced_df = df.loc['homeTeamName':'awayTeamName']\nprint(sliced_df)\n\n\n    homeTeamName    awayTeamName\n0   Cubs            Reds        \n1   Indians         Astros      \n2   Padres          Giants      \n3   Diamondbacks    Brewers     \n\n\n...Did we just do that? We totally did. We were able to slice a two-dimensional\nset of data by using the same syntax that we'd used to slice arrays, thanks to\nthe power of the series object.\n\nWelcome to the Club\nThere are a lot more entertaining, mind-blowing ways to introduce people to\nPandas. If our goal had been sheer amusement, we would have leveraged the\ncookie-cutter route to Pandas tutorials: overloading readers with Pandas\n\"tricks\" displaying immense power in minimal effort. Unfortunately, we took the\napplicable approach to actually retaining information. Surely this model of\n\"informational and time consuming\" will beat out \"useless but instantly\ngratifying,\" right? RIGHT? \n\nWhatever. I’ll schedule the Pandas and Pandas rebrand for next week. From now on\nwhen people want that quick fix, you can call me Pablo Escobar. Join us next\ntime when we use Pandas data analysis to determine which private Caribbean\nisland offers the best return on investment with all the filthy money we’ll\nmake.\n\nHint: it’s definitely not the Fyre festival one.","html":"<p>Let’s face it: the last thing the world needs is another “<strong>Intro to Pandas</strong>” post. Anybody strange enough to read this blog surely had the same reaction to discovering Pandas as I did: a manic euphoria that can only be described as love at first sight. We wanted to tell the world, and that we did. A lot. Yet here I am, about to helplessly sing cliche praises one more time. </p><p>I’m a prisoner of circumstance here. As it turns out, the vast (and I mean <em><strong>vast</strong></em>) majority of our fans have a raging Pandas addiction. They come to our humble mom-and-pop shop here at <strong>Hackers and Slackers </strong>foaming at the mouth, going on raging benders for all Pandas-related content. If I had half a brain, I’d rename this site <strong>Pandas and Pandas</strong> and delete all non-Pandas-related content. Talk about cash money. </p><p>As a middle-ground, I’ve decided to do a bit of housekeeping. My previous “Intro to Pandas” post was an unflattering belligerent mess jotted into a Confluence instance long ago during a <a>Friday night</a> pregame. That mess snuck its way on to this blog, and has gone unnoticed for a year now. I've decided that this probably wasn't the best way to open up a series about the most influential Python library of all time. We're going to try this again... For the Pandas.</p><h2 id=\"intro-to-pandas-rereleased-in-imax-8k-4d\">Intro to Pandas Rereleased: in IMAX 8k 4D </h2><p>Pandas is used to analyze and modify tabular data in Python. When we say “tabular data,” we mean any instance in life where data is represented in a table format. Excel, SQL databases, shitty HTML tables.... they’ve all been the same thing with different syntax this whole time. Pandas can achieve anything that any other table can. </p><p>If you’re reasonably green to data analysis and are experiencing the <em>“oh-my-God-all-data-professions-are-kinda-just-Excel”</em> realization as we speak, feel free to take a moment. Great, that’s behind us now.</p><h2 id=\"the-anatomy-of-a-dataframe\">The Anatomy of a DataFrame</h2><p>Tabular data in Pandas is referred to as a “DataFrame.” We can’t call <em>everything</em> “tables-” otherwise, our choice of vague terminology would grow horribly confusing when we refer to data in different systems. Between you and me though, DataFrames are basically tables.</p><p>So how do we represent two-dimensional data via command line: a concept which inherently interprets and displays information one-dimensionally? </p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/moon.jpg\" class=\"kg-image\"><figcaption>\"Oh nothing, we think it's cute.\"</figcaption></figure><!--kg-card-end: image--><p>DataFrames consist of individual parts which are easy-to-understand at face value. It’s the complexity of these things together, creating a sum greater than the whole of its parts, which fuels the seemingly endless power of DataFrames. If we want <em>any</em> hope of contributing to the field of Data Science, we need to not only understand the terminology but <em>at least </em>be aware of core concepts of what a DataFrame is beneath the hood. This understanding is what separates engineers from Excel monkeys. </p><!--kg-card-begin: html--><div class=\"scoreboard\">\n\t<!-- Score Header -->\n\t<div class=\"score-header\">\n\t\t<!-- Background -->\n\t\t<div class=\"score-header-background\">\n\t\t\t<div class=\"score-header-background__left\"></div>\n\t\t\t<div class=\"score-header-background__right\"></div>\n\t\t\t<div class=\"score-header-background__logo\"></div>\n\t\t</div>\n\t\t<!-- Foreground -->\n\t\t<div class=\"score-header-foreground\">\n\t\t\t<div class=\"score-header-foreground__left\">\n\t\t\t\t<h1 class=\"score-header-foreground__title\">Engineers</h1>\n\t\t\t\t<h2 class=\"score-header-foreground__score\">1</h2>\n\t\t\t\t<span class=\"score-header-foreground__win\">Win</span>\n\t\t\t</div>\n\t\t\t<div class=\"score-header-foreground__right\">\n\t\t\t\t<h1 class=\"score-header-foreground__title\">Excel Nerds</h1>\n\t\t\t\t<h2 class=\"score-header-foreground__score\">0</h2>\n\t\t\t\t<span class=\"score-header-foreground__win\">Lose</span>\n\t\t\t</div>\n\t\t</div>\n\t</div>\n</div><!--kg-card-end: html--><h2 id=\"parts-of-a-dataframe\">Parts of a DataFrame</h2><p>Were you expecting this post just to be a bunch of one-liners in Pandas? Good, I hope you're disappointed. Strap yourself in, we might actually learn something today. Class is now in session, baby. Let's break apart what makes a DataFrame, piece-by-piece:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/03/dataframe2.jpg\" class=\"kg-image\"></figure><!--kg-card-end: image--><p>The most basic description of any table would be a collection of <strong>columns </strong>and <strong>rows. </strong>Despite looking at a two-dimensional grid, columns are in fact very different from rows. Unlike rows, all data in a <em>column</em> typically abides by the same data type. In the above example, any value saved in the <strong>startTime</strong> column will always be a <strong>time</strong>. Rows, on the other hand, are simply an entry- an instance of a \"thing\", where each thing is described by attributes stored horizontally across columns.</p><p>This seems like really elementary stuff, but I mention it for a reason. By our definition, <em>columns</em> are more pivotal to structuring a table than rows, because even empty columns have meaning, whereas an empty row with no columns will always equal infinite nothingness. <strong>Rows are made up of values in columns, not the other way around. </strong> Thus, columns in Pandas are actually their own type of object called a <strong>Series</strong>. </p><ul><li><strong>Series</strong>' are objects native to Pandas (and Numpy) which refer to one-dimensional sequences of data. Another example of a one-dimensional sequence of data could be an <strong><em>array</em></strong><em>, </em>but series' are much more than arrays: they're a class of their own for many powerful reasons, which we'll see in a moment.</li><li><strong>Axis</strong> refers to the 'direction' of a series, or in other words \"column\" or \"row\". A series with an axis of <code>0</code> is a <em>row</em>, whereas a series with an axis of <code>1</code> is a <em>column</em>. </li><li>A series contains <strong>labels</strong>, which are given visual names for a row/column specifying labels allows us to call upon any labeled series in the same way we would access a value in a Python dictionary. For instance, accessing <code>dataframe['awayTeamName']</code> returns the entire column matching the header <em>\"awayTeamName\"</em>.</li><li>Every row and column has a numerical <strong>index. </strong>Most of the time, a row's <strong>label</strong> will be equivalent to the row's <strong>index. </strong>While it's common practice to define headers for columns, columns have indexes as well, which simply aren't shown. In this regard, Series share an attribute with lists/arrays, in that they are a collection of indexed values</li></ul><p>Consider the last two points: we just described a series to work the same way as a Python dictionary, but also the same way as a Python list. That's right: series' objects are like the biracial offspring of lists and dicts. We can access any column by either its name or its index, and the same goes for rows. Even if we rip a column out from a DataFrame, each cell in that series will still retain the row labels for every cell. This means we can say things like <strong>get me column #3, and then find me the value for whatever was in the row labeled \"Y\".</strong> Of course, this works in the reverse as well. It's crazy how things get exponentially more powerful and complicated when we add entire dimensions, isn't it?</p><h2 id=\"loading-data-into-pandas\">Loading Data Into Pandas</h2><p>If you've made it this far, you've earned the right to start getting hands-on. Luckily, Pandas has plenty of methods to load tabular data into DataFrames, regardless if you're using static files, SQL, or quirkier methods, Pandas has you covered. Here are some of my favorite examples:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Reads a local CSV file.\ncsv_df = pd.read_csv('data.csv')\n\n# Similar to above\nexcel_df = pd.read_excel('data.xlsx')\n\n# Creating tabular data from non-tabular JSON\njson_df = pd.read_json('data.json')\n\n# Direct db access utilizing SQLAlchemy\nread_sql = read_sql('SELECT * FROM blah', conn=sqlalchemy_engine)\n\n# My personal ridiculous favorite: HTML table to DataFrame.\nread_html = read_html('examplePageWithTable.html')\n\n# The strength of Google BigQuery: already officially supported by Pandas\nread_gbq = read_gbq('SELECT * FROM test_dataset.test_table', projectid)\n</code></pre>\n<!--kg-card-end: markdown--><p>All of these achieve the same result of creating a DataFrame. No matter what horrible data sources you may have been forced to inherit, Pandas is here to help. Pandas knows our pain. Pandas is love. Pandas is life.</p><p>With data loaded, let's see how we can apply our new knowledge of <strong>series'</strong> to interact with out data.</p><h2 id=\"finding-data-in-our-dataframe\">Finding Data in Our Dataframe</h2><p>Pandas has a method for finding a series by label, as well as a separate method for finding a series by index. These methods are <code>.iloc</code> and <code>.loc</code>, respectively. Let's say our DataFrame from the example above is stored as a variable named <code>baseball_df</code>. To get the values of a column by name, we would do the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">baseball_df = baseball_df.iloc['homeTeamName']\nprint(baseball_df)\n</code></pre>\n<!--kg-card-end: markdown--><p>This would return the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">0   Cubs\n1   Indians\n2   Padres\n3   Diamondbacks\n4   Giants\n5   Blue Jays\n6   Reds\n7   Cubs\n8   Rockies\n9   Yankees\nName: homeTeamName, dtype: object\n</code></pre>\n<!--kg-card-end: markdown--><p>That's our column! We can see the row labels being listed alongside each row's value. Told ya so. Getting a column will also return the column's <strong>dtype</strong>, or <em>data type</em>. Data types can be set on columns explicitly. If they aren't, Pandas will generally either default to detecting that the data in the column is a <strong>float</strong> (returned for any column which only holds numerical values, despite number of decimal points) or an '<strong>object'</strong>, which is a fancy catch-all meaning \"fuck if I know, there's letters and shit in there, it could be anything probably.\" Pandas doesn't try hard on its own to discern the types of data in each field.</p><p>If you're thinking ahead, you might see a looming conflict of interest with <code>iloc</code>. Since we've established that columns and rows are the same, and we're accessing series' based on criteria that is met by <em>both</em> columns and rows (every table has a first row and a first column), how does Pandas know what we want with <code>.loc()</code>? Short answer: It doesn't, so it just returns both! </p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">baseball_df = baseball_df.loc[3]\nprint(baseball_df)\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">    homeTeamName    awayTeamName   startTime      duration_minutes\n0   Cubs            Reds           18:20:00 UTC   188\n1   Indians         Astros         18:20:00 UTC   194\n2   Padres          Giants         18:20:00 UTC   185\n3   Diamondbacks    Brewers        18:20:00 UTC   211\n</code></pre>\n<!--kg-card-end: markdown--><p>Ahhh, a 4x4 grid! This does, in fact, satisfy what we asked for- albiet in a clever, intentional way. \"<strong>Clever and intentional\"</strong> is actually a great way to describe Pandas as a library. This combination of ease and power is what makes Pandas so magnetic to curious newcomers. </p><p>Want another example? How about leveraging the unique attributes of <strong>series'</strong> to splice DataFrames as though they were arrays?</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">sliced_df = df.loc['homeTeamName':'awayTeamName']\nprint(sliced_df)\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">    homeTeamName    awayTeamName\n0   Cubs            Reds        \n1   Indians         Astros      \n2   Padres          Giants      \n3   Diamondbacks    Brewers     \n</code></pre>\n<!--kg-card-end: markdown--><p>...Did we just do that? We totally did. We were able to slice a two-dimensional set of data by using the same syntax that we'd used to slice arrays, thanks to the power of the series object.</p><h2 id=\"welcome-to-the-club\">Welcome to the Club</h2><p>There are a lot more entertaining, mind-blowing ways to introduce people to Pandas. If our goal had been sheer amusement, we would have leveraged the cookie-cutter route to Pandas tutorials: overloading readers with Pandas \"tricks\" displaying immense power in minimal effort. Unfortunately, we took the applicable approach to actually retaining information. Surely this model of \"informational and time consuming\" will beat out \"useless but instantly gratifying,\" right? <em>RIGHT? </em></p><p>Whatever. I’ll schedule the <strong>Pandas and Pandas </strong>rebrand for next week. From now on when people want that quick fix, you can call me Pablo Escobar. Join us next time when we use Pandas data analysis to determine which private Caribbean island offers the best return on investment with all the filthy money we’ll make.</p><p>Hint: it’s definitely not the Fyre festival one.</p>","url":"https://hackersandslackers.com/intro-to-data-analysis-in-python-using-pandas/","uuid":"828b4a6f-e6f2-446f-b51e-64fe19e05ba0","page":false,"codeinjection_foot":null,"codeinjection_head":"<style>\n  *,\n  *::before,\n  *::after {\n    box-sizing: inherit;\n  }\n\n  .scoreboard {\n    margin: auto;\n    max-width: 980px;\n    box-shadow: 0 0 10px #b0bddd;\n  }\n\n  .score-header {\n    position: relative;\n    height: 74px;\n    overflow: hidden;\n  }\n\n  .score-header-background {\n    position: absolute;\n    display: flex;\n    height: 100%;\n    width: calc(100% + 63px + 4px);\n    left: -33.5px;\n  }\n\n  .score-header-background .score-header-background__left,\n  .score-header-background .score-header-background__right {\n    position: relative;\n    flex: 1 1 100%;\n    overflow: hidden;\n    border-bottom: 4px solid #fff;\n    transform: skewX(-40deg);\n  }\n\n  .score-header-background .score-header-background__left::before,\n  .score-header-background .score-header-background__right::before {\n    content: \"\";\n    position: absolute;\n    width: 100%;\n    height: 100%;\n    transform: skewX(40deg);\n  }\n\n  .score-header-background .score-header-background__left::after,\n  .score-header-background .score-header-background__right::after {\n    content: \"\";\n    position: absolute;\n    width: 100%;\n    height: 100%;\n    opacity: 0.35;\n    background: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeAgMAAABGXkYxAAAACVBMVEUAAAD///8AAABzxoNxAAAAAnRSTlMAAHaTzTgAAAAlSURBVHhe3cmhEQAACMPAjIhhv+pOiahAsAGvchc6asMhjvdrAFlGOgM9VYUmAAAAAElFTkSuQmCC');\n  }\n\n  .score-header-background .score-header-background__left {\n    margin-right: 5px;\n    border-color: #19d9ff;\n  }\n\n  .score-header-background .score-header-background__left::before {\n    right: -31.5px;\n    background: linear-gradient(to left, #19d9ff 31.5px, #a9f6ff 60%);\n  }\n\n  .score-header-background .score-header-background__right {\n    margin-left: 5px;\n    border-color: #ff1979;\n  }\n\n  .score-header-background .score-header-background__right::before {\n    left: -31.5px;\n    background: linear-gradient(to right, #ff1979 31.5px, #ffb5ee 60%);\n  }\n\n  .score-header-background .score-header-background__logo {\n    position: absolute;\n    top: 0;\n    right: 0;\n    bottom: 0;\n    left: 0;\n    margin: auto;\n    width: 60px;\n    height: 60px;\n    border: 5px solid #ffffff;\n    border-radius: 100%;\n    background-color: rgba(111, 77, 238, 0.51);\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiP…A3NDcsNTQ2LjMgDQoJCQkJCQkJIi8+DQoJCTwvZz4NCgk8L2c+DQo8L2c+DQo8L3N2Zz4NCg==);\n  }\n\n  .score-header-foreground {\n    position: absolute;\n    display: flex;\n    height: 100%;\n    width: 100%;\n  }\n\n  .score-header-foreground .score-header-foreground__left,\n  .score-header-foreground .score-header-foreground__right {\n    display: flex;\n    margin: 0 20px;\n    flex: 1 1 100%;\n    align-items: baseline;\n  }\n\n  .score-header-foreground .score-header-foreground__left .score-header-foreground__title {\n    color: #fff;\n  }\n\n  .score-header-foreground .score-header-foreground__left .score-header-foreground__score {\n    margin-right: 20px;\n  }\n\n  .score-header-foreground .score-header-foreground__right {\n    flex-direction: row-reverse;\n    text-align: right;\n  }\n\n  .score-header-foreground .score-header-foreground__right .score-header-foreground__title {\n    color: #fff;\n  }\n\n  .score-header-foreground .score-header-foreground__right .score-header-foreground__score {\n    margin-left: 20px;\n  }\n\n  .score-header-foreground .score-header-foreground__title,\n  .score-header-foreground .score-header-foreground__score,\n  .score-header-foreground .score-header-foreground__win {\n    margin: 0 10px;\n    line-height: 69px;\n    text-transform: uppercase;\n  }\n\n  .score-header-foreground .score-header-foreground__title {\n    margin: 0;\n    flex: 1 1 auto;\n    font-size: 30px;\n  }\n\n  .score-header-foreground .score-header-foreground__score {\n    order: 1;\n    text-shadow: 0 0 4px rgba(255, 255, 255, 0.75), 0 0 8px rgba(255, 255, 255, 0.45);\n    font-size: 30px;\n    color: white;\n  }\n\n  .score-header-foreground .score-header-foreground__win {\n    font-size: 18px;\n    font-weight: 600;\n    font-family: 'TTNorms-Medium', sans-serif;\n    color: white;\n    color: #4a47a2;\n    mix-blend-mode: color-burn;\n  }\n\n  .player-list {\n    display: flex;\n    padding: 0;\n    flex-flow: column;\n    list-style: none;\n  }\n\n  .player-row {\n    display: flex;\n    margin: 20px 0;\n    flex: 1 1 auto;\n    align-items: center;\n  }\n\n  .player {\n    display: flex;\n    padding: 20px;\n    min-width: 0;\n    flex: 1 1 auto;\n    align-items: center;\n  }\n\n  .player.player--left {\n    padding-left: 20px;\n  }\n\n  .player.player--left .player__avatar {\n    margin-right: 20px;\n    border-color: #19d9ff;\n  }\n\n  .player.player--right {\n    padding-right: 20px;\n    text-align: right;\n    flex-flow: row-reverse;\n  }\n\n  .player.player--right .player__avatar {\n    margin-left: 20px;\n    border-color: #ff1979;\n  }\n\n  .player .player__avatar {\n    position: relative;\n    min-height: 60px;\n    min-width: 60px;\n    overflow: hidden;\n    border: 3px solid #fff;\n    border-radius: 100%;\n    background-color: #222;\n  }\n\n  .player .player__avatar::before {\n    content: \"\";\n    position: absolute;\n    left: 0;\n    width: 100%;\n    height: 100%;\n    opacity: 0.1;\n    background: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAA8CAMAAAANIilAAAABTVBMVEU7PUP////4+Pj7+/v29vZAQkj6+vpCRErx8fL+/v5BQ0lNT1T9/f3t7u5HSU/8/Pz09PRGSE5aW2BOUFY8PkRJSlB/gITk5eWqq64+QEWPkJSVlppoam5KTFHZ2tvDw8XBwsPa29zP0NGdnqH6+/vExMVVV1z+/v/LzMxRUlidn6HKy8zFxce3uLuVlpmBgYZSVFnz8/SvsLOUlZhkZmv5+flRU1jg4OFDRUrExMepqqyWl5uAgYXMzc7r6+xZWl/AwMKenqFjZWnn6OjBwcJ5en7U1dZ+gIPNzs8/QUbi4+Smp6pSU1lUVVuLjI/j5OWwsLNpam9BQ0hLTFK7vL7p6ep0dXmIio3LzM339/fi4+OrrK5cXmI9P0Wlpqny8/PLy8xzdHh6e3/ExMZVVlzs7e2hoqU+QEbR0tO4ubyHiIzs7O1FR01bXWLz8/PjR6/UAAABIklEQVR4Xu3UxW7FMBCGUU+Sy8xFZmZmZmZmhvdfVuqi9rTprf8uIlXKtz+yNGON+Ke5uQ30NQb/JoMlozGimtopD259DWH6yCxfRG1pGX1WFQVxNSkVYbbOUHF8G8JNUuJPN3NcAeEcx5UQtjgeQ6yHeBaCM8TzOoZP6zmOC6Rzjqch3M/xHIRbOG6FcBvH7RDuMFXb6RNQXSruFlg9MWl7X0EcfZM4Al+xQYmHBNqwxCMwLpY46ygen5B4ElpzOjFDapHZQm06v+AlXmBpeUWHrq6tk13GxubWLzS0Y9JPBXb38sjE/sEh5e3o+MSeJs/8pNHFpc1nvTJIr/D1t9Hf3JJ2d4J3/0D6WSGOkwYBPXL8REjPLwwXQNifcgK72MXv0xEfs26TMDAAAAAASUVORK5CYII=');\n    background-size: cover;\n  }\n\n  .player .player__username {\n    font-size: 24px;\n    text-overflow: ellipsis;\n    overflow: hidden;\n    white-space: nowrap;\n  }\n\n  .language {\n    font-size: 24px;\n  }\n\n  .language.language--html {\n    color: #f69c24;\n  }\n\n  .language.language--css {\n    color: #299bf7;\n  }\n\n  .language.language--js {\n    color: #ffce22;\n  }\n\n  @media (max-width:600px) {\n    .score-header-foreground__title {\n      margin: 0;\n      font-size: 16px;\n      height: fit-content;\n      width: fit-content;\n      /* display: block; */\n      text-shadow: #12183d 1px 1px 1px;\n      position: absolute;\n      bottom: 9px;\n    }\n\n    .score-header-foreground__left,\n    .score-header-foreground__right {\n      margin: 10px 11px 0;\n      display: block;\n      position: relative;\n    }\n\n    .score-header-foreground .score-header-foreground__right .score-header-foreground__score {\n          right: 10px;\n    }\n\n    .score-header-foreground .score-header-foreground__left, .score-header-foreground .score-header-foreground__right {\n          margin: 0 10px;\n          display: block;\n    }\n\n    .score-header-foreground__left .score-header-foreground__title {\n      left:0;\n      margin: 0;\n      font-size: 16px;\n      height: fit-content;\n      width: fit-content;\n      /* display: block; */\n      text-shadow: #12183d 1px 1px 1px;\n      position: absolute;\n      bottom: 9px;\n          line-height: 1;\n    }\n\n    .score-header-foreground__right .score-header-foreground__title {\n      right:0;\n      margin: 0;\n      font-size: 16px;\n      height: fit-content;\n      width: fit-content;\n      /* display: block; */\n      text-shadow: #12183d 1px 1px 1px;\n      position: absolute;\n      bottom: 9px;\n          line-height: 1;\n    }\n\n    .score-header-foreground .score-header-foreground__win {\n      font-size: 12px;\n      font-weight: 600;\n      font-family: 'TTNorms-Medium', sans-serif;\n      color: white;\n      color: #4a47a2;\n      mix-blend-mode: multiply;\n      position: absolute;\n      width: fit-content;\n      bottom: 32px;\n    }\n\n    .score-header-foreground__score {\n      padding: 0;\n      display: block;\n      position: absolute;\n      top: 2px;\n      padding: 0 !important;\n      margin: 0 !important;\n      line-height: 1 !important;\n      height: fit-content;\n          top: 14px;\n    }\n\n    .score-header-foreground__win {\n      position: absolute;\n      bottom: 35px;\n      width: fit-content;\n    }\n\n    .score-header-foreground__right .score-header-foreground__win {\n          right: 36px;\n      bottom: 32px;\n      height: fit-content;\n      line-height: 1;\n      margin: 0;\n    }\n\n    .score-header-foreground__left .score-header-foreground__win {\n      left: 19px;\n      bottom: 32px;\n      height: fit-content;\n      line-height: 1;\n      margin: 0;\n    }\n\n    .score-header-foreground .score-header-foreground__title {\n      right: 10px;\n    }\n  }\n</style>","comment_id":"5ad7ee6365cd784d6288cb03"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673637","title":"Managing Python Environments With Virtualenv","slug":"managing-python-environments","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/virtualenv.jpg","excerpt":"Working with virtualenv and virtualenvwrapper.","custom_excerpt":"Working with virtualenv and virtualenvwrapper.","created_at_pretty":"12 April, 2018","published_at_pretty":"15 November, 2017","updated_at_pretty":"10 April, 2019","created_at":"2018-04-12T17:49:21.000-04:00","published_at":"2017-11-15T17:48:00.000-05:00","updated_at":"2019-04-09T21:05:13.000-04:00","meta_title":"Managing Python Environments | Hackers and Slackers","meta_description":"Keep your Python environments separate with virtualenv and virtualenvwrapper.","og_description":"Keep your Python environments separate with virtualenv and virtualenvwrapper.","og_image":"https://hackersandslackers.com/content/images/2019/04/virtualenv-2.jpg","og_title":"Managing Python Environments With Virtualenv","twitter_description":"Keep your Python environments separate with virtualenv and virtualenvwrapper.","twitter_image":"https://hackersandslackers.com/content/images/2019/04/virtualenv-1.jpg","twitter_title":"Managing Python Environments With Virtualenv","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"As with any programming language, Python uses package managers (pip  in this\ncase) to manage the addition of libraries to be called at runtime. By default,\ninstalling a Python library with pip  will install that package to the default \nPython path,  which is the default folder from which Python stores its installed\npackages. For reference, you can determine you Python path via the following in\nthe Python shell:\n\nimport sys\nprint(sys.path)\n\n['', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python27.zip', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload', '/Library/Python/2.7/site-packages', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/PyObjC']\n\n\nWithout any other specification, Python will always look in the Python path at\nruntime to locate and execute any packages imported by a script. For example,\nlet's say I were to run a script called myscript.py  which attempts to import\nthe 'requests' library, as such:\n\n# myscript.py\nimport requests\n\n\nRunning python myscript.py  in your terminal will attempt to look for the\nlibrary in your generic python path.\n\nEnvironments With Virtualenv\nWhile keeping all your Python packages in one place may be nice at first, this\nbecomes an unmanageable problem when you suddenly find yourself managing\nmultiple projects, each of which may contain different libraries and versions of\nsuch libraries. As such, it is best practice to always encapsulate the library\ndependancies of a project by utilizing one of python's environment manages, such\nas virtualenv.\n\nVirtualenv is the oldest and most common method for managing Python\nenvironments. Creating an environment with virtualenv will create a folder in\nthe user's current directory. This folder represents an environment which can\nthen be 'activated.' This is a way of explicitly using the new environment\ndirectory in place of PYTHONPATH to handle Python packages. As such, we can\ncreate as many environments as we want without worrying about package conflicts.\n\nINSTALLATION\nInstall virtualenv via the following:\n\n$ pip3 install virtualenv\n\n\nWith virtualenv installed, we can then create the environment. cd to the\ndirectory of your choice (preferably the one which you're planning to hold your\nproject) and create an environment with the name of your choice:\n\n$ virtualenv myenv\n\nUsing base prefix '/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6'\nNew python executable in /Users/toddbirchard/myenv/bin/python3.6\nAlso creating executable in /Users/toddbirchard/myenv/bin/python\nInstalling setuptools, pip, wheel...done.\n\n\nA folder should now have been created in the current directory. That folder is\nthe new home of your virtual environment; every time you install a Python\npackage with the environment active, that package will be saved to the directory\nof said environment (as opposed to saved on your machine's Python path).\n\nACTIVATION\nNow that the environment has been created, it must be 'activated'.\n\n$ source myenv/bin/activate\n\n\nYou should notice in the terminal that once this is activated, the command line\nwill always state that the user is working out of the activated environment\nuntil otherwise changed.\n\nAlternative Methods of Virtual Environment Management","html":"<p>As with any programming language, Python uses package managers (<em>pip</em> in this case) to manage the addition of libraries to be called at runtime. By default, installing a Python library with <em>pip</em> will install that package to the default <em>Python path,</em> which is the default folder from which Python stores its installed packages. For reference, you can determine you Python path via the following in the Python shell:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import sys\nprint(sys.path)\n\n['', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python27.zip', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload', '/Library/Python/2.7/site-packages', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/PyObjC']\n</code></pre>\n<!--kg-card-end: markdown--><p>Without any other specification, Python will always look in the Python path at runtime to locate and execute any packages imported by a script. For example, let's say I were to run a script called <code>myscript.py</code> which attempts to import the 'requests' library, as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># myscript.py\nimport requests\n</code></pre>\n<!--kg-card-end: markdown--><p>Running <code>python myscript.py</code> in your terminal will attempt to look for the library in your generic python path.</p><h2 id=\"environments-with-virtualenv\">Environments With Virtualenv</h2><p>While keeping all your Python packages in one place may be nice at first, this becomes an unmanageable problem when you suddenly find yourself managing multiple projects, each of which may contain different libraries and versions of such libraries. As such, it is best practice to always encapsulate the library dependancies of a project by utilizing one of python's environment manages, such as <strong>virtualenv</strong>.</p><p>Virtualenv is the oldest and most common method for managing Python environments. Creating an environment with virtualenv will create a folder in the user's current directory. This folder represents an environment which can then be 'activated.' This is a way of explicitly using the new environment directory in place of PYTHONPATH to handle Python packages. As such, we can create as many environments as we want without worrying about package conflicts.</p><h3 id=\"installation\">INSTALLATION</h3><p>Install virtualenv via the following:</p><!--kg-card-begin: markdown--><pre><code>$ pip3 install virtualenv\n</code></pre>\n<!--kg-card-end: markdown--><p>With virtualenv installed, we can then create the environment. cd to the directory of your choice (preferably the one which you're planning to hold your project) and create an environment with the name of your choice:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">$ virtualenv myenv\n\nUsing base prefix '/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6'\nNew python executable in /Users/toddbirchard/myenv/bin/python3.6\nAlso creating executable in /Users/toddbirchard/myenv/bin/python\nInstalling setuptools, pip, wheel...done.\n</code></pre>\n<!--kg-card-end: markdown--><p>A folder should now have been created in the current directory. That folder is the new home of your virtual environment; every time you install a Python package with the environment active, that package will be saved to the directory of said environment (as opposed to saved on your machine's Python path).</p><h3 id=\"activation\">ACTIVATION</h3><p>Now that the environment has been created, it must be 'activated'.</p><!--kg-card-begin: markdown--><pre><code>$ source myenv/bin/activate\n</code></pre>\n<!--kg-card-end: markdown--><p>You should notice in the terminal that once this is activated, the command line will always state that the user is working out of the activated environment until otherwise changed.</p><h2 id=\"alternative-methods-of-virtual-environment-management\">Alternative Methods of Virtual Environment Management</h2>","url":"https://hackersandslackers.com/managing-python-environments/","uuid":"e5af4c12-7a41-4152-970f-63f20b8b2fde","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5acfd461583e28622a7833f9"}}]}},"pageContext":{"slug":"python","limit":12,"skip":72,"numberOfPages":7,"humanPageNumber":7,"prevPageNumber":6,"nextPageNumber":null,"previousPagePath":"/tag/python/page/6/","nextPagePath":null}}