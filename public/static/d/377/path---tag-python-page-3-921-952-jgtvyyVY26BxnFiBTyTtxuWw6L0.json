{"data":{"ghostTag":{"slug":"python","name":"Python","visibility":"public","feature_image":null,"description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold"},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ee","title":"Structuring Your Flask Application","slug":"structuring-your-flask-app","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/flaskblueprints2@2x.jpg","excerpt":"Leverage Blueprints, Flask-Assets, and the Application Factory.","custom_excerpt":"Leverage Blueprints, Flask-Assets, and the Application Factory.","created_at_pretty":"02 September, 2018","published_at_pretty":"15 October, 2018","updated_at_pretty":"23 February, 2019","created_at":"2018-09-02T03:02:29.000-04:00","published_at":"2018-10-15T08:00:00.000-04:00","updated_at":"2019-02-23T11:21:49.000-05:00","meta_title":"Structuring your Flask Application | Hackers and Slackers","meta_description":"Follow best practices when building your Flask apps. Leverage Blueprints, Flask-Assets, and the Application Factory.","og_description":"Follow best practices when building your Flask apps. Leverage Blueprints, Flask-Assets, and the Application Factory.","og_image":"https://hackersandslackers.com/content/images/2018/09/flaskblueprints2@2x.jpg","og_title":"Structuring your Flask App Like an Adult | Hackers and Slackers","twitter_description":"Follow best practices when building your Flask apps. Leverage Blueprints, Flask-Assets, and the Application Factory.","twitter_image":"https://hackersandslackers.com/content/images/2018/09/flaskblueprints2@2x.jpg","twitter_title":"Structuring your Flask App Like an Adult | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"When we first started developing in Flask, most of us took the 5 lines of code\nin the quick-start guide and ran with it. Compared to every other web framework,\ngetting a \"Hello world\" to flash on screen without being hassled with database\nconfigurations, template preferences, or reverse proxy setups felt a lot like\nrobbing a bank.\n\nAt some point or another, we inevitably pause the party and take a look around.\nAll of our views are smashed into a single file named something meaningless like\n app.py. All logic lives in the root directory. We're in our 30s and the app\nwe've just created looks as terrible as our bathrooms. It's time to get our shit\ntogether.\n\nThe Flask Application Factory\nThe overwhelming preference to start a Flask application is to use a structure\ndubbed the Application Factory\n[http://flask.pocoo.org/docs/1.0/patterns/appfactories/]. The gist is to keep\nthe initialization preferences of our application in a single __init__.py  file,\nsometimes borrowing help from peer files such as db.py  or models.py. Either\nway, the gist is to keep global logic separated from the other parts.\n\nA simple app using the application factory method might look something like\nthis:\n\n[app]\n├── myapp/\n│   ├── __init__.py\n│   ├── db.py\n│   ├── forms.py\n│   ├── models.py\n│   ├── views.py\n│   ├── static/\n│   └── templates/\n├── config.py\n├── requirements.txt\n├── setup.py\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── app.json\n└── wsgi.py\n\n\nThe main takeaway here being the presence of the myapp  directory which now\nhouses our app logic, and the presence of our good friend __init__.py.\n\nAn example of what might live in __init.py__  could be something like this:\n\nimport os\nimport sys\nfrom flask import Flask, g\nfrom config import BaseConfig\nfrom flask_login import LoginManager\nfrom flask_pymongo import PyMongo\n\n\ndef create_app():\n    app = Flask(__name__, instance_relative_config=True)\n    app.config.from_object('config.BaseConfig')\n    login = LoginManager()\n\n    with app.app_context():\n        from . import views\n        from . import auth\n        login.init_app(app)\n        mongo = PyMongo(app, app.config['MONGO_URI'])\n        app.register_blueprint(views.main)\n        app.register_blueprint(admin.admin)\n\n        return app\n\n\nHere we initialize our app and the dependencies we'd like to initialize within a\nsingle function. Most familiar might be the first two lines of our function: The\nfirst creating our app object, and the second loading a config from a class in a\nconfig file.\n\nAnother common practice is to keep libraries which need to run init_app  in this\nfile as well. This could be something like the LoginManager  seen in the example\nabove, or a global database configuration. Lastly, this is also where we would\nregister any Blueprints  as well.\n\nUsing Blueprints in Flask\nWhile the Application Factory is an excellent first step to building cohesive\napps, we haven't solved the problem of organizing our app into separation of\nconcerns. Blueprints  are a way for us to separate our app into parts which\nshare very little with one another. Prime examples would include apps with an \nadmin  panel with an accompanying client-facing  side, or apps where the \"logged\nin\" state is vastly different from the app's \"logged out\"  state. In these\ncases, it seems silly to mix both logic and static assets into a single lump,\nwhich is where Blueprints come in.\n\nNOTE:  If you're a Django person and this is all starting to sound familiar,\nthat's because we can equate Flask's Blueprints  to Django's concept of apps. \nThere are differences and added flexibility, but the concept remains the same.\n\nRegistering a part of your app as a Blueprint begins with the following two\nlines:\n\nfrom flask import Blueprint\n\nauth = Blueprint('auth', __name__)\n\n\nWhen we registered the admin  Blueprint previously in __init__.py, the line \napp.register_blueprint(admin.admin)  is essentially saying \"look for a Blueprint \n named admin  in a module (either file or folder structure) called admin.\"  It's\nimportant not to overlook the concept that Blueprints can either be single files\nor entirely standalone file structures with their own templates and static\nfiles.  For instance, a Flask app with completely decoupled Blueprints might be\nstructured as follows:\n\n[app]\n├── myapp/\n│   ├── __init__.py\n│   ├── admin/\n│   │    ├── __init__.py\n│   │    ├── views.py\n│   │    ├── forms.py\n│   │    ├── static/\n│   │\t └── templates/\n│   ├── frontend/\n│   │    ├── __init__.py\n│   │    ├── views.py\n│   │    ├── forms.py\n│   │    ├── static/\n│   │\t └── templates/  \n│   ├── db.py\n│   ├── forms.py\n│   ├── models.py\n│   └── views.py\n├── config.py\n├── requirements.txt\n├── setup.py\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── app.json\n└── wsgi.py\n        \n\n\nIn the case above, each Blueprint  stands as though it were its own Python\nmodule. Each blueprint contains its own logic, templates, and static files -\npresumably encapsulated in a way which makes sense.\n\nUsing Flask-Assets with Blueprints\nWe've already forced a lot of information down your throat, but there's one last\nthing worth mentioning in this overview of working with Blueprints, which is\nworking with assets. We've previously looked at the Flask-Static-Compress \nlibrary for static asset management, but Blueprints  lend themselves better to \nFlask-Assets  way of thinking.\n\nFlask-Assets  is a library which creates a bundle (aka compressed) of assets\nupfront. Thus, the start of a Blueprint definition might now look something like\nthis:\n\nfrom flask import Blueprint\nfrom flask_assets import Environment, Bundle, build\nimport sass\n\nauth = Blueprint('admin', __name__)\n\nassets = Environment(admin)\nscss = Bundle('scss/main.scss', 'scss/forms.scss', filters='libsass', output='build/css/style.css')\nassets.register('scss_all', scss)\nscss.build()\n\n\nEnvironment  states the context of our asset bundle, which is admin, the current\nBlueprint. \n\nBundle  takes any number of files to compressed together as arguments. Then we\nmust pass the type of \"filter\" the assets are (typically a precompiler) and of\ncourse an output destination for the Bundle.\n\n.register()  registers the bundle we just created, not unlike the way we\nregistered our Blueprint.\n\n.build()  must be called explicitly in order to build the bundle at runtime.\nConversely, we could intentionally exclude .build()  if we expect our assets are\nnot to change.\n\nAnd Now You Know Everything\n...or not, really. The most we should take from this post is:\n\n * There's a better way to structure our apps.\n * There are many potential decisions we can make about the structure of our\n   app.\n * There's way more stuff we need to Google or look up on StackOverflow.\n\nTruthfully, there are plenty of resources within Flask's documentation\n[http://flask.pocoo.org/docs/1.0/tutorial/views/#]  or around the internet that\ncovers the topic of Flask app organization and its granular topics more than\nthis single post could ever hope to. Nonetheless, here's to hoping you're\nfeeling a sense of direction in these crazy, adult lives of ours.","html":"<p>When we first started developing in Flask, most of us took the 5 lines of code in the quick-start guide and ran with it. Compared to every other web framework, getting a \"Hello world\" to flash on screen without being hassled with database configurations, template preferences, or reverse proxy setups felt a lot like robbing a bank.</p><p>At some point or another, we inevitably pause the party and take a look around. All of our views are smashed into a single file named something meaningless like <code>app.py</code>. All logic lives in the root directory. We're in our 30s and the app we've just created looks as terrible as our bathrooms. It's time to get our shit together.</p><h2 id=\"the-flask-application-factory\">The Flask Application Factory</h2><p>The overwhelming preference to start a Flask application is to use a structure dubbed the <a href=\"http://flask.pocoo.org/docs/1.0/patterns/appfactories/\">Application Factory</a>. The gist is to keep the initialization preferences of our application in a single <code>__init__.py</code> file, sometimes borrowing help from peer files such as <code>db.py</code> or <code>models.py</code>. Either way, the gist is to keep global logic separated from the other parts.</p><p>A simple app using the application factory method might look something like this:</p><pre><code class=\"language-shell\">[app]\n├── myapp/\n│   ├── __init__.py\n│   ├── db.py\n│   ├── forms.py\n│   ├── models.py\n│   ├── views.py\n│   ├── static/\n│   └── templates/\n├── config.py\n├── requirements.txt\n├── setup.py\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── app.json\n└── wsgi.py\n</code></pre>\n<p>The main takeaway here being the presence of the <strong>myapp</strong> directory which now houses our app logic, and the presence of our good friend <code>__init__.py</code>.</p><p>An example of what might live in <code>__init.py__</code> could be something like this:</p><pre><code class=\"language-python\">import os\nimport sys\nfrom flask import Flask, g\nfrom config import BaseConfig\nfrom flask_login import LoginManager\nfrom flask_pymongo import PyMongo\n\n\ndef create_app():\n    app = Flask(__name__, instance_relative_config=True)\n    app.config.from_object('config.BaseConfig')\n    login = LoginManager()\n\n    with app.app_context():\n        from . import views\n        from . import auth\n        login.init_app(app)\n        mongo = PyMongo(app, app.config['MONGO_URI'])\n        app.register_blueprint(views.main)\n        app.register_blueprint(admin.admin)\n\n        return app\n</code></pre>\n<p>Here we initialize our app and the dependencies we'd like to initialize within a single function. Most familiar might be the first two lines of our function: The first creating our app object, and the second loading a config from a class in a config file.</p><p>Another common practice is to keep libraries which need to run <code>init_app</code> in this file as well. This could be something like the <code>LoginManager</code> seen in the example above, or a global database configuration. Lastly, this is also where we would register any <strong>Blueprints</strong> as well.</p><h2 id=\"using-blueprints-in-flask\">Using Blueprints in Flask</h2><p>While the Application Factory is an excellent first step to building cohesive apps, we haven't solved the problem of organizing our app into <em>separation of concerns</em>. <strong>Blueprints</strong> are a way for us to separate our app into parts which share very little with one another. Prime examples would include apps with an <em>admin</em> panel with an accompanying <em>client-facing</em> side, or apps where the \"<em>logged in\" </em>state is vastly different from the app's \"<em>logged out\"</em> state. In these cases, it seems silly to mix both logic and static assets into a single lump, which is where Blueprints come in.</p><p><strong>NOTE:</strong> If you're a Django person and this is all starting to sound familiar, that's because we can equate Flask's <strong>Blueprints</strong> to Django's concept of <strong>apps.</strong> There are differences and added flexibility, but the concept remains the same.</p><p>Registering a part of your app as a Blueprint begins with the following two lines:</p><pre><code class=\"language-python\">from flask import Blueprint\n\nauth = Blueprint('auth', __name__)\n</code></pre>\n<p>When we registered the <code>admin</code> Blueprint previously in <code>__init__.py</code>, the line <code>app.register_blueprint(admin.admin)</code> is essentially saying \"look for a <strong>Blueprint</strong> named <em>admin</em> in a module (either file or folder structure) called <em>admin.\"</em> It's important not to overlook the concept that Blueprints can either be single files or <em>entirely standalone file structures with their own templates and static files.</em> For instance, a Flask app with completely decoupled Blueprints might be structured as follows:</p><pre><code class=\"language-shell\">[app]\n├── myapp/\n│   ├── __init__.py\n│   ├── admin/\n│   │    ├── __init__.py\n│   │    ├── views.py\n│   │    ├── forms.py\n│   │    ├── static/\n│   │\t └── templates/\n│   ├── frontend/\n│   │    ├── __init__.py\n│   │    ├── views.py\n│   │    ├── forms.py\n│   │    ├── static/\n│   │\t └── templates/  \n│   ├── db.py\n│   ├── forms.py\n│   ├── models.py\n│   └── views.py\n├── config.py\n├── requirements.txt\n├── setup.py\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── app.json\n└── wsgi.py\n        \n</code></pre>\n<p>In the case above, each <strong>Blueprint</strong> stands as though it were its own Python module. Each blueprint contains its own logic, templates, and static files - presumably encapsulated in a way which makes sense.</p><h2 id=\"using-flask-assets-with-blueprints\">Using Flask-Assets with Blueprints</h2><p>We've already forced a lot of information down your throat, but there's one last thing worth mentioning in this overview of working with <strong>Blueprints, </strong>which is working with assets. We've previously looked at the <code>Flask-Static-Compress</code> library for static asset management, but <strong>Blueprints</strong> lend themselves better to <code>Flask-Assets</code> way of thinking.</p><p><code>Flask-Assets</code> is a library which creates a bundle (aka compressed) of assets upfront. Thus, the start of a Blueprint definition might now look something like this:</p><pre><code class=\"language-shell\">from flask import Blueprint\nfrom flask_assets import Environment, Bundle, build\nimport sass\n\nauth = Blueprint('admin', __name__)\n\nassets = Environment(admin)\nscss = Bundle('scss/main.scss', 'scss/forms.scss', filters='libsass', output='build/css/style.css')\nassets.register('scss_all', scss)\nscss.build()\n</code></pre>\n<p><code>Environment</code> states the context of our asset bundle, which is admin, the current Blueprint. </p><p><code>Bundle</code> takes any number of files to compressed together as arguments. Then we must pass the type of \"filter\" the assets are (typically a precompiler) and of course an output destination for the Bundle.</p><p><code>.register()</code> registers the bundle we just created, not unlike the way we registered our Blueprint.</p><p><code>.build()</code> must be called explicitly in order to build the bundle at runtime. Conversely, we could intentionally exclude <code>.build()</code> if we expect our assets are not to change.</p><h2 id=\"and-now-you-know-everything\">And Now You Know Everything</h2><p>...or not, really. The most we should take from this post is:</p><ul><li>There's a better way to structure our apps.</li><li>There are many potential decisions we can make about the structure of our app.</li><li>There's way more stuff we need to Google or look up on StackOverflow.</li></ul><p>Truthfully, there are plenty of resources within <a href=\"http://flask.pocoo.org/docs/1.0/tutorial/views/#\">Flask's documentation</a> or around the internet that covers the topic of Flask app organization and its granular topics more than this single post could ever hope to. Nonetheless, here's to hoping you're feeling a sense of direction in these crazy, adult lives of ours.</p>","url":"https://hackersandslackers.com/structuring-your-flask-app/","uuid":"4345eb76-e1ce-471a-94b9-f06a43c3ad27","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b8b8b05852e5c07171fcab7"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867371b","title":"Extract Nested Data From Complex JSON","slug":"extract-data-from-complex-json-python","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/10/107@2x.jpg","excerpt":"Never manually walk through complex JSON objects again by using this function.","custom_excerpt":"Never manually walk through complex JSON objects again by using this function.","created_at_pretty":"10 October, 2018","published_at_pretty":"10 October, 2018","updated_at_pretty":"22 January, 2019","created_at":"2018-10-10T00:15:29.000-04:00","published_at":"2018-10-10T08:00:00.000-04:00","updated_at":"2019-01-22T15:20:23.000-05:00","meta_title":"Extract Nested Data From Complex JSON Trees | Hackers and Slackers","meta_description":"Never manually walk through complex JSON objects again by using this function","og_description":"Never manually walk through complex JSON objects again by using this function","og_image":"https://hackersandslackers.com/content/images/2018/10/107@2x.jpg","og_title":"Extract Nested Data From Complex JSON Trees | Hackers and Slackers","twitter_description":"Never manually walk through complex JSON objects again by using this function","twitter_image":"https://hackersandslackers.com/content/images/2018/10/107@2x.jpg","twitter_title":"Extract Nested Data From Complex JSON Trees | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"We're all data people here, so you already know the scenario: it happens perhaps\nonce a day, perhaps 5, or even more. There's an API you're working with, and\nit's great. It contains all the information you're looking for, but there's just\none problem: the complexity of nested JSON objects is endless, and suddenly the\njob you love needs to be put on hold to painstakingly retrieve the data you\nactually want, and it's 5 levels deep in a nested JSON hell. Nobody feels like\nmuch of a \"scientist\" or an \"engineer\" when half their day becomes dealing with\nkey value errors.\n\nLuckily, we code in Python!  (okay fine, language doesn't make much of a\ndifference here. It felt like a rallying call at the time).\n\nUsing Google Maps API as an Example\nTo visualize the problem, let's take an example somebody might actually want to\nuse.  I think the  Google Maps API is a good candidate to fit the bill here.\n\nWhile Google Maps is actually a collection of APIs, the Google Maps Distance\nMatrix [https://developers.google.com/maps/documentation/distance-matrix/start].\nThe idea is that with a single API call, a user can calculate the distance and\ntime traveled between an origin and an infinite number of destinations. It's a\ngreat full-featured API, but as you might imagine the resulting JSON for\ncalculating commute time between where you stand and every location in the\nconceivable universe  makes an awfully complex JSON structure.\n\nGetting a Taste of JSON Hell\nReal quick, here's an example of the types of parameters this request accepts:\n\nimport requests\nimport API_KEY\n\ndef google_api_matrix():\n    \"\"\"Example Google Distance Matrix function.\"\"\"\n    endpoint = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': 'New York City, NY',\n       'destinations': 'Philadelphia,PA',\n       'transit_mode': 'car'\n    }\n    r = requests.get(endpoint, params=params)\n    return r.json\n\n\nOne origin, one destination. The JSON response for a request this\nstraightforward is quite simple:\n\n{\n    \"destination_addresses\": [\n        \"Philadelphia, PA, USA\"\n    ],\n    \"origin_addresses\": [\n        \"New York, NY, USA\"\n    ],\n    \"rows\": [\n        {\n            \"elements\": [\n                {\n                    \"distance\": {\n                        \"text\": \"94.6 mi\",\n                        \"value\": 152193\n                    },\n                    \"duration\": {\n                        \"text\": \"1 hour 44 mins\",\n                        \"value\": 6227\n                    },\n                    \"status\": \"OK\"\n                }\n            ]\n        }\n    ],\n    \"status\": \"OK\"\n}\n\n\nFor each destination, we're getting two data points: the commute distance, and \nestimated duration. If we hypothetically wanted to extract those values, typing \nresponse['rows'][0]['elements']['distance']['test']  isn't too  crazy. I mean,\nit's somewhat awful and brings on casual thoughts of suicide, but nothing out of\nthe ordinary\n\nNow let's make things interesting by adding a few more stops on our trip:\n\nimport requests \nimport API_KEY\n\ndef google_api_matrix():\n    \"\"\"Example Google Distance Matrix function.\"\"\"\n    endpoint = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': 'New York City, NY',\n       'destinations': 'Washington,DC|Philadelphia,PA|Santa Barbara,CA|Miami,FL|Austin,TX|Napa County,CA',\n       'transit_mode': 'car'\n    }\n    r = requests.get(endpoint, params=params)\n    return r.json\n\n\nOh fuuucckkkk:\n\n{\n  \"destination_addresses\": [\n    \"Washington, DC, USA\",\n    \"Philadelphia, PA, USA\",\n    \"Santa Barbara, CA, USA\",\n    \"Miami, FL, USA\",\n    \"Austin, TX, USA\",\n    \"Napa County, CA, USA\"\n  ],\n  \"origin_addresses\": [\n    \"New York, NY, USA\"\n  ],\n  \"rows\": [\n    {\n      \"elements\": [\n        {\n          \"distance\": {\n            \"text\": \"227 mi\",\n            \"value\": 365468\n          },\n          \"duration\": {\n            \"text\": \"3 hours 54 mins\",\n            \"value\": 14064\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"94.6 mi\",\n            \"value\": 152193\n          },\n          \"duration\": {\n            \"text\": \"1 hour 44 mins\",\n            \"value\": 6227\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"2,878 mi\",\n            \"value\": 4632197\n          },\n          \"duration\": {\n            \"text\": \"1 day 18 hours\",\n            \"value\": 151772\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"1,286 mi\",\n            \"value\": 2069031\n          },\n          \"duration\": {\n            \"text\": \"18 hours 43 mins\",\n            \"value\": 67405\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"1,742 mi\",\n            \"value\": 2802972\n          },\n          \"duration\": {\n            \"text\": \"1 day 2 hours\",\n            \"value\": 93070\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"2,871 mi\",\n            \"value\": 4620514\n          },\n          \"duration\": {\n            \"text\": \"1 day 18 hours\",\n            \"value\": 152913\n          },\n          \"status\": \"OK\"\n        }\n      ]\n    }\n  ],\n  \"status\": \"OK\"\n}\n\n\nA lot is happening here. There are objects. There are lists. There are lists of\nobjects which are part of an object. The last thing I'd want to deal with is\ntrying to parse this data only to accidentally get a useless key:value pair like\n \"status\": \"OK\".\n\nCode Snippet To The Rescue\nLet's say we only want the human-readable data from this JSON, which is labeled \n\"text\"  for both distance and duration. We've created a function below dubbed \nextract_values()  to help us resolve this very issue. The idea is that \nextract_values()  is flexible and agnostic, therefore can be imported as a\nmodule into any project you might need.\n\n# recursivejson.py\n\ndef extract_values(obj, key):\n    \"\"\"Pull all values of specified key from nested JSON.\"\"\"\n    arr = []\n\n    def extract(obj, arr, key):\n        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n        if isinstance(obj, dict):\n            for k, v in obj.items():\n                if isinstance(v, (dict, list)):\n                    extract(v, arr, key)\n                elif k == key:\n                    arr.append(v)\n        elif isinstance(obj, list):\n            for item in obj:\n                extract(item, arr, key)\n        return arr\n\n    results = extract(obj, arr, key)\n    return results\n\n\nWe need to pass this function two values:\n\n * A JSON object, such as r.json()  from an API request.\n * The name of the key  we're looking to extract values from.\n\nnames = extract_values('myjson.json', 'name')\nprint(names)\n\n\nRegardless of where the key \"text\"  lives in the JSON, this function returns\nevery value for the instance of \"key.\" Here's our function in action:\n\nimport requests\nimport API_KEY\nfrom recursivejson import extract_values\n\n\ndef google_api_matrix():\n    \"\"\"Example Google Distance Matrix function.\"\"\"\n    endpoint = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': \"New York City,NY\",\n       'destinations': \"Washington,DC|Philadelphia,PA|Santa Barbara,CA|Miami,FL|Austin,TX|Napa Valley,CA\",\n       'transit_mode': 'car',\n    }\n\n   r = requests.get(endpoint, params=params)\n   travel_values = extract_values(r.json(), 'text')\n   return travel_values\n\n\nRunning this function will result in the following output:\n\n['227 mi', '3 hours 54 mins', '94.6 mi', '1 hour 44 mins', '2,878 mi', '1 day 18 hours', '1,286 mi', '18 hours 43 mins', '1,742 mi', '1 day 2 hours', '2,871 mi', '1 day 18 hours']\n\n\nOh fiddle me timbers! Because the Google API alternates between distance and \ntrip duration, every other value alternates between distance and time (can we\npause to appreciate this horrible design? There are infinitely better ways to\nstructure this response). Never fear, some simple Python can help us split this\nlist into two lists:\n\nmy_values = extract_values(r.json(), 'text')\n\ndurations = my_values[1::2]\ndistances = my_values[2::1]\n\nprint('DURATIONS = ', durations)\nprint('DISTANCES = ', distances)\n\n\nThis will take our one list and split it in to two  lists, alternating between\neven and odd:\n\nDURATIONS = ['3 hours 54 mins', '1 hour 44 mins', '1 day 18 hours', '18 hours 43 mins', '1 day 2 hours', '1 day 18 hours']\nDISTANCES = ['94.6 mi', '1 hour 44 mins', '2,878 mi', '1 day 18 hours', '1,286 mi', '18 hours 43 mins', '1,742 mi', '1 day 2 hours', '2,871 mi', '1 day 18 hours']\n\n\nGetting Creative With Lists\nA common theme I run in to while extracting lists of values from JSON objects\nlike these is that the lists of values I extract are very much related.  In the\nabove example, for every duration  we have an accompanying distance, which is a\none-to-one basis. Imagine if we wanted to associate these values somehow?\n\nTo use a better example, I recently I used this exact_values()  function to\nextract lists of column names and their data types from a database schema. As\nseparate lists, the data looked something like this:\n\ncolumn_names = ['index', 'first_name', 'last_name', 'join_date']\ncolumn_datatypes = ['integer', 'string', 'string', 'date']\n\n\nClearly these two lists are directly related; the latter is describing the\nformer. How can this be useful? By using Python's zip  method!\n\nschema_dict = dict(zip(column_names, column_datatypes))\nprint(schema_dict)\n\n\nI like to think they call it zip  because it's like zipping up a zipper, where\neach side of the zipper is a list. This output a dictionary where list 1 serves\nas the keys, and list 2 serves as values:\n\n{\n'index': 'integer', \n'first_name': 'string', \n'last_name':'string',\n'join_date': 'date'\n}\n\n\nAnd there you have it folks: a free code snippet to copy and secretly pretend\nyou wrote forever. I've thrown the function up on Github Gists\n[https://gist.github.com/toddbirchard/b6f86f03f6cf4fc9492ad4349ee7ff8b], if such\na thing pleases you.\n\nIn the meantime, zip it up and zip it out. Zippity-do-da, buh bye.","html":"<p>We're all data people here, so you already know the scenario: it happens perhaps once a day, perhaps 5, or even more. There's an API you're working with, and it's great. It contains all the information you're looking for, but there's just one problem: the complexity of nested JSON objects is endless, and suddenly the job you love needs to be put on hold to painstakingly retrieve the data you actually want, and it's 5 levels deep in a nested JSON hell. Nobody feels like much of a \"scientist\" or an \"engineer\" when half their day becomes dealing with key value errors.</p><p>Luckily, we code in <strong><em>Python!</em></strong> (okay fine, language doesn't make much of a difference here. It felt like a rallying call at the time).</p><h2 id=\"using-google-maps-api-as-an-example\">Using Google Maps API as an Example</h2><p>To visualize the problem, let's take an example somebody might actually want to use.  I think the<strong> Google Maps API </strong>is a good candidate to fit the bill here.</p><p>While Google Maps is actually a collection of APIs, the <a href=\"https://developers.google.com/maps/documentation/distance-matrix/start\">Google Maps Distance Matrix</a>. The idea is that with a single API call, a user can calculate the distance and time traveled between an origin and an infinite number of destinations. It's a great full-featured API, but as you might imagine the resulting JSON for calculating commute time between where you stand and <em>every location in the conceivable universe</em> makes an awfully complex JSON structure.</p><h3 id=\"getting-a-taste-of-json-hell\">Getting a Taste of JSON Hell</h3><p>Real quick, here's an example of the types of parameters this request accepts:</p><pre><code class=\"language-python\">import requests\nimport API_KEY\n\ndef google_api_matrix():\n    &quot;&quot;&quot;Example Google Distance Matrix function.&quot;&quot;&quot;\n    endpoint = &quot;https://maps.googleapis.com/maps/api/distancematrix/json&quot;\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': 'New York City, NY',\n       'destinations': 'Philadelphia,PA',\n       'transit_mode': 'car'\n    }\n    r = requests.get(endpoint, params=params)\n    return r.json\n</code></pre>\n<p>One origin, one destination. The JSON response for a request this straightforward is quite simple:</p><pre><code class=\"language-json\">{\n    &quot;destination_addresses&quot;: [\n        &quot;Philadelphia, PA, USA&quot;\n    ],\n    &quot;origin_addresses&quot;: [\n        &quot;New York, NY, USA&quot;\n    ],\n    &quot;rows&quot;: [\n        {\n            &quot;elements&quot;: [\n                {\n                    &quot;distance&quot;: {\n                        &quot;text&quot;: &quot;94.6 mi&quot;,\n                        &quot;value&quot;: 152193\n                    },\n                    &quot;duration&quot;: {\n                        &quot;text&quot;: &quot;1 hour 44 mins&quot;,\n                        &quot;value&quot;: 6227\n                    },\n                    &quot;status&quot;: &quot;OK&quot;\n                }\n            ]\n        }\n    ],\n    &quot;status&quot;: &quot;OK&quot;\n}\n</code></pre>\n<p>For each destination, we're getting two data points: the <em>commute distance</em>, and <em>estimated duration</em>. If we hypothetically wanted to extract those values, typing <code>response['rows'][0]['elements']['distance']['test']</code> isn't <em>too</em> crazy. I mean, it's somewhat awful and brings on casual thoughts of suicide, but nothing out of the ordinary</p><p>Now let's make things interesting by adding a few more stops on our trip:</p><pre><code class=\"language-python\">import requests \nimport API_KEY\n\ndef google_api_matrix():\n    &quot;&quot;&quot;Example Google Distance Matrix function.&quot;&quot;&quot;\n    endpoint = &quot;https://maps.googleapis.com/maps/api/distancematrix/json&quot;\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': 'New York City, NY',\n       'destinations': 'Washington,DC|Philadelphia,PA|Santa Barbara,CA|Miami,FL|Austin,TX|Napa County,CA',\n       'transit_mode': 'car'\n    }\n    r = requests.get(endpoint, params=params)\n    return r.json\n</code></pre>\n<p>Oh fuuucckkkk:</p><pre><code class=\"language-json\">{\n  &quot;destination_addresses&quot;: [\n    &quot;Washington, DC, USA&quot;,\n    &quot;Philadelphia, PA, USA&quot;,\n    &quot;Santa Barbara, CA, USA&quot;,\n    &quot;Miami, FL, USA&quot;,\n    &quot;Austin, TX, USA&quot;,\n    &quot;Napa County, CA, USA&quot;\n  ],\n  &quot;origin_addresses&quot;: [\n    &quot;New York, NY, USA&quot;\n  ],\n  &quot;rows&quot;: [\n    {\n      &quot;elements&quot;: [\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;227 mi&quot;,\n            &quot;value&quot;: 365468\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;3 hours 54 mins&quot;,\n            &quot;value&quot;: 14064\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;94.6 mi&quot;,\n            &quot;value&quot;: 152193\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;1 hour 44 mins&quot;,\n            &quot;value&quot;: 6227\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;2,878 mi&quot;,\n            &quot;value&quot;: 4632197\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;1 day 18 hours&quot;,\n            &quot;value&quot;: 151772\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;1,286 mi&quot;,\n            &quot;value&quot;: 2069031\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;18 hours 43 mins&quot;,\n            &quot;value&quot;: 67405\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;1,742 mi&quot;,\n            &quot;value&quot;: 2802972\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;1 day 2 hours&quot;,\n            &quot;value&quot;: 93070\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;2,871 mi&quot;,\n            &quot;value&quot;: 4620514\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;1 day 18 hours&quot;,\n            &quot;value&quot;: 152913\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        }\n      ]\n    }\n  ],\n  &quot;status&quot;: &quot;OK&quot;\n}\n</code></pre>\n<p>A lot is happening here. There are objects. There are lists. There are lists of objects which are part of an object. The last thing I'd want to deal with is trying to parse this data only to accidentally get a useless key:value pair like <strong>\"status\": \"OK\".</strong></p><h2 id=\"code-snippet-to-the-rescue\">Code Snippet To The Rescue</h2><p>Let's say we only want the human-readable data from this JSON, which is labeled <em>\"text\"</em> for both distance and duration. We've created a function below dubbed <code>extract_values()</code> to help us resolve this very issue. The idea is that <code>extract_values()</code> is flexible and agnostic, therefore can be imported as a module into any project you might need.</p><pre><code class=\"language-python\"># recursivejson.py\n\ndef extract_values(obj, key):\n    &quot;&quot;&quot;Pull all values of specified key from nested JSON.&quot;&quot;&quot;\n    arr = []\n\n    def extract(obj, arr, key):\n        &quot;&quot;&quot;Recursively search for values of key in JSON tree.&quot;&quot;&quot;\n        if isinstance(obj, dict):\n            for k, v in obj.items():\n                if isinstance(v, (dict, list)):\n                    extract(v, arr, key)\n                elif k == key:\n                    arr.append(v)\n        elif isinstance(obj, list):\n            for item in obj:\n                extract(item, arr, key)\n        return arr\n\n    results = extract(obj, arr, key)\n    return results\n</code></pre>\n<p>We need to pass this function two values:</p><ul><li>A JSON object, such as <code>r.json()</code> from an API request.</li><li>The name of the <strong>key</strong> we're looking to extract values from.</li></ul><pre><code class=\"language-python\">names = extract_values('myjson.json', 'name')\nprint(names)\n</code></pre>\n<p>Regardless of where the key <strong>\"text\"</strong> lives in the JSON, this function returns every value for the instance of <strong>\"key.\" </strong>Here's our function in action:</p><pre><code class=\"language-python\">import requests\nimport API_KEY\nfrom recursivejson import extract_values\n\n\ndef google_api_matrix():\n    &quot;&quot;&quot;Example Google Distance Matrix function.&quot;&quot;&quot;\n    endpoint = &quot;https://maps.googleapis.com/maps/api/distancematrix/json&quot;\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': &quot;New York City,NY&quot;,\n       'destinations': &quot;Washington,DC|Philadelphia,PA|Santa Barbara,CA|Miami,FL|Austin,TX|Napa Valley,CA&quot;,\n       'transit_mode': 'car',\n    }\n\n   r = requests.get(endpoint, params=params)\n   travel_values = extract_values(r.json(), 'text')\n   return travel_values\n</code></pre>\n<p>Running this function will result in the following output:</p><pre><code class=\"language-python\">['227 mi', '3 hours 54 mins', '94.6 mi', '1 hour 44 mins', '2,878 mi', '1 day 18 hours', '1,286 mi', '18 hours 43 mins', '1,742 mi', '1 day 2 hours', '2,871 mi', '1 day 18 hours']\n</code></pre>\n<p>Oh <em>fiddle me timbers</em>! Because the Google API alternates between <strong>distance </strong>and <strong>trip duration</strong>, every other value alternates between distance and time (can we pause to appreciate this horrible design? There are infinitely better ways to structure this response). Never fear, some simple Python can help us split this list into two lists:</p><pre><code class=\"language-python\">my_values = extract_values(r.json(), 'text')\n\ndurations = my_values[1::2]\ndistances = my_values[2::1]\n\nprint('DURATIONS = ', durations)\nprint('DISTANCES = ', distances)\n</code></pre>\n<p>This will take our one list and split it in to <em>two</em> lists, alternating between even and odd:</p><pre><code class=\"language-python\">DURATIONS = ['3 hours 54 mins', '1 hour 44 mins', '1 day 18 hours', '18 hours 43 mins', '1 day 2 hours', '1 day 18 hours']\nDISTANCES = ['94.6 mi', '1 hour 44 mins', '2,878 mi', '1 day 18 hours', '1,286 mi', '18 hours 43 mins', '1,742 mi', '1 day 2 hours', '2,871 mi', '1 day 18 hours']\n</code></pre>\n<h2 id=\"getting-creative-with-lists\">Getting Creative With Lists</h2><p>A common theme I run in to while extracting lists of values from JSON objects like these is that the lists of values I extract are very much related.  In the above example, for every <em>duration</em> we have an accompanying <em>distance, </em>which is a one-to-one basis. Imagine if we wanted to associate these values somehow?</p><p>To use a better example, I recently I used this <code>exact_values()</code> function to extract lists of column names and their data types from a database schema. As separate lists, the data looked something like this:</p><pre><code class=\"language-python\">column_names = ['index', 'first_name', 'last_name', 'join_date']\ncolumn_datatypes = ['integer', 'string', 'string', 'date']\n</code></pre>\n<p>Clearly these two lists are directly related; the latter is describing the former. How can this be useful? By using Python's <code>zip</code> method!</p><pre><code class=\"language-python\">schema_dict = dict(zip(column_names, column_datatypes))\nprint(schema_dict)\n</code></pre>\n<p>I like to think they call it <em>zip</em> because it's like zipping up a zipper, where each side of the zipper is a list. This output a dictionary where list 1 serves as the keys, and list 2 serves as values:</p><pre><code class=\"language-python\">{\n'index': 'integer', \n'first_name': 'string', \n'last_name':'string',\n'join_date': 'date'\n}\n</code></pre>\n<p>And there you have it folks: a free code snippet to copy and secretly pretend you wrote forever. I've thrown the function up on <a href=\"https://gist.github.com/toddbirchard/b6f86f03f6cf4fc9492ad4349ee7ff8b\">Github Gists</a>, if such a thing pleases you.</p><p>In the meantime, zip it up and zip it out. Zippity-do-da, buh bye.</p>","url":"https://hackersandslackers.com/extract-data-from-complex-json-python/","uuid":"9a494df4-9e13-45ed-8648-efdda21c55a4","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5bbd7ce1b936605163ece407"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673718","title":"Reading and Writing to CSVs in Python","slug":"reading-and-writing-to-csvs-in-python","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/csvpython2@2x.jpg","excerpt":"Playing with tabular data the native Python way.","custom_excerpt":"Playing with tabular data the native Python way.","created_at_pretty":"27 September, 2018","published_at_pretty":"27 September, 2018","updated_at_pretty":"05 November, 2018","created_at":"2018-09-27T13:22:47.000-04:00","published_at":"2018-09-27T18:35:00.000-04:00","updated_at":"2018-11-05T07:55:10.000-05:00","meta_title":"Reading and Writing to CSVs in Python | Hackers and Slackers","meta_description":"Using native Python libraries to interact with tabular data. Pandas not included.\n\n\n\n\n\n\n\n\nar \n\n","og_description":"Using native Python libraries to interact with tabular data. Pandas not included.","og_image":"https://hackersandslackers.com/content/images/2018/09/csvpython2@2x.jpg","og_title":"Reading and Writing to CSVs in Python | Hackers and Slackers","twitter_description":"Using native Python libraries to interact with tabular data. Pandas not included.","twitter_image":"https://hackersandslackers.com/content/images/2018/09/csvpython2@2x.jpg","twitter_title":"Reading and Writing to CSVs in Python | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"Tables. Cells. Two-dimensional data. We here at Hackers & Slackers know how to\ntalk dirty, but there's one word we'll be missing from our vocabulary today:\nPandas.Before the remaining audience closes their browser windows in fury, hear\nme out. We love Pandas; so much so that tend to recklessly gunsling this 30mb\nlibrary to perform simple tasks. This isn't always a wise choice. I get it:\nyou're here for data, not software engineering best practices. We all are, but\nin a landscape where engineers and scientists already produce polarizing code\nquality, we're all just a single bloated lambda function away from looking like\n idiots and taking a hit to our credibility. This is a silly predicament when\nthere are plenty of built-in Python libraries at our disposable which work\nperfectly fine. Python’s built in CSV library can cover quite a bit of data\nmanipulation use cases to achieve the same results of large scientific libraries\njust as easily.\n\nBasic CSV Interaction\nRegardless of whether you're reading or writing to CSVs, there are a couple\nlines of code which will stay mostly the same between the two. \n\n# read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r', newline='') as myCsvFile:\n     reader = csv.reader(myCsvFile, delimiter=',', quotechar='|')\n\nBefore accomplishing anything, we've stated some critical things in these two\nlines of code:\n\n * All interactions with our CSV will only be valid as long as they live within\n   the with.open  block (comparable to managing database connections).\n * We'll be interacting with a file in our directory called hackers.csv, for\n   which we only need read (or r) permissions\n * We create a reader  object, which is again comparable to managing database \n   cursors  if you're familiar.\n * We have the ability to set the delimiter of our CSV (a curious feature,\n   considering the meaning of C  in the acronym CSV.\n\nIterating Rows\nAn obvious use case you probably have in mind would be to loop through each row\nto see what sort of values we're dealing with. Your first inclination might be\nto do something like this:\n\n# read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r', newline='') as myCsvFile:\n    reader = csv.reader(myCsvFile, delimiter=',', quotechar='|')\n\tfor row in reader.readlines():\n\t\tprint('row = ', row)\n\nThat's fine and all, but row  in this case returns a simple list - this is\nobviously problem if you want to access the values of certain columns by column \nname,  as opposed to numeric index (I bet you do). Well, we've got you covered:\n\n# read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r', newline='') as myCsvFile:\n    reader = csv.DictReader(myCsvFile)\n\tfor row in reader.readlines():\n\t\tprint(row['column_name_1'], row['column_name_2'])\n\nChanging reader  to DictReader  outputs a dictionary  per CSV row, as opposed to\na simple list. Are things starting to feel a little Panda-like yet?\n\nBonus: Printing all Keys and Their Values\nLet's get a little weird just for fun. Since our rows are dict objects now, we\ncan print our entire CSV as a series of dicts like so:\n\n# read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r', newline='') as myCsvFile:\n    reader = csv.DictReader(myCsvFile)\n\tfor row in loc_reader:\n            for (k, v) in row.items():\n\t\t\t\tprint(k, ':', v)\n\nSkipping Headers\nAs we read information from CSVs to be repurposed for, say, API calls, we \nprobably  don't want to iterate over the first row of our CSV: this will output\nour key values alone, which would be useless in this context. Consider this:\n\n# read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r') as myCsvFile:\n\tnext(myCsvFile)\n\tfor row in myCsvFile.readlines():\n\t\tprint(row)\n\nWhoa! A different approach.... but somehow just as simple? In this case, we\nleave out reader  altogether (which still works!) but more importantly, we\nintroduce next(). next(myCsvFile)  immediately skips to the next line in a CSV,\nso in our case, we simply skip line one before going into our For loop. Amazing.\n\nWriting to CSVs\nWriting to CSVs isn't much different than reading from them. In fact, almost all\nthe same principles apply, where instances of the word \"read\" are more or less\nreplaced with\" write. Huh. \n\n# write_csv.py\nimport csv\n\nwith open('hackers.csv', 'w') as myCsvFile:\n    columns = ['column_name_1', 'column_name_2']\n    writer = csv.DictWriter(myCsvFile, fieldnames=columns)\n\n    writer.writeheader()\n    writer.writerow({'column_name_1': 'Mark', 'column_name_2': 'Twain'})\n    writer.writerow({'column_name_1': 'Foo', 'column_name_2: 'Bar'})\n\nWe're writing a brand new CSV here: 'hackers.csv' doesn't technically exist yet,\nbut that doesn't stop Python from not giving a shit. Python knows what you mean.\nPython has your back.\n\nHere, we set our headers as a fixed list set by the column  variable. This is a\nstatic way of creating headers, but the same can be done dynamically by passing\nthe keys  of a dict, or whatever it is you like to do. \n\nwriter.writeheader()  knows what we're saying thanks to the aforementioned \nfieldnames  we passed to our writer earlier. Good for you, writer.\n\nBut how do we write rows, you might ask? Why, with writer.writerow(), of course!\nBecause we use DictWriter  similarly to how we used DictReader  earlier, we can\nmap values to our CSV with simple column references. Easy.","html":"<p>Tables. Cells. Two-dimensional data. We here at Hackers &amp; Slackers know how to talk dirty, but there's one word we'll be missing from our vocabulary today: Pandas.Before the remaining audience closes their browser windows in fury, hear me out. We love Pandas; so much so that tend to recklessly gunsling this 30mb library to perform simple tasks. This isn't always a wise choice. I get it: you're here for data, not software engineering best practices. We all are, but in a landscape where engineers and scientists already produce polarizing code quality, we're all just a single bloated lambda function away from looking like  idiots and taking a hit to our credibility. This is a silly predicament when there are plenty of built-in Python libraries at our disposable which work perfectly fine. Python’s built in CSV library can cover quite a bit of data manipulation use cases to achieve the same results of large scientific libraries just as easily.</p><h2 id=\"basic-csv-interaction\">Basic CSV Interaction</h2><p>Regardless of whether you're reading or writing to CSVs, there are a couple lines of code which will stay mostly the same between the two. </p><pre><code># read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r', newline='') as myCsvFile:\n     reader = csv.reader(myCsvFile, delimiter=',', quotechar='|')</code></pre><p>Before accomplishing anything, we've stated some critical things in these two lines of code:</p><ul><li>All interactions with our CSV will only be valid as long as they live within the <code>with.open</code> block (comparable to managing database connections).</li><li>We'll be interacting with a file in our directory called <code>hackers.csv</code>, for which we only need read (or <code>r</code>) permissions</li><li>We create a <code>reader</code> object, which is again comparable to managing database <code>cursors</code> if you're familiar.</li><li>We have the ability to set the delimiter of our CSV (a curious feature, considering the meaning of <strong>C</strong> in the acronym <strong>CSV.</strong></li></ul><h3 id=\"iterating-rows\">Iterating Rows</h3><p>An obvious use case you probably have in mind would be to loop through each row to see what sort of values we're dealing with. Your first inclination might be to do something like this:</p><pre><code># read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r', newline='') as myCsvFile:\n    reader = csv.reader(myCsvFile, delimiter=',', quotechar='|')\n\tfor row in reader.readlines():\n\t\tprint('row = ', row)</code></pre><p>That's fine and all, but <code>row</code> in this case returns a simple list - this is obviously problem if you want to access the values of certain columns by column <em>name,</em> as opposed to <em>numeric index </em>(I bet you do). Well, we've got you covered:</p><pre><code># read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r', newline='') as myCsvFile:\n    reader = csv.DictReader(myCsvFile)\n\tfor row in reader.readlines():\n\t\tprint(row['column_name_1'], row['column_name_2'])</code></pre><p>Changing <code>reader</code> to <code>DictReader</code> outputs a <em>dictionary</em> per CSV row, as opposed to a simple list. Are things starting to feel a little Panda-like yet?</p><h4 id=\"bonus-printing-all-keys-and-their-values\">Bonus: Printing all Keys and Their Values</h4><p>Let's get a little weird just for fun. Since our rows are dict objects now, we can print our entire CSV as a series of dicts like so:</p><pre><code># read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r', newline='') as myCsvFile:\n    reader = csv.DictReader(myCsvFile)\n\tfor row in loc_reader:\n            for (k, v) in row.items():\n\t\t\t\tprint(k, ':', v)</code></pre><h3 id=\"skipping-headers\">Skipping Headers</h3><p>As we read information from CSVs to be repurposed for, say, API calls, we <em>probably</em> don't want to iterate over the first row of our CSV: this will output our key values alone, which would be useless in this context. Consider this:</p><pre><code># read_csv.py\nimport csv\n\nwith open('hackers.csv', 'r') as myCsvFile:\n\tnext(myCsvFile)\n\tfor row in myCsvFile.readlines():\n\t\tprint(row)</code></pre><p>Whoa! A different approach.... but somehow just as simple? In this case, we leave out <code>reader</code> altogether (which still works!) but more importantly, we introduce <code>next()</code>. <code>next(myCsvFile)</code> immediately skips to the next line in a CSV, so in our case, we simply skip line one before going into our For loop. Amazing.</p><h2 id=\"writing-to-csvs\">Writing to CSVs</h2><p>Writing to CSVs isn't much different than reading from them. In fact, almost all the same principles apply, where instances of the word \"read\" are more or less replaced with\" write. Huh. </p><pre><code># write_csv.py\nimport csv\n\nwith open('hackers.csv', 'w') as myCsvFile:\n    columns = ['column_name_1', 'column_name_2']\n    writer = csv.DictWriter(myCsvFile, fieldnames=columns)\n\n    writer.writeheader()\n    writer.writerow({'column_name_1': 'Mark', 'column_name_2': 'Twain'})\n    writer.writerow({'column_name_1': 'Foo', 'column_name_2: 'Bar'})</code></pre><p>We're writing a brand new CSV here: 'hackers.csv' doesn't technically exist yet, but that doesn't stop Python from not giving a shit. Python knows what you mean. Python has your back.</p><p>Here, we set our headers as a fixed list set by the <code>column</code> variable. This is a static way of creating headers, but the same can be done dynamically by passing the <code>keys</code> of a dict, or whatever it is you like to do. </p><p><code>writer.writeheader()</code> knows what we're saying thanks to the aforementioned <code>fieldnames</code> we passed to our writer earlier. Good for you, writer.</p><p>But how do we write rows, you might ask? Why, with <code>writer.writerow()</code>, of course! Because we use <code>DictWriter</code> similarly to how we used <code>DictReader</code> earlier, we can map values to our CSV with simple column references. Easy.</p>","url":"https://hackersandslackers.com/reading-and-writing-to-csvs-in-python/","uuid":"eb4f019f-e135-49d2-a568-f03f1e622d62","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5bad11e75ee4c83af27dda9e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673709","title":"Using Random Forests for Feature Selection with Categorical Features","slug":"random-forests-for-feature-selection","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/codesnippertsomething@2x.jpg","excerpt":"Python helper functions for adding feature importance, and displaying them as a single variable.","custom_excerpt":"Python helper functions for adding feature importance, and displaying them as a single variable.","created_at_pretty":"24 September, 2018","published_at_pretty":"24 September, 2018","updated_at_pretty":"19 February, 2019","created_at":"2018-09-23T20:23:32.000-04:00","published_at":"2018-09-24T07:30:00.000-04:00","updated_at":"2019-02-19T03:48:04.000-05:00","meta_title":"Using Random Forests for Feature Selection | Hackers and Slackers","meta_description":"Helper functions in Python to gauge  importance of Categorical Features for Random Forests in Scikit-learn","og_description":"Helper functions in Python to gauge  importance of Categorical Features for Random Forests in Scikit-learn","og_image":"https://hackersandslackers.com/content/images/2018/09/codesnippertsomething@2x.jpg","og_title":"Using Random Forests for Feature Selection","twitter_description":"Helper functions in Python to gauge  importance of Categorical Features for Random Forests in Scikit-learn","twitter_image":"https://hackersandslackers.com/content/images/2018/09/codesnippertsomething@2x.jpg","twitter_title":"Using Random Forests for Feature Selection","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},"tags":[{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},{"name":"Machine Learning","slug":"machine-learning","description":"The latest developments in machine learning tools and technology available to data scientists.","feature_image":null,"meta_description":"The latest developments in machine learning tools and technology available to data scientists.","meta_title":"Machine Learning | Hackers and Slackers","visibility":"public"},{"name":"#Code Snippet Corner","slug":"code-snippet-corner","description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o_o.jpg","meta_description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","meta_title":"Python Code Snippet Corner","visibility":"internal"}],"plaintext":"Notebook here\n[https://github.com/mattalhonte/random_forest_categorical_feature_imprtance/blob/master/Categorical%20Feature%20Importance.ipynb]\n.  Helper functions here\n[https://github.com/mattalhonte/random_forest_categorical_feature_imprtance/blob/master/foresthelpers/featureimportance.py]\n.\n\nOne of the best features of Random Forests is that it has built-in Feature\nSelection.  Explicability is one of the things we often lose when we go from\ntraditional statistics to Machine Learning, but Random Forests lets us actually\nget some insight into our dataset instead of just having to treat our model as a\nblack box.\n\nOne problem, though - it doesn't work that well for categorical features.  Since\nyou'll generally have to One-Hot Encode a categorical feature (for instance,\nturn something with 7 categories into 7 variables that are a \"True/False\"),\nyou'll wind up with a bunch of small features.  This gets tough to read,\nespecially if you're dealing with a lot of categories.  It also makes that\nfeature look less important than it is - rather than appearing near the top,\nyou'll maybe have 17 weak-seeming features near the bottom - which gets worse if\nyou're filtering it so that you only see features above a certain threshold.\n\nSoo, here's some helper functions for adding up their importance and displaying\nthem as a single variable.  I did have to \"reinvent the wheel\" a bit and roll my\nmy own One-Hot function, rather than using Scikit's builtin one.\n\nFirst, let's grab a dataset.  I'm using this\n[https://www.kaggle.com/c/avazu-ctr-prediction]  Kaggle dataset because it has a\ngood number of categorical predictors.  I'm also only using the first 500 rows\nbecause the whole dataset is like ~ 1 GB.\n\nimport pandas as pd\n\ndf = pd.read_csv(\"train.csv\", \n                   nrows=500)\n\nLet's just use the Categorical variables as our predictors because that's what\nwe're focusing on, but in actual usage you don't have to make them the same.\n\npredVars = [\n    \"site_category\",\n    \"app_category\",\n    \"device_model\",\n    \"device_type\",\n    \"device_conn_type\",\n]\n\nX = (df\n     .dropna()\n     [predVars]\n     .pipe((fh.oneHotEncodeMultipleVars, \"df\"),\n           varList = predVars) #Change this if you don't have solely categoricals\n    )\n\nlabels = X.columns\n\ny = (df\n     .dropna()\n     [\"click\"]\n     .values)\n\nLet's use log_loss  as our metric, because I saw this\n[https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512] \n blog post that used it for this dataset.\n\nfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.metrics import log_loss\nfi.displayFeatureImportances(X,y,labels,log_loss,{\"n_estimators\": 18,\"oob_score\": True},)\nScore is 3.6297600214665064 \n\nVariable\n Importance\n 0\n device_model\n 0.843122\n 1\n site_category\n 0.083392\n 2\n app_category\n 0.037216\n 3\n device_type\n 0.025057\n 4\n device_conn_type\n 0.011213","html":"<p><em>Notebook <a href=\"https://github.com/mattalhonte/random_forest_categorical_feature_imprtance/blob/master/Categorical%20Feature%20Importance.ipynb\">here</a>.  Helper functions <a href=\"https://github.com/mattalhonte/random_forest_categorical_feature_imprtance/blob/master/foresthelpers/featureimportance.py\">here</a>.</em></p><p>One of the best features of Random Forests is that it has built-in Feature Selection.  Explicability is one of the things we often lose when we go from traditional statistics to Machine Learning, but Random Forests lets us actually get some insight into our dataset instead of just having to treat our model as a black box.</p><p>One problem, though - it doesn't work that well for categorical features.  Since you'll generally have to One-Hot Encode a categorical feature (for instance, turn something with 7 categories into 7 variables that are a \"True/False\"), you'll wind up with a bunch of small features.  This gets tough to read, especially if you're dealing with a lot of categories.  It also makes that feature look less important than it is - rather than appearing near the top, you'll maybe have 17 weak-seeming features near the bottom - which gets worse if you're filtering it so that you only see features above a certain threshold.</p><p>Soo, here's some helper functions for adding up their importance and displaying them as a single variable.  I did have to \"reinvent the wheel\" a bit and roll my my own One-Hot function, rather than using Scikit's builtin one.</p><p>First, let's grab a dataset.  I'm using <a href=\"https://www.kaggle.com/c/avazu-ctr-prediction\">this</a> Kaggle dataset because it has a good number of categorical predictors.  I'm also only using the first 500 rows because the whole dataset is like ~ 1 GB.</p><pre><code>import pandas as pd\n\ndf = pd.read_csv(\"train.csv\", \n                   nrows=500)</code></pre><p>Let's just use the Categorical variables as our predictors because that's what we're focusing on, but in actual usage you don't have to make them the same.</p><pre><code>predVars = [\n    \"site_category\",\n    \"app_category\",\n    \"device_model\",\n    \"device_type\",\n    \"device_conn_type\",\n]\n\nX = (df\n     .dropna()\n     [predVars]\n     .pipe((fh.oneHotEncodeMultipleVars, \"df\"),\n           varList = predVars) #Change this if you don't have solely categoricals\n    )\n\nlabels = X.columns\n\ny = (df\n     .dropna()\n     [\"click\"]\n     .values)</code></pre><p>Let's use <code>log_loss</code> as our metric, because I saw <a href=\"https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512\">this</a> blog post that used it for this dataset.</p><pre><code>from sklearn.ensemble import RandomForestClassifierfrom sklearn.metrics import log_loss\nfi.displayFeatureImportances(X,y,labels,log_loss,{\"n_estimators\": 18,\"oob_score\": True},)\nScore is 3.6297600214665064 </code></pre><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variable</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>device_model</td>\n      <td>0.843122</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>site_category</td>\n      <td>0.083392</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>app_category</td>\n      <td>0.037216</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>device_type</td>\n      <td>0.025057</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>device_conn_type</td>\n      <td>0.011213</td>\n    </tr>\n  </tbody>\n</table>","url":"https://hackersandslackers.com/random-forests-for-feature-selection/","uuid":"26ebccb3-ab41-44cf-8d57-bf995100b088","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5ba82e84a1cf0b13cf2e9886"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673701","title":"Flask Routing & Sessions: A Subtle Symphony","slug":"the-art-of-building-flask-routes","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/flaskroutes@2x.jpg","excerpt":"With great flexibility comes great responsibility .","custom_excerpt":"With great flexibility comes great responsibility .","created_at_pretty":"17 September, 2018","published_at_pretty":"19 September, 2018","updated_at_pretty":"17 November, 2018","created_at":"2018-09-17T05:05:03.000-04:00","published_at":"2018-09-19T08:58:00.000-04:00","updated_at":"2018-11-16T20:57:42.000-05:00","meta_title":"Flask Routing & Sessions: A Subtle Symphony | Hackers and Slackers","meta_description":"There's nothing wrong with being a worker drone repeating worthless projects and contributing nothing to humanity. I'd personally prefer using Flask.","og_description":"There's nothing wrong with being a worker drone repeating worthless projects and contributing nothing to humanity. I'd personally prefer using Flask.","og_image":"https://hackersandslackers.com/content/images/2018/09/flaskroutes@2x.jpg","og_title":"Flask Routing & Sessions: A Subtle Symphony | Hackers and Slackers","twitter_description":"There's nothing wrong with being a worker drone repeating worthless projects and contributing nothing to humanity. I'd personally prefer using Flask.","twitter_image":"https://hackersandslackers.com/content/images/2018/09/flaskroutes@2x.jpg","twitter_title":"Flask Routing & Sessions: A Subtle Symphony | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"It isn't often you find somebody sad or miserable enough to detail the inner\nworkings of web framework features, such as sessions or routing. This is\nunderstandably so; we use frameworks because presumably hate dealing with these\nthings from scratch. This is especially so when it comes to Flask, which only\nreleased version 1.0 a few months ago, introducing breaking changes rendering\nprevious documentation more-or-less worthless. \n\nGoogling some of Flask's critical features mostly returns one-liners from the\napp's authors (half of which are useless, as they are for older versions of\nFlask). Stack Overflow threads mostly sit in silence, and even Kite\n[https://kite.com/], AKA \"The smart copilot for programmers\" returns blank pages\nof documentation, akin to the blank stare of a clueless Golden Retriever.\n\nIn retrospect, it was probably a poor choice for me to pick up 4 separate\nFlask-based projects during this time.\n\nWe're in a historic place in time where a team of developers put together\nsomething beautiful, yet somehow feels undersold. It seems as though the niche\nmarket of \"those who can't do, teach\" remains untapped for Flask, as the usual\nsuspects have yet to \"do\". This leaves newcomers like myself to hack away for\ntheir own survival in the meantime. I've only just turned that mental corner\nwhere Flask's quirks are as comforting as home-cooked meal, as opposed to\nfrustrating single-word methods containing 6 words of documentation on average.\n\nThe good news is I am still technically alive, after spending weeks building\nFlask applications mostly through trial and error. The bad news is that I've\nbecome Mr. Robot  in the process. That said, if there will ever be an ideal\nmoment in my life to write about Flask, now is the time. As reality slowly slips\naway in 1s and 0s, I may as well pass along  what I've learned.\n\nBroad Strokes\nIt only takes a couple minutes into explaining what Flask is when you realize\nthat Flask, at its core, is overwhelmingly just the “V” in “MVC”. Jinja handles\nthe templates, and something like SQLAlchemy will likely handle your models.\nFlask has an abundance of third-party libraries to handle business logic, but it\nis the core Flask package that we all agreed to gather around. This speaks\nvolumes about the quality of Flask’s simple yet powerful request handling.\n\nI'll  break down as many of Flask's out-of-the-box features, focusing on what\nmatters most (in my opinion). Take a look at some of the Flask libraries we'll\nbe playing around with:\n\n# app.py\nfrom flask import Flask, render_template, request, redirect, Session, g\nimport os\n\nConfiguring Our App\nAs always, we create our app with app = Flask(name). Equally uninteresting is\nour configuration setup, which we'll import via a class in config.py:\n\n# app.py\nfrom flask import Flask, render_template, request, redirect, Session, g\nimport config\nimport os\n\n# Our app\napp = Flask(__name__)\n\n# Load our config variables\napp.config.from_object('config.ProductionConfig')\n\nA number of things in our config are absolutely essential for sessions to work.\nBelow is an example config file:\n\n# config.py\nimport os\n\nclass ProductionConfig():\n    \"\"\"Set app config vars.\"\"\"\n    SECRET_KEY = os.urandom(24)\n    SESSION_TYPE = null\n    SESSION_COOKIE_NAME = 'session name'\n    SESSION_PERMANENT = True\n    PERMANENT_SESSION_LIFETIME = timedelta(days=31) (2678400 seconds)\n\nSECRET_KEY  is critical: this variable needs to exist in out config for sessions\nto function properly. The best way to handle is is by generating a key as seen\nabove.\n\nSESSION_TYPE  allows us to specify where our session data should be stored. This\nis set null by default, but Flask supports a number of options:\n\n * RedisSessionInterface:  Uses the Redis key-value store as a session backend. \n * MemcachedSessionInterface:  Uses the Memcached as a session backend. \n * FileSystemSessionInterface:  werkzeug.contrib.cache.FileSystemCache  as a\n   session backend.\n * MongoDBSessionInterface:  Uses MongoDB as a backend \n   [http://api.mongodb.org/python/current/index.html]via pymongo\n * SqlAlchemySessionInterface:  Uses SQLAlchemy, or rather Flask-SQLAlchemy\n   [https://pythonhosted.org/Flask-SQLAlchemy/]\n\nThere are plenty more variables you can set if you want to take a look here\n[http://flask.pocoo.org/docs/1.0/config/].\n\nSessions and Contexts\nUnlike cookie-based sessions, Flask sessions are handled and stored on the\nserver-side. A session object is simply a dict which is accessible throughout\nthe application a global level, referring to a single 'logged-in user'. As long\nas the session is active, any context of our app will be able to retrieve,\nmodify, or delete the values held in this session object,\n\n# Save a value to the user's session.\nsession['username'] = 'MyUsername' \n\n# IMPORTANT: \"True\" forces our changes to be recognized.\nsession.modified = True: \n\n# Retrieve session values at any time, anywhere \nsession.get('username') = True\n\nSeeing as how sessions are accessible globally, it is also important to note\nthat sessions can last a very long time; pretty much self explanatory given the \nSESSION_PERMANENT = True  configuration option.  It's a good idea to set a\nsession timeout period, or better yet, close them by the user's own request.\nClearing a session is as simple as resetting the session dictionary values back\nto None  by using the pop  method: session.pop('value', None).\n\nThe Application Context\nBesides undying global sessions,  Flask also provides us with a feature with an\nobject more suitable for storing and passing temporary values between app\ncontexts. This object known simply as g. While  technically an abbreviation for\n\"global\",g  is really just a convenient place to store temporarily store values\nwhich you can always depend on to be by your side.\n\n# app.py\nfrom Flask import g\n\nIt's important to note that values assigned to g  only exist within the context\nthey were created by default. For example, if we store information to the object\ndue to some user interaction on the dashboard, these values are lost once the\nuser moves to another part of our app. That said, values assigned to g  can\ntechnically be passed between contexts if we return g.value. This distinction\nbetween always-alive sessions  and every dying g  should be indicative of what\nreach respective object does.  Spoiler alert: sensitive (or contextually\nuseless) data should be stored temporarily with g, where values which will\ncontinuously be useful in determining the functionality of our should should\nreside in session.\n\nInterestingly enough, Flask has a decorator  specifically for terminating values\nsaved to g  in the case we'd want to ensure the swift and total annihilation of\nsuch data. For instance, if we were to assign a database connection to g  using\ng.db = connect_to_database(), we'd want to make sure that connection is closed\nas fast as possible before we forget:\n\n# app.py\ndef db_stuff():\n    g.db = database_connection()\n    g.db.somequeryorwhatever\n    return g.db\n\n@app.teardown_appcontext\ndef teardown_db():\n    db = g.pop('db', None)\n\nRoutes & Decorators\nWe're surely familiar with the concepts behind routing users to deserved views\nby now. Before we look at the juicy stuff, consider this boring route for a\nboring product, where the homepage is a dashboard:\n\n# app.py\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef dashboard():\n    \"\"\"Boring route.\"\"\"\n    return render_template('/dashboard.html')\n\nOh snap, our landing page is a /dashboard?  How will we know which user's\ndashboard to display when they visit the dashboard, or any other page for that\nmatter? If only there were a way to intercept every request a user makes to our\napp?\n\nFlask comes with a bunch of insanely useful decorators. Python decorators are\nfunctions which either 'wrap'  other functions in additional logic, or in our\ncase, intercept functions to do with them what we what. Flask has a vast\nplethora of logic decorators, ranging from detecting first-time visitors,\nhandling exceptions, executing logic before/after page loads, etc. Even the\nroute we set above is a decorator!\n\n@flask.before_request\nAdding before_request  to our app allows us to run logic prior to the\naforementioned request. With this power, we can do things like treat users\ndifferently (such as recognized or anonymous users), or just execute some sort\nof unique logic upon page load. \n\nIn this simple case, we check to see if a visitor has an active session every\ntime they hit a route. This way, if a user's session expired between before\nhitting a route in our app, we can prompt them to log in... or whatever. \n\nbefore_request doesn't accept any value parameters - the handler is mostly\nintended to perform tasks such as making a database query necessary for our app\nto run, or make sure users are still logged in.\n\n# app.py\n@app.before_request\ndef before_request():\n    \"\"\"Handle multiple users.\"\"\"\n    if 'username' in session:\n        return render_template('/dashboard.html')\n    else:\n        return render_template('/login.html')\n\n@flask.url_value_preprocessor\nUnlike before_request, url_value_preprocessor  does  accept incoming data. This\nallows us to handle data being posted to any part of our app before we even\nbother serving up views. Not only does this provide a convenient separation of\nconcerns, but also helps us avoid callback hell, which yes, can happen in Python\ntoo.\n\nLet's say we're accepting a POST request, where we create a view for our user's\npersonal details. When the user passes us their email address, we decide to\nretrieve the user's records by hitting an API, and passing the results to the\nview.\n\nWithout modularizing our code, we'd have to handle things like waiting on API\ncalls in the same functions as  our routes. Not only is this shitty repetitive\ncode, but running numerous API calls and rendering a view all at once is going\nto eventually break. Go ahead and ask the NodeJS guys. They'll know.\n\n# app.py\n@app.url_value_preprocessor\ndef url_value_preprocessor(endpoint, values):\n    \"\"\"Handle data sent to any route.\"\"\"\n       if request.args:\n           email = request.args.get('email')\n           r = requests.post(endpoint, headers=headers, data=email)\n           session['usermetadata'] = r\n           session.modified = True\n           return session\n\nYou're Only Getting Started\nWe've only covered small percentage of convenient tools Flask offers us. Go\nahead and see how many decorators [http://flask.pocoo.org/docs/1.0/api/]   you\ncan fuck with. Yeah dude, shit is legit - and we haven't even talked about the\nFlask-Login package yet.\n\nThe beauty of lightweight frameworks is that they focus on the problems that\ndrive us to web frameworks in the first place. Flask is clearly designed to\nhandle serving views, standing up APIs, and handling user management\neffectively. Contrast this with frameworks like Django, which forces rigid app\nsetup in what can commonly be an  hour-long setup or greater. I'll truthfully\nalways have a place in my heart for Django as the fathers of Python MVC: I would\ncan say with confidence that without the creation of Django (as well as the\nofficial $10 dollar intro book from Barnes and Noble) I never would have\ntransitioned from an obnoxious product manager  personality to the kind of guy\nwho owns multiple Python t-shirts. Hmm. Now that I think about it, maybe I\nshould've stayed an office tool as opposed to solving all these complex\nproblems. oh well.\n\nFlask is indicative of a new direction of framework design - or rather lack\nthereof. Programmers who know what they're doing  can express themselves outside\nof traditional boundaries set by other frameworks, surely designed to keep\nidiots from ruining everything. There's nothing wrong with being a worker drone\nrepeating the same worthless projects,  using same libraries, and essentially\ncontributing nothing to humanity. I'd personally prefer to take the freedom and\nspeed of Flask any day.","html":"<p>It isn't often you find somebody sad or miserable enough to detail the inner workings of web framework features, such as sessions or routing. This is understandably so; we use frameworks because presumably hate dealing with these things from scratch. This is especially so when it comes to Flask, which only released version 1.0 a few months ago, introducing breaking changes rendering previous documentation more-or-less worthless. </p><p>Googling some of Flask's critical features mostly returns one-liners from the app's authors (half of which are useless, as they are for older versions of Flask). Stack Overflow threads mostly sit in silence, and even <a href=\"https://kite.com/\">Kite</a>, AKA <em>\"The smart copilot for programmers\" </em>returns blank pages of documentation, akin to the blank stare of a clueless Golden Retriever.</p><p><strong><em>In retrospect, it was probably a poor choice for me to pick up 4 separate Flask-based projects during this time.</em></strong></p><p>We're in a historic place in time where a team of developers put together something beautiful, yet somehow feels undersold. It seems as though the niche market of \"those who can't do, teach\" remains untapped for Flask, as the usual suspects have yet to \"do\". This leaves newcomers like myself to hack away for their own survival in the meantime. I've only just turned that mental corner where Flask's quirks are as comforting as home-cooked meal, as opposed to frustrating single-word methods containing 6 words of documentation on average.</p><p>The good news is I am still technically alive, after spending weeks building Flask applications mostly through trial and error. The bad news is that I've become <em>Mr. Robot</em> in the process. That said, if there will ever be an ideal moment in my life to write about Flask, now is the time. As reality slowly slips away in 1s and 0s, I may as well pass along  what I've learned.</p><h2 id=\"broad-strokes\">Broad Strokes</h2><p>It only takes a couple minutes into explaining what Flask is when you realize that Flask, at its core, is overwhelmingly just the “V” in “MVC”. Jinja handles the templates, and something like SQLAlchemy will likely handle your models. Flask has an abundance of third-party libraries to handle business logic, but it is the core Flask package that we all agreed to gather around. This speaks volumes about the quality of Flask’s simple yet powerful request handling.</p><p>I'll  break down as many of Flask's out-of-the-box features, focusing on what matters most (in my opinion). Take a look at some of the Flask libraries we'll be playing around with:</p><pre><code># app.py\nfrom flask import Flask, render_template, request, redirect, Session, g\nimport os</code></pre><h2 id=\"configuring-our-app\">Configuring Our App</h2><p>As always, we create our app with <code>app = Flask(name)</code><em>. </em>Equally uninteresting is our configuration setup, which we'll import via a class in <code>config.py</code>:</p><pre><code># app.py\nfrom flask import Flask, render_template, request, redirect, Session, g\nimport config\nimport os\n\n# Our app\napp = Flask(__name__)\n\n# Load our config variables\napp.config.from_object('config.ProductionConfig')</code></pre><p>A number of things in our config are absolutely essential for sessions to work. Below is an example config file:</p><pre><code># config.py\nimport os\n\nclass ProductionConfig():\n    \"\"\"Set app config vars.\"\"\"\n    SECRET_KEY = os.urandom(24)\n    SESSION_TYPE = null\n    SESSION_COOKIE_NAME = 'session name'\n    SESSION_PERMANENT = True\n    PERMANENT_SESSION_LIFETIME = timedelta(days=31) (2678400 seconds)</code></pre><p><strong>SECRET_KEY</strong> is critical: this variable needs to exist in out config for sessions to function properly. The best way to handle is is by generating a key as seen above.</p><p><strong>SESSION_TYPE</strong> allows us to specify where our session data should be stored. This is set null by default, but Flask supports a number of options:</p><ul><li><a href=\"https://pythonhosted.org/Flask-Session/#flask.ext.session.RedisSessionInterface\">RedisSessionInterface</a>:<strong> </strong>Uses the Redis key-value store as a session backend. </li><li><a href=\"https://pythonhosted.org/Flask-Session/#flask.ext.session.MemcachedSessionInterface\">MemcachedSessionInterface</a>:<strong> </strong>Uses the Memcached as a session backend. </li><li><a href=\"https://pythonhosted.org/Flask-Session/#flask.ext.session.FileSystemSessionInterface\">FileSystemSessionInterface</a>:<strong> </strong><code>werkzeug.contrib.cache.FileSystemCache</code> as a session backend.</li><li><a href=\"https://pythonhosted.org/Flask-Session/#flask.ext.session.MongoDBSessionInterface\">MongoDBSessionInterface</a>:<strong> </strong>Uses MongoDB as a backend<a href=\"http://api.mongodb.org/python/current/index.html\"> </a>via <code>pymongo</code></li><li><a href=\"https://pythonhosted.org/Flask-Session/#flask.ext.session.SqlAlchemySessionInterface\">SqlAlchemySessionInterface</a>:<strong> </strong>Uses SQLAlchemy, or rather <a href=\"https://pythonhosted.org/Flask-SQLAlchemy/\">Flask-SQLAlchemy</a></li></ul><p>There are plenty more variables you can set if you want to take a look <a href=\"http://flask.pocoo.org/docs/1.0/config/\">here</a>.</p><h2 id=\"sessions-and-contexts\">Sessions and Contexts</h2><p>Unlike cookie-based sessions, Flask sessions are handled and stored on the server-side. A session object is simply a dict which is accessible throughout the application a global level, referring to a single 'logged-in user'. As long as the session is active, any context of our app will be able to retrieve, modify, or delete the values held in this session object,</p><pre><code># Save a value to the user's session.\nsession['username'] = 'MyUsername' \n\n# IMPORTANT: \"True\" forces our changes to be recognized.\nsession.modified = True: \n\n# Retrieve session values at any time, anywhere \nsession.get('username') = True</code></pre><p>Seeing as how sessions are accessible globally, it is also important to note that sessions can last a very long time; pretty much self explanatory given the <code>SESSION_PERMANENT = True</code> configuration option.  It's a good idea to set a session timeout period, or better yet, close them by the user's own request. Clearing a session is as simple as resetting the session dictionary values back to <em>None</em> by using the <strong>pop</strong> method: <code>session.pop('value', None)</code>.</p><h3 id=\"the-application-context\">The Application Context</h3><p>Besides undying global sessions,  Flask also provides us with a feature with an object more suitable for storing and passing temporary values between app contexts. This object known simply as <code>g</code>. While<strong> </strong>technically an abbreviation for \"global\",  <code>g</code> is really just a convenient place to store temporarily store values which you can always depend on to be by your side.</p><pre><code># app.py\nfrom Flask import g</code></pre><p>It's important to note that values assigned to <code>g</code> <em>only exist within the context they were created </em>by default. For example, if we store information to the object due to some user interaction on the dashboard, these values are lost once the user moves to another part of our app. That said, values assigned to <code>g</code> can technically be passed between contexts if we <code>return g.value</code>. This distinction between always-alive <em>sessions</em> and every dying <em>g</em> should be indicative of what reach respective object does.  Spoiler alert: sensitive (or contextually useless) data should be stored temporarily with <code>g</code>, where values which will continuously be useful in determining the functionality of our should should reside in <code>session</code><em>.</em></p><p>Interestingly enough, Flask has a <em>decorator</em> specifically for terminating values saved to <code>g</code> in the case we'd want to ensure the swift and total annihilation of such data. For instance, if we were to assign a database connection to <code>g</code> using  <code>g.db = connect_to_database()</code>, we'd want to make sure that connection is closed as fast as possible before we forget:</p><pre><code># app.py\ndef db_stuff():\n    g.db = database_connection()\n    g.db.somequeryorwhatever\n    return g.db\n\n@app.teardown_appcontext\ndef teardown_db():\n    db = g.pop('db', None)</code></pre><h2 id=\"routes-decorators\">Routes &amp; Decorators</h2><p>We're surely familiar with the concepts behind routing users to deserved views by now. Before we look at the juicy stuff, consider this boring route for a boring product, where the homepage is a dashboard:</p><pre><code># app.py\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef dashboard():\n    \"\"\"Boring route.\"\"\"\n    return render_template('/dashboard.html')</code></pre><p>Oh snap, our landing page is a /<em>dashboard?</em> How will we know which user's dashboard to display when they visit the dashboard, or any other page for that matter? If only there were a way to intercept every request a user makes to our app?</p><p>Flask comes with a bunch of insanely useful <strong><em>decorators</em></strong>. Python decorators are functions which either 'wrap'  other functions in additional logic, or in our case, intercept functions to do with them what we what. Flask has a vast plethora of logic decorators, ranging from detecting first-time visitors, handling exceptions, executing logic before/after page loads, etc. Even the route we set above is a decorator!</p><h3 id=\"-flask-before_request\">@flask.before_request</h3><p>Adding <strong>before_request</strong> to our app allows us to run logic prior to the aforementioned request. With this power, we can do things like treat users differently (such as recognized or anonymous users), or just execute some sort of unique logic upon page load. </p><p>In this simple case, we check to see if a visitor has an active session every time they hit a route. This way, if a user's session expired between before hitting a route in our app, we can prompt them to log in... or whatever. </p><p><strong>before_request </strong>doesn't accept any value parameters - the handler is mostly intended to perform tasks such as making a database query necessary for our app to run, or make sure users are still logged in.</p><pre><code># app.py\n@app.before_request\ndef before_request():\n    \"\"\"Handle multiple users.\"\"\"\n    if 'username' in session:\n        return render_template('/dashboard.html')\n    else:\n        return render_template('/login.html')</code></pre><h3 id=\"-flask-url_value_preprocessor\">@flask.url_value_preprocessor</h3><p>Unlike <em>before_request</em><strong>, url_value_preprocessor</strong> <em>does</em> accept incoming data. This allows us to handle data being posted to any part of our app before we even bother serving up views. Not only does this provide a convenient separation of concerns, but also helps us avoid <em>callback hell, </em>which yes, can happen in Python too.</p><p>Let's say we're accepting a POST request, where we create a view for our user's personal details. When the user passes us their email address, we decide to retrieve the user's records by hitting an API, and passing the results to the view.</p><p>Without modularizing our code, we'd have to handle things like waiting on API calls in the same functions as  our routes. Not only is this shitty repetitive code, but running numerous API calls and rendering a view all at once is going to eventually break. Go ahead and ask the NodeJS guys. They'll know.</p><pre><code># app.py\n@app.url_value_preprocessor\ndef url_value_preprocessor(endpoint, values):\n    \"\"\"Handle data sent to any route.\"\"\"\n       if request.args:\n           email = request.args.get('email')\n           r = requests.post(endpoint, headers=headers, data=email)\n           session['usermetadata'] = r\n           session.modified = True\n           return session</code></pre><h2 id=\"you-re-only-getting-started\">You're Only Getting Started</h2><p>We've only covered small percentage of convenient tools Flask offers us. Go ahead and see <a href=\"http://flask.pocoo.org/docs/1.0/api/\">how many decorators</a>  you can fuck with. Yeah dude, shit is legit - and we haven't even talked about the Flask-Login package yet.</p><p>The beauty of lightweight frameworks is that they focus on the problems that drive us to web frameworks in the first place. Flask is clearly designed to handle serving views, standing up APIs, and handling user management effectively. Contrast this with frameworks like <strong>Django</strong>, which forces rigid app setup in what can commonly be an  hour-long setup or greater. I'll truthfully always have a place in my heart for Django as the fathers of Python MVC: I would can say with confidence that without the creation of Django (as well as the official $10 dollar intro book from Barnes and Noble) I never would have transitioned from an obnoxious product manager  personality to the kind of guy who owns multiple Python t-shirts. Hmm. Now that I think about it, maybe I should've stayed an office tool as opposed to solving all these complex problems. oh well.</p><p>Flask is indicative of a new direction of framework design - or rather lack thereof. Programmers who <em>know what they're doing</em> can express themselves outside of traditional boundaries set by other frameworks, surely designed to keep idiots from ruining everything. There's nothing wrong with being a worker drone repeating the same worthless projects,  using same libraries, and essentially contributing nothing to humanity. I'd personally prefer to take the freedom and speed of Flask any day.</p><p></p>","url":"https://hackersandslackers.com/the-art-of-building-flask-routes/","uuid":"67a6407a-5804-4bd0-812d-219561e2488a","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b9f6e3ff79bcf0717187d8b"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673700","title":"Tuning Random Forests Hyperparameters with Binary Search Part III: min_samples_leaf","slug":"random-forests-hyperparameters-min_samples_leaf","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/codecorner2-1-1@2x.jpg","excerpt":"Tune the min_samples_leaf parameter in for a Random Forests classifier in scikit-learn in Python\n.","custom_excerpt":"Tune the min_samples_leaf parameter in for a Random Forests classifier in scikit-learn in Python\n.","created_at_pretty":"17 September, 2018","published_at_pretty":"17 September, 2018","updated_at_pretty":"19 February, 2019","created_at":"2018-09-16T21:33:48.000-04:00","published_at":"2018-09-17T07:30:00.000-04:00","updated_at":"2019-02-19T03:44:33.000-05:00","meta_title":"Tuning Random Forests Hyperparameters with Binary Search Part III: min_samples_leaf | Hackers and Slackers","meta_description":"Tune the min_samples_leaf parameter in for a Random Forests classifier in scikit-learn in Python\n","og_description":"Tuning Random Forests Hyperparameters with Binary Search Part III: min_samples_leaf","og_image":"https://hackersandslackers.com/content/images/2018/09/codecorner2-1-1@2x.jpg","og_title":"Tuning Random Forests Hyperparameters with Binary Search Part III: min_samples_leaf","twitter_description":"Tune the min_samples_leaf parameter in for a Random Forests classifier in scikit-learn in Python\n","twitter_image":"https://hackersandslackers.com/content/images/2018/09/codecorner2-1-1@2x.jpg","twitter_title":"Tuning Random Forests Hyperparameters with Binary Search Part III: min_samples_leaf","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},"tags":[{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},{"name":"Machine Learning","slug":"machine-learning","description":"The latest developments in machine learning tools and technology available to data scientists.","feature_image":null,"meta_description":"The latest developments in machine learning tools and technology available to data scientists.","meta_title":"Machine Learning | Hackers and Slackers","visibility":"public"},{"name":"#Code Snippet Corner","slug":"code-snippet-corner","description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o_o.jpg","meta_description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","meta_title":"Python Code Snippet Corner","visibility":"internal"}],"plaintext":"Part 1 (n_estimators) here\n[https://hackersandslackers.com/code-snippet-corner-tuning-machine-learning-hyperparameters-with-binary-search/]\nPart 2 (max_depth) here\n[https://hackersandslackers.com/code-snippet-corner-tuning-random-learning-hyperparameters-with-binary-search/]\nNotebook here\n[https://github.com/mattalhonte/binary-grid-search/blob/master/Introspect%20Trees%20(Samples).ipynb]\n\n\n--------------------------------------------------------------------------------\n\nAnother parameter, another set of quirks!\n\nmin_samples_leaf  is sort of similar to max_depth.  It helps us avoid\noverfitting.  It's also non-obvious what you should use as your upper and lower\nlimits to search between.  Let's do what we did last week - build a forest with\nno parameters, see what it does, and use the upper and lower limits!\n\nimport pandas as pd\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_breast_cancer\n\n\ndata = load_breast_cancer()\nX, y = data.data, data.target\n\nrfArgs = {\"random_state\": 0,\n          \"n_jobs\": -1,\n          \"class_weight\": \"balanced\",\n         \"n_estimators\": 18,\n         \"oob_score\": True}\n\nclf = RandomForestClassifier(**rfArgs)\nclf.fit(X, y)\n\n\nLet's use the handy function from here\n[https://aysent.github.io/2015/11/08/random-forest-leaf-visualization.html]  to\ncrawl the number of samples in a tree's leaf nodes: \n\ndef leaf_samples(tree, node_id = 0):\n    left_child = tree.children_left[node_id]\n    right_child = tree.children_right[node_id]\n    \n    if left_child == _tree.TREE_LEAF:\n        samples = np.array([tree.n_node_samples[node_id]])\n        \n    else:\n        \n        left_samples = leaf_samples(tree, left_child)\n        right_samples = leaf_samples(tree, right_child)\n        \n        samples = np.append(left_samples, right_samples)\n        \n    return samples\n\n\nLast week we made a function to grab them for a whole forest - since this is the\nsecond time we're doing this, and we may do it again, let's make a modular\nlittle function that takes a crawler function as an argument!\n\ndef getForestParams(X, y, param, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    clf.fit(X, y)\n    params = np.hstack([param(estimator.tree_) \n                 for estimator in clf.estimators_])\n    return {\"min\": params.min(),\n           \"max\": params.max()}\n\n\nLet's see it in action!\n\ndata = load_breast_cancer()\nX, y = data.data, data.target\n\nrfArgs = {\"random_state\": 0,\n          \"n_jobs\": -1,\n          \"class_weight\": \"balanced\",\n         \"n_estimators\": 18,\n         \"oob_score\": True}\n\ngetForestParams(X, y, leaf_samples, rfArgs)\n#> {'max': 199, 'min': 1}\n\n\nAlmost ready to start optimizing!  Since part of what we get out of optimizing \nmin_samples_leaf  is regularization (and because it's just good practice!),\nlet's make a metric with some cross-validation.  Luckily, Scikit  has a builtin \ncross_val_score  function.  We'll just need to do a teensy bit of tweaking to\nmake it use the area under a precision_recall_curve.\n\nfrom sklearn.model_selection import cross_val_score\n\ndef auc_prc(estimator, X, y):\n    estimator.fit(X, y)\n    y_pred = estimator.oob_decision_function_[:, 1]\n    precision, recall, _ = precision_recall_curve(y, y_pred)\n    return auc(recall, precision)\n\ndef getForestAccuracyCV(X, y, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    return np.mean(cross_val_score(clf, X, y, scoring=auc_prc, cv=5))\n\n\nAwesome, now we have a metric that can be fed into our binary search.\n\nmin_samples_leaf = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracyCV,        \n                    rfArgs, \n                    \"min_samples_leaf\", \n                    0, \n                    1, \n                    199)\nbgs.showTimeScoreChartAndGraph(min_samples_leaf)\n\n\nmin_samples_leaf\n score\n time\n 1\n 0.981662\n 1.402102\n 199\n 0.506455\n 1.416349\n 100\n 0.506455\n 1.401090\n 51\n 0.506455\n 1.394548\n 26\n 0.975894\n 1.396503\n 14\n 0.982954\n 1.398522\n 7\n 0.979888\n 1.398929\n 10\n 0.984789\n 1.404815\n 12\n 0.986302\n 1.391171\n \nmin_samples_leaf\n score\n time\n scoreTimeRatio\n 1\n 0.992414\n 0.473848\n 0.082938\n 199\n 0.002084\n 1.039718\n 0.000000\n 100\n 0.002084\n 0.433676\n 0.000111\n 51\n 0.002084\n 0.173824\n 0.000396\n 26\n 0.980393\n 0.251484\n 0.154448\n 14\n 0.995105\n 0.331692\n 0.118839\n 7\n 0.988716\n 0.347858\n 0.112585\n 10\n 0.998930\n 0.581632\n 0.067998\n 12\n 1.002084\n 0.039718\n 1.000000\n Looks like the action's between 1 and 51.  More than that, and the score goes\nwhile simultaneously increasing the runtime - the opposite of what we want!\n\nmin_samples_leaf = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracyCV,        \n                    rfArgs, \n                    \"min_samples_leaf\", \n                    0, \n                    1, \n                    14)\nbgs.showTimeScoreChartAndGraph(min_samples_leaf)\n\n\nmin_samples_leaf\n score\n time\n 1\n 0.981662\n 1.389387\n 51\n 0.506455\n 1.403807\n 26\n 0.975894\n 1.404517\n 14\n 0.982954\n 1.385420\n 7\n 0.979888\n 1.398840\n 10\n 0.984789\n 1.393863\n 12\n 0.986302\n 1.411774\n \nmin_samples_leaf\n score\n time\n scoreTimeRatio\n 1\n 0.992414\n 0.188492\n 0.200671\n 51\n 0.002084\n 0.735618\n 0.000000\n 26\n 0.980393\n 0.762561\n 0.048920\n 14\n 0.995105\n 0.037944\n 1.000000\n 7\n 0.988716\n 0.547179\n 0.068798\n 10\n 0.998930\n 0.358303\n 0.106209\n 12\n 1.002084\n 1.037944\n 0.036709\n Big drop-off after 26, it seems!\n\nmin_samples_leaf = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracyCV,        \n                    rfArgs, \n                    \"min_samples_leaf\", \n                    0, \n                    1, \n                    26)\nbgs.showTimeScoreChartAndGraph(min_samples_leaf)\n\n\nmin_samples_leaf\n score\n time\n 1\n 0.981662\n 1.407957\n 26\n 0.975894\n 1.398042\n 14\n 0.982954\n 1.396782\n 7\n 0.979888\n 1.396096\n 10\n 0.984789\n 1.402322\n 12\n 0.986302\n 1.401080\n \nmin_samples_leaf\n score\n time\n scoreTimeRatio\n 1\n 0.650270\n 1.084306\n 0.040144\n 26\n 0.096077\n 0.248406\n 0.000000\n 14\n 0.774346\n 0.142157\n 0.954016\n 7\n 0.479788\n 0.084306\n 1.000000\n 10\n 0.950677\n 0.609184\n 0.221294\n 12\n 1.096077\n 0.504512\n 0.336668\n One more with 14 as our upper limit!\n\nmin_samples_leaf = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracyCV,        \n                    rfArgs, \n                    \"min_samples_leaf\", \n                    0, \n                    1, \n                    14)\nbgs.showTimeScoreChartAndGraph(min_samples_leaf)\n\n\nmin_samples_leaf\n score\n time\n 1\n 0.981662\n 1.401341\n 14\n 0.982954\n 1.400361\n 7\n 0.979888\n 1.402408\n 4\n 0.981121\n 1.401396\n 3\n 0.983580\n 1.401332\n \nmin_samples_leaf\n score\n time\n scoreTimeRatio\n 1\n 0.992414\n 0.188492\n 0.200671\n 51\n 0.002084\n 0.735618\n 0.000000\n 26\n 0.980393\n 0.762561\n 0.048920\n 14\n 0.995105\n 0.037944\n 1.000000\n 7\n 0.988716\n 0.547179\n 0.068798\n 10\n 0.998930\n 0.358303\n 0.106209\n 12\n 1.002084\n 1.037944\n 0.036709\n 3 it is!I suppose when it gets this small we could use a regular Grid Search,\nbut...maybe next week!  Or maybe another variable!  Or maybe benchmarks vs \nGridSearchCV  and/or RandomizedSearchCV.  Who knows what the future holds?","html":"<p>Part 1 (n_estimators) <a href=\"https://hackersandslackers.com/code-snippet-corner-tuning-machine-learning-hyperparameters-with-binary-search/\">here</a><br>Part 2 (max_depth) <a href=\"https://hackersandslackers.com/code-snippet-corner-tuning-random-learning-hyperparameters-with-binary-search/\">here</a><br>Notebook <a href=\"https://github.com/mattalhonte/binary-grid-search/blob/master/Introspect%20Trees%20(Samples).ipynb\">here</a></p><hr><p>Another parameter, another set of quirks!</p><p><code>min_samples_leaf</code> is sort of similar to <code>max_depth</code>.  It helps us avoid overfitting.  It's also non-obvious what you should use as your upper and lower limits to search between.  Let's do what we did last week - build a forest with no parameters, see what it does, and use the upper and lower limits!</p><pre><code class=\"language-python\">import pandas as pd\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_breast_cancer\n\n\ndata = load_breast_cancer()\nX, y = data.data, data.target\n\nrfArgs = {&quot;random_state&quot;: 0,\n          &quot;n_jobs&quot;: -1,\n          &quot;class_weight&quot;: &quot;balanced&quot;,\n         &quot;n_estimators&quot;: 18,\n         &quot;oob_score&quot;: True}\n\nclf = RandomForestClassifier(**rfArgs)\nclf.fit(X, y)\n</code></pre>\n<p>Let's use the handy function from <a href=\"https://aysent.github.io/2015/11/08/random-forest-leaf-visualization.html\">here</a> to crawl the number of samples in a tree's leaf nodes: </p><pre><code class=\"language-python\">def leaf_samples(tree, node_id = 0):\n    left_child = tree.children_left[node_id]\n    right_child = tree.children_right[node_id]\n    \n    if left_child == _tree.TREE_LEAF:\n        samples = np.array([tree.n_node_samples[node_id]])\n        \n    else:\n        \n        left_samples = leaf_samples(tree, left_child)\n        right_samples = leaf_samples(tree, right_child)\n        \n        samples = np.append(left_samples, right_samples)\n        \n    return samples\n</code></pre>\n<p>Last week we made a function to grab them for a whole forest - since this is the second time we're doing this, and we may do it again, let's make a modular little function that takes a crawler function as an argument!</p><pre><code class=\"language-python\">def getForestParams(X, y, param, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    clf.fit(X, y)\n    params = np.hstack([param(estimator.tree_) \n                 for estimator in clf.estimators_])\n    return {&quot;min&quot;: params.min(),\n           &quot;max&quot;: params.max()}\n</code></pre>\n<p>Let's see it in action!</p><pre><code class=\"language-python\">data = load_breast_cancer()\nX, y = data.data, data.target\n\nrfArgs = {&quot;random_state&quot;: 0,\n          &quot;n_jobs&quot;: -1,\n          &quot;class_weight&quot;: &quot;balanced&quot;,\n         &quot;n_estimators&quot;: 18,\n         &quot;oob_score&quot;: True}\n\ngetForestParams(X, y, leaf_samples, rfArgs)\n#&gt; {'max': 199, 'min': 1}\n</code></pre>\n<p>Almost ready to start optimizing!  Since part of what we get out of optimizing <code>min_samples_leaf</code> is regularization (and because it's just good practice!), let's make a metric with some cross-validation.  Luckily, <strong>Scikit</strong> has a builtin <code>cross_val_score</code> function.  We'll just need to do a teensy bit of tweaking to make it use the area under a <code>precision_recall_curve</code>.</p><pre><code class=\"language-python\">from sklearn.model_selection import cross_val_score\n\ndef auc_prc(estimator, X, y):\n    estimator.fit(X, y)\n    y_pred = estimator.oob_decision_function_[:, 1]\n    precision, recall, _ = precision_recall_curve(y, y_pred)\n    return auc(recall, precision)\n\ndef getForestAccuracyCV(X, y, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    return np.mean(cross_val_score(clf, X, y, scoring=auc_prc, cv=5))\n</code></pre>\n<p>Awesome, now we have a metric that can be fed into our binary search.</p><pre><code class=\"language-python\">min_samples_leaf = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracyCV,        \n                    rfArgs, \n                    &quot;min_samples_leaf&quot;, \n                    0, \n                    1, \n                    199)\nbgs.showTimeScoreChartAndGraph(min_samples_leaf)\n</code></pre>\n<div class=\"tableContainer\">\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>min_samples_leaf</th>\n      <th>score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.981662</td>\n      <td>1.402102</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>0.506455</td>\n      <td>1.416349</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>0.506455</td>\n      <td>1.401090</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.506455</td>\n      <td>1.394548</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.975894</td>\n      <td>1.396503</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.982954</td>\n      <td>1.398522</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.979888</td>\n      <td>1.398929</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.984789</td>\n      <td>1.404815</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.986302</td>\n      <td>1.391171</td>\n    </tr>\n  </tbody>\n</table>\n<br>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>min_samples_leaf</th>\n      <th>score</th>\n      <th>time</th>\n      <th>scoreTimeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.992414</td>\n      <td>0.473848</td>\n      <td>0.082938</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>0.002084</td>\n      <td>1.039718</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>0.002084</td>\n      <td>0.433676</td>\n      <td>0.000111</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.002084</td>\n      <td>0.173824</td>\n      <td>0.000396</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.980393</td>\n      <td>0.251484</td>\n      <td>0.154448</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.995105</td>\n      <td>0.331692</td>\n      <td>0.118839</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.988716</td>\n      <td>0.347858</td>\n      <td>0.112585</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.998930</td>\n      <td>0.581632</td>\n      <td>0.067998</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.002084</td>\n      <td>0.039718</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/min_samples_leaf1.png\" class=\"kg-image\"></figure><p>Looks like the action's between 1 and 51.  More than that, and the score goes while simultaneously increasing the runtime - the opposite of what we want!</p><pre><code class=\"language-python\">min_samples_leaf = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracyCV,        \n                    rfArgs, \n                    &quot;min_samples_leaf&quot;, \n                    0, \n                    1, \n                    14)\nbgs.showTimeScoreChartAndGraph(min_samples_leaf)\n</code></pre>\n<div class=\"tableContainer\">\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>min_samples_leaf</th>\n      <th>score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.981662</td>\n      <td>1.389387</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.506455</td>\n      <td>1.403807</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.975894</td>\n      <td>1.404517</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.982954</td>\n      <td>1.385420</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.979888</td>\n      <td>1.398840</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.984789</td>\n      <td>1.393863</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.986302</td>\n      <td>1.411774</td>\n    </tr>\n  </tbody>\n</table>\n<br>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>min_samples_leaf</th>\n      <th>score</th>\n      <th>time</th>\n      <th>scoreTimeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.992414</td>\n      <td>0.188492</td>\n      <td>0.200671</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.002084</td>\n      <td>0.735618</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.980393</td>\n      <td>0.762561</td>\n      <td>0.048920</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.995105</td>\n      <td>0.037944</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.988716</td>\n      <td>0.547179</td>\n      <td>0.068798</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.998930</td>\n      <td>0.358303</td>\n      <td>0.106209</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.002084</td>\n      <td>1.037944</td>\n      <td>0.036709</td>\n    </tr>\n  </tbody>\n</table>\n</div><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/min_samples_leaf2.png\" class=\"kg-image\"></figure><p>Big drop-off after 26, it seems!</p><pre><code class=\"language-python\">min_samples_leaf = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracyCV,        \n                    rfArgs, \n                    &quot;min_samples_leaf&quot;, \n                    0, \n                    1, \n                    26)\nbgs.showTimeScoreChartAndGraph(min_samples_leaf)\n</code></pre>\n<div class=\"tableContainer\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>min_samples_leaf</th>\n      <th>score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.981662</td>\n      <td>1.407957</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.975894</td>\n      <td>1.398042</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.982954</td>\n      <td>1.396782</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.979888</td>\n      <td>1.396096</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.984789</td>\n      <td>1.402322</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.986302</td>\n      <td>1.401080</td>\n    </tr>\n  </tbody>\n</table>\n<br>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>min_samples_leaf</th>\n      <th>score</th>\n      <th>time</th>\n      <th>scoreTimeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.650270</td>\n      <td>1.084306</td>\n      <td>0.040144</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.096077</td>\n      <td>0.248406</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.774346</td>\n      <td>0.142157</td>\n      <td>0.954016</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.479788</td>\n      <td>0.084306</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.950677</td>\n      <td>0.609184</td>\n      <td>0.221294</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.096077</td>\n      <td>0.504512</td>\n      <td>0.336668</td>\n    </tr>\n  </tbody>\n</table>\n</div><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/min_samples_leaf3.png\" class=\"kg-image\"></figure><p>One more with 14 as our upper limit!</p><pre><code class=\"language-python\">min_samples_leaf = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracyCV,        \n                    rfArgs, \n                    &quot;min_samples_leaf&quot;, \n                    0, \n                    1, \n                    14)\nbgs.showTimeScoreChartAndGraph(min_samples_leaf)\n</code></pre>\n<div class=\"tableContainer\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>min_samples_leaf</th>\n      <th>score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.981662</td>\n      <td>1.401341</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.982954</td>\n      <td>1.400361</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.979888</td>\n      <td>1.402408</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.981121</td>\n      <td>1.401396</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.983580</td>\n      <td>1.401332</td>\n    </tr>\n  </tbody>\n</table>\n<br>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>min_samples_leaf</th>\n      <th>score</th>\n      <th>time</th>\n      <th>scoreTimeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.992414</td>\n      <td>0.188492</td>\n      <td>0.200671</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.002084</td>\n      <td>0.735618</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.980393</td>\n      <td>0.762561</td>\n      <td>0.048920</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.995105</td>\n      <td>0.037944</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.988716</td>\n      <td>0.547179</td>\n      <td>0.068798</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.998930</td>\n      <td>0.358303</td>\n      <td>0.106209</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.002084</td>\n      <td>1.037944</td>\n      <td>0.036709</td>\n    </tr>\n  </tbody>\n</table>\n</div><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/min_samples_leaf4.png\" class=\"kg-image\"><figcaption>3 it is!</figcaption></figure><p>I suppose when it gets this small we could use a regular Grid Search, but...maybe next week!  Or maybe another variable!  Or maybe benchmarks vs <code>GridSearchCV</code> and/or <code>RandomizedSearchCV</code>.  Who knows what the future holds?</p>","url":"https://hackersandslackers.com/random-forests-hyperparameters-min_samples_leaf/","uuid":"766a3eb8-aacc-47c6-91a9-744b84613626","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b9f047cab64c97c60f7be90"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736fe","title":"So You've Fucked up your Python Path","slug":"so-youve-fucked-up-your-python-path","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/pythonpath-3@2x.jpg","excerpt":"A timeless hazing ritual for new Python devs, and how to fix it.","custom_excerpt":"A timeless hazing ritual for new Python devs, and how to fix it.","created_at_pretty":"11 September, 2018","published_at_pretty":"12 September, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-09-11T07:56:57.000-04:00","published_at":"2018-09-12T08:04:00.000-04:00","updated_at":"2019-02-02T04:47:15.000-05:00","meta_title":"How to Recover from a Broken Python Path | Hackers and Slackers","meta_description":"Deleting your native system Python: a coming of age story. Learn how to fix your broken Python path without wiping your machine.","og_description":"Deleting your native system Python: a coming of age story. Learn how to fix your broken Python path without wiping your machine.","og_image":"https://hackersandslackers.com/content/images/2018/09/pythonpath-3@2x.jpg","og_title":"How to Recover from a Broken Python Path | Hackers and Slackers","twitter_description":"Deleting your native system Python: a coming of age story. Learn how to fix your broken Python path without wiping your machine.","twitter_image":"https://hackersandslackers.com/content/images/2018/09/pythonpath-3@2x.jpg","twitter_title":"How to Recover from a Broken Python Path | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"}],"plaintext":"I remember back to when I first learned Python. It was a strange decision for a\nhappily employed post-graduate to make, especially for a time when many were\nscreaming for the death of the language with Guido's (outrageous?) grand reveal\nof Python 3.  The Ruby on Rails guys seemed to be doing just fine. Those were\nthe days.\n\nAfter weeks of sweating over a keyboard in the basement of an illegal BedStuy\nhostel, I had finally set out what I had hoped to achieve. It was the greatest\ncredential any programmer could possibly strive for: yes ladies and gentlemen,\nnone other than yours truly became an officially recognized licensed\nprofessional: I had just completed the last Python course in Codecademy.\n\nCongrats! You know nothing.Armed with this new unfathomable knowledge, I was\nready to take on the world. I did have a few gaps in my knowledge, such as:\n\n * Experience with Linux\n * General idea of what a terminal is and why anybody would use one\n * Basic understanding of the internet\n * Motor skills needed to survive\n\nThat aside, I was determined. Nothing could stop me, which turns out to be a\nreally bad attitude when you're SSHed into a VPS with root access, and zero\nhesitation to wreak havoc upon any and all system files. You see where this is\ngoing.\n\nDear Stack Overflow: I Think I Deleted Python\nDisabling your system's native Python version, whether via deletion or a\nmisconfigured PATH, is a coming-of-age cliché as timeless as losing one's\nvirginity on prom night. Young developers flock to Stack Overflow pleading for\nhelp, while those senior enough to reply sigh a gasp of nostalgia before\nreassuring them that their efforts are pointless. \"Ah yes,\" they reminisce, \"I\nremember my first devastating life-altering failure. To be young again.\"\n\nIf you're lucky enough to be unaware, UNIX based systems depend on their\nnatively installed version of Python to run, well, almost everything. If Python\nis unavailable for just a moment, the developer loses the ability to use:\n\n * vi\n * vim\n * nano\n * grep\n * source\n * wait, SOURCE?\n\nYep, the command you'd normally use to relaunch a corrupted startup file (such\nas the one that holds your PATH  variable) is totally unusable. Not that it\nmatters, what are you going to do, edit it?  Oh right, you just ruined every\nbash text editor. I'd actually be more interested in seeing what DOES work\nwithout Python configuring on Mac/Linux, other than moving up and down your file\nstructure helplessly, trying to quantify the damage you just wrecked upon your\nwork, life, and career.\n\nSo, Should I Kill Myself?\nHow to destroy everything ever.Calm yourself and stick with me here; I have no\ninterest in writing long-winded posts without providing any sort of solution.\nThat said, I have no problem making you sit down and think about what you've\ndone while I bother getting to the point. Nobody else has fixed this for you\nyet, and I need to improve my site's metrics, so it seems like we need each\nother on this one.\n\nBesides, don't be so hard on yourself. Not even a week ago, I sat with a Senior\nDeveloper to review my development stack, and how that would fit into the\ncurrent ecosystem of the department. Naturally I explained that I prefer running\n Flask  on Python 3.7, as I adjusted my motorcycle jacket and sat forward to\ncasually   extinguish a cigarette on his desk. Even through my vision was\nobstructed by the timelessly classic aviators resting on my face, I could see\nthe letters roll across the terminal window before him as he typed. The poor\nbastard running a 4-year old Linux distribution had just checked if Python 3 was\ninstalled on his live production instance, when his fingertips unleashed the\nunmistakable export PATH=..., seconds away from linking CentOS' native Python\nfrom Python 2.7 to Python 3.7. My exact reaction was something along the lines\nof \"OH GOD NO DON'T DO THAT STOP HOLY MOTHER OF JESUS FUCK!\" \n\nHe stopped typing. The day was saved, and I was able to explain the importance\nof leaving native Python versions intact on the systems they come installed on.\nThen, I myself fucked up the Python path maybe an hour later. On production.\n\nWe all do dumb things sometimes. That doesn't mean you're dumb. Well, except in\nmy case, having done this countless times before. Some of us simply like to live\ndangerously. Fortune favors the bold, and so on.\n\nRetro meme outta nowhere!Getting out of this Mess\nNow that we've hit rock bottom, where do we go from here? Well, two things to\nkeep in mind:\n\n 1. Not everything  is broken without Python. Extreme foreshadowing.\n 2. Restarting a terminal will automatically run all startup scripts.\n\nBy now you know that .bash_profile  and .bashrc  are critically important to\nyour system, considering how badly you've fucked things up just now. These files\nset important variables for your system every time you open your terminal; more\nspecifically, .bash_profile  kicks in on any sort of user log in (such as SSH)\nwhere .bashrc  fires every time a new additional terminal window is opened. Even\nif your startup files are corrupted, the system will always love them and turn\nto them regardless of how horribly disfigured you left them. Talk about a spark\nof hope.\n\nOn Mac OSX\nI'll admit I'm a bit embarrassed at how long it took me to realize this: even\nthough you ruined every text editor known to man, there's one resilient enough\nto hold strong. The name? TextEdit.\n\nReveal hidden files in OSX easily.In your root directory, a combo ofShift + Cmd + .  displays all hidden files.\nCheck out bash_profile. Fix it, save it, reopen terminal. Cancel the suicide\nparty. Pop the Champagne.\n\nOn Linux\nNo GUI can save us now, but what can? Perhaps a command so stupid, so simple,\nthat it couldn't possibly need Python to work:\n\necho 'export PATH=\"/YOUR/ORIGINAL/PATH/2.7/bin:${PATH}\"' >> ~/.bash_profile\n\n\nThis appends the text you provide to the end of an existing file. .bash_profile \nand .bashrc  both only pay attention to the last exported PATH in the document,\nwhich means the rest of your file will work, and the only PATH which is\nrespected is the one which you've presumably entered correctly this time around.\nRestart your terminal. Get back in the game son: it ain't about how hard you\nhit, but how hard you can get hit and keep moving forward.\n\nSidenote\nWe're not exactly conducting rocket science here (data science is a close second\nperhaps? Just kidding. We barely know what's going on most of the time). I felt\ncompelled to write this post for two reasons: one being how common and\ndestructive this pitfall can be for most people, but more importantly, the\nknee-jerk reaction veterans have in response to this problem is \"good luck,\nyou're fucked.\" \n\nI'm not here to comment on the integrity of our fine anonymous internet\ncommunities, but the discrepancy between how devastating losing a server can be\ndoesn't seem to met with much urgency by anybody with insight. Nobody taught me\nhow to work around these issues. Had I listened to anonymous internet advice, I\nprobably wouldn't let entire servers of sensitive data for dead, including my\npersonal machines. I worked through it, and quite frankly, I'm kind of a fucking\nidiot [https://hackersandslackers.com/about/], as is our mission statement. If\nan idiot who majored in nonsense and learned a programming language before\nlearning Linux can work through this, I would expect the same of those with much\nmore intelligence than I to, at the very least, attempt the same.","html":"<p>I remember back to when I first learned Python. It was a strange decision for a happily employed post-graduate to make, especially for a time when many were screaming for the death of the language with Guido's (outrageous?) grand reveal of Python 3.  The Ruby on Rails guys seemed to be doing just fine. Those were the days.</p><p>After weeks of sweating over a keyboard in the basement of an illegal BedStuy hostel, I had finally set out what I had hoped to achieve. It was the greatest credential any programmer could possibly strive for: yes ladies and gentlemen, none other than yours truly became an <em>officially recognized licensed professional</em>: I had just completed the last Python course in Codecademy.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/python-codecademy-champion.png\" class=\"kg-image\"><figcaption>Congrats! You know nothing.</figcaption></figure><p>Armed with this new unfathomable knowledge, I was ready to take on the world. I did have a few gaps in my knowledge, such as:</p><ul><li>Experience with Linux</li><li>General idea of what a terminal is and why anybody would use one</li><li>Basic understanding of the internet</li><li>Motor skills needed to survive</li></ul><p>That aside, I was determined. Nothing could stop me, which turns out to be a really bad attitude when you're SSHed into a VPS with root access, and zero hesitation to wreak havoc upon any and all system files. You see where this is going.</p><h2 id=\"dear-stack-overflow-i-think-i-deleted-python\">Dear Stack Overflow: I Think I Deleted Python</h2><style>\n    iframe{\n    height: 423px !important;\n        margin-bottom: 20px;\n    }\n</style>  <script type=\"text/javascript\" src=\"https://ssl.gstatic.com/trends_nrtr/1709_RC01/embed_loader.js\"></script>\n  <script type=\"text/javascript\">\n    trends.embed.renderExploreWidget(\"TIMESERIES\", {\"comparisonItem\":[{\"keyword\":\"python path\",\"geo\":\"US\",\"time\":\"2004-01-01 2019-02-02\"}],\"category\":0,\"property\":\"\"}, {\"exploreQuery\":\"date=all&geo=US&q=python%20path\",\"guestPath\":\"https://trends.google.com:443/trends/embed/\"});\n  </script><p>Disabling your system's native Python version, whether via deletion or a misconfigured <code>PATH</code>, is a coming-of-age cliché as timeless as losing one's virginity on prom night. Young developers flock to Stack Overflow pleading for help, while those senior enough to reply sigh a gasp of nostalgia before reassuring them that their efforts are pointless. \"<em>Ah yes,\" </em>they reminisce, \"<em>I remember my first devastating life-altering failure. To be young again.\"</em></p><p>If you're lucky enough to be unaware, UNIX based systems depend on their natively installed version of Python to run, well, almost everything. If Python is unavailable for just a moment, the developer loses the ability to use:</p><ul><li>vi</li><li>vim</li><li>nano</li><li>grep</li><li>source</li><li>wait, <em>SOURCE?</em></li></ul><p>Yep, the command you'd normally use to relaunch a corrupted startup file (such as the one that holds your <code>PATH</code> variable) is totally unusable. Not that it matters, what are you going to do, <em>edit it?</em> Oh right, you just ruined <em>every bash text editor. </em>I'd actually be more interested in seeing what DOES work without Python configuring on Mac/Linux, other than moving up and down your file structure helplessly, trying to quantify the damage you just wrecked upon your work, life, and career.</p><h3 id=\"so-should-i-kill-myself\">So, Should I Kill Myself?</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/nRrH6Gn.gif\" class=\"kg-image\"><figcaption>How to destroy everything ever.</figcaption></figure><p>Calm yourself and stick with me here; I have no interest in writing long-winded posts without providing any sort of solution. That said, I have no problem making you sit down and think about what you've done while I bother getting to the point. Nobody else has fixed this for you yet, and I need to improve my site's metrics, so it seems like we need each other on this one.</p><p>Besides, don't be so hard on yourself. Not even a week ago, I sat with a Senior Developer to review my development stack, and how that would fit into the current ecosystem of the department. Naturally I explained that I prefer running <strong>Flask</strong> on <strong>Python 3.7</strong>, as I adjusted my motorcycle jacket and sat forward to casually   extinguish a cigarette on his desk. Even through my vision was obstructed by the timelessly classic aviators resting on my face, I could see the letters roll across the terminal window before him as he typed. The poor bastard running a 4-year old Linux distribution had just checked if Python 3 was installed <strong>on his live production instance</strong>, when his fingertips unleashed the unmistakable <code>export PATH=...</code>, seconds away from linking CentOS' native Python from Python 2.7 to Python 3.7. My exact reaction was something along the lines of \"OH GOD NO DON'T DO THAT STOP HOLY MOTHER OF JESUS FUCK!\" </p><p>He stopped typing. The day was saved, and I was able to explain the importance of leaving native Python versions intact on the systems they come installed on. Then, I myself fucked up the Python path maybe an hour later. On production.  </p><p>We all do dumb things sometimes. That doesn't mean you're dumb. Well, except in my case, having done this countless times before. Some of us simply like to live dangerously. Fortune favors the bold, and so on.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/arNjoZz.gif\" class=\"kg-image\"><figcaption>Retro meme outta nowhere!</figcaption></figure><h2 id=\"getting-out-of-this-mess\">Getting out of this Mess</h2><p>Now that we've hit rock bottom, where do we go from here? Well, two things to keep in mind:</p><ol><li>Not <em>everything</em> is broken without Python. Extreme foreshadowing.</li><li>Restarting a terminal will automatically run all startup scripts.</li></ol><p>By now you know that <code>.bash_profile</code> and <code>.bashrc</code> are critically important to your system, considering how badly you've fucked things up just now. These files set important variables for your system every time you open your terminal; more specifically, <code>.bash_profile</code> kicks in on any sort of user log in (such as SSH) where <code>.bashrc</code> fires every time a new additional terminal window is opened. Even if your startup files are corrupted, the system will always love them and turn to them regardless of how horribly disfigured you left them. Talk about a spark of hope.</p><h3 id=\"on-mac-osx\">On Mac OSX</h3><p>I'll admit I'm a bit embarrassed at how long it took me to realize this: even though you ruined every text editor known to man, there's one resilient enough to hold strong. The name? <strong>TextEdit.</strong></p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ngA6gj0.gif\" class=\"kg-image\"><figcaption>Reveal hidden files in OSX easily.</figcaption></figure><p>In your root directory, a combo of  <code>Shift + Cmd + .</code> displays all hidden files. Check out bash_profile. Fix it, save it, reopen terminal. Cancel the suicide party. Pop the Champagne.</p><h3 id=\"on-linux\">On Linux</h3><p>No GUI can save us now, but what can? Perhaps a command so stupid, so simple, that it couldn't possibly need Python to work:</p><pre><code class=\"language-bash\">echo 'export PATH=&quot;/YOUR/ORIGINAL/PATH/2.7/bin:${PATH}&quot;' &gt;&gt; ~/.bash_profile\n</code></pre>\n<p>This <em>appends </em>the text you provide to the end of an existing file. <code>.bash_profile</code> and <code>.bashrc</code> both only pay attention to the last exported PATH in the document, which means the rest of your file will work, and the only PATH which is respected is the one which you've <em>presumably entered correctly this time around</em>. Restart your terminal. Get back in the game son: it ain't about how hard you hit, but how hard you can get hit and keep moving forward.</p><h2 id=\"sidenote\">Sidenote</h2><p>We're not exactly conducting rocket science here (data science is a close second perhaps? Just kidding. We barely know what's going on most of the time). I felt compelled to write this post for two reasons: one being how common and destructive this pitfall can be for most people, but more importantly, the knee-jerk reaction veterans have in response to this problem is \"good luck, you're fucked.\" </p><p>I'm not here to comment on the integrity of our fine anonymous internet communities, but the discrepancy between how devastating losing a server can be doesn't seem to met with much urgency by anybody with insight. Nobody taught me how to work around these issues. Had I listened to anonymous internet advice, I probably wouldn't let entire servers of sensitive data for dead, including my personal machines. I worked through it, and quite frankly, I'm <a href=\"https://hackersandslackers.com/about/\">kind of a <em>fucking idiot</em></a><em>, </em>as is our mission statement. If an idiot who majored in nonsense and learned a programming language before learning Linux can work through this, I would expect the same of those with much more intelligence than I to, at the very least, attempt the same.</p>","url":"https://hackersandslackers.com/so-youve-fucked-up-your-python-path/","uuid":"5de62a8f-94c9-4e70-8034-d46fb9369a73","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b97ad891fc1fc7d92b5c537"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736fd","title":"Tuning Random  Forests Hyperparameters with Binary Search Part II: max_depth","slug":"tuning-random-forests-hyperparameters-with-binary-search","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/codecorner@2x.jpg","excerpt":"Code snippet corner is back! Tune the max_depth parameter in for a Random Forests classifier in scikit-learn in Python","custom_excerpt":"Code snippet corner is back! Tune the max_depth parameter in for a Random Forests classifier in scikit-learn in Python","created_at_pretty":"09 September, 2018","published_at_pretty":"10 September, 2018","updated_at_pretty":"19 February, 2019","created_at":"2018-09-09T19:14:32.000-04:00","published_at":"2018-09-10T07:30:00.000-04:00","updated_at":"2019-02-19T03:46:39.000-05:00","meta_title":"Code snippet corner is back! Tune the max_depth parameter in for a Random Forests classifier in scikit-learn in Python | Hackers And Slackers","meta_description":"While n_estimators has a tradeoff between speed & score, max_depth can improve both.  By limiting the depth of your trees, you can reduce overfitting.","og_description":"While n_estimators has a tradeoff between speed & score, max_depth can improve both.  By limiting the depth of your trees, you can reduce overfitting.","og_image":"https://hackersandslackers.com/content/images/2018/09/codecorner@2x.jpg","og_title":"Tuning Random  Forests Hyperparameters with Binary Search Part II: max_depth","twitter_description":"While n_estimators has a tradeoff between speed & score, max_depth can improve both.  By limiting the depth of your trees, you can reduce overfitting.","twitter_image":"https://hackersandslackers.com/content/images/2018/09/codecorner@2x.jpg","twitter_title":"Tuning Random  Forests Hyperparameters with Binary Search Part II: max_depth","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},"tags":[{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},{"name":"Machine Learning","slug":"machine-learning","description":"The latest developments in machine learning tools and technology available to data scientists.","feature_image":null,"meta_description":"The latest developments in machine learning tools and technology available to data scientists.","meta_title":"Machine Learning | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},{"name":"#Code Snippet Corner","slug":"code-snippet-corner","description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o_o.jpg","meta_description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","meta_title":"Python Code Snippet Corner","visibility":"internal"}],"plaintext":"Continued from here\n[https://hackersandslackers.com/code-snippet-corner-tuning-machine-learning-hyperparameters-with-binary-search/]\n\nNotebook for this post is here\n[https://github.com/mattalhonte/binary-grid-search/blob/master/Introspect%20Trees%20(Depth).ipynb]\n\nBinary search code itself is here\n[https://github.com/mattalhonte/binary-grid-search/blob/master/binarygridsearch/binarygridsearch.py]\n\nmax_depth  is an interesting parameter.  While n_estimators  has a tradeoff\nbetween speed & score, max_depth  has the possibility of improving both.  By\nlimiting the depth of your trees, you can reduce overfitting.\n\nUnfortunately, deciding on upper & lower bounds is less than straightforward.\n It'll depend on your dataset.  Luckily, I found a post on StackOverflow that\nhad a link to a blog post that had a promising methodology\n[https://aysent.github.io/2015/11/08/random-forest-leaf-visualization.html].\n\nFirst, we build a tree with default arguments and fit it to our data. \n\nimport pandas as pd\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_breast_cancer\n\n\ndata = load_breast_cancer()\nX, y = data.data, data.target\n\nrfArgs = {\"random_state\": 0,\n          \"n_jobs\": -1,\n          \"class_weight\": \"balanced\",\n         \"n_estimators\": 18,\n         \"oob_score\": True}\n\nclf = RandomForestClassifier(**rfArgs)\nclf.fit(X, y)\n\nNow, let's see how deep the trees get when we don't impose any sort of max_depth\n. We'll use the code from that wonderful blog post to crawl our Random Forest,\nand get the height of every tree.\n\n#From here: https://aysent.github.io/2015/11/08/random-forest-leaf-visualization.html\ndef leaf_depths(tree, node_id = 0):\n    \n    '''\n    tree.children_left and tree.children_right store ids\n    of left and right chidren of a given node\n    '''\n    left_child = tree.children_left[node_id]\n    right_child = tree.children_right[node_id]\n\n    '''\n    If a given node is terminal, \n    both left and right children are set to _tree.TREE_LEAF\n    '''\n    if left_child == _tree.TREE_LEAF:\n        \n        '''\n        Set depth of terminal nodes to 0\n        '''\n        depths = np.array([0])\n    else:\n        '''\n        Get depths of left and right children and\n        increment them by 1\n        '''\n        left_depths = leaf_depths(tree, left_child) + 1\n        right_depths = leaf_depths(tree, right_child) + 1\n \n        depths = np.append(left_depths, right_depths)\n \n    return depths\n\nallDepths = [leaf_depths(estimator.tree_) \n             for estimator in clf.estimators_]\n\nnp.hstack(allDepths).min()\n#> 2\nnp.hstack(allDepths).max()\n#> 9\n\nWe'll be searching between 2 and 9!\n\nLet's bring back our old make a helper function to easily return scores.\n\ndef getForestAccuracy(X, y, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    clf.fit(X, y)\n    y_pred = clf.oob_decision_function_[:, 1]\n    precision, recall, _ = precision_recall_curve(y, y_pred)\n    return auc(recall, precision)\n\nmax_depth = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    \"max_depth\", \n                    0, \n                    2, \n                    9)\nbgs.showTimeScoreChartAndGraph(max_depth, html=True)\n\nmax_depth\n score\n time\n 2\n 0.987707\n 0.145360\n 9\n 0.987029\n 0.147563\n 6\n 0.986247\n 0.140514\n 4\n 0.968316\n 0.140164\n \nmax_depth\n score\n time\n scoreTimeRatio\n 2\n 1.051571\n 0.837377\n 0.175986\n 9\n 1.016649\n 1.135158\n 0.103478\n 6\n 0.976311\n 0.182516\n 1.000000\n 4\n 0.051571\n 0.135158\n 0.000000\n So, for our purposes, 9 will function as our baseline since that was the\nbiggest depth that it built with default arguments.\n\nLooks like a max_depth  of 2 has a slightly higher score than 9, and is slightly\nfaster!  Interestingly, it's slightly slower than  4 or 6.  Not sure why that\nis.","html":"<p>Continued from <a href=\"https://hackersandslackers.com/code-snippet-corner-tuning-machine-learning-hyperparameters-with-binary-search/\">here</a></p><p>Notebook for this post is <a href=\"https://github.com/mattalhonte/binary-grid-search/blob/master/Introspect%20Trees%20(Depth).ipynb\">here</a></p><p>Binary search code itself is <a href=\"https://github.com/mattalhonte/binary-grid-search/blob/master/binarygridsearch/binarygridsearch.py\">here</a></p><p><code>max_depth</code> is an interesting parameter.  While <code>n_estimators</code> has a tradeoff between speed &amp; score, <code>max_depth</code> has the possibility of improving both.  By limiting the depth of your trees, you can reduce overfitting.</p><p>Unfortunately, deciding on upper &amp; lower bounds is less than straightforward.  It'll depend on your dataset.  Luckily, I found a post on StackOverflow that had a link to a blog post that had a promising <a href=\"https://aysent.github.io/2015/11/08/random-forest-leaf-visualization.html\">methodology</a>.  </p><p>First, we build a tree with default arguments and fit it to our data. </p><pre><code>import pandas as pd\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_breast_cancer\n\n\ndata = load_breast_cancer()\nX, y = data.data, data.target\n\nrfArgs = {\"random_state\": 0,\n          \"n_jobs\": -1,\n          \"class_weight\": \"balanced\",\n         \"n_estimators\": 18,\n         \"oob_score\": True}\n\nclf = RandomForestClassifier(**rfArgs)\nclf.fit(X, y)</code></pre><p>Now, let's see how deep the trees get when we don't impose any sort of <code>max_depth</code>. We'll use the code from that wonderful blog post to crawl our Random Forest, and get the height of every tree.</p><pre><code>#From here: https://aysent.github.io/2015/11/08/random-forest-leaf-visualization.html\ndef leaf_depths(tree, node_id = 0):\n    \n    '''\n    tree.children_left and tree.children_right store ids\n    of left and right chidren of a given node\n    '''\n    left_child = tree.children_left[node_id]\n    right_child = tree.children_right[node_id]\n\n    '''\n    If a given node is terminal, \n    both left and right children are set to _tree.TREE_LEAF\n    '''\n    if left_child == _tree.TREE_LEAF:\n        \n        '''\n        Set depth of terminal nodes to 0\n        '''\n        depths = np.array([0])\n    else:\n        '''\n        Get depths of left and right children and\n        increment them by 1\n        '''\n        left_depths = leaf_depths(tree, left_child) + 1\n        right_depths = leaf_depths(tree, right_child) + 1\n \n        depths = np.append(left_depths, right_depths)\n \n    return depths\n\nallDepths = [leaf_depths(estimator.tree_) \n             for estimator in clf.estimators_]\n\nnp.hstack(allDepths).min()\n#&gt; 2\nnp.hstack(allDepths).max()\n#&gt; 9</code></pre><p>We'll be searching between 2 and 9!  </p><p>Let's bring back our old make a helper function to easily return scores.</p><pre><code>def getForestAccuracy(X, y, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    clf.fit(X, y)\n    y_pred = clf.oob_decision_function_[:, 1]\n    precision, recall, _ = precision_recall_curve(y, y_pred)\n    return auc(recall, precision)</code></pre><pre><code>max_depth = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    \"max_depth\", \n                    0, \n                    2, \n                    9)\nbgs.showTimeScoreChartAndGraph(max_depth, html=True)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/09/max_depth.png\" class=\"kg-image\"></figure><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>max_depth</th>\n      <th>score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2</td>\n      <td>0.987707</td>\n      <td>0.145360</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.987029</td>\n      <td>0.147563</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.986247</td>\n      <td>0.140514</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.968316</td>\n      <td>0.140164</td>\n    </tr>\n  </tbody>\n</table>\n<br>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>max_depth</th>\n      <th>score</th>\n      <th>time</th>\n      <th>scoreTimeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2</td>\n      <td>1.051571</td>\n      <td>0.837377</td>\n      <td>0.175986</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.016649</td>\n      <td>1.135158</td>\n      <td>0.103478</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.976311</td>\n      <td>0.182516</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.051571</td>\n      <td>0.135158</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>So, for our purposes, 9 will function as our baseline since that was the biggest depth that it built with default arguments.  </p><p>Looks like a <code>max_depth</code> of 2 has a slightly higher score than 9, and is slightly faster!  Interestingly, it's slightly slower than  4 or 6.  Not sure why that is.</p>","url":"https://hackersandslackers.com/tuning-random-forests-hyperparameters-with-binary-search/","uuid":"3c92aed0-61ed-4c1a-b7d5-cc47c709764b","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b95a9581fc1fc7d92b5c51f"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ec","title":"Tuning Machine Learning Hyperparameters with Binary Search","slug":"tuning-machine-learning-hyperparameters-with-binary-search","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/ai2@2x.jpg","excerpt":"Tune the n_estimators parameter in for a Random Forests classifier in scikit-learn in Python.","custom_excerpt":"Tune the n_estimators parameter in for a Random Forests classifier in scikit-learn in Python.","created_at_pretty":"30 August, 2018","published_at_pretty":"03 September, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-08-29T21:35:41.000-04:00","published_at":"2018-09-03T07:30:00.000-04:00","updated_at":"2019-02-13T22:50:35.000-05:00","meta_title":"Tune the n_estimators parameter in for a Random Forests classifier in scikit-learn in Python | Hackers And Slackers","meta_description":"RandomizedSearchCV goes noticeably faster than a full GridSearchCV but it still takes a while - which can be rough.","og_description":"Code Snippet Corner: Tuning Machine Learning Hyperparameters with Binary Search","og_image":"https://hackersandslackers.com/content/images/2018/08/ai2@2x.jpg","og_title":"Code Snippet Corner: Tuning Machine Learning Hyperparameters with Binary Search","twitter_description":"Tune the n_estimators parameter in for a Random Forests classifier in scikit-learn in Python","twitter_image":"https://hackersandslackers.com/content/images/2018/08/ai2@2x.jpg","twitter_title":"Code Snippet Corner: Tuning Machine Learning Hyperparameters with Binary Search","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},"tags":[{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},{"name":"Machine Learning","slug":"machine-learning","description":"The latest developments in machine learning tools and technology available to data scientists.","feature_image":null,"meta_description":"The latest developments in machine learning tools and technology available to data scientists.","meta_title":"Machine Learning | Hackers and Slackers","visibility":"public"},{"name":"#Code Snippet Corner","slug":"code-snippet-corner","description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o_o.jpg","meta_description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","meta_title":"Python Code Snippet Corner","visibility":"internal"}],"plaintext":"Ah, hyperparameter tuning.  Time & compute-intensive.  Frequently containing\nweird non-linearities in how changing a parameter changes the score and/or the\ntime it takes to train the model.\n\nRandomizedSearchCV  goes noticeably faster than a full GridSearchCV  but it\nstill takes a while - which can be rough, because in my experience you do still\nneed to be iterative with it and experiment with different distributions.  Plus,\nthen you've got hyper-hyperparameters to tune - how many iterations SHOULD you\nrun it for, anyway?\n\nI've been experimenting with using the trusty old Binary Search to tune\nhyperparameters.  I'm finding it has two advantages.\n\n 1. It's blazing fast\n 2. The performance is competitive with a Randomized Search\n 3. It gives you a rough sketch of \"the lay of the land\".  An initial binary\n    search can then provide parameters for future searches, including with Grid\n    or Randomized Searches.\n\nCode is here\n[https://github.com/mattalhonte/binary-grid-search/blob/master/binarygridsearch/binarygridsearch.py]\n\nNotebook summary is here\n[https://github.com/mattalhonte/binary-grid-search/blob/master/Binary%20Search%20Interactive%20(n_estimators).ipynb]\n\nLet's see it in action!\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nWe'll be using a Random Forest classifier, because, as with all my code posts,\nit's what I've been using recently.\n\nfrom sklearn.datasets import load_breast_cancer\ndata = load_breast_cancer()\nX, y = data.data, data.target\n\n\nWe'll be using scikit-learn's breast cancer dataset, because I remembered that\nthese packages I'm posting about have built-in demo datasets that I should be\nusing for posts.\n\nrfArgs = {\"random_state\": 0,\n          \"n_jobs\": -1,\n          \"class_weight\": \"balanced\",\n         \"oob_score\": True}\n\n\nLet's set our random_state  for better reproducibility.\nWe'll set n_jobs=-1  because obviously we want to use all our cores, we are not\npatient people.\n\n\nWe'll have class_weight=\"balanced\"  because that'll compensate for the fact that\nthe breast cancer dataset (like most medical datasets) has unbalanced classes.\nWe'll use oob_score  because we like being lazy, part of the appeal of Random\nForests is the opportunity to be extra lazy (no need to normalize features!),\nand oob  lets us be even lazier  by giving some built-in cross-validation.\n\nNow let's define a function that'll take all this, and spit out a score.  I\nwrote the binary search function to take a function like this as an argument -\nscikit-learn is usually pretty consistent when it comes to the interface it\nprovides you, but sometimes different algorithms need to work a little\ndifferently.  For instance, since we'll be using Area Under \nprecision_recall_curve  as our metric (a good choice for classifiers with\nunbalanced classes!), it takes a teensy bit of extra fiddling to get it to play\nnicely with our oob_decision_function_.\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\n\ndef getForestAccuracy(X, y, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    clf.fit(X, y)\n    y_pred = clf.oob_decision_function_[:, 1]\n    precision, recall, _ = precision_recall_curve(y, y_pred)\n    return auc(recall, precision)\n\n\nWe'll try to optimize the n_estimators  parameter first.  For two reasons:\n\n 1. Finding a good mix between speed and accuracy here will make it easier to\n    tune subsequent parameters.\n 2. It's the most straightforward to decide upper and lower bounds for.  Other\n    ones (like, say, max_depth) require a little work to figure the potential\n    range to search in.\n\nOkay!  So, let's put our lower limit as 32 and our upper limit as 128, because I\nread in a StackOverflow post that there's a paper that says to search within\nthat range.\n\nn_estimators = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    \"n_estimators\", \n                    0, \n                    18, \n                    128)\n\nbgs.showTimeScoreChartAndGraph(n_estimators)\n\n\nPlotting score, time, and the ratio between them - we're not just optimizing for\nthe best score right now, we're looking for tipping points that give us good\ntradeoffs.  Scores and times are normalized for a more-meaningful ratio between\nthem.\n\nn_estimators\n score\n time\n scoreTimeRatio\n 0\n 32\n 1.073532\n 0.002459\n 1.000000\n 1\n 128\n 1.867858\n 1.002459\n 0.000000\n 2\n 80\n 2.052255\n 0.440060\n 0.006443\n 3\n 56\n 1.605447\n 0.075185\n 0.044843\n 4\n 68\n 1.910411\n 0.107187\n 0.036721\n 5\n 74\n 2.066440\n 0.377136\n 0.008320\n 6\n 77\n 2.066440\n 0.388378\n 0.007955\n 7\n 75\n 2.073532\n 0.457481\n 0.006141\n n_estimators\n score\n time\n 0\n 32\n 0.988663\n 0.180521\n 1\n 128\n 0.989403\n 0.587113\n 2\n 80\n 0.989575\n 0.358446\n 3\n 56\n 0.989159\n 0.210091\n 4\n 68\n 0.989443\n 0.223102\n 5\n 74\n 0.989588\n 0.332861\n 6\n 77\n 0.989588\n 0.337432\n 7\n 75\n 0.989595\n 0.365529\n Hrm, looks like the score starts getting somewhere interesting around 68, and\ntime starts shooting up at about 80.  Let's do another with those as our bounds!\n\nn_estimators = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    \"n_estimators\", \n                    0, \n                    68, \n                    80)\n\nbgs.showTimeScoreChartAndGraph(n_estimators)\n\n\nn_estimators\n score\n time\n scoreTimeRatio\n 0\n 68\n 6.390333\n 0.333407\n 0.135692\n 1\n 80\n 7.223667\n 1.064343\n 0.000000\n 2\n 74\n 7.307000\n 0.404471\n 0.123622\n 3\n 71\n 6.307000\n 0.064343\n 1.000000\n 4\n 72\n 6.390333\n 0.175190\n 0.325419\n n_estimators\n score\n time\n 0\n 68\n 0.989443\n 0.344220\n 1\n 80\n 0.989575\n 0.355580\n 2\n 74\n 0.989588\n 0.345324\n 3\n 71\n 0.989430\n 0.340038\n 4\n 72\n 0.989443\n 0.341761\n 71 looks like our winner!  Or close enough for our purposes while we then go\noptimize other things.  And we only had to train our model 13 times - as opposed\nto the 96 we would have with a brute-force grid search.\n\nHopefully this will become a series on using this to tune other RF\nhyperparameters - other ones have some interesting quirks that I'd like to\nexpound upon.  Or you could just look at the GitHub repo for spoilers.  Or both!","html":"<p>Ah, hyperparameter tuning.  Time &amp; compute-intensive.  Frequently containing weird non-linearities in how changing a parameter changes the score and/or the time it takes to train the model.</p><p><code>RandomizedSearchCV</code> goes noticeably faster than a full <code>GridSearchCV</code> but it still takes a while - which can be rough, because in my experience you do still need to be iterative with it and experiment with different distributions.  Plus, then you've got hyper-hyperparameters to tune - how many iterations SHOULD you run it for, anyway?</p><p>I've been experimenting with using the trusty old Binary Search to tune hyperparameters.  I'm finding it has two advantages.</p><ol><li>It's blazing fast</li><li>The performance is competitive with a Randomized Search</li><li>It gives you a rough sketch of \"the lay of the land\".  An initial binary search can then provide parameters for future searches, including with Grid or Randomized Searches.</li></ol><p>Code is <a href=\"https://github.com/mattalhonte/binary-grid-search/blob/master/binarygridsearch/binarygridsearch.py\">here</a></p><p>Notebook summary is <a href=\"https://github.com/mattalhonte/binary-grid-search/blob/master/Binary%20Search%20Interactive%20(n_estimators).ipynb\">here</a></p><p>Let's see it in action!</p><pre><code class=\"language-python\">from sklearn.ensemble import RandomForestClassifier\n</code></pre>\n<p>We'll be using a Random Forest classifier, because, as with all my code posts, it's what I've been using recently.</p><pre><code class=\"language-python\">from sklearn.datasets import load_breast_cancer\ndata = load_breast_cancer()\nX, y = data.data, data.target\n</code></pre>\n<p>We'll be using scikit-learn's breast cancer dataset, because I remembered that these packages I'm posting about have built-in demo datasets that I should be using for posts.</p><pre><code class=\"language-python\">rfArgs = {&quot;random_state&quot;: 0,\n          &quot;n_jobs&quot;: -1,\n          &quot;class_weight&quot;: &quot;balanced&quot;,\n         &quot;oob_score&quot;: True}\n</code></pre>\n<p>Let's set our <code>random_state</code> for better reproducibility.<br>We'll set <code>n_jobs=-1</code> because obviously we want to use all our cores, we are not patient people.</p><p><br>We'll have <code>class_weight=\"balanced\"</code> because that'll compensate for the fact that the breast cancer dataset (like most medical datasets) has unbalanced classes.<br>We'll use <code>oob_score</code> because we like being lazy, part of the appeal of Random Forests is the opportunity to be extra lazy (no need to normalize features!), and <code>oob</code> lets us be <em>even lazier</em> by giving some built-in cross-validation.</p><p>Now let's define a function that'll take all this, and spit out a score.  I wrote the binary search function to take a function like this as an argument - scikit-learn is usually pretty consistent when it comes to the interface it provides you, but sometimes different algorithms need to work a little differently.  For instance, since we'll be using Area Under <code>precision_recall_curve</code> as our metric (a good choice for classifiers with unbalanced classes!), it takes a teensy bit of extra fiddling to get it to play nicely with our <code>oob_decision_function_</code>.</p><pre><code class=\"language-python\">from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\n\ndef getForestAccuracy(X, y, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    clf.fit(X, y)\n    y_pred = clf.oob_decision_function_[:, 1]\n    precision, recall, _ = precision_recall_curve(y, y_pred)\n    return auc(recall, precision)\n</code></pre>\n<p>We'll try to optimize the <code>n_estimators</code> parameter first.  For two reasons:</p><ol><li>Finding a good mix between speed and accuracy here will make it easier to tune subsequent parameters.</li><li>It's the most straightforward to decide upper and lower bounds for.  Other ones (like, say, <code>max_depth</code>) require a little work to figure the potential range to search in.</li></ol><p>Okay!  So, let's put our lower limit as 32 and our upper limit as 128, because I read in a StackOverflow post that there's a paper that says to search within that range.</p><pre><code class=\"language-python\">n_estimators = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    &quot;n_estimators&quot;, \n                    0, \n                    18, \n                    128)\n\nbgs.showTimeScoreChartAndGraph(n_estimators)\n</code></pre>\n<p>Plotting score, time, and the ratio between them - we're not just optimizing for the best score right now, we're looking for tipping points that give us good tradeoffs.  Scores and times are normalized for a more-meaningful ratio between them.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/visualization--2-.png\" class=\"kg-image\"></figure><div class=\"tableContainer\">\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_estimators</th>\n      <th>score</th>\n      <th>time</th>\n      <th>scoreTimeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32</td>\n      <td>1.073532</td>\n      <td>0.002459</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>128</td>\n      <td>1.867858</td>\n      <td>1.002459</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80</td>\n      <td>2.052255</td>\n      <td>0.440060</td>\n      <td>0.006443</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1.605447</td>\n      <td>0.075185</td>\n      <td>0.044843</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>68</td>\n      <td>1.910411</td>\n      <td>0.107187</td>\n      <td>0.036721</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>74</td>\n      <td>2.066440</td>\n      <td>0.377136</td>\n      <td>0.008320</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>77</td>\n      <td>2.066440</td>\n      <td>0.388378</td>\n      <td>0.007955</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>75</td>\n      <td>2.073532</td>\n      <td>0.457481</td>\n      <td>0.006141</td>\n    </tr>\n  </tbody>\n</table>\n</div><div class=\"tableContainer\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_estimators</th>\n      <th>score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32</td>\n      <td>0.988663</td>\n      <td>0.180521</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>128</td>\n      <td>0.989403</td>\n      <td>0.587113</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80</td>\n      <td>0.989575</td>\n      <td>0.358446</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>0.989159</td>\n      <td>0.210091</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>68</td>\n      <td>0.989443</td>\n      <td>0.223102</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>74</td>\n      <td>0.989588</td>\n      <td>0.332861</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>77</td>\n      <td>0.989588</td>\n      <td>0.337432</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>75</td>\n      <td>0.989595</td>\n      <td>0.365529</td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Hrm, looks like the score starts getting somewhere interesting around 68, and time starts shooting up at about 80.  Let's do another with those as our bounds!</p><pre><code class=\"language-python\">n_estimators = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    &quot;n_estimators&quot;, \n                    0, \n                    68, \n                    80)\n\nbgs.showTimeScoreChartAndGraph(n_estimators)\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/max_depth.png\" class=\"kg-image\"></figure><div class=\"tableContainer\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_estimators</th>\n      <th>score</th>\n      <th>time</th>\n      <th>scoreTimeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>68</td>\n      <td>6.390333</td>\n      <td>0.333407</td>\n      <td>0.135692</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80</td>\n      <td>7.223667</td>\n      <td>1.064343</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>74</td>\n      <td>7.307000</td>\n      <td>0.404471</td>\n      <td>0.123622</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>71</td>\n      <td>6.307000</td>\n      <td>0.064343</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>72</td>\n      <td>6.390333</td>\n      <td>0.175190</td>\n      <td>0.325419</td>\n    </tr>\n  </tbody>\n</table>\n</div><div class=\"tableContainer\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_estimators</th>\n      <th>score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>68</td>\n      <td>0.989443</td>\n      <td>0.344220</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80</td>\n      <td>0.989575</td>\n      <td>0.355580</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>74</td>\n      <td>0.989588</td>\n      <td>0.345324</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>71</td>\n      <td>0.989430</td>\n      <td>0.340038</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>72</td>\n      <td>0.989443</td>\n      <td>0.341761</td>\n    </tr>\n  </tbody>\n</table>\n</div><p>71 looks like our winner!  Or close enough for our purposes while we then go optimize other things.  And we only had to train our model 13 times - as opposed to the 96 we would have with a brute-force grid search.</p><p>Hopefully this will become a series on using this to tune other RF hyperparameters - other ones have some interesting quirks that I'd like to expound upon.  Or you could just look at the GitHub repo for spoilers.  Or both!</p>","url":"https://hackersandslackers.com/tuning-machine-learning-hyperparameters-with-binary-search/","uuid":"ca7241c3-52cd-4910-86dc-0bb5474d07af","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b8749ed4b98380b152292ea"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736d2","title":"Recreate JIRA Service Desk in Python & Flask","slug":"building-a-better-jira","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/jsd@2x.jpg","excerpt":"When SaaS doesn't cut it, beat it down and take everything its got.","custom_excerpt":"When SaaS doesn't cut it, beat it down and take everything its got.","created_at_pretty":"11 August, 2018","published_at_pretty":"31 August, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-08-11T14:02:52.000-04:00","published_at":"2018-08-31T10:25:00.000-04:00","updated_at":"2019-02-02T05:11:05.000-05:00","meta_title":"When SaaS doesn't cut it, beat it down and take everything its got | Hackers And Slackers","meta_description":"Vanilla helpdesks tend to dehumanize customers. We all think we're special, but a cold support queue reminds us otherwise. We can build something  better.","og_description":"Vanilla helpdesks tend to dehumanize customers. We all think we're special, but a cold support queue reminds us otherwise. We can build something  better.","og_image":"https://hackersandslackers.com/content/images/2018/08/jsd@2x.jpg","og_title":"Recreate JIRA Service Desk in Python & Flask","twitter_description":"Vanilla helpdesks tend to dehumanize customers. We all think we're special, but a cold support queue reminds us otherwise. We can build something  better.","twitter_image":"https://hackersandslackers.com/content/images/2018/08/jsd@2x.jpg","twitter_title":"Recreate JIRA Service Desk in Python & Flask","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"}],"plaintext":"When it comes to SaaS products in the realm of Service desks, JIRA Service Desk\nis at the very least, just as powerful as the next solution (Zendesk comes to\nmind). This naturally begs the question: Why is JIRA Service Desk's pricing\nmodel roughly 1/10th of that of it's competitor?\n\nThe answer lies within ease of use,  but more importantly, presentation. While\nAtlassian's cloud offering is slowly playing catchup, Atlassian as a company has\nnever quite seemed to nail down the importance of a friendly user interface, nor\nthe importance of this when it comes to worldwide adoption. To see what I mean,\nhere's an example that Atlassian themselves tout on their own documentation as a\n\"ready for production\" customer portal:\n\nI'm convinced this is purposefully hideous to force the purchase of plugins.To\nyour average software developer (Atlassian's core demographic for years), one\nmight see nothing wrong with this interface, but as somebody `who has rolled out\nover 30 of these desks for over 6 thousand people, layouts such as these commit\nnumerous UI atrocities which simply are not acceptable for top enterprise\nsoftware.\n\nWhat do we do about this? We build an alternative, of course.\n\nMethod to This Madness\nOur focus is not on JIRA as a product,  but rather an API. Instead of attempting\nto work within JIRA’s boundaries via customization or add-ons, we can take\nmatters into our own hands by owning the application that users use to interact\nwith a JIRA instance. By using the JIRA API, we can not only extend features but\nactually ‘rebuild’ the application to gain full control over the UI or\nadditional logic. JIRA is a hideous yet entirely necessary Java application,\nwhich makes it a perfect candidate for recreation.\n\nWe're going to use Flask for this. Shocking, I know. Here's the obligatory file\nstructure of our project:\n\nmyproject\n├─ app.py\n├─ jira.py\n├─ /static\n│  └─ js\n│  └─ less\n│  └─ img\n└─ /templates\n   └─ layout.html\n   └─ index.html\n\n\nThis tutorial will be working against the JIRA Server  API for Service Desk -\nthat said, Cloud users should still find this applicable.\n\nPulling Your Service Desk Form\nBefore we get nuts building our application, we’ll need to be sure that a\nService Desk already exists in JIRA with our expected intake form. Remember: our\nend goal is to simply consume JIRA as an API, but that entails interacting with\nsomething that exists in the first place.\n\nWith your Service Desk created, there’s one annoyance we need to resolve before\ngetting into code: determining your Service Desk’s ID number. Like most things\nin JIRA, Service Desks are identified by an ID which is simply an arbitrary\ngrouping of integers in some way. What is the official way to find this ID, you\nmight ask? Why, by extracting it from the portal’s URL or by inspecting your XHR\nrequests, of course! Remember: JIRA hates you, that’s why we’re doing this in\nthe first place.\n\nWith your Service Desk ID handy, we can finally break into retrieving our desk\nvia the Service Desk API:\n\nimport requests\nfrom jira_config import jira_username, jira_password\n\nrequest_types_endpoint = \"https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/\"\n\nheaders = {'Content-Type': 'application/json'}\n\ndef fieldsPerRequest(id):\n    \"\"\"Get form fields per request type.\"\"\"\n    r = requests.get(request_types_endpoint + id + '/field', auth=(jira_username, jira_password), headers=headers)\n    form = r.json()\n    return form\n\n\ndef serviceDeskRequestTypes():\n    \"\"\"Get request types.\"\"\"\n    request_array = []\n    r = requests.get(request_types_endpoint, auth=(jira_username, jira_password), headers=headers)\n    for requesttype in r.json()['values']:\n        id = requesttype['id']\n        request_dict = {\n            'name': requesttype['name'],\n            'description': requesttype['description'],\n            'icon': requesttype['icon']['_links']['iconUrls']['32x32'],\n            'fields': fieldsPerRequest(id)\n        }\n        request_array.append(request_dict)\n    return request_array\n\n\nserviceDeskRequestTypes()\nBy using the request_types_endpoint  URL, our function serviceDeskRequestTypes() \n returns the request types  of a given JIRA service desk; or in other words, the\n types of requests users can submit.  This alone only gives us high-level\ninformation about the types of requests we allow but doesn't go into further\ndetail such as the actual resulting form. That's where our next function comes\nin.\n\nfieldsPerRequest()\nThis function gets passed the ID of each request type. With that, we extend our\nendpoint to look like \n'https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/[REQUESTID]/field'\n. Looping through each request type gives up exactly what we need: every request\ntype and every form field per request type.\n\nuserSession()\nThere's another thing left to consider: what if the user isn't currently logged\nin to JIRA? At the very least, we need to check to see if a JIRA session is\nactive:\n\nuser_session_endpoint = 'https://jira.we.co/rest/auth/1/session'\n\ndef getUserSession():\n    \"\"\"Get logged-in user.\"\"\"\n    r = requests.get(user_session_endpoint, headers=headers)\n    if r.status_code == 200:\n        return r.json()\n    else:\n        return False\n\n\nIf the user is logged in to JIRA, we'll receive a 200 code letting us know\neverything is alright. The body of the response will also contain the name of\nthe user plus some extra metadata. What if the user isn't  logged in? Let's get\nto that in a bit.\n\nEasy Routing\nOur view will be nice and simple:\n\nfrom jira import request_forms, user_details\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    \"\"\"Landing page.\"\"\"\n    if user_details == False:\n        return redirect('https://example.com')\n    else:\n        return render_template('/index.html', requests=request_forms)\n\n\nNotice that all we're doing is making sure the user is signed in to JIRA. But\nwhat's with the example.com, you ask? Well, because I'm leaving this part up to\nyou, dear friend. There's really a number of things we can do, but it depends\nentirely on your situation. For instance:\n\n * You can handle basic auth on your own\n * Register an OAuth application to handle sign-ins (perhaps the most robust\n   solution)\n * If your JIRA instance is behind SSO, you may want to send users to your\n   company's  SAML partner\n * Simply throw an error message\n\nWhatever you decide to do, it's not really my problem. Obligatory smiley face\nemoji :).\n\nThe Template\nRemember: the main reason most of you are probably doing this is to control the\npresentation layer as you see fit. That said, here comes a call of presentation\nlayer text, in the form of a Jinja template:\n\n{% block form %}\n  <div>\n    <h3 class=\"subtitle\">Submit new requests here</h3>\n    <ul class=\"collapsible\">\n      {% for request in requests %}\n      <li class=\"{{request.name}}\">\n        <div class=\"collapsible-header\">\n          <img src=\"{{request.icon}}\">\n          <div class=\"info\">\n            <h5>{{request.name}}</h5>\n            <p>{{request.description}}</p>\n          </div>\n        </div>\n        <div class=\"collapsible-body\">\n          <div class=\"row\">\n            <form method=\"post\">\n              <div>\n                {% for field in request.fields.requestTypeFields %}\n                  {% if field.name in ('Category', 'Product') %}\n                    <div class=\"input-field\">\n                      <select id=\"{{request.name}} {{field.name}}\">\n                        <option value=\"Choose your option\" disabled selected>Choose your option</option>\n                        {% for option in field.validValues %}\n                          <option value=\"{{option.label}}\">{{option.label}}</option>\n                        {% endfor %}\n                      </select>\n                      <label>{{field.name}}</label>\n                    </div>\n                  {% elif field.name == 'Description' %}\n                    <div class=\"input-field\">\n                      <textarea id=\"{{field.name}}\" class=\"materialize-textarea\" placeholder=\"{{field.description}}\"></textarea>\n                      <label for=\"{{request.name}} {{field.name}}\">{{field.name}}</label>\n                    </div>\n                  {% else %}\n                    <div class=\"input-field\">\n                      <input placeholder=\"{{field.description}}\" id=\"{{request.name}} {{field.name}}\" type=\"text\" class=\"validate\">\n                      <label for=\"{{request.name}} {{field.name}}\">{{field.name}}</label>\n                    </div>\n                  {% endif %}\n                {% endfor %}\n                <input type=\"button\" value=\"Submit\" class=\"btn cyan lighten-3 formsubmit\">\n              </div>\n            </form>\n          </div>\n        </div>\n      </li>\n      {% endfor %}\n    </ul>\n  </div>\n{% endblock %}\n\n\nBecause we passed the Service Desk JSON we extracted from the JIRA API to our\nform, we can go crazy setting our labels, placeholder text, or whatever,\nanywhere we please. In my example, I utilize Material Design\n[https://materializecss.com/]'s pretty package of pre-made frontend elements,\nbecause God knows nobody wants to deal with designing that shit. Sorry, I was\njust having a brief flashback to Frontend dev.\n\nThe code above explicitly looks for fields we know are dropdowns, so that we may\nfill the select options accordingly. Same goes for textarea fields. That said,\nthe way I've handled this above is, well, stupid. Instead of hardcoding if\nstatements to look for certain fields, leverage our JSON to determine the type\nof each field as you iterate over them. Do as I say, not as I do.\n\nGoing Further\nThere's so much more we can add here. Take a list of the user's opened tickets,\nfor instance. The great thing about controlling your own portal UI is that you\ncan now control the narrative of your own workload: perhaps the person in\nmarketing who started 2 weeks ago could benefit from seeing the 200 tickets\nbeing addressed before her, thus second-guessing the urge to type URGENT across\na subject line only to be violently shoved down your throat.\n\nIn all seriousness, nobody likes the experience of a vanilla helpdesk because it\ndehumanizes the customer. While our personal beliefs reassure us that we are\nspecial, entering a cold support queue is a stark suggestion that we may not be\nso special after all, which isn't exactly a fact Millennials or Executives like\nto ponder on. If nothing else, take this as a chance to build software friendly\ntowards humans with full transparency, and both parties will surely benefit.\nRemember: happy humans bides times for the inevitable robot revolution on the\nhorizon destined to eradicate mankind. Do your part!","html":"<p>When it comes to SaaS products in the realm of Service desks, JIRA Service Desk is at the very <em>least</em>, just as powerful as the next solution (Zendesk comes to mind). This naturally begs the question: Why is JIRA Service Desk's pricing model roughly 1/10th of that of it's competitor?</p><p>The answer lies within <em>ease of use,</em> but more importantly, <em>presentation</em>. While Atlassian's cloud offering is slowly playing catchup, Atlassian as a company has never quite seemed to nail down the importance of a friendly user interface, nor the importance of this when it comes to worldwide adoption. To see what I mean, here's an example that Atlassian themselves tout on their own documentation as a \"ready for production\" customer portal:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/customer-portal.png\" class=\"kg-image\"><figcaption>I'm convinced this is purposefully hideous to force the purchase of plugins.</figcaption></figure><p>To your average software developer (Atlassian's core demographic for years), one might see nothing wrong with this interface, but as somebody `who has rolled out over 30 of these desks for over 6 thousand people, layouts such as these commit numerous UI atrocities which simply are not acceptable for top enterprise software.</p><p>What do we do about this? We build an alternative, of course.</p><h2 id=\"method-to-this-madness\">Method to This Madness</h2><p>Our focus is not on JIRA as a <em>product,</em> but rather an <em>API. </em>Instead of attempting to work within JIRA’s boundaries via customization or add-ons, we can take matters into our own hands by owning the application that users use to interact with a JIRA instance. By using the JIRA API, we can not only extend features but actually ‘rebuild’ the application to gain full control over the UI or additional logic. JIRA is a hideous yet entirely necessary Java application, which makes it a perfect candidate for recreation.</p><p>We're going to use Flask for this. Shocking, I know. Here's the obligatory file structure of our project:</p><pre><code class=\"language-bash\">myproject\n├─ app.py\n├─ jira.py\n├─ /static\n│  └─ js\n│  └─ less\n│  └─ img\n└─ /templates\n   └─ layout.html\n   └─ index.html\n</code></pre>\n<p>This tutorial will be working against the JIRA <em>Server</em> API for Service Desk - that said, Cloud users should still find this applicable.</p><h2 id=\"pulling-your-service-desk-form\">Pulling Your Service Desk Form</h2><p>Before we get nuts building our application, we’ll need to be sure that a Service Desk already exists in JIRA with our expected intake form. Remember: our end goal is to simply consume JIRA as an API, but that entails interacting with something that exists in the first place.</p><p>With your Service Desk created, there’s one annoyance we need to resolve before getting into code: determining your Service Desk’s ID number. Like most things in JIRA, Service Desks are identified by an ID which is simply an arbitrary grouping of integers in some way. What is the official way to find this ID, you might ask? Why, by extracting it from the portal’s URL or by inspecting your XHR requests, of course! Remember: JIRA hates you, that’s why we’re doing this in the first place.</p><p>With your Service Desk ID handy, we can finally break into retrieving our desk via the Service Desk API:</p><pre><code class=\"language-python\">import requests\nfrom jira_config import jira_username, jira_password\n\nrequest_types_endpoint = &quot;https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/&quot;\n\nheaders = {'Content-Type': 'application/json'}\n\ndef fieldsPerRequest(id):\n    &quot;&quot;&quot;Get form fields per request type.&quot;&quot;&quot;\n    r = requests.get(request_types_endpoint + id + '/field', auth=(jira_username, jira_password), headers=headers)\n    form = r.json()\n    return form\n\n\ndef serviceDeskRequestTypes():\n    &quot;&quot;&quot;Get request types.&quot;&quot;&quot;\n    request_array = []\n    r = requests.get(request_types_endpoint, auth=(jira_username, jira_password), headers=headers)\n    for requesttype in r.json()['values']:\n        id = requesttype['id']\n        request_dict = {\n            'name': requesttype['name'],\n            'description': requesttype['description'],\n            'icon': requesttype['icon']['_links']['iconUrls']['32x32'],\n            'fields': fieldsPerRequest(id)\n        }\n        request_array.append(request_dict)\n    return request_array\n</code></pre>\n<h3 id=\"servicedeskrequesttypes-\">serviceDeskRequestTypes()</h3><p>By using the <em>request_types_endpoint</em> URL, our function <code>serviceDeskRequestTypes()</code> returns the <strong>request types</strong> of a given JIRA service desk; or in other words, the <em>types of requests users can submit.</em> This alone only gives us high-level information about the types of requests we allow but doesn't go into further detail such as the actual resulting form. That's where our next function comes in.</p><h3 id=\"fieldsperrequest-\">fieldsPerRequest()</h3><p>This function gets passed the ID of each request type. With that, we extend our endpoint to look like <code>'https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/[REQUESTID]/field'</code>. Looping through each request type gives up exactly what we need: every request type and every form field per request type.</p><h3 id=\"usersession-\">userSession()</h3><p>There's another thing left to consider: what if the user isn't currently logged in to JIRA? At the very least, we need to check to see if a JIRA session is active:</p><pre><code class=\"language-python\">user_session_endpoint = 'https://jira.we.co/rest/auth/1/session'\n\ndef getUserSession():\n    &quot;&quot;&quot;Get logged-in user.&quot;&quot;&quot;\n    r = requests.get(user_session_endpoint, headers=headers)\n    if r.status_code == 200:\n        return r.json()\n    else:\n        return False\n</code></pre>\n<p>If the user is logged in to JIRA, we'll receive a 200 code letting us know everything is alright. The body of the response will also contain the name of the user plus some extra metadata. What if the user <em>isn't</em> logged in? Let's get to that in a bit.</p><h2 id=\"easy-routing\">Easy Routing</h2><p>Our view will be nice and simple:</p><pre><code class=\"language-python\">from jira import request_forms, user_details\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    &quot;&quot;&quot;Landing page.&quot;&quot;&quot;\n    if user_details == False:\n        return redirect('https://example.com')\n    else:\n        return render_template('/index.html', requests=request_forms)\n</code></pre>\n<p>Notice that all we're doing is making sure the user is signed in to JIRA. But what's with the <em>example.com</em>, you ask? Well, because I'm leaving this part up to you, dear friend. There's really a number of things we can do, but it depends entirely on your situation. For instance:</p><ul><li>You can handle basic auth on your own</li><li>Register an OAuth application to handle sign-ins (perhaps the most robust solution)</li><li>If your JIRA instance is behind SSO, you may want to send users to your company's  SAML partner</li><li>Simply throw an error message</li></ul><p>Whatever you decide to do, it's not really my problem. Obligatory smiley face emoji :).</p><h2 id=\"the-template\">The Template</h2><p>Remember: the main reason most of you are probably doing this is to control the presentation layer as you see fit. That said, here comes a call of presentation layer text, in the form of a Jinja template:</p><pre><code class=\"language-jinja\">{% block form %}\n  &lt;div&gt;\n    &lt;h3 class=&quot;subtitle&quot;&gt;Submit new requests here&lt;/h3&gt;\n    &lt;ul class=&quot;collapsible&quot;&gt;\n      {% for request in requests %}\n      &lt;li class=&quot;{{request.name}}&quot;&gt;\n        &lt;div class=&quot;collapsible-header&quot;&gt;\n          &lt;img src=&quot;{{request.icon}}&quot;&gt;\n          &lt;div class=&quot;info&quot;&gt;\n            &lt;h5&gt;{{request.name}}&lt;/h5&gt;\n            &lt;p&gt;{{request.description}}&lt;/p&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div class=&quot;collapsible-body&quot;&gt;\n          &lt;div class=&quot;row&quot;&gt;\n            &lt;form method=&quot;post&quot;&gt;\n              &lt;div&gt;\n                {% for field in request.fields.requestTypeFields %}\n                  {% if field.name in ('Category', 'Product') %}\n                    &lt;div class=&quot;input-field&quot;&gt;\n                      &lt;select id=&quot;{{request.name}} {{field.name}}&quot;&gt;\n                        &lt;option value=&quot;Choose your option&quot; disabled selected&gt;Choose your option&lt;/option&gt;\n                        {% for option in field.validValues %}\n                          &lt;option value=&quot;{{option.label}}&quot;&gt;{{option.label}}&lt;/option&gt;\n                        {% endfor %}\n                      &lt;/select&gt;\n                      &lt;label&gt;{{field.name}}&lt;/label&gt;\n                    &lt;/div&gt;\n                  {% elif field.name == 'Description' %}\n                    &lt;div class=&quot;input-field&quot;&gt;\n                      &lt;textarea id=&quot;{{field.name}}&quot; class=&quot;materialize-textarea&quot; placeholder=&quot;{{field.description}}&quot;&gt;&lt;/textarea&gt;\n                      &lt;label for=&quot;{{request.name}} {{field.name}}&quot;&gt;{{field.name}}&lt;/label&gt;\n                    &lt;/div&gt;\n                  {% else %}\n                    &lt;div class=&quot;input-field&quot;&gt;\n                      &lt;input placeholder=&quot;{{field.description}}&quot; id=&quot;{{request.name}} {{field.name}}&quot; type=&quot;text&quot; class=&quot;validate&quot;&gt;\n                      &lt;label for=&quot;{{request.name}} {{field.name}}&quot;&gt;{{field.name}}&lt;/label&gt;\n                    &lt;/div&gt;\n                  {% endif %}\n                {% endfor %}\n                &lt;input type=&quot;button&quot; value=&quot;Submit&quot; class=&quot;btn cyan lighten-3 formsubmit&quot;&gt;\n              &lt;/div&gt;\n            &lt;/form&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/li&gt;\n      {% endfor %}\n    &lt;/ul&gt;\n  &lt;/div&gt;\n{% endblock %}\n</code></pre>\n<p>Because we passed the Service Desk JSON we extracted from the JIRA API to our form, we can go crazy setting our labels, placeholder text, or whatever, anywhere we please. In my example, I utilize <a href=\"https://materializecss.com/\">Material Design</a>'s pretty package of pre-made frontend elements, because God knows nobody wants to deal with designing that shit. Sorry, I was just having a brief flashback to Frontend dev.</p><p>The code above explicitly looks for fields we know are dropdowns, so that we may fill the select options accordingly. Same goes for textarea fields. That said, the way I've handled this above is, well, stupid. Instead of hardcoding if statements to look for certain fields, leverage our JSON to determine the type of each field as you iterate over them. Do as I say, not as I do.</p><h2 id=\"going-further\">Going Further</h2><p>There's so much more we can add here. Take a list of the user's opened tickets, for instance. The great thing about controlling your own portal UI is that you can now control the narrative of your own workload: perhaps the person in marketing who started 2 weeks ago could benefit from seeing the 200 tickets being addressed before her, thus second-guessing the urge to type <strong>URGENT </strong>across a subject line only to be violently shoved down your throat.</p><p>In all seriousness, nobody likes the experience of a vanilla helpdesk because it dehumanizes the customer. While our personal beliefs reassure us that we are special, entering a cold support queue is a stark suggestion that we may not be so special after all, which isn't exactly a fact Millennials or Executives like to ponder on. If nothing else, take this as a chance to build software friendly towards humans with full transparency, and both parties will surely benefit. Remember: happy humans bides times for the inevitable robot revolution on the horizon destined to eradicate mankind. Do your part!</p>","url":"https://hackersandslackers.com/building-a-better-jira/","uuid":"789d1406-0dbf-432e-aaa0-32d10f7d6337","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b6f24cc0cd9b8583e46ab5b"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736eb","title":"Pipenv: Better Environment Management for Python","slug":"pipenv-python-environment-management","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/pipenv.jpg","excerpt":"Effortlessly manage your Python environment and dependencies.","custom_excerpt":"Effortlessly manage your Python environment and dependencies.","created_at_pretty":"27 August, 2018","published_at_pretty":"30 August, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-08-27T19:40:53.000-04:00","published_at":"2018-08-30T07:36:00.000-04:00","updated_at":"2019-04-10T09:09:36.000-04:00","meta_title":"Effortlessly manage your Python environment | Hackers And Slackers","meta_description":"Pipenv serves as both an environment management tool as well as a sort of 'package.json' for your Python app.","og_description":"Pipenv serves as both an environment management tool as well as a sort of 'package.json' for your Python app.","og_image":"https://hackersandslackers.com/content/images/2019/04/pipenv-2.jpg","og_title":"Pipenv: Better Environment Management for Python","twitter_description":"Pipenv serves as both an environment management tool as well as a sort of 'package.json' for your Python app.","twitter_image":"https://hackersandslackers.com/content/images/2019/04/pipenv-1.jpg","twitter_title":"Pipenv: Better Environment Management for Python","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"As a shoutout to my fellow Data Engineers, I'm going to take a step back from\ntypical data science workflows. When we build standalone applications, we\nprobably don't want to be tossing around Miniconda's 720 software packages in\nproduction, nor would we ever want to commit the source of any dependencies to\nGithub. This is where Pipenv comes in handy: it serves as both an environment\nmanagement tool, as well as a sort of package.json  for your Python app.\n\nThe combination of virtualenv  and virtualenvwrapper  have reigned supreme for\nsome time. While this combination is a totally fine solution, I've noticed even\nsenior developers gloss over the existence of a better alternative, pipenv,\nwhich makes package management way, way easier. This is especially important in\ncases such as building apps for Heroku, where we're pushing to an otherwise\nagnostic environment which must explicitly be kept in sync with our local setup\nto ensure anything works.\n\nApologies in advance for what might seem a bit like Python 101, but I've been\nfinding that the following information might be more relevant to some than we\nmight presume.\n\nWhy Pipenv?\nPipenv's shell interface is entirely user-friendly. Rarely will developers find\nthemselves needing to type more than two words, perhaps a single argument, to\nachieve a series of tasks which were previously less trivial. Pipenv also does\nan excellent job of documenting all dependencies in the resulting Pipfile  and \nPipfile.lock, which are easily generated and capture our project's dependencies\nto be handed off to the next poor bloke. Finally, Pipenv does us the luxury of\nkeeping installed dependencies out of our project folder and instead creates\nvirtual environments in parallel with our Python Path. This keeps folders\npotentially holding hundreds of dependencies out of our project folders,\n mitigates any risk of us committing these packages to any git repos (if you're\na nodejs person, you know what I mean with npm  and node_modules).\n\nCreating Environments\nUnsurprisingly, we get started with pip3 install pipenv. This may as well be the\nfirst and last package you install on your python path.\n\nWhile in your project folder, give ‘pipenv shell’ a go. If an environment has\nnot been created in this folder previously, this will create a new environment\nfor this directory. If an environment does exist, this same command will be used\nto activate the environment. Compare this to the syntax of virtualenv:\n\n$ virtualenv myenv\n$ source myenv/bin/activate\n\n\nWhen creating environments, ‘pipenv shell’ can also take additional arguments\nsuch as —python, which allows you to specify which installed version of python\nto use for this environment:\n\n$ pipenv shell —python 3.7\n\n\nWhile in the shell, we can install packages using pip as expected.\n\nManaging packages\nThe point of environments is not only to isolate dependencies, but also to track\nthem so that our environment is both transferable and easily reproducible.\nChances are you’re familiar with the typical output of pip freeze:\n\naadict==0.2.3\nasset==0.6.12\nbeautifulsoup4==4.6.1\ncertifi==2018.4.16\nchardet==3.0.4\nclick==6.7\ndecorator==4.3.0\ndnspython==1.15.0\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Static-Compress==1.0.2\nglobre==0.1.5\ngunicorn==19.9.0\nidna==2.7\ninfinity==1.4\nintervals==0.8.1\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nlessc==0.1.2\nlesscpy==0.13.0\nMarkupSafe==1.0\nordereddict==1.1\nply==3.11\npymongo==3.7.1\nrequests==2.19.1\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.10\nSQLAlchemy-Utils==0.33.3\nurllib3==1.23\nvalidators==0.12.2\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\nWTForms-Alchemy==0.16.7\nWTForms-Components==0.10.3\n\npip freeze  is a great human-friendly way to see what you have installed in your\nenvironment; but what about robots? This wouldn't be Hackers And Slackers if we\ndidn't have a robot-friendly solution, now would it? Check out the output of \npipenv lock, which writes to a file called Pipfile.lock  in your local\nenvironment:\n\n{\n    \"_meta\": {\n        \"hash\": {\n            \"sha256\": \"668ab7d6f7db268048ca01a717c1cf77b8b4f373ed8074e48a9f22517975a306\"\n        },\n        \"pipfile-spec\": 6,\n        \"requires\": {\n            \"python_version\": \"3.7\"\n        },\n        \"sources\": [\n            {\n                \"name\": \"pypi\",\n                \"url\": \"https://pypi.org/simple\",\n                \"verify_ssl\": true\n            }\n        ]\n    },\n    \"default\": {\n        \"asn1crypto\": {\n            \"hashes\": [\n                \"sha256:2f1adbb7546ed199e3c90ef23ec95c5cf3585bac7d11fb7eb562a3fe89c64e87\",\n                \"sha256:9d5c20441baf0cb60a4ac34cc447c6c189024b6b4c6cd7877034f4965c464e49\"\n            ],\n            \"version\": \"==0.24.0\"\n        },\n        \"certifi\": {\n            \"hashes\": [\n                \"sha256:13e698f54293db9f89122b0581843a782ad0934a4fe0172d2a980ba77fc61bb7\",\n                \"sha256:9fa520c1bacfb634fa7af20a76bcbd3d5fb390481724c597da32c719a7dca4b0\"\n            ],\n            \"version\": \"==2018.4.16\"\n        },\n        \"cffi\": {\n            \"hashes\": [\n                \"sha256:151b7eefd035c56b2b2e1eb9963c90c6302dc15fbd8c1c0a83a163ff2c7d7743\",\n                \"sha256:1553d1e99f035ace1c0544050622b7bc963374a00c467edafac50ad7bd276aef\",\n                \"sha256:1b0493c091a1898f1136e3f4f991a784437fac3673780ff9de3bcf46c80b6b50\",\n                \"sha256:2ba8a45822b7aee805ab49abfe7eec16b90587f7f26df20c71dd89e45a97076f\",\n                \"sha256:3bb6bd7266598f318063e584378b8e27c67de998a43362e8fce664c54ee52d30\",\n                \"sha256:3c85641778460581c42924384f5e68076d724ceac0f267d66c757f7535069c93\",\n                \"sha256:3eb6434197633b7748cea30bf0ba9f66727cdce45117a712b29a443943733257\",\n                \"sha256:495c5c2d43bf6cebe0178eb3e88f9c4aa48d8934aa6e3cddb865c058da76756b\",\n                \"sha256:4c91af6e967c2015729d3e69c2e51d92f9898c330d6a851bf8f121236f3defd3\",\n                \"sha256:57b2533356cb2d8fac1555815929f7f5f14d68ac77b085d2326b571310f34f6e\",\n                \"sha256:770f3782b31f50b68627e22f91cb182c48c47c02eb405fd689472aa7b7aa16dc\",\n                \"sha256:79f9b6f7c46ae1f8ded75f68cf8ad50e5729ed4d590c74840471fc2823457d04\",\n                \"sha256:7a33145e04d44ce95bcd71e522b478d282ad0eafaf34fe1ec5bbd73e662f22b6\",\n                \"sha256:857959354ae3a6fa3da6651b966d13b0a8bed6bbc87a0de7b38a549db1d2a359\",\n                \"sha256:87f37fe5130574ff76c17cab61e7d2538a16f843bb7bca8ebbc4b12de3078596\",\n                \"sha256:95d5251e4b5ca00061f9d9f3d6fe537247e145a8524ae9fd30a2f8fbce993b5b\",\n                \"sha256:9d1d3e63a4afdc29bd76ce6aa9d58c771cd1599fbba8cf5057e7860b203710dd\",\n                \"sha256:a36c5c154f9d42ec176e6e620cb0dd275744aa1d804786a71ac37dc3661a5e95\",\n                \"sha256:a6a5cb8809091ec9ac03edde9304b3ad82ad4466333432b16d78ef40e0cce0d5\",\n                \"sha256:ae5e35a2c189d397b91034642cb0eab0e346f776ec2eb44a49a459e6615d6e2e\",\n                \"sha256:b0f7d4a3df8f06cf49f9f121bead236e328074de6449866515cea4907bbc63d6\",\n                \"sha256:b75110fb114fa366b29a027d0c9be3709579602ae111ff61674d28c93606acca\",\n                \"sha256:ba5e697569f84b13640c9e193170e89c13c6244c24400fc57e88724ef610cd31\",\n                \"sha256:be2a9b390f77fd7676d80bc3cdc4f8edb940d8c198ed2d8c0be1319018c778e1\",\n                \"sha256:ca1bd81f40adc59011f58159e4aa6445fc585a32bb8ac9badf7a2c1aa23822f2\",\n                \"sha256:d5d8555d9bfc3f02385c1c37e9f998e2011f0db4f90e250e5bc0c0a85a813085\",\n                \"sha256:e55e22ac0a30023426564b1059b035973ec82186ddddbac867078435801c7801\",\n                \"sha256:e90f17980e6ab0f3c2f3730e56d1fe9bcba1891eeea58966e89d352492cc74f4\",\n                \"sha256:ecbb7b01409e9b782df5ded849c178a0aa7c906cf8c5a67368047daab282b184\",\n                \"sha256:ed01918d545a38998bfa5902c7c00e0fee90e957ce036a4000a88e3fe2264917\",\n                \"sha256:edabd457cd23a02965166026fd9bfd196f4324fe6032e866d0f3bd0301cd486f\",\n                \"sha256:fdf1c1dc5bafc32bc5d08b054f94d659422b05aba244d6be4ddc1c72d9aa70fb\"\n            ],\n            \"version\": \"==1.11.5\"\n        },\n        \"chardet\": {\n            \"hashes\": [\n                \"sha256:84ab92ed1c4d4f16916e05906b6b75a6c0fb5db821cc65e70cbd64a3e2a5eaae\",\n                \"sha256:fc323ffcaeaed0e0a02bf4d117757b98aed530d9ed4531e3e15460124c106691\"\n            ],\n            \"version\": \"==3.0.4\"\n        },\n        \"cryptography\": {\n            \"hashes\": [\n                \"sha256:21af753934f2f6d1a10fe8f4c0a64315af209ef6adeaee63ca349797d747d687\",\n                \"sha256:27bb401a20a838d6d0ea380f08c6ead3ccd8c9d8a0232dc9adcc0e4994576a66\",\n                \"sha256:29720c4253263cff9aea64585adbbe85013ba647f6e98367efff9db2d7193ded\",\n                \"sha256:2a35b7570d8f247889784010aac8b384fd2e4a47b33e15c4a60b45a7c1944120\",\n                \"sha256:42c531a6a354407f42ee07fda5c2c0dc822cf6d52744949c182f2b295fbd4183\",\n                \"sha256:5eb86f03f9c4f0ac2336ac5431271072ddf7ecc76b338e26366732cfac58aa19\",\n                \"sha256:67f7f57eae8dede577f3f7775957f5bec93edd6bdb6ce597bb5b28e1bdf3d4fb\",\n                \"sha256:6ec84edcbc966ae460560a51a90046503ff0b5b66157a9efc61515c68059f6c8\",\n                \"sha256:7ba834564daef87557e7fcd35c3c3183a4147b0b3a57314e53317360b9b201b3\",\n                \"sha256:7d7f084cbe1fdb82be5a0545062b59b1ad3637bc5a48612ac2eb428ff31b31ea\",\n                \"sha256:82409f5150e529d699e5c33fa8fd85e965104db03bc564f5f4b6a9199e591f7c\",\n                \"sha256:87d092a7c2a44e5f7414ab02fb4145723ebba411425e1a99773531dd4c0e9b8d\",\n                \"sha256:8c56ef989342e42b9fcaba7c74b446f0cc9bed546dd00034fa7ad66fc00307ef\",\n                \"sha256:9449f5d4d7c516a6118fa9210c4a00f34384cb1d2028672100ee0c6cce49d7f6\",\n                \"sha256:bc2301170986ad82d9349a91eb8884e0e191209c45f5541b16aa7c0cfb135978\",\n                \"sha256:c132bab45d4bd0fff1d3fe294d92b0a6eb8404e93337b3127bdec9f21de117e6\",\n                \"sha256:c3d945b7b577f07a477700f618f46cbc287af3a9222cd73035c6ef527ef2c363\",\n                \"sha256:cee18beb4c807b5c0b178f4fa2fae03cef9d51821a358c6890f8b23465b7e5d2\",\n                \"sha256:d01dfc5c2b3495184f683574e03c70022674ca9a7be88589c5aba130d835ea90\"\n            ],\n            \"version\": \"==2.3\"\n        },\n        \"defusedxml\": {\n            \"hashes\": [\n                \"sha256:24d7f2f94f7f3cb6061acb215685e5125fbcdc40a857eff9de22518820b0a4f4\",\n                \"sha256:702a91ade2968a82beb0db1e0766a6a273f33d4616a6ce8cde475d8e09853b20\"\n            ],\n            \"version\": \"==0.5.0\"\n        },\n        \"idna\": {\n            \"hashes\": [\n                \"sha256:156a6814fb5ac1fc6850fb002e0852d56c0c8d2531923a51032d1b70760e186e\",\n                \"sha256:684a38a6f903c1d71d6d5fac066b58d7768af4de2b832e426ec79c30daa94a16\"\n            ],\n            \"version\": \"==2.7\"\n        },\n        \"jira\": {\n            \"hashes\": [\n                \"sha256:9adeead4d5f5a6aff74c630787f8bd2d4b0e154f3a3036641298064e91b2d25d\",\n                \"sha256:e2a94adff98e45b29ded030adc76103eab34fa7d4d57303f211f572bedba0e93\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.0.0\"\n        },\n        \"numpy\": {\n            \"hashes\": [\n                \"sha256:14fb76bde161c87dcec52d91c78f65aa8a23aa2e1530a71f412dabe03927d917\",\n                \"sha256:21041014b7529237994a6b578701c585703fbb3b1bea356cdb12a5ea7804241c\",\n                \"sha256:24f3bb9a5f6c3936a8ccd4ddfc1210d9511f4aeb879a12efd2e80bec647b8695\",\n                \"sha256:34033b581bc01b1135ca2e3e93a94daea7c739f21a97a75cca93e29d9f0c8e71\",\n                \"sha256:3fbccb399fe9095b1c1d7b41e7c7867db8aa0d2347fc44c87a7a180cedda112b\",\n                \"sha256:50718eea8e77a1bedcc85befd22c8dbf5a24c9d2c0c1e36bbb8d7a38da847eb3\",\n                \"sha256:55daf757e5f69aa75b4477cf4511bf1f96325c730e4ad32d954ccb593acd2585\",\n                \"sha256:61efc65f325770bbe787f34e00607bc124f08e6c25fdf04723848585e81560dc\",\n                \"sha256:62cb836506f40ce2529bfba9d09edc4b2687dd18c56cf4457e51c3e7145402fd\",\n                \"sha256:64c6acf5175745fd1b7b7e17c74fdbfb7191af3b378bc54f44560279f41238d3\",\n                \"sha256:674ea7917f0657ddb6976bd102ac341bc493d072c32a59b98e5b8c6eaa2d5ec0\",\n                \"sha256:73a816e441dace289302e04a7a34ec4772ed234ab6885c968e3ca2fc2d06fe2d\",\n                \"sha256:78c35dc7ad184aebf3714dbf43f054714c6e430e14b9c06c49a864fb9e262030\",\n                \"sha256:7f17efe9605444fcbfd990ba9b03371552d65a3c259fc2d258c24fb95afdd728\",\n                \"sha256:816645178f2180be257a576b735d3ae245b1982280b97ae819550ce8bcdf2b6b\",\n                \"sha256:924f37e66db78464b4b85ed4b6d2e5cda0c0416e657cac7ccbef14b9fa2c40b5\",\n                \"sha256:a17a8fd5df4fec5b56b4d11c9ba8b9ebfb883c90ec361628d07be00aaa4f009a\",\n                \"sha256:aaa519335a71f87217ca8a680c3b66b61960e148407bdf5c209c42f50fe30f49\",\n                \"sha256:ae3864816287d0e86ead580b69921daec568fe680857f07ee2a87bf7fd77ce24\",\n                \"sha256:b5f8c15cb9173f6cdf0f994955e58d1265331029ae26296232379461a297e5f2\",\n                \"sha256:c3ac359ace241707e5a48fe2922e566ac666aacacf4f8031f2994ac429c31344\",\n                \"sha256:c7c660cc0209fdf29a4e50146ca9ac9d8664acaded6b6ae2f5d0ae2e91a0f0cd\",\n                \"sha256:d690a2ff49f6c3bc35336693c9924fe5916be3cc0503fe1ea6c7e2bf951409ee\",\n                \"sha256:e2317cf091c2e7f0dacdc2e72c693cc34403ca1f8e3807622d0bb653dc978616\",\n                \"sha256:f28e73cf18d37a413f7d5de35d024e6b98f14566a10d82100f9dc491a7d449f9\",\n                \"sha256:f2a778dd9bb3e4590dbe3bbac28e7c7134280c4ec97e3bf8678170ee58c67b21\",\n                \"sha256:f5a758252502b466b9c2b201ea397dae5a914336c987f3a76c3741a82d43c96e\",\n                \"sha256:fb4c33a404d9eff49a0cdc8ead0af6453f62f19e071b60d283f9dc05581e4134\"\n            ],\n            \"markers\": \"python_version >= '2.7' and python_version != '3.2.*' and python_version != '3.3.*' and python_version != '3.0.*' and python_version != '3.1.*'\",\n            \"version\": \"==1.15.0\"\n        },\n        \"oauthlib\": {\n            \"hashes\": [\n                \"sha256:ac35665a61c1685c56336bda97d5eefa246f1202618a1d6f34fccb1bdd404162\",\n                \"sha256:d883b36b21a6ad813953803edfa563b1b579d79ca758fe950d1bc9e8b326025b\"\n            ],\n            \"version\": \"==2.1.0\"\n        },\n        \"pandas\": {\n            \"hashes\": [\n                \"sha256:11975fad9edbdb55f1a560d96f91830e83e29bed6ad5ebf506abda09818eaf60\",\n                \"sha256:12e13d127ca1b585dd6f6840d3fe3fa6e46c36a6afe2dbc5cb0b57032c902e31\",\n                \"sha256:1c87fcb201e1e06f66e23a61a5fea9eeebfe7204a66d99df24600e3f05168051\",\n                \"sha256:242e9900de758e137304ad4b5663c2eff0d798c2c3b891250bd0bd97144579da\",\n                \"sha256:26c903d0ae1542890cb9abadb4adcb18f356b14c2df46e4ff657ae640e3ac9e7\",\n                \"sha256:2e1e88f9d3e5f107b65b59cd29f141995597b035d17cc5537e58142038942e1a\",\n                \"sha256:31b7a48b344c14691a8e92765d4023f88902ba3e96e2e4d0364d3453cdfd50db\",\n                \"sha256:4fd07a932b4352f8a8973761ab4e84f965bf81cc750fb38e04f01088ab901cb8\",\n                \"sha256:5b24ca47acf69222e82530e89111dd9d14f9b970ab2cd3a1c2c78f0c4fbba4f4\",\n                \"sha256:647b3b916cc8f6aeba240c8171be3ab799c3c1b2ea179a3be0bd2712c4237553\",\n                \"sha256:66b060946046ca27c0e03e9bec9bba3e0b918bafff84c425ca2cc2e157ce121e\",\n                \"sha256:6efa9fa6e1434141df8872d0fa4226fc301b17aacf37429193f9d70b426ea28f\",\n                \"sha256:be4715c9d8367e51dbe6bc6d05e205b1ae234f0dc5465931014aa1c4af44c1ba\",\n                \"sha256:bea90da782d8e945fccfc958585210d23de374fa9294a9481ed2abcef637ebfc\",\n                \"sha256:d785fc08d6f4207437e900ffead930a61e634c5e4f980ba6d3dc03c9581748c7\",\n                \"sha256:de9559287c4fe8da56e8c3878d2374abc19d1ba2b807bfa7553e912a8e5ba87c\",\n                \"sha256:f4f98b190bb918ac0bc0e3dd2ab74ff3573da9f43106f6dba6385406912ec00f\",\n                \"sha256:f71f1a7e2d03758f6e957896ed696254e2bc83110ddbc6942018f1a232dd9dad\",\n                \"sha256:fb944c8f0b0ab5c1f7846c686bc4cdf8cde7224655c12edcd59d5212cd57bec0\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==0.23.4\"\n        },\n        \"pbr\": {\n            \"hashes\": [\n                \"sha256:1b8be50d938c9bb75d0eaf7eda111eec1bf6dc88a62a6412e33bf077457e0f45\",\n                \"sha256:b486975c0cafb6beeb50ca0e17ba047647f229087bd74e37f4a7e2cac17d2caa\"\n            ],\n            \"version\": \"==4.2.0\"\n        },\n        \"psycopg2-binary\": {\n            \"hashes\": [\n                \"sha256:04afb59bbbd2eab3148e6816beddc74348078b8c02a1113ea7f7822f5be4afe3\",\n                \"sha256:098b18f4d8857a8f9b206d1dc54db56c2255d5d26458917e7bcad61ebfe4338f\",\n                \"sha256:0bf855d4a7083e20ead961fda4923887094eaeace0ab2d76eb4aa300f4bbf5bd\",\n                \"sha256:197dda3ffd02057820be83fe4d84529ea70bf39a9a4daee1d20ffc74eb3d042e\",\n                \"sha256:278ef63afb4b3d842b4609f2c05ffbfb76795cf6a184deeb8707cd5ed3c981a5\",\n                \"sha256:3cbf8c4fc8f22f0817220891cf405831559f4d4c12c4f73913730a2ea6c47a47\",\n                \"sha256:4305aed922c4d9d6163ab3a41d80b5a1cfab54917467da8168552c42cad84d32\",\n                \"sha256:47ee296f704fb8b2a616dec691cdcfd5fa0f11943955e88faa98cbd1dc3b3e3d\",\n                \"sha256:4a0e38cb30457e70580903367161173d4a7d1381eb2f2cfe4e69b7806623f484\",\n                \"sha256:4d6c294c6638a71cafb82a37f182f24321f1163b08b5d5ca076e11fe838a3086\",\n                \"sha256:4f3233c366500730f839f92833194fd8f9a5c4529c8cd8040aa162c3740de8e5\",\n                \"sha256:5221f5a3f4ca2ddf0d58e8b8a32ca50948be9a43351fda797eb4e72d7a7aa34d\",\n                \"sha256:5c6ca0b507540a11eaf9e77dee4f07c131c2ec80ca0cffa146671bf690bc1c02\",\n                \"sha256:789bd89d71d704db2b3d5e67d6d518b158985d791d3b2dec5ab85457cfc9677b\",\n                \"sha256:7b94d29239efeaa6a967f3b5971bd0518d2a24edd1511edbf4a2c8b815220d07\",\n                \"sha256:89bc65ef3301c74cf32db25334421ea6adbe8f65601ea45dcaaf095abed910bb\",\n                \"sha256:89d6d3a549f405c20c9ae4dc94d7ed2de2fa77427a470674490a622070732e62\",\n                \"sha256:97521704ac7127d7d8ba22877da3c7bf4a40366587d238ec679ff38e33177498\",\n                \"sha256:a395b62d5f44ff6f633231abe568e2203b8fabf9797cd6386aa92497df912d9a\",\n                \"sha256:a6d32c37f714c3f34158f3fa659f3a8f2658d5f53c4297d45579b9677cc4d852\",\n                \"sha256:a89ee5c26f72f2d0d74b991ce49e42ddeb4ac0dc2d8c06a0f2770a1ab48f4fe0\",\n                \"sha256:b4c8b0ef3608e59317bfc501df84a61e48b5445d45f24d0391a24802de5f2d84\",\n                \"sha256:b5fcf07140219a1f71e18486b8dc28e2e1b76a441c19374805c617aa6d9a9d55\",\n                \"sha256:b86f527f00956ecebad6ab3bb30e3a75fedf1160a8716978dd8ce7adddedd86f\",\n                \"sha256:be4c4aa22ba22f70de36c98b06480e2f1697972d49eb20d525f400d204a6d272\",\n                \"sha256:c2ac7aa1a144d4e0e613ac7286dae85671e99fe7a1353954d4905629c36b811c\",\n                \"sha256:de26ef4787b5e778e8223913a3e50368b44e7480f83c76df1f51d23bd21cea16\",\n                \"sha256:e70ebcfc5372dc7b699c0110454fc4263967f30c55454397e5769eb72c0eb0ce\",\n                \"sha256:eadbd32b6bc48b67b0457fccc94c86f7ccc8178ab839f684eb285bb592dc143e\",\n                \"sha256:ecbc6dfff6db06b8b72ae8a2f25ff20fbdcb83cb543811a08f7cb555042aa729\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.7.5\"\n        },\n        \"pycparser\": {\n            \"hashes\": [\n                \"sha256:99a8ca03e29851d96616ad0404b4aad7d9ee16f25c9f9708a11faf2810f7b226\"\n            ],\n            \"version\": \"==2.18\"\n        },\n        \"pyjwt\": {\n            \"hashes\": [\n                \"sha256:30b1380ff43b55441283cc2b2676b755cca45693ae3097325dea01f3d110628c\",\n                \"sha256:4ee413b357d53fd3fb44704577afac88e72e878716116270d722723d65b42176\"\n            ],\n            \"version\": \"==1.6.4\"\n        },\n        \"python-dateutil\": {\n            \"hashes\": [\n                \"sha256:1adb80e7a782c12e52ef9a8182bebeb73f1d7e24e374397af06fb4956c8dc5c0\",\n                \"sha256:e27001de32f627c22380a688bcc43ce83504a7bc5da472209b4c70f02829f0b8\"\n            ],\n            \"version\": \"==2.7.3\"\n        },\n        \"pytz\": {\n            \"hashes\": [\n                \"sha256:a061aa0a9e06881eb8b3b2b43f05b9439d6583c206d0a6c340ff72a7b6669053\",\n                \"sha256:ffb9ef1de172603304d9d2819af6f5ece76f2e85ec10692a524dd876e72bf277\"\n            ],\n            \"version\": \"==2018.5\"\n        },\n        \"requests\": {\n            \"hashes\": [\n                \"sha256:63b52e3c866428a224f97cab011de738c36aec0185aa91cfacd418b5d58911d1\",\n                \"sha256:ec22d826a36ed72a7358ff3fe56cbd4ba69dd7a6718ffd450ff0e9df7a47ce6a\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.19.1\"\n        },\n        \"requests-oauthlib\": {\n            \"hashes\": [\n                \"sha256:8886bfec5ad7afb391ed5443b1f697c6f4ae98d0e5620839d8b4499c032ada3f\",\n                \"sha256:e21232e2465808c0e892e0e4dbb8c2faafec16ac6dc067dd546e9b466f3deac8\"\n            ],\n            \"version\": \"==1.0.0\"\n        },\n        \"requests-toolbelt\": {\n            \"hashes\": [\n                \"sha256:42c9c170abc2cacb78b8ab23ac957945c7716249206f90874651971a4acff237\",\n                \"sha256:f6a531936c6fa4c6cfce1b9c10d5c4f498d16528d2a54a22ca00011205a187b5\"\n            ],\n            \"version\": \"==0.8.0\"\n        },\n        \"six\": {\n            \"hashes\": [\n                \"sha256:70e8a77beed4562e7f14fe23a786b54f6296e34344c23bc42f07b15018ff98e9\",\n                \"sha256:832dc0e10feb1aa2c68dcc57dbb658f1c7e65b9b61af69048abc87a2db00a0eb\"\n            ],\n            \"version\": \"==1.11.0\"\n        },\n        \"sqlalchemy\": {\n            \"hashes\": [\n                \"sha256:72325e67fb85f6e9ad304c603d83626d1df684fdf0c7ab1f0352e71feeab69d8\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==1.2.10\"\n        },\n        \"urllib3\": {\n            \"hashes\": [\n                \"sha256:a68ac5e15e76e7e5dd2b8f94007233e01effe3e50e8daddf69acfd81cb686baf\",\n                \"sha256:b5725a0bd4ba422ab0e66e89e030c806576753ea3ee08554382c14e685d117b5\"\n            ],\n            \"markers\": \"python_version != '3.0.*' and python_version != '3.3.*' and python_version != '3.1.*' and python_version != '3.2.*' and python_version < '4' and python_version >= '2.6'\",\n            \"version\": \"==1.23\"\n        }\n    },\n    \"develop\": {}\n}\n\n\nPipfile.lock  is Python's very own equivalent to package-lock.json. With \nPipfile.lock  present, future developers need only to type the command pipenv\ninstall  to install the exact dependencies in your project with all the correct\nversions. What's more, Pipfile.lock is actually a must-have for Heroku \ndevelopment, which uses this file to wisely produce environments upon\ndeployment.\n\nWhat about updating all packages past their locked version, you might ask? Check\nout the output of pipenv update, which updates all packages to their latest, and\nupdates the corresponding .lock file accordingly:\n\nYou had me at Snake emoji.When to Use Conda or Virtualenv\nIf you're strictly in the data science  profession, chances are that none of\nthis nonsense interests you - you and all your friends are always working with\nthe full Anaconda suite (which has its own similar environment manager), and you\ndon't care for shipping products. You're a scientist, not some sort of blue\ncollar data equivalent of manufacturing. \n\nEven if you're engineer, virtualenv  still has it's place. Take Lambda Functions\nin AWS for example: if you're looking to create a zip of dependencies to upload\nto your Lambda, it's much simpler to have those packages to live in your local\nworking folder. \n\nI'm sure you're itching to hear more on the topic of Python environment\nmanagement, but the analytics say that 90% of readers have already bounced by\nthis point. To the remaining 10%... you are all that I live for.","html":"<p>As a shoutout to my fellow Data Engineers, I'm going to take a step back from typical data science workflows. When we build standalone applications, we probably don't want to be tossing around Miniconda's 720 software packages in production, nor would we ever want to commit the source of any dependencies to Github. This is where Pipenv comes in handy: it serves as both an environment management tool, as well as a sort of <em>package.json</em> for your Python app.</p><p>The combination of <code>virtualenv</code> and <code>virtualenvwrapper</code> have reigned supreme for some time. While this combination is a totally fine solution, I've noticed even senior developers gloss over the existence of a better alternative, <code>pipenv</code>, which makes package management way, way easier. This is especially important in cases such as building apps for Heroku, where we're pushing to an otherwise agnostic environment which must explicitly be kept in sync with our local setup to ensure anything works.</p><p>Apologies in advance for what might seem a bit like Python 101, but I've been finding that the following information might be more relevant to some than we might presume.</p><h2 id=\"why-pipenv\">Why Pipenv?</h2><p>Pipenv's shell interface is entirely user-friendly. Rarely will developers find themselves needing to type more than two words, perhaps a single argument, to achieve a series of tasks which were previously less trivial. Pipenv also does an excellent job of documenting all dependencies in the resulting <strong>Pipfile</strong> and <strong>Pipfile.lock</strong>, which are easily generated and capture our project's dependencies to be handed off to the next poor bloke. Finally, Pipenv does us the luxury of keeping installed dependencies out of our project folder and instead creates virtual environments in parallel with our Python Path. This keeps folders potentially holding hundreds of dependencies out of our project folders,  mitigates any risk of us committing these packages to any git repos (if you're a nodejs person, you know what I mean with <em>npm</em> and <em>node_modules</em>).</p><h2 id=\"creating-environments\">Creating Environments</h2><p>Unsurprisingly, we get started with <code>pip3 install pipenv</code>. This may as well be the first and last package you install on your python path.</p><p>While in your project folder, give ‘pipenv shell’ a go. If an environment has not been created in this folder previously, this will create a new environment for this directory. If an environment does exist, this same command will be used to activate the environment. Compare this to the syntax of virtualenv:</p><pre><code class=\"language-shell\">$ virtualenv myenv\n$ source myenv/bin/activate\n</code></pre>\n<p>When creating environments, ‘pipenv shell’ can also take additional arguments such as —python, which allows you to specify which installed version of python to use for this environment:</p><pre><code class=\"language-shell\">$ pipenv shell —python 3.7\n</code></pre>\n<p>While in the shell, we can install packages using pip as expected.</p><h2 id=\"managing-packages\">Managing packages</h2><p>The point of environments is not only to isolate dependencies, but also to track them so that our environment is both transferable and easily reproducible. Chances are you’re familiar with the typical output of <code>pip freeze</code>:</p><pre><code>aadict==0.2.3\nasset==0.6.12\nbeautifulsoup4==4.6.1\ncertifi==2018.4.16\nchardet==3.0.4\nclick==6.7\ndecorator==4.3.0\ndnspython==1.15.0\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Static-Compress==1.0.2\nglobre==0.1.5\ngunicorn==19.9.0\nidna==2.7\ninfinity==1.4\nintervals==0.8.1\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nlessc==0.1.2\nlesscpy==0.13.0\nMarkupSafe==1.0\nordereddict==1.1\nply==3.11\npymongo==3.7.1\nrequests==2.19.1\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.10\nSQLAlchemy-Utils==0.33.3\nurllib3==1.23\nvalidators==0.12.2\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\nWTForms-Alchemy==0.16.7\nWTForms-Components==0.10.3</code></pre><p><code>pip freeze</code> is a great human-friendly way to see what you have installed in your environment; but what about robots? This wouldn't be Hackers And Slackers if we didn't have a robot-friendly solution, now would it? Check out the output of <code>pipenv lock</code>, which writes to a file called <code>Pipfile.lock</code> in your local environment:</p><pre><code>{\n    \"_meta\": {\n        \"hash\": {\n            \"sha256\": \"668ab7d6f7db268048ca01a717c1cf77b8b4f373ed8074e48a9f22517975a306\"\n        },\n        \"pipfile-spec\": 6,\n        \"requires\": {\n            \"python_version\": \"3.7\"\n        },\n        \"sources\": [\n            {\n                \"name\": \"pypi\",\n                \"url\": \"https://pypi.org/simple\",\n                \"verify_ssl\": true\n            }\n        ]\n    },\n    \"default\": {\n        \"asn1crypto\": {\n            \"hashes\": [\n                \"sha256:2f1adbb7546ed199e3c90ef23ec95c5cf3585bac7d11fb7eb562a3fe89c64e87\",\n                \"sha256:9d5c20441baf0cb60a4ac34cc447c6c189024b6b4c6cd7877034f4965c464e49\"\n            ],\n            \"version\": \"==0.24.0\"\n        },\n        \"certifi\": {\n            \"hashes\": [\n                \"sha256:13e698f54293db9f89122b0581843a782ad0934a4fe0172d2a980ba77fc61bb7\",\n                \"sha256:9fa520c1bacfb634fa7af20a76bcbd3d5fb390481724c597da32c719a7dca4b0\"\n            ],\n            \"version\": \"==2018.4.16\"\n        },\n        \"cffi\": {\n            \"hashes\": [\n                \"sha256:151b7eefd035c56b2b2e1eb9963c90c6302dc15fbd8c1c0a83a163ff2c7d7743\",\n                \"sha256:1553d1e99f035ace1c0544050622b7bc963374a00c467edafac50ad7bd276aef\",\n                \"sha256:1b0493c091a1898f1136e3f4f991a784437fac3673780ff9de3bcf46c80b6b50\",\n                \"sha256:2ba8a45822b7aee805ab49abfe7eec16b90587f7f26df20c71dd89e45a97076f\",\n                \"sha256:3bb6bd7266598f318063e584378b8e27c67de998a43362e8fce664c54ee52d30\",\n                \"sha256:3c85641778460581c42924384f5e68076d724ceac0f267d66c757f7535069c93\",\n                \"sha256:3eb6434197633b7748cea30bf0ba9f66727cdce45117a712b29a443943733257\",\n                \"sha256:495c5c2d43bf6cebe0178eb3e88f9c4aa48d8934aa6e3cddb865c058da76756b\",\n                \"sha256:4c91af6e967c2015729d3e69c2e51d92f9898c330d6a851bf8f121236f3defd3\",\n                \"sha256:57b2533356cb2d8fac1555815929f7f5f14d68ac77b085d2326b571310f34f6e\",\n                \"sha256:770f3782b31f50b68627e22f91cb182c48c47c02eb405fd689472aa7b7aa16dc\",\n                \"sha256:79f9b6f7c46ae1f8ded75f68cf8ad50e5729ed4d590c74840471fc2823457d04\",\n                \"sha256:7a33145e04d44ce95bcd71e522b478d282ad0eafaf34fe1ec5bbd73e662f22b6\",\n                \"sha256:857959354ae3a6fa3da6651b966d13b0a8bed6bbc87a0de7b38a549db1d2a359\",\n                \"sha256:87f37fe5130574ff76c17cab61e7d2538a16f843bb7bca8ebbc4b12de3078596\",\n                \"sha256:95d5251e4b5ca00061f9d9f3d6fe537247e145a8524ae9fd30a2f8fbce993b5b\",\n                \"sha256:9d1d3e63a4afdc29bd76ce6aa9d58c771cd1599fbba8cf5057e7860b203710dd\",\n                \"sha256:a36c5c154f9d42ec176e6e620cb0dd275744aa1d804786a71ac37dc3661a5e95\",\n                \"sha256:a6a5cb8809091ec9ac03edde9304b3ad82ad4466333432b16d78ef40e0cce0d5\",\n                \"sha256:ae5e35a2c189d397b91034642cb0eab0e346f776ec2eb44a49a459e6615d6e2e\",\n                \"sha256:b0f7d4a3df8f06cf49f9f121bead236e328074de6449866515cea4907bbc63d6\",\n                \"sha256:b75110fb114fa366b29a027d0c9be3709579602ae111ff61674d28c93606acca\",\n                \"sha256:ba5e697569f84b13640c9e193170e89c13c6244c24400fc57e88724ef610cd31\",\n                \"sha256:be2a9b390f77fd7676d80bc3cdc4f8edb940d8c198ed2d8c0be1319018c778e1\",\n                \"sha256:ca1bd81f40adc59011f58159e4aa6445fc585a32bb8ac9badf7a2c1aa23822f2\",\n                \"sha256:d5d8555d9bfc3f02385c1c37e9f998e2011f0db4f90e250e5bc0c0a85a813085\",\n                \"sha256:e55e22ac0a30023426564b1059b035973ec82186ddddbac867078435801c7801\",\n                \"sha256:e90f17980e6ab0f3c2f3730e56d1fe9bcba1891eeea58966e89d352492cc74f4\",\n                \"sha256:ecbb7b01409e9b782df5ded849c178a0aa7c906cf8c5a67368047daab282b184\",\n                \"sha256:ed01918d545a38998bfa5902c7c00e0fee90e957ce036a4000a88e3fe2264917\",\n                \"sha256:edabd457cd23a02965166026fd9bfd196f4324fe6032e866d0f3bd0301cd486f\",\n                \"sha256:fdf1c1dc5bafc32bc5d08b054f94d659422b05aba244d6be4ddc1c72d9aa70fb\"\n            ],\n            \"version\": \"==1.11.5\"\n        },\n        \"chardet\": {\n            \"hashes\": [\n                \"sha256:84ab92ed1c4d4f16916e05906b6b75a6c0fb5db821cc65e70cbd64a3e2a5eaae\",\n                \"sha256:fc323ffcaeaed0e0a02bf4d117757b98aed530d9ed4531e3e15460124c106691\"\n            ],\n            \"version\": \"==3.0.4\"\n        },\n        \"cryptography\": {\n            \"hashes\": [\n                \"sha256:21af753934f2f6d1a10fe8f4c0a64315af209ef6adeaee63ca349797d747d687\",\n                \"sha256:27bb401a20a838d6d0ea380f08c6ead3ccd8c9d8a0232dc9adcc0e4994576a66\",\n                \"sha256:29720c4253263cff9aea64585adbbe85013ba647f6e98367efff9db2d7193ded\",\n                \"sha256:2a35b7570d8f247889784010aac8b384fd2e4a47b33e15c4a60b45a7c1944120\",\n                \"sha256:42c531a6a354407f42ee07fda5c2c0dc822cf6d52744949c182f2b295fbd4183\",\n                \"sha256:5eb86f03f9c4f0ac2336ac5431271072ddf7ecc76b338e26366732cfac58aa19\",\n                \"sha256:67f7f57eae8dede577f3f7775957f5bec93edd6bdb6ce597bb5b28e1bdf3d4fb\",\n                \"sha256:6ec84edcbc966ae460560a51a90046503ff0b5b66157a9efc61515c68059f6c8\",\n                \"sha256:7ba834564daef87557e7fcd35c3c3183a4147b0b3a57314e53317360b9b201b3\",\n                \"sha256:7d7f084cbe1fdb82be5a0545062b59b1ad3637bc5a48612ac2eb428ff31b31ea\",\n                \"sha256:82409f5150e529d699e5c33fa8fd85e965104db03bc564f5f4b6a9199e591f7c\",\n                \"sha256:87d092a7c2a44e5f7414ab02fb4145723ebba411425e1a99773531dd4c0e9b8d\",\n                \"sha256:8c56ef989342e42b9fcaba7c74b446f0cc9bed546dd00034fa7ad66fc00307ef\",\n                \"sha256:9449f5d4d7c516a6118fa9210c4a00f34384cb1d2028672100ee0c6cce49d7f6\",\n                \"sha256:bc2301170986ad82d9349a91eb8884e0e191209c45f5541b16aa7c0cfb135978\",\n                \"sha256:c132bab45d4bd0fff1d3fe294d92b0a6eb8404e93337b3127bdec9f21de117e6\",\n                \"sha256:c3d945b7b577f07a477700f618f46cbc287af3a9222cd73035c6ef527ef2c363\",\n                \"sha256:cee18beb4c807b5c0b178f4fa2fae03cef9d51821a358c6890f8b23465b7e5d2\",\n                \"sha256:d01dfc5c2b3495184f683574e03c70022674ca9a7be88589c5aba130d835ea90\"\n            ],\n            \"version\": \"==2.3\"\n        },\n        \"defusedxml\": {\n            \"hashes\": [\n                \"sha256:24d7f2f94f7f3cb6061acb215685e5125fbcdc40a857eff9de22518820b0a4f4\",\n                \"sha256:702a91ade2968a82beb0db1e0766a6a273f33d4616a6ce8cde475d8e09853b20\"\n            ],\n            \"version\": \"==0.5.0\"\n        },\n        \"idna\": {\n            \"hashes\": [\n                \"sha256:156a6814fb5ac1fc6850fb002e0852d56c0c8d2531923a51032d1b70760e186e\",\n                \"sha256:684a38a6f903c1d71d6d5fac066b58d7768af4de2b832e426ec79c30daa94a16\"\n            ],\n            \"version\": \"==2.7\"\n        },\n        \"jira\": {\n            \"hashes\": [\n                \"sha256:9adeead4d5f5a6aff74c630787f8bd2d4b0e154f3a3036641298064e91b2d25d\",\n                \"sha256:e2a94adff98e45b29ded030adc76103eab34fa7d4d57303f211f572bedba0e93\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.0.0\"\n        },\n        \"numpy\": {\n            \"hashes\": [\n                \"sha256:14fb76bde161c87dcec52d91c78f65aa8a23aa2e1530a71f412dabe03927d917\",\n                \"sha256:21041014b7529237994a6b578701c585703fbb3b1bea356cdb12a5ea7804241c\",\n                \"sha256:24f3bb9a5f6c3936a8ccd4ddfc1210d9511f4aeb879a12efd2e80bec647b8695\",\n                \"sha256:34033b581bc01b1135ca2e3e93a94daea7c739f21a97a75cca93e29d9f0c8e71\",\n                \"sha256:3fbccb399fe9095b1c1d7b41e7c7867db8aa0d2347fc44c87a7a180cedda112b\",\n                \"sha256:50718eea8e77a1bedcc85befd22c8dbf5a24c9d2c0c1e36bbb8d7a38da847eb3\",\n                \"sha256:55daf757e5f69aa75b4477cf4511bf1f96325c730e4ad32d954ccb593acd2585\",\n                \"sha256:61efc65f325770bbe787f34e00607bc124f08e6c25fdf04723848585e81560dc\",\n                \"sha256:62cb836506f40ce2529bfba9d09edc4b2687dd18c56cf4457e51c3e7145402fd\",\n                \"sha256:64c6acf5175745fd1b7b7e17c74fdbfb7191af3b378bc54f44560279f41238d3\",\n                \"sha256:674ea7917f0657ddb6976bd102ac341bc493d072c32a59b98e5b8c6eaa2d5ec0\",\n                \"sha256:73a816e441dace289302e04a7a34ec4772ed234ab6885c968e3ca2fc2d06fe2d\",\n                \"sha256:78c35dc7ad184aebf3714dbf43f054714c6e430e14b9c06c49a864fb9e262030\",\n                \"sha256:7f17efe9605444fcbfd990ba9b03371552d65a3c259fc2d258c24fb95afdd728\",\n                \"sha256:816645178f2180be257a576b735d3ae245b1982280b97ae819550ce8bcdf2b6b\",\n                \"sha256:924f37e66db78464b4b85ed4b6d2e5cda0c0416e657cac7ccbef14b9fa2c40b5\",\n                \"sha256:a17a8fd5df4fec5b56b4d11c9ba8b9ebfb883c90ec361628d07be00aaa4f009a\",\n                \"sha256:aaa519335a71f87217ca8a680c3b66b61960e148407bdf5c209c42f50fe30f49\",\n                \"sha256:ae3864816287d0e86ead580b69921daec568fe680857f07ee2a87bf7fd77ce24\",\n                \"sha256:b5f8c15cb9173f6cdf0f994955e58d1265331029ae26296232379461a297e5f2\",\n                \"sha256:c3ac359ace241707e5a48fe2922e566ac666aacacf4f8031f2994ac429c31344\",\n                \"sha256:c7c660cc0209fdf29a4e50146ca9ac9d8664acaded6b6ae2f5d0ae2e91a0f0cd\",\n                \"sha256:d690a2ff49f6c3bc35336693c9924fe5916be3cc0503fe1ea6c7e2bf951409ee\",\n                \"sha256:e2317cf091c2e7f0dacdc2e72c693cc34403ca1f8e3807622d0bb653dc978616\",\n                \"sha256:f28e73cf18d37a413f7d5de35d024e6b98f14566a10d82100f9dc491a7d449f9\",\n                \"sha256:f2a778dd9bb3e4590dbe3bbac28e7c7134280c4ec97e3bf8678170ee58c67b21\",\n                \"sha256:f5a758252502b466b9c2b201ea397dae5a914336c987f3a76c3741a82d43c96e\",\n                \"sha256:fb4c33a404d9eff49a0cdc8ead0af6453f62f19e071b60d283f9dc05581e4134\"\n            ],\n            \"markers\": \"python_version &gt;= '2.7' and python_version != '3.2.*' and python_version != '3.3.*' and python_version != '3.0.*' and python_version != '3.1.*'\",\n            \"version\": \"==1.15.0\"\n        },\n        \"oauthlib\": {\n            \"hashes\": [\n                \"sha256:ac35665a61c1685c56336bda97d5eefa246f1202618a1d6f34fccb1bdd404162\",\n                \"sha256:d883b36b21a6ad813953803edfa563b1b579d79ca758fe950d1bc9e8b326025b\"\n            ],\n            \"version\": \"==2.1.0\"\n        },\n        \"pandas\": {\n            \"hashes\": [\n                \"sha256:11975fad9edbdb55f1a560d96f91830e83e29bed6ad5ebf506abda09818eaf60\",\n                \"sha256:12e13d127ca1b585dd6f6840d3fe3fa6e46c36a6afe2dbc5cb0b57032c902e31\",\n                \"sha256:1c87fcb201e1e06f66e23a61a5fea9eeebfe7204a66d99df24600e3f05168051\",\n                \"sha256:242e9900de758e137304ad4b5663c2eff0d798c2c3b891250bd0bd97144579da\",\n                \"sha256:26c903d0ae1542890cb9abadb4adcb18f356b14c2df46e4ff657ae640e3ac9e7\",\n                \"sha256:2e1e88f9d3e5f107b65b59cd29f141995597b035d17cc5537e58142038942e1a\",\n                \"sha256:31b7a48b344c14691a8e92765d4023f88902ba3e96e2e4d0364d3453cdfd50db\",\n                \"sha256:4fd07a932b4352f8a8973761ab4e84f965bf81cc750fb38e04f01088ab901cb8\",\n                \"sha256:5b24ca47acf69222e82530e89111dd9d14f9b970ab2cd3a1c2c78f0c4fbba4f4\",\n                \"sha256:647b3b916cc8f6aeba240c8171be3ab799c3c1b2ea179a3be0bd2712c4237553\",\n                \"sha256:66b060946046ca27c0e03e9bec9bba3e0b918bafff84c425ca2cc2e157ce121e\",\n                \"sha256:6efa9fa6e1434141df8872d0fa4226fc301b17aacf37429193f9d70b426ea28f\",\n                \"sha256:be4715c9d8367e51dbe6bc6d05e205b1ae234f0dc5465931014aa1c4af44c1ba\",\n                \"sha256:bea90da782d8e945fccfc958585210d23de374fa9294a9481ed2abcef637ebfc\",\n                \"sha256:d785fc08d6f4207437e900ffead930a61e634c5e4f980ba6d3dc03c9581748c7\",\n                \"sha256:de9559287c4fe8da56e8c3878d2374abc19d1ba2b807bfa7553e912a8e5ba87c\",\n                \"sha256:f4f98b190bb918ac0bc0e3dd2ab74ff3573da9f43106f6dba6385406912ec00f\",\n                \"sha256:f71f1a7e2d03758f6e957896ed696254e2bc83110ddbc6942018f1a232dd9dad\",\n                \"sha256:fb944c8f0b0ab5c1f7846c686bc4cdf8cde7224655c12edcd59d5212cd57bec0\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==0.23.4\"\n        },\n        \"pbr\": {\n            \"hashes\": [\n                \"sha256:1b8be50d938c9bb75d0eaf7eda111eec1bf6dc88a62a6412e33bf077457e0f45\",\n                \"sha256:b486975c0cafb6beeb50ca0e17ba047647f229087bd74e37f4a7e2cac17d2caa\"\n            ],\n            \"version\": \"==4.2.0\"\n        },\n        \"psycopg2-binary\": {\n            \"hashes\": [\n                \"sha256:04afb59bbbd2eab3148e6816beddc74348078b8c02a1113ea7f7822f5be4afe3\",\n                \"sha256:098b18f4d8857a8f9b206d1dc54db56c2255d5d26458917e7bcad61ebfe4338f\",\n                \"sha256:0bf855d4a7083e20ead961fda4923887094eaeace0ab2d76eb4aa300f4bbf5bd\",\n                \"sha256:197dda3ffd02057820be83fe4d84529ea70bf39a9a4daee1d20ffc74eb3d042e\",\n                \"sha256:278ef63afb4b3d842b4609f2c05ffbfb76795cf6a184deeb8707cd5ed3c981a5\",\n                \"sha256:3cbf8c4fc8f22f0817220891cf405831559f4d4c12c4f73913730a2ea6c47a47\",\n                \"sha256:4305aed922c4d9d6163ab3a41d80b5a1cfab54917467da8168552c42cad84d32\",\n                \"sha256:47ee296f704fb8b2a616dec691cdcfd5fa0f11943955e88faa98cbd1dc3b3e3d\",\n                \"sha256:4a0e38cb30457e70580903367161173d4a7d1381eb2f2cfe4e69b7806623f484\",\n                \"sha256:4d6c294c6638a71cafb82a37f182f24321f1163b08b5d5ca076e11fe838a3086\",\n                \"sha256:4f3233c366500730f839f92833194fd8f9a5c4529c8cd8040aa162c3740de8e5\",\n                \"sha256:5221f5a3f4ca2ddf0d58e8b8a32ca50948be9a43351fda797eb4e72d7a7aa34d\",\n                \"sha256:5c6ca0b507540a11eaf9e77dee4f07c131c2ec80ca0cffa146671bf690bc1c02\",\n                \"sha256:789bd89d71d704db2b3d5e67d6d518b158985d791d3b2dec5ab85457cfc9677b\",\n                \"sha256:7b94d29239efeaa6a967f3b5971bd0518d2a24edd1511edbf4a2c8b815220d07\",\n                \"sha256:89bc65ef3301c74cf32db25334421ea6adbe8f65601ea45dcaaf095abed910bb\",\n                \"sha256:89d6d3a549f405c20c9ae4dc94d7ed2de2fa77427a470674490a622070732e62\",\n                \"sha256:97521704ac7127d7d8ba22877da3c7bf4a40366587d238ec679ff38e33177498\",\n                \"sha256:a395b62d5f44ff6f633231abe568e2203b8fabf9797cd6386aa92497df912d9a\",\n                \"sha256:a6d32c37f714c3f34158f3fa659f3a8f2658d5f53c4297d45579b9677cc4d852\",\n                \"sha256:a89ee5c26f72f2d0d74b991ce49e42ddeb4ac0dc2d8c06a0f2770a1ab48f4fe0\",\n                \"sha256:b4c8b0ef3608e59317bfc501df84a61e48b5445d45f24d0391a24802de5f2d84\",\n                \"sha256:b5fcf07140219a1f71e18486b8dc28e2e1b76a441c19374805c617aa6d9a9d55\",\n                \"sha256:b86f527f00956ecebad6ab3bb30e3a75fedf1160a8716978dd8ce7adddedd86f\",\n                \"sha256:be4c4aa22ba22f70de36c98b06480e2f1697972d49eb20d525f400d204a6d272\",\n                \"sha256:c2ac7aa1a144d4e0e613ac7286dae85671e99fe7a1353954d4905629c36b811c\",\n                \"sha256:de26ef4787b5e778e8223913a3e50368b44e7480f83c76df1f51d23bd21cea16\",\n                \"sha256:e70ebcfc5372dc7b699c0110454fc4263967f30c55454397e5769eb72c0eb0ce\",\n                \"sha256:eadbd32b6bc48b67b0457fccc94c86f7ccc8178ab839f684eb285bb592dc143e\",\n                \"sha256:ecbc6dfff6db06b8b72ae8a2f25ff20fbdcb83cb543811a08f7cb555042aa729\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.7.5\"\n        },\n        \"pycparser\": {\n            \"hashes\": [\n                \"sha256:99a8ca03e29851d96616ad0404b4aad7d9ee16f25c9f9708a11faf2810f7b226\"\n            ],\n            \"version\": \"==2.18\"\n        },\n        \"pyjwt\": {\n            \"hashes\": [\n                \"sha256:30b1380ff43b55441283cc2b2676b755cca45693ae3097325dea01f3d110628c\",\n                \"sha256:4ee413b357d53fd3fb44704577afac88e72e878716116270d722723d65b42176\"\n            ],\n            \"version\": \"==1.6.4\"\n        },\n        \"python-dateutil\": {\n            \"hashes\": [\n                \"sha256:1adb80e7a782c12e52ef9a8182bebeb73f1d7e24e374397af06fb4956c8dc5c0\",\n                \"sha256:e27001de32f627c22380a688bcc43ce83504a7bc5da472209b4c70f02829f0b8\"\n            ],\n            \"version\": \"==2.7.3\"\n        },\n        \"pytz\": {\n            \"hashes\": [\n                \"sha256:a061aa0a9e06881eb8b3b2b43f05b9439d6583c206d0a6c340ff72a7b6669053\",\n                \"sha256:ffb9ef1de172603304d9d2819af6f5ece76f2e85ec10692a524dd876e72bf277\"\n            ],\n            \"version\": \"==2018.5\"\n        },\n        \"requests\": {\n            \"hashes\": [\n                \"sha256:63b52e3c866428a224f97cab011de738c36aec0185aa91cfacd418b5d58911d1\",\n                \"sha256:ec22d826a36ed72a7358ff3fe56cbd4ba69dd7a6718ffd450ff0e9df7a47ce6a\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.19.1\"\n        },\n        \"requests-oauthlib\": {\n            \"hashes\": [\n                \"sha256:8886bfec5ad7afb391ed5443b1f697c6f4ae98d0e5620839d8b4499c032ada3f\",\n                \"sha256:e21232e2465808c0e892e0e4dbb8c2faafec16ac6dc067dd546e9b466f3deac8\"\n            ],\n            \"version\": \"==1.0.0\"\n        },\n        \"requests-toolbelt\": {\n            \"hashes\": [\n                \"sha256:42c9c170abc2cacb78b8ab23ac957945c7716249206f90874651971a4acff237\",\n                \"sha256:f6a531936c6fa4c6cfce1b9c10d5c4f498d16528d2a54a22ca00011205a187b5\"\n            ],\n            \"version\": \"==0.8.0\"\n        },\n        \"six\": {\n            \"hashes\": [\n                \"sha256:70e8a77beed4562e7f14fe23a786b54f6296e34344c23bc42f07b15018ff98e9\",\n                \"sha256:832dc0e10feb1aa2c68dcc57dbb658f1c7e65b9b61af69048abc87a2db00a0eb\"\n            ],\n            \"version\": \"==1.11.0\"\n        },\n        \"sqlalchemy\": {\n            \"hashes\": [\n                \"sha256:72325e67fb85f6e9ad304c603d83626d1df684fdf0c7ab1f0352e71feeab69d8\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==1.2.10\"\n        },\n        \"urllib3\": {\n            \"hashes\": [\n                \"sha256:a68ac5e15e76e7e5dd2b8f94007233e01effe3e50e8daddf69acfd81cb686baf\",\n                \"sha256:b5725a0bd4ba422ab0e66e89e030c806576753ea3ee08554382c14e685d117b5\"\n            ],\n            \"markers\": \"python_version != '3.0.*' and python_version != '3.3.*' and python_version != '3.1.*' and python_version != '3.2.*' and python_version &lt; '4' and python_version &gt;= '2.6'\",\n            \"version\": \"==1.23\"\n        }\n    },\n    \"develop\": {}\n}\n</code></pre><p><code>Pipfile.lock</code> is Python's very own equivalent to <code>package-lock.json</code>. With <code>Pipfile.lock</code> present, future developers need only to type the command <code>pipenv install</code> to install the exact dependencies in your project with all the correct versions. What's more, Pipfile.lock is actually a must-have for <strong>Heroku</strong> development, which uses this file to wisely produce environments upon deployment.</p><p>What about updating all packages past their locked version, you might ask? Check out the output of <code>pipenv update</code>, which updates all packages to their latest, and updates the corresponding .lock file accordingly:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-08-29_18-52-30.gif\" class=\"kg-image\"><figcaption>You had me at Snake emoji.</figcaption></figure><h2 id=\"when-to-use-conda-or-virtualenv\">When to Use Conda or Virtualenv</h2><p>If you're strictly in the data <em>science</em> profession, chances are that none of this nonsense interests you - you and all your friends are always working with the full Anaconda suite (which has its own similar environment manager), and you don't care for shipping products. You're a scientist, not some sort of blue collar data equivalent of manufacturing. </p><p>Even if you're engineer, <code>virtualenv</code> still has it's place. Take Lambda Functions in AWS for example: if you're looking to create a zip of dependencies to upload to your Lambda, it's much simpler to have those packages to live in your local working folder. </p><p>I'm sure you're itching to hear more on the topic of Python environment management, but the analytics say that 90% of readers have already bounced by this point. To the remaining 10%... you are all that I live for.</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p>","url":"https://hackersandslackers.com/pipenv-python-environment-management/","uuid":"0d7b1982-a0a4-4e69-abdb-ecca53665ed3","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b848c058d5a814c505a70b6"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ea","title":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","slug":"add-db-variables-to-match-new-input-python-pandas","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/apidata@2x.jpg","excerpt":"Python, Pandas, & Functional Programming!","custom_excerpt":"Python, Pandas, & Functional Programming!","created_at_pretty":"22 August, 2018","published_at_pretty":"27 August, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-08-22T18:04:53.000-04:00","published_at":"2018-08-27T07:30:00.000-04:00","updated_at":"2019-02-13T22:48:04.000-05:00","meta_title":"Python, Pandas, & Functional Programming! | Hackers And Slackers","meta_description":"Python, Pandas, & Functional Programming!","og_description":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","og_image":"https://hackersandslackers.com/content/images/2018/08/apidata@2x.jpg","og_title":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","twitter_description":"Python, Pandas, & Functional Programming!","twitter_image":"https://hackersandslackers.com/content/images/2018/08/apidata@2x.jpg","twitter_title":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"}],"plaintext":"APIs.  They're wonderful.  For every headache they've given me, I'm glad I live\nin the age where hitting an API endpoint is a standard way of retrieving data -\nI recently had to crawl a bunch of records from the Brazilian census in 200, and\nthat was an ordeal (but this isn't about that!).\n\nThe thing about APIs is that you generally shouldn't be hitting them all day\nlong - generally you should be doing regular imports to a database (or\nwhatever).  And the other thing about APIs is that they're not quite as fussy\nabout names as databases.  There's nothing stopping you from having the first\nrow of your API's output include field names like \"Account Canceled?\", which a\ntypical SQL RDBMS will not care for one bit.\n\nHow do we translate them?  Well, simple enough - we just have to think of\neverything that might be in our input string that won't be allowed in our\ndatabase, and change that!  I'm going to use the pipe  function from my beloved \ntoolz  library, provider of Functional Programming goodies for Python.\n\nfrom toolz import pipe\nimport string\n\ndef dbReady(toConvert):\n    return pipe(toConvert,\n                lambda x: x.lower(),\n                lambda x: filter(lambda y: \n                                y in string.ascii_lowercase + \" \",\n                                x),\n                lambda x: \"\".join(x),\n                lambda x: x.split(),\n                lambda x: \"_\".join(x))\n\n\n 1. We made it lowercase.\n 2. We filtered everything that wasn't a lowercase letter or a space.\n 3. We joined the filter back into a string.\n 4. We split the resulting string (in case we wound up with any double spaces,\n    such as from deleting a &.\n 5. We joined the list of strings with underscores.\n\ndbReady(\"Account Canceled?\")\n'account_canceled'\n\n\nFor comparison's sake, here's what that same function looks like without pipe\n\ndef dbReady(toConvert):\n    return '_'.join(\n               \"\".join(\n                   filter(lambda x:\n                          x in string.ascii_lowercase + \" \",\n                          (toConvert\n                           .lower()))\n                   ).split())\n\n\nBut wait!  There's more!\n\nWhat if your API changes?  Oh no, that could break your import!\n\nWell, if you don't care about the new columns, you could just filter them out.\n Let's say we have a list of lists called latestResponse  that came from a\nrequest to our API, with the first row as the labels.\n\nimport pymysql\nfrom sqlalchemy import create_engine\nimport sqlalchemy\nimport pandas as pd\n\nlatestCols = latestResponse[0]\n\n#Change to what they'll be in the database\ndbReadies = [dbReady(x) for x in latestCols] \n\n#Grab the columns currently in the database\ncnx = create_engine('mysql+pymysql://root:cracked1@localhost/appointments', echo=False)\ndbCols = pd.io.sql.read_sql_table(\"appointments_tableau\", \n                                  cnx).columns\n\n#Make a dataframe with what the columns would be named in a database\ndf = pd.DataFrame(latestResponse[1:], columns = dbReady)\n\n#Only select the columns that are currently in the db, and upload\ndf[dbCols].to_sql(name=\"my_table\",\n                  con=cnx, \n                  if_exists='append')\n\n\n\nBut what if you DO want the new columns from now on?  But you're already in the\nzone, don't feel like manually searching for which columns are new, and opening\na new terminal window to add the new variables?  What if you are, in a word,\nlazy?  And what if it's sorta important to preserve the order of the fields, and\nthe new ones are in the middle?\n\nNever fear!\n\nFirst, let's cook up a little function to produce an SQL ALTER TABLE  statement\n(standard disclaimers apply: do NOT do this blindly, or automatically).  Oh, and\nfor our purposes let's say these new columns all have the same type ( \nVARCHAR(255)), because if that's not the case then we have to be slightly less\nlazy. \n\ndef alterStatement(existingCol, newCol):\n    return (f\"ALTER TABLE appointments_tableau \"\n            f\"ADD COLUMN {newCol} VARCHAR(255) AFTER {existingCol};\")\n\n\nLet's use the wonderful sliding_window  function from toolz  to feed us a bunch\nof column names. \n\nExample from the official docs:\n\nlist(sliding_window(2, [1, 2, 3, 4]))\n[(1, 2), (2, 3), (3, 4)]\n\n\nBack to the show!\n\nfrom toolz.itertoolz import sliding_window\n\n#Get the variables that aren't currently in the db\nnewVars = [x for x in dbReadies if x not in dbCols]\n\n#Get a list where each entry is a tuple that has every new variable, and the existing preceding one\ntuples = list(sliding_window(2, dbReadies))\nnewVarTups = [x for x in tuples if x[1] in newVars]\n\n\nAnd, finally, let's set up our statements, and have Pandas execute them!  I know\nI promised I was going to start using SQLAlchemy for this kind of thing instead\nof unsanitized raw SQL, but I'm back on my bullshit again.\n\nfor x in newVarTups:\n    pd.io.sql.execute(alterStatement(*x), cnx)","html":"<p>APIs.  They're wonderful.  For every headache they've given me, I'm glad I live in the age where hitting an API endpoint is a standard way of retrieving data - I recently had to crawl a bunch of records from the Brazilian census in 200, and that was an ordeal (but this isn't about that!).</p><p>The thing about APIs is that you generally shouldn't be hitting them all day long - generally you should be doing regular imports to a database (or whatever).  And the other thing about APIs is that they're not quite as fussy about names as databases.  There's nothing stopping you from having the first row of your API's output include field names like \"Account Canceled?\", which a typical SQL RDBMS will not care for one bit.</p><p>How do we translate them?  Well, simple enough - we just have to think of everything that might be in our input string that won't be allowed in our database, and change that!  I'm going to use the <code>pipe</code> function from my beloved <code>toolz</code> library, provider of Functional Programming goodies for Python.</p><pre><code class=\"language-python\">from toolz import pipe\nimport string\n\ndef dbReady(toConvert):\n    return pipe(toConvert,\n                lambda x: x.lower(),\n                lambda x: filter(lambda y: \n                                y in string.ascii_lowercase + &quot; &quot;,\n                                x),\n                lambda x: &quot;&quot;.join(x),\n                lambda x: x.split(),\n                lambda x: &quot;_&quot;.join(x))\n</code></pre>\n<ol><li>We made it lowercase.</li><li>We filtered everything that wasn't a lowercase letter or a space.</li><li>We joined the filter back into a string.</li><li>We split the resulting string (in case we wound up with any double spaces, such as from deleting a <code>&amp;</code>.</li><li>We joined the list of strings with underscores.</li></ol><pre><code class=\"language-python\">dbReady(&quot;Account Canceled?&quot;)\n'account_canceled'\n</code></pre>\n<p>For comparison's sake, here's what that same function looks like without <code>pipe</code></p><pre><code class=\"language-python\">def dbReady(toConvert):\n    return '_'.join(\n               &quot;&quot;.join(\n                   filter(lambda x:\n                          x in string.ascii_lowercase + &quot; &quot;,\n                          (toConvert\n                           .lower()))\n                   ).split())\n</code></pre>\n<p>But wait!  There's more!</p><p>What if your API changes?  Oh no, that could break your import!</p><p>Well, if you don't care about the new columns, you could just filter them out.  Let's say we have a list of lists called <code>latestResponse</code> that came from a request to our API, with the first row as the labels.</p><pre><code class=\"language-python\">import pymysql\nfrom sqlalchemy import create_engine\nimport sqlalchemy\nimport pandas as pd\n\nlatestCols = latestResponse[0]\n\n#Change to what they'll be in the database\ndbReadies = [dbReady(x) for x in latestCols] \n\n#Grab the columns currently in the database\ncnx = create_engine('mysql+pymysql://root:cracked1@localhost/appointments', echo=False)\ndbCols = pd.io.sql.read_sql_table(&quot;appointments_tableau&quot;, \n                                  cnx).columns\n\n#Make a dataframe with what the columns would be named in a database\ndf = pd.DataFrame(latestResponse[1:], columns = dbReady)\n\n#Only select the columns that are currently in the db, and upload\ndf[dbCols].to_sql(name=&quot;my_table&quot;,\n                  con=cnx, \n                  if_exists='append')\n\n</code></pre>\n<p>But what if you DO want the new columns from now on?  But you're already in the zone, don't feel like manually searching for which columns are new, and opening a new terminal window to add the new variables?  What if you are, in a word, lazy?  And what if it's sorta important to preserve the order of the fields, and the new ones are in the middle?  </p><p>Never fear!</p><p>First, let's cook up a little function to produce an SQL <code>ALTER TABLE</code> statement (standard disclaimers apply: do NOT do this blindly, or automatically).  Oh, and for our purposes let's say these new columns all have the same type ( <code>VARCHAR(255)</code>), because if that's not the case then we have to be slightly less lazy. </p><pre><code class=\"language-python\">def alterStatement(existingCol, newCol):\n    return (f&quot;ALTER TABLE appointments_tableau &quot;\n            f&quot;ADD COLUMN {newCol} VARCHAR(255) AFTER {existingCol};&quot;)\n</code></pre>\n<p>Let's use the wonderful <code>sliding_window</code> function from <code>toolz</code> to feed us a bunch of column names. </p><p>Example from the <a href=\"https://toolz.readthedocs.io/en/latest/api.html#toolz.itertoolz.sliding_window\">official docs</a>:</p><pre><code class=\"language-python\">list(sliding_window(2, [1, 2, 3, 4]))\n[(1, 2), (2, 3), (3, 4)]\n</code></pre>\n<p>Back to the show!</p><pre><code class=\"language-python\">from toolz.itertoolz import sliding_window\n\n#Get the variables that aren't currently in the db\nnewVars = [x for x in dbReadies if x not in dbCols]\n\n#Get a list where each entry is a tuple that has every new variable, and the existing preceding one\ntuples = list(sliding_window(2, dbReadies))\nnewVarTups = [x for x in tuples if x[1] in newVars]\n</code></pre>\n<p>And, finally, let's set up our statements, and have Pandas execute them!  I know I promised I was going to start using SQLAlchemy for this kind of thing instead of unsanitized raw SQL, but I'm back on my bullshit again.</p><pre><code class=\"language-python\">for x in newVarTups:\n    pd.io.sql.execute(alterStatement(*x), cnx)\n</code></pre>\n","url":"https://hackersandslackers.com/add-db-variables-to-match-new-input-python-pandas/","uuid":"8c2a6558-0216-46bc-aaef-ef2ab08342a3","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b7dde05a2743b50f2e9edeb"}}]}},"pageContext":{"slug":"python","limit":12,"skip":24,"numberOfPages":7,"humanPageNumber":3,"prevPageNumber":2,"nextPageNumber":4,"previousPagePath":"/tag/python/page/2/","nextPagePath":"/tag/python/page/4/"}}