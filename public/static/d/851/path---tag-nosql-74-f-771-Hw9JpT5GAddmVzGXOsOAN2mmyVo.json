{"data":{"ghostTag":{"slug":"nosql","name":"NoSQL","visibility":"public","feature_image":null,"description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances."},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c307c9493bed0776a0a3d80","title":"Using Redis to Store Information in Python Applications","slug":"using-redis-with-python","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/redis-1-2.jpg","excerpt":"A temporary data store for everything from session variables to chat queues.","custom_excerpt":"A temporary data store for everything from session variables to chat queues.","created_at_pretty":"05 January, 2019","published_at_pretty":"05 January, 2019","updated_at_pretty":"28 March, 2019","created_at":"2019-01-05T04:44:52.000-05:00","published_at":"2019-01-05T08:21:00.000-05:00","updated_at":"2019-03-28T05:41:12.000-04:00","meta_title":"Using Redis to Store Information in Python Apps | Hackers and Slackers","meta_description":"Take the guesswork out of storing values in memory: use Redis in your Python stack to have full control over session variables.","og_description":"Take the guesswork out of storing values in memory: use Redis in your Python stack to have full control over session variables.","og_image":"https://hackersandslackers.com/content/images/2019/03/redis-1-2.jpg","og_title":"Using Redis to Store Information in Python Applications","twitter_description":"Take the guesswork out of storing values in memory: use Redis in your Python stack to have full control over session variables.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/redis-1-1.jpg","twitter_title":"Using Redis to Store Information in Python Applications","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"We’re hacking into the new year here at Hackers and Slackers, and in the\nprocess, we’ve received plenty of new gifts to play with. Nevermind how Santa\nmanages to fit physically non-existent SaaS products under the Christmas tree.\nWe ask for abstract enterprise software every year, and this time we happened to\nget a little red box.\n\nIf you've never personally used Redis, the name probably sounds familiar as\nyou've been bombarded with obscure technology brand names in places like the\nHeroku marketplace, or your unacceptably nerdy Twitter account (I assure you,\nmine is worse). So what is Redis, you ask? Well, it's a NoSQL datasto- wait,\nwhere are you... NO! Don't leave! It's not like THAT, I swear!\n\nWhat Redis is and When to Use It\nRedis stores information in the familiar key/value pair format, but the term\n‘NoSQL’ is more of a technicality than an indicator of use cases synonymous with\nNoSQL databases of the past. Redis looks the part for the very purpose it\nserves: a box that you fill with crap which may or may not be important down the\nline. It’s the perfect place to put a Starbucks gift card or the clothes you’ve\nalready worn which aren’t quite ready to be washed yet.\n\nAll Users go to Heaven: Cloud Storage for User Sessions\nPerhaps the most common use case is a glorified session cache. Similar to the\nway users might store temporary app information in cookies, Redis holds on to\ninformation which is fleeting. The difference is we now own this information\ninside our very own box, thus the Redis motto: “your box, your rules.”* \n\n* I made this up: it holds zero truth.Because temporary user information is in\nour hands as opposed to a fickle browser, we can decide just how  temporary our\n“cache” is, having it persist across sessions or even devices. While local\nmemory storage may as well be a place for throwaway information, and databases\nfor persistent or eternal information, Redis is somewhere in between. As users\ninteract and the information they create within our app evolves, we may choose\nat any point to promote information stored in Redis to a database, or perhaps\nhave it stick around a little while longer. They’ll be thrilled to see their\nshopping cart still filled with the stupid things they almost bought while they\nwere drunk yesterday.\n\nWhen Variables are on a Bagel, You can Have Variables Any Time \nIn other words, Redis is great for solving the need of globally accessible\nvariables throughout an entire application, on a per-user basis. Users who\naccidentally quit your app, move to a new context, or merely use your app for\nlonger than your QA team are easier to manage when their temporary information\nis in a safe and global environment. Compare this to saving a user’s Pac-Man\nscore to a global variable:  the moment an app like Pac-Man crashes or restarts,\nthat session is gone forever. Thus dies another three-letter app obscenity\nbelonging to a leaderboard.\n\nSpeaking of Leaderboards...\nRedis is great at counting in increments. This is probably made evident by the\nfact that it is a computer, and these are the things computers do. Something\nelse that’s made great by counting: queues! Cues of tasks, notifications, chats,\ndisappearing naked photos, etc: all of these things are ideally suited for our\nred box.\n\nGetting a Red Box of Your Own\nPlaying around with a cloud-hosted Redis box will cost you maybe 5 bucks\n(monthly if you forget to cancel). Redis is open source so there are plenty of\nvendors to choose from with little differentiation between them. I’ll consider\nrecommending whichever vendor offers to bribe me the most, but in the meantime\nI’ll leave the window shopping to you.\n\nSetting up Redis should feel like setting up a cloud SQL database, except\nsmaller and cuter. You’ll be able to pick adorable features for your box of\npossibly-but-not-surely-worthless stuff, such as hosted region, etc. Once you're\nset up you should have a host URL for reaching your instance:\n\nredis-1738.c62.us-east-1-4.ec2.cloud.fakeredisprovider.com:42069\n\nNow we’re cooking with gas.\n\nUsing the redis-py Python Library\nThe main Python Redis library is typed as redis, as in pip install Redis. The\neasiest way to connect in any case is via a URI connection string, like such:\n\nr = redis.Redis( url='rediss://:password@hostname:port/0')\n\n\nNote the unique structure of the URI above:\n\n * rediss://: precedes all Redis URIs; NOTE THE TRAILING COLON.\n * password  comes next, with the interesting choice to bypass usernames.\n * hostname  is the instance's URL... almost always a thinly veiled repurposed\n   EC2 instance. That's right, we're being sold simple open source software\n   hosted on AWS. Don't think about it.\n * port is your preferred port of call after pillaging British trade ships. Just\n   making sure you're still here.\n * /database brings up the rear, which is the name of your database.\n\nAs with regular databases, other connection methods exist such as via SSL\ncertificates, etc.\n\nStoring and Getting Values\nThis is your bread and butter for interacting with Redis:\n\n * .set():  Set a key/value pair by either overwriting or creating a new value\n * .get():  Retrieve a value by naming the associated key\n * hmget():  Accepts a variable number of keys, and will return values for each\n   if they exist\n * hmset():  Set multiple values to a single key.\n * hgetall():  Get all values for a key where a key has been assigned multiple\n   values.\n\nIt’s important to note that Redis by default returns bytes as opposed to\nstrings. As a result, it is important to remember the encoding/decoding of\nvalues in order to retrieve them properly. For example:\n\n# Setting a Value\nr.set('uri', str(app.config['SQLALCHEMY_DATABASE_URI']).encode('utf-8'))\n\n# Getting a Value\nr.get('uri').decode('utf-8')\n\n\nIf you happen to be remotely sane, you probably don't want to deal with encoding\nand decoding values over and again. Luckily we can ensure that responses are\nalways decoded for us by setting the decode_responses  parameter to True  when\nsetting up our Redis instance:\n\nredis.StrictRedis(host=\"localhost\", port=6379, charset=\"utf-8\", decode_responses=True)\n\n\nThe redis-py documentation [https://redis-py.readthedocs.io/en/latest/] \nactually goes wayyy deeper than the 5 methods listed above. If you ever somehow\nmanage to cover all of it, I have many questions about the type of person you\nare.\n\nMore Redis Libraries for Python\nIf the above encoding/decoding seems annoying, you aren’t the first. That’s why\nlibraries like Redisworks [https://github.com/seperman/redisworks]  exist.\nRedisworks allows for the seamless exchange of Python data types to and from\nRedis. Want to shove a Python dict down your box’s throat? Go ahead! You won’t\neven have to think about it very hard. There are plenty of similar libraries all\naimed to make sad lives easier.\n\nWant more? How about Asyncio’s very own asynchronous Redis library\n[https://asyncio-redis.readthedocs.io/en/latest/]?  Or how about the similar \naioredis [aioredis.readthedocs.org], another Asyncio Redis plug-in, which also\nincludes pure Python parsing, clustering support, and things I don’t even\nunderstand! There are truly more Python libraries for Redis\n[https://redis.io/clients#python]  than you could need.\n\nFinally, how could we ever forget Flask-Redis? We’ve already covered this\n[https://hackersandslackers.com/demystifying-flasks-application-context/], but\nis easily the first and last Redis library any Flask developer will use.\n\nYour Box, Your Treasure, Your World™\nNow that we’ve uncovered this niche between cached data and stored data, the\npossibilities are endless. The world is your oyster full of things which you may\nor may not choose to shove in your box.\n\nOk, fine. Perhaps this whole concept feels like a bit of an obscure niche hardly\nworthy of the words on this page. Just remember that feeling when the time comes\nthat you too need a little red cube, and it will be waiting with love and\ncompassion. A companion cube, if you will.","html":"<p>We’re hacking into the new year here at Hackers and Slackers, and in the process, we’ve received plenty of new gifts to play with. Nevermind how Santa manages to fit physically non-existent SaaS products under the Christmas tree. We ask for abstract enterprise software every year, and this time we happened to get a little red box.</p><p>If you've never personally used Redis, the name probably sounds familiar as you've been bombarded with obscure technology brand names in places like the Heroku marketplace, or your unacceptably nerdy Twitter account (I assure you, mine is worse). So what is Redis, you ask? Well, it's a NoSQL datasto- wait, where are you... NO! Don't leave! It's not like THAT, I swear!</p><h2 id=\"what-redis-is-and-when-to-use-it\">What Redis is and When to Use It</h2><p>Redis stores information in the familiar key/value pair format, but the term ‘NoSQL’ is more of a technicality than an indicator of use cases synonymous with NoSQL databases of the past. Redis looks the part for the very purpose it serves: a box that you fill with crap which may or may not be important down the line. It’s the perfect place to put a Starbucks gift card or the clothes you’ve already worn which aren’t quite ready to be washed yet.</p><h3 id=\"all-users-go-to-heaven-cloud-storage-for-user-sessions\">All Users go to Heaven: Cloud Storage for User Sessions</h3><p>Perhaps the most common use case is a glorified <strong>session cache</strong>. Similar to the way users might store temporary app information in cookies, Redis holds on to information which is fleeting. The difference is we now own this information inside our very own box, thus the Redis motto: “<em>your box, your rules</em>.”* </p><!--kg-card-begin: html--><span style=\"color:#9DA0A0;font-style:italic;margin-bottom:30px;display:block;text-align:right;width:100%;\">* I made this up: it holds zero truth.</span><!--kg-card-end: html--><p>Because temporary user information is in our hands as opposed to a fickle browser, we can decide just <em>how</em> temporary our “cache” is, having it persist across sessions or even devices. While local memory storage may as well be a place for throwaway information, and databases for persistent or eternal information, Redis is somewhere in between. As users interact and the information they create within our app evolves, we may choose at any point to promote information stored in Redis to a database, or perhaps have it stick around a little while longer. They’ll be thrilled to see their shopping cart still filled with the stupid things they almost bought while they were drunk yesterday.</p><h3 id=\"when-variables-are-on-a-bagel-you-can-have-variables-any-time\">When Variables are on a Bagel, You can Have Variables Any Time </h3><p>In other words, Redis is great for solving the need of globally accessible variables throughout an entire application, on a per-user basis. Users who accidentally quit your app, move to a new context, or merely use your app for longer than your QA team are easier to manage when their temporary information is in a safe and global environment. Compare this to saving a user’s Pac-Man score to a global variable:  the moment an app like Pac-Man crashes or restarts, that session is gone forever. Thus dies another three-letter app obscenity belonging to a leaderboard.</p><h3 id=\"speaking-of-leaderboards-\">Speaking of Leaderboards...</h3><p>Redis is great at counting in increments. This is probably made evident by the fact that it is a computer, and these are the things computers do. Something else that’s made great by counting: queues! Cues of tasks, notifications, chats, disappearing naked photos, etc: all of these things are ideally suited for our red box.</p><h2 id=\"getting-a-red-box-of-your-own\">Getting a Red Box of Your Own</h2><p>Playing around with a cloud-hosted Redis box will cost you maybe 5 bucks (monthly if you forget to cancel). Redis is open source so there are plenty of vendors to choose from with little differentiation between them. I’ll consider recommending whichever vendor offers to bribe me the most, but in the meantime I’ll leave the window shopping to you.</p><p>Setting up Redis should feel like setting up a cloud SQL database, except smaller and cuter. You’ll be able to pick adorable features for your box of possibly-but-not-surely-worthless stuff, such as hosted region, etc. Once you're set up you should have a host URL for reaching your instance:</p><!--kg-card-begin: code--><pre><code>redis-1738.c62.us-east-1-4.ec2.cloud.fakeredisprovider.com:42069</code></pre><!--kg-card-end: code--><p>Now we’re cooking with gas.</p><h2 id=\"using-the-redis-py-python-library\">Using the redis-py Python Library</h2><p>The main Python Redis library is typed as <code>redis</code>, as in <code>pip install Redis</code>. The easiest way to connect in any case is via a URI connection string, like such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">r = redis.Redis( url='rediss://:password@hostname:port/0')\n</code></pre>\n<!--kg-card-end: markdown--><p>Note the unique structure of the URI above:</p><ul><li><strong>rediss://: </strong>precedes all Redis URIs; <em>NOTE THE TRAILING COLON.</em></li><li><strong>password</strong> comes next, with the interesting choice to bypass usernames.</li><li><strong>hostname</strong> is the instance's URL... almost always a thinly veiled repurposed EC2 instance. That's right, we're being sold simple open source software hosted on AWS. Don't think about it.</li><li><strong>port </strong>is your preferred port of call after pillaging British trade ships. Just making sure you're still here.</li><li><strong>/database </strong>brings up the rear, which is the name of your database.</li></ul><p>As with regular databases, other connection methods exist such as via SSL certificates, etc.</p><h3 id=\"storing-and-getting-values\">Storing and Getting Values</h3><p>This is your bread and butter for interacting with Redis:</p><ul><li><strong>.set():</strong> Set a key/value pair by either overwriting or creating a new value</li><li><strong>.get():</strong> Retrieve a value by naming the associated key</li><li><strong>hmget():</strong> Accepts a variable number of keys, and will return values for each if they exist</li><li><strong>hmset():</strong> Set multiple values to a single key.</li><li><strong>hgetall():</strong> Get all values for a key where a key has been assigned multiple values.</li></ul><p>It’s important to note that Redis by default returns bytes as opposed to strings. As a result, it is important to remember the encoding/decoding of values in order to retrieve them properly. For example:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># Setting a Value\nr.set('uri', str(app.config['SQLALCHEMY_DATABASE_URI']).encode('utf-8'))\n\n# Getting a Value\nr.get('uri').decode('utf-8')\n</code></pre>\n<!--kg-card-end: markdown--><p>If you happen to be remotely sane, you probably don't want to deal with encoding and decoding values over and again. Luckily we can ensure that responses are always decoded for us by setting the <code>decode_responses</code> parameter to <code>True</code> when setting up our Redis instance:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">redis.StrictRedis(host=&quot;localhost&quot;, port=6379, charset=&quot;utf-8&quot;, decode_responses=True)\n</code></pre>\n<!--kg-card-end: markdown--><p>The <a href=\"https://redis-py.readthedocs.io/en/latest/\" rel=\"noopener\"><strong>redis-py</strong> documentation</a> actually goes wayyy deeper than the 5 methods listed above. If you ever somehow manage to cover all of it, I have many questions about the type of person you are.</p><h2 id=\"more-redis-libraries-for-python\">More Redis Libraries for Python</h2><p>If the above encoding/decoding seems annoying, you aren’t the first. That’s why libraries like <a href=\"https://github.com/seperman/redisworks\" rel=\"noopener\"><strong>Redisworks</strong></a> exist. Redisworks allows for the seamless exchange of Python data types to and from Redis. Want to shove a Python dict down your box’s throat? Go ahead! You won’t even have to think about it very hard. There are plenty of similar libraries all aimed to make sad lives easier.</p><p>Want more? How about Asyncio’s very own <a href=\"https://asyncio-redis.readthedocs.io/en/latest/\">asynchronous Redis library</a>?  Or how about the similar <strong><a href=\"aioredis.readthedocs.org\">aioredis</a></strong>, another Asyncio Redis plug-in, which also includes pure Python parsing, clustering support, and things I don’t even understand! There are truly <a href=\"https://redis.io/clients#python\">more Python libraries for Redis</a> than you could need.</p><p>Finally, how could we ever forget <strong>Flask-Redis</strong>? We’ve <a href=\"https://hackersandslackers.com/demystifying-flasks-application-context/\" rel=\"noopener\">already covered this</a>, but is easily the first and last Redis library any Flask developer will use.</p><h2 id=\"your-box-your-treasure-your-world-\">Your Box, Your Treasure, Your World<strong>™</strong></h2><p>Now that we’ve uncovered this niche between cached data and stored data, the possibilities are endless. The world is your oyster full of things which you may or may not choose to shove in your box.</p><p>Ok, fine. Perhaps this whole concept feels like a bit of an obscure niche hardly worthy of the words on this page. Just remember that feeling when the time comes that you too need a little red cube, and it will be waiting with love and compassion. A companion cube, if you will.</p>","url":"https://hackersandslackers.com/using-redis-with-python/","uuid":"fcf41325-f7d3-4f3f-b43f-8609e5dc6b07","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c307c9493bed0776a0a3d80"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673758","title":"Complex Features in MongoDB Cloud: Add Image Tags with AI","slug":"complex-features-in-mongodb-cloud","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/mongowebhooks@2x.jpg","excerpt":"Using functions, webhooks, and values to utilize external APIs.","custom_excerpt":"Using functions, webhooks, and values to utilize external APIs.","created_at_pretty":"12 December, 2018","published_at_pretty":"14 December, 2018","updated_at_pretty":"01 January, 2019","created_at":"2018-12-12T18:26:09.000-05:00","published_at":"2018-12-14T08:00:00.000-05:00","updated_at":"2019-01-01T09:36:10.000-05:00","meta_title":"Building Complex Features in MongoDB Cloud | Hackers and Slackers","meta_description":"Using functions, webhooks, and values to utilize external APIs. Today’s challenge: auto-tagging images using AI.","og_description":"Using functions, webhooks, and values to utilize external APIs. Today’s challenge: auto-tagging images using AI.","og_image":"https://hackersandslackers.com/content/images/2018/12/mongowebhooks@2x.jpg","og_title":"Complex Features in MongoDB Cloud: Add Image Tags with AI","twitter_description":"Using functions, webhooks, and values to utilize external APIs. Today’s challenge: auto-tagging images using AI.","twitter_image":"https://hackersandslackers.com/content/images/2018/12/mongowebhooks@2x.jpg","twitter_title":"Complex Features in MongoDB Cloud: Add Image Tags with AI","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"Friends, family, and most importantly, strangers: I approach you today with a\ntale of renewed inspiration. After loudly broadcasting my own confusion and\nmediocre ability to actually implement an effective cloud via MongoDB Stitch, my\nineptitude has been answered with an early Christmas gift. \n\nMy incessant complaining gained some acknowledgement from a couple of folks over\nat MongoDB. Perhaps the timing is simply by chance, but since then I've begun\nnoticing something some subtleties in the Stitch documentation; namely that if\nyou look hard enough, some of it begins to make sense. Either way, I'm chalking\nthis one up as a Christmas Miracle.\n\nLet's Automate Stuff: More Webhooks, Less Labor\nTo demonstrate what building an end-to-end sexy feature looks like in MongoDB\nStitch, I'm going to borrow some help from some old friends: the team behind \nClarifai. \n\nClarifai is one of the early players in the field of what I'm sure we'll\ncreatively refer to as AI as a service. More specifically, they provide an API\nfor image recognition which returns impressive metadata simply by passing an\nimage URL. Best part is, unless you're abusing the shit out of 5000 requests per\nmonth, the API is essentially free:\n\nPredict\n Search\n Custom Model Training\n Add or Edit Input Images\n 5,000  free operations\n 5,000  free operations\n 5,000  free operations\n 5,000  free operations\n Pre-Built Models: \n$1.20 / 1,000  operations\n\nCustom Models:\n$3.20 / 1,000  operations\n$1.20 / 1,000  operations\n $1.20 / 1,000  operations\n $1.20 / 1,000  operations\n If we were to try to fit any more instances of the words \"AI\" and \"Cloud\" into\nthis post, things could quickly derail into a shitty  IBM Watson commercial.\n\n(PS: Blockchain.)\n\nStoring Our Clarifai API Key\nIf you're following along, hit up Clarifai [https://clarifai.com/]  to grab your\nAPI key, no strings attached.\n\nAnd no, nobody is paying me to me to write about their SaaS products.Copy and\npaste your brand new key and head over to the MongoDB Stitch Console\n[https://stitch.mongodb.com]. In our Stitch project, we're going to store our\nkey as a value (you might recall this as being a convenient way to store\nsecrets).\n\nCopy and paste your key as a string in a new value. The only catch is we'll be\nformatting our key as Key #####################, simply because this is the\nformat the API expects to receive when we pass our key as a header to the\nClarifai API.\n\nWarning: Mild Architecting Ahead\nBefore going too far into code, let's recap how this functionality will probably\nwork.\n\nIn our actual application, we'll be identifying images needing alt  tags (either\nvia frontend or backend logic). At that point, we should find the src  attribute\nof said <img>  tags and pass it to a Stitch function; preferably one that makes\na post request to Clarifai. \n\nThis is in fact too simple to be true, as there is one gotcha: Stitch functions \ncannot make http requests on their own. They can,  however, invoke Stitch \nWebhooks. These webhooks share nearly identical syntax and structure to \nfunctions, with a few exceptions:\n\n * Webhooks have endpoints (duh).\n * They have explicit inbound/outbound rules restricting what can invoke them.\n * There are options to set authorization via key or otherwise.\n\nWith all that in mind, our end-to-end flow will end up looking something like\nthis:\n\n 1. Our application identifies an image needing tags an invokes a serverless \n    function.\n 2. The function  constructs the body of the request we'll be making to Clarifai \n     with containing the URL of the image.\n 3. As crazy as it sounds, we then POST to a Stitch endpoint, which in turns\n    makes the actual  POST request to Clarifai. The request is made with the\n    body passed from our function, as well as the API key we stored earlier.\n 4. We'll receive a response of tags which we can do something with on the\n    application-side.\n\nWriting our Function\nWe'll start by writing a simple function as our go-between for our app and our\nservice:\n\nexports = function(img){\n   const http = context.services.get(\"GetClarifaiTags\");\n   var data = {\n        \"inputs\": [\n          {\n            \"data\": {\n              \"image\": {\n                \"url\": img\n              }\n            }\n          }\n        ]\n      };\n      \n    var header_data = {\"Content-Type\": [ \"application/json\" ]};\n   \n    return http.post({\n        url: \"https://webhooks.mongodb-stitch.com/api/client/v2.0/app/hackers-uangn/service/GetClarifaiTags/incoming_webhook/GetTagsForNewImage\",\n        headers: header_data,\n        body: JSON.stringify(data)\n      })\n      .then(response => {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n\n\nThe first thing we do is reference our webhook (which we haven't created yet)\nwith this line:\n\nconst http = context.services.get(\"GetClarifaiTags\");\n\n\nIn the context of a function, context.services.get()  allows us to reference and\ninteract with other services we've created in Stitch. It's important to note\nthat we pass the user-created name of service we want to interact with. This is\none of the reasons why Stitch's documentation is so confusing - they\nconsistently use \"http\"  as an example service name. This seems to imply that\nwe'd want to import a type  of service as opposed to an instance  of a service,\nwhich is wrong.  \n\ndata  is the body of our request, which abides by Clarifai's documentation on\nhow to user their predict API. We need to pass this as a string to our webhook,\nthus we use JSON.stringify(data).\n\nIt's also important to note the structure of Mongo's headers when making\nrequests; notice that the value of each key pair is a list, as exemplified by \n\"Content-Type\": [ \"application/json\" ].\n\nAs you might imagine, these things in combination can cause a whole lot of\nconfusion. Hopefully you know a good blog to point these things out to you\nbeforehand.\n\nCreate a Webhook via 'HTTP Services'\nMove into the \"Services\" tab to create our webhook. Select HTTP  from the list\nof options:\n\nKind of a weird mix of services imho.Set your webhook to be a POST request.\nAuthentication shouldn't be a problem for us since we're only exposing this hook\nto our function, plus there are other ways to handle this.\n\nTIP: Don't post screenshots of sensitive endpoint URLs on the internet.The\nsyntax and methods available for writing a webhook are almost exactly the same\nas when writing regular functions. The one thing to note would be the presence\nof payload  being passed into the function; this object contains both the\nparameters and the body of requests being received by this endpoint. \npayload.body  gives us the body, whereas payload.query.arg  will give us the\nparameters.\n\nexports = function(payload){\n  const http = context.services.get(\"GetClarifaiTags\");\n  const token = context.values.get(\"clarifai_key\");\n  \n  var data = {};\n  if (payload.body) {\n    data = payload.body;\n  }\n  var header_data = {\n    \"Authorization\": [token], \n    \"Content-Type\": [\"application/json\"]\n  };\n\n    return http.post({\n        url: \"https://api.clarifai.com/v2/models/aaa03c23b3724a16a56b629203edc62c/versions/aa7f35c01e0642fda5cf400f543e7c40/outputs\",\n        body: data,\n        headers: header_data\n      })\n      .then(response => {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n\n\nJust as we can access services within functions, we can similarly access values\nvia context.values.get(\"myValue\").\n\nNow that we have both the body and our API key ready, we can actually go ahead\nand construct a valid request to Clarifai. The syntax should be\nself-explanatory, but here's the Stitch http service documentation\n[https://docs.mongodb.com/stitch/services/http-actions/http.post/]  just in\ncase.\n\nWhy Did we Have to Make a Weird Webhook which is both Receiving and Posting\nInformation?\nThis is an excellent question and served to be a huge source of confusion for\nwhat must have been months. Go back to the \"Services\" tab, and pay close\nattention: for each service we create, a set of Rules  are automatically created\nand attached to our service. HTTP services have all functionality disabled room\ndefault, with little to no mention of the existence of rules in the first place. \n This is important for two reasons:\n\n 1. It's a silly UI hiccup that can waste the majority of your waking life.\n 2. This means that only  services can do things like post to external APIs.\n    This is why we didn't simply keep our logic in one function.\n\nOur Workflow in Practice\nAssuming you've added some logic to your app to pick out image URLs needing\ntags, our chain of events should be complete and return results to our\napplication. The POST request we make will return a response to the POST request\nof our function, and our function will return the results to our application.\nWe've successfully created a complex, albeit confusing, cloud architecture or\nexternal services.\n\nThis is where your imagination should hopefully kick in. You'll notice I have a\nfew services such as the endpoints which receive updates every time a JIRA issue\nis created or updated. This is what powers our public-facing kanban board.\n[https://hackersandslackers.com/projects/]","html":"<p>Friends, family, and most importantly, strangers: I approach you today with a tale of renewed inspiration. After loudly broadcasting my own confusion and mediocre ability to actually implement an effective cloud via MongoDB Stitch, my ineptitude has been answered with an early Christmas gift. </p><p>My incessant complaining gained some acknowledgement from a couple of folks over at MongoDB. Perhaps the timing is simply by chance, but since then I've begun noticing something some subtleties in the Stitch documentation; namely that if you look hard enough, some of it begins to make sense. Either way, I'm chalking this one up as a Christmas Miracle.</p><h2 id=\"let-s-automate-stuff-more-webhooks-less-labor\">Let's Automate Stuff: More Webhooks, Less Labor</h2><p>To demonstrate what building an end-to-end sexy feature looks like in MongoDB Stitch, I'm going to borrow some help from some old friends: the team behind <strong>Clarifai</strong>. </p><p>Clarifai is one of the early players in the field of what I'm sure we'll creatively refer to as <em>AI as a service. </em>More specifically, they provide an API for image recognition which returns impressive metadata simply by passing an image URL. Best part is, unless you're abusing the shit out of 5000 requests per month, the API is essentially free:</p><style>\n    table td {\n        text-align:left;\n        font-size: .95em;\n    }\n</style>\n\n<div class=\"tableContainer\">\n  <table>\n    <thead>\n      <th>Predict</th>\n      <th>Search</th>\n      <th>Custom Model Training</th>\n      <th>Add or Edit Input Images</th>\n    </thead>\n    <tbody>\n      <tr>\n        <td><strong>5,000</strong> free operations</td>\n        <td><strong>5,000</strong> free operations</td>\n        <td><strong>5,000</strong> free operations</td>\n        <td><strong>5,000</strong> free operations</td>\n      </tr>\n      <tr>\n        <td>\n          <strong>Pre-Built Models: </strong><br>\n          <small><strong>$1.20 / 1,000</strong> operations</small><br><br>\n          <strong>Custom Models:</strong><br>\n          <small><strong>$3.20 / 1,000</strong> operations</small><br>\n        </td>\n        <td><strong>$1.20 / 1,000</strong> operations</td>\n        <td><strong>$1.20 / 1,000</strong> operations</td>\n        <td><strong>$1.20 / 1,000</strong> operations</td>\n      </tr>\n    </tbody>\n  </table>\n</div>\n<p>If we were to try to fit any more instances of the words \"AI\" and \"Cloud\" into this post, things could quickly derail into a shitty  IBM Watson commercial.</p><p><em>(PS: Blockchain.)</em></p><h2 id=\"storing-our-clarifai-api-key\">Storing Our Clarifai API Key</h2><p>If you're following along, hit up <a href=\"https://clarifai.com/\">Clarifai</a> to grab your API key, no strings attached.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/clarifaiapi_o.png\" class=\"kg-image\"><figcaption>And no, nobody is paying me to me to write about their SaaS products.</figcaption></figure><p>Copy and paste your brand new key and head over to the <a href=\"https://stitch.mongodb.com\">MongoDB Stitch Console</a>. In our Stitch project, we're going to store our key as a <strong>value </strong>(you might recall this as being a convenient way to store secrets).</p><p>Copy and paste your key as a string in a new value. The only catch is we'll be formatting our key as <code>Key #####################</code>, simply because this is the format the API expects to receive when we pass our key as a header to the Clarifai API.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/mongovalues_o-1.png\" class=\"kg-image\"></figure><h2 id=\"warning-mild-architecting-ahead\">Warning: Mild Architecting Ahead</h2><p>Before going too far into code, let's recap how this functionality will probably work.</p><p>In our actual application, we'll be identifying images needing <code>alt</code> tags (either via frontend or backend logic). At that point, we should find the <code>src</code> attribute of said <code>&lt;img&gt;</code> tags and pass it to a Stitch function; preferably one that makes a post request to <strong>Clarifai</strong>. </p><p>This is in fact too simple to be true, as there is one gotcha: Stitch <strong>functions</strong> cannot make http requests on their own. They <em>can,</em> however, invoke Stitch <strong>Webhooks. </strong>These webhooks share nearly identical syntax and structure to <strong>functions</strong>, with a few exceptions:</p><ul><li>Webhooks have endpoints (duh).</li><li>They have explicit inbound/outbound rules restricting what can invoke them.</li><li>There are options to set authorization via key or otherwise.</li></ul><p>With all that in mind, our end-to-end flow will end up looking something like this:</p><ol><li>Our application identifies an image needing tags an invokes a serverless <strong>function.</strong></li><li>The <strong>function</strong> constructs the body of the request we'll be making to <strong>Clarifai</strong> with containing the URL of the image.</li><li>As crazy as it sounds, we then POST to a Stitch endpoint, which in turns makes the <em>actual</em> POST request to Clarifai. The request is made with the body passed from our function, as well as the API key we stored earlier.</li><li>We'll receive a response of tags which we can do something with on the application-side.</li></ol><h2 id=\"writing-our-function\">Writing our Function</h2><p>We'll start by writing a simple function as our go-between for our app and our service:</p><pre><code class=\"language-javascript\">exports = function(img){\n   const http = context.services.get(&quot;GetClarifaiTags&quot;);\n   var data = {\n        &quot;inputs&quot;: [\n          {\n            &quot;data&quot;: {\n              &quot;image&quot;: {\n                &quot;url&quot;: img\n              }\n            }\n          }\n        ]\n      };\n      \n    var header_data = {&quot;Content-Type&quot;: [ &quot;application/json&quot; ]};\n   \n    return http.post({\n        url: &quot;https://webhooks.mongodb-stitch.com/api/client/v2.0/app/hackers-uangn/service/GetClarifaiTags/incoming_webhook/GetTagsForNewImage&quot;,\n        headers: header_data,\n        body: JSON.stringify(data)\n      })\n      .then(response =&gt; {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n</code></pre>\n<p>The first thing we do is reference our webhook (which we haven't created yet) with this line:</p><pre><code class=\"language-javascript\">const http = context.services.get(&quot;GetClarifaiTags&quot;);\n</code></pre>\n<p>In the context of a function, <code>context.services.get()</code> allows us to reference and interact with other services we've created in Stitch. It's important to note that we pass <strong>the user-created name of service </strong>we want to interact with. This is one of the reasons why Stitch's documentation is so confusing - they consistently use <em>\"http\"</em> as an example service name. This seems to imply that we'd want to import a <em>type</em> of service as opposed to an <em>instance</em> of a service, which is <strong>wrong.</strong> </p><p><code>data</code> is the body of our request, which abides by <a href=\"https://clarifai.com/developer/guide/predict#predict\">Clarifai's documentation on how to user their <em>predict</em> API</a>. We need to pass this as a string to our webhook, thus we use <code>JSON.stringify(data)</code>.</p><p>It's also important to note the structure of Mongo's headers when making requests; notice that the value of each key pair is a <strong>list, </strong>as exemplified by <code>\"Content-Type\": [ \"application/json\" ]</code>.</p><p>As you might imagine, these things in combination can cause a whole lot of confusion. Hopefully you know a good blog to point these things out to you beforehand.</p><h2 id=\"create-a-webhook-via-http-services-\">Create a Webhook via 'HTTP Services'</h2><p>Move into the \"Services\" tab to create our webhook. Select <strong>HTTP</strong> from the list of options:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/mongoservices.png\" class=\"kg-image\"><figcaption>Kind of a weird mix of services imho.</figcaption></figure><p>Set your webhook to be a POST request. Authentication shouldn't be a problem for us since we're only exposing this hook to our function, plus there are other ways to handle this.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-12-13-at-4.23.27-PM_o.png\" class=\"kg-image\"><figcaption>TIP: Don't post screenshots of sensitive endpoint URLs on the internet.</figcaption></figure><p>The syntax and methods available for writing a webhook are almost exactly the same as when writing regular functions. The one thing to note would be the presence of <strong>payload</strong> being passed into the function; this object contains <em><strong>both the parameters and the body </strong></em>of requests being received by this endpoint. <code>payload.body</code> gives us the body, whereas <code>payload.query.arg</code> will give us the parameters.</p><pre><code class=\"language-javascript\">exports = function(payload){\n  const http = context.services.get(&quot;GetClarifaiTags&quot;);\n  const token = context.values.get(&quot;clarifai_key&quot;);\n  \n  var data = {};\n  if (payload.body) {\n    data = payload.body;\n  }\n  var header_data = {\n    &quot;Authorization&quot;: [token], \n    &quot;Content-Type&quot;: [&quot;application/json&quot;]\n  };\n\n    return http.post({\n        url: &quot;https://api.clarifai.com/v2/models/aaa03c23b3724a16a56b629203edc62c/versions/aa7f35c01e0642fda5cf400f543e7c40/outputs&quot;,\n        body: data,\n        headers: header_data\n      })\n      .then(response =&gt; {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n</code></pre>\n<p>Just as we can access services within functions, we can similarly access values via <code>context.values.get(\"myValue\")</code>.</p><p>Now that we have both the body and our API key ready, we can actually go ahead and construct a valid request to Clarifai. The syntax should be self-explanatory, but here's the <a href=\"https://docs.mongodb.com/stitch/services/http-actions/http.post/\">Stitch http service documentation</a> just in case.</p><h3 id=\"why-did-we-have-to-make-a-weird-webhook-which-is-both-receiving-and-posting-information\">Why Did we Have to Make a Weird Webhook which is both Receiving and Posting Information?</h3><p>This is an excellent question and served to be a huge source of confusion for what must have been months. Go back to the \"Services\" tab, and pay close attention: for each service we create, a set of <strong>Rules</strong> are automatically created and attached to our service. <strong>HTTP services have all functionality disabled room default, with little to no mention of the existence of rules in the first place.</strong> This is important for two reasons:</p><ol><li>It's a silly UI hiccup that can waste the majority of your waking life.</li><li>This means that <em>only</em> services can do things like post to external APIs. This is why we didn't simply keep our logic in one function.</li></ol><h2 id=\"our-workflow-in-practice\">Our Workflow in Practice</h2><p>Assuming you've added some logic to your app to pick out image URLs needing tags, our chain of events should be complete and return results to our application. The POST request we make will return a response to the POST request of our function, and our function will return the results to our application. We've successfully created a complex, albeit confusing, cloud architecture or external services.</p><p>This is where your imagination should hopefully kick in. You'll notice I have a few services such as the endpoints which receive updates every time a <strong>JIRA </strong>issue is created or updated. This is what powers our <a href=\"https://hackersandslackers.com/projects/\">public-facing kanban board.</a></p>","url":"https://hackersandslackers.com/complex-features-in-mongodb-cloud/","uuid":"91acc3b3-88c2-4313-aedd-adf1eac1dc36","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c1199114b9896120b3c1b34"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c9","title":"MongoDB Stitch Serverless Functions","slug":"mongodb-stitch-serverless-functions","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/stitch3@2x.jpg","excerpt":"A crash course in MongoDB Stitch serverless functions: the bread and butter of MongoDB Cloud.","custom_excerpt":"A crash course in MongoDB Stitch serverless functions: the bread and butter of MongoDB Cloud.","created_at_pretty":"06 August, 2018","published_at_pretty":"26 November, 2018","updated_at_pretty":"05 April, 2019","created_at":"2018-08-06T19:35:37.000-04:00","published_at":"2018-11-26T08:00:00.000-05:00","updated_at":"2019-04-04T21:42:58.000-04:00","meta_title":"Using Serverless Functions in MongoDB Stitch  | Hackers And Slackers","meta_description":"You have a database, and you want to get data out of it. MongoDB Stitch can achieve this without building an API and can do it securely via frontend code.","og_description":"A crash course in MongoDB Stitch serverless functions: the bread and butter of MongoDB Cloud.\n","og_image":"https://hackersandslackers.com/content/images/2018/08/stitch3@2x.jpg","og_title":"MongoDB Stitch Serverless Functions","twitter_description":"A crash course in MongoDB Stitch serverless functions: the bread and butter of MongoDB Cloud.\n","twitter_image":"https://hackersandslackers.com/content/images/2018/08/stitch3@2x.jpg","twitter_title":"MongoDB Stitch Serverless Functions","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"At times, I've found my opinion of MongoDB Atlas  and MongoDB Stitch  to waver\nbetween two extremes. Sometimes I'm struck by the allure of a cloud which\nfundamentally disregards schemas (wooo no schema party!). Other times, such as\nwhen Mongo decides to upgrade to a new version and you find all your production\ninstances broken, I like the ecosystem a bit less. \n\nMy biggest qualm with MongoDB is poor documentation. The \"tutorials\" and sample\ncode seems hacked-together, unmaintained, and worst of all, inconsistent with\nitself. Reading through the docs seems to always end up with Mongo forcing\nTwilio down my throat my for some miserable reason. \n\nJust to illustrate how bad things can get, below are two totally sets of\ndocumentation for what is supposed to be the same product. Mongo's main\ndocumentation on the left frequently references the bastardized documentation on\nthe right. What is the documentation on the right? It's a collection of\nnonsense\nliving on an S3 bucket\n[https://s3.amazonaws.com/stitch-sdks/js/docs/4.0.0/index.html]  which lists the\nmethods black-boxed into Stitch, often with zero explanation on how to actually\nutilize functionality.\n\nWhich one is real? And WHY?!How frustrating is this? I've had email user\nauthentication \"working\" for weeks as far as Stitch's logs say, although not a\nsingle user has actually been registered in that time. Anyways, I digress.\n\nMaking a Serverless Function\nStitch Serverless functions are of course strictly Javascript (MongoDB abides by\nECMA2015 features). In your Stitch console, check out the \"functions\" link in\nthe left hand nav:\n\nGo ahead and create a new function.There are just a few things we need to\nspecify when creating a new function:\n\n * The name of the function (duh).\n * Whether or not the function can be accessed \"publicly\". A \"Private\" function\n   is the equivalent of a function that only accessible to the VPC it belongs to\n   (although technically MongoDB Cloud doesn't use this terminology).\n * A condition which needs to be met in order for the function to execute.\n\nHere's a screenshot of everything we just went over. Because whatever.Switch\nover to the function editor to start really F*&king Sh!t up.\n\nMongo's Serverless Function Editor\nWe can call a Serverless function in a number of ways, with one of those ways\nbeing directly from our frontend code. In this case, we're basically just taking\na Javascript function which could  live in our frontend codebase and moving it\nto the cloud, thus functions can be passed any number of arguments (just like a\nnormal function).\n\nLuckily for us, Mongo provides some commented out boilerplate code when creating\na new function, which gives us an idea of what we might want to use these\nfunctions for:\n\nexports = function(arg){\n  /*\n    Accessing application's values:\n    var x = context.values.get(\"value_name\");\n\n    Accessing a mongodb service:\n    var collection = context.services.get(\"mongodb-atlas\").db(\"dbname\").collection(\"coll_name\");\n    var doc = collection.findOne({owner_id: context.user.id});\n\n    To call other named functions:\n    var result = context.functions.execute(\"function_name\", arg1, arg2);\n\n    Try running in the console below.\n  */\n  return {arg: arg};\n};\n\n\nPay special attention to context.services  here. When using a serverless\nfunction to access MongoDB services such as our database or endpoints, we can\naccess these via context.services  along with whichever service we're trying to\nmess with.\n\nQuerying our Database Within a Function\nLet's grab a single record from a collection in our Atlas collection:\n\nexports = function(arg){\n      const mongodb = context.services.get(\"mongodb-atlas\");\n      const collection = mongodb.db(\"blog\").collection(\"authors\");\n      var result = collection.findOne({\"author\": arg});\n      return result;\n};\n\n\nWe use findOne here to return an object, whereas we'd probably use toArray  if\nwe'd be expecting multiple results. The query we're running is contained within \nfindOne({\"author\": arg}). Our function takes an argument and returns a record\nwhere the value matches the argument: this makes our functions highly reusable,\nof course.\n\nCalling Our Function via Our App\nAs a recap, you have the option of including Stitch in your app either via a\nlink to a script or by installing the appropriate NPM modules. It's preferable\nto do the latter, but for the sake of this post, my patience with dealing with\nJavascript's babel browserify webpack gulp yarn npm requires package-lock .env\npipify facepunch  ecosystem has reached its limit. \n\nFeel free to follow in my footsteps of worst practices by embedding stitch\ndirectly:\n\n<script src=\"https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js\"></script>\n\n\nAuthenticating Before Calling Functions\nBefore making queries or interacting with any serverless functions of any kind,\nwe need to authenticate a 'user' with the server; even if that user is an\nanonymous one (it's in our own best benefit to know which user crashed the\nserver, even if that 'users' is a random string of numbers). Because we allowed\nanonymous users to peruse through our data, this is easy:\n\n// Authenticates anonymous user\nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => {\n  console.log('logged in anonymously as user')\n});\n\n\nCalling our Function\nNow that that's done, we can call our function immediately after:\n\n// Authenticates anonymous user\nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => {\n  console.log('logged in anonymously as user')\n});\n\n// Calls function\nclient.callFunction(\"getUsers\", [\"{{author}}\"]).then(result => {\n  console.log(result)\n});\n\n\nOur function is called get users  and we're passing a single parameter of \n{{author}}. Even though one parameter is being passed, we pass parameters as\nlists as Mongo Serverless functions, as these functions are agnostic to what\nmight be coming their way.\n\nUsing Functions to Grab Stored Values\nLet's look at one more use case where calling a Stitch Serverless function might\ncome in handy.\n\nBack in the Stitch UI, check out the \"values\" tab in the left-hand nav. This is\na place where we can store constant values which should accessible through our\napplication, or even a place to retrieve secrets:\n\n2secret4uValues can only be retrieved by functions, and this would be a good\ntime to ensure those particular functions are marked \"private\" For instance, if\nyou have an API call you need to make, It would be best to create a function\nthat handles the logic of that API call, and within that function, invoke\nanother private function whose job it is simply to retrieve the key in question.\nMake sense?  Ah well, you'll figure it out.\n\nMaking a Serverless Function that Does Something\nAnyway, let's apply our knowledge of functions to actually do something. On our\nsite we currently use a third party Medium widget which fetches stories from a\nuser's Medium account. Here's how that would look in its entirety:\n\n<script src=\"https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js\"></script>\n\n<script src=\"https://medium-widget.pixelpoint.io/widget.js\"></script>\n\n<script>\nfunction createMediumCard(medium){\n  console.log('medium= ' + medium);\n  MediumWidget.Init({\n    renderTo: '#medium-widget',\n    params: {\n      \"resource\": 'https://medium.com/' + medium,\n      \"postsPerLine\": 1,\n      \"limit\": 3,\n      \"picture\": \"small\",\n      \"fields\": [\"description\", \"publishAt\"],\n      \"ratio\": \"square\"\n    }\n  })\n  $('#medium').css('display', 'block');\n}\n    \nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => {\n  console.log('logged in anonymously as user')\n});\n    \nclient.callFunction(\"getUsers\", [\"{{author}}\"]).then(result => {\n  console.log(result)\n});\n</script>\n\n\nNormally, \"resource\": medium,  would actually read the URL of the Medium profile\nwe're trying to embed. However, when you blog on a platform like Ghost which\nonly allows your authors to have either Facebook or Twitter profiles, we need to\nessentially go out of our way to build a second, nonintrusive database to pull\ndata from to add functionality like this. Yeah - I'll have to show you what MY\n\"stack\" looks like for a single blog theme some day. It's ridiculous.\n\nAnyway, that’s all I’ve got for now. I hope these ramblings help you assess\nMongoDB Cloud for yourself. No matter the provider, Enterprise Clouds target fat\nbudgets and are designed to rake in big money. It almost makes you wonder why\nsomebody would pay out of pocket for three of them just to write a stupid blog.","html":"<p>At times, I've found my opinion of <strong>MongoDB Atlas</strong> and <strong>MongoDB Stitch</strong> to waver between two extremes. Sometimes I'm struck by the allure of a cloud which fundamentally disregards schemas (wooo no schema party!). Other times, such as when Mongo decides to upgrade to a new version and you find all your production instances broken, I like the ecosystem a bit less. </p><p><strong>My biggest qualm with MongoDB is poor documentation. </strong>The \"tutorials\" and sample code seems hacked-together, unmaintained, and worst of all, inconsistent with itself. Reading through the docs seems to always end up with Mongo forcing Twilio down my throat my for some miserable reason. </p><p>Just to illustrate how bad things can get, below are two totally sets of documentation for what is supposed to be the same product. Mongo's main documentation on the left frequently references the bastardized documentation on the right. What is the documentation on the right? It's a <a href=\"https://s3.amazonaws.com/stitch-sdks/js/docs/4.0.0/index.html\">collection of nonsense living on an S3 bucket</a> which lists the methods black-boxed into Stitch, often with zero explanation on how to actually utilize functionality.</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/mongodocs.jpg\" class=\"kg-image\"><figcaption>Which one is real? And WHY?!</figcaption></figure><!--kg-card-end: image--><p>How frustrating is this? I've had email user authentication \"working\" for weeks as far as Stitch's logs say, although not a single user has actually been registered in that time. Anyways, I digress.</p><h2 id=\"making-a-serverless-function\">Making a Serverless Function</h2><p>Stitch Serverless functions are of course strictly Javascript (MongoDB abides by ECMA2015 features). In your Stitch console, check out the \"functions\" link in the left hand nav:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-25-at-10.28.24-PM.png\" class=\"kg-image\"><figcaption>Go ahead and create a new function.</figcaption></figure><!--kg-card-end: image--><p>There are just a few things we need to specify when creating a new function:</p><ul><li>The name of the function (duh).</li><li>Whether or not the function can be accessed \"publicly\". A \"Private\" function is the equivalent of a function that only accessible to the VPC it belongs to (although technically MongoDB Cloud doesn't use this terminology).</li><li>A condition which needs to be met in order for the function to execute.</li></ul><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-25-at-10.31.05-PM_o.png\" class=\"kg-image\"><figcaption>Here's a screenshot of everything we just went over. Because whatever.</figcaption></figure><!--kg-card-end: image--><p>Switch over to the function editor to start really F*&amp;king Sh!t up.</p><h2 id=\"mongo-s-serverless-function-editor\">Mongo's Serverless Function Editor</h2><p>We can call a Serverless function in a number of ways, with one of those ways being directly from our frontend code. In this case, we're basically just taking a Javascript function which <em>could</em> live in our frontend codebase and moving it to the cloud, thus functions can be passed any number of arguments (just like a normal function).</p><p>Luckily for us, Mongo provides some commented out boilerplate code when creating a new function, which gives us an idea of what we might want to use these functions for:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">exports = function(arg){\n  /*\n    Accessing application's values:\n    var x = context.values.get(&quot;value_name&quot;);\n\n    Accessing a mongodb service:\n    var collection = context.services.get(&quot;mongodb-atlas&quot;).db(&quot;dbname&quot;).collection(&quot;coll_name&quot;);\n    var doc = collection.findOne({owner_id: context.user.id});\n\n    To call other named functions:\n    var result = context.functions.execute(&quot;function_name&quot;, arg1, arg2);\n\n    Try running in the console below.\n  */\n  return {arg: arg};\n};\n</code></pre>\n<!--kg-card-end: markdown--><p>Pay special attention to <code>context.services</code> here. When using a serverless function to access MongoDB services such as our database or endpoints, we can access these via <code>context.services</code> along with whichever service we're trying to mess with.</p><h3 id=\"querying-our-database-within-a-function\">Querying our Database Within a Function</h3><p>Let's grab a single record from a collection in our Atlas collection:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">exports = function(arg){\n      const mongodb = context.services.get(&quot;mongodb-atlas&quot;);\n      const collection = mongodb.db(&quot;blog&quot;).collection(&quot;authors&quot;);\n      var result = collection.findOne({&quot;author&quot;: arg});\n      return result;\n};\n</code></pre>\n<!--kg-card-end: markdown--><p>We use <strong>findOne </strong>here to return an object, whereas we'd probably use <strong>toArray</strong> if we'd be expecting multiple results. The query we're running is contained within <code>findOne({\"author\": arg})</code>. Our function takes an argument and returns a record where the value matches the argument: this makes our functions highly reusable, of course.</p><h2 id=\"calling-our-function-via-our-app\">Calling Our Function via Our App</h2><p>As a recap, you have the option of including Stitch in your app either via a link to a script or by installing the appropriate NPM modules. It's preferable to do the latter, but for the sake of this post, my patience with dealing with Javascript's <strong>babel browserify webpack gulp yarn npm requires package-lock .env pipify facepunch</strong> ecosystem has reached its limit. </p><p>Feel free to follow in my footsteps of worst practices by embedding stitch directly:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">&lt;script src=&quot;https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js&quot;&gt;&lt;/script&gt;\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"authenticating-before-calling-functions\">Authenticating Before Calling Functions</h3><p>Before making queries or interacting with any serverless functions of any kind, we need to authenticate a 'user' with the server; even if that user is an anonymous one (it's in our own best benefit to know which user crashed the server, even if that 'users' is a random string of numbers). Because we allowed anonymous users to peruse through our data, this is easy:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">// Authenticates anonymous user\nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; {\n  console.log('logged in anonymously as user')\n});\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"calling-our-function\">Calling our Function</h3><p>Now that that's done, we can call our function immediately after:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">// Authenticates anonymous user\nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; {\n  console.log('logged in anonymously as user')\n});\n\n// Calls function\nclient.callFunction(&quot;getUsers&quot;, [&quot;{{author}}&quot;]).then(result =&gt; {\n  console.log(result)\n});\n</code></pre>\n<!--kg-card-end: markdown--><p>Our function is called <code>get users</code> and we're passing a single parameter of <code>{{author}}</code>. Even though one parameter is being passed, we pass parameters as lists as Mongo Serverless functions, as these functions are agnostic to what might be coming their way.</p><h2 id=\"using-functions-to-grab-stored-values\">Using Functions to Grab Stored Values</h2><p>Let's look at one more use case where calling a Stitch Serverless function might come in handy.</p><p>Back in the Stitch UI, check out the \"values\" tab in the left-hand nav. This is a place where we can store constant values which should accessible through our application, or even a place to retrieve secrets:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-26-at-8.04.25-AM_o.png\" class=\"kg-image\"><figcaption>2secret4u</figcaption></figure><!--kg-card-end: image--><p>Values can only be retrieved by functions, and this would be a good time to ensure those particular functions are marked \"private\" For instance, if you have an API call you need to make, It would be best to create a function that handles the logic of that API call, and within that function, invoke another private function whose job it is simply to retrieve the key in question. Make sense?  Ah well, you'll figure it out.</p><h2 id=\"making-a-serverless-function-that-does-something\">Making a Serverless Function that Does Something</h2><p>Anyway, let's apply our knowledge of functions to actually do something. On our site we currently use a third party Medium widget which fetches stories from a user's Medium account. Here's how that would look in its entirety:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">&lt;script src=&quot;https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js&quot;&gt;&lt;/script&gt;\n\n&lt;script src=&quot;https://medium-widget.pixelpoint.io/widget.js&quot;&gt;&lt;/script&gt;\n\n&lt;script&gt;\nfunction createMediumCard(medium){\n  console.log('medium= ' + medium);\n  MediumWidget.Init({\n    renderTo: '#medium-widget',\n    params: {\n      &quot;resource&quot;: 'https://medium.com/' + medium,\n      &quot;postsPerLine&quot;: 1,\n      &quot;limit&quot;: 3,\n      &quot;picture&quot;: &quot;small&quot;,\n      &quot;fields&quot;: [&quot;description&quot;, &quot;publishAt&quot;],\n      &quot;ratio&quot;: &quot;square&quot;\n    }\n  })\n  $('#medium').css('display', 'block');\n}\n    \nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; {\n  console.log('logged in anonymously as user')\n});\n    \nclient.callFunction(&quot;getUsers&quot;, [&quot;{{author}}&quot;]).then(result =&gt; {\n  console.log(result)\n});\n&lt;/script&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>Normally, <code>\"resource\": medium,</code> would actually read the URL of the Medium profile we're trying to embed. However, when you blog on a platform like Ghost which only allows your authors to have either Facebook or Twitter profiles, we need to essentially go out of our way to build a second, nonintrusive database to pull data from to add functionality like this. Yeah - I'll have to show you what MY \"stack\" looks like for a single blog theme some day. It's ridiculous.</p><p>Anyway, that’s all I’ve got for now. I hope these ramblings help you assess MongoDB Cloud for yourself. No matter the provider, Enterprise Clouds target fat budgets and are designed to rake in big money. It almost makes you wonder why somebody would pay out of pocket for three of them just to write a stupid blog.</p>","url":"https://hackersandslackers.com/mongodb-stitch-serverless-functions/","uuid":"96e26ca1-02d4-41d6-afa8-db92b2e9c171","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b68db4904d65d1246ebd1eb"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673665","title":"Stitch's “Query Anywhere”: Executing Business Logic via Frontend","slug":"mongodb-stitch-query-anywhere","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/06/stitch5@2x.jpg","excerpt":"MongoDB Stitch vs the impossible: secure database queries via frontend JS.","custom_excerpt":"MongoDB Stitch vs the impossible: secure database queries via frontend JS.","created_at_pretty":"02 June, 2018","published_at_pretty":"23 November, 2018","updated_at_pretty":"05 January, 2019","created_at":"2018-06-02T12:07:57.000-04:00","published_at":"2018-11-23T07:00:00.000-05:00","updated_at":"2019-01-04T21:09:07.000-05:00","meta_title":"MongoDB Stitch \"Query Anywhere\" | Hackers and Slackers","meta_description":"Use MongoDB Stitch to query databases via Frontend code.","og_description":"Use MongoDB Stitch to query databases via Frontend code.","og_image":"https://hackersandslackers.com/content/images/2018/06/stitch5@2x.jpg","og_title":"MongoDB Stitch \"Query Anywhere\"","twitter_description":"Use MongoDB Stitch to query databases via Frontend code.","twitter_image":"https://hackersandslackers.com/content/images/2018/06/stitch5@2x.jpg","twitter_title":"MongoDB Stitch \"Query Anywhere\"","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"Some tools are simply the right tool for the job. I imagine this must have been\nthe thinking behind the wave of JSON-like NoSQL databases at their peak, and\neven so today. If we figure we’ll be passing information as JSON to an endpoint,\nto then have it structured into a schema, only to be promptly broken down again\nfor our request seconds later, if you will, it’s fair to question the\ncost-benefit of schemas in some cases. A lot of those cases cover the apps we\nbuild for ourselves: ones that let us do stupid things like spamming selfies or\nfilling the internet with vast mindless thoughts.\n\nMongoDB Atlas  is a hell of product in its own right, being a cloud NoSQL\ndatabase with the ability to execute queries similar to SQL JOINs, countless\naggregations, and more possibilities to work into a pipeline than I’ve even had\ntime to explore (we’ll get there). If you’ve ever been tasked to build endpoints\nfor yourself, chances are you already appreciate side-stepping the manual\none-to-one key association that comes with passing JSON to Lambda Functions or\nwhat-have-you.\n\nTake our situation at Hackers And Slackers, for instance. We’re running a Ghost\nblog, which is a young piece of software built by a non-profit organization:\nthis software is constantly being updated and improved, which means if we want\nto modify the logic of our Node app at all, our choices are:\n\n 1. Modify the Ghost source and refuse future updates\n 2. Merge our custom backend with Ghost changes in the event of an update\n 3. Build a third-party API using a platform such as AWS\n\nMongoDB Stitch  gives us a new fourth option: extend our app without all the\nrepetitive boilerplate.  I say extend  because it empowers us to build on top of\nthings which were previously black-boxed to us, such developing a theme atop a\nblogging system.\n\nCarrying on the Legacy\nMongoDB Stitch extends the philosophy of avoiding repetition. In a similar way\nto how NoSQL removed a pain point for many developers, Stitch wants you to keep\ndoing what you do best, which is probably writing NodeJS apps. Forever.\n\nIf I worked for Mongo, I’d sell the product like this:\n\nMongoDB Stitch empowers you to build powerful features without ever switching\ngears to the menial aspects of development.What I’m really saying is that MongoDB Stitch  is Google Firebase. Both products\ntarget the frontend  and mobile  developer markets, and both are very young and\nearly in fully achieving this goal. I’m watching the MongoDB product video for\nthe first time, and it feels like what I’ve assumed from using the product\naligns with their sell (good job on their part, I suppose):\n\nAs warm and uppity as that video is, Mongo has been rather bashful about their\nCloud. I'm guessing that has something to do with an IPO.\n\nOn the other hand, Google Firebase  has been tooting its own horn loudly for a\nyoung product, with a level of growth which feels almost reckless at times (I\nwon't get into it):\n\nAnyway, we're not here to compare. We're here to judge.\n\nGetting Started with a New Database\nFeel free to follow along by setting up a free tier cluster\n[https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/]. \n\nProper Mongo accounts are managed at https://cloud.mongodb.com  once created.\nThis landing dash has plenty of useful info and stats regarding the cluster\nitself. We'll also need to be sure that a database exists before we crate any\napps, otherwise we'll just be interacting with nothing.\n\nI highly  suggest using the MongoDB Compass  desktop app to connect to your your\ncluster. It's easy to download, and even saves you the time of entering\ncredentials by connecting with a copy+pasted URI:\n\nConnect with your database; emotionally.Within Compass, simply create a database\nand collection:\n\nIn MongoWorld, \"collections\" are the equivalent of \"tables\".Let's Get Stitched\nWith all that out of the way, head back to your account on the Mongo Cloud. Now\nour interest is entirely in the Stitch Apps  link on the left side nav:\n\nThere’s so much to explore!Create and name a new Stitch application, and we'll\nland on the \"getting started\" page. \n\nEnable anonymous auth & point to your collectionOnce we create our app, Stitch\nimmediately throws us in to a quick 101 of how to interact with our database.\nWe're going to use the exact example that Stitch gives us; it's important to\nhave the \"A-ha\" moment where everything comes together. \n\nBefore getting to any code, the only two things we need to do are:\n\n 1. Enable Anonymous Authentication: This is fancy language for creating a user\n    type where anybody who accesses our app can make queries\n 2. Pointing to our Mongo Collection: We need somewhere to store the data we'll\n    be messing with.\n\nConnecting Your App\nWe're going to copy and paste this code on to a page of our app. Once this is\nlive, visit the page and keep an eye on the console:\n\n<script src=\"https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js\"></script>\n\n<script>\n  const clientPromise = stitch.StitchClientFactory.create('hackerjira-bzmfe');\n  clientPromise.then(client => {\n    const db = client.service('mongodb', 'mongodb-atlas').db('HackersBlog');\n    client.login().then(() =>\n      db.collection('jira').updateOne({owner_id: client.authedId()}, {$set:{number:42}}, {upsert:true})\n    ).then(()=>\n      db.collection('jira').find({owner_id: client.authedId()}).limit(100).execute()\n    ).then(docs => {\n      console.log(\"Found docs\", docs)\n      console.log(\"[MongoDB Stitch] Connected to Stitch\")\n    }).catch(err => {\n      console.error(err)\n    });\n  });\n</script>\n\n\nChecking this on the live sites looks like this:\n\nNote the \"docs\" found in the console on the right.It worked, but what exactly?\nThe first thing the snippet tells the database to do is to upsert a row where\n\"number\" is equal to 42:\n\ndb.collection('jira').updateOne({owner_id: client.authedId()}, {$set:{number:42}}, {upsert:true})\n\n\nFor sanity, let's check the database to see what's up:\n\nIs that… a new record?!?!Sure enough, a new entry has been added to our database\nin the collection we specified. That's fun and all, but what about our actual\ndata? Isn't that what we came here for? Consider the next line:\n\ndb.collection('jira').find({owner_id: client.authedId()}).limit(100).execute()\n\n\nAhhh, we’re querying based on entries only  created from the current user!\nBecause the sample code we pasted creates a record, we can then query the\ndatabase for records created by that user. Let’s not ignore how cool that is\nhaving not actually done any work: we already have logic in place to allow\nanonymous users to create records and recognize them based on their session.\n\n.find()  is our bread and butter for retrieving records, much like SQL SELECT.\nSo in theory, to show all issues from this collection we'd just need to run the\nfollowing, right?\n\ndb.collection('jira').find({}).execute()\n\n\nSlow down there, buddy- but yes, pretty much. We just need to make read\npermissions public on the MongoDB Stitch side first. Back in the Stitch UI,\nselect \"Rules\" from the sidebar. Here, we can modify the rules for who can\nread/write which records from which DB:\n\nIt's less complicated than it looks.We can create rules as advanced as we'd\nlike, but the rules we need right now are simple enough to handle purely via the\nUI.\n\nGet All The Records\nGo ahead and add a bunch of records to your database collection. Experiment with\nimporting data via JSON or CSV, or just add some records one-by-one.\n\nWhen that's done, go back to your app and see what .find({})  comes back with:\n\nNow that's a collection.There they are: every record from a database collection,\ngrabbed with a single line of code on our frontend. Feel free to take a moment\nto reflect on this: we didn’t need to create an API, write logic, or log in to\nany shitty IAM policy management UIs. We didn’t even need to write a query; the\n‘query’ in this case is just a JSON object.\n\nStitching it All Together\nWhen I first reached this point, I experienced a rush of emotions: can creating\nnew features truly be this simple? If so, what have we been doing with our lives\nuntil this moment- repeating the same boilerplate and relearning the same\nconcepts as millions before us? Is this knowledge all worthless now? Does the\nexistence of Stitch reduce our lives’ greatest accomplishments to something that\ncan now be reproduced in minutes?\n\nWhile there are a great number of things that come easily with Stitch, there are\na fair share of headaches that come along with them. Many intricacies of complex\nflows and user management lack documentation or examples altogether. Creating a\ncloud based on ease-of-use even more frustrating: there’s not much that sucks\nmore than knowing something should be simple, but lacking the few lines of code\nto do it.\n\nThat’s where we’ll be filling in the blanks. Next time, we’ll take a look into\nStitch’s Serverless functions.","html":"<p>Some tools are simply the right tool for the job. I imagine this must have been the thinking behind the wave of JSON-like NoSQL databases at their peak, and even so today. If we figure we’ll be passing information as JSON to an endpoint, to then have it structured into a schema, only to be promptly broken down again for our request seconds later, if you will, it’s fair to question the cost-benefit of schemas in some cases. A lot of those cases cover the apps we build for ourselves: ones that let us do stupid things like spamming selfies or filling the internet with vast mindless thoughts.</p><p><strong><strong>MongoDB Atlas</strong></strong> is a hell of product in its own right, being a cloud NoSQL database with the ability to execute queries similar to SQL JOINs, countless aggregations, and more possibilities to work into a pipeline than I’ve even had time to explore (we’ll get there). If you’ve ever been tasked to build endpoints for yourself, chances are you already appreciate side-stepping the manual one-to-one key association that comes with passing JSON to Lambda Functions or what-have-you.</p><p>Take our situation at Hackers And Slackers, for instance. We’re running a Ghost blog, which is a young piece of software built by a non-profit organization: this software is constantly being updated and improved, which means if we want to modify the logic of our Node app at all, our choices are:</p><ol><li>Modify the Ghost source and refuse future updates</li><li>Merge our custom backend with Ghost changes in the event of an update</li><li>Build a third-party API using a platform such as AWS</li></ol><p><strong><strong>MongoDB Stitch</strong></strong> gives us a new fourth option: <em>extend our app without all the repetitive boilerplate.</em> I say <em>extend</em> because it empowers us to build on top of things which were previously black-boxed to us, such developing a theme atop a blogging system.</p><h2 id=\"carrying-on-the-legacy\">Carrying on the Legacy</h2><p><strong><strong>MongoDB Stitch </strong></strong>extends the philosophy of avoiding repetition. In a similar way to how NoSQL removed a pain point for many developers, Stitch wants you to keep doing what you do best, which is probably writing NodeJS apps. Forever.</p><p>If I worked for Mongo, I’d sell the product like this:</p><blockquote><em><em>MongoDB Stitch empowers you to build powerful features without ever switching gears to the menial aspects of development.</em></em></blockquote><p>What I’m really saying is that <strong><strong>MongoDB Stitch</strong></strong> is <strong><strong>Google Firebase</strong></strong>. Both products target the <em>frontend</em> and <em>mobile</em> developer markets, and both are very young and early in fully achieving this goal. I’m watching the MongoDB product video for the first time, and it feels like what I’ve assumed from using the product aligns with their sell (good job on their part, I suppose):</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"480\" height=\"270\" src=\"https://www.youtube.com/embed/H3P0lW94L2Q?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>As warm and uppity as that video is, Mongo has been rather bashful about their Cloud. I'm guessing that has something to do with an IPO.</p><p>On the other hand, <strong>Google Firebase</strong> has been tooting its own horn loudly for a young product, with a level of growth which feels almost reckless at times (I won't get into it):</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"480\" height=\"270\" src=\"https://www.youtube.com/embed/iosNuIdQoy8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>Anyway, we're not here to compare. We're here to judge.</p><h2 id=\"getting-started-with-a-new-database\">Getting Started with a New Database</h2><p>Feel free to follow along by <a href=\"https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/\">setting up a free tier cluster</a>. </p><p>Proper Mongo accounts are managed at <a href=\"https://cloud.mongodb.com\">https://cloud.mongodb.com</a> once created. This landing dash has plenty of useful info and stats regarding the cluster itself. We'll also need to be sure that a database exists before we crate any apps, otherwise we'll just be interacting with nothing.</p><p>I <em>highly</em> suggest using the <strong>MongoDB Compass</strong> desktop app to connect to your your cluster. It's easy to download, and even saves you the time of entering credentials by connecting with a copy+pasted URI:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/connectcompass.gif\" class=\"kg-image\"><figcaption>Connect with your database; emotionally.</figcaption></figure><p>Within Compass, simply create a database and collection:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/createdatabase_o.jpg\" class=\"kg-image\"><figcaption>In MongoWorld, \"collections\" are the equivalent of \"tables\".</figcaption></figure><h2 id=\"let-s-get-stitched\">Let's Get Stitched</h2><p>With all that out of the way, head back to your account on the Mongo Cloud. Now our interest is entirely in the <strong>Stitch Apps</strong> link on the left side nav:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/selectstitch.png\" class=\"kg-image\"><figcaption>There’s so much to explore!</figcaption></figure><p>Create and name a new Stitch application, and we'll land on the \"getting started\" page. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/cf61a09bd893c453854634988b71d500.gif\" class=\"kg-image\"><figcaption><em>Enable anonymous auth &amp; point to your collection</em></figcaption></figure><p>Once we create our app, Stitch immediately throws us in to a quick 101 of how to interact with our database. We're going to use the exact example that Stitch gives us; it's important to have the \"A-ha\" moment where everything comes together. </p><p>Before getting to any code, the only two things we need to do are:</p><ol><li><strong>Enable Anonymous Authentication</strong>: This is fancy language for creating a user type where anybody who accesses our app can make queries</li><li><strong>Pointing to our Mongo Collection</strong>: We need somewhere to store the data we'll be messing with.</li></ol><h3 id=\"connecting-your-app\">Connecting Your App</h3><p>We're going to copy and paste this code on to a page of our app. Once this is live, visit the page and keep an eye on the console:</p><pre><code class=\"language-javascript\">&lt;script src=&quot;https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js&quot;&gt;&lt;/script&gt;\n\n&lt;script&gt;\n  const clientPromise = stitch.StitchClientFactory.create('hackerjira-bzmfe');\n  clientPromise.then(client =&gt; {\n    const db = client.service('mongodb', 'mongodb-atlas').db('HackersBlog');\n    client.login().then(() =&gt;\n      db.collection('jira').updateOne({owner_id: client.authedId()}, {$set:{number:42}}, {upsert:true})\n    ).then(()=&gt;\n      db.collection('jira').find({owner_id: client.authedId()}).limit(100).execute()\n    ).then(docs =&gt; {\n      console.log(&quot;Found docs&quot;, docs)\n      console.log(&quot;[MongoDB Stitch] Connected to Stitch&quot;)\n    }).catch(err =&gt; {\n      console.error(err)\n    });\n  });\n&lt;/script&gt;\n</code></pre>\n<p>Checking this on the live sites looks like this:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screenshot-2018-06-02-16.40.43.png\" class=\"kg-image\"><figcaption>Note the \"docs\" found in the console on the right.</figcaption></figure><p>It worked, but what exactly? The first thing the snippet tells the database to do is to upsert a row where \"number\" is equal to 42:</p><pre><code class=\"language-javascript\">db.collection('jira').updateOne({owner_id: client.authedId()}, {$set:{number:42}}, {upsert:true})\n</code></pre>\n<p>For sanity, let's check the database to see what's up:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/createdatabase_o.jpg\" class=\"kg-image\"><figcaption>Is that… a new record?!?!</figcaption></figure><p>Sure enough, a new entry has been added to our database in the collection we specified. That's fun and all, but what about our actual data? Isn't that what we came here for? Consider the next line:</p><pre><code class=\"language-javascript\">db.collection('jira').find({owner_id: client.authedId()}).limit(100).execute()\n</code></pre>\n<p>Ahhh, we’re querying based on entries <em>only</em> created from the current user! Because the sample code we pasted creates a record, we can then query the database for records created by that user. Let’s not ignore how cool that is having not actually done any work: we already have logic in place to allow anonymous users to create records and recognize them based on their session.</p><p><code>.find()</code> is our bread and butter for retrieving records, much like SQL <code>SELECT</code>. So in theory, to show all issues from this collection we'd just need to run the following, right?</p><pre><code class=\"language-javascript\">db.collection('jira').find({}).execute()\n</code></pre>\n<p>Slow down there, buddy- but yes, pretty much. We just need to make read permissions public on the MongoDB Stitch side first. Back in the Stitch UI, select \"Rules\" from the sidebar. Here, we can modify the rules for who can read/write which records from which DB:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screenshot-2018-06-02-16.43.31.png\" class=\"kg-image\"><figcaption>It's less complicated than it looks.</figcaption></figure><p>We can create rules as advanced as we'd like, but the rules we need right now are simple enough to handle purely via the UI.</p><h2 id=\"get-all-the-records\">Get All The Records</h2><p>Go ahead and add a bunch of records to your database collection. Experiment with importing data via JSON or CSV, or just add some records one-by-one.</p><p>When that's done, go back to your app and see what <code>.find({})</code> comes back with:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-24-at-4.45.50-PM_o.png\" class=\"kg-image\"><figcaption>Now that's a collection.</figcaption></figure><p>There they are: every record from a database collection, grabbed with a single line of code on our frontend. Feel free to take a moment to reflect on this: we didn’t need to create an API, write logic, or log in to any shitty IAM policy management UIs. We didn’t even need to write a query; the ‘query’ in this case is just a JSON object.</p><h3 id=\"stitching-it-all-together\">Stitching it All Together</h3><p>When I first reached this point, I experienced a rush of emotions: can creating new features truly be this simple? If so, what have we been doing with our lives until this moment- repeating the same boilerplate and relearning the same concepts as millions before us? Is this knowledge all worthless now? Does the existence of Stitch reduce our lives’ greatest accomplishments to something that can now be reproduced in minutes?</p><p>While there are a great number of things that come easily with Stitch, there are a fair share of headaches that come along with them. Many intricacies of complex flows and user management lack documentation or examples altogether. Creating a cloud based on ease-of-use even more frustrating: there’s not much that sucks more than knowing something should be simple, but lacking the few lines of code to do it.</p><p>That’s where we’ll be filling in the blanks. Next time, we’ll take a look into Stitch’s Serverless functions.</p>","url":"https://hackersandslackers.com/mongodb-stitch-query-anywhere/","uuid":"76a0bed5-d98a-47a1-a00a-64cff37d16a8","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b12c0ddb5ac11477416d88d"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867373d","title":"MongoDB Cloud: \"Backend as a Service\" with Atlas & Stitch","slug":"mongodb-cloud-backend-as-a-service-with-atlas-and-stitch","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/11/mongodbcloud@2x.jpg","excerpt":"MongoDB's silent transformation from an open-source database to enterprise cloud provider.","custom_excerpt":"MongoDB's silent transformation from an open-source database to enterprise cloud provider.","created_at_pretty":"13 November, 2018","published_at_pretty":"15 November, 2018","updated_at_pretty":"15 February, 2019","created_at":"2018-11-13T16:05:20.000-05:00","published_at":"2018-11-15T08:00:00.000-05:00","updated_at":"2019-02-15T12:49:05.000-05:00","meta_title":"MongoDB Cloud: \"Backend as a Service\" | Hackers and Slackers","meta_description":"Breaking down MongoDB Atlas and MongoDB Stitch to fully assess the capabilities of an unlikely cloud platform.","og_description":"Breaking down MongoDB Atlas and MongoDB Stitch to fully assess the capabilities of an unlikely cloud platform.","og_image":"https://hackersandslackers.com/content/images/2018/11/mongodbcloud@2x.jpg","og_title":"MongoDB Cloud: \"Backend as a Service\" with Atlas And Stitch","twitter_description":"Breaking down MongoDB Atlas and MongoDB Stitch to fully assess the capabilities of an unlikely cloud platform.","twitter_image":"https://hackersandslackers.com/content/images/2018/11/mongodbcloud@2x.jpg","twitter_title":"MongoDB Cloud: \"Backend as a Service\" with Atlas And Stitch","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"Unless you've been living under a rock (or only visit this site via work-related\nGoogle Searches, like most people) you've probably heard me drone on here and\nthere about MongoDB Atlas  and MongoDB Stitch. I even went so far as to hack\ntogether an awful workflow that somehow utilized Tableau as an ETL tool to feed\nJIRA information into Mongo. I'd like to formally apologize for that entire\nseries: I can't imagine there's a single soul on this planet interested in\nlearning about all of those things simultaneously. Such hobbies reserved for\nmasochists with blogging addictions. I apologize. Let's start over.\n\nFirst off, this is not a tutorial on how to use MongoDB: the database. I have\nzero interest cluttering the internet by reiterating what a MEAN stack is for\nthe ten thousandth time, nor will I bore you with core NoSQL concepts you\nalready understand. I'm here to talk about the giant on the horizon we didn't\nsee coming, where MongoDB the database decided to become MongoDB Inc\n[https://en.wikipedia.org/wiki/MongoDB_Inc.]:  the enterprise cloud provider.\nThe same MongoDB that recently purchased mLab\n[https://www.mongodb.com/press/mongodb-strengthens-global-cloud-database-with-acquisition-of-mlab]\n, the other  cloud-hosted solution for Mongo databases. MongoDB the company is\nbold enough to place its bets on building a cloud far  simpler and restricted\nthan either AWS or GCloud. The core of that bet implies that most of us aren't\nexactly building unicorn products as much as we're reinventing the wheel: and\nthey're probably right.\n\nWelcome to our series on MongoDB cloud, where we break down every service\nMongoDB has to offer; one by one.\n\nWhat is MongoDB Cloud, and Does it Exist?\nWhat I refer to as \"MongoDB Cloud\" (which, for some reason, isn't the actual\nname of the suite MongoDB offers) is actually two products:\n\n * MongoDB Atlas: A cloud-hosted MongoDB cluster with a beefy set of features.\n   Real-time dashboards, high-availability, security features,  an awesome\n   desktop client, and a CLI to top it all off.\n * MongoDB Stitch: A group of services designed to interact with Atlas in every\n   conceivable way, including creating endpoints, triggers, user authentication\n   flows, serverless functions, and a UI to handle all of this.\n\nI'm spying on you and every query you make.Atlas as a Standalone Database\nThere are plenty of people who simply want an instance of MongoDB hosted in the\ncloud as-is: just ask the guys at mLab. This was in fact how I got pulled into\nMongo's cloud myself.\n\nMongoDB Atlas has plenty of advantages over a self-hosted instance of Mongo,\nwhich Mongo itself is confident in by offering a free tier\n[https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/]  of Atlas to\nprospective buyers. If you're a company or enterprise, the phrases High\nAvailability, Horizontal Scalability, relatively Higher Performance  will\nprobably be enough for you. But for us hobbyists, why pay for a Mongo cloud\ninstance?\n\nMongo themselves gives this comparison:\n\nOverview\n MongoDB Atlas\n Compose\n ObjectRocket\n Free Tier\n Yes\nStorage: 512 MB\nRAM: Variable\n No\n30-day free trial\n No\n30-day free trial\n Live migration\n Yes\nNo\nNo\nChoice of cloud providers\n AWS, Azure & GCP\n AWS, Softlayer & GCP\nAvailable in 2 regions for each provider\n Rackspace\n Choice of instance configuration\n Yes\n No\nConfiguration based on required storage capacity only. No way to independently\nselect underlying hardware configurations\n No\nConfiguration based on required storage capacity only. No way to independently\nselect underlying hardware configurations\n Availability of latest MongoDB version\n Yes\nNew versions of the database are available on MongoDB Atlas as soon as they are\nreleased\n No\nNew versions typically available 1-2 quarters following database release\nNo\nNew versions typically available 1-2 quarters following database release\nReplica Set Configuration\n Up to 7 replicas\nAll replicas configured as data-bearing nodes\n 3 data-bearing nodes\nOne of the data-bearing nodes is hidden and used for backups only\n 3 data-bearing nodes\nAutomatic Sharding Support\n Yes\nNo\nYes\nData explorer\n Yes\nYes\nNo\nSQL-based BI Connectivity\n Yes\nNo\nNo\nPause and resume clusters\n Yes\nNo\nNo\nDatabase supported in on-premise deployments\n Yes\nMongoDB Enterprise Advanced [/products/mongodb-enterprise-advanced]\n No\nNo\nGlobal writes Low-latency writes from anywhere in the world Yes\n No\n No\n Cross-region replication Distribute data around the world for multi-region\nfault tolerance and local reads Yes\n No\n No\n Monitoring of database health with automated alerting\n Yes\nMongoDB Atlas UI & support for APM platforms (New Relic)\n Yes\nNew Relic\n Yes\nNew Relic\n Continuous backup\n Yes\nBackups maintained\nseconds behind production cluster\n No\nBackups taken with mongodump against hidden replica set member\n No\nBackups taken with mongodump\n Queryable backups\n Yes\nNo\nNo\nAutomated & consistent snapshots of sharded clusters\n Yes\nNot Applicable\nNo support for auto-sharding\n No\nRequires manually coordinating the recovery of mongodumps across shards\n Access control & IP whitelisting\n Yes\nYes\nYes\nAWS VPC Peering\n Yes\nBeta Release\nYes\nAdditional Charge\n Encryption of data in-flight\n Yes\nTLS/SSL as standard\n Yes\nYes\nEncryption of data at-rest\n Yes\nAvailable for AWS deployments; always on with Azure and GCP\n No\nYes\nAvailable only with specific pricing plans and data centers\n LDAP Integration\n Yes\n No\nNo\n Database-level auditing\nTrack DDL, DML, DCL operations\n Yes\n No\nNo\n Bring your own KMS\n Yes\n No\nNo\n Realistically there are probably only a number of items that stand out on the\ncomparison list when we go strictly database-to-database. Freedom over instance\nconfiguration sounds great, but in practice is more similar to putting a cap on\nhow much MongoDB decides to charge you that month (by the way, it's usually a\nlot; keep this mind). Having the Latest Version  seems great, but this can just\nas easily mean breaking production unannounced as much as it means new features.\n\nMongoDB clearly wins over the enterprise space with Continuous & queryable\nbackups, integration with LDAP, and automatic sharding support. Truthfully if\nthis were merely a database-level feature and cost comparison, the decision to\ngo with  MongoDB Atlas  would come down to how much you like their pretty\ndesktop interface:\n\nA perfectly legitimate reason to pay up, imho.So let's say MongoDB Atlas is\nmarginally better than a competitor in the confined realm of \"being a database.\"\nAre Stitch microservices enough to justify keeping your instance with the\nMongoDB team?\n\nService-by-Service Breakdown of Stitch\nStitch is kind of like if AWS exited in an alternative universe, where JSON and\nJavaScript were earth's only technologies. Thinking back to how we create APIs\nin AWS, the status quo almost always involves spinning up a Dynamo  (NoSQL)\ndatabase to put behind Lambda functions, accessible by API Gateway endpoints.\nStitch's core use case revolves around this use-case of end-user-accessing-data,\nwith a number of services dedicated specifically to supporting or improving this\nflow. The closest comparison to Stitch would be GCloud's Firebase. \n\nSo what makes Stitch so special?\n\nService 1: Querying Atlas Securely via Frontend Code\nSomething that cannot be understated is the ability to query Atlas via frontend\nJavascript. We're not passing API keys, Secrets, or any sort of nonsense;\nbecause you're configured things correctly, whitelisted domains can run queries\nof any complexity without ever interacting with an app's backend.  This is not a\ncrazy use case: consider this blog for example, or more so lately, mobile\napplications:\n\n<script src=\"https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js\"></script>\n<script>\n  const client = stitch.Stitch.initializeDefaultAppClient('myapp');\n\n  const db = client.getServiceClient(stitch.RemoteMongoClient.factory, 'mongodb-atlas').db('<DATABASE>');\n\n  client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => \n    db.collection('<COLLECTION>').updateOne({owner_id: client.auth.user.id}, {$set:{number:42}}, {upsert:true})\n  ).then(() => \n    db.collection('<COLLECTION>').find({owner_id: client.auth.user.id}, { limit: 100}).asArray()\n  ).then(docs => {\n      console.log(\"Found docs\", docs)\n      console.log(\"[MongoDB Stitch] Connected to Stitch\")\n  }).catch(err => {\n    console.error(err)\n  });\n</script>\n\n\nThis isn't to say we're allowing any user to query any data all willy-nilly just\nbecause they're on our whitelisted IP: all data stored in Atlas is restricted to\nspecified Users  by defining User Roles. Joe Schmoe can't just inject a query\ninto any presumed database and wreak havoc, because Joe Schmoe can only access\ndata we've permitted his user account to view or write to. What is this \"user\naccount\" you ask? This brings us to the next big feature...\n\nService 2: End-User Account Creation & Management\nStitch will handle user account creation for you without the boilerplate.\nCreating an app with user accounts is a huge pain in the ass. Cheeky phrases\nlike 'Do the OAuth Dance'  can't ever hope to minimize the agonizing repetitive\npain of creating user accounts or managing relationships between users and data\n(can user X  see a comment from user Y?). Stitch allows most of the intolerably\nbenign logic behind these features to be handled via a UI.\n\nIt would be a far cry to say these processes have been \"trivialized\", but the\ntime saved is perhaps just enough to keep a coding hobbyist interested in their\nside projects as opposed to giving up and playing Rocket League.\n\nAs far as the permissions to read comments go... well, here's a self-explanatory\nscreenshot of how Stitch handles read/write document permission in its simplest\nform:\n\nOwners of comments can write their comments. Everybody else reads. Seems simple.\nService 3: Serverless Functions\nStitch functions are akin to AWS Lambda functions, but much easier to configure\nfor cross-service integration (and also limited to JavaScript ECMA 2015 or\nsomething). Functions benefit from the previous two features, in that they too\ncan be triggered from a whitelisted app's frontend, and are governed by a simple\n\"rules\" system, eliminating the need for security group configurations etc.\n\nThis is what calling a function from an app's frontend looks like:\n\n<script>\n    client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => {\n     client.callFunction(\"numCards\", [\"In Progress\"]).then(results => {\n       $('#progress .count').text(results + ' issues');\n     })\n    });\n</script>\n\n\nFunctions can run any query against Atlas, retrieve values  (such as environment\nvariables), and even call other functions. Functions can also be fired by\ndatabase triggers,  where a change to a collection will prompt an action such as\nan alert.\n\nService 4: HTTP Webhooks\nWebhooks are a fast way to toss up endpoints. Stitch endpoints are agnostic to\none another in that they are one-off URLs to perform single tasks. We could\nnever build a well-designed API using Stitch Webhooks, as we could with API\nGateway; this simply isn't the niche MongoDB is trying to hit (the opposite, in\nfact). \n\nConfiguration for a single Webhook.This form with a mere 6 fields clearly\nillustrates what Stitch intends to do: trivializing the creation of\ntraditionally non-trivial features.\n\nService 5: Storing 'Values' in Stitch\nA \"value\" is equivalent to an environment variable. These can be used to store\nAPI keys, secrets, or whatever. Of course, values are retrieved via functions.\n\nShhh, it's a secret ;)Service 6+: A Bunch of Mostly Bloated Extras\nFinally, Stitch has thrown in a few third-party integrations for good measure.\nSome integrations like S3 Integration could definitely come in handy, but it's\nworth asking why Mongo constantly over advertises their integrations with Github \n and Twilio. We've already established that we can create endpoints which accept\ninformation, and we can make functions which GET  information... so isn't\nanything with an API pretty easy to 'integrate' with?\n\nThis isn't to say the extra services aren't useful, they just seem a bit... odd.\nIt feels a lot like bloating the catalog, but the catalog isn't nearly bloated\nenough where it feels normal (like Heroku add-ons, for example). The choice to\nlaunch Stitch with a handful of barely-useful integrations only comes off as\nmore and more aimless as time passes; as months turn to years and no additions\nor updates are made to service offerings, it's worth questioning what the vision\nhad been for the product in the first place. In my experience, feature sets like\nthese happen when Product Managers are more powerful than they are useful.\n\nThe Breathtaking Climax: Is Stitch Worth It?\nI've been utilizing Stitch to fill in the blanks in development for months now,\nperhaps nearly a year. Each time I find myself working with Stitch or looking at\nthe bill, I can't decide if it's been a Godsend for its nich\u001dé, or an expensive\ntoy with an infuriating lack of accurate documentation.\n\n  Stitch is very much a copy-and-paste-cookie-cutter-code  type of product,\nwhich begs the question of why their tutorials are recklessly outdated;\nsometimes to the point where MongoDB's own tutorial source code doesn't work. \nThere are so many use cases and potential benefits to Stitch, so why is the \nGithub repo [https://github.com/mongodb/stitch-examples]  containing example\ncode snippets so unmaintained, and painfully irrelevant? Lastly, why am I\nselling this product harder than their own internal team?\n\nStitch is a good product with a lot of unfortunate oversight. That said, Google\nFirebase still doesn't even have an \"import data\" feature, so I suppose it's\ntime to dig deep into this vendor lock and write a 5-post series about it before\nSilicon Valley's best and brightest get their shit together enough to actually\ncreate something useful and intuitive for other human beings to use. In the\nmeantime, feel free to steal source from tutorials I'll be posting, because\nthey'll be sure to, you know, actually work.","html":"<p>Unless you've been living under a rock (or only visit this site via work-related Google Searches, like most people) you've probably heard me drone on here and there about <strong>MongoDB Atlas</strong> and <strong>MongoDB Stitch</strong>. I even went so far as to hack together an awful workflow that somehow utilized Tableau as an ETL tool to feed JIRA information into Mongo. I'd like to formally apologize for that entire series: I can't imagine there's a single soul on this planet interested in learning about all of those things simultaneously. Such hobbies reserved for masochists with blogging addictions. I apologize. Let's start over.</p><p>First off, this is not a tutorial on how to use <em>MongoDB: the database</em>. I have zero interest cluttering the internet by reiterating what a MEAN stack is for the ten thousandth time, nor will I bore you with core NoSQL concepts you already understand. I'm here to talk about the giant on the horizon we didn't see coming, where MongoDB the database decided to become <a href=\"https://en.wikipedia.org/wiki/MongoDB_Inc.\"><strong>MongoDB Inc</strong></a><strong>:</strong> the enterprise cloud provider. The same MongoDB that recently purchased <a href=\"https://www.mongodb.com/press/mongodb-strengthens-global-cloud-database-with-acquisition-of-mlab\">mLab</a>, the <em>other</em> cloud-hosted solution for Mongo databases. MongoDB the company is bold enough to place its bets on building a cloud <em>far</em> simpler and restricted than either AWS or GCloud. The core of that bet implies that most of us aren't exactly building unicorn products as much as we're reinventing the wheel: and they're probably right.</p><p>Welcome to our series on MongoDB cloud, where we break down every service MongoDB has to offer; one by one.</p><h2 id=\"what-is-mongodb-cloud-and-does-it-exist\">What is MongoDB Cloud, and Does it Exist?</h2><p>What I refer to as \"MongoDB Cloud\" (which, for some reason, isn't the actual name of the suite MongoDB offers) is actually two products:</p><ul><li><strong>MongoDB Atlas</strong>: A cloud-hosted MongoDB cluster with a beefy set of features. Real-time dashboards, high-availability, security features,  an awesome desktop client, and a CLI to top it all off.</li><li><strong>MongoDB Stitch: </strong>A group of services designed to interact with Atlas in every conceivable way, including creating endpoints, triggers, user authentication flows, serverless functions, and a UI to handle all of this.</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/metrics.gif\" class=\"kg-image\"><figcaption>I'm spying on you and every query you make.</figcaption></figure><h3 id=\"atlas-as-a-standalone-database\">Atlas as a Standalone Database</h3><p>There are plenty of people who simply want an instance of MongoDB hosted in the cloud as-is: just ask the guys at mLab. This was in fact how I got pulled into Mongo's cloud myself.</p><p>MongoDB Atlas has plenty of advantages over a self-hosted instance of Mongo, which Mongo itself is confident in by offering a <a href=\"https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/\">free tier</a> of Atlas to prospective buyers. If you're a company or enterprise, the phrases <strong>High Availability</strong>, <strong>Horizontal Scalability, </strong>relatively <strong>Higher Performance</strong> will probably be enough for you. But for us hobbyists, why pay for a Mongo cloud instance?</p><p>Mongo themselves gives this comparison:</p><div class=\"tableContainer\">\n<table class=\"table left\">\n  <thead>\n    <tr>\n      <th>\n        <strong>Overview</strong>\n      </th>\n      <th>\n        <strong>MongoDB Atlas</strong>\n      </th>\n      <th>\n        <strong>Compose</strong>\n      </th>\n      <th>\n        <strong>ObjectRocket</strong>\n      </th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\n        Free Tier\n      </td>\n      <td>\n        Yes<br><small>Storage: 512 MB<br>RAM: Variable</small>\n      </td>\n      <td>\n        No<br><small>30-day free trial</small>\n      </td>\n      <td>\n        No<br><small>30-day free trial</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Live migration\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Choice of cloud providers\n      </td>\n      <td>\n        AWS, Azure &amp; GCP\n      </td>\n      <td>\n        AWS, Softlayer &amp; GCP<br><small>Available in 2 regions for each provider</small>\n      </td>\n      <td>\n        Rackspace\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Choice of instance configuration\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small>Configuration based on required storage capacity only. No way to independently select underlying hardware configurations</small>\n      </td>\n      <td>\n        No<br><small>Configuration based on required storage capacity only. No way to independently select underlying hardware configurations</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Availability of latest MongoDB version\n      </td>\n      <td>\n        Yes<br><small>New versions of the database are available on MongoDB Atlas as soon as they are released</small>\n      </td>\n      <td>\n        No<br><small>New versions typically available 1-2 quarters following database release<br></small>\n      </td>\n      <td>\n        No<br><small>New versions typically available 1-2 quarters following database release<br></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Replica Set Configuration\n      </td>\n      <td>\n        Up to 7 replicas<br><small>All replicas configured as data-bearing nodes</small>\n      </td>\n      <td>\n        3 data-bearing nodes<br><small>One of the data-bearing nodes is hidden and used for backups only</small>\n      </td>\n      <td>\n        3 data-bearing nodes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Automatic Sharding Support\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Data explorer\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        SQL-based BI Connectivity\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Pause and resume clusters\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Database supported in on-premise deployments\n      </td>\n      <td>\n        Yes<br><small><a href=\"/products/mongodb-enterprise-advanced\">MongoDB Enterprise Advanced</a></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Global writes <small>Low-latency writes from anywhere in the world </small>\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Cross-region replication <small>Distribute data around the world for multi-region fault tolerance and local reads </small>\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No\n      </td>\n      <td>\n        No\n      </td>\n    </tr><tr>\n      <td>\n        Monitoring of database health with automated alerting\n      </td>\n      <td>\n        Yes<br><small>MongoDB Atlas UI &amp; support for APM platforms (New Relic)</small>\n      </td>\n      <td>\n        Yes<br><small>New Relic</small>\n      </td>\n      <td>\n        Yes<br><small>New Relic</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Continuous backup\n      </td>\n      <td>\n        Yes<br><small>Backups maintained<br>seconds behind production cluster</small>\n      </td>\n      <td>\n        No<br><small>Backups taken with mongodump against hidden replica set member</small>\n      </td>\n      <td>\n        No<br><small>Backups taken with mongodump</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Queryable backups\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Automated &amp; consistent snapshots of sharded clusters\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Not Applicable<br><small>No support for auto-sharding</small>\n      </td>\n      <td>\n        No<br><small>Requires manually coordinating the recovery of mongodumps across shards</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Access control &amp; IP whitelisting\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        AWS VPC Peering\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Beta Release<br><small></small>\n      </td>\n      <td>\n        Yes<br><small>Additional Charge</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Encryption of data in-flight\n      </td>\n      <td>\n        Yes<br><small>TLS/SSL as standard</small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Encryption of data at-rest\n      </td>\n      <td>\n        Yes<br><small>Available for AWS deployments; always on with Azure and GCP</small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        Yes<br><small>Available only with specific pricing plans and data centers</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        LDAP Integration\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Database-level auditing<br><small>Track DDL, DML, DCL operations</small>\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Bring your own KMS\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Realistically there are probably only a number of items that stand out on the comparison list when we go strictly database-to-database. Freedom over <strong>instance configuration </strong>sounds great, but in practice is more similar to putting a cap on how much MongoDB decides to charge you that month (by the way, it's usually a lot; keep this mind). Having the <strong>Latest Version</strong> seems great, but this can just as easily mean breaking production unannounced as much as it means new features.</p><p>MongoDB clearly wins over the enterprise space with <strong>Continuous &amp; queryable backups</strong>, integration with <strong>LDAP, </strong>and <strong>automatic sharding support. </strong>Truthfully if this were merely a database-level feature and cost comparison, the decision to go with<strong> MongoDB Atlas</strong> would come down to how much you like their pretty desktop interface:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/compass.gif\" class=\"kg-image\"><figcaption>A perfectly legitimate reason to pay up, imho.</figcaption></figure><p>So let's say MongoDB Atlas is marginally better than a competitor in the confined realm of \"being a database.\" Are Stitch microservices enough to justify keeping your instance with the MongoDB team?</p><h2 id=\"service-by-service-breakdown-of-stitch\">Service-by-Service Breakdown of Stitch</h2><p>Stitch is kind of like if AWS exited in an alternative universe, where JSON and JavaScript were earth's only technologies. Thinking back to how we create APIs in AWS, the status quo almost always involves spinning up a <strong>Dynamo</strong> (NoSQL) database to put behind <strong>Lambda </strong>functions, accessible by <strong>API Gateway </strong>endpoints. Stitch's core use case revolves around this use-case of <em>end-user-accessing-data</em>, with a number of services dedicated specifically to supporting or improving this flow. The closest comparison to Stitch would be GCloud's <strong>Firebase</strong>. </p><p>So what makes Stitch so special?</p><h3 id=\"service-1-querying-atlas-securely-via-frontend-code\">Service 1: Querying Atlas Securely via Frontend Code</h3><p>Something that cannot be understated is the ability to query Atlas via frontend Javascript. We're not passing API keys, Secrets, or any sort of nonsense; because you're configured things correctly, whitelisted domains can run queries of any complexity <em>without ever interacting with an app's backend.</em> This is not a crazy use case: consider this blog for example, or more so lately, mobile applications:</p><pre><code class=\"language-javascript\">&lt;script src=&quot;https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js&quot;&gt;&lt;/script&gt;\n&lt;script&gt;\n  const client = stitch.Stitch.initializeDefaultAppClient('myapp');\n\n  const db = client.getServiceClient(stitch.RemoteMongoClient.factory, 'mongodb-atlas').db('&lt;DATABASE&gt;');\n\n  client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; \n    db.collection('&lt;COLLECTION&gt;').updateOne({owner_id: client.auth.user.id}, {$set:{number:42}}, {upsert:true})\n  ).then(() =&gt; \n    db.collection('&lt;COLLECTION&gt;').find({owner_id: client.auth.user.id}, { limit: 100}).asArray()\n  ).then(docs =&gt; {\n      console.log(&quot;Found docs&quot;, docs)\n      console.log(&quot;[MongoDB Stitch] Connected to Stitch&quot;)\n  }).catch(err =&gt; {\n    console.error(err)\n  });\n&lt;/script&gt;\n</code></pre>\n<p>This isn't to say we're allowing any user to query any data all willy-nilly just because they're on our whitelisted IP: all data stored in Atlas is restricted to specified <strong>Users</strong> by defining <strong>User Roles. </strong>Joe Schmoe can't just inject a query into any presumed database and wreak havoc, because Joe Schmoe can only access data we've permitted his user account to view or write to. What is this \"user account\" you ask? This brings us to the next big feature...</p><h3 id=\"service-2-end-user-account-creation-management\">Service 2: End-User Account Creation &amp; Management</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-13-at-5.59.03-PM.png\" class=\"kg-image\"><figcaption>Stitch will handle user account creation for you without the boilerplate.</figcaption></figure><p>Creating an app with user accounts is a huge pain in the ass. Cheeky phrases like '<strong>Do the OAuth Dance'</strong> can't ever hope to minimize the agonizing repetitive pain of creating user accounts or managing relationships between users and data (can <em>user X</em> see a comment from <em>user Y</em>?). Stitch allows most of the intolerably benign logic behind these features to be handled via a UI.</p><p>It would be a far cry to say these processes have been \"trivialized\", but the time saved is perhaps just enough to keep a coding hobbyist interested in their side projects as opposed to giving up and playing Rocket League.</p><p>As far as the permissions to read comments go... well, here's a self-explanatory screenshot of how Stitch handles read/write document permission in its simplest form:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-13-at-6.09.25-PM.png\" class=\"kg-image\"><figcaption>Owners of comments can write their comments. Everybody else reads. Seems simple.</figcaption></figure><h3 id=\"service-3-serverless-functions\">Service 3: Serverless Functions</h3><p>Stitch functions are akin to AWS Lambda functions, but much easier to configure for cross-service integration (and also limited to JavaScript ECMA 2015 or something). Functions benefit from the previous two features, in that they too can be triggered from a whitelisted app's frontend, and are governed by a simple \"rules\" system, eliminating the need for security group configurations etc.</p><p>This is what calling a function from an app's frontend looks like:</p><pre><code class=\"language-javascript\">&lt;script&gt;\n    client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; {\n     client.callFunction(&quot;numCards&quot;, [&quot;In Progress&quot;]).then(results =&gt; {\n       $('#progress .count').text(results + ' issues');\n     })\n    });\n&lt;/script&gt;\n</code></pre>\n<p>Functions can run any query against Atlas, retrieve <em>values</em> (such as environment variables), and even call other functions. Functions can also be fired by database <strong>triggers,</strong> where a change to a collection will prompt an action such as an alert.</p><h3 id=\"service-4-http-webhooks\">Service 4: HTTP Webhooks</h3><p>Webhooks are a fast way to toss up endpoints. Stitch endpoints are agnostic to one another in that they are one-off URLs to perform single tasks. We could never build a well-designed API using Stitch Webhooks, as we could with <strong>API Gateway</strong>; this simply isn't the niche MongoDB is trying to hit (the opposite, in fact). </p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-14-at-4.33.27-PM.png\" class=\"kg-image\"><figcaption>Configuration for a single Webhook.</figcaption></figure><p>This form with a mere 6 fields clearly illustrates what Stitch intends to do: trivializing the creation of traditionally non-trivial features.</p><h3 id=\"service-5-storing-values-in-stitch\">Service 5: Storing 'Values' in Stitch</h3><p>A \"value\" is equivalent to an environment variable. These can be used to store API keys, secrets, or whatever. Of course, values are retrieved via functions.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-14-at-7.45.28-PM.png\" class=\"kg-image\"><figcaption>Shhh, it's a secret ;)</figcaption></figure><h3 id=\"service-6-a-bunch-of-mostly-bloated-extras\">Service 6+: A Bunch of Mostly Bloated Extras</h3><p>Finally, Stitch has thrown in a few third-party integrations for good measure. Some integrations like <strong>S3 Integration </strong>could definitely come in handy, but it's worth asking why Mongo constantly over advertises their integrations with <strong>Github</strong> and <strong>Twilio</strong>. We've already established that we can create endpoints which accept information, and we can make functions which <em>GET</em> information... so isn't anything with an API pretty easy to 'integrate' with?</p><p>This isn't to say the extra services aren't useful, they just seem a bit... odd. It feels a lot like bloating the catalog, but the catalog isn't nearly bloated enough where it feels normal (like Heroku add-ons, for example). The choice to launch Stitch with a handful of barely-useful integrations only comes off as more and more aimless as time passes; as months turn to years and no additions or updates are made to service offerings, it's worth questioning what the vision had been for the product in the first place. In my experience, feature sets like these happen when Product Managers are more powerful than they are useful.</p><h2 id=\"the-breathtaking-climax-is-stitch-worth-it\">The Breathtaking Climax: Is Stitch Worth It?</h2><p>I've been utilizing Stitch to fill in the blanks in development for months now, perhaps nearly a year. Each time I find myself working with Stitch or looking at the bill, I can't decide if it's been a Godsend for its nich\u001dé, or an expensive toy with an infuriating lack of accurate documentation.</p><p> Stitch is very much a <em>copy-and-paste-cookie-cutter-code</em> type of product, which begs the question of why their tutorials are recklessly outdated; sometimes to the point where MongoDB's own tutorial source code <em>doesn't work. </em>There are so many use cases and potential benefits to Stitch, so why is the <a href=\"https://github.com/mongodb/stitch-examples\">Github repo</a> containing example code snippets so unmaintained, and painfully irrelevant? Lastly, why am I selling this product harder than their own internal team?</p><p>Stitch is a good product with a lot of unfortunate oversight. That said, Google Firebase still doesn't even have an \"import data\" feature, so I suppose it's time to dig deep into this vendor lock and write a 5-post series about it before Silicon Valley's best and brightest get their shit together enough to actually create something useful and intuitive for other human beings to use. In the meantime, feel free to steal source from tutorials I'll be posting, because they'll be sure to, you know, actually work.</p>","url":"https://hackersandslackers.com/mongodb-cloud-backend-as-a-service-with-atlas-and-stitch/","uuid":"5555fa6e-07f0-4f9a-8069-e1e68868e608","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5beb3c900dbec217f3ce801b"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c6","title":"Using MongoDB Atlas as your Flask Database","slug":"using-mongodb-atlas-as-your-flask-database","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/flaskpymongo@2x.jpg","excerpt":"Since you prefer using Python and Flask, I’ll assume we both prefer enjoyable dev.","custom_excerpt":"Since you prefer using Python and Flask, I’ll assume we both prefer enjoyable dev.","created_at_pretty":"28 July, 2018","published_at_pretty":"31 July, 2018","updated_at_pretty":"07 March, 2019","created_at":"2018-07-28T13:42:54.000-04:00","published_at":"2018-07-31T16:59:00.000-04:00","updated_at":"2019-03-07T01:02:11.000-05:00","meta_title":"Using MongoDB Atlas as your Flask Database | Hackers And Slackers","meta_description":"MongoDB Atlas and Stitch are easy to use, making Mongo’s cloud offering a natural choice for quick Flask-based applications.","og_description":"MongoDB Atlas and Stitch are easy to use, making Mongo’s cloud offering a natural choice for quick Flask-based applications.","og_image":"https://hackersandslackers.com/content/images/2019/03/flaskpymongo@2x.jpg","og_title":"Using MongoDB Atlas as your Flask Database","twitter_description":"MongoDB Atlas and Stitch are easy to use, making Mongo’s cloud offering a natural choice for quick Flask-based applications.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/flaskpymongo@2x.jpg","twitter_title":"Using MongoDB Atlas as your Flask Database","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"It's been roughly a year since MongoDB launched their Stitch: a \"back-end as a\nservice\" cloud offering. I've been tinkering with Mongo on the cloud ever\nsince... Alright fine, \"tinkering with\"  may better be described as\"accidentally\nbecame dependent on it after developing new features in production\nenvironments,\" but I can't really complain thus-far. If you're not familiar, \nMongoDB Atlas  is MongoDB's cloud-hosted database offering; that is to say, the\nsame as any other MongoDB database, except very expensive.\n\nThe jury is still out on how MongoDB Atlas  and its counterpart Stitch  will fit\ninto the picture of next generation cloud services. That said, I can vouch that\nMongo products are simply fun to use  for developers, especially when compared\nto  traditional rigid alternatives. Since I would also group Python  and Flask \nin the 'fun to use' category, selecting MongoDB as the database for your Flask\napp makes a lot of sense.\n\nFor this tutorial we're going to set up a simple app where users can submit\ninformation via a form to MongoDB. After writing to our database, we'll query\nthe db to see the results. The result will be a Flask app with the following\nfile structure:\n\nmy-flask-project\n├── templates/\n├── static/\n├── app.py\n├── config.py\n├── currenttime.py\n└── form.py\n\n\nConnect to your Database with PyMongo\nPyMongo  is Python's go-to library for interacting with MongoDB. \n\nWe'll keep all database connection logic within db.py. After importing PyMongo,\nmost of the configuration we need to handle happens in a single line containing\nour MongoDB URI: the massive string which contains our DB location, creds, and\nauthorization DB. The string is broken down like this:\n\nmongodb+srv://[username]:[password]@[projectname]-gktww.gcp.mongodb.net/[authDB]\n\n\nAuthenticate with a [username]  and [password] you’ve set up in whichever\ndatabase handles authentication for your MongoDB instance (this is also what \n[authDB]  is referring to). \n\n[projectname]  is the unique name of your cloud instance. The rest of the URI\ncontains some nonsense, including the host of your particular instance (I’m\nusing Google Cloud, hence the .gcp in the URI). Most of this information can be\nfound just by jumping on mongodb.com [https://www.mongodb.com/]  and\ninvestigating your URI via the \"connect\" popup:\n\nThat should make things a bit easier.Now we can set up our connection:\n\nimport pymongo\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@hackerdata-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\n\nNote that we intentionally set the connection to False. Otherwise, we're going\nto find ourselves in a hell of managing open connections every time we interact\nwith the DB.\n\nSpeaking of the DB, we need to specify which database and collection we want to\ninteract with. This brings our config file to something as follows:\n\nimport pymongo\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@myInstance-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\ndb = pymongo.database.Database(mongo, 'mydatabase')\ncol = pymongo.collection.Collection(db, 'mycollection')\n\n\nLastly, if you'd like to access, say, all the objects inside of a collection (or\nsimilar query), we'll just need to add a few lines line to ensure we're reading\nthe collection's data:\n\nimport pymongo\nfrom bson.json_util import dumps\nimport json\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@myInstance-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\ndb = pymongo.database.Database(mongo, 'mydatabase')\ncol = pymongo.collection.Collection(db, 'mycollection')\n\ncol_results = json.loads(dumps(col.find().limit(5).sort(\"time\", -1)))\n\n\nRemember that Mongo returns BSON objects as opposed to JSON objects, which isn't\nvery useful for our purposes. To alleviate this we'll do a messy little dance to\nconvert Mongo's BSON into a string, and convert this to JSON using json.dumps().\n\nNote: the need to do this may have been something changed in recent versions of\nMongo, as I have older application functioning where this wasn't the case.\n¯\\_(ツ)_/¯.\n\nCreating a Form\nHeading over to form.py, we just need to set up a simple single-field form for\nusers to submit their URLs. For the sake of Python, let's say we're only\naccepting URLs for Jupyter noteboooks:\n\nfrom wtforms import Form, StringField, validators\nfrom wtforms.validators import DataRequired, Regexp\n\nclass myForm(Form):\n    \"\"\"Homepage form.\"\"\"\n    PlotlyURL = StringField('Provide a raw .ipynb URL from Github',\n    validators=[\n            DataRequired(),\n            Regexp(\".*\\.ipynb$\",\n            message=\"Please provide a URL ending in ipynb\"),\n          ])\n\n\nWe could have an entire tutorial just about Flask's WTForms\n[http://flask.pocoo.org/docs/1.0/patterns/wtforms/], but let's stay on topic\n and move on to currenttime.py.\n\nAdding Time Metadata\nIn a lot of cases where we store information to a database, we at least want to\nadd certain metadata such as the time something was added. This allows us to\narrange results by most recently updated, which we'll be doing in this example.\n\nfrom datetime import datetime, timezone\n\ndef getTime():\n    \"\"\"Get user's current time\"\"\"\n    rightnow = datetime.today()\n    return rightnow\n\ndef getPrettyTime():\n    \"\"\"Get user's pretty current time\"\"\"\n    rightnow = datetime.today()\n    prettytime = rightnow.ctime()\n    return prettytime\n\nyourtime = getTime()\nprettytime = getPrettyTime()\n\n\nThe variable yourtime  will be a datetime string representing the local time of\nthe user creating a new record. We will use this value to sort the queried\nresults by time. On the contrary,prettytime  will be the same time, only\nformatted in a way that is readable to humans.\n\nPutting the Pieces Together\nFinally we get to move on app.py and get this thing moving. We'll initiate our\napp by importing the necessary libraries, as well as the scripts we just\ncreated:\n\nfrom flask import Flask, render_template, Markup, request, redirect\nfrom config import col, col_results\nimport requests\nfrom form import myForm\nfrom flask_static_compress import FlaskStaticCompress\nfrom currenttime import yourtime, prettytime\nimport logging\n\n\nNote that we need to import from the DB config we set earlier is the \"col\"\nvariable; we'll only be interacting directly with the collection we want to\nmodify, and the rest is assumed within the config file itself. Now let's build a\nroute for our homepage that does two things:\n\n * Allows users to submit a URL via the simple form we created\n * Displays all previous searches by all users.\n\nfrom flask import Flask, render_template, Markup, request, redirect\nfrom config import col, col_results\nimport requests\nfrom form import myForm\nfrom flask_static_compress import FlaskStaticCompress\nfrom currenttime import yourtime, prettytime\nimport logging\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    \"\"\"Landing page.\"\"\"\n    recent_searches = list(col_results)\n    return render_template('/index.html', form=myForm(), recents=recent_searches, template=\"home-template\")\n\n\nThere's only two significant lines here, but let's break them down piece by\npiece.\n\nrecent_searches\nFirst we set a recent_searches  variable which is essentially a query against\nour collection to retrieve a list of previous searches. We ask that these be\nreturned as a list()  upfront. Typically the find() method would contain the\nconstraints of our query, but we're simply asking to return all  results in the\ncollection, with a limit()  up to 5. Finally, we sort()  the results by the\nfield we refer to as 'time' is descending order, as noted by the -1 argument.\n\nThis is all probably very difficult to visualize without a graphic. Here's a\nsnapshot of the collection we're defining with dummy data added:\n\nSee why we need to differentiate \"time\" and \"prettytime\"?render_template\nWe already know [https://hackersandslackers.com/serving-static-assets-in-flask/] \n the basics of serving templates and assets in Flask, so it shouldn't be too\ndifficult to break down the last line in our route:\n\n * '/index.html'  specifies the base template we'll be serving up.\n * form=myForm()  passes the form class we created earlier to the form partial\n   we're including as part of the index page.\n * recents=recent_searches  passes the query of previous searches to the\n   template, with which we can build a widget.\n * template=\"home-template\" is a simple variable passed which we'll utilize as a\n   class on the page we're loading.\n\nThe Result\nFrom everything we've completed, you should be expecting to see a somewhat\nworthless page where users can submit links via a form, simply to see results\nposted by previous posters. If we expand on this idea just a bit, we can see how\nsomething so simple can actually be extended to a full product: \n\n> Planet Jupyter [https://planetjupyter.com]\nStyle your Jupyter Notebooks.\n\n\nPlanet Jupyter is demo product we built at H&S to style Jupyter notebooks.\nPerhaps 60% of the logic behind Planet Jupyter is the simple DB interactions we\njust covered, with the rest being added flair.\n\nThis is not a shameless plug for the barely functioning toys we've built, mind\nyou, but rather an example of simple DB interactions using Flask can be easily\nextensible into relevant, useful, products.\n\nWe hope you’ve found this tutorial to be useful!","html":"<p>It's been roughly a year since MongoDB launched their <strong>Stitch: </strong>a \"back-end as a service\" cloud offering. I've been tinkering with Mongo on the cloud ever since... Alright fine, <em>\"tinkering with\"</em> may better be described as  <em>\"accidentally became dependent on it after developing new features in production environments,\" </em>but I can't really complain thus-far. If you're not familiar, <strong>MongoDB Atlas</strong> is MongoDB's cloud-hosted database offering; that is to say, the same as any other MongoDB database, except very expensive.</p><p>The jury is still out on how MongoDB <strong>Atlas</strong> and its counterpart <strong>Stitch</strong> will fit into the picture of next generation cloud services. That said, I can vouch that Mongo products are simply <em>fun to use</em> for developers, especially when compared to  traditional rigid alternatives. Since I would also group <em>Python</em> and <em>Flask</em> in the 'fun to use' category, selecting MongoDB as the database for your Flask app makes a lot of sense.</p><p>For this tutorial we're going to set up a simple app where users can submit information via a form to MongoDB. After writing to our database, we'll query the db to see the results. The result will be a Flask app with the following file structure:</p><pre><code class=\"language-shell\">my-flask-project\n├── templates/\n├── static/\n├── app.py\n├── config.py\n├── currenttime.py\n└── form.py\n</code></pre>\n<h2 id=\"connect-to-your-database-with-pymongo\">Connect to your Database with PyMongo</h2><p><strong>PyMongo</strong> is Python's go-to library for interacting with MongoDB. </p><p>We'll keep all database connection logic within <strong>db.py</strong>. After importing PyMongo, most of the configuration we need to handle happens in a single line containing our MongoDB URI: the massive string which contains our DB location, creds, and authorization DB. The string is broken down like this:</p><pre><code class=\"language-shell\">mongodb+srv://[username]:[password]@[projectname]-gktww.gcp.mongodb.net/[authDB]\n</code></pre>\n<p>Authenticate with a <strong>[username]</strong> and <strong>[password] </strong>you’ve set up in whichever database handles authentication for your MongoDB instance (this is also what<strong> [authDB]</strong> is referring to). </p><p><strong>[projectname]</strong> is the unique name of your cloud instance. The rest of the URI contains some nonsense, including the host of your particular instance (I’m using Google Cloud, hence the .gcp in the URI). Most of this information can be found just by jumping on <a href=\"https://www.mongodb.com/\">mongodb.com</a> and investigating your URI via the \"connect\" popup:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-30-at-9.46.42-PM.png\" class=\"kg-image\"><figcaption>That should make things a bit easier.</figcaption></figure><p>Now we can set up our connection:</p><pre><code class=\"language-python\">import pymongo\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@hackerdata-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n</code></pre>\n<p>Note that we intentionally set the connection to <strong>False. </strong>Otherwise, we're going to find ourselves in a hell of managing open connections every time we interact with the DB.</p><p>Speaking of the DB, we need to specify which database and collection we want to interact with. This brings our config file to something as follows:</p><pre><code class=\"language-python\">import pymongo\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@myInstance-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\ndb = pymongo.database.Database(mongo, 'mydatabase')\ncol = pymongo.collection.Collection(db, 'mycollection')\n</code></pre>\n<p>Lastly, if you'd like to access, say, all the objects inside of a collection (or similar query), we'll just need to add a few lines line to ensure we're reading the collection's data:</p><pre><code class=\"language-python\">import pymongo\nfrom bson.json_util import dumps\nimport json\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@myInstance-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\ndb = pymongo.database.Database(mongo, 'mydatabase')\ncol = pymongo.collection.Collection(db, 'mycollection')\n\ncol_results = json.loads(dumps(col.find().limit(5).sort(&quot;time&quot;, -1)))\n</code></pre>\n<p>Remember that Mongo returns BSON objects as opposed to JSON objects, which isn't very useful for our purposes. To alleviate this we'll do a messy little dance to convert Mongo's BSON into a string, and convert this to JSON using <strong>json.dumps()</strong>.</p><p><strong>Note: </strong>the need to do this may have been something changed in recent versions of Mongo, as I have older application functioning where this wasn't the case. ¯\\_(ツ)_/¯.</p><h2 id=\"creating-a-form\">Creating a Form</h2><p>Heading over to <strong>form.py, </strong>we just need to set up a simple single-field form for users to submit their URLs. For the sake of Python, let's say we're only accepting URLs for Jupyter noteboooks:</p><pre><code class=\"language-python\">from wtforms import Form, StringField, validators\nfrom wtforms.validators import DataRequired, Regexp\n\nclass myForm(Form):\n    &quot;&quot;&quot;Homepage form.&quot;&quot;&quot;\n    PlotlyURL = StringField('Provide a raw .ipynb URL from Github',\n    validators=[\n            DataRequired(),\n            Regexp(&quot;.*\\.ipynb$&quot;,\n            message=&quot;Please provide a URL ending in ipynb&quot;),\n          ])\n</code></pre>\n<p>We could have an entire tutorial just about Flask's WTF<a href=\"http://flask.pocoo.org/docs/1.0/patterns/wtforms/\">orms</a>, but let's stay on topic  and move on to <strong>currenttime.py.</strong></p><h2 id=\"adding-time-metadata\">Adding Time Metadata</h2><p>In a lot of cases where we store information to a database, we at least want to add certain metadata such as the time something was added. This allows us to arrange results by most recently updated, which we'll be doing in this example.</p><pre><code class=\"language-python\">from datetime import datetime, timezone\n\ndef getTime():\n    &quot;&quot;&quot;Get user's current time&quot;&quot;&quot;\n    rightnow = datetime.today()\n    return rightnow\n\ndef getPrettyTime():\n    &quot;&quot;&quot;Get user's pretty current time&quot;&quot;&quot;\n    rightnow = datetime.today()\n    prettytime = rightnow.ctime()\n    return prettytime\n\nyourtime = getTime()\nprettytime = getPrettyTime()\n</code></pre>\n<p>The variable <strong>yourtime</strong> will be a datetime string representing the local time of the user creating a new record. We will use this value to sort the queried results by time. On the contrary,  <strong>prettytime</strong> will be the same time, only formatted in a way that is readable to humans.</p><h2 id=\"putting-the-pieces-together\">Putting the Pieces Together</h2><p>Finally we get to move on <strong>app.py </strong>and get this thing moving. We'll initiate our app by importing the necessary libraries, as well as the scripts we just created:</p><pre><code class=\"language-python\">from flask import Flask, render_template, Markup, request, redirect\nfrom config import col, col_results\nimport requests\nfrom form import myForm\nfrom flask_static_compress import FlaskStaticCompress\nfrom currenttime import yourtime, prettytime\nimport logging\n</code></pre>\n<p>Note that we need to import from the DB config we set earlier is the \"col\" variable; we'll only be interacting directly with the collection we want to modify, and the rest is assumed within the config file itself. Now let's build a route for our homepage that does two things:</p><ul><li>Allows users to submit a URL via the simple form we created</li><li>Displays all previous searches by all users.</li></ul><pre><code class=\"language-python\">from flask import Flask, render_template, Markup, request, redirect\nfrom config import col, col_results\nimport requests\nfrom form import myForm\nfrom flask_static_compress import FlaskStaticCompress\nfrom currenttime import yourtime, prettytime\nimport logging\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    &quot;&quot;&quot;Landing page.&quot;&quot;&quot;\n    recent_searches = list(col_results)\n    return render_template('/index.html', form=myForm(), recents=recent_searches, template=&quot;home-template&quot;)\n</code></pre>\n<p>There's only two significant lines here, but let's break them down piece by piece.</p><h3 id=\"recent_searches\">recent_searches</h3><p>First we set a <strong>recent_searches</strong> variable which is essentially a query against our collection to retrieve a list of previous searches. We ask that these be returned as a <strong>list()</strong> upfront. Typically the <strong>find() </strong>method would contain the constraints of our query, but we're simply asking to return <em>all</em> results in the collection, with a <strong>limit()</strong> up to 5. Finally, we <strong>sort()</strong> the results by the field we refer to as 'time' is descending order, as noted by the -1 argument.</p><p>This is all probably very difficult to visualize without a graphic. Here's a snapshot of the collection we're defining with dummy data added:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-31-at-11.08.44-AM.png\" class=\"kg-image\"><figcaption>See why we need to differentiate \"time\" and \"prettytime\"?</figcaption></figure><h3 id=\"render_template\">render_template</h3><p>We <a href=\"https://hackersandslackers.com/serving-static-assets-in-flask/\">already know</a> the basics of serving templates and assets in Flask, so it shouldn't be too difficult to break down the last line in our route:</p><ul><li><strong>'/index.html'</strong> specifies the base template we'll be serving up.</li><li><strong>form=myForm()</strong> passes the form class we created earlier to the form partial we're including as part of the index page.</li><li><strong>recents=recent_searches</strong> passes the query of previous searches to the template, with which we can build a widget.</li><li><strong>template=\"home-template\" </strong>is a simple variable passed which we'll utilize as a class on the page we're loading.</li></ul><h2 id=\"the-result\">The Result</h2><p>From everything we've completed, you should be expecting to see a somewhat worthless page where users can submit links via a form, simply to see results posted by previous posters. If we expand on this idea just a bit, we can see how something so simple can actually be extended to a full product: </p><blockquote class=\"embedly-card\" data-card-controls=\"0\"><h4><a href=\"https://planetjupyter.com\">Planet Jupyter</a></h4><p>Style your Jupyter Notebooks.</p></blockquote>\n<script async src=\"//cdn.embedly.com/widgets/platform.js\" charset=\"UTF-8\"></script><p>Planet Jupyter is demo product we built at H&amp;S to style Jupyter notebooks. Perhaps 60% of the logic behind Planet Jupyter is the simple DB interactions we just covered, with the rest being added flair.</p><p>This is not a shameless plug for the barely functioning toys we've built, mind you, but rather an example of simple DB interactions using Flask can be easily extensible into relevant, useful, products.</p><p>We hope you’ve found this tutorial to be useful!</p>","url":"https://hackersandslackers.com/using-mongodb-atlas-as-your-flask-database/","uuid":"e8c92cbd-6845-45b5-acfc-a744810eafcd","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b5cab1e2189c353565a2adf"}}]}},"pageContext":{"slug":"nosql","limit":12,"skip":0,"numberOfPages":1,"humanPageNumber":1,"prevPageNumber":null,"nextPageNumber":null,"previousPagePath":null,"nextPagePath":null}}