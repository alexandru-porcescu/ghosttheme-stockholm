{"data":{"ghostPost":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673703","title":"Lynx Roundup, September 20th","slug":"lynx-roundup-september-20th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/lynx/87@2x.jpg","excerpt":"Map projections!  Jupyter stuff!  A new kind of neuron!","custom_excerpt":"Map projections!  Jupyter stuff!  A new kind of neuron!","created_at_pretty":"19 September, 2018","published_at_pretty":"20 September, 2018","updated_at_pretty":"20 September, 2018","created_at":"2018-09-18T22:43:29.000-04:00","published_at":"2018-09-20T13:00:00.000-04:00","updated_at":"2018-09-20T13:00:00.000-04:00","meta_title":"Lynx Roundup, September 20th | Hackers and Slackers","meta_description":"Map projections!  Jupyter stuff!  A new kind of neuron!","og_description":"Map projections!  Jupyter stuff!  A new kind of neuron!","og_image":"https://hackersandslackers.com/content/images/lynx/87@2x.jpg","og_title":"Lynx Roundup, September 20th","twitter_description":"Map projections!  Jupyter stuff!  A new kind of neuron!","twitter_image":"https://hackersandslackers.com/content/images/lynx/87@2x.jpg","twitter_title":"Lynx Roundup, September 20th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"What is this weird Twitter army of Amazon drones cheerfully defending warehouse\nwork?\n[https://techcrunch.com/2018/08/23/what-is-this-weird-twitter-army-of-amazon-drones-cheerfully-defending-warehouse-work/]\n\n\n\nhttp://willcrichton.net/notes/lessons-from-jupytercon/\n\n\n\n\n\nEqual Earth map projection\n[https://www.johndcook.com/blog/2018/08/10/equal-earth-projection/]\n\n\n\nhttps://www.wired.com/story/meet-the-rosehip-cell-a-new-kind-of-neuron\n\n\n\n\n\nPareto’s 80-20 rule\n[https://www.johndcook.com/blog/2018/08/27/pareto-80-20-rule/]\n\nEarlier this week, I was at the Second Joint Congress on Evolutionary Biology\n[https://www.evolutionmontpellier2018.org/]  (Evol2018). It was overwhelming,\nbut very educational. \n\nMany of the talks were about very specific evolutionary mechanisms in very\nspecific model organisms. This diversity of questions and approaches to answers\nreminded me of the importance of bouquets of heuristic models in biology. But\nwhat made this particularly overwhelming for me as a non-biologist was the lack\nof unifying formal framework to make sense of what was happening. Without the\nencyclopedic knowledge of a good naturalist, I had a very difficult time linking\ntopics to each other. I was experiencing the pluralistic nature of biology. This\nwas stressed by Laura Nuño De La Rosa [https://lauranrg.wordpress.com/]‘s slide\nthat contrasts the pluralism of biology with the theory reduction of physics:\n\n  [https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg]\n\nThat’s right, to highlight the pluralism, there were great talks from\nphilosophers of biology along side all the experimental and theoretical biology\nat Evol2018.\n\nAs I’ve discussed before, I think that theoretical computer science can provide\nthe unifying formal framework that biology needs\n[https://egtheory.wordpress.com/2013/09/09/cstheory-of-biology/]. In particular,\nthe cstheory approach to reductions is the more robust (compared to physics)\nnotion of ‘theory reduction’ that a pluralistic discipline like evolutionary\nbiology could benefit from. However, I still don’t have any idea of how such a\nformal framework would look in practice. Hence, throughout Evol2018 I needed\nrefuge from the overwhelming overstimulation of organisms and mechanisms that\nwere foreign to me. \n\nOne of the places I sought refuge was in talks on computational studies. There,\nI heard speakers emphasize several times that they weren’t “just simulating\nevolution” but that their programs were evolution (or evolving) in a computer.\nNot only were they looking at evolution in a computer, but this model organism\ngave them an advantage over other systems because of its transparency: they\ncould track every lineage, every offspring, every mutation, and every random\nevent. Plus, computation is cheaper and easier than culturing E.coli, brewing\nyeast, or raising fruit flies. And just like those model organisms,\ncomputational models could test evolutionary hypotheses and generate new ones.\n\nThis defensive emphasis surprised me. It suggested that these researchers have\noften been questioned on the usefulness of their simulations for the study of\nevolution. \n\nIn this post, I want to reflect on some reasons for such questioning. \n\n\n\nLet’s rewind to a time before computers. To a time before Darwin’s evolution by\nnatural selection. Just to stress that this debate could have been had (and to\nsome extent, has been had) before either computers or evolution. Let’s rewind to\nthe time of Thomas Hobbes. \n\nWhen Hobbes was writing, clocks and watches were some of the best examples of\ntechnology; and the hottest idea was the new science of mechanistic physics.\nExcept Hobbes wanted to write about politics — more than that, he wanted to\nwrite a science of politics. The problem was that by looking at the\ncommonwealth, he saw the importance of its form and the relative unimportance of\nits matter. If he was a pure Aristotelian, this would be no issue, but he\naccepted the new science’s eliminate of form as an explanatory tool. For the\nmechanistic physics, formal cause was not seen as an acceptable mode of\nexplanation. \n\nThis forced Hobbes to distinguish between two kinds of knowledge. First, there\nwas knowledge of things that we have made ourselves — for him, the central\nexamples of this were geometry and the state. Second, there was knowledge of\nthings that we did not make — i.e., the domain of mechanistic physics. In the\ncase of physics, we could not deconstruct the machine because different\nmechanisms can produce the same effect. Thus, if we tried to reason from effects\nto causes, we could only arrive at reasonable conjectures and hypotheses. But\nfor the state, we could  know the causes because we had constructed them\nourselves. With this move, Hobbes could avoid the problem of underdetermination.\n\nThis is also the move that a computational modeler employs. By explicitly\nspecifying all the rules that the digital organism follows, she is making its\nworld. Thus, she can then dismantle the machine and understand all of its parts\nand how they contribute to the effect of interest. Unlike Hobbes, she has the\nextra advantage of not having had the State build around her and being able to\ndismantle her simulation at will. Of course, in practice, just like Hobbes, most\ncomputer modelers usually don’t fully understand the code they’ve written.\nStill, this powerful determination is the computational modeler’s cake.\n\nUnfortunately, the modeler wants to eat her cake, too. By appealing to multiple\nrealizability, the modeler can claim that evolution does not need to be realized\nin DNA but can also be in silico. In other words, that evolution is\nunderdetermined. She will usually proceed further by saying that a big advantage\nof a computational model is that it can be run in conditions that aren’t easily\naccessible to wet-lab experiments. In other words, she wants to assume a set of\nrules — which are underdetermined by a set of intuitions of real experiments —\nand then extrapolate their effects to carry out unreal experiments.\n\nI think it is this tension between having your cake and eating it that causes\nthe criticisms of “just a simulation”. All the advantages of peering\nunder-the-hood come from determination, but all the applicability to\nnon-simulations comes from underdetermination. And since we don’t usually\ninherently care about in silico  organisms, we have to embrace the\nunderdeterminism for the sake of applicability. Once we do that, all the power\nof peering under-the-hood disappears: since the detailed mechanisms are just\nconjectural. This is made worse by the curse of computing\n[https://egtheory.wordpress.com/2013/05/14/curse-of-computing/]  in big\nsimulations, where the modeler doesn’t actually understand all the details of\nthe mechanism they implemented — for example, when the organisms are arbitrary\nprograms in some simple specification language.\n\nSome of this critique can be avoided by replacing in silico  with in logico. And\nI think computational modelers often offer this defence, too. For this, let’s\nturn again to Hobbes. \n\nAfter sidestepping the problem of underdetermination, Hobbes could imagine the\nState as a giant watch or more general automaton. But he did not see the gears\nof that watch as the humans that make up society. Instead he compares artificial\nconstructs like “wealth of the population” to strength of the automaton,\ncounselors to memory, and reward/punishment to nerves. In this way, he was not\nimplementing the State through physical processes (which would then make its\nstudy the extension of physical mechanics) but through conceptual human-made\nprocesses.\n\nWe can do a similar move with simulations. We can recognize that the physical\nworld is separate from our descriptions of it. And that evolution is our way of\nmaking sense of the order and diversity in the physical world. As such,\nevolution is a concept which we can implement with other concepts. A computer\nsimulation is then just the physical model of those concepts. Much like a clock\nwas — for a long time — often used as a physical model of our astronomical\nhypotheses. This is the same sort of separation of theory and reality that I\ntried to do with Post’s variant of the Church-Turing thesis\n[https://egtheory.wordpress.com/2014/09/11/transcendental-idealism-and-posts-variant-of-the-church-turing-thesis/]\n. And this provide a way to interpret evolutionary simulations as \nimplementations of theory\n[https://egtheory.wordpress.com/2018/07/14/heuristics-and-abstraction/].\n\nI think that modelers make the above argument when they point out that what\nmatters is not the DNA/RNA/squishy-stuff of biology, but some set of logical\nprocess-based rules that defines the applicability of evolution. However, I\nthink that when we make this argument, we have to be mindful of the\nunderdetermination of our theory. In particular, that our goal is to improve how\nthe theory is determined. In practice, I think that this can only be done if we\nprovide an opportunity to directly link to systems of interest. We want our\nprocesses to have operationalizations that apply both in our computational model\nand other model organisms or natural organisms. For me, this can mean giving up\nsome of the peaking under the hood in favor of an effective theory rather than\na\nreductive one\n[https://egtheory.wordpress.com/2018/07/17/jms-reductive-vs-effective/].\n\nOf course, the above considerations are not limited to computer models. Model\norganisms in conditions designed for the purpose of a particular experiment are\nboth conceptual and physical systems. And although computer models are also both\nconceptual and physical systems, these two aspects of them are usually easier to\ndisentangle than for model organisms. This means that the above considerations\ncould be repeated for experimental systems, but more care would be required.\n\n\n\n\n\nhttps://www.oreilly.com/ideas/jupyter-notebooks-and-the-intersection-of-data-science-and-data-engineering","html":"<p></p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"wp-embedded-content\"><a href=\"https://techcrunch.com/2018/08/23/what-is-this-weird-twitter-army-of-amazon-drones-cheerfully-defending-warehouse-work/\">What is this weird Twitter army of Amazon drones cheerfully defending warehouse work?</a></blockquote>\n<script type=\"text/javascript\">\n<!--//--><![CDATA[//><!--\n\t\t!function(a,b){\"use strict\";function c(){if(!e){e=!0;var a,c,d,f,g=-1!==navigator.appVersion.indexOf(\"MSIE 10\"),h=!!navigator.userAgent.match(/Trident.*rv:11\\./),i=b.querySelectorAll(\"iframe.wp-embedded-content\");for(c=0;c<i.length;c++){if(d=i[c],!d.getAttribute(\"data-secret\"))f=Math.random().toString(36).substr(2,10),d.src+=\"#?secret=\"+f,d.setAttribute(\"data-secret\",f);if(g||h)a=d.cloneNode(!0),a.removeAttribute(\"security\"),d.parentNode.replaceChild(a,d)}}}var d=!1,e=!1;if(b.querySelector)if(a.addEventListener)d=!0;if(a.wp=a.wp||{},!a.wp.receiveEmbedMessage)if(a.wp.receiveEmbedMessage=function(c){var d=c.data;if(d.secret||d.message||d.value)if(!/[^a-zA-Z0-9]/.test(d.secret)){var e,f,g,h,i,j=b.querySelectorAll('iframe[data-secret=\"'+d.secret+'\"]'),k=b.querySelectorAll('blockquote[data-secret=\"'+d.secret+'\"]');for(e=0;e<k.length;e++)k[e].style.display=\"none\";for(e=0;e<j.length;e++)if(f=j[e],c.source===f.contentWindow){if(f.removeAttribute(\"style\"),\"height\"===d.message){if(g=parseInt(d.value,10),g>1e3)g=1e3;else if(~~g<200)g=200;f.height=g}if(\"link\"===d.message)if(h=b.createElement(\"a\"),i=b.createElement(\"a\"),h.href=f.getAttribute(\"src\"),i.href=d.value,i.host===h.host)if(b.activeElement===f)a.top.location.href=d.value}else;}},d)a.addEventListener(\"message\",a.wp.receiveEmbedMessage,!1),b.addEventListener(\"DOMContentLoaded\",c,!1),a.addEventListener(\"load\",c,!1)}(window,document);\n//--><!]]>\n</script><iframe sandbox=\"allow-scripts\" security=\"restricted\" src=\"https://techcrunch.com/2018/08/23/what-is-this-weird-twitter-army-of-amazon-drones-cheerfully-defending-warehouse-work/embed/\" width=\"600\" height=\"338\" title=\"&#8220;What is this weird Twitter army of Amazon drones cheerfully defending warehouse work?&#8221; &#8212; TechCrunch\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" class=\"wp-embedded-content\"></iframe></figure><p></p><p></p><p><a href=\"http://willcrichton.net/notes/lessons-from-jupytercon/\">http://willcrichton.net/notes/lessons-from-jupytercon/</a></p><p></p><p></p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"wp-embedded-content\"><a href=\"https://www.johndcook.com/blog/2018/08/10/equal-earth-projection/\">Equal Earth map projection</a></blockquote>\n<script type=\"text/javascript\">\n<!--//--><![CDATA[//><!--\n\t\t!function(a,b){\"use strict\";function c(){if(!e){e=!0;var a,c,d,f,g=-1!==navigator.appVersion.indexOf(\"MSIE 10\"),h=!!navigator.userAgent.match(/Trident.*rv:11\\./),i=b.querySelectorAll(\"iframe.wp-embedded-content\");for(c=0;c<i.length;c++){if(d=i[c],!d.getAttribute(\"data-secret\"))f=Math.random().toString(36).substr(2,10),d.src+=\"#?secret=\"+f,d.setAttribute(\"data-secret\",f);if(g||h)a=d.cloneNode(!0),a.removeAttribute(\"security\"),d.parentNode.replaceChild(a,d)}}}var d=!1,e=!1;if(b.querySelector)if(a.addEventListener)d=!0;if(a.wp=a.wp||{},!a.wp.receiveEmbedMessage)if(a.wp.receiveEmbedMessage=function(c){var d=c.data;if(d.secret||d.message||d.value)if(!/[^a-zA-Z0-9]/.test(d.secret)){var e,f,g,h,i,j=b.querySelectorAll('iframe[data-secret=\"'+d.secret+'\"]'),k=b.querySelectorAll('blockquote[data-secret=\"'+d.secret+'\"]');for(e=0;e<k.length;e++)k[e].style.display=\"none\";for(e=0;e<j.length;e++)if(f=j[e],c.source===f.contentWindow){if(f.removeAttribute(\"style\"),\"height\"===d.message){if(g=parseInt(d.value,10),g>1e3)g=1e3;else if(~~g<200)g=200;f.height=g}if(\"link\"===d.message)if(h=b.createElement(\"a\"),i=b.createElement(\"a\"),h.href=f.getAttribute(\"src\"),i.href=d.value,i.host===h.host)if(b.activeElement===f)a.top.location.href=d.value}else;}},d)a.addEventListener(\"message\",a.wp.receiveEmbedMessage,!1),b.addEventListener(\"DOMContentLoaded\",c,!1),a.addEventListener(\"load\",c,!1)}(window,document);\n//--><!]]>\n</script><iframe sandbox=\"allow-scripts\" security=\"restricted\" src=\"https://www.johndcook.com/blog/2018/08/10/equal-earth-projection/embed/\" width=\"600\" height=\"338\" title=\"&#8220;Equal Earth map projection&#8221; &#8212; John D. Cook\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" class=\"wp-embedded-content\"></iframe></figure><p></p><p></p><p><a href=\"https://www.wired.com/story/meet-the-rosehip-cell-a-new-kind-of-neuron\">https://www.wired.com/story/meet-the-rosehip-cell-a-new-kind-of-neuron</a></p><p></p><p></p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"wp-embedded-content\"><a href=\"https://www.johndcook.com/blog/2018/08/27/pareto-80-20-rule/\">Pareto&#8217;s 80-20 rule</a></blockquote>\n<script type=\"text/javascript\">\n<!--//--><![CDATA[//><!--\n\t\t!function(a,b){\"use strict\";function c(){if(!e){e=!0;var a,c,d,f,g=-1!==navigator.appVersion.indexOf(\"MSIE 10\"),h=!!navigator.userAgent.match(/Trident.*rv:11\\./),i=b.querySelectorAll(\"iframe.wp-embedded-content\");for(c=0;c<i.length;c++){if(d=i[c],!d.getAttribute(\"data-secret\"))f=Math.random().toString(36).substr(2,10),d.src+=\"#?secret=\"+f,d.setAttribute(\"data-secret\",f);if(g||h)a=d.cloneNode(!0),a.removeAttribute(\"security\"),d.parentNode.replaceChild(a,d)}}}var d=!1,e=!1;if(b.querySelector)if(a.addEventListener)d=!0;if(a.wp=a.wp||{},!a.wp.receiveEmbedMessage)if(a.wp.receiveEmbedMessage=function(c){var d=c.data;if(d.secret||d.message||d.value)if(!/[^a-zA-Z0-9]/.test(d.secret)){var e,f,g,h,i,j=b.querySelectorAll('iframe[data-secret=\"'+d.secret+'\"]'),k=b.querySelectorAll('blockquote[data-secret=\"'+d.secret+'\"]');for(e=0;e<k.length;e++)k[e].style.display=\"none\";for(e=0;e<j.length;e++)if(f=j[e],c.source===f.contentWindow){if(f.removeAttribute(\"style\"),\"height\"===d.message){if(g=parseInt(d.value,10),g>1e3)g=1e3;else if(~~g<200)g=200;f.height=g}if(\"link\"===d.message)if(h=b.createElement(\"a\"),i=b.createElement(\"a\"),h.href=f.getAttribute(\"src\"),i.href=d.value,i.host===h.host)if(b.activeElement===f)a.top.location.href=d.value}else;}},d)a.addEventListener(\"message\",a.wp.receiveEmbedMessage,!1),b.addEventListener(\"DOMContentLoaded\",c,!1),a.addEventListener(\"load\",c,!1)}(window,document);\n//--><!]]>\n</script><iframe sandbox=\"allow-scripts\" security=\"restricted\" src=\"https://www.johndcook.com/blog/2018/08/27/pareto-80-20-rule/embed/\" width=\"600\" height=\"338\" title=\"&#8220;Pareto&#8217;s 80-20 rule&#8221; &#8212; John D. Cook\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" class=\"wp-embedded-content\"></iframe></figure><p></p><figure class=\"kg-card kg-embed-card\"><p>Earlier this week, I was at the <a href=\"https://www.evolutionmontpellier2018.org/\">Second Joint Congress on Evolutionary Biology</a> (Evol2018). It was overwhelming, but very educational. </p>\n<p>Many of the talks were about very specific evolutionary mechanisms in very specific model organisms. This diversity of questions and approaches to answers reminded me of the importance of bouquets of heuristic models in biology. But what made this particularly overwhelming for me as a non-biologist was the lack of unifying formal framework to make sense of what was happening. Without the encyclopedic knowledge of a good naturalist, I had a very difficult time linking topics to each other. I was experiencing the pluralistic nature of biology. This was stressed by <a href=\"https://lauranrg.wordpress.com/\">Laura Nuño De La Rosa</a>&#8216;s slide that contrasts the pluralism of biology with the theory reduction of physics:</p>\n<p><a href=\"https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg\"><img data-attachment-id=\"13821\" data-permalink=\"https://egtheory.wordpress.com/2018/08/25/hobbes-on-simulations/ndlr_slide/\" data-orig-file=\"https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg\" data-orig-size=\"1486,1218\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPad&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1534847086&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.28&quot;,&quot;iso&quot;:&quot;50&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"NDLR_Slide\" data-image-description=\"\" data-medium-file=\"https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg?w=300\" data-large-file=\"https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg?w=1024\" src=\"https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg?w=1024&#038;h=839\" alt=\"\" class=\"alignright size-large wp-image-13821\" srcset=\"https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg?w=1024&amp;h=839 1024w, https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg?w=150&amp;h=123 150w, https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg?w=300&amp;h=246 300w, https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg?w=768&amp;h=629 768w, https://egtheory.files.wordpress.com/2018/08/ndlr_slide.jpg 1486w\" sizes=\"(max-width: 1024px) 100vw, 1024px\"></a></p>\n<p>That&#8217;s right, to highlight the pluralism, there were great talks from philosophers of biology along side all the experimental and theoretical biology at Evol2018.</p>\n<p>As I&#8217;ve discussed before, I think that <a href=\"https://egtheory.wordpress.com/2013/09/09/cstheory-of-biology/\">theoretical computer science can provide the unifying formal framework that biology needs</a>. In particular, the cstheory approach to reductions is the more robust (compared to physics) notion of &#8216;theory reduction&#8217; that a pluralistic discipline like evolutionary biology could benefit from. However, I still don&#8217;t have any idea of how such a formal framework would look in practice. Hence, throughout Evol2018 I needed refuge from the overwhelming overstimulation of organisms and mechanisms that were foreign to me. </p>\n<p>One of the places I sought refuge was in talks on computational studies. There, I heard speakers emphasize several times that they weren&#8217;t &#8220;just simulating evolution&#8221; but that their programs were evolution (or evolving) in a computer. Not only were they looking at evolution in a computer, but this model organism gave them an advantage over other systems because of its transparency: they could track every lineage, every offspring, every mutation, and every random event. Plus, computation is cheaper and easier than culturing E.coli, brewing yeast, or raising fruit flies. And just like those model organisms, computational models could test evolutionary hypotheses and generate new ones.</p>\n<p>This defensive emphasis surprised me. It suggested that these researchers have often been questioned on the usefulness of their simulations for the study of evolution. </p>\n<p>In this post, I want to reflect on some reasons for such questioning. </p>\n<p><!--more--></p>\n<p>Let&#8217;s rewind to a time before computers. To a time before Darwin&#8217;s evolution by natural selection. Just to stress that this debate could have been had (and to some extent, has been had) before either computers or evolution. Let&#8217;s rewind to the time of Thomas Hobbes. </p>\n<p>When Hobbes was writing, clocks and watches were some of the best examples of technology; and the hottest idea was the new science of mechanistic physics. Except Hobbes wanted to write about politics &#8212; more than that, he wanted to write a science of politics. The problem was that by looking at the commonwealth, he saw the importance of its form and the  relative unimportance of its matter. If he was a pure Aristotelian, this would be no issue, but he accepted the new science&#8217;s eliminate of form as an explanatory tool. For the mechanistic physics, formal cause was not seen as an acceptable mode of explanation. </p>\n<p>This forced Hobbes to distinguish between two kinds of knowledge. First, there was knowledge of things that we have made ourselves &#8212; for him, the central examples of this were geometry and the state. Second, there was knowledge of things that we did not make &#8212; i.e., the domain of mechanistic physics. In the case of physics, we could not deconstruct the machine because different mechanisms can produce the same effect. Thus, if we tried to reason from effects to causes, we could only arrive at reasonable conjectures and hypotheses. But for the state, we <i>could</i> know the causes because we had constructed them ourselves. With this move, Hobbes could avoid the problem of underdetermination.</p>\n<p>This is also the move that a computational modeler employs. By explicitly specifying all the rules that the digital organism follows, she is making its world. Thus, she can then dismantle the machine and understand all of its parts and how they contribute to the effect of interest. Unlike Hobbes, she has the extra advantage of not having had the State build around her and being able to dismantle her simulation at will. Of course, in practice, just like Hobbes, most computer modelers usually don&#8217;t fully understand the code they&#8217;ve written. Still, this powerful determination is the computational modeler&#8217;s cake.</p>\n<p>Unfortunately, the modeler wants to eat her cake, too. By appealing to multiple realizability, the modeler can claim that evolution does not need to be realized in DNA but can also be <i>in silico</i>. In other words, that evolution is underdetermined. She will usually proceed further by saying that a big advantage of a computational model is that it can be run in conditions that aren&#8217;t easily accessible to wet-lab experiments. In other words, she wants to assume a set of rules &#8212; which are underdetermined by a set of intuitions of real experiments &#8212; and then extrapolate their effects to carry out unreal experiments.</p>\n<p>I think it is this tension between having your cake and eating it that causes the criticisms of &#8220;just a simulation&#8221;. All the advantages of peering under-the-hood come from determination, but all the applicability to non-simulations comes from underdetermination. And since we don&#8217;t usually inherently care about <i>in silico</i> organisms, we have to embrace the underdeterminism for the sake of applicability. Once we do that, all the power of peering under-the-hood disappears: since the detailed mechanisms are just conjectural. This is made worse by the <a href=\"https://egtheory.wordpress.com/2013/05/14/curse-of-computing/\">curse of computing</a> in big simulations, where the modeler doesn&#8217;t actually understand all the details of the mechanism they implemented &#8212; for example, when the organisms are arbitrary programs in some simple specification language.</p>\n<p>Some of this critique can be avoided by replacing <i>in silico</i> with <i>in logico</i>. And I think computational modelers often offer this defence, too. For this, let&#8217;s turn again to Hobbes. </p>\n<p>After sidestepping the problem of underdetermination, Hobbes could imagine the State as a giant watch or more general automaton. But he did not see the gears of that watch as the humans that make up society. Instead he compares artificial constructs like &#8220;wealth of the population&#8221; to strength of the automaton, counselors to memory, and reward/punishment to nerves. In this way, he was not implementing the State through physical processes (which would then make its study the extension of physical mechanics) but through conceptual human-made processes.</p>\n<p>We can do a similar move with simulations. We can recognize that the physical world is separate from our descriptions of it. And that evolution is our way of making sense of the order and diversity in the physical world. As such, evolution is a concept which we can implement with other concepts. A computer simulation is then just the physical model of those concepts. Much like a clock was &#8212; for a long time &#8212; often used as a physical model of our astronomical hypotheses. This is the same sort of separation of theory and reality that I tried to do with <a href=\"https://egtheory.wordpress.com/2014/09/11/transcendental-idealism-and-posts-variant-of-the-church-turing-thesis/\">Post&#8217;s variant of the Church-Turing thesis</a>. And this provide a way to interpret evolutionary simulations as <a href=\"https://egtheory.wordpress.com/2018/07/14/heuristics-and-abstraction/\">implementations of theory</a>.</p>\n<p>I think that modelers make the above argument when they point out that what matters is not the DNA/RNA/squishy-stuff of biology, but some set of logical process-based rules that defines the applicability of evolution. However, I think that when we make this argument, we have to be mindful of the underdetermination of our theory. In particular, that our goal is to improve how the theory is determined. In practice, I think that this can only be done if we provide an opportunity to directly link to systems of interest. We want our processes to have operationalizations that apply both in our computational model and other model organisms or natural organisms. For me, this can mean giving up some of the peaking under the hood in favor of <a href=\"https://egtheory.wordpress.com/2018/07/17/jms-reductive-vs-effective/\">an effective theory rather than a reductive one</a>.</p>\n<p>Of course, the above considerations are not limited to computer models. Model organisms in conditions designed for the purpose of a particular experiment are both conceptual and physical systems. And although computer models are also both conceptual and physical systems, these two aspects of them are usually easier to disentangle than for model organisms. This means that the above considerations could be repeated for experimental systems, but more care would be required.</p>\n</figure><p></p><p></p><p><a href=\"https://www.oreilly.com/ideas/jupyter-notebooks-and-the-intersection-of-data-science-and-data-engineering\">https://www.oreilly.com/ideas/jupyter-notebooks-and-the-intersection-of-data-science-and-data-engineering</a></p>","url":"https://hackersandslackers.com/lynx-roundup-september-20th/","uuid":"9c5d96fa-9ba5-4f91-a03e-45e8d37bf6f2","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5ba1b7d178afd65c7f626dd0"}},"pageContext":{"slug":"lynx-roundup-september-20th"}}