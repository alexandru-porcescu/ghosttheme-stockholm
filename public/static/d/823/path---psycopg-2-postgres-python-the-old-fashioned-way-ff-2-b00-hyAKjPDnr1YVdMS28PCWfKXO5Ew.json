{"data":{"ghostPost":{"id":"Ghost__Post__5c3d0b441719dc6b38ee53b6","title":"Psycopg2: PostgreSQL & Python the Old Fashioned Way","slug":"psycopg2-postgres-python-the-old-fashioned-way","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/psycopg2.jpg","excerpt":"Manage PostgreSQL database interactions in Python with the Psycopg2 library.","custom_excerpt":"Manage PostgreSQL database interactions in Python with the Psycopg2 library.","created_at_pretty":"14 January, 2019","published_at_pretty":"15 January, 2019","updated_at_pretty":"28 March, 2019","created_at":"2019-01-14T17:20:52.000-05:00","published_at":"2019-01-15T15:57:34.000-05:00","updated_at":"2019-03-28T14:46:14.000-04:00","meta_title":"Psycopg2: PostgreSQL & Python the Old Way | Hackers and Slackers","meta_description":"Manage PostgreSQL database interactions in Python with the Psycopg2 library.","og_description":"Manage PostgreSQL database interactions in Python with the Psycopg2 library.","og_image":"https://hackersandslackers.com/content/images/2019/02/psycopg2.jpg","og_title":"Psycopg2: PostgreSQL & Python the Old Fashioned Way","twitter_description":"Manage PostgreSQL database interactions in Python with the Psycopg2 library.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/psycopg2.jpg","twitter_title":"Psycopg2: PostgreSQL & Python the Old Fashioned Way","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"PostgreSQL","slug":"postgresql","description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","feature_image":null,"meta_description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","meta_title":"Working with PostgreSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"PostgreSQL","slug":"postgresql","description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","feature_image":null,"meta_description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","meta_title":"Working with PostgreSQL | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"Last time we met, we joyfully shared a little tirade\n[https://hackersandslackers.com/pythonic-database-management-with-sqlalchemy/] \nabout missing out on functionality provided to us by libraries such as \nSQLAlchemy, and the advantages of interacting with databases where ORMs are\ninvolved. I stand by that sentiment, but I’ll now directly contradict myself by\nsharing some tips on using vanilla Psycopg2  to interact with databases. \n\nWe never know when we’ll be stranded on a desert island without access to\nSQLAlchemy, but a lonesome Psycopg2 washes up on shore. Either that or perhaps\nyou’re part of a development team stuck in a certain way of doing things which\ndoesn't include utilize SQLAlchemy. Whatever the situation may be, we’re here\nfor you. \n\nThe Quintessential Boilerplate\nNo matter the type of database or the library, the boilerplate code for\nconnecting to databases remains mostly the same. To some extent, this even holds\ntrue across programming languages. Let's look at a barebones example while\nignoring the library at hand:\n\nimport SomeDatabaseLibrary\n\nclass Database:\n    \"\"\"A Generic Database class.\"\"\"\n\n    def __init__(self, config):\n        self.username = config.database('USERNAME')\n        self.password = config.database('PASSWORD')\n        self.host = config.database('HOST')\n        self.port = config.database('PORT')\n        self.db = config.database('DB')\n\n    def run_query(self, query):\n            conn = None\n            records = []\n            try:\n                conn = SomeDatabaseLibrary.connect(host=self.host, \n                                                user=self.username, \n                                                password=self.password,\n                                                port=self.port, \n                                                dbname=self.db)\n                with conn.cursor() as cur:\n                    cur.execute(query)\n                    result = cur.fetchall()\n                    for row in result:\n                        records.append(row)\n                    cur.close()\n                    return records\n            except (Exception, SomeDatabaseLibrary.DatabaseError) as error:\n                print(error)\n            finally:\n                if conn is not None:\n                    conn.close()\n                    print('Database connection closed.')\n\n\nIn the above example, we could swap SomeDatabaseLibrary  with either Psycopg2 \nor PyMySQL  just the same. If we compare this to our example with PyMySQL\n[https://hackersandslackers.com/using-pymysql/], it's easy to see that the\nbasics of utilizing connections, cursors, and the methods to close them\ntranscend libraries. If you know the basics of one, you know them all.\n\nIf you'd like to keep your connection logic separate (as I do), we can cleanly\nbreak the logic of handling connections out to a separate function. This time,\nwe'll replace SomeDatabaseLibrary  with Psycopg2  to produce some working code:\n\nimport psycopg2\n\nclass Database:\n    \"\"\"A Generic Database class.\"\"\"\n\n    def __init__(self, config):\n        self.username = config.database('USERNAME')\n        self.password = config.database('PASSWORD')\n        self.host = config.database('HOST')\n        self.port = config.database('PORT')\n        self.db = config.database('DB')\n        self.conn = None\n        \n    def open_connection():\n        \"\"\"Encapsulated connection management logic.\"\"\"\n        try:\n            if(self.conn is None):\n                self.conn = psycopg2.connect(host=self.host, \n                                       user=self.username, \n                                       password=self.password,\n                                       port=self.port, \n                                       dbname=self.db)\n            elif (not conn.open):\n                self.conn = psycopg2.connect(host=self.host, \n                                       user=self.username, \n                                       password=self.password,\n                                       port=self.port, \n                                       dbname=self.db)  \n        except:\n            logger.error(\"ERROR: Could not connect to Postgres.\")\n            sys.exit()\n\n    def run_query(self, query):\n            records = []\n            try:\n                open_connection()\n                with self.conn.cursor() as cur:\n                    cur.execute(query)\n                    result = cur.fetchall()\n                    for row in result:\n                        records.append(row)\n                    cur.close()\n                    return records\n            except (Exception, psycopg2.DatabaseError) as error:\n                print(error)\n            finally:\n                if conn is not None:\n                    conn.close()\n                    print('Database connection closed.')\n\n\nPsycopg2 Extras\nPsycopg2 has many useful features via a library called psycopg2.extras\n[http://initd.org/psycopg/docs/extras.html]. My personal favorite of these\nextras is the DictCursor, which renders the rows being returned by our query as\nPython dictionaries  as opposed to lists. \n\nUsing DictCursor to Return More Useful Results\nWhen using a DictCursor, the key  is always the column name, and the value is\nthe value of that column in that particular row.\n\nTo use extras, we import psycopg2.extras.\n\nThen, we turn our attention to the following line:\n\nself.conn.cursor() as cur:\n\n\nWithin cursor, we can pass an attribute named cursor_factory   and set it as\nsuch:\n\nconn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:\n\n\nWhile our cursor is open, all rows returned by the query will be returned as\ndictionaries. For example, the row  in the above example will be returned as a\ndict. To demonstrate, here's what a query on this exact post  you're reading now\nlooks like when returned as a Dict:\n\n{\n    title: \"Psycopg2: Postgres & Python the Old Fashioned Way\",\n    slug: \"psycopg2-postgres-python-the-old-fashioned-way\",\n    feature_image: \"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/psycopg2.jpg\",\n    status: \"draft\",\n    created_at: \"2019-01-14 22:20:52\",\n    custom_excerpt: \"Managing Postgres Database connections with Psycopg2\"\n}\n\n\nCompare this to what we would've seen had we not used DictCursor:\n\n[\"Psycopg2: Postgres & Python the Old Fashioned Way\",\n\"psycopg2-postgres-python-the-old-fashioned-way\",\n\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/psycopg2.jpg\",\n\"draft\",\n\"2019-01-14 22:20:52\",\n\"Managing Postgres Database connections with Psycopg2\"]\n\n\nYes, it's a list, and thereby much less useful. Even from a readability\nstandpoint, I (the human user) have no idea what these values represent unless\ncomparing them to the table schema. Even worse would be compiling CSVs or even\nPandas Dataframes this way. When building a table made of lists, you set your\nheaders and hope that every row to come matches the number of header columns\none-to-one. Otherwise, it's entirely unclear as to which value belongs to which\ncolumn.\n\nOther Psycopg2 Extras\nThere are plenty more Psycopg2 extras where that came from; it's mostly up to\nyou to decide which are worth your while.\n\nFor example, another extra which might be of interest could be \npsycopg2.extras.LoggingConnection, useful for debugging connection statuses and\nerrors as you work through your program.\n\nThere's even a JSON Adaptation  extra, which provides support for leveraging\nJSON data in building queries:\n\ncur.execute(\"insert into mytable (jsondata) values (%s)\",\n    [Json({'a': 100})])\n\n\nI don't dwell too deep in Psycopg2 extras myself, but if you see any Godlike\nextras I'm missing, feel free to call them out in the COMMENTS BELOW!  (Hah!\nI've always wanted to say that).\n\nA Few More Fundamental Useful Things\nSomething worth visiting is the ability to upload CSVs into Postgres to create\ntables. We can accomplish this via the built-in method copy_expert.\n\nFrom CSV to Postgres Table\nTo save a CSV to Postgres table, we need to begin with a basic SQL query saved\nin our project as a variable:\n\nCOPY %s FROM STDIN WITH\n                    CSV\n                    HEADER\n                    DELIMITER AS ','\n\n\nAs should be familiar, %s  represents a value we can pass in later. With this\nraw query, we're only missing two more values:\n\n * The path of our CSV file to be uploaded\n * The name of the table we'd like to upload to in Postgres\n\nCheck out how we use copy_expert  here to put it all together:\n\nsql = \"COPY %s FROM STDIN WITH CSVHEADER DELIMITER AS ','\"\nfile = open('files/myfile.csv', \"r\")\ntable = 'my_postgres_table'\nwith conn.cursor() as cur:\n    cur.execute(\"truncate \" + table + \";\")\n    cur.copy_expert(sql=sql % table, file=file)\n    conn.commit()\n    cur.close()\n    conn.close()\n\n\nNotice that I opt to truncate the existing table before uploading the new data,\nas seen by cur.execute(\"truncate \" + table + \";\"). Without doing this, we would\nbe uploading the same CSV to the same table forever, creating duplicate rows\nover and over.\n\nWhat if The Table Doesn't Exist?\nUgh, of course  this would come up. The truth is (to the best of my knowledge),\nthere aren't many native things Psycopg2 has to offer to make this process easy.\n \n\nRecall that creating a table has a syntax similar to this:\n\nCREATE TABLE `recommended_reads` (\n  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,\n  `title` varchar(150) NOT NULL,\n  `content` text,\n  `url` varchar(150) NOT NULL,\n  `created` int(11) NOT NULL,\n  `unique_ID` int(11) NOT NULL,\n  `image` varchar(150) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `id` (`id`),\n  UNIQUE KEY `uniqueid` (`unique_ID`) USING BTREE\n)\n\n\nIt's not impossible to build this string yourself in Python. It just entails a\nlot of iterating over whichever dynamic data structure you have coming through,\ndetermining the correct data type per column, and then the unavoidable task of\nsetting your Primary  and Unique  keys if applicable. This is where my patience\nends and knee-jerk reaction of \"would be easier in SQLAlchemy\" kicks in. Hey,\nit's possible! I just don't feel like writing about it. :).\n\nGodspeed to You, Brave Warrior\nFor those about to Psycopg2, we salute you. That is unless the choice is\nself-inflicted. In that case, perhaps it's best we don't work together any time\nsoon.","html":"<p>Last time we met, we joyfully <a href=\"https://hackersandslackers.com/pythonic-database-management-with-sqlalchemy/\">shared a little tirade</a> about missing out on functionality provided to us by libraries such as <strong>SQLAlchemy</strong>, and the advantages of interacting with databases where ORMs are involved. I stand by that sentiment, but I’ll now directly contradict myself by sharing some tips on using vanilla <strong>Psycopg2</strong> to interact with databases. </p><p>We never know when we’ll be stranded on a desert island without access to SQLAlchemy, but a lonesome Psycopg2 washes up on shore. Either that or perhaps you’re part of a development team stuck in a certain way of doing things which doesn't include utilize SQLAlchemy. Whatever the situation may be, we’re here for you. </p><h2 id=\"the-quintessential-boilerplate\">The Quintessential Boilerplate</h2><p>No matter the type of database or the library, the boilerplate code for connecting to databases remains mostly the same. To some extent, this even holds true across programming languages. Let's look at a barebones example while ignoring the library at hand:</p><pre><code class=\"language-python\">import SomeDatabaseLibrary\n\nclass Database:\n    &quot;&quot;&quot;A Generic Database class.&quot;&quot;&quot;\n\n    def __init__(self, config):\n        self.username = config.database('USERNAME')\n        self.password = config.database('PASSWORD')\n        self.host = config.database('HOST')\n        self.port = config.database('PORT')\n        self.db = config.database('DB')\n\n    def run_query(self, query):\n            conn = None\n            records = []\n            try:\n                conn = SomeDatabaseLibrary.connect(host=self.host, \n                                                user=self.username, \n                                                password=self.password,\n                                                port=self.port, \n                                                dbname=self.db)\n                with conn.cursor() as cur:\n                    cur.execute(query)\n                    result = cur.fetchall()\n                    for row in result:\n                        records.append(row)\n                    cur.close()\n                    return records\n            except (Exception, SomeDatabaseLibrary.DatabaseError) as error:\n                print(error)\n            finally:\n                if conn is not None:\n                    conn.close()\n                    print('Database connection closed.')\n</code></pre>\n<p>In the above example, we could swap <code>SomeDatabaseLibrary</code> with either <code>Psycopg2</code> or <code>PyMySQL</code> just the same. If we compare this to <a href=\"https://hackersandslackers.com/using-pymysql/\">our example with PyMySQL</a>, it's easy to see that the basics of utilizing <strong>connections</strong>, <strong>cursors</strong>, and the methods to close them transcend libraries. If you know the basics of one, you know them all.</p><p>If you'd like to keep your connection logic separate (as I do), we can cleanly break the logic of handling connections out to a separate function. This time, we'll replace <code>SomeDatabaseLibrary</code> with <code>Psycopg2</code> to produce some working code:</p><pre><code class=\"language-python\">import psycopg2\n\nclass Database:\n    &quot;&quot;&quot;A Generic Database class.&quot;&quot;&quot;\n\n    def __init__(self, config):\n        self.username = config.database('USERNAME')\n        self.password = config.database('PASSWORD')\n        self.host = config.database('HOST')\n        self.port = config.database('PORT')\n        self.db = config.database('DB')\n        self.conn = None\n        \n    def open_connection():\n        &quot;&quot;&quot;Encapsulated connection management logic.&quot;&quot;&quot;\n        try:\n            if(self.conn is None):\n                self.conn = psycopg2.connect(host=self.host, \n                                       user=self.username, \n                                       password=self.password,\n                                       port=self.port, \n                                       dbname=self.db)\n            elif (not conn.open):\n                self.conn = psycopg2.connect(host=self.host, \n                                       user=self.username, \n                                       password=self.password,\n                                       port=self.port, \n                                       dbname=self.db)  \n        except:\n            logger.error(&quot;ERROR: Could not connect to Postgres.&quot;)\n            sys.exit()\n\n    def run_query(self, query):\n            records = []\n            try:\n                open_connection()\n                with self.conn.cursor() as cur:\n                    cur.execute(query)\n                    result = cur.fetchall()\n                    for row in result:\n                        records.append(row)\n                    cur.close()\n                    return records\n            except (Exception, psycopg2.DatabaseError) as error:\n                print(error)\n            finally:\n                if conn is not None:\n                    conn.close()\n                    print('Database connection closed.')\n</code></pre>\n<h2 id=\"psycopg2-extras\">Psycopg2 Extras</h2><p>Psycopg2 has many useful features via a library called <a href=\"http://initd.org/psycopg/docs/extras.html\">psycopg2.extras</a>. My personal favorite of these extras is the <code>DictCursor</code>, which renders the rows being returned by our query as Python <em>dictionaries</em> as opposed to <em>lists. </em></p><h3 id=\"using-dictcursor-to-return-more-useful-results\">Using DictCursor to Return More Useful Results</h3><p>When using a DictCursor, the <em>key</em> is always the column name, and the <em>value </em>is the value of that column in that particular row.</p><p>To use extras, we <code>import psycopg2.extras</code>.</p><p>Then, we turn our attention to the following line:</p><pre><code class=\"language-python\">self.conn.cursor() as cur:\n</code></pre>\n<p>Within <code>cursor</code>, we can pass an attribute named <code>cursor_factory</code>  and set it as such:</p><pre><code class=\"language-python\">conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:\n</code></pre>\n<p>While our cursor is open, all rows returned by the query will be returned as dictionaries. For example, the <strong>row</strong> in the above example will be returned as a dict. To demonstrate, here's what a query on this <em>exact post</em> you're reading now looks like when returned as a Dict:</p><pre><code class=\"language-python\">{\n    title: &quot;Psycopg2: Postgres &amp; Python the Old Fashioned Way&quot;,\n    slug: &quot;psycopg2-postgres-python-the-old-fashioned-way&quot;,\n    feature_image: &quot;https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/psycopg2.jpg&quot;,\n    status: &quot;draft&quot;,\n    created_at: &quot;2019-01-14 22:20:52&quot;,\n    custom_excerpt: &quot;Managing Postgres Database connections with Psycopg2&quot;\n}\n</code></pre>\n<p>Compare this to what we would've seen had we not used <code>DictCursor</code>:</p><pre><code class=\"language-python\">[&quot;Psycopg2: Postgres &amp; Python the Old Fashioned Way&quot;,\n&quot;psycopg2-postgres-python-the-old-fashioned-way&quot;,\n&quot;https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/psycopg2.jpg&quot;,\n&quot;draft&quot;,\n&quot;2019-01-14 22:20:52&quot;,\n&quot;Managing Postgres Database connections with Psycopg2&quot;]\n</code></pre>\n<p>Yes, it's a list, and thereby much less useful. Even from a readability standpoint, I (the human user) have no idea what these values represent unless comparing them to the table schema. Even worse would be compiling CSVs or even Pandas Dataframes this way. When building a table made of lists, you set your headers and hope that every row to come matches the number of header columns one-to-one. Otherwise, it's entirely unclear as to which value belongs to which column.</p><h3 id=\"other-psycopg2-extras\">Other Psycopg2 Extras</h3><p>There are plenty more Psycopg2 extras where that came from; it's mostly up to you to decide which are worth your while.</p><p>For example, another extra which might be of interest could be <code>psycopg2.extras.LoggingConnection</code>, useful for debugging connection statuses and errors as you work through your program.</p><p>There's even a <strong>JSON Adaptation</strong> extra, which provides support for leveraging JSON data in building queries:</p><pre><code class=\"language-python\">cur.execute(&quot;insert into mytable (jsondata) values (%s)&quot;,\n    [Json({'a': 100})])\n</code></pre>\n<p>I don't dwell too deep in Psycopg2 extras myself, but if you see any Godlike extras I'm missing, feel free to call them out in the <strong><em>COMMENTS BELOW!</em></strong> (Hah! I've always wanted to say that).</p><h2 id=\"a-few-more-fundamental-useful-things\">A Few More Fundamental Useful Things</h2><p>Something worth visiting is the ability to upload CSVs into Postgres to create tables. We can accomplish this via the built-in method <code>copy_expert</code>.</p><h3 id=\"from-csv-to-postgres-table\">From CSV to Postgres Table</h3><p>To save a CSV to Postgres table, we need to begin with a basic SQL query saved in our project as a variable:</p><pre><code class=\"language-sql\">COPY %s FROM STDIN WITH\n                    CSV\n                    HEADER\n                    DELIMITER AS ','\n</code></pre>\n<p>As should be familiar, <code>%s</code> represents a value we can pass in later. With this raw query, we're only missing two more values:</p><ul><li>The path of our CSV file to be uploaded</li><li>The name of the table we'd like to upload to in Postgres</li></ul><p>Check out how we use <code>copy_expert</code> here to put it all together:</p><pre><code class=\"language-python\">sql = &quot;COPY %s FROM STDIN WITH CSVHEADER DELIMITER AS ','&quot;\nfile = open('files/myfile.csv', &quot;r&quot;)\ntable = 'my_postgres_table'\nwith conn.cursor() as cur:\n    cur.execute(&quot;truncate &quot; + table + &quot;;&quot;)\n    cur.copy_expert(sql=sql % table, file=file)\n    conn.commit()\n    cur.close()\n    conn.close()\n</code></pre>\n<p>Notice that I opt to truncate the existing table before uploading the new data, as seen by <code>cur.execute(\"truncate \" + table + \";\")</code>. Without doing this, we would be uploading the same CSV to the same table forever, creating duplicate rows over and over.</p><h3 id=\"what-if-the-table-doesn-t-exist\">What if The Table Doesn't Exist?</h3><p>Ugh, of <em>course</em> this would come up. The truth is (to the best of my knowledge), there aren't many native things Psycopg2 has to offer to make this process easy. </p><p>Recall that creating a table has a syntax similar to this:</p><pre><code class=\"language-sql\">CREATE TABLE `recommended_reads` (\n  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,\n  `title` varchar(150) NOT NULL,\n  `content` text,\n  `url` varchar(150) NOT NULL,\n  `created` int(11) NOT NULL,\n  `unique_ID` int(11) NOT NULL,\n  `image` varchar(150) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `id` (`id`),\n  UNIQUE KEY `uniqueid` (`unique_ID`) USING BTREE\n)\n</code></pre>\n<p>It's not impossible to build this string yourself in Python. It just entails a lot of iterating over whichever dynamic data structure you have coming through, determining the correct data type per column, and then the unavoidable task of setting your <strong>Primary</strong> and <strong>Unique</strong> keys if applicable. This is where my patience ends and knee-jerk reaction of \"would be easier in SQLAlchemy\" kicks in. Hey, it's possible! I just don't feel like writing about it. :).</p><h2 id=\"godspeed-to-you-brave-warrior\">Godspeed to You, Brave Warrior</h2><p>For those about to Psycopg2, we salute you. That is unless the choice is self-inflicted. In that case, perhaps it's best we don't work together any time soon.</p>","url":"https://hackersandslackers.com/psycopg2-postgres-python-the-old-fashioned-way/","uuid":"f07736c5-c167-4fe9-b932-1b6b4d95e3ff","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c3d0b441719dc6b38ee53b6"}},"pageContext":{"slug":"psycopg2-postgres-python-the-old-fashioned-way"}}