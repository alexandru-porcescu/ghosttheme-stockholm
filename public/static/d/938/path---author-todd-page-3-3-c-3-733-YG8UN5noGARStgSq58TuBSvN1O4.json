{"data":{"ghostAuthor":{"slug":"todd","name":"Todd Birchard","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","cover_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/fox_o_o.jpg","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","location":"New York City","website":"https://toddbirchard.com","twitter":"@ToddRBirchard","facebook":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c27630bda392c696eab97de","title":"Tableau's REST API: Turning Tableau into an ETL Pipeline GUI","slug":"tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/hacktaleau-4@2x.jpg","excerpt":"Organizing a heist on Tableau Server to reclaim workbook data.","custom_excerpt":"Organizing a heist on Tableau Server to reclaim workbook data.","created_at_pretty":"29 December, 2018","published_at_pretty":"29 December, 2018","updated_at_pretty":"13 March, 2019","created_at":"2018-12-29T07:05:31.000-05:00","published_at":"2018-12-29T07:18:53.000-05:00","updated_at":"2019-03-13T05:53:25.000-04:00","meta_title":"Tableau's View Extraction REST API | Hackers and Slackers","meta_description":"Our siege on Tableau Server continues as we organize a heist to reclaim our workbook data","og_description":"Our siege on Tableau Server continues as we organize a heist to reclaim our workbook data","og_image":"https://hackersandslackers.com/content/images/2018/12/hacktaleau-4@2x.jpg","og_title":"Tableau's REST API: Turning Tableau into an ETL Pipeline GUI","twitter_description":"Our siege on Tableau Server continues as we organize a heist to reclaim our workbook data","twitter_image":"https://hackersandslackers.com/content/images/2018/12/hacktaleau-4@2x.jpg","twitter_title":"Tableau's REST API: Turning Tableau into an ETL Pipeline GUI","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Hacking Tableau Server","slug":"hacking-tableau-server","description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauseries-2.jpg","meta_description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","meta_title":"Hacking Tableau Server","visibility":"internal"}],"plaintext":"There's nothing I love more than exposing expensive enterprise software. \n\nIt may not seem obvious, but most SaaS products have an underlying core goal:\nshackle businesses to depend on proprietary, closed-source, costly software.\nWhen you pair a surplus of money with a reluctance to work, you've arrived at\nCorporate America: a prime victim yearning to marry itself to any vendor with a\nnice pitch deck and a vague promise.\n\nIn the case of Tableau, this becomes obvious when you attempt to do anything\nbesides create visuals. I don't like spending hours of my time cleaning data to\nbe rewarded with a shitty iframe embed: I want my data. As we've already seen by\nexposing Tableau's hidden Superadmin access\n[\thttps://hackersandslackers.com/hacking-linux-tableu-server/], it's pretty\nclear Tableau doesn't want you to do this. \n\nI realize Tableau is a BI tool, and some might argue we're barking up the wrong\ntree, and all data should be clean before reaching Tableau. My sentiment is\nthis: fuck that. If a single license costs one thousand dollars, and we have the\npower to manipulate data faster  as we visualize it, we should at least be able\nto own  that data: and by \"own,\" I don't mean a CSV export. I want it in my own \ndatabase of choice, not a locked down and hidden Postgres database living on a\nVPS filled with Tableau stuff.\n\nHere's how we'd do that.\n\n\"You Expect us to Just Walk out the Casino with Millions of Dollars on us?\"\nYou're looking at a Boeski, a Jim Brown, a Miss Daisy, two Jethros and a Leon\nSpinks, not to mention the biggest Ella Fitzgerald ever.You're here because\nyou're the best of the best. If you're feeling scared, feel free to back out\nnow.\n\nThis tutorial assumes you have a Tableau Server instance, with a workbook\npublished to a site within said instance. We're going to take a page out of that\nworkbook and turn the raw data into a database table. FAIR  WARNING: We're about\nto dive deep into the obscure world of the Tableau Server REST API\n[https://onlinehelp.tableau.com/current/api/rest_api/en-us/REST/rest_api_ref.htm]\n. It's clunky, it's ugly, and it returns XML. Strap yourself in. \n\nWe're going to be working with 3 core endpoints. Let's walk through them, and\nI'll show you how to exploit said endpoints to create a ruthless data mining\nmachine in Python.\n\n'Tableau Authorization' Endpoint\nLike all obnoxious (aka useful) APIs, we need to authorize each API call with a\ntemporary token. Of course, we'll just have Python generate said token for every\ncall we make.\n\nPOST: http://[MyTaleauServerURL]/api/3.0/auth/signin\n\nHitting this endpoint successfully will result in an XML response (ugh). The\nresponse should look something like this:\n\n<?xml version='1.0' encoding='UTF-8'?>\n<tsResponse xmlns=\"http://tableau.com/api\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd\">\n    <credentials token=\"KBIuvu6FTViuyivuTUR^yfvgTUycvjGubgc\">\n        <site id=\"09Hiugv-345-45d0-b48b-34543giuyvg\" contentUrl=\"hackers\"/>\n        <user id=\"Uohiiyu-3455-8675-9b42-bugvdr876gv\"/>\n    </credentials>\n</tsResponse>\n\n\nThere are a number of things going on here that we should take note of. The\nfirst being a marvel of modern technology: this is perhaps the shittiest\nresponse to a token API call in modern history. Other than that, we need two\nthings from this response:\n\n * The token  is required for every API call from here on out. It is intended to\n   be passed as a header value with the key X-Tableau-Auth.\n * The site ID  is what we'll be using to look up the location of our workbooks\n   in our server instance. This is added to the URL of future API calls (again,\n   impressively shitty design here).\n\n'List All Views by Site' Endpoint\nThere are actually a number of methods we could use to retrieve views, but we're\nspecifically settling on listing our views by 'site,' in the Tableau sense of\nthe word. If you're unfamiliar, a Tableau site  is not a site at all: it's more\nof project within a greater Tableau instance. They probably should've named them\nthat.\n\nGET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views\n\nAs mentioned, we use the site ID  from step 1 to construct this endpoint. In my\nparticular instance, I've only saved a single workbook for simplicity's sake.\nThe response for such a case is as follows:\n\n<?xml version='1.0' encoding='UTF-8'?>\n<tsResponse xmlns=\"http://tableau.com/api\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd\">\n    <pagination pageNumber=\"1\" pageSize=\"100\" totalAvailable=\"1\"/>\n    <views>\n        <view id=\"9a4a1de9-b7af-4a4a-8556-fd5ac82f92bd\" name=\"Jira\" contentUrl=\"JiraIssues/sheets/Jira\" createdAt=\"2018-12-21T09:11:39Z\" updatedAt=\"2018-12-21T09:11:39Z\">\n            <workbook id=\"208a0c4e-e1d9-4852-9d19-7a2fe2717191\"/>\n            <owner id=\"Uohiiyu-3455-8675-9b42-bugvdr876gv\"/>\n            <project id=\"4d1ca337-20b4-442c-aa7b-1dfd470b68bd\"/>\n            <tags/>\n        </view>\n    </views>\n</tsResponse>\n\n\nCheck out the views  node: when we make this API call, <views>  will contain a\nlist of every view saved to the specified site. Keep in mind that a view is\nequivalent to a \"sheet\" of a workbook: in almost any case, you will have many\nviews listed here. \n\nMy sheet happens to be called \"Jira,\" as stated by name=\"Jira\". The thing we\nreally need however is the view id attribute: this will be used in our third and\nfinal API call.\n\n'Get View Data' Endpoint\nNow let's get the raw data from a view of our choice.\n\nGET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views/[MyViewID]/data\n\n\nHere's where we hit pay dirt. This request will result in an output of\ncomma-separated values; I don't need to tell you what we can do with\ncomma-separated values. Here's what my response looks like after formatting it\nas a table:\n\nCurrent AssigneeCurrent StatusDay of Updatedepic_colorepic_nameIssue Type\nissuetype_colorissuetype_urlkeyPriorityprojectsummaryTodd BirchardDoneJune 7,\n2018#42526EWidgetsBug#db5d5dhttps://hackers.nyc3.digitaloceanspaces.com/bug.png\nHACK-96LowestHackers and Slackers\"Recent Posts\" widget does not have link\nrolloverTodd BirchardBacklogJune 15, 2018#57D9A3Page TemplatesTask#73B0E1\nhttps://hackers.nyc3.digitaloceanspaces.com/task.pngHACK-32LowestHackers and\nSlackers“Join” pageTodd BirchardDoneNovember 13, 2018#42526EWidgetsTask#73B0E1\nhttps://hackers.nyc3.digitaloceanspaces.com/task.pngHACK-543MediumHackers and\nSlackersAdd “pro tip” boxTodd BirchardTo DoDecember 14, 2018#679EEFSEOMajor\nFunctionality#93d171https://hackers.nyc3.digitaloceanspaces.com/story.png\nHACK-656LowHackers and SlackersAdd alt attributes to images vis clarifai Todd\nBirchardBacklogOctober 16, 2018#FDDA3EAccountsMajor Functionality#93d171\nhttps://hackers.nyc3.digitaloceanspaces.com/story.pngHACK-473MediumHackers and\nSlackersAdd avatar selection to signupTodd BirchardDoneNovember 13, 2018#57D9A3\nPage TemplatesSub-task#92BFE5\nhttps://hackers.nyc3.digitaloceanspaces.com/subtask.pngHACK-231MediumHackers and\nSlackersAdd blurb to each post page explaining what these areTodd BirchardDone\nDecember 10, 2018#291BA9Code snippetsTask#73B0E1\nhttps://hackers.nyc3.digitaloceanspaces.com/task.pngHACK-452MediumHackers and\nSlackersAdd color styles for json snippetsThat's right, a table.  Databases are comprised of tables. Perhaps you see where\nI'm going with this.\n\n\"There's a Ninety-five Pound Chinese Man with a Hundred Sixty Million Dollars\nBehind this Door.\"\nLet's get him out.We've got the goods, but calling all these individual\nendpoints manually does nothing for us. We don't want to steal a single view, we\nwant to systematically rob Tableau of it's views on a scheduler and Shanghai\nthem off to a database of our choosing.\n\nIt would be a crime not to automate this, so I've created a class containing all\nthe relevant methods we'd want when it comes to interacting with Tableau's REST\nAPI:\n\nimport requests\nimport xml.etree.ElementTree as ET\nfrom . import r\nimport pandas as pd\nimport io\n\n\nclass ExtractTableauView:\n    \"\"\"Class for with the Tableau server API.\"\"\"\n\n    __baseurl = r.get('baseurl')\n    __username = r.get('username')\n    __password = r.get('password')\n    __database = r.get('uri')\n    __contenturl = r.get('contenturl')\n\n    @classmethod\n    def get_view(cls, site, xml, view, token):\n        \"\"\"Extract contents of a single view.\"\"\"\n        headers = {'X-Tableau-Auth': token,\n                   'Content-Type': 'text/csv'\n                   }\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + str(site) +'/views/' + str(view) + '/data', headers=headers, stream=True)\n        csv_text = req.text\n        view_df = pd.read_csv(io.StringIO(csv_text), header=0)\n        return view_df\n\n    @classmethod\n    def list_views(cls, site, xml, token):\n        \"\"\"List all views belonging to a Tableau Site.\"\"\"\n        headers = {'X-Tableau-Auth': token}\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + site + '/views', auth=(cls.__username, cls.__password), headers=headers)\n        root = ET.fromstring(req.content)\n        views_arr = []\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}views':\n                for view in child:\n                    view_dict = {\n                        'name': view.attrib.get('name'),\n                        'id': view.attrib.get('id'),\n                        'url': cls.__baseurl + '/' + view.attrib.get('contentUrl'),\n                        'created': view.attrib.get('createdAt'),\n                        'updated': view.attrib.get('updatedAt')\n                    }\n                    views_arr.append(view_dict)\n        return views_arr\n\n    @classmethod\n    def get_token(cls, xml):\n        \"\"\"Receive Auth token to perform API requests.\"\"\"\n        for child in xml.iter('*'):\n            if child.tag == '{http://tableau.com/api}credentials':\n                token = child.attrib.get('token')\n                return token\n\n    @classmethod\n    def get_site(cls, xml):\n        \"\"\"Retrieve ID of Tableau 'site' instance.\"\"\"\n        root = xml\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}site':\n                site = child.attrib.get('id')\n                return site\n\n    @classmethod\n    def initialize_tableau_request(cls):\n        \"\"\"Retrieve core XML for interacting with Tableau.\"\"\"\n        headers = {'Content-Type': 'application/xml'}\n        body = '<tsRequest><credentials name=\"' + cls.__username + '\" password=\"' + cls.__password + '\" ><site contentUrl=\"' + cls.__contenturl + '\" /></credentials></tsRequest>'\n        req = requests.post(cls.__baseurl + '/api/3.2/auth/signin', auth=(cls.__username, cls.__password), headers=headers, data=body)\n        root = ET.fromstring(req.content)\n        return root\n\n\nThe above snippet is a Python class utilizing all the API endpoints we explored\nin a mostly effortless manner. Instantiating the class immediately covers the\ngrunt work of:\n\n *   Generating a token\n * Getting your (unfriendly) site ID\n * Listing all views belonging to the provided site\n * Retrieving data from a worksheet of choice\n\nGet a list of views in your Tableau site by using the list_views()  method. When\nyou see the view you want, pass the view ID  to the .get_view()  method. This\nwill result in response of all raw data in the view in the form of a CSV. \n\nHow to Pull a Heist (Final Chapter): Storing in Offshore Accounts\nTo earn your title as a true con artist, I'm leaving the final step up to you.\nYou've escaped with the loot, but you'll need to put all that data somewhere.\nThis should be a trivial matter of automating a simple database query, but the\nspecifics are up to you.\n\nIf you're ready to liberate your data, feel free to grab the source off of\nGithub [https://gist.github.com/toddbirchard/ad1386b4334e7b22b2f7b38edca3bd5c] \nand go nuts.","html":"<p>There's nothing I love more than exposing expensive enterprise software. </p><p>It may not seem obvious, but most SaaS products have an underlying core goal: shackle businesses to depend on proprietary, closed-source, costly software. When you pair a surplus of money with a reluctance to work, you've arrived at Corporate America: a prime victim yearning to marry itself to any vendor with a nice pitch deck and a vague promise.</p><p>In the case of Tableau, this becomes obvious when you attempt to do anything besides create visuals. I don't like spending hours of my time cleaning data to be rewarded with a shitty iframe embed: I want my <em>data</em>. As we've already seen by exposing Tableau's hidden <a href=\"\thttps://hackersandslackers.com/hacking-linux-tableu-server/\">Superadmin access</a>, it's pretty clear Tableau doesn't want you to do this. </p><p>I realize Tableau is a BI tool, and some might argue we're barking up the wrong tree, and all data should be clean before reaching Tableau. My sentiment is this: <em>fuck that</em>. If a single license costs <em><strong>one thousand dollars</strong></em>, and we have the power to manipulate data <em>faster</em> as we visualize it, we should at least be able to <em>own</em> that data: and by \"own,\" I don't mean a CSV export. I want it in my <em>own</em> database of choice, not a locked down and hidden Postgres database living on a VPS filled with Tableau stuff.</p><p>Here's how we'd do that.</p><h2 id=\"you-expect-us-to-just-walk-out-the-casino-with-millions-of-dollars-on-us\">\"You Expect us to Just Walk out the Casino with Millions of Dollars on us?\"</h2><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/oceans.gif\" class=\"kg-image\"><figcaption>You're looking at a Boeski, a Jim Brown, a Miss Daisy, two Jethros and a Leon Spinks, not to mention the biggest Ella Fitzgerald ever.</figcaption></figure><!--kg-card-end: image--><p>You're here because you're the best of the best. If you're feeling scared, feel free to back out now.</p><p>This tutorial assumes you have a Tableau Server instance, with a workbook published to a site within said instance. We're going to take a page out of that workbook and turn the raw data into a database table. <strong>FAIR</strong> <strong>WARNING</strong>: We're about to dive deep into the obscure world of the <a href=\"https://onlinehelp.tableau.com/current/api/rest_api/en-us/REST/rest_api_ref.htm\">Tableau Server REST API</a>. It's clunky, it's ugly, and it returns XML. Strap yourself in. </p><p>We're going to be working with 3 core endpoints. Let's walk through them, and I'll show you how to exploit said endpoints to create a ruthless data mining machine in Python.</p><h3 id=\"-tableau-authorization-endpoint\">'Tableau Authorization' Endpoint</h3><p>Like all obnoxious (aka useful) APIs, we need to authorize each API call with a temporary token. Of course, we'll just have Python generate said token for every call we make.</p><!--kg-card-begin: code--><pre><code>POST: http://[MyTaleauServerURL]/api/3.0/auth/signin</code></pre><!--kg-card-end: code--><p>Hitting this endpoint successfully will result in an XML response (ugh). The response should look something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-xml\">&lt;?xml version='1.0' encoding='UTF-8'?&gt;\n&lt;tsResponse xmlns=&quot;http://tableau.com/api&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd&quot;&gt;\n    &lt;credentials token=&quot;KBIuvu6FTViuyivuTUR^yfvgTUycvjGubgc&quot;&gt;\n        &lt;site id=&quot;09Hiugv-345-45d0-b48b-34543giuyvg&quot; contentUrl=&quot;hackers&quot;/&gt;\n        &lt;user id=&quot;Uohiiyu-3455-8675-9b42-bugvdr876gv&quot;/&gt;\n    &lt;/credentials&gt;\n&lt;/tsResponse&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>There are a number of things going on here that we should take note of. The first being a marvel of modern technology: this is perhaps the shittiest response to a token API call in modern history. Other than that, we need two things from this response:</p><ul><li>The <strong>token</strong> is required for every API call from here on out. It is intended to be passed as a header value with the key <code>X-Tableau-Auth</code>.</li><li>The <strong>site ID</strong> is what we'll be using to look up the location of our workbooks in our server instance. This is added to the URL of future API calls (again, impressively shitty design here).</li></ul><h3 id=\"-list-all-views-by-site-endpoint\">'List All Views by Site' Endpoint</h3><p>There are actually a number of methods we could use to retrieve views, but we're specifically settling on listing our views by '<em>site,' </em>in the Tableau sense of the word<em>. </em>If you're unfamiliar, a Tableau <em>site</em> is not a site at all: it's more of project within a greater Tableau instance. They probably should've named them that.</p><!--kg-card-begin: code--><pre><code>GET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views</code></pre><!--kg-card-end: code--><p>As mentioned, we use the <strong>site ID</strong> from step 1 to construct this endpoint. In my particular instance, I've only saved a single workbook for simplicity's sake. The response for such a case is as follows:</p><!--kg-card-begin: markdown--><pre><code class=\"language-xml\">&lt;?xml version='1.0' encoding='UTF-8'?&gt;\n&lt;tsResponse xmlns=&quot;http://tableau.com/api&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd&quot;&gt;\n    &lt;pagination pageNumber=&quot;1&quot; pageSize=&quot;100&quot; totalAvailable=&quot;1&quot;/&gt;\n    &lt;views&gt;\n        &lt;view id=&quot;9a4a1de9-b7af-4a4a-8556-fd5ac82f92bd&quot; name=&quot;Jira&quot; contentUrl=&quot;JiraIssues/sheets/Jira&quot; createdAt=&quot;2018-12-21T09:11:39Z&quot; updatedAt=&quot;2018-12-21T09:11:39Z&quot;&gt;\n            &lt;workbook id=&quot;208a0c4e-e1d9-4852-9d19-7a2fe2717191&quot;/&gt;\n            &lt;owner id=&quot;Uohiiyu-3455-8675-9b42-bugvdr876gv&quot;/&gt;\n            &lt;project id=&quot;4d1ca337-20b4-442c-aa7b-1dfd470b68bd&quot;/&gt;\n            &lt;tags/&gt;\n        &lt;/view&gt;\n    &lt;/views&gt;\n&lt;/tsResponse&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>Check out the <strong>views</strong> node: when we make this API call, <code>&lt;views&gt;</code> will contain a list of every view saved to the specified site. Keep in mind that a view is equivalent to a \"sheet\" of a workbook: in almost any case, you will have many views listed here. </p><p>My sheet happens to be called \"Jira,\" as stated by <code>name=\"Jira\"</code>. The thing we really need however is the <strong>view id </strong>attribute: this will be used in our third and final API call.</p><h3 id=\"-get-view-data-endpoint\">'Get View Data' Endpoint</h3><p>Now let's get the raw data from a view of our choice.</p><!--kg-card-begin: code--><pre><code>GET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views/[MyViewID]/data\n</code></pre><!--kg-card-end: code--><p>Here's where we hit pay dirt. This request will result in an output of comma-separated values; I don't need to tell you what we can do with comma-separated values. Here's what my response looks like after formatting it as a table:</p><!--kg-card-begin: html--><div class=\"tableContainer\">\n<table class=\"table table-bordered table-hover table-condensed\">\n<thead><tr><th title=\"Field #1\">Current Assignee</th>\n<th title=\"Field #2\">Current Status</th>\n<th title=\"Field #3\">Day of Updated</th>\n<th title=\"Field #4\">epic_color</th>\n<th title=\"Field #5\">epic_name</th>\n<th title=\"Field #6\">Issue Type</th>\n<th title=\"Field #7\">issuetype_color</th>\n<th title=\"Field #8\">issuetype_url</th>\n<th title=\"Field #9\">key</th>\n<th title=\"Field #10\">Priority</th>\n<th title=\"Field #11\">project</th>\n<th title=\"Field #12\">summary</th>\n</tr></thead>\n<tbody><tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>June 7, 2018</td>\n<td>#42526E</td>\n<td>Widgets</td>\n<td>Bug</td>\n<td>#db5d5d</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/bug.png</td>\n<td>HACK-96</td>\n<td>Lowest</td>\n<td>Hackers and Slackers</td>\n<td>&quot;Recent Posts&quot; widget does not have link rollover</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Backlog</td>\n<td>June 15, 2018</td>\n<td>#57D9A3</td>\n<td>Page Templates</td>\n<td>Task</td>\n<td>#73B0E1</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/task.png</td>\n<td>HACK-32</td>\n<td>Lowest</td>\n<td>Hackers and Slackers</td>\n<td>“Join” page</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>November 13, 2018</td>\n<td>#42526E</td>\n<td>Widgets</td>\n<td>Task</td>\n<td>#73B0E1</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/task.png</td>\n<td>HACK-543</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add “pro tip” box</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>To Do</td>\n<td>December 14, 2018</td>\n<td>#679EEF</td>\n<td>SEO</td>\n<td>Major Functionality</td>\n<td>#93d171</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/story.png</td>\n<td>HACK-656</td>\n<td>Low</td>\n<td>Hackers and Slackers</td>\n<td>Add alt attributes to images vis clarifai </td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Backlog</td>\n<td>October 16, 2018</td>\n<td>#FDDA3E</td>\n<td>Accounts</td>\n<td>Major Functionality</td>\n<td>#93d171</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/story.png</td>\n<td>HACK-473</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add avatar selection to signup</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>November 13, 2018</td>\n<td>#57D9A3</td>\n<td>Page Templates</td>\n<td>Sub-task</td>\n<td>#92BFE5</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/subtask.png</td>\n<td>HACK-231</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add blurb to each post page explaining what these are</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>December 10, 2018</td>\n<td>#291BA9</td>\n<td>Code snippets</td>\n<td>Task</td>\n<td>#73B0E1</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/task.png</td>\n<td>HACK-452</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add color styles for json snippets</td>\n</tr>\n</tbody></table>\n</div><!--kg-card-end: html--><p>That's right, a <em>table.</em> Databases are comprised of tables. Perhaps you see where I'm going with this.</p><h2 id=\"there-s-a-ninety-five-pound-chinese-man-with-a-hundred-sixty-million-dollars-behind-this-door-\">\"There's a Ninety-five Pound Chinese Man with a Hundred Sixty Million Dollars Behind this Door.\"</h2><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/1379892761308689767.jpg\" class=\"kg-image\"><figcaption>Let's get him out.</figcaption></figure><!--kg-card-end: image--><p>We've got the goods, but calling all these individual endpoints manually does nothing for us. We don't want to steal a single view, we want to systematically rob Tableau of it's views on a scheduler and Shanghai them off to a database of our choosing.</p><p>It would be a crime not to automate this, so I've created a class containing all the relevant methods we'd want when it comes to interacting with Tableau's REST API:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import requests\nimport xml.etree.ElementTree as ET\nfrom . import r\nimport pandas as pd\nimport io\n\n\nclass ExtractTableauView:\n    &quot;&quot;&quot;Class for with the Tableau server API.&quot;&quot;&quot;\n\n    __baseurl = r.get('baseurl')\n    __username = r.get('username')\n    __password = r.get('password')\n    __database = r.get('uri')\n    __contenturl = r.get('contenturl')\n\n    @classmethod\n    def get_view(cls, site, xml, view, token):\n        &quot;&quot;&quot;Extract contents of a single view.&quot;&quot;&quot;\n        headers = {'X-Tableau-Auth': token,\n                   'Content-Type': 'text/csv'\n                   }\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + str(site) +'/views/' + str(view) + '/data', headers=headers, stream=True)\n        csv_text = req.text\n        view_df = pd.read_csv(io.StringIO(csv_text), header=0)\n        return view_df\n\n    @classmethod\n    def list_views(cls, site, xml, token):\n        &quot;&quot;&quot;List all views belonging to a Tableau Site.&quot;&quot;&quot;\n        headers = {'X-Tableau-Auth': token}\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + site + '/views', auth=(cls.__username, cls.__password), headers=headers)\n        root = ET.fromstring(req.content)\n        views_arr = []\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}views':\n                for view in child:\n                    view_dict = {\n                        'name': view.attrib.get('name'),\n                        'id': view.attrib.get('id'),\n                        'url': cls.__baseurl + '/' + view.attrib.get('contentUrl'),\n                        'created': view.attrib.get('createdAt'),\n                        'updated': view.attrib.get('updatedAt')\n                    }\n                    views_arr.append(view_dict)\n        return views_arr\n\n    @classmethod\n    def get_token(cls, xml):\n        &quot;&quot;&quot;Receive Auth token to perform API requests.&quot;&quot;&quot;\n        for child in xml.iter('*'):\n            if child.tag == '{http://tableau.com/api}credentials':\n                token = child.attrib.get('token')\n                return token\n\n    @classmethod\n    def get_site(cls, xml):\n        &quot;&quot;&quot;Retrieve ID of Tableau 'site' instance.&quot;&quot;&quot;\n        root = xml\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}site':\n                site = child.attrib.get('id')\n                return site\n\n    @classmethod\n    def initialize_tableau_request(cls):\n        &quot;&quot;&quot;Retrieve core XML for interacting with Tableau.&quot;&quot;&quot;\n        headers = {'Content-Type': 'application/xml'}\n        body = '&lt;tsRequest&gt;&lt;credentials name=&quot;' + cls.__username + '&quot; password=&quot;' + cls.__password + '&quot; &gt;&lt;site contentUrl=&quot;' + cls.__contenturl + '&quot; /&gt;&lt;/credentials&gt;&lt;/tsRequest&gt;'\n        req = requests.post(cls.__baseurl + '/api/3.2/auth/signin', auth=(cls.__username, cls.__password), headers=headers, data=body)\n        root = ET.fromstring(req.content)\n        return root\n</code></pre>\n<!--kg-card-end: markdown--><p>The above snippet is a Python class utilizing all the API endpoints we explored in a mostly effortless manner. Instantiating the class immediately covers the grunt work of:</p><ul><li> Generating a token</li><li>Getting your (unfriendly) site ID</li><li>Listing all views belonging to the provided site</li><li>Retrieving data from a worksheet of choice</li></ul><p>Get a list of views in your Tableau site by using the <code>list_views()</code> method. When you see the view you want, pass the <strong>view ID</strong> to the <code>.get_view()</code> method. This will result in response of all raw data in the view in the form of a CSV. </p><h3 id=\"how-to-pull-a-heist-final-chapter-storing-in-offshore-accounts\">How to Pull a Heist (Final Chapter): Storing in Offshore Accounts</h3><p>To earn your title as a true con artist, I'm leaving the final step up to you. You've escaped with the loot, but you'll need to put all that data somewhere. This should be a trivial matter of automating a simple database query, but the specifics are up to you.</p><p>If you're ready to liberate your data, feel free to <a href=\"https://gist.github.com/toddbirchard/ad1386b4334e7b22b2f7b38edca3bd5c\">grab the source off of Github</a> and go nuts.</p>","url":"https://hackersandslackers.com/tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui/","uuid":"77d21a34-e5c1-4582-aade-ff92d8596387","page":false,"codeinjection_foot":null,"codeinjection_head":"<style>\n  .post-template .post-content img {\n    width: 100% !important;\n  }\n\n  figcaption {\n    width: -webkit-fill-available !important;\n    width: -moz-available !important;\n    margin: 0 auto 0;\n    margin-top: -10px;\n    padding: 10px !important;\n    background-color: rgba(33, 69, 138, .04);\n    color: #5e6167;\n    font-size: .8em !important;\n    font-style: italic;\n    text-align: center !important;\n    white-space: normal !important;\n    line-height: 1.5 !important;\n  }\n\n  .language-xml::before {\n    content: \"XML\" !important;\n  }\n\n  .language-html::before {\n    content: \"XML\" !important;\n  }\n\n  td {\n    display: table-cell;\n    padding: 15px 10px !important;\n    font-size: .7em !important;\n    line-height: 1.2 !important;\n    text-align: left !important;\n    text-align: center !important;\n    vertical-align: middle !important;\n    max-width: 150px !important;\n    overflow: hidden !important;\n    white-space: nowrap !important;\n  }\n\n  th {\n    padding: 10px !important;\n    font-size: .7em !important;\n    text-align: center !important;\n    min-width: none !important;\n  }\n\n  .tableContainer {\n    margin-top: 30px;\n    overflow: hidden;\n  }\n</style>","comment_id":"5c27630bda392c696eab97de"}},{"node":{"id":"Ghost__Post__5c1af93bffe54a660c58b85a","title":"Cracking Full Control Over Plot.ly Dash","slug":"gaining-full-control-over-plotly-dash","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/Dash@2x.jpg","excerpt":"Build apps with Plot.ly Dash on your own terms","custom_excerpt":"Build apps with Plot.ly Dash on your own terms","created_at_pretty":"20 December, 2018","published_at_pretty":"20 December, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-12-19T21:06:51.000-05:00","published_at":"2018-12-20T14:58:00.000-05:00","updated_at":"2019-03-28T05:19:31.000-04:00","meta_title":"Cracking Full Control Over Plot.ly Dash | Hackers and Slackers","meta_description":"Build apps with Plot.ly Dash on your own terms. Extend Flask functionality with Dash, not the other way around.","og_description":"Build apps with Plot.ly Dash on your own terms. Extend Flask functionality with Dash, not the other way around.","og_image":"https://hackersandslackers.com/content/images/2018/12/Dash@2x.jpg","og_title":"Cracking Full Control Over Plot.ly Dash","twitter_description":"Build apps with Plot.ly Dash on your own terms. Extend Flask functionality with Dash, not the other way around.","twitter_image":"https://hackersandslackers.com/content/images/2018/12/Dash@2x.jpg","twitter_title":"Cracking Full Control Over Plot.ly Dash","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Plotly","slug":"plotly","description":"Get intimate with a staple product in data visualization. Create charts with Plot.ly's core product, or become a pro with Plot.ly Dash.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Dash.jpg","meta_description":"Get intimate with a staple product in data visualization. Create charts with Plot.ly's core product, or become a pro with Plot.ly Dash.","meta_title":"Plotly for Data Visualization | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Plotly","slug":"plotly","description":"Get intimate with a staple product in data visualization. Create charts with Plot.ly's core product, or become a pro with Plot.ly Dash.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Dash.jpg","meta_description":"Get intimate with a staple product in data visualization. Create charts with Plot.ly's core product, or become a pro with Plot.ly Dash.","meta_title":"Plotly for Data Visualization | Hackers and Slackers","visibility":"public"},{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Using Plotly Dash Like a Pro","slug":"plotly-dash","description":"Push the limits of Plot.ly Dash to create data-driven applications with ease. Take on Python, Pandas, Flask, and Data Visualization all at once.","feature_image":"https://hackersandslackers.com/content/images/2019/03/Dash.jpg","meta_description":"Push the limits of Plot.ly Dash to create data-driven applications with ease. Take on Python, Pandas, Flask, and Data Visualization all at once.","meta_title":"Using Plotly Dash Like a Pro","visibility":"internal"}],"plaintext":"Ahh, Plot.ly [http://plot.ly/]; typing that name into a post headline triggers\nan emotional cocktail of pride and embarrassment. Over the years Plotly has been\nat the core of some of the most influential products I’ve worked on: a\nhodgepodge of Fintech and humanitarian clients, all of which are still proudly\nwaving their charts and dashboards around the world. Yet, my mind is boggled by\na simple question: what the hell  took us so long to write our first post about\nPlotly? We've been operating Hackers and Slackers for over a full year now...\ndid I seriously write a  post about JQuery\n[https://hackersandslackers.com/making-ajax-calls-with-jquery/]  in that time\nbefore reaching this point?\n\nMuch has changed in the last year or so for our friends in Montreal. Number 1 in\nmy book is the price reduction of their core product: from 300 dollars  to zero.\nI paid the 300 dollars. We really need to get a “donate” button around here. \n\nA close second is undoubtedly the introduction of Plot.ly Dash\n[https://plot.ly/products/dash/]. Dash  tickles a sentiment which has danced\nthrough many young and helplessly naïve Pythonistas' minds: what if we could\nwrite only  in Python, like, forever?  As awful of an idea it is to start\nGoogling Python-to-frontend code interpreters (they exist; I checked), Plotly's\nDash does a shockingly good job of breathing life into that romantic fantasy of\ncommitting to Python forever.\n\nBut we're not here to deliver a recycled 'What is Plotly?'  synopsis. We're not\neven interested in the obligatory 'How to Get Started Using This\nAlready-Well-Documented-Technology' post. Plotly deserves better than that.\nInstead, we're coming hot out of the gate swinging: we're going to show you how\nto beat Plotly down, break it, and make it bend to your will. Welcome to a\nmagical edition of Hacking Plotly. It must be Christmas, folks.\n\nLet's Make a Plotly + Flask Lovechild from Hell\nLike almost every single advancement to come out of Python-geared architecture\nthis year, Dash has a little secret: it's gotten here with a little help from\nFlask. Alright, perhaps more than a little: Dash actually extends Flask. Sounds\nsensible, and perhaps even exciting at first; its almost as though every crush\nyou've ever had decided it be best to simply put their differences aside to\nstart a group chat with you in the interest of making your sexual well-being an\nequal team effort out of sheer love. As you've already guessed, life doesn't\nwork like that.\n\nDash hijacks Flask from the beginning, starting with the way we instantiate the\napp. Any code monkey who has laid eyes upon a wsgi.py file can tell you\nsomething is up before you can even say app = dash.Dash(__name__). Check out the\nrecommended startup boilerplate:\n\nfrom dash import Dash\nimport dash_core_components as dcc\nimport dash_html_components as html\n\nexternal_stylesheets = ['https://codepen.io/fgdsgfhgfh/pen/IHvjvb.css']\n\napp = Dash(__name__, external_stylesheets=external_stylesheets)\n\napp.layout = html.Div(\n        id='example-div-element'\n        )\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n\n\nIf you were to attempt to take this boilerplate and attempt to add core Flask\nlogic, such as authentication with Flask-Login, generating assets with \nFlask-Assets, or just creating a global database, where would you start? Plotly\ncleverly suggests reserving the app  namespace for your app- the very same that\nwe would do with Flask. Yet if we attempt to modify the app  object the same as\nwe would with Flask, nothing will work: Dash has declared an ecosystem, and\nnowhere in that ecosystem are you invited to add custom Flask application logic\nout of the box.\n\nDash does what it was intended to do very well: building dashboard-based\napplications. The issue is that applications which can only display data  aren't\nentirely useful as end products. What if we wanted to create a fully-featured\napp, where data visualization was simply a feature  of said app?\n\nCreating a Fully-Featured App (Where Data Vis is Simply a Feature of Said App)\nA common \"workaround\" you'll find in the community is passing Flask to Dash as\nthe underlying \"server\", something like this:\n\nfrom flask import Flask\nfrom dash import Dash\nimport dash_core_components as dcc\nimport dash_html_components as html\n\nserver = Flask(__name__)\napp = dash.Dash(__name__, server=server, url_base_pathname='/path')\napp.layout = html.Div(id='example-div-element')\n\n@server.route(\"/dash\")\ndef MyDashApp():\n    return app.index()\n\n\nMake no mistake: this method sucks. Sure, you've regained the ability to create\nroutes here and there, but let's not forget:\n\n * Your app will always start on a Dash-served page: if anything, we'd want our\n   start page to be something we have full control over to then dive into the\n   Dash components.\n * Access to globally available Flask plugins are still unavailable in this\n   method. Notice how we never set an application context?\n * Your ability to style your application with static assets and styles is\n   completely out of your hands.\n * Container architecture built on Flask, such as Google App Engine, won't play\n   nicely when we start something that isn't Flask. So there's a good chance\n   that playing by the rules means losing the ability to deploy.\n\nIf we want to do these things, we cannot start our app as an instance of Dash\nand attempt to work around it. Instead, we must create a Flask app, and put Dash\nin its place as an app embedded in our  app. This gives us full control over\nwhen users can enter the Dash interface, and even within that interface, we can\nstill manage database connections or user sessions as we see fit. Welcome to the\nbig leagues.\n\nTurning the Tables: Dash Inside Flask\nFirst things first, let's get our wsgi.py  file back. Pretty much any hosted\nPython application expects this, so please: enough with the app.py  nonsense.\n\nfrom plotly_flask_tutorial import create_app\n\napp = create_app()\n\nif __name__ == \"__main__\":\n    app.run(host='0.0.0.0', debug=True)\n\n\nLook familiar? Not only do we get Flask back, but we get our entire application\nfactory and all that it includes. Take a look at application/__init__.py:\n\nfrom flask import Flask\nfrom . import dash_view\n\n\ndef create_app():\n    \"\"\"Construct the core application.\"\"\"\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n    dash_app = dash_view.Add_Dash(app)\n\n    with app.app_context():\n        # Construct the core application\n        from . import routes\n        app.register_blueprint(routes.main_bp)\n\n        return app\n\n\nIt's almost as though nothing changed! In fact, the only line we have regarding\nDash here is dash_app = plotly_dash_views.Add_Dash(app). \n\nWe import dash_view  at the start of __init.py__. What is this, you might ask?\nIt's actually a file which contains our Dash app! Dash apps typically like to\nhave a single .py  file per view, which turns out to work great for us. Let's\nlook at why this works by checking dash_view.py:\n\nimport glob\nfrom dash import Dash\nimport dash_table\nimport dash_core_components as dcc\nimport dash_html_components as html\nimport pandas as pd\n\n\ndef Add_Dash(server):\n    \"\"\"Plot.ly Dash view which populates the screen with loaded DataFrames.\"\"\"\n    external_stylesheets = ['https://hackers.nyc3.cdn.digitaloceanspaces.com/css/plotly-flask-tutorial.css']\n    dash_app = Dash(server=server,\n                    external_stylesheets=external_stylesheets,\n                    routes_pathname_prefix='/dash_view/')\n\n    # Create Dash Layout\n    dash_app.layout = html.Div(\n        id='dash-container'\n      )\n\n    return dash_app.server\n\n\nWe pass our Flask instance to Add_Dash  as a parameter called server. Unlike the\nprevious examples, it's actually server  running the show this time, with Dash\npiggybacking as a module. This is our most important line of code:\n\ndash_app = Dash(server=server, routes_pathname_prefix='/dash_view/')\n\n\nDash doesn't handle routes like Flask does (or at all, really). That's fine! We\nstart dash_app  with URL prefix, which means the Dash logic here is confined to\nthat single page. This means we can build a sprawling Flask app with hundreds of\nfeatures and views, and oh yeah, if we want a Dash view, we can just create a\nfile for that to chill on its own, not touching anything else.\n\nNow you're thinking with portals™.\n\nWhat Our App Looks Like\nIf you're following along, it would probably help to have a top-level view of\nwhat's going on so far:\n\nplotlydash-flask-tutorial\n├── /plotly_flask_tutorial\n│   ├── __init__.py\n│   ├── dash_view.py\n│   ├── routes.py\n│   ├── /data\n│   │   ├── chicago_taxis.csv\n│   │   ├── citibike_trips.csv\n│   │   ├── cities.csv\n│   │   └── pocket.csv\n│   ├── /static\n│   │   ├── dist\n│   │   │   └── css\n│   │   │       └── plotly-flask-tutorial.css\n│   │   ├── js\n│   │   │   └── main.js\n│   │   └── less\n│   │       ├── global.less\n│   │       ├── header.less\n│   │       └── table.less\n│   ├── /templates\n│   │   ├── index.html\n│   │   └── nav.html\n│   └── /data\n│       ├── chicago_taxis.csv\n│       ├── citibike_trips.csv\n│       ├── cities.csv\n│       └── pocket.csv\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── config.py\n├── requirements.txt\n├── setup.py\n├── start.sh\n└── wsgi.py\n\n\nWe're storing our app within a directory called plotly_flask_tutorial. In that\ndirectory, we have our typical Flask stuff (/templates, /static, etc) as well as\ntwo notable files: routes.py  and dash_view.py.\n\nroutes.py\nroutes.py  can contain anything we want. Our application will default to serving\na Flask page, not  a Dash page, so our routes can be an entire standalone\napplication. Here's what I tossed in there: \n\nimport os\nfrom flask import Blueprint, render_template\nfrom flask_assets import Environment, Bundle\nfrom flask import current_app as app\nimport lesscpy\n\nmain_bp = Blueprint('main_bp', __name__,\n                    template_folder='templates',\n                    static_folder='static')\nassets = Environment(app)\nEnvironment.auto_build = True\nEnvironment.debug = False\nless_bundle = Bundle('less/*.less',\n                     filters='less,cssmin',\n                     output='dist/css/plotly-flask-tutorial.css.css',\n                     extra={'rel': 'stylesheet/less'})\njs_bundle = Bundle('js/*.js',\n                   filters='jsmin',\n                   output='dist/js/main.js')\nassets.register('less_all', less_bundle)\nassets.register('js_all', js_bundle)\nless_bundle.build(force=True)\njs_bundle.build()\n\n\n# Landing Page\n@main_bp.route('/', methods=['GET'])\ndef home():\n    return render_template('index.html',\n                           title='Plotly Flask Tutorial.',\n                           template='home-template',\n                           body=\"This is an example homepage, served with Flask.\")\n\n\nAll this is doing is serving up index.html.\n\ndash_view.py\ndash_view.py  is the Dash app we have living within  our Flask app. But how does\nFlask know which url to serve our application at? Wasn't it missing from \nroutes.py? Indeed it was, good fellow! Because we set routes_pathname_prefix, we\n don't need  to create a route for dash_view.py: it will always be served\nwhenever we navigate to 127.0.01/dash_view. Thus, we can create a navigation\ntemplate like this:\n\n<nav>\n  <a href=\"/\"><i class=\"fas fa-home\"></i> Home</a>\n  <a href=\"/dash_view/\"><i class=\"fas fa-chart-line\"></i> Embdedded Plotly Dash</a>\n</nav>\n\n\nCreating Something Useful\nHere's a fun little thing I was able to do with Dash, while in the context of\nrunning under a Flask app. In our file dash_view.py, I have the app look at a\nfolder of extracted datasets (called  /data). For each dataset, I use Pandas to\ngenerate a preview, and Dash's \"data table\" component to render said previews in\nour Dash app. This lets us quickly cruise through the data an app depends on\nwith a cool interface:\n\nA bit rough around the edges, but you get the point.If you're hungry for some\nsource code to get started building your own Plotly Dash views, here's the\nsource I used to create the page above:\n\nimport glob\nfrom pathlib import Path, PurePath\nfrom dash import Dash\nimport dash_table\nimport dash_core_components as dcc\nimport dash_html_components as html\nimport pandas as pd\n\np = Path('.')\n\n\ndef Add_Dash(server):\n    \"\"\"Plot.ly Dash view which populates the screen with loaded DataFrames.\"\"\"\n    external_stylesheets = ['https://hackers.nyc3.cdn.digitaloceanspaces.com/css/plotly-flask-tutorial.css',\n                            'https://fonts.googleapis.com/css?family=Lato',\n                   'https://use.fontawesome.com/releases/v5.8.1/css/all.css']\n    dash_app = Dash(server=server,\n                    external_stylesheets=external_stylesheets,\n                    routes_pathname_prefix='/dash_view/')\n\n    # Override the underlying HTML template\n    dash_app.index_string = '''<!DOCTYPE html>\n        <html>\n            <head>\n                {%metas%}\n                <title>{%title%}</title>\n                {%favicon%}\n                {%css%}\n            </head>\n            <body>\n                <nav>\n                  <a href=\"/\"><i class=\"fas fa-home\"></i> Home</a>\n                  <a href=\"/dash_view/\"><i class=\"fas fa-chart-line\"></i> Embdedded Plotly Dash</a>\n                </nav>\n                {%app_entry%}\n                <footer>\n                    {%config%}\n                    {%scripts%}\n                    {%renderer%}\n                </footer>\n            </body>\n        </html>'''\n\n    # Create Dash Layout comprised of Data Tables\n    dash_app.layout = html.Div(\n        children=get_datasets(),\n        id='flex-container'\n      )\n\n    return dash_app.server\n\n\ndef get_datasets():\n    \"\"\"Returns previews of all CSVs saved in /data directory.\"\"\"\n    data_filepath = list(p.glob('plotly_flask_tutorial/data/*.csv'))\n    arr = ['This is an example Plot.ly Dash App.']\n    for index, csv in enumerate(data_filepath):\n        print(PurePath(csv))\n        df = pd.read_csv(data_filepath[index]).head(10)\n        table_preview = dash_table.DataTable(\n            id='table_' + str(index),\n            columns=[{\"name\": i, \"id\": i} for i in df.columns],\n            data=df.to_dict(\"rows\"),\n            sorting=True,\n        )\n        arr.append(table_preview)\n    return arr\n\n\nI've gone ahead and uploaded the source code for this working example up on\nGithub [https://github.com/toddbirchard/plotlydash-flask-tutorial]. Please steal\nit: it's all yours.\n\nNeedless to say, there's way more cool shit we can accomplish with Plotly Dash.\nStick around long enough, and chances are we'll cover all of them.","html":"<p>Ahh, <a href=\"http://plot.ly/\"><strong>Plot.ly</strong></a>; typing that name into a post headline triggers an emotional cocktail of pride and embarrassment. Over the years Plotly has been at the core of some of the most influential products I’ve worked on: a hodgepodge of Fintech and humanitarian clients, all of which are still proudly waving their charts and dashboards around the world. Yet, my mind is boggled by a simple question: what the <em>hell</em> took us so long to write our first post about Plotly? We've been operating Hackers and Slackers for over a full year now... did I seriously write a<a href=\"https://hackersandslackers.com/making-ajax-calls-with-jquery/\"> post about JQuery</a> in that time before reaching this point?</p><p>Much has changed in the last year or so for our friends in Montreal. Number 1 in my book is the price reduction of their core product: from <em><strong>300 dollars</strong></em> to <em><strong>zero</strong></em>. I paid the 300 dollars. We really need to get a “donate” button around here. </p><p>A close second is undoubtedly the introduction of <strong><a href=\"https://plot.ly/products/dash/\">Plot.ly Dash</a></strong>. <strong>Dash</strong> tickles a sentiment which has danced through many young and helplessly naïve Pythonistas' minds: <em>what if we could write </em><strong><em>only</em></strong><em> in Python, like, </em><strong><em>forever</em></strong><em>?</em> As awful of an idea it is to start Googling Python-to-frontend code interpreters (they exist; I checked), Plotly's Dash does a shockingly good job of breathing life into that romantic fantasy of committing to Python forever.</p><p>But we're not here to deliver a recycled 'W<em>hat is Plotly?'</em> synopsis. We're not even interested in the obligatory '<em>How to Get Started Using This Already-Well-Documented-Technology' </em>post<em>. </em>Plotly deserves better than that. Instead, we're coming hot out of the gate swinging: we're going to show you how to beat Plotly down, break it, and make it bend to your will. Welcome to a magical edition of Hacking Plotly. It must be Christmas, folks.</p><h2 id=\"let-s-make-a-plotly-flask-lovechild-from-hell\">Let's Make a Plotly + Flask Lovechild from Hell</h2><p>Like almost every single advancement to come out of Python-geared architecture this year, Dash has a little secret: it's gotten here with a little help from Flask. Alright, perhaps more than a little: Dash actually extends Flask. Sounds sensible, and perhaps even exciting at first; its almost as though every crush you've ever had decided it be best to simply put their differences aside to start a group chat with you in the interest of making your sexual well-being an equal team effort out of sheer love. As you've already guessed, life doesn't work like that.</p><p>Dash hijacks Flask from the beginning, starting with the way we instantiate the app. Any code monkey who has laid eyes upon a <strong>wsgi.py </strong>file can tell you something is up before you can even say <code>app = dash.Dash(__name__)</code>. Check out the recommended startup boilerplate:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from dash import Dash\nimport dash_core_components as dcc\nimport dash_html_components as html\n\nexternal_stylesheets = ['https://codepen.io/fgdsgfhgfh/pen/IHvjvb.css']\n\napp = Dash(__name__, external_stylesheets=external_stylesheets)\n\napp.layout = html.Div(\n        id='example-div-element'\n        )\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre>\n<!--kg-card-end: markdown--><p>If you were to attempt to take this boilerplate and attempt to add core Flask logic, such as authentication with <code>Flask-Login</code>, generating assets with <code>Flask-Assets</code>, or just creating a global database, where would you start? Plotly cleverly suggests reserving the <code>app</code> namespace for your app- the very same that we would do with Flask. Yet if we attempt to modify the <code>app</code> object the same as we would with Flask, nothing will work: Dash has declared an ecosystem, and nowhere in that ecosystem are you invited to add custom Flask application logic out of the box.</p><p>Dash does what it was intended to do very well: building dashboard-based applications. The issue is that applications which can <em>only display data</em> aren't entirely useful as end products. What if we wanted to create a fully-featured app, where data visualization was simply a <em>feature</em> of said app?</p><h2 id=\"creating-a-fully-featured-app-where-data-vis-is-simply-a-feature-of-said-app-\">Creating a Fully-Featured App (Where Data Vis is Simply a Feature of Said App)</h2><p>A common \"workaround\" you'll find in the community is passing Flask to Dash as the underlying \"server\", something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask\nfrom dash import Dash\nimport dash_core_components as dcc\nimport dash_html_components as html\n\nserver = Flask(__name__)\napp = dash.Dash(__name__, server=server, url_base_pathname='/path')\napp.layout = html.Div(id='example-div-element')\n\n@server.route(&quot;/dash&quot;)\ndef MyDashApp():\n    return app.index()\n</code></pre>\n<!--kg-card-end: markdown--><p>Make no mistake: this method <em>sucks. </em>Sure, you've regained the ability to create routes here and there, but let's not forget:</p><ul><li>Your app will always start on a Dash-served page: if anything, we'd want our start page to be something we have full control over to then dive into the Dash components.</li><li>Access to globally available Flask plugins are still unavailable in this method. Notice how we never set an application context?</li><li>Your ability to style your application with static assets and styles is completely out of your hands.</li><li>Container architecture built on Flask, such as Google App Engine, won't play nicely when we start something that isn't Flask. So there's a good chance that playing by the rules means losing the ability to deploy.</li></ul><p>If we want to do these things, we cannot start our app as an instance of Dash and attempt to work around it. Instead, we must create a Flask app, and put Dash in its place as an app embedded in <em>our</em> app. This gives us full control over when users can enter the Dash interface, and even within that interface, we can still manage database connections or user sessions as we see fit. Welcome to the big leagues.</p><h2 id=\"turning-the-tables-dash-inside-flask\">Turning the Tables: Dash Inside Flask</h2><p>First things first, let's get our <strong>wsgi.py</strong> file back. Pretty much any hosted Python application expects this, so please: enough with the <strong>app.py</strong> nonsense.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from plotly_flask_tutorial import create_app\n\napp = create_app()\n\nif __name__ == &quot;__main__&quot;:\n    app.run(host='0.0.0.0', debug=True)\n</code></pre>\n<!--kg-card-end: markdown--><p>Look familiar? Not only do we get Flask back, but we get our entire application factory and all that it includes. Take a look at <code>application/__init__.py</code><em>:</em></p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask\nfrom . import dash_view\n\n\ndef create_app():\n    &quot;&quot;&quot;Construct the core application.&quot;&quot;&quot;\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n    dash_app = dash_view.Add_Dash(app)\n\n    with app.app_context():\n        # Construct the core application\n        from . import routes\n        app.register_blueprint(routes.main_bp)\n\n        return app\n</code></pre>\n<!--kg-card-end: markdown--><p>It's almost as though nothing changed! In fact, the only line we have regarding Dash here is <code>dash_app = plotly_dash_views.Add_Dash(app)</code>. </p><p>We import <code>dash_view</code> at the start of <code>__init.py__</code>. What is this, you might ask? It's actually a file which contains our Dash app! Dash apps typically like to have a single <em>.py</em> file per view, which turns out to work great for us. Let's look at why this works by checking <code>dash_view.py</code>:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import glob\nfrom dash import Dash\nimport dash_table\nimport dash_core_components as dcc\nimport dash_html_components as html\nimport pandas as pd\n\n\ndef Add_Dash(server):\n    &quot;&quot;&quot;Plot.ly Dash view which populates the screen with loaded DataFrames.&quot;&quot;&quot;\n    external_stylesheets = ['https://hackers.nyc3.cdn.digitaloceanspaces.com/css/plotly-flask-tutorial.css']\n    dash_app = Dash(server=server,\n                    external_stylesheets=external_stylesheets,\n                    routes_pathname_prefix='/dash_view/')\n\n    # Create Dash Layout\n    dash_app.layout = html.Div(\n        id='dash-container'\n      )\n\n    return dash_app.server\n</code></pre>\n<!--kg-card-end: markdown--><p>We pass our Flask instance to <code>Add_Dash</code> as a parameter called <em>server. </em>Unlike the previous examples, it's actually <em>server</em> running the show this time, with Dash piggybacking as a module. This is our most important line of code:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">dash_app = Dash(server=server, routes_pathname_prefix='/dash_view/')\n</code></pre>\n<!--kg-card-end: markdown--><p>Dash doesn't handle routes like Flask does (or at all, really). That's fine! We start <code>dash_app</code> with URL prefix, which means the Dash logic here is confined to that single page. This means we can build a sprawling Flask app with hundreds of features and views, and oh yeah, if we want a Dash view, we can just create a file for that to chill on its own, not touching anything else.</p><p>Now you're thinking with portals<strong>™.</strong></p><h2 id=\"what-our-app-looks-like\">What Our App Looks Like</h2><p>If you're following along, it would probably help to have a top-level view of what's going on so far:</p><!--kg-card-begin: markdown--><pre><code>plotlydash-flask-tutorial\n├── /plotly_flask_tutorial\n│   ├── __init__.py\n│   ├── dash_view.py\n│   ├── routes.py\n│   ├── /data\n│   │   ├── chicago_taxis.csv\n│   │   ├── citibike_trips.csv\n│   │   ├── cities.csv\n│   │   └── pocket.csv\n│   ├── /static\n│   │   ├── dist\n│   │   │   └── css\n│   │   │       └── plotly-flask-tutorial.css\n│   │   ├── js\n│   │   │   └── main.js\n│   │   └── less\n│   │       ├── global.less\n│   │       ├── header.less\n│   │       └── table.less\n│   ├── /templates\n│   │   ├── index.html\n│   │   └── nav.html\n│   └── /data\n│       ├── chicago_taxis.csv\n│       ├── citibike_trips.csv\n│       ├── cities.csv\n│       └── pocket.csv\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── config.py\n├── requirements.txt\n├── setup.py\n├── start.sh\n└── wsgi.py\n</code></pre>\n<!--kg-card-end: markdown--><p>We're storing our app within a directory called <code>plotly_flask_tutorial</code>. In that directory, we have our typical Flask stuff (<strong>/templates</strong>, <strong>/static</strong>, etc) as well as two notable files: <code>routes.py</code> and <code>dash_view.py</code>.</p><h3 id=\"routes-py\">routes.py</h3><p><code>routes.py</code> can contain anything we want. Our application will default to serving a Flask page, <em>not</em> a Dash page, so our routes can be an entire standalone application. Here's what I tossed in there: </p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nfrom flask import Blueprint, render_template\nfrom flask_assets import Environment, Bundle\nfrom flask import current_app as app\nimport lesscpy\n\nmain_bp = Blueprint('main_bp', __name__,\n                    template_folder='templates',\n                    static_folder='static')\nassets = Environment(app)\nEnvironment.auto_build = True\nEnvironment.debug = False\nless_bundle = Bundle('less/*.less',\n                     filters='less,cssmin',\n                     output='dist/css/plotly-flask-tutorial.css.css',\n                     extra={'rel': 'stylesheet/less'})\njs_bundle = Bundle('js/*.js',\n                   filters='jsmin',\n                   output='dist/js/main.js')\nassets.register('less_all', less_bundle)\nassets.register('js_all', js_bundle)\nless_bundle.build(force=True)\njs_bundle.build()\n\n\n# Landing Page\n@main_bp.route('/', methods=['GET'])\ndef home():\n    return render_template('index.html',\n                           title='Plotly Flask Tutorial.',\n                           template='home-template',\n                           body=&quot;This is an example homepage, served with Flask.&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>All this is doing is serving up <code>index.html</code>.</p><h3 id=\"dash_view-py\">dash_view.py</h3><p><code>dash_view.py</code> is the Dash app we have living <em>within</em> our Flask app. But how does Flask know which url to serve our application at? Wasn't it missing from <code>routes.py</code>? Indeed it was, good fellow! Because we set <strong>routes_pathname_prefix</strong>, we <em>don't need</em> to create a route for <code>dash_view.py</code>: it will always be served whenever we navigate to <code>127.0.01/dash_view</code>. Thus, we can create a navigation template like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">&lt;nav&gt;\n  &lt;a href=&quot;/&quot;&gt;&lt;i class=&quot;fas fa-home&quot;&gt;&lt;/i&gt; Home&lt;/a&gt;\n  &lt;a href=&quot;/dash_view/&quot;&gt;&lt;i class=&quot;fas fa-chart-line&quot;&gt;&lt;/i&gt; Embdedded Plotly Dash&lt;/a&gt;\n&lt;/nav&gt;\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"creating-something-useful\">Creating Something Useful</h2><p>Here's a fun little thing I was able to do with Dash, while in the context of running under a Flask app. In our file <code>dash_view.py</code>, I have the app look at a folder of extracted datasets (called<em> /data</em>). For each dataset, I use Pandas to generate a preview, and Dash's \"data table\" component to render said previews in our Dash app. This lets us quickly cruise through the data an app depends on with a cool interface:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/dataframes.gif\" class=\"kg-image\"><figcaption>A bit rough around the edges, but you get the point.</figcaption></figure><!--kg-card-end: image--><p>If you're hungry for some source code to get started building your own Plotly Dash views, here's the source I used to create the page above:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import glob\nfrom pathlib import Path, PurePath\nfrom dash import Dash\nimport dash_table\nimport dash_core_components as dcc\nimport dash_html_components as html\nimport pandas as pd\n\np = Path('.')\n\n\ndef Add_Dash(server):\n    &quot;&quot;&quot;Plot.ly Dash view which populates the screen with loaded DataFrames.&quot;&quot;&quot;\n    external_stylesheets = ['https://hackers.nyc3.cdn.digitaloceanspaces.com/css/plotly-flask-tutorial.css',\n                            'https://fonts.googleapis.com/css?family=Lato',\n                   'https://use.fontawesome.com/releases/v5.8.1/css/all.css']\n    dash_app = Dash(server=server,\n                    external_stylesheets=external_stylesheets,\n                    routes_pathname_prefix='/dash_view/')\n\n    # Override the underlying HTML template\n    dash_app.index_string = '''&lt;!DOCTYPE html&gt;\n        &lt;html&gt;\n            &lt;head&gt;\n                {%metas%}\n                &lt;title&gt;{%title%}&lt;/title&gt;\n                {%favicon%}\n                {%css%}\n            &lt;/head&gt;\n            &lt;body&gt;\n                &lt;nav&gt;\n                  &lt;a href=&quot;/&quot;&gt;&lt;i class=&quot;fas fa-home&quot;&gt;&lt;/i&gt; Home&lt;/a&gt;\n                  &lt;a href=&quot;/dash_view/&quot;&gt;&lt;i class=&quot;fas fa-chart-line&quot;&gt;&lt;/i&gt; Embdedded Plotly Dash&lt;/a&gt;\n                &lt;/nav&gt;\n                {%app_entry%}\n                &lt;footer&gt;\n                    {%config%}\n                    {%scripts%}\n                    {%renderer%}\n                &lt;/footer&gt;\n            &lt;/body&gt;\n        &lt;/html&gt;'''\n\n    # Create Dash Layout comprised of Data Tables\n    dash_app.layout = html.Div(\n        children=get_datasets(),\n        id='flex-container'\n      )\n\n    return dash_app.server\n\n\ndef get_datasets():\n    &quot;&quot;&quot;Returns previews of all CSVs saved in /data directory.&quot;&quot;&quot;\n    data_filepath = list(p.glob('plotly_flask_tutorial/data/*.csv'))\n    arr = ['This is an example Plot.ly Dash App.']\n    for index, csv in enumerate(data_filepath):\n        print(PurePath(csv))\n        df = pd.read_csv(data_filepath[index]).head(10)\n        table_preview = dash_table.DataTable(\n            id='table_' + str(index),\n            columns=[{&quot;name&quot;: i, &quot;id&quot;: i} for i in df.columns],\n            data=df.to_dict(&quot;rows&quot;),\n            sorting=True,\n        )\n        arr.append(table_preview)\n    return arr\n</code></pre>\n<!--kg-card-end: markdown--><p>I've gone ahead and uploaded the source code for this working example up <a href=\"https://github.com/toddbirchard/plotlydash-flask-tutorial\">on Github</a>. Please steal it: it's all yours.</p><p>Needless to say, there's way more cool shit we can accomplish with Plotly Dash. Stick around long enough, and chances are we'll cover all of them.</p>","url":"https://hackersandslackers.com/gaining-full-control-over-plotly-dash/","uuid":"535768b9-34b6-4a80-b5fa-b69b50cf3a68","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c1af93bffe54a660c58b85a"}},{"node":{"id":"Ghost__Post__5c192cdba632c8240cad3869","title":"Globally Accessible Variables in Flask: Demystifying the 'Application Context'","slug":"demystifying-flasks-application-context","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/flask_factory-2.jpg","excerpt":"Breaking down the nuances of the ‘app context’ in Flask's Application Factory.","custom_excerpt":"Breaking down the nuances of the ‘app context’ in Flask's Application Factory.","created_at_pretty":"18 December, 2018","published_at_pretty":"19 December, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-12-18T12:22:35.000-05:00","published_at":"2018-12-19T08:00:00.000-05:00","updated_at":"2019-04-09T23:49:27.000-04:00","meta_title":"Demystifying Flask's Application Context | Hackers and Slackers","meta_description":"A guide breaking down the cryptic nuances of Flask's 'Application Context.' Putting an end to \"RuntimeError: working outside of application context\".","og_description":"A guide breaking down the cryptic nuances of Flask's 'Application Context.' Putting an end to \"RuntimeError: working outside of application context\".","og_image":"https://hackersandslackers.com/content/images/2019/04/flask_factory-2-2.jpg","og_title":"Demystifying Flask's Application Context","twitter_description":"A guide breaking down the cryptic nuances of Flask's 'Application Context.' Putting an end to \"RuntimeError: working outside of application context\".","twitter_image":"https://hackersandslackers.com/content/images/2019/04/flask_factory-2-1.jpg","twitter_title":"Demystifying Flask's Application Context","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"A 'skill' that's always fascinated me is just how long some engineers can make\nit in their career while carrying glaringly obvious gaps in their knowledge of\nthe systems they use every day. To my surprise, I've turned corners where I\nmyself have been that engineer all along, and there's perhaps no better example\nof this then the time I've spent with Flask.\n\nWARNING! Highly opinionated statement incoming: Flask is everything a framework\nshould be. That is to say, it isn't really  a framework a fully-fledged\nframework at all. Sure, the term microframework might seem like a cute PR term,\nbut that doesn't negate the fact that there's something about Flask that's\ndifferent. When I write apps in Flask,  I feel as though I'm writing apps in \nPython.  On the other hand, when I write apps in Django,  I feel like I'm just\nwriting apps in Django.  A disciplined programmer might feel that overly\nstructured frameworks damper creativity and they're probably right: these are\nthe backbones of businesses, thus it makes sense to keep people from deviating\nfrom the norm. \n\nThe upside of Flask is also its downside: there's nearly an infinite number of\nways to solve a single problem. Every Stackoverflow regular has their own\npreference, and sometimes, just none of them seem... right. The problem is\ncompounded by some of the phrasing coming from Flask's documentation itself.\nFlask touts the importance of structuring apps with factories and Blueprints,\nwhile simultaneously expressing the power behind the application context.  What\nyou'll notice over time is that in Flask's own examples, these two 'very\nimportant things' never both appear at the same time: that's because they're\nsimply incompatible with one another.  This is a highly understated\ncontradiction of philosophies.\n\nCommunication Breakdown?\nHere's Flask's take on Application factories\n[http://flask.pocoo.org/docs/1.0/patterns/appfactories/]:\n\n> If you are already using packages and blueprints for your application (Modular\nApplications with Blueprints) there are a couple of really nice ways to further\nimprove the experience. A common pattern is creating the application object when\nthe blueprint is imported.\n\n\nAnd here's their description of the Application context\n[http://flask.pocoo.org/docs/1.0/appcontext/]:\n\n> The application context keeps track of the application-level data during a\nrequest, CLI command, or other activity. Rather than passing the application\naround to each function, the current_app and g proxies are accessed instead.\n\n\nConsidering g  is intended to stand for \"global\" it seems safe from the previous\nstatements that setting attributes of g  can be accessed globally within an\napplication... but they can't. This is where we backpedal and get into messy\nterritory:\n\n> However, importing the app instance within the modules in your project is prone\nto circular import issues. When using the app factory pattern or writing\nreusable blueprints or extensions there won’t be an app instance to import at\nall.\n\nFlask solves this issue with the application context. Rather than referring to\nan app directly, you use the the current_app  proxy, which points to the\napplication handling the current activity.\n\n\nOkay, fine. So if I instantiate an application factory with app.app_context(): \n(which is the only sensible way to create a factory at all)  I should be able to\nregister blueprints within that context, and reference the app context, correct?\n\nI could be crazy but this never seems to work  within blueprints. Whether they\nexist as peer modules or submodules, the words 'from application import\ncurrent_app as app' always seems to result in the same \"missing application\ncontext\" error. Conveniently it seems, all working examples of the application\ncontext seem to be when the Flask developers opt to serve single-file app\nexamples. This stranger from Stackoverflow\n[https://stackoverflow.com/questions/50233118/access-to-flask-global-variables-in-blueprint-apps] \n clears things up a bit:\n\n> This happens because the data are lost when the context (with app.app_context())\nends (doc).\nInside the context, everything is ok :\n\nfrom flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n   print(g.my_db)\n\nthis prints 'database ok'\n\n\nBut outside, you cannot access the attribute:\n\nfrom flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n\nprint(g.my_db)\n\n\nthis throws RuntimeError: Working outside of application context\n\neven if you create a new context:\n\nfrom flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n\nwith app.app_context():\n   print(g.my_db)\n\n\nthis throws AttributeError: '_AppCtxGlobals' object has no attribute 'my_db'\n\n\nAlas, here I am. Doomed writing posts to fill in the blanks of documentation\nleft behind by others. \n\nFlask Sessions: The REAL Slim Shady\nFlask-Session  is the MVP when it comes sharing temporary information across\nmodularized parts of our program. In fact, it's a bit odd this isn't encouraged\nmore-so than g. But whatever. We're here to heal.\n\nSessions  can handled in a number of different ways besides cookies. Take a look\nat the choices we have for storing session-based values in an instance of Flask:\n\nSESSION_TYPE\n Specifies which type of session interface to\nuse. Built-in session types:\n\n * null: NullSessionInterface (default)\n * redis: RedisSessionInterface\n * memcached: MemcachedSessionInterface\n * filesystem: FileSystemSessionInterface\n * mongodb: MongoDBSessionInterface\n * sqlalchemy: SqlAlchemySessionInterface\n\nSESSION_PERMANENT\n Whether use permanent session or not, default\nto be True\n SESSION_USE_SIGNER\n Whether sign the session cookie sid or not,\nif set to True, you have to set\n flask.Flask.secret_key\n[http://flask.pocoo.org/docs/api/#flask.Flask.secret_key], default to be\n False\n SESSION_KEY_PREFIX\n A prefix that is added before all session keys.\nThis makes it possible to use the same backend\nstorage server for different apps, default\n“session:”\n SESSION_REDIS\n A redis.Redis  instance, default connect to\n 127.0.0.1:6379\n SESSION_MEMCACHED\n A memcache.Client  instance, default connect\nto 127.0.0.1:11211\n SESSION_FILE_DIR\n The directory where session files are stored.\nDefault to use flask_session  directory under\ncurrent working directory.\n SESSION_FILE_THRESHOLD\n The maximum number of items the session stores\nbefore it starts deleting some, default 500\n SESSION_FILE_MODE\n The file mode wanted for the session files,\ndefault 0600\n SESSION_MONGODB\n A pymongo.MongoClient  instance, default\nconnect to 127.0.0.1:27017\n SESSION_MONGODB_DB\n The MongoDB database you want to use, default\n“flask_session”\n SESSION_MONGODB_COLLECT\n The MongoDB collection you want to use, default\n“sessions”\n SESSION_SQLALCHEMY\n A flask.ext.sqlalchemy.SQLAlchemy  instance\nwhose database connection URI is configured\nusing the SQLALCHEMY_DATABASE_URI  parameter\n SESSION_SQLALCHEMY_TABLE\n The name of the SQL table you want to use,\ndefault “sessions”\n Using Redis For Cached Session Information\nFor the sake of trying something different, I've opted to pick up a tiny Redis\ninstance from redislabs [https://redislabs.com/]. I can't help myself but\nwasting money on new services to play with; after all, check out how cool this\nlittle red box looks:\n\nRedis Enterprise: A Unique Primary Database\nPerfomance at Scale\n * 50M ops/sec,\n    Symmetric shared–nothing architecture ensures no performance overheads while\n   scaling, auto-sharding and re-balancing\n    Enhanced connection management, pipeline execution and request scheduling\n    \n\nBuilt-in high performance search\n * High performance, real-time indexing with items available for search within\n   1ms\n * Predictable high performance querying while maintaining concurrent loads of\n   indexing and querying\n * Highly scalable across multiple nodes to billions of items per second \n\nFailsafe high availability\n * Cross-rack/zone/datacenter/geo replication\n * Instant auto-failover in single digit second\n * Zero impact on throughput and latency during cluster operations such as\n   scaling, upgrades, re-sharding and rebalancing\n * Out-of-the box support for backup, restore and DR\n\nActive-active geo distribution\n * Reads/Writes in multiple geo regions to the same dataset\n * Local latencies, global availability\n * Built-in conflict resolution for simple and complex data types\n * Based on revolutionary CRDT academic research\n\nBuilt-in persistence\n * Enhanced storage engine for parallel access to any persistent storage\n * Multiple options for enhanced data persistence\n * Reliable persistence configurations on both master and slave shards with zero\n   performance impact\n\nMulti-model\n * Graph, JSON, Machine Learning and Bloom filter modules set industry standards\n   for high performance\n * Multi-shard coordination\n * Extensibility with custom modules\n\nIntelligent tiered access to memory\n * Up to 80% lower infrastructure costs by running Redis on Flash\n * Automatic management of data tiering between RAM & Flash with no code changes\n * Supports all new persistent memory technologies\n\nFlexible deployment options\n * Hybrid clusters can span on-prem infrastructure and multiple clouds\n * Most efficient use of resources with maximized core usage, multi-tenancy,\n   re-sharding and re-balancing to avoid noisy neighbors in every environment\n\nPerfomance at Scale\n Built-in persistence\n Failsafe high availability\n Active-active geo distribution\n Built-in high performance search\n Multi-model\n Intelligent tiered access to memory\n \n(RAM and Flash)\n Flexible deployment options\n \n(cloud, on-prem, hybrid)\n Fast\nPerformance at scale\n Built-in high performance search\n Reliable\nBuilt-in persistence\n Failsafe high availability\n Active-active geo distribution\n Flexible\nMulti-model\n Flexible deployment options (cloud, hybrid, on-prem)\n Intelligent tiered access to memory (ram and flash)\n (Why am I not getting paid for this? Why did I take the time to even make that\nmodule?)Redis  is NoSQL datastore written in C intended to temporarily hold data in\nmemory for users as they blaze mindlessly through your site. Other use cases\ninclude serving as the foundation for real-time chat apps via the\npublish/subscribe messaging paradigm; popular amongst stupid chat or dating apps\nslowly destroying our abilities as human beings to interact face-to-face.\nPowerful stuff.\n\nStructuring init.py Correctly\nConsider this to be the guide to Flask Application factories I wish I had months\nago. A healthy application factory should:\n\n * Derive all app configuration values from a class or environment variables.\n * Allow Database interactions to occur at any point within the app.\n * Pass values globally outside of the application context.\n\nThis does all of those things:\n\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_session import Session\nfrom flask_redis import FlaskRedis\n\n# Globally accessible libraries\ndb = SQLAlchemy()\nr = FlaskRedis()\n\n\ndef create_app():\n    \"\"\"Initialize the core application.\"\"\"\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n\n    with app.app_context():\n        # Set global session variables\n        r.set('endpoint', str(app.config['ENDPOINT']).encode('utf-8'))\n        r.set('post_query', str(app.config['POST_QUERY']).encode('utf-8'))\n        \n        # Initialize Global Libraries\n        redis_store.init_app(app)\n        db.init_app(app)\n\n        # Include our Routes\n        from . import routes\n\n        return app\n\n\nThe order of operations here is critical.\n\nBefore we do anything related to the app itself, we create instances of \nflask_sqlalchemy  and flask_redis. This will be initialized with our app once we\nactually have one created.\n\nThe first two lines of create_app()  should be no surprise: we're just creating\nour Flask app, and stating that it should be configured using a class called \nConfig  in a file named config.py.\n\napp = Flask(__name__, instance_relative_config=False)\napp.config.from_object('config.Config')\n\n\nMoving down the function comes the moment of truth: creating the app context. \nWhat happens in the app context stays in the app context... except for our sick\nnew Redis setup. By using the Redis .set()  method, we can assign key/value\npairs  for Redis hang on to, such as values from our app config which might be\nneeded elsewhere in our app: r.set('endpoint',\nstr(app.config['ENDPOINT']).encode('utf-8')).\n\nRedis stores information as bytes by default, thus attempting to pass values\nsuch as strings will result in the infamous `b'leading letter b'` phenomenon. Be\nsure to encode your values as utf-8 when using set(), and decode when using\nget().Making Redis Globally Available\nThe next part is important: we need to 'initialize' the services we want to use\nglobally (such as database access or Redis) by using init_app(). This must \nhappen inside the application context, with the parameter being app. This is our\nway of achieving singularity into inter-dimensional travel, thus breaking out of\nthe dreaded application context long after it dies.\n\nLet's Access Some Variables, Baby\nThe moment of truth: will this actually work? Or am I actually a filthy liar\nflooding the internet with more uselessly outdated Flask advice? Let's see:\n\n# routes.py\n\nfrom flask import current_app as app\nfrom flask import make_response\nimport json\nfrom . import models\nfrom . import r\n\nheaders = { 'Access-Control-Allow-Headers': 'Content-Type' }\n\n\n@app.route('/', methods=['GET', 'POST'])\ndef entry():\n    readers = models.Readers.query.filter_by(username='john').all()\n    print(readers)\n    print(r.get('uri').decode('utf-8'))\n    return make_response(str('readers'), 200, headers)\n\n\nEureka! This worthless entry-point prints two things: the value we assigned to\nour Redis block, and all records in our database of people named John:\n\n>> [<User john>]\n>> https://us1-hackersandslackers-543.cloudfunctions.net/link-endpoint?url=\n\n\nAs simple and stupid as it seems, developing an app to this point while\nunderstanding why it works  is a victory for any developer. I complain about\nthis nearly every post, but the fact of the matter is that the heroes who build\nmuch of today's technologies commonly fail to explain their own art in\nunderstandable terms. It's an understandable phenomenon resulting from isolated\nspurts of genius, perhaps, but it damages the growth of companies and humanity\nalike.\n\nSo I guess this is my calling: writing documentation for other people's\naccomplishments. \"Marginally less confusing than 4 open Stackoverflow tabs.\" \nThat's what I hope to have engraved on my gravestone.\n\nMerry Christmas.","html":"<p>A 'skill' that's always fascinated me is just how long some engineers can make it in their career while carrying glaringly obvious gaps in their knowledge of the systems they use every day. To my surprise, I've turned corners where I myself have been that engineer all along, and there's perhaps no better example of this then the time I've spent with Flask.</p><p><strong>WARNING! Highly opinionated statement incoming</strong>: Flask is everything a framework should be. That is to say, it <em>isn't really</em> a framework a fully-fledged framework at all. Sure, the term <em>microframework </em>might seem like a cute PR term, but that doesn't negate the fact that there's something about Flask that's different. When I write apps in <strong>Flask,</strong> I feel as though I'm writing apps in <strong>Python.</strong> On the other hand, when I write apps in <strong>Django,</strong> I feel like I'm just writing apps in <strong>Django.</strong> A disciplined programmer might feel that overly structured frameworks damper creativity and they're probably right: these are the backbones of businesses, thus it makes sense to keep people from deviating from the norm. </p><p>The upside of Flask is also its downside: there's nearly an infinite number of ways to solve a single problem. Every Stackoverflow regular has their own preference, and sometimes, just none of them seem... <em>right. </em>The problem is compounded by some of the phrasing coming from Flask's documentation itself. Flask touts the importance of structuring apps with factories and Blueprints, while simultaneously expressing the power behind the <strong><em>application context.</em></strong> What you'll notice over time is that in Flask's own examples, these two 'very important things' never both appear at the same time: that's because they're simply <em>incompatible with one another.</em> This is a highly understated contradiction of philosophies.</p><h2 id=\"communication-breakdown\">Communication Breakdown?</h2><p>Here's <a href=\"http://flask.pocoo.org/docs/1.0/patterns/appfactories/\">Flask's take on Application factories</a>:</p><blockquote>\n<p>If you are already using packages and blueprints for your application (Modular Applications with Blueprints) there are a couple of really nice ways to further improve the experience. A common pattern is creating the application object when the blueprint is imported.</p>\n</blockquote>\n<p>And here's their <a href=\"http://flask.pocoo.org/docs/1.0/appcontext/\">description of the Application context</a>:</p><blockquote>\n<p>The application context keeps track of the application-level data during a request, CLI command, or other activity. Rather than passing the application around to each function, the current_app and g proxies are accessed instead.</p>\n</blockquote>\n<p>Considering <code>g</code> is intended to stand for \"global\" it seems safe from the previous statements that setting attributes of <code>g</code> can be accessed globally within an application... but they can't. This is where we backpedal and get into messy territory:</p><blockquote>\n<p>However, importing the app instance within the modules in your project is prone to circular import issues. When using the app factory pattern or writing reusable blueprints or extensions there won’t be an app instance to import at all.</p>\n<p>Flask solves this issue with the application context. Rather than referring to an app directly, you use the the <strong>current_app</strong> proxy, which points to the application handling the current activity.</p>\n</blockquote>\n<p>Okay, fine. So if I instantiate an application factory with <code>app.app_context():</code> (which is the only sensible way to create a factory at all)  I should be able to register blueprints within that context, and reference the app context, correct?</p><p>I could be crazy but this <em>never seems to work</em> within blueprints. Whether they exist as peer modules or submodules, the words 'from application import current_app as app' always seems to result in the same \"missing application context\" error. Conveniently it seems, all working examples of the application context seem to be when the Flask developers opt to serve single-file app examples. This <a href=\"https://stackoverflow.com/questions/50233118/access-to-flask-global-variables-in-blueprint-apps\">stranger from Stackoverflow</a> clears things up a bit:</p><blockquote>\n<p>This happens because the data are lost when the context (with app.app_context()) ends (doc).<br>\nInside the context, everything is ok :</p>\n<pre><code class=\"language-python\">from flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n   print(g.my_db)\n\nthis prints 'database ok'\n</code></pre>\n<p>But outside, you cannot access the attribute:</p>\n<pre><code class=\"language-python\">from flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n\nprint(g.my_db)\n</code></pre>\n<p>this throws RuntimeError: Working outside of application context</p>\n<p>even if you create a new context:</p>\n<pre><code class=\"language-python\">from flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n\nwith app.app_context():\n   print(g.my_db)\n</code></pre>\n<p>this throws AttributeError: '_AppCtxGlobals' object has no attribute 'my_db'</p>\n</blockquote>\n<p>Alas, here I am. Doomed writing posts to fill in the blanks of documentation left behind by others. </p><h2 id=\"flask-sessions-the-real-slim-shady\">Flask Sessions: The REAL Slim Shady</h2><p><code>Flask-Session</code> is the MVP when it comes sharing temporary information across modularized parts of our program. In fact, it's a bit odd this isn't encouraged more-so than <code>g</code>. But whatever. We're here to heal.</p><p><strong>Sessions</strong> can handled in a number of different ways besides cookies. Take a look at the choices we have for storing session-based values in an instance of Flask:</p><style>\n    tr td:first-child{\n    text-align: left;\n    text-align: top;\n    }\n    \n    tr td:first-child {\n    text-align: left;\n    text-align: top;\n    font-weight: 500;\n    background: #646c82 !important;\n    color: white;\n    border-bottom: 1px solid #747d92;\n    max-width: 70px;\n}\n    \n    table td {\n        font-size:.9em;\n    }\n    \n    td {\n       text-align: left;\n        font-size:.9em;\n        \n    }\n   \n    \n    tr td:nth-of-type(2){\n        font-weight: 100;\n            padding: 20px;\n    }\n    @media (max-width: 800px) {\n        \n        tr td {\n    \t\tpadding: 10px 0;\n        }\n        \n        tbody {\n            margin-left: 0 !important;\n        }\n        \n      tr td:first-child {\n       width: 100%;\n       white-space: nowrap;\n    padding: 10px 0 !important;\n    text-overflow: ellipsis;\n          max-width: none;\n    }\n        \n        tr:first-child td{\n       \t    min-width: 300px;\n            max-width: -webkit-fill-available !important;\n        }\n        \n        th {\n            \n        }\n        \n        tr {\n            padding: 0px !important;\n            overflow-x: hidden;\n        }\n        \n        td {\n            line-height:1.5;\n        }\n        \n        td:nth-of-type(2) {\n            width: 100%;\n            padding: 20px !important;\n        }\n        \n        tr td:nth-of-type(2){\n        font-weight: 100;\n        padding: 15px !important;\n    \t}\n    }\n    \n        \n</style>\n\n<div class=\"tableContainer\">\n  <table>\n  <tbody valign=\"top\">\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_TYPE</span></td>\n      <td>\n        <p class=\"first\">Specifies which type of session interface to\n          use. Built-in session types:</p>\n        <ul class=\"last simple\">\n          <li><strong>null</strong>: NullSessionInterface (default)</li>\n          <li><strong>redis</strong>: RedisSessionInterface</li>\n          <li><strong>memcached</strong>: MemcachedSessionInterface</li>\n          <li><strong>filesystem</strong>: FileSystemSessionInterface</li>\n          <li><strong>mongodb</strong>: MongoDBSessionInterface</li>\n          <li><strong>sqlalchemy</strong>: SqlAlchemySessionInterface</li>\n        </ul>\n      </td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_PERMANENT</span></td>\n      <td>Whether use permanent session or not, default\n        to be <span class=\"pre\">True</span></td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_USE_SIGNER</span></td>\n      <td>Whether sign the session cookie sid or not,\n        if set to <span class=\"pre\">True</span>, you have to set\n        <a class=\"reference external\" href=\"http://flask.pocoo.org/docs/api/#flask.Flask.secret_key\" title=\"(in Flask v0.12-dev)\"><tt class=\"xref py py-attr docutils literal\"><span class=\"pre\">flask.Flask.secret_key</span></tt></a>, default to be\n        <span class=\"pre\">False</span></td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_KEY_PREFIX</span></td>\n      <td>A prefix that is added before all session keys.\n        This makes it possible to use the same backend\n        storage server for different apps, default\n        “session:”</td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_REDIS</span></td>\n      <td>A <span class=\"pre\">redis.Redis</span> instance, default connect to\n        <span class=\"pre\">127.0.0.1:6379</span></td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_MEMCACHED</span></td>\n      <td>A <span class=\"pre\">memcache.Client</span> instance, default connect\n        to <span class=\"pre\">127.0.0.1:11211</span></td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_FILE_DIR</span></td>\n      <td>The directory where session files are stored.\n        Default to use <cite>flask_session</cite> directory under\n        current working directory.</td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_FILE_THRESHOLD</span></td>\n      <td>The maximum number of items the session stores\n        before it starts deleting some, default 500</td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_FILE_MODE</span></td>\n      <td>The file mode wanted for the session files,\n        default 0600</td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_MONGODB</span></td>\n      <td>A <span class=\"pre\">pymongo.MongoClient</span> instance, default\n        connect to <span class=\"pre\">127.0.0.1:27017</span></td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_MONGODB_DB</span></td>\n      <td>The MongoDB database you want to use, default\n        “flask_session”</td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_MONGODB_COLLECT</span></td>\n      <td>The MongoDB collection you want to use, default\n        “sessions”</td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_SQLALCHEMY</span></td>\n      <td>A <span class=\"pre\">flask.ext.sqlalchemy.SQLAlchemy</span> instance\n        whose database connection URI is configured\n        using the <span class=\"pre\">SQLALCHEMY_DATABASE_URI</span> parameter</td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_SQLALCHEMY_TABLE</span></td>\n      <td>The name of the SQL table you want to use,\n        default “sessions”</td>\n    </tr>\n  </tbody>\n    </table>\n</div>\n<h3 id=\"using-redis-for-cached-session-information\">Using Redis For Cached Session Information</h3><p>For the sake of trying something different, I've opted to pick up a tiny Redis instance from <a href=\"https://redislabs.com/\"><strong>redislabs</strong></a>. I can't help myself but wasting money on new services to play with; after all, check out how cool this little red box looks:</p>\n<!-- Strengths -->\n<div id=\"unique\">\n  <!-- Headline -->\n  <h2>Redis Enterprise: A Unique Primary Database</h2>\n  <div class=\"item-scale item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-performance-reverse.svg\">\n    <h3>Perfomance at Scale</h3>\n    <ul>\n      <li>50M ops/sec,\n        <1ms 26=\"\" latency,=\"\" with=\"\" only=\"\" cloud=\"\" instances<=\"\" li=\"\"> <li>Symmetric shared–nothing architecture ensures no performance overheads while scaling, auto-sharding and re-balancing</li>\n      <li>Enhanced connection management, pipeline execution and request scheduling</li>\n    </1ms></li></ul>\n  </div>\n  <div class=\"item-search item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-search-reverse.svg\">\n    <h3>Built-in high performance search</h3>\n    <ul>\n      <li>High performance, real-time indexing with items available for search within 1ms</li>\n      <li>Predictable high performance querying while maintaining concurrent loads of indexing and querying</li>\n      <li>Highly scalable across multiple nodes to billions of items per second </li>\n    </ul>\n  </div>\n  <div class=\"item-fail item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-fail-reverse.svg\" class=\"popup-image\">\n    <h3>Failsafe high availability</h3>\n    <ul>\n      <li>Cross-rack/zone/datacenter/geo replication</li>\n      <li>Instant auto-failover in single digit second</li>\n      <li>Zero impact on throughput and latency during cluster operations such as scaling, upgrades, re-sharding and rebalancing</li>\n      <li>Out-of-the box support for backup, restore and DR</li>\n    </ul>\n  </div>\n  <div class=\"item-geo item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-geo-reverse.svg\" class=\"popup-image\">\n    <h3>Active-active geo distribution</h3>\n    <ul>\n      <li>Reads/Writes in multiple geo regions to the same dataset</li>\n      <li>Local latencies, global availability</li>\n      <li>Built-in conflict resolution for simple and complex data types</li>\n      <li>Based on revolutionary CRDT academic research</li>\n    </ul>\n  </div>\n  <div class=\"item-persist item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-persist-reverse.svg\" class=\"popup-image\">\n    <h3>Built-in persistence</h3>\n    <ul>\n      <li>Enhanced storage engine for parallel access to any persistent storage</li>\n      <li>Multiple options for enhanced data persistence</li>\n      <li>Reliable persistence configurations on both master and slave shards with zero performance impact</li>\n    </ul>\n  </div>\n  <div class=\"item-multi item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-multi-reverse.svg\" class=\"popup-image\">\n    <h3>Multi-model</h3>\n    <ul>\n      <li>Graph, JSON, Machine Learning and Bloom filter modules set industry standards for high performance</li>\n      <li>Multi-shard coordination</li>\n      <li>Extensibility with custom modules</li>\n    </ul>\n  </div>\n  <div class=\"item-tiered item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-tiered-reverse.svg\" class=\"popup-image\">\n    <h3>Intelligent tiered access to memory</h3>\n    <ul>\n      <li>Up to 80% lower infrastructure costs by running Redis on Flash</li>\n      <li>Automatic management of data tiering between RAM &amp; Flash with no code changes</li>\n      <li>Supports all new persistent memory technologies</li>\n    </ul>\n  </div>\n  <div class=\"item-deploy item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-deploy-reverse.svg\" class=\"popup-image\">\n    <h3>Flexible deployment options</h3>\n    <ul>\n      <li>Hybrid clusters can span on-prem infrastructure and multiple clouds</li>\n      <li>Most efficient use of resources with maximized core usage, multi-tenancy, re-sharding and re-balancing to avoid noisy neighbors in every environment</li>\n    </ul>\n  </div>\n  <!-- Categories -->\n  <!-- Desktop Grid -->\n  <div class=\"strengths\">\n    <!-- Grid - Row -->\n\n    <div class=\"main-flex\">\n      <div class=\"columns medium-4 left parent\">\n        <div class=\"columns feature item-fast scale\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Perfomance at Scale\n          </div>\n        </div>\n\n        <div class=\"columns feature item-durable persistence\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Built-in persistence\n          </div>\n        </div>\n\n        <div class=\"columns feature item-durable failsafe\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Failsafe high availability\n          </div>\n        </div>\n\n        <div class=\"columns feature item-durable geo\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Active-active geo distribution\n          </div>\n        </div>\n\n      </div>\n      <div class=\"columns medium-4 center parent\">\n        <div class=\"redis red-strengths\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/redis-e-logo.svg\" alt=\"Redis Labs\">\n        </div>\n      </div>\n      <div class=\"columns medium-4 right parent\">\n        <div class=\"columns feature right item-fast search\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Built-in high performance search\n          </div>\n        </div>\n\n        <div class=\"columns feature item-flex multi\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Multi-model\n          </div>\n        </div>\n\n        <div class=\"columns feature item-flex vert tiered\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Intelligent tiered access to memory\n            <br>(RAM and Flash)\n          </div>\n        </div>\n\n        <div class=\"columns feature item-flex vert deploy\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Flexible deployment options\n            <br>(cloud, on-prem, hybrid)\n          </div>\n        </div>\n\n\n      </div>\n\n    </div>\n\n    <!-- Grid - Redis Logo-->\n\n  </div>\n  <!-- End Desktop Grid -->\n\n\n\n  <div class=\"grid-container mobile-grid\">\n    <div class=\"redis-mobile red-strengths\">\n      <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/redis-e-logo.svg\" alt=\"Redis Labs\">\n    </div>\n    <!-- Column 1 -->\n    <div class=\"mobile-flex\">\n      <div class=\"columns small-12 medium-4\">\n        <h3>Fast</h3>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-performance.svg\">\n          <span class=\"text short\">\n            Performance at scale\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-search.svg\">\n          <span class=\"text med\">\n            Built-in high performance search\n          </span>\n        </div>\n      </div>\n      <!-- End Column 1 -->\n      <!-- Column 2 -->\n      <div class=\"columns small-12 medium-4\">\n        <h3>Reliable</h3>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-persist.svg\">\n          <span class=\"text short\">\n            Built-in persistence\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-fail.svg\">\n          <span class=\"text short med\">\n            Failsafe high availability\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-geo.svg\">\n          <span class=\"text med\">\n            Active-active geo distribution\n          </span>\n        </div>\n      </div>\n      <!-- End Column 2 -->\n      <!-- Column 3 -->\n      <div class=\"columns small-12 medium-4\">\n        <h3>Flexible</h3>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-multi.svg\">\n          <span class=\"text short\">\n            Multi-model\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-deploy.svg\">\n          <span class=\"text long\">\n            Flexible deployment options <span class=\"small\">(cloud, hybrid, on-prem)</span>\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-tiered.svg\">\n          <span class=\"text long\">\n            Intelligent tiered access to memory <span class=\"small\">(ram and flash)</span>\n          </span>\n        </div>\n      </div>\n    </div>\n    <!-- End Column 3 -->\n  </div>\n</div>\n<span style=\"color: #969696;\n    text-align: center;\n    display: block;\n    font-weight: 100;\n    font-style: italic;\n    margin-bottom: 30px;\n    font-size: .9em;\">(Why am I not getting paid for this? Why did I take the time to even make that module?)</span><p><strong>Redis</strong> is NoSQL datastore written in C intended to temporarily hold data in memory for users as they blaze mindlessly through your site. Other use cases include serving as the foundation for real-time chat apps via the publish/subscribe messaging paradigm; popular amongst stupid chat or dating apps slowly destroying our abilities as human beings to interact face-to-face. Powerful stuff.</p><h2 id=\"structuring-init-py-correctly\">Structuring <strong>init</strong>.py Correctly</h2><p>Consider this to be the guide to Flask Application factories I wish I had months ago. A healthy application factory should:</p><ul><li>Derive all app configuration values from a class or environment variables.</li><li>Allow Database interactions to occur at any point within the app.</li><li>Pass values globally outside of the application context.</li></ul><p>This does all of those things:</p><pre><code class=\"language-python\">from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_session import Session\nfrom flask_redis import FlaskRedis\n\n# Globally accessible libraries\ndb = SQLAlchemy()\nr = FlaskRedis()\n\n\ndef create_app():\n    &quot;&quot;&quot;Initialize the core application.&quot;&quot;&quot;\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n\n    with app.app_context():\n        # Set global session variables\n        r.set('endpoint', str(app.config['ENDPOINT']).encode('utf-8'))\n        r.set('post_query', str(app.config['POST_QUERY']).encode('utf-8'))\n        \n        # Initialize Global Libraries\n        redis_store.init_app(app)\n        db.init_app(app)\n\n        # Include our Routes\n        from . import routes\n\n        return app\n</code></pre>\n<p>The order of operations here is critical.</p><p>Before we do anything related to the app itself, we create instances of <code>flask_sqlalchemy</code> and <code>flask_redis</code>. This will be initialized with our app once we actually have one created.</p><p>The first two lines of <code>create_app()</code> should be no surprise: we're just creating our Flask app, and stating that it should be configured using a class called <strong>Config</strong> in a file named <strong>config.py.</strong></p><pre><code class=\"language-python\">app = Flask(__name__, instance_relative_config=False)\napp.config.from_object('config.Config')\n</code></pre>\n<p>Moving down the function comes the moment of truth: <strong>creating the app context.</strong> What happens in the app context stays in the app context... except for our sick new Redis setup. By using the Redis <code>.set()</code> method, we can assign <em>key/value pairs</em> for Redis hang on to, such as values from our app config which might be needed elsewhere in our app: <code>r.set('endpoint', str(app.config['ENDPOINT']).encode('utf-8'))</code>.</p><div class=\"protip\">\n    Redis stores information as bytes by default, thus attempting to pass values such as strings will result in the infamous `b'leading letter b'` phenomenon. Be sure to encode your values as utf-8 when using set(), and decode when using get().\n</div><h3 id=\"making-redis-globally-available\">Making Redis Globally Available</h3><p>The next part is important: we need to 'initialize' the services we want to use globally (such as database access or Redis) by using <code>init_app()</code>. This <em>must </em>happen inside the application context, with the parameter being <code>app</code>. This is our way of achieving singularity into inter-dimensional travel, thus breaking out of the dreaded application context long after it dies.</p><h2 id=\"let-s-access-some-variables-baby\">Let's Access Some Variables, Baby</h2><p>The moment of truth: will this actually work? Or am I actually a filthy liar flooding the internet with more uselessly outdated Flask advice? Let's see:</p><pre><code class=\"language-python\"># routes.py\n\nfrom flask import current_app as app\nfrom flask import make_response\nimport json\nfrom . import models\nfrom . import r\n\nheaders = { 'Access-Control-Allow-Headers': 'Content-Type' }\n\n\n@app.route('/', methods=['GET', 'POST'])\ndef entry():\n    readers = models.Readers.query.filter_by(username='john').all()\n    print(readers)\n    print(r.get('uri').decode('utf-8'))\n    return make_response(str('readers'), 200, headers)\n</code></pre>\n<p>Eureka! This worthless entry-point prints two things: the value we assigned to our Redis block, and all records in our database of people named John:</p><pre><code class=\"language-bash\">&gt;&gt; [&lt;User john&gt;]\n&gt;&gt; https://us1-hackersandslackers-543.cloudfunctions.net/link-endpoint?url=\n</code></pre>\n<p>As simple and stupid as it seems, developing an app to this point <em>while understanding why it works</em> is a victory for any developer. I complain about this nearly every post, but the fact of the matter is that the heroes who build much of today's technologies commonly fail to explain their own art in understandable terms. It's an understandable phenomenon resulting from isolated spurts of genius, perhaps, but it damages the growth of companies and humanity alike.</p><p>So I guess this is my calling: writing documentation for other people's accomplishments. <strong>\"Marginally less confusing than 4 open Stackoverflow tabs.\"</strong> That's what I hope to have engraved on my gravestone.</p><p>Merry Christmas.</p>","url":"https://hackersandslackers.com/demystifying-flasks-application-context/","uuid":"ede882df-a696-43ef-a392-9430d98a961e","page":false,"codeinjection_foot":"<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/autoNumeric.min.js\"></script>\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/underscore-min.js\"></script>\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/mustache.min.js\"></script>\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/owl.js\"></script>\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/jquery.counterup.min.js\"></script>\n\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/foundation.js\"></script>\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/docker.js\"></script>\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/jquery.fancybox.pack.js\"></script>\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/scripts.js\"></script>","codeinjection_head":"<link rel=\"stylesheet\" href=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/redislast2.css\">","comment_id":"5c192cdba632c8240cad3869"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673756","title":"Geocoding Raw Datasets for Mapbox","slug":"preparing-data-for-mapbox-geocoding","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/mapbox2_o-2@2x.jpg","excerpt":"Make sense of unstructured data with enough precision to put it on a map.","custom_excerpt":"Make sense of unstructured data with enough precision to put it on a map.","created_at_pretty":"10 December, 2018","published_at_pretty":"18 December, 2018","updated_at_pretty":"02 April, 2019","created_at":"2018-12-10T17:16:29.000-05:00","published_at":"2018-12-18T08:00:00.000-05:00","updated_at":"2019-04-01T20:27:23.000-04:00","meta_title":"Geocoding Raw Datasets for Mapbpox | Hackers and Slackers","meta_description":"Make sense of unstructured data with enough precision to put it on a map.","og_description":"Make sense of unstructured data with enough precision to put it on a map.","og_image":"https://hackersandslackers.com/content/images/2018/12/mapbox2_o-2@2x.jpg","og_title":"Geocoding Raw Datasets for Mapbpox | Hackers and Slackers","twitter_description":"Make sense of unstructured data with enough precision to put it on a map.","twitter_image":"https://hackersandslackers.com/content/images/2018/12/mapbox2_o-2@2x.jpg","twitter_title":"Geocoding Raw Datasets for Mapbpox | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Analysis","slug":"data-analysis","description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","feature_image":null,"meta_description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","meta_title":"Data Analysis | Hackers and Slackers","visibility":"public"},{"name":"#Mapping Data with Mapbox","slug":"mapping-data-with-mapbox","description":"A full exploration into Mapbox: the sweetheart of geovisualization amongst data scientists. Learn the core product or see why the API rivals Google Maps.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mapbox.jpg","meta_description":"A full exploration into Mapbox: the sweetheart of geovisualization amongst data scientists. Learn the core product or see why the API rivals Google Maps.","meta_title":"Mapping Data with Mapbox","visibility":"internal"}],"plaintext":"This wouldn't be a proper data blog unless we spend a vast majority of our time\ntalking about cleaning data. Chances are if you're pursuing analysis that's\ngroundbreaking (or worthwhile), we're probably starting with some ugly, untapped\ninformation. It turns out Mapbox has an API specifically for this purpose: the \nMapbox Geocoding API [https://www.mapbox.com/api-documentation/#geocoding].\n\nGeocoding  is a blanket term for turning vague information into specific\nLat/Long coordinates. How vague, you ask? The API covers:\n\n * Pinpointing exact location via street address.\n * Locating regions or cities by recognizable name (ie: Rio de Janeiro).\n * Locating cities by highly unspecific name (Geocoding for \"Springfield\" will\n   return results for 41 American cities)\n * Locating cities or venues by name within a given region (such as searching\n   for Ray's Pizza in NYC).\n\nWe can also use Geocoding to do the reverse of this, where passing in\ncoordinates will return location names. If you find this useful, I'm assuming\nyou're a spy.\n\nChipping Away at a Real Use Case\nIn a real-life example, I have two sets of data: one represents general places\nof residence for a particular sample group. The goal is to see how they interact\nwith the second dataset: a list of locations they will be traveling to. I'd love\nto go into more detail, but:\n\nI get one cliche meme per year.So how can we use the Mapbox Geocoding API to\nsystematically extract coordinates for thousands of addresses, from multiple\ndatasets? With Pandas, of course!\n\nI'm Just Happy to be Writing About Pandas Right Now\nPardon my excitement; I've been far overdue for posting anything Pandas-related.\nIt's been killing me on the inside.\n\nWe need to make sense of some vague data. As seen in our Citibike example\n[https://hackersandslackers.com/map-data-visualization-with-mapbox/], New York\nhas plenty of public datasets with information like Taxi pickup/dropoffs, public\ntransit, etc. These start and end points are typically too fluid to have\nLat/Long coordinates associated with them, so we'll add them in ourselves. Given\nthat we're about to pass hundreds or thousands of addresses and locations, we'll\nuse Pandas .apply()  to fill out the missing Lat/Long columns in our dataset. \n\nInstead of using Mapbox's Python SDK, I'll actually be using requests  to hit\nthe Mapbox REST API. For some reason, the Python SDK was a bit unpredictable on\nmy last run.*\n\n*UPDATE: the Python SDK \"wasn't working\" because I apparently don't know the\ndifference between longitude and latitude. Awesome, so I'm a moron.\n\nimport sys\nimport os\nimport pandas as pd\nimport requests\nimport json\n\n\nclass GeocodeAddresses:\n    \"\"\"Add missing lat/long information to exisiting dataset.\"\"\"\n\n    def __init__(self, address_data):\n        self.data = address_data\n        self.address_df = pd.read_csv(self.data)\n        self.complete_data = self.get_coords(self.address_df)\n\n\n    @classmethod\n    def get_coords(self, employee_address_df):\n        \"\"\"Fill Dataframe lat/long columns.\"\"\"\n\n        def fill_coords(row):\n            \"\"\"Create a route object by passing GeoJSON start/end objects.\"\"\"\n            base_url = 'https://api.mapbox.com/geocoding/v5/mapbox.places/'\n            address = str(row.home_address)\n            format = '.json'\n            endpoint = base_url + address + format\n            params = {\n                'access_token':  'pk.eyJ1IjNoYXJkd2VthisisreallolaXdyNHQ3OTUifQ.VTAUrmzD91Ppxr1AJww'\n            }\n            headers = {\n                'Content-Type': 'application/json'\n            }\n            r = requests.get(endpoint, params=params, headers=headers)\n            try:\n                Lat = r.json()['features'][0]['geometry']['coordinates'][0]\n                Long = r.json()['features'][0]['geometry']['coordinates'][1]\n                print(pd.Series([Lat, Long]))\n                return pd.Series([Lat, Long])\n            except IndexError:\n                pass\n\n        address_df[['Lat', 'Long']] = address_df.head(100).apply(fill_coords, axis=1)\n        address_df.to_csv('geocoded.csv')\n\n\nIn the above example, we're using .apply()  against an empty series (our\nLat/Long columns) as opposed to our entire Dataframe. When get_coords()  returns\ntwo values, these values will fill the empty columns on a per-row basis.\n\nFor the scope of this tutorial, we'll simply focus on getting these points\nplotted. Don't worry, this is only part 2 of our Mapbox series! Yes, an entire\nseries!\n\nTurning Your Datasets into Tilesets\nIn Mapbox terms, a Tileset  is essentially a layer of data we can overlay on top\nof our blank map. The map style  we created last time was really just the\naesthetic unpinning of all the interesting data we can pile on time.\n\nTilesets can be stacked on one another, thus giving us infinite possibilities of\nthe types of data we can communicate: especially when you consider that Mapbox\nsupports Heatmaps and topology - far more than just plotted points.\n\nFirst, we'll plot our origins. I've put together a dataset of completely\nfalsified names (with presumably real addresses?) to demonstrate how we'd plot\nthese points. Here's a sample of the garbage I'll be feeding into Mapbox:\n\naddressnamelonglat761 ST ANNS AVE NY NY 10451Royal Hiett40.754466-73.97945525\nCOLUMBUS CIR NY NY 10019Yolanda Antonio40.8201997-73.91103241145 LENOX RD NY NY\n11212Marguerita Autry40.7667595-73.98157042800 VICTORY BLVD NY NY 10314Alyse\nPeranio40.6597804-73.9183181750 LEXINGTON AVE NY NY 10022Sina Walberg40.6080557\n-74.153241829 BAY RIDGE AVE NY NY 11220Ignacia Frasher40.7625148-73.9685564550\nRIVERSIDE DR NY NY 10027Marta Haymond40.6386587-74.034633808 W END AVE NY NY\n10025Angie Tseng40.8159612-73.96031841-03 69 ST NY NY 11377Marcella Weinstock\n40.797233-73.971324550 PARK AVE NY NY 10016Filiberto Everett40.7444514\n-73.8956728739 BROOK AVE NY NY 10451Vernia Mcgregor40.7492656-73.9803386777 W\nEND AVE NY NY 10025Michelina Althoff40.8199675-73.9122757866 E 165 ST NY NY\n10459Dave Tauber40.7965956-73.9726135130 E 37 ST NY NY 10016Tandra Gowen\n40.8237011-73.8990202797 ST ANNS AVE NY NY 10451Toby Philbrick40.7482336\n-73.97856641 AARON LN NY NY 10309Aisha Grief40.82089-73.9109118641 LEXINGTON AVE\nNY NY 10022Tarah Sinkler40.5541368-74.21266534201 4 AVE NY NY 11232Coletta\nJeansonne40.7590297-73.97032191021 PARK AVE NY NY 10028Lorie Shriver40.650317\n-74.0081672127 RIVERSIDE DR NY NY 10024Antwan Fullilove40.7794132-73.95724755120\nBROADWAY NY NY 10034Normand Beerman40.7890613-73.98065697124 20 AVE NY NY 11204\nWes Nieman40.8714856-73.91303623506 BEDFORD AVE NY NY 11210Marlen Hutcherson\n40.6127972-73.9901551550 GRAND ST NY NY 10002Leonie Lablanc40.6168306-73.9501481\n1711 GROVE ST NY NY 11385Doris Herrman40.7143151-73.9800558785 W END AVE NY NY\n10025Cyndy Kossman40.7032053-73.91119426040 HUXLEY AVE NY NY 10471Donya Ponte\n40.796763-73.972483Head Over to Mapbox Studio\nWhile we can technically do everything programmatically, Mapbox's GUI is simply\ntoo easy to ignore. Using Mapbox Studio\n[https://www.mapbox.com/studio/datasets/], we can upload our data and turn it\ninto a tileset; the heart and soul of what makes our maps interesting. \n\nOnce you've uploaded your CSV (or JSON, or whatever) as a dataset, we can\nimmediately see what this information looks like on a map by previewing it as a\ntileset. Mapbox is surprisingly intelligent in that it can deduce lat/long\nvalues from poorly named or formatted columns (such as Lat/Long, \nLatitutde/Longitude, start_longitude_lol/start_latitude_lmao, etc). Mapbox gets\nit right most of the time.\n\nIf y'all went well you should see a cluster of points on a map - this is a\npreview of your Tileset. Think of this as a layer in Photoshop: we can stack\nthese layers of information atop one another continuously to make something\ngreater than the sum of its parts.\n\nIf all looks good, export your Tileset via the \"export\" button on the top right.\n\nUpload your dataset and click \"edit\"Switch Over to Your Map \"Style\"\nYou map 'style' is your blank canvas. Get in there and add a layer, and from\nthere select the Tileset you just created. Once your Tileset is loaded, you can\nstyle the points themselves and even label them with the data in your dataset as\nyou see fit:\n\nSo many colorful layers.Simply clicking around the preloaded Tilesets should\nstart giving you ideas of what's possible down the line. Just look at those\nhorrifically bright Miami Vice themed streets.\n\nFeel free to get creative with Mapbox's tools to clarify the visual story you're\ntrying to tell. I've distinguished points from others after adding a third data\nset: Every Starbucks in New York City.  Yes, those map pins have been replaced\nwith that terrifying Starbucks Logo Mermaid Sea-demon\n\nTake a look at that perfect grid of mocha frappa-whatevers and tell me these\nguys don't have a business strategy:\n\nGod that's an ugly map.For all it's worth, I'd like to sincerely apologize for\nblinding your eyes with classless use of gifs paired with the useless corporate\nmonstrosity of a map I've created. I have faith that you'll do better.\n\nNow that we've spent enough time covering the n00b stuff, it's time to take the\ngloves off. While Mapbox studio's GUI serves as an amazing crutch and way to\ncustomize the look of our data, we must not forget: we're programmers, God damn\nit! True magic lies in 1s and 0s, not WYSIWYG editors.\n\nUntil we start using Plot.ly Dash, that is.\n\n(Suddenly, thousands of fans erupt into a roaring cheer at the very mention of\nPlot.ly. It's about time.™)","html":"<p>This wouldn't be a proper data blog unless we spend a vast majority of our time talking about cleaning data. Chances are if you're pursuing analysis that's groundbreaking (or worthwhile), we're probably starting with some ugly, untapped information. It turns out Mapbox has an API specifically for this purpose: the <a href=\"https://www.mapbox.com/api-documentation/#geocoding\">Mapbox Geocoding API</a>.</p><p><strong>Geocoding</strong> is a blanket term for turning vague information into specific Lat/Long coordinates. How vague, you ask? The API covers:</p><ul><li>Pinpointing exact location via street address.</li><li>Locating regions or cities by recognizable name (ie: Rio de Janeiro).</li><li>Locating cities by highly unspecific name (Geocoding for \"Springfield\" will return results for 41 American cities)</li><li>Locating cities or venues by name within a given region (such as searching for Ray's Pizza in NYC).</li></ul><p>We can also use Geocoding to do the reverse of this, where passing in coordinates will return location names. If you find this useful, I'm assuming you're a spy.</p><h3 id=\"chipping-away-at-a-real-use-case\">Chipping Away at a Real Use Case</h3><p>In a real-life example, I have two sets of data: one represents general places of residence for a particular sample group. The goal is to see how they interact with the second dataset: a list of locations they will be traveling to. I'd love to go into more detail, but:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"http://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/tenor.gif\" class=\"kg-image\"><figcaption>I get one cliche meme per year.</figcaption></figure><!--kg-card-end: image--><p>So how can we use the Mapbox Geocoding API to systematically extract coordinates for thousands of addresses, from multiple datasets? With Pandas, of course!</p><h2 id=\"i-m-just-happy-to-be-writing-about-pandas-right-now\">I'm Just Happy to be Writing About Pandas Right Now</h2><p>Pardon my excitement; I've been far overdue for posting anything Pandas-related. It's been killing me on the inside.</p><p>We need to make sense of some vague data. As seen in <a href=\"https://hackersandslackers.com/map-data-visualization-with-mapbox/\">our Citibike example</a>, New York has plenty of public datasets with information like Taxi pickup/dropoffs, public transit, etc. These start and end points are typically too fluid to have Lat/Long coordinates associated with them, so we'll add them in ourselves. Given that we're about to pass hundreds or thousands of addresses and locations, we'll use Pandas <code>.apply()</code> to fill out the missing Lat/Long columns in our dataset. </p><p>Instead of using Mapbox's Python SDK, I'll actually be using <code>requests</code> to hit the Mapbox REST API. For some reason, the Python SDK was a bit unpredictable on my last run.<strong>*</strong></p><p><strong>*UPDATE: </strong>the Python SDK \"wasn't working\" because I apparently don't know the difference between longitude and latitude. Awesome, so I'm a moron.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import sys\nimport os\nimport pandas as pd\nimport requests\nimport json\n\n\nclass GeocodeAddresses:\n    &quot;&quot;&quot;Add missing lat/long information to exisiting dataset.&quot;&quot;&quot;\n\n    def __init__(self, address_data):\n        self.data = address_data\n        self.address_df = pd.read_csv(self.data)\n        self.complete_data = self.get_coords(self.address_df)\n\n\n    @classmethod\n    def get_coords(self, employee_address_df):\n        &quot;&quot;&quot;Fill Dataframe lat/long columns.&quot;&quot;&quot;\n\n        def fill_coords(row):\n            &quot;&quot;&quot;Create a route object by passing GeoJSON start/end objects.&quot;&quot;&quot;\n            base_url = 'https://api.mapbox.com/geocoding/v5/mapbox.places/'\n            address = str(row.home_address)\n            format = '.json'\n            endpoint = base_url + address + format\n            params = {\n                'access_token':  'pk.eyJ1IjNoYXJkd2VthisisreallolaXdyNHQ3OTUifQ.VTAUrmzD91Ppxr1AJww'\n            }\n            headers = {\n                'Content-Type': 'application/json'\n            }\n            r = requests.get(endpoint, params=params, headers=headers)\n            try:\n                Lat = r.json()['features'][0]['geometry']['coordinates'][0]\n                Long = r.json()['features'][0]['geometry']['coordinates'][1]\n                print(pd.Series([Lat, Long]))\n                return pd.Series([Lat, Long])\n            except IndexError:\n                pass\n\n        address_df[['Lat', 'Long']] = address_df.head(100).apply(fill_coords, axis=1)\n        address_df.to_csv('geocoded.csv')\n</code></pre>\n<!--kg-card-end: markdown--><p>In the above example, we're using <code>.apply()</code> against an empty series (our Lat/Long columns) as opposed to our entire Dataframe. When <code>get_coords()</code> returns two values, these values will fill the empty columns on a per-row basis.</p><p>For the scope of this tutorial, we'll simply focus on getting these points plotted. Don't worry, this is only part 2 of our Mapbox series! Yes, an entire series!</p><h2 id=\"turning-your-datasets-into-tilesets\">Turning Your Datasets into Tilesets</h2><p>In Mapbox terms, a <strong>Tileset</strong> is essentially a layer of data we can overlay on top of our blank map. The map <strong>style</strong> we created last time was really just the aesthetic unpinning of all the interesting data we can pile on time.</p><p>Tilesets can be stacked on one another, thus giving us infinite possibilities of the types of data we can communicate: especially when you consider that Mapbox supports Heatmaps and topology - far more than just plotted points.</p><p>First, we'll plot our origins. I've put together a dataset of completely falsified names (with presumably real addresses?) to demonstrate how we'd plot these points. Here's a sample of the garbage I'll be feeding into Mapbox:</p><!--kg-card-begin: html--><div class=\"tableContainer\">\n\t\t\t<table>\n\t\t\t\t<thead>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<th>address</th>\n\t\t\t\t\t\t<th>name</th>\n\t\t\t\t\t\t<th>long</th>\n\t\t\t\t\t\t<th>lat</th>\n\t\t\t\t\t</tr>\n\t\t\t\t</thead>\n\t\t\t\t<tbody>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>761 ST ANNS AVE NY NY 10451</td>\n\t\t\t\t\t\t<td>Royal Hiett</td>\n\t\t\t\t\t\t<td>40.754466</td>\n\t\t\t\t\t\t<td>-73.9794552</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>5 COLUMBUS CIR NY NY 10019</td>\n\t\t\t\t\t\t<td>Yolanda Antonio</td>\n\t\t\t\t\t\t<td>40.8201997</td>\n\t\t\t\t\t\t<td>-73.9110324</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>1145 LENOX RD NY NY 11212</td>\n\t\t\t\t\t\t<td>Marguerita Autry</td>\n\t\t\t\t\t\t<td>40.7667595</td>\n\t\t\t\t\t\t<td>-73.9815704</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>2800 VICTORY BLVD NY NY 10314</td>\n\t\t\t\t\t\t<td>Alyse Peranio</td>\n\t\t\t\t\t\t<td>40.6597804</td>\n\t\t\t\t\t\t<td>-73.9183181</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>750 LEXINGTON AVE NY NY 10022</td>\n\t\t\t\t\t\t<td>Sina Walberg</td>\n\t\t\t\t\t\t<td>40.6080557</td>\n\t\t\t\t\t\t<td>-74.1532418</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>29 BAY RIDGE AVE NY NY 11220</td>\n\t\t\t\t\t\t<td>Ignacia Frasher</td>\n\t\t\t\t\t\t<td>40.7625148</td>\n\t\t\t\t\t\t<td>-73.9685564</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>550 RIVERSIDE DR NY NY 10027</td>\n\t\t\t\t\t\t<td>Marta Haymond</td>\n\t\t\t\t\t\t<td>40.6386587</td>\n\t\t\t\t\t\t<td>-74.034633</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>808 W END AVE NY NY 10025</td>\n\t\t\t\t\t\t<td>Angie Tseng</td>\n\t\t\t\t\t\t<td>40.8159612</td>\n\t\t\t\t\t\t<td>-73.960318</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>41-03 69 ST NY NY 11377</td>\n\t\t\t\t\t\t<td>Marcella Weinstock</td>\n\t\t\t\t\t\t<td>40.797233</td>\n\t\t\t\t\t\t<td>-73.9713245</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>50 PARK AVE NY NY 10016</td>\n\t\t\t\t\t\t<td>Filiberto Everett</td>\n\t\t\t\t\t\t<td>40.7444514</td>\n\t\t\t\t\t\t<td>-73.8956728</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>739 BROOK AVE NY NY 10451</td>\n\t\t\t\t\t\t<td>Vernia Mcgregor</td>\n\t\t\t\t\t\t<td>40.7492656</td>\n\t\t\t\t\t\t<td>-73.9803386</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>777 W END AVE NY NY 10025</td>\n\t\t\t\t\t\t<td>Michelina Althoff</td>\n\t\t\t\t\t\t<td>40.8199675</td>\n\t\t\t\t\t\t<td>-73.9122757</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>866 E 165 ST NY NY 10459</td>\n\t\t\t\t\t\t<td>Dave Tauber</td>\n\t\t\t\t\t\t<td>40.7965956</td>\n\t\t\t\t\t\t<td>-73.9726135</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>130 E 37 ST NY NY 10016</td>\n\t\t\t\t\t\t<td>Tandra Gowen</td>\n\t\t\t\t\t\t<td>40.8237011</td>\n\t\t\t\t\t\t<td>-73.8990202</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>797 ST ANNS AVE NY NY 10451</td>\n\t\t\t\t\t\t<td>Toby Philbrick</td>\n\t\t\t\t\t\t<td>40.7482336</td>\n\t\t\t\t\t\t<td>-73.978566</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>41 AARON LN NY NY 10309</td>\n\t\t\t\t\t\t<td>Aisha Grief</td>\n\t\t\t\t\t\t<td>40.82089</td>\n\t\t\t\t\t\t<td>-73.9109118</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>641 LEXINGTON AVE NY NY 10022</td>\n\t\t\t\t\t\t<td>Tarah Sinkler</td>\n\t\t\t\t\t\t<td>40.5541368</td>\n\t\t\t\t\t\t<td>-74.2126653</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>4201 4 AVE NY NY 11232</td>\n\t\t\t\t\t\t<td>Coletta Jeansonne</td>\n\t\t\t\t\t\t<td>40.7590297</td>\n\t\t\t\t\t\t<td>-73.9703219</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>1021 PARK AVE NY NY 10028</td>\n\t\t\t\t\t\t<td>Lorie Shriver</td>\n\t\t\t\t\t\t<td>40.650317</td>\n\t\t\t\t\t\t<td>-74.0081672</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>127 RIVERSIDE DR NY NY 10024</td>\n\t\t\t\t\t\t<td>Antwan Fullilove</td>\n\t\t\t\t\t\t<td>40.7794132</td>\n\t\t\t\t\t\t<td>-73.9572475</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>5120 BROADWAY NY NY 10034</td>\n\t\t\t\t\t\t<td>Normand Beerman</td>\n\t\t\t\t\t\t<td>40.7890613</td>\n\t\t\t\t\t\t<td>-73.9806569</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>7124 20 AVE NY NY 11204</td>\n\t\t\t\t\t\t<td>Wes Nieman</td>\n\t\t\t\t\t\t<td>40.8714856</td>\n\t\t\t\t\t\t<td>-73.9130362</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>3506 BEDFORD AVE NY NY 11210</td>\n\t\t\t\t\t\t<td>Marlen Hutcherson</td>\n\t\t\t\t\t\t<td>40.6127972</td>\n\t\t\t\t\t\t<td>-73.9901551</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>550 GRAND ST NY NY 10002</td>\n\t\t\t\t\t\t<td>Leonie Lablanc</td>\n\t\t\t\t\t\t<td>40.6168306</td>\n\t\t\t\t\t\t<td>-73.9501481</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>1711 GROVE ST NY NY 11385</td>\n\t\t\t\t\t\t<td>Doris Herrman</td>\n\t\t\t\t\t\t<td>40.7143151</td>\n\t\t\t\t\t\t<td>-73.9800558</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>785 W END AVE NY NY 10025</td>\n\t\t\t\t\t\t<td>Cyndy Kossman</td>\n\t\t\t\t\t\t<td>40.7032053</td>\n\t\t\t\t\t\t<td>-73.9111942</td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td>6040 HUXLEY AVE NY NY 10471</td>\n\t\t\t\t\t\t<td>Donya Ponte</td>\n\t\t\t\t\t\t<td>40.796763</td>\n\t\t\t\t\t\t<td>-73.972483</td>\n\t\t\t\t\t</tr>\n\t\t\t\t</tbody>\n\t\t\t</table>\n</div><!--kg-card-end: html--><h3 id=\"head-over-to-mapbox-studio\">Head Over to Mapbox Studio</h3><p>While we can technically do everything programmatically, Mapbox's GUI is simply too easy to ignore. Using <a href=\"https://www.mapbox.com/studio/datasets/\">Mapbox Studio</a>, we can upload our data and turn it into a <em><strong>tileset; </strong></em>the heart and soul of what makes our maps interesting. </p><p>Once you've uploaded your CSV (or JSON, or whatever) as a dataset, we can immediately see what this information looks like on a map by previewing it as a tileset. Mapbox is surprisingly intelligent in that it can deduce lat/long values from poorly named or formatted columns (such as <em>Lat/Long</em>, <em>Latitutde/Longitude</em>, <em>start_longitude_lol/start_latitude_lmao</em>, etc). Mapbox gets it right most of the time.</p><p>If y'all went well you should see a cluster of points on a map - this is a preview of your Tileset. Think of this as a layer in Photoshop: we can stack these layers of information atop one another continuously to make something greater than the sum of its parts.</p><p>If all looks good, export your Tileset via the \"export\" button on the top right.</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"http://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/tileset.gif\" class=\"kg-image\"><figcaption>Upload your dataset and click \"edit\"</figcaption></figure><!--kg-card-end: image--><h3 id=\"switch-over-to-your-map-style\">Switch Over to Your Map \"Style\"</h3><p>You map 'style' is your blank canvas. Get in there and add a layer, and from there select the Tileset you just created. Once your Tileset is loaded, you can style the points themselves and even label them with the data in your dataset as you see fit:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"http://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/layers.gif\" class=\"kg-image\"><figcaption>So many colorful layers.</figcaption></figure><!--kg-card-end: image--><p>Simply clicking around the preloaded Tilesets should start giving you ideas of what's possible down the line. Just look at those horrifically bright Miami Vice themed streets.</p><p>Feel free to get creative with Mapbox's tools to clarify the visual story you're trying to tell. I've distinguished points from others after adding a third data set: <strong>Every Starbucks in New York City.</strong> Yes, those map pins have been replaced with that terrifying Starbucks Logo Mermaid Sea-demon</p><p>Take a look at that perfect grid of mocha frappa-whatevers and tell me these guys don't have a business strategy:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/mapstarbucks2.gif\" class=\"kg-image\"><figcaption>God that's an ugly map.</figcaption></figure><!--kg-card-end: image--><p>For all it's worth, I'd like to sincerely apologize for blinding your eyes with classless use of gifs paired with the useless corporate monstrosity of a map I've created. I have faith that you'll do better.</p><p>Now that we've spent enough time covering the n00b stuff, it's time to take the gloves off. While Mapbox studio's GUI serves as an amazing crutch and way to customize the look of our data, we must not forget: we're programmers, God damn it! True magic lies in 1s and 0s, not WYSIWYG editors.</p><p>Until we start using <strong>Plot.ly Dash</strong>, that is.</p><!--kg-card-begin: html--><span class=\"subtext\">(Suddenly, thousands of fans erupt into a roaring cheer at the very mention of Plot.ly. It's about time.™)</span><!--kg-card-end: html-->","url":"https://hackersandslackers.com/preparing-data-for-mapbox-geocoding/","uuid":"b2e24775-df44-464e-839a-be24e2a3eb42","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c0ee5bd8687896e154a9376"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673758","title":"Complex Features in MongoDB Cloud: Add Image Tags with AI","slug":"complex-features-in-mongodb-cloud","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/mongowebhooks@2x.jpg","excerpt":"Using functions, webhooks, and values to utilize external APIs.","custom_excerpt":"Using functions, webhooks, and values to utilize external APIs.","created_at_pretty":"12 December, 2018","published_at_pretty":"14 December, 2018","updated_at_pretty":"01 January, 2019","created_at":"2018-12-12T18:26:09.000-05:00","published_at":"2018-12-14T08:00:00.000-05:00","updated_at":"2019-01-01T09:36:10.000-05:00","meta_title":"Building Complex Features in MongoDB Cloud | Hackers and Slackers","meta_description":"Using functions, webhooks, and values to utilize external APIs. Today’s challenge: auto-tagging images using AI.","og_description":"Using functions, webhooks, and values to utilize external APIs. Today’s challenge: auto-tagging images using AI.","og_image":"https://hackersandslackers.com/content/images/2018/12/mongowebhooks@2x.jpg","og_title":"Complex Features in MongoDB Cloud: Add Image Tags with AI","twitter_description":"Using functions, webhooks, and values to utilize external APIs. Today’s challenge: auto-tagging images using AI.","twitter_image":"https://hackersandslackers.com/content/images/2018/12/mongowebhooks@2x.jpg","twitter_title":"Complex Features in MongoDB Cloud: Add Image Tags with AI","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"Friends, family, and most importantly, strangers: I approach you today with a\ntale of renewed inspiration. After loudly broadcasting my own confusion and\nmediocre ability to actually implement an effective cloud via MongoDB Stitch, my\nineptitude has been answered with an early Christmas gift. \n\nMy incessant complaining gained some acknowledgement from a couple of folks over\nat MongoDB. Perhaps the timing is simply by chance, but since then I've begun\nnoticing something some subtleties in the Stitch documentation; namely that if\nyou look hard enough, some of it begins to make sense. Either way, I'm chalking\nthis one up as a Christmas Miracle.\n\nLet's Automate Stuff: More Webhooks, Less Labor\nTo demonstrate what building an end-to-end sexy feature looks like in MongoDB\nStitch, I'm going to borrow some help from some old friends: the team behind \nClarifai. \n\nClarifai is one of the early players in the field of what I'm sure we'll\ncreatively refer to as AI as a service. More specifically, they provide an API\nfor image recognition which returns impressive metadata simply by passing an\nimage URL. Best part is, unless you're abusing the shit out of 5000 requests per\nmonth, the API is essentially free:\n\nPredict\n Search\n Custom Model Training\n Add or Edit Input Images\n 5,000  free operations\n 5,000  free operations\n 5,000  free operations\n 5,000  free operations\n Pre-Built Models: \n$1.20 / 1,000  operations\n\nCustom Models:\n$3.20 / 1,000  operations\n$1.20 / 1,000  operations\n $1.20 / 1,000  operations\n $1.20 / 1,000  operations\n If we were to try to fit any more instances of the words \"AI\" and \"Cloud\" into\nthis post, things could quickly derail into a shitty  IBM Watson commercial.\n\n(PS: Blockchain.)\n\nStoring Our Clarifai API Key\nIf you're following along, hit up Clarifai [https://clarifai.com/]  to grab your\nAPI key, no strings attached.\n\nAnd no, nobody is paying me to me to write about their SaaS products.Copy and\npaste your brand new key and head over to the MongoDB Stitch Console\n[https://stitch.mongodb.com]. In our Stitch project, we're going to store our\nkey as a value (you might recall this as being a convenient way to store\nsecrets).\n\nCopy and paste your key as a string in a new value. The only catch is we'll be\nformatting our key as Key #####################, simply because this is the\nformat the API expects to receive when we pass our key as a header to the\nClarifai API.\n\nWarning: Mild Architecting Ahead\nBefore going too far into code, let's recap how this functionality will probably\nwork.\n\nIn our actual application, we'll be identifying images needing alt  tags (either\nvia frontend or backend logic). At that point, we should find the src  attribute\nof said <img>  tags and pass it to a Stitch function; preferably one that makes\na post request to Clarifai. \n\nThis is in fact too simple to be true, as there is one gotcha: Stitch functions \ncannot make http requests on their own. They can,  however, invoke Stitch \nWebhooks. These webhooks share nearly identical syntax and structure to \nfunctions, with a few exceptions:\n\n * Webhooks have endpoints (duh).\n * They have explicit inbound/outbound rules restricting what can invoke them.\n * There are options to set authorization via key or otherwise.\n\nWith all that in mind, our end-to-end flow will end up looking something like\nthis:\n\n 1. Our application identifies an image needing tags an invokes a serverless \n    function.\n 2. The function  constructs the body of the request we'll be making to Clarifai \n     with containing the URL of the image.\n 3. As crazy as it sounds, we then POST to a Stitch endpoint, which in turns\n    makes the actual  POST request to Clarifai. The request is made with the\n    body passed from our function, as well as the API key we stored earlier.\n 4. We'll receive a response of tags which we can do something with on the\n    application-side.\n\nWriting our Function\nWe'll start by writing a simple function as our go-between for our app and our\nservice:\n\nexports = function(img){\n   const http = context.services.get(\"GetClarifaiTags\");\n   var data = {\n        \"inputs\": [\n          {\n            \"data\": {\n              \"image\": {\n                \"url\": img\n              }\n            }\n          }\n        ]\n      };\n      \n    var header_data = {\"Content-Type\": [ \"application/json\" ]};\n   \n    return http.post({\n        url: \"https://webhooks.mongodb-stitch.com/api/client/v2.0/app/hackers-uangn/service/GetClarifaiTags/incoming_webhook/GetTagsForNewImage\",\n        headers: header_data,\n        body: JSON.stringify(data)\n      })\n      .then(response => {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n\n\nThe first thing we do is reference our webhook (which we haven't created yet)\nwith this line:\n\nconst http = context.services.get(\"GetClarifaiTags\");\n\n\nIn the context of a function, context.services.get()  allows us to reference and\ninteract with other services we've created in Stitch. It's important to note\nthat we pass the user-created name of service we want to interact with. This is\none of the reasons why Stitch's documentation is so confusing - they\nconsistently use \"http\"  as an example service name. This seems to imply that\nwe'd want to import a type  of service as opposed to an instance  of a service,\nwhich is wrong.  \n\ndata  is the body of our request, which abides by Clarifai's documentation on\nhow to user their predict API. We need to pass this as a string to our webhook,\nthus we use JSON.stringify(data).\n\nIt's also important to note the structure of Mongo's headers when making\nrequests; notice that the value of each key pair is a list, as exemplified by \n\"Content-Type\": [ \"application/json\" ].\n\nAs you might imagine, these things in combination can cause a whole lot of\nconfusion. Hopefully you know a good blog to point these things out to you\nbeforehand.\n\nCreate a Webhook via 'HTTP Services'\nMove into the \"Services\" tab to create our webhook. Select HTTP  from the list\nof options:\n\nKind of a weird mix of services imho.Set your webhook to be a POST request.\nAuthentication shouldn't be a problem for us since we're only exposing this hook\nto our function, plus there are other ways to handle this.\n\nTIP: Don't post screenshots of sensitive endpoint URLs on the internet.The\nsyntax and methods available for writing a webhook are almost exactly the same\nas when writing regular functions. The one thing to note would be the presence\nof payload  being passed into the function; this object contains both the\nparameters and the body of requests being received by this endpoint. \npayload.body  gives us the body, whereas payload.query.arg  will give us the\nparameters.\n\nexports = function(payload){\n  const http = context.services.get(\"GetClarifaiTags\");\n  const token = context.values.get(\"clarifai_key\");\n  \n  var data = {};\n  if (payload.body) {\n    data = payload.body;\n  }\n  var header_data = {\n    \"Authorization\": [token], \n    \"Content-Type\": [\"application/json\"]\n  };\n\n    return http.post({\n        url: \"https://api.clarifai.com/v2/models/aaa03c23b3724a16a56b629203edc62c/versions/aa7f35c01e0642fda5cf400f543e7c40/outputs\",\n        body: data,\n        headers: header_data\n      })\n      .then(response => {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n\n\nJust as we can access services within functions, we can similarly access values\nvia context.values.get(\"myValue\").\n\nNow that we have both the body and our API key ready, we can actually go ahead\nand construct a valid request to Clarifai. The syntax should be\nself-explanatory, but here's the Stitch http service documentation\n[https://docs.mongodb.com/stitch/services/http-actions/http.post/]  just in\ncase.\n\nWhy Did we Have to Make a Weird Webhook which is both Receiving and Posting\nInformation?\nThis is an excellent question and served to be a huge source of confusion for\nwhat must have been months. Go back to the \"Services\" tab, and pay close\nattention: for each service we create, a set of Rules  are automatically created\nand attached to our service. HTTP services have all functionality disabled room\ndefault, with little to no mention of the existence of rules in the first place. \n This is important for two reasons:\n\n 1. It's a silly UI hiccup that can waste the majority of your waking life.\n 2. This means that only  services can do things like post to external APIs.\n    This is why we didn't simply keep our logic in one function.\n\nOur Workflow in Practice\nAssuming you've added some logic to your app to pick out image URLs needing\ntags, our chain of events should be complete and return results to our\napplication. The POST request we make will return a response to the POST request\nof our function, and our function will return the results to our application.\nWe've successfully created a complex, albeit confusing, cloud architecture or\nexternal services.\n\nThis is where your imagination should hopefully kick in. You'll notice I have a\nfew services such as the endpoints which receive updates every time a JIRA issue\nis created or updated. This is what powers our public-facing kanban board.\n[https://hackersandslackers.com/projects/]","html":"<p>Friends, family, and most importantly, strangers: I approach you today with a tale of renewed inspiration. After loudly broadcasting my own confusion and mediocre ability to actually implement an effective cloud via MongoDB Stitch, my ineptitude has been answered with an early Christmas gift. </p><p>My incessant complaining gained some acknowledgement from a couple of folks over at MongoDB. Perhaps the timing is simply by chance, but since then I've begun noticing something some subtleties in the Stitch documentation; namely that if you look hard enough, some of it begins to make sense. Either way, I'm chalking this one up as a Christmas Miracle.</p><h2 id=\"let-s-automate-stuff-more-webhooks-less-labor\">Let's Automate Stuff: More Webhooks, Less Labor</h2><p>To demonstrate what building an end-to-end sexy feature looks like in MongoDB Stitch, I'm going to borrow some help from some old friends: the team behind <strong>Clarifai</strong>. </p><p>Clarifai is one of the early players in the field of what I'm sure we'll creatively refer to as <em>AI as a service. </em>More specifically, they provide an API for image recognition which returns impressive metadata simply by passing an image URL. Best part is, unless you're abusing the shit out of 5000 requests per month, the API is essentially free:</p><style>\n    table td {\n        text-align:left;\n        font-size: .95em;\n    }\n</style>\n\n<div class=\"tableContainer\">\n  <table>\n    <thead>\n      <th>Predict</th>\n      <th>Search</th>\n      <th>Custom Model Training</th>\n      <th>Add or Edit Input Images</th>\n    </thead>\n    <tbody>\n      <tr>\n        <td><strong>5,000</strong> free operations</td>\n        <td><strong>5,000</strong> free operations</td>\n        <td><strong>5,000</strong> free operations</td>\n        <td><strong>5,000</strong> free operations</td>\n      </tr>\n      <tr>\n        <td>\n          <strong>Pre-Built Models: </strong><br>\n          <small><strong>$1.20 / 1,000</strong> operations</small><br><br>\n          <strong>Custom Models:</strong><br>\n          <small><strong>$3.20 / 1,000</strong> operations</small><br>\n        </td>\n        <td><strong>$1.20 / 1,000</strong> operations</td>\n        <td><strong>$1.20 / 1,000</strong> operations</td>\n        <td><strong>$1.20 / 1,000</strong> operations</td>\n      </tr>\n    </tbody>\n  </table>\n</div>\n<p>If we were to try to fit any more instances of the words \"AI\" and \"Cloud\" into this post, things could quickly derail into a shitty  IBM Watson commercial.</p><p><em>(PS: Blockchain.)</em></p><h2 id=\"storing-our-clarifai-api-key\">Storing Our Clarifai API Key</h2><p>If you're following along, hit up <a href=\"https://clarifai.com/\">Clarifai</a> to grab your API key, no strings attached.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/clarifaiapi_o.png\" class=\"kg-image\"><figcaption>And no, nobody is paying me to me to write about their SaaS products.</figcaption></figure><p>Copy and paste your brand new key and head over to the <a href=\"https://stitch.mongodb.com\">MongoDB Stitch Console</a>. In our Stitch project, we're going to store our key as a <strong>value </strong>(you might recall this as being a convenient way to store secrets).</p><p>Copy and paste your key as a string in a new value. The only catch is we'll be formatting our key as <code>Key #####################</code>, simply because this is the format the API expects to receive when we pass our key as a header to the Clarifai API.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/mongovalues_o-1.png\" class=\"kg-image\"></figure><h2 id=\"warning-mild-architecting-ahead\">Warning: Mild Architecting Ahead</h2><p>Before going too far into code, let's recap how this functionality will probably work.</p><p>In our actual application, we'll be identifying images needing <code>alt</code> tags (either via frontend or backend logic). At that point, we should find the <code>src</code> attribute of said <code>&lt;img&gt;</code> tags and pass it to a Stitch function; preferably one that makes a post request to <strong>Clarifai</strong>. </p><p>This is in fact too simple to be true, as there is one gotcha: Stitch <strong>functions</strong> cannot make http requests on their own. They <em>can,</em> however, invoke Stitch <strong>Webhooks. </strong>These webhooks share nearly identical syntax and structure to <strong>functions</strong>, with a few exceptions:</p><ul><li>Webhooks have endpoints (duh).</li><li>They have explicit inbound/outbound rules restricting what can invoke them.</li><li>There are options to set authorization via key or otherwise.</li></ul><p>With all that in mind, our end-to-end flow will end up looking something like this:</p><ol><li>Our application identifies an image needing tags an invokes a serverless <strong>function.</strong></li><li>The <strong>function</strong> constructs the body of the request we'll be making to <strong>Clarifai</strong> with containing the URL of the image.</li><li>As crazy as it sounds, we then POST to a Stitch endpoint, which in turns makes the <em>actual</em> POST request to Clarifai. The request is made with the body passed from our function, as well as the API key we stored earlier.</li><li>We'll receive a response of tags which we can do something with on the application-side.</li></ol><h2 id=\"writing-our-function\">Writing our Function</h2><p>We'll start by writing a simple function as our go-between for our app and our service:</p><pre><code class=\"language-javascript\">exports = function(img){\n   const http = context.services.get(&quot;GetClarifaiTags&quot;);\n   var data = {\n        &quot;inputs&quot;: [\n          {\n            &quot;data&quot;: {\n              &quot;image&quot;: {\n                &quot;url&quot;: img\n              }\n            }\n          }\n        ]\n      };\n      \n    var header_data = {&quot;Content-Type&quot;: [ &quot;application/json&quot; ]};\n   \n    return http.post({\n        url: &quot;https://webhooks.mongodb-stitch.com/api/client/v2.0/app/hackers-uangn/service/GetClarifaiTags/incoming_webhook/GetTagsForNewImage&quot;,\n        headers: header_data,\n        body: JSON.stringify(data)\n      })\n      .then(response =&gt; {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n</code></pre>\n<p>The first thing we do is reference our webhook (which we haven't created yet) with this line:</p><pre><code class=\"language-javascript\">const http = context.services.get(&quot;GetClarifaiTags&quot;);\n</code></pre>\n<p>In the context of a function, <code>context.services.get()</code> allows us to reference and interact with other services we've created in Stitch. It's important to note that we pass <strong>the user-created name of service </strong>we want to interact with. This is one of the reasons why Stitch's documentation is so confusing - they consistently use <em>\"http\"</em> as an example service name. This seems to imply that we'd want to import a <em>type</em> of service as opposed to an <em>instance</em> of a service, which is <strong>wrong.</strong> </p><p><code>data</code> is the body of our request, which abides by <a href=\"https://clarifai.com/developer/guide/predict#predict\">Clarifai's documentation on how to user their <em>predict</em> API</a>. We need to pass this as a string to our webhook, thus we use <code>JSON.stringify(data)</code>.</p><p>It's also important to note the structure of Mongo's headers when making requests; notice that the value of each key pair is a <strong>list, </strong>as exemplified by <code>\"Content-Type\": [ \"application/json\" ]</code>.</p><p>As you might imagine, these things in combination can cause a whole lot of confusion. Hopefully you know a good blog to point these things out to you beforehand.</p><h2 id=\"create-a-webhook-via-http-services-\">Create a Webhook via 'HTTP Services'</h2><p>Move into the \"Services\" tab to create our webhook. Select <strong>HTTP</strong> from the list of options:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/mongoservices.png\" class=\"kg-image\"><figcaption>Kind of a weird mix of services imho.</figcaption></figure><p>Set your webhook to be a POST request. Authentication shouldn't be a problem for us since we're only exposing this hook to our function, plus there are other ways to handle this.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-12-13-at-4.23.27-PM_o.png\" class=\"kg-image\"><figcaption>TIP: Don't post screenshots of sensitive endpoint URLs on the internet.</figcaption></figure><p>The syntax and methods available for writing a webhook are almost exactly the same as when writing regular functions. The one thing to note would be the presence of <strong>payload</strong> being passed into the function; this object contains <em><strong>both the parameters and the body </strong></em>of requests being received by this endpoint. <code>payload.body</code> gives us the body, whereas <code>payload.query.arg</code> will give us the parameters.</p><pre><code class=\"language-javascript\">exports = function(payload){\n  const http = context.services.get(&quot;GetClarifaiTags&quot;);\n  const token = context.values.get(&quot;clarifai_key&quot;);\n  \n  var data = {};\n  if (payload.body) {\n    data = payload.body;\n  }\n  var header_data = {\n    &quot;Authorization&quot;: [token], \n    &quot;Content-Type&quot;: [&quot;application/json&quot;]\n  };\n\n    return http.post({\n        url: &quot;https://api.clarifai.com/v2/models/aaa03c23b3724a16a56b629203edc62c/versions/aa7f35c01e0642fda5cf400f543e7c40/outputs&quot;,\n        body: data,\n        headers: header_data\n      })\n      .then(response =&gt; {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n</code></pre>\n<p>Just as we can access services within functions, we can similarly access values via <code>context.values.get(\"myValue\")</code>.</p><p>Now that we have both the body and our API key ready, we can actually go ahead and construct a valid request to Clarifai. The syntax should be self-explanatory, but here's the <a href=\"https://docs.mongodb.com/stitch/services/http-actions/http.post/\">Stitch http service documentation</a> just in case.</p><h3 id=\"why-did-we-have-to-make-a-weird-webhook-which-is-both-receiving-and-posting-information\">Why Did we Have to Make a Weird Webhook which is both Receiving and Posting Information?</h3><p>This is an excellent question and served to be a huge source of confusion for what must have been months. Go back to the \"Services\" tab, and pay close attention: for each service we create, a set of <strong>Rules</strong> are automatically created and attached to our service. <strong>HTTP services have all functionality disabled room default, with little to no mention of the existence of rules in the first place.</strong> This is important for two reasons:</p><ol><li>It's a silly UI hiccup that can waste the majority of your waking life.</li><li>This means that <em>only</em> services can do things like post to external APIs. This is why we didn't simply keep our logic in one function.</li></ol><h2 id=\"our-workflow-in-practice\">Our Workflow in Practice</h2><p>Assuming you've added some logic to your app to pick out image URLs needing tags, our chain of events should be complete and return results to our application. The POST request we make will return a response to the POST request of our function, and our function will return the results to our application. We've successfully created a complex, albeit confusing, cloud architecture or external services.</p><p>This is where your imagination should hopefully kick in. You'll notice I have a few services such as the endpoints which receive updates every time a <strong>JIRA </strong>issue is created or updated. This is what powers our <a href=\"https://hackersandslackers.com/projects/\">public-facing kanban board.</a></p>","url":"https://hackersandslackers.com/complex-features-in-mongodb-cloud/","uuid":"91acc3b3-88c2-4313-aedd-adf1eac1dc36","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c1199114b9896120b3c1b34"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673743","title":"Geographic Data Visualization with Mapbox","slug":"map-data-visualization-with-mapbox","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/mapbox@2x.jpg","excerpt":"Visualizing Geodata with Mapbox's API and Tools.","custom_excerpt":"Visualizing Geodata with Mapbox's API and Tools.","created_at_pretty":"07 December, 2018","published_at_pretty":"11 December, 2018","updated_at_pretty":"31 January, 2019","created_at":"2018-12-07T12:36:58.000-05:00","published_at":"2018-12-11T08:00:00.000-05:00","updated_at":"2019-01-31T17:52:32.000-05:00","meta_title":"Geographical Data Visualization with Mapbox | Hackers and Slackers","meta_description":"A collection of Map APIs that rivals Google Maps, plus Beautiful GeoData Visualization.","og_description":"A collection of Map APIs that rivals Google Maps, plus Beautiful GeoData Visualization.","og_image":"https://hackersandslackers.com/content/images/2018/12/mapbox@2x.jpg","og_title":"Geographic Data Visualization with Mapbox","twitter_description":"A collection of Map APIs that rivals Google Maps, plus Beautiful GeoData Visualization.","twitter_image":"https://hackersandslackers.com/content/images/2018/12/mapbox@2x.jpg","twitter_title":"Geographic Data Visualization with Mapbox","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"SaaS Products","slug":"saas","description":"Third-party products and services we’ve discovered to be diamonds in the rough. These are products we’ve included in our stack based on price and value add.","feature_image":null,"meta_description":"Third-party products and services we’ve discovered to be diamonds in the rough. These are products we’ve included in our stack based on price and value add.","meta_title":"Our Picks: SaaS Products | Hackers and Slackers","visibility":"public"},{"name":"#Mapping Data with Mapbox","slug":"mapping-data-with-mapbox","description":"A full exploration into Mapbox: the sweetheart of geovisualization amongst data scientists. Learn the core product or see why the API rivals Google Maps.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mapbox.jpg","meta_description":"A full exploration into Mapbox: the sweetheart of geovisualization amongst data scientists. Learn the core product or see why the API rivals Google Maps.","meta_title":"Mapping Data with Mapbox","visibility":"internal"}],"plaintext":"There's a trend among those using Jupyter Notebooks (or equivalent) which leads\nme to believe humanity is coming to an important realization: Google Maps,  as\nan API is expensive.\n\nRegardless if Google maps is embedded as a consumer-facing widget, or part of a\nroutine data-pipeline, a single surge of high-traffic can leave enterprises with\nprice tags in the hundreds of thousands of dollars. In fact, I can hardly\nremember a product where this hadn't  become the case. One can hardly blame the\nsearch engine; after all, our tendency to ignore the Terms and Service\nagreements (as well as payment policies) has always been core to the Google\nbusiness model.  Even then, there are enough enterprises to go around to turn a\nblind eye and actually pay such a bill willingly without exploring alternatives.\n\nData Scientists in particular have no excuse for inaction when it comes to\nseeking a better alternative. As it turns out, there is  one, and it is Cheaper,\n Easier, and perhaps more Fully Featured  than its Google Maps counterpart. That\nproduct is Mapbox. \n\nMapbox  is much more than a Google API clone. The web product offers a plethora\nof UI-driven features that we can use to customize maps as well as save or\neffortlessly transform raw data into workable GeoJSON data without even touching\nan API (which, mind you, there is.... with SDKs in every conceivable language).\nWe're going to create a quick map visualization incorporating some real data to\nget introduced to Mapbox's functionality, but this is only the beginning.\nDownload the line we'll see just how easy it is to incorporate Mapbox in\nproducts like Plot.ly Dash  or even Jupyter Notebooks.\n\nX Marks the Spot\nBefore straying from reigning champion Google Maps, it's worth exploring the\nsignificance of the metric that brought us here first: price.\n\nMurphy's law clearly states \"Cash Rules Everything Around Me, C.R.E.A.M; get the\nmoney, Dolla dolla bill y'all.\"  Given this reality, a minimum requirement for\nMapbox should be it's pricing model when compared to Google's.\n\nMapbox Pricing Tiers\nPrice\n Web apps\n Mobile SDKs\n Free to Start\n\n$0\n\n50,000  map views /mo\n\n50,000  Geocoding requests /mo\n\n50,000  Directions requests /mo\n\n50,000  Matrix elements /mo\n\n50,000  Tilequery requests /mo\n\n50,000  map views /mo\n\n50,000  Geocoding requests /mo\n\n50,000  Directions requests /mo\n\n50,000  Matrix elements /mo\n\n50,000  Tilequery requests /mo\n\nAdditional Usage\n\n$0.50\n\n50,000  map views /mo\n\n50,000  Geocoding requests /mo\n\n50,000  Directions requests /mo\n\n50,000  Matrix elements /mo\n\n50,000  Tilequery requests /mo\n\n50,000  map views /mo\n\n50,000  Geocoding requests /mo\n\n50,000  Directions requests /mo\n\n50,000  Matrix elements /mo\n\n50,000  Tilequery requests /mo\n\nCompare this to Google's transparent pricing structure:\n\nGoogle API Pricing Tiers\nPrice\n Web apps\n Mobile SDKs\n Starter Pack\n\nBrown Paper Bag full of $20s\n\n5  and a half map views /mo\n\n11  times thinking about the API /mo\n\n6  verbal mentions of \"Google\" /mo\n\n2  directions to shitty parties /mo\n\n8  visits to anywhere /mo\n\n9  Android unlocks /mo\n\n12  Google queries for restaurants /mo\n\n3  \"OK Google\" queries /mo\n\n7  Accidental app opens /mo\n\n1  Creating the next \"Uber for X\" /mo\n\nAdditional Usage\n\nEleventy Billion Dollars\n\nUnlimited Requests!* \n\n*See Pricing \n\nUnlimited Requests!*\n\n*See Pricing\n\nSeems like a convincing point in the win column for Mapbox. If we stay within\nreason, Mapbox can essentially serve us as an entirely free service.\n\nSurely we must be missing something  since we're opting for free services\nthough, right? How do Mapbox visualizations stack up against Google Maps?\n\n\n[https://codepen.io/ro-ka/pen/ENoOjz/]  [https://codepen.io/ro-ka] \n[https://codepen.io]\n\nPardon my French here, but hot damn that map is dope.  There are plenty more\nexamples where that came from, but it's clear that Mapbox has lowkey stolen the\nhearts of the scientific analysis  market, while Google  concerns itself on the \nconsumer  and business  markets.\n\nTonight's Itinerary: Creating Dope Maps\nTo make some data art, we have a few items on our checklist:\n\n * Obtain a dataset with location-based data: In our case of routing, we need a\n   dataset with a set origin and destination per row.\n * Create direction object routes by running our dataset through the Mapbox API.\n    \n * Create a styled map for our presentation by using Mapbox's style editor.\n * Overlay our route data on our beautiful map.\n\nStep 1: Get Some Free Data\nNow that we've properly shit-talked Google, let's use Google. We're going to\nneed to get some good data, and BigQuery  has some awesome free datasets that we\ncan run wild with. I'll be opting for NYC's dataset on Citibike trips, as it\nprovides a clean set of data where starting and ending coordinates are always\npresent.\n\nGoogle Cloud's Free Dataset of Citibike TripsAs a side note, BigQuery is great.\nEven if you're only somewhat versed in SQL, BigQuery's syntax is essentially\nwhatever your first guess would be.\n\nGranted we only need the start and end locations to make our map, but i decided\nto take a bit extra for curiosity's sake:\n\nstart_namestart_latitudestart_longitudeend_nameend_latitudeend_longitude1 Ave &\nE 15 St40.732218530-73.9816555701 Ave & E 18 St40.733812192-73.9805442091 Ave &\nE 30 St40.741443870-73.975360820E 39 St & 2 Ave40.747803730-73.9734419001 Ave &\nE 62 St40.761227400-73.960940220E 75 St & 3 Ave40.771129270-73.9577229702 Ave &\nE 99 St40.786258600-73.9455257903 Ave & E 112 St40.795508000-73.9416060003 St &\n3 Ave40.675070500-73.98775226010 St & 7 Ave40.666207800-73.9819988603 St &\nProspect Park West40.668132000-73.9736383103 St & Prospect Park West40.668132000\n-73.9736383106 Ave & W 33 St40.749012710-73.988483950W 37 St & 5 Ave40.750380090\n-73.9833898808 Ave & W 52 St40.763707390-73.985161500Central Park S & 6 Ave\n40.765909360-73.97634151011 Ave & W 41 St40.760300960-73.998842220W 34 St & 11\nAve40.755941590-74.00211630012 Ave & W 40 St40.760875020-74.002776680W 42 St & 8\nAve40.757569900-73.990985070Allen St & E Houston St40.722055000-73.989111000Mott\nSt & Prince St40.723179580-73.994800120Allen St & Hester St40.716058660\n-73.991907590Greenwich St & N Moore St40.720434110-74.010206090Amsterdam Ave & W\n73 St40.779668090-73.980930448E 85 St & 3 Ave40.778012030-73.954071490Bank St &\nHudson St40.736528890-74.006180260MacDougal St & Prince St40.727102580\n-74.002970880Bank St & Washington St40.736196700-74.008592070W 4 St & 7 Ave S\n40.734011430-74.002938770Barclay St & Church St40.712912240-74.010202340Clinton\nSt & Tillary St40.696192000-73.991218000Berkeley Pl & 7 Ave40.675146839\n-73.975232095West Drive & Prospect Park West40.661063372-73.979452550Bialystoker\nPl & Delancey St40.716226440-73.982612060Reade St & Broadway40.714504510\n-74.005627890Broadway & W 24 St40.742354300-73.989150760South End Ave & Liberty\nSt40.711512000-74.015756000Broadway & W 29 St40.746200900-73.988557230Stanton St\n& Chrystie St40.722293460-73.991475350Broadway & W 56 St40.765265400\n-73.981923380Broadway & W 49 St40.760683271-73.984527290Broadway & W 58 St\n40.766953170-73.9816933305 Ave & E 78 St40.776321422-73.964273930Cadman Plaza E\n& Red Cross Pl40.699917550-73.989717730Leonard St & Church St40.717571000\n-74.005549000Cadman Plaza E & Tillary St40.695976830-73.990148920Lawrence St &\nWilloughby St40.692361780-73.986317460Carmine St & 6 Ave40.730385990\n-74.002149880W 27 St & 7 Ave40.746647000-73.993915000Central Park W & W 96 St\n40.791270000-73.964839000W 52 St & 6 Ave40.761329831-73.979820013Central Park\nWest & W 76 St40.778967840-73.973747370Central Park S & 6 Ave40.765909360\n-73.976341510Step 2: Style a Sexy Map in Mapbox Studio\nMapbox provides a superb web UI labeled “studio” interface to help us get\nstarted. The “studio” web UI is separated into three parts: custom map styles, \ntilesets, and datasets.\n\nAll of these can we saved for later use.These three sections can be summarized\nas:\n\n * Styles: Custom map styles editable via a GUI, which produce a stylesheet for\n   convenience \n * Tilesets: Map overlays we can apply from our own data or otherwise to segment\n   geographical areas\n * Datasets:  Data containing anything from points on a map to complex direction\n   routes we can overlay atop our map.\n\nHere's a quick look at the Map style editor:\n\nI want to wake up, in a city that doesn't sleep.Save your styled map once you\nfind it to be adequately attractive. We'll need it for later.\n\nStep 4: Start a Flask App\nOf course we're making a Flask app; is there even any other kind? We'll be using\nthe Flask Application Factory setup as we usually do, so we should end up with a\nfile structure as below. If you feel like you're getting ahead of ourself,\ncheckout our post on structuring Flask applications\n[https://hackersandslackers.com/structuring-your-flask-app/].\n\nmapbox-app\n├── /application\n│   └── __init__.py\n├── /datasets\n│   ├── data.json\n│   └── output.csv   \n├── /maps\n│   ├── __init__.py\n│   ├── /templates\n│   │    └── index.html\n│   ├── views.py\n│   └── plots.py\n├── start.sh\n├── settings.py\n├── wsgi.py\n├── Pipfile\n├── README.md\n└── requirements.txt\n\n\nTo mix things up a bit we'll use a shell script this time to handle envars and\nrunning our script. Start by creating start.sh:\n\n# start.sh\n\nexport FLASK_APP=wsgi.py\nexport FLASK_DEBUG=1\nexport APP_CONFIG_FILE=settings.py\nflask run\n\n\nYes, we'll be using settings.py  as our config file for a change. Ahhh, just\nlike the Django days. This file should contain a Mapbox access token. Mapbox\nprovides you with a public token by default in many of its tutorials (noted by\nthe pk  prefix for 'public key' - contrast this with sk  for 'secret key'). If\nyou'd like to do anything meaningful with Mapbox, you'll have to retrieve a\nsecret key via the UI. Then we can add this token to settings.py  as such:\n\nMAPBOX_ACCESS_TOKEN=\"sk.eyJ1IB&F^&f^R&DFRUYFTRUctyrcTYRUFrtCFTYDYTuEg\"\n\n\nFinally, here's a look at application/__init__.py  just to make sure we're on\nthe same page:\n\n# application/__init__.py\n\nimport os\nfrom flask import Flask, g\n\ndef create_app():\n    \"\"\"Construct the core application.\"\"\"\n    app = Flask(__name__)\n    app.config.from_envvar('APP_CONFIG_FILE', silent=True)\n\n    with app.app_context():\n        # Construct map blueprint\n        from maps import mapviews\n        app.register_blueprint(mapviews.map_blueprint)\n\n        return app\n\n\nStep 5: Create a Blueprint for Your Map\nYou may have noticed we registered this Blueprint in the previous step. Create a\n /maps  directory which we'll set as a module; we'll need this to handle the \nview, model (or just data),  and controller (routes.py as seen below).\n\nroutes.py\nimport os\nfrom flask import Blueprint, render_template, request\nfrom flask import current_app as app\nfrom . import locations\n\nmap_blueprint = Blueprint('map', __name__, template_folder='templates', static_folder='static')\nplot_locations = locations.LocationData()\n\n\n# Landing Page\n@map_blueprint.route('/', methods=['GET'])\ndef map():\n    return render_template('index.html', ACCESS_KEY=app.MAPBOX_ACCESS_KEY,  locations=plot_locations.get_plots, title=\"CitiBike Mapbox App.\")\n\n\n\ntemplates/index.html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset='utf-8' />\n  <title>{{title}}</title>\n  <meta name='viewport' content='initial-scale=1,maximum-scale=1,user-scalable=no' />\n  <script src='https://api.tiles.mapbox.com/mapbox-gl-js/v0.49.0/mapbox-gl.js'></script>\n  <link href='https://api.tiles.mapbox.com/mapbox-gl-js/v0.49.0/mapbox-gl.css' rel='stylesheet' />\n  <style>\n    body { margin:0; padding:0; }\n    #map { position:absolute; top:0; bottom:0; width:100%; }\n  </style>\n</head>\n<body>\n\n<div id='map'></div>\n<script>\nmapboxgl.accessToken = {{MAPBOX_ACCESS_TOKEN}};\nconst map = new mapboxgl.Map({\n  container: 'map',\n  style: 'mapbox://styles/toddbirchard/cjpij1gfhghiy2spetf5w998w',\n  center: [-73.981856, 40.703820],\n  zoom: 11.1,\n\n});\n\nmap.on('load', function(e) {\n  // Add the data to your map as a layer\n  map.addLayer({\n    id: 'locations',\n    type: 'symbol',\n    // Add a GeoJSON source containing place coordinates and information.\n    source: {\n      type: 'geojson',\n      data: {{locations}}\n    },\n    layout: {\n      'icon-image': 'restaurant-15',\n      'icon-allow-overlap': true,\n    }\n  });\n});\n</script>\n\n</body>\n</html>\n\n\ndata.py\nNormally this is where we'd use the magic of the Mapbox API to get coordinates,\nroute objects, or whatever it is your heart hopes to plot. This is intended to\nbe intro post, so let's break that logic out for another time and use a dataset\nMapbox would be happy to receive for the sake of results.\n\nStep 6: Uploading our Dataset via Mapbox Studio\nMapbox graciously lets us upload our data via their Studio UI, which does the\nunthinkable; immediately upon upload, Mapbox will take the data we give it\n(whether it be CSV, GeoJSON, etc) and immediately parse it in a way that makes\nsense. Upload your dataset at https://www.mapbox.com/studio/datasets/:\n\nUploading the raw data of our Citibike CSV.Next, Mapbox shows us a preview of\nour data before we even know what happened:\n\nIt's like they don't even want us to do work.Step 7: Do It in Flask\nAfter uploading your dataset via mapbox studio, you can actually redownload  the\ndata with a subtle twist: your data will be automatically formatted as GeoJSON:\nthe format of JSON objects Mapbox uses to plot points, draw routes, etc.\n\nSince we've had a long day, I'll allow you to download this pre-formatted data\nand hardcore the values in to your Map view. You're getting off easy for now,\nbut next time we're doing this programmatically ;).\n\n<!DOCTYPE html>\n<html>\n\n<head>\n  <meta charset='utf-8' />\n  <title>{{title}}</title>\n  <meta name='viewport' content='initial-scale=1,maximum-scale=1,user-scalable=no' />\n  <script src='https://api.tiles.mapbox.com/mapbox-gl-js/v0.49.0/mapbox-gl.js'></script>\n  <link href='https://api.tiles.mapbox.com/mapbox-gl-js/v0.49.0/mapbox-gl.css' rel='stylesheet' />\n  <style>\n    body {\n      margin: 0;\n      padding: 0;\n    }\n\n    #map {\n      position: absolute;\n      top: 0;\n      bottom: 0;\n      width: 100%;\n    }\n  </style>\n</head>\n\n<body>\n\n  <div id='map'></div>\n  <script>\n    mapboxgl.accessToken = '{{ACCESS_KEY}}';\n    const map = new mapboxgl.Map({\n      container: 'map',\n      style: 'mapbox://styles/toddbirchard/cjpij1oxl3hiy2spetf5w998w',\n      center: [-73.981856, 40.703820],\n      zoom: 11.1,\n\n    });\n\n\n    map.addLayer({\n      \"id\": \"points\",\n      \"type\": \"symbol\",\n      \"source\": {\n        \"features\": [{\n            \"type\": \"Feature\",\n            \"properties\": {\n              \"start_station_name\": \"Central Park West & W 76 St\",\n              \"end_station_name\": \"Central Park S & 6 Ave\",\n              \"end_station_latitude\": \"40.76590936\",\n              \"end_station_longitude\": \"-73.97634151\"\n            },\n            \"geometry\": {\n              \"coordinates\": [\n                -73.973747,\n                40.778967\n              ],\n              \"type\": \"Point\"\n            },\n            \"id\": \"000a1f944d4dd786d9e7ed04620af02b\"\n          },\n          {\n            \"type\": \"Feature\",\n            \"properties\": {\n              \"start_station_name\": \"W 64 St & West End Ave\",\n              \"end_station_name\": \"W 70 St & Amsterdam Ave\",\n              \"end_station_latitude\": \"40.77748046\",\n              \"end_station_longitude\": \"-73.98288594\"\n            },\n            \"geometry\": {\n              \"coordinates\": [\n                -73.987537,\n                40.774528\n              ],\n              \"type\": \"Point\"\n            },\n            \"id\": \"01d8c19524f067a3f4712653265e0a49\"\n          },\n          {\n            \"type\": \"Feature\",\n            \"properties\": {\n              \"start_station_name\": \"E 20 St & FDR Drive\",\n              \"end_station_name\": \"W 13 St & 7 Ave\",\n              \"end_station_latitude\": \"40.73781509\",\n              \"end_station_longitude\": \"-73.99994661\"\n            },\n            \"geometry\": {\n              \"coordinates\": [\n                -73.975738,\n                40.733142\n              ],\n              \"type\": \"Point\"\n            },\n            \"id\": \"038ac5403b136e34874a7278f64d4e95\"\n          },\n          {\n              \\\\ --------------------------------------\n              (etc etc....)\n               \\\\ --------------------------------------\n          },\n          {\n            \"type\": \"Feature\",\n            \"properties\": {\n              \"start_station_name\": \"Mercer St & Bleecker St\",\n              \"end_station_name\": \"1 Ave & E 30 St\",\n              \"end_station_latitude\": \"40.74144387\",\n              \"end_station_longitude\": \"-73.97536082\"\n            },\n            \"geometry\": {\n              \"coordinates\": [\n                -73.996621,\n                40.727063\n              ],\n              \"type\": \"Point\"\n            },\n            \"id\": \"ff1daf9aadbf0cd6b788bd76f0a3f333\"\n          }\n        ],\n        \"type\": \"FeatureCollection\"\n      },\n      \"layout\": {\n        \"icon-image\": \"{icon}-15\",\n        \"text-field\": \"{title}\",\n        \"text-font\": [\"Open Sans Semibold\", \"Arial Unicode MS Bold\"],\n        \"text-offset\": [0, 0.6],\n        \"text-anchor\": \"top\"\n      }\n    });\n  </script>\n\n</body>\n\n</html>\n\n\nUncharted Territory\nThere's way more for us to explore in Mapbox. Stay tuned for the rest of this\nseries as we explore generating GeoData programmatically, and build interactive\napplications to really get users involved in map data by letting them control\nconstraints such as time, etc.","html":"<p>There's a trend among those using Jupyter Notebooks (or equivalent) which leads me to believe humanity is coming to an important realization: <strong>Google Maps,</strong> as an API is <em>expensive.</em></p><p>Regardless if Google maps is embedded as a consumer-facing widget, or part of a routine data-pipeline, a single surge of high-traffic can leave enterprises with price tags in the hundreds of thousands of dollars. In fact, I can hardly remember a product where this <em>hadn't</em> become the case. One can hardly blame the search engine; after all, our tendency to ignore the Terms and Service agreements (as well as payment policies) has always been core to the Google business model.  Even then, there are enough enterprises to go around to turn a blind eye and actually pay such a bill willingly without exploring alternatives.</p><p>Data Scientists in particular have no excuse for inaction when it comes to seeking a better alternative. As it turns out, there <em>is</em> one, and it is <strong>Cheaper</strong>, <strong>Easier, </strong>and perhaps more <strong>Fully Featured</strong> than its Google Maps counterpart. That product is <strong>Mapbox</strong>. </p><p><strong>Mapbox</strong> is much more than a Google API clone. The web product offers a plethora of UI-driven features that we can use to customize maps as well as save or effortlessly transform raw data into workable GeoJSON data without even touching an API (which, mind you, there is.... with SDKs in every conceivable language). We're going to create a quick map visualization incorporating some real data to get introduced to Mapbox's functionality, but this is only the beginning. Download the line we'll see just how easy it is to incorporate Mapbox in products like <strong>Plot.ly Dash</strong> or even <strong>Jupyter Notebooks</strong>.</p><h2 id=\"x-marks-the-spot\">X Marks the Spot</h2><p>Before straying from reigning champion Google Maps, it's worth exploring the significance of the metric that brought us here first: price.</p><p>Murphy's law clearly states <strong>\"Cash Rules Everything Around Me, C.R.E.A.M; get the money, Dolla dolla bill y'all.\"</strong> Given this reality, a minimum requirement for Mapbox should be it's pricing model when compared to Google's.</p><h3 id=\"mapbox-pricing-tiers\">Mapbox Pricing Tiers</h3><style>\n  p {\n    line-height: 1.2;\n    color: #444350;\n    margin: 0 0 0 0 !important;\n  }\n   \n  td > p {\n      margin: 0 0 5px 0 !important;\n    }\n    \n  .introbox {\n    text-align: left;\n    vertical-align: top;\n    padding: 3%;\n    max-width: 200px;\n   }\n\n  .tier {\n    font-weight: 900 !important;\n    font-size: 16px !important;\n    display: block;\n    line-height: 1 !important;\n    margin: 0 0 10px !important;\n  }\n\n  .price {\n    font-weight: 500 !important;\n\tfont-size: 18px !important;\n    display: block;\n    color: #60afe6 !important;\n    line-height: 1.3 !important;\n  }\n    \n    thead th {\n        text-align: left !important;\n    }\n    \n    th strong {\n      font-size: 18px;\n      text-align: left;\n    }\n    \n</style>\n\n<div class=\"tableContainer\">\n  <table class=\"table left\">\n    <thead>\n      <tr>\n        <th>\n          <strong>Price</strong>\n        </th>\n        <th>\n          <strong>Web apps</strong>\n        </th>\n        <th>\n          <strong>Mobile SDKs</strong>\n        </th>\n      </tr>\n    </thead>\n    <tbody>\n      <tr>\n        <td class=\"introbox\">\n          <p class=\"tier\">Free to Start</p>\n          <p class=\"price\">$0</p>\n        </td>\n        <td style=\"padding: 20px 15px;\">\n          <p><strong>50,000</strong> map views <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Geocoding requests <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Directions requests <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Matrix elements <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Tilequery requests <strong>/mo</strong></p>\n        </td>\n        <td style=\"padding: 20px 15px;\">\n          <p><strong>50,000</strong> map views <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Geocoding requests <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Directions requests <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Matrix elements <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Tilequery requests <strong>/mo</strong></p>\n        </td>\n      </tr>\n      <tr>\n        <td class=\"introbox\">\n          <p class=\"tier\">Additional Usage</p>\n          <p class=\"price\">$0.50</p>\n        </td>\n        <td style=\"padding: 20px 15px;\">\n          <p><strong>50,000</strong> map views <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Geocoding requests <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Directions requests <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Matrix elements <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Tilequery requests <strong>/mo</strong></p>\n        </td>\n        <td style=\"padding: 20px 15px;\">\n          <p><strong>50,000</strong> map views <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Geocoding requests <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Directions requests <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Matrix elements <strong>/mo</strong></p>\n          <p><strong>50,000</strong> Tilequery requests <strong>/mo</strong></p>\n        </td>\n      </tr>\n    </tbody>\n  </table>\n</div>\n<p>Compare this to Google's transparent pricing structure:</p><h3 id=\"google-api-pricing-tiers\">Google API Pricing Tiers</h3><style>\n  p {\n    line-height: 1.2;\n    color: #444350;\n    margin: 0 0 0 0 !important;\n  }\n    \n  .introbox {\n      text-align: left;\n      vertical-align: top;\n      padding: 3%;\n      max-width: 200px;\n    }\n\n  .tier {\n    font-weight: 900 !important;\n    font-size: 16px !important;\n    display: block;\n    line-height: 1 !important;\n    margin: 0 0 10px !important;\n  }\n\n  .price {\n    font-weight: 500 !important;\n\tfont-size: 18px !important;\n    display: block;\n    color: #60afe6 !important;\n    line-height: 1.3 !important;\n  }\n    \n    thead th {\n        text-align: left !important;\n    }\n    \n    th strong {\n      font-size: 18px;\n      text-align: left;\n    }\n\n</style>\n\n<div class=\"tableContainer\">\n  <table class=\"table left\">\n    <thead>\n      <tr>\n        <th>\n          <strong>Price</strong>\n        </th>\n        <th>\n          <strong>Web apps</strong>\n        </th>\n        <th>\n          <strong>Mobile SDKs</strong>\n        </th>\n      </tr>\n    </thead>\n    <tbody>\n      <tr>\n        <td class=\"introbox\">\n          <p class=\"tier\">Starter Pack</p>\n          <p class=\"price\">Brown Paper Bag full of $20s</p>\n        </td>\n        <td style=\"padding: 20px 15px;\">\n          <p><strong>5</strong> and a half map views  <strong>/mo</strong></p>\n          <p><strong>11</strong> times thinking about the API <strong>/mo</strong></p>\n          <p><strong>6</strong> verbal mentions of \"Google\"  <strong>/mo</strong></p>\n          <p><strong>2</strong> directions to shitty parties <strong>/mo</strong></p>\n          <p><strong>8</strong> visits to anywhere <strong>/mo</strong></p>\n        </td>\n        <td style=\"padding: 20px 15px;\">\n          <p><strong>9</strong> Android unlocks <strong>/mo</strong></p>\n          <p><strong>12</strong> Google queries for restaurants  <strong>/mo</strong></p>\n          <p><strong>3</strong> \"OK Google\" queries  <strong>/mo</strong></p>\n          <p><strong>7</strong> Accidental app opens <strong>/mo</strong></p>\n          <p><strong>1</strong> Creating the next \"Uber for X\" <strong>/mo</strong></p>\n        </td>\n      </tr>\n      <tr>\n        <td class=\"introbox\">\n          <p class=\"tier\">Additional Usage</p>\n          <p class=\"price\">Eleventy Billion Dollars</p>\n        </td>\n        <td style=\"padding: 20px 15px;\">\n          <p>Unlimited Requests!*  </p>\n          <p><small>*See Pricing </small></p>\n        </td>\n        <td style=\"padding: 20px 15px;\">\n          <p>Unlimited Requests!*</p>\n          <p><small>*See Pricing</small></p>\n        </td>\n      </tr>\n    </tbody>\n  </table>\n</div>\n<p>Seems like a convincing point in the win column for <strong>Mapbox</strong>. If we stay within reason, Mapbox can essentially serve us as an entirely free service.</p><p>Surely we must be missing <em>something</em> since we're opting for free services though, right? How do Mapbox visualizations stack up against Google Maps?</p><p data-height=\"511\" data-theme-id=\"0\" data-slug-hash=\"ENoOjz\" data-default-tab=\"result\" data-user=\"ro-ka\" data-pen-title=\"3D map visualizations with Mapbox GL JS\" class=\"codepen\"><a href=\"https://codepen.io/ro-ka/pen/ENoOjz/\"><br></a><a href=\"https://codepen.io/ro-ka\"></a><a href=\"https://codepen.io\"></a></p>\n<script async src=\"https://static.codepen.io/assets/embed/ei.js\"></script><p>Pardon my French here, but hot damn that map is <em>dope.</em> There are plenty more examples where that came from, but it's clear that <strong>Mapbox </strong>has lowkey stolen the hearts of the <em>scientific analysis</em> market, while <strong>Google</strong> concerns itself on the <em>consumer</em> and <em>business</em> markets.</p><h2 id=\"tonight-s-itinerary-creating-dope-maps\">Tonight's Itinerary: Creating Dope Maps</h2><p>To make some data art, we have a few items on our checklist:</p><ul><li>Obtain a dataset with location-based data: In our case of routing, we need a dataset with a set origin and destination per row.</li><li>Create <strong>direction </strong>object routes by running our dataset through the Mapbox API. </li><li>Create a styled map for our presentation by using Mapbox's style editor.</li><li>Overlay our route data on our beautiful map.</li></ul><h2 id=\"step-1-get-some-free-data\">Step 1: Get Some Free Data</h2><p>Now that we've properly shit-talked Google, let's use Google. We're going to need to get some good data, and <strong>BigQuery</strong> has some awesome free datasets that we can run wild with. I'll be opting for <strong>NYC's dataset on Citibike trips</strong>, as it provides a clean set of data where starting and ending coordinates are always present.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/Screen-Shot-2018-12-07-at-2.53.34-AM.png\" class=\"kg-image\"><figcaption>Google Cloud's Free Dataset of Citibike Trips</figcaption></figure><p>As a side note, BigQuery is great. Even if you're only somewhat versed in SQL, BigQuery's syntax is essentially whatever your first guess would be.</p><p>Granted we only need the start and end locations to make our map, but i decided to take a bit extra for curiosity's sake:</p><div class=\"tableContainer\">\n<table border=\"1\" class=\"table table-striped table-bordered table-hover table-condensed\">\n<thead><tr><th title=\"Field #1\">start_name</th>\n<th title=\"Field #2\">start_latitude</th>\n<th title=\"Field #3\">start_longitude</th>\n<th title=\"Field #4\">end_name</th>\n<th title=\"Field #5\">end_latitude</th>\n<th title=\"Field #6\">end_longitude</th>\n</tr></thead>\n<tbody><tr><td>1 Ave &amp; E 15 St</td>\n<td align=\"right\">40.732218530</td>\n<td align=\"right\">-73.981655570</td>\n<td>1 Ave &amp; E 18 St</td>\n<td align=\"right\">40.733812192</td>\n<td align=\"right\">-73.980544209</td>\n</tr>\n<tr><td>1 Ave &amp; E 30 St</td>\n<td align=\"right\">40.741443870</td>\n<td align=\"right\">-73.975360820</td>\n<td>E 39 St &amp; 2 Ave</td>\n<td align=\"right\">40.747803730</td>\n<td align=\"right\">-73.973441900</td>\n</tr>\n<tr><td>1 Ave &amp; E 62 St</td>\n<td align=\"right\">40.761227400</td>\n<td align=\"right\">-73.960940220</td>\n<td>E 75 St &amp; 3 Ave</td>\n<td align=\"right\">40.771129270</td>\n<td align=\"right\">-73.957722970</td>\n</tr>\n<tr><td>2 Ave &amp; E 99 St</td>\n<td align=\"right\">40.786258600</td>\n<td align=\"right\">-73.945525790</td>\n<td>3 Ave &amp; E 112 St</td>\n<td align=\"right\">40.795508000</td>\n<td align=\"right\">-73.941606000</td>\n</tr>\n<tr><td>3 St &amp; 3 Ave</td>\n<td align=\"right\">40.675070500</td>\n<td align=\"right\">-73.987752260</td>\n<td>10 St &amp; 7 Ave</td>\n<td align=\"right\">40.666207800</td>\n<td align=\"right\">-73.981998860</td>\n</tr>\n<tr><td>3 St &amp; Prospect Park West</td>\n<td align=\"right\">40.668132000</td>\n<td align=\"right\">-73.973638310</td>\n<td>3 St &amp; Prospect Park West</td>\n<td align=\"right\">40.668132000</td>\n<td align=\"right\">-73.973638310</td>\n</tr>\n<tr><td>6 Ave &amp; W 33 St</td>\n<td align=\"right\">40.749012710</td>\n<td align=\"right\">-73.988483950</td>\n<td>W 37 St &amp; 5 Ave</td>\n<td align=\"right\">40.750380090</td>\n<td align=\"right\">-73.983389880</td>\n</tr>\n<tr><td>8 Ave &amp; W 52 St</td>\n<td align=\"right\">40.763707390</td>\n<td align=\"right\">-73.985161500</td>\n<td>Central Park S &amp; 6 Ave</td>\n<td align=\"right\">40.765909360</td>\n<td align=\"right\">-73.976341510</td>\n</tr>\n<tr><td>11 Ave &amp; W 41 St</td>\n<td align=\"right\">40.760300960</td>\n<td align=\"right\">-73.998842220</td>\n<td>W 34 St &amp; 11 Ave</td>\n<td align=\"right\">40.755941590</td>\n<td align=\"right\">-74.002116300</td>\n</tr>\n<tr><td>12 Ave &amp; W 40 St</td>\n<td align=\"right\">40.760875020</td>\n<td align=\"right\">-74.002776680</td>\n<td>W 42 St &amp; 8 Ave</td>\n<td align=\"right\">40.757569900</td>\n<td align=\"right\">-73.990985070</td>\n</tr>\n<tr><td>Allen St &amp; E Houston St</td>\n<td align=\"right\">40.722055000</td>\n<td align=\"right\">-73.989111000</td>\n<td>Mott St &amp; Prince St</td>\n<td align=\"right\">40.723179580</td>\n<td align=\"right\">-73.994800120</td>\n</tr>\n<tr><td>Allen St &amp; Hester St</td>\n<td align=\"right\">40.716058660</td>\n<td align=\"right\">-73.991907590</td>\n<td>Greenwich St &amp; N Moore St</td>\n<td align=\"right\">40.720434110</td>\n<td align=\"right\">-74.010206090</td>\n</tr>\n<tr><td>Amsterdam Ave &amp; W 73 St</td>\n<td align=\"right\">40.779668090</td>\n<td align=\"right\">-73.980930448</td>\n<td>E 85 St &amp; 3 Ave</td>\n<td align=\"right\">40.778012030</td>\n<td align=\"right\">-73.954071490</td>\n</tr>\n<tr><td>Bank St &amp; Hudson St</td>\n<td align=\"right\">40.736528890</td>\n<td align=\"right\">-74.006180260</td>\n<td>MacDougal St &amp; Prince St</td>\n<td align=\"right\">40.727102580</td>\n<td align=\"right\">-74.002970880</td>\n</tr>\n<tr><td>Bank St &amp; Washington St</td>\n<td align=\"right\">40.736196700</td>\n<td align=\"right\">-74.008592070</td>\n<td>W 4 St &amp; 7 Ave S</td>\n<td align=\"right\">40.734011430</td>\n<td align=\"right\">-74.002938770</td>\n</tr>\n<tr><td>Barclay St &amp; Church St</td>\n<td align=\"right\">40.712912240</td>\n<td align=\"right\">-74.010202340</td>\n<td>Clinton St &amp; Tillary St</td>\n<td align=\"right\">40.696192000</td>\n<td align=\"right\">-73.991218000</td>\n</tr>\n<tr><td>Berkeley Pl &amp; 7 Ave</td>\n<td align=\"right\">40.675146839</td>\n<td align=\"right\">-73.975232095</td>\n<td>West Drive &amp; Prospect Park West</td>\n<td align=\"right\">40.661063372</td>\n<td align=\"right\">-73.979452550</td>\n</tr>\n<tr><td>Bialystoker Pl &amp; Delancey St</td>\n<td align=\"right\">40.716226440</td>\n<td align=\"right\">-73.982612060</td>\n<td>Reade St &amp; Broadway</td>\n<td align=\"right\">40.714504510</td>\n<td align=\"right\">-74.005627890</td>\n</tr>\n<tr><td>Broadway &amp; W 24 St</td>\n<td align=\"right\">40.742354300</td>\n<td align=\"right\">-73.989150760</td>\n<td>South End Ave &amp; Liberty St</td>\n<td align=\"right\">40.711512000</td>\n<td align=\"right\">-74.015756000</td>\n</tr>\n<tr><td>Broadway &amp; W 29 St</td>\n<td align=\"right\">40.746200900</td>\n<td align=\"right\">-73.988557230</td>\n<td>Stanton St &amp; Chrystie St</td>\n<td align=\"right\">40.722293460</td>\n<td align=\"right\">-73.991475350</td>\n</tr>\n<tr><td>Broadway &amp; W 56 St</td>\n<td align=\"right\">40.765265400</td>\n<td align=\"right\">-73.981923380</td>\n<td>Broadway &amp; W 49 St</td>\n<td align=\"right\">40.760683271</td>\n<td align=\"right\">-73.984527290</td>\n</tr>\n<tr><td>Broadway &amp; W 58 St</td>\n<td align=\"right\">40.766953170</td>\n<td align=\"right\">-73.981693330</td>\n<td>5 Ave &amp; E 78 St</td>\n<td align=\"right\">40.776321422</td>\n<td align=\"right\">-73.964273930</td>\n</tr>\n<tr><td>Cadman Plaza E &amp; Red Cross Pl</td>\n<td align=\"right\">40.699917550</td>\n<td align=\"right\">-73.989717730</td>\n<td>Leonard St &amp; Church St</td>\n<td align=\"right\">40.717571000</td>\n<td align=\"right\">-74.005549000</td>\n</tr>\n<tr><td>Cadman Plaza E &amp; Tillary St</td>\n<td align=\"right\">40.695976830</td>\n<td align=\"right\">-73.990148920</td>\n<td>Lawrence St &amp; Willoughby St</td>\n<td align=\"right\">40.692361780</td>\n<td align=\"right\">-73.986317460</td>\n</tr>\n<tr><td>Carmine St &amp; 6 Ave</td>\n<td align=\"right\">40.730385990</td>\n<td align=\"right\">-74.002149880</td>\n<td>W 27 St &amp; 7 Ave</td>\n<td align=\"right\">40.746647000</td>\n<td align=\"right\">-73.993915000</td>\n</tr>\n<tr><td>Central Park W &amp; W 96 St</td>\n<td align=\"right\">40.791270000</td>\n<td align=\"right\">-73.964839000</td>\n<td>W 52 St &amp; 6 Ave</td>\n<td align=\"right\">40.761329831</td>\n<td align=\"right\">-73.979820013</td>\n</tr>\n<tr><td>Central Park West &amp; W 76 St</td>\n<td align=\"right\">40.778967840</td>\n<td align=\"right\">-73.973747370</td>\n<td>Central Park S &amp; 6 Ave</td>\n<td align=\"right\">40.765909360</td>\n<td align=\"right\">-73.976341510</td>\n</tr>\n</tbody></table>\n</div><h2 id=\"step-2-style-a-sexy-map-in-mapbox-studio\">Step 2: Style a Sexy Map in Mapbox Studio</h2><p>Mapbox provides a superb web UI labeled “studio” interface to help us get started. The “studio” web UI is separated into three parts: <strong>custom map styles</strong>, <strong>tilesets</strong>, and <strong>datasets</strong>.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mapboxstudio.gif\" class=\"kg-image\"><figcaption>All of these can we saved for later use.</figcaption></figure><p>These three sections can be summarized as:</p><ul><li><strong>Styles: </strong>Custom map styles editable via a GUI, which produce a stylesheet for convenience </li><li><strong>Tilesets: </strong>Map overlays we can apply from our own data or otherwise to segment geographical areas</li><li><strong>Datasets:</strong> Data containing anything from points on a map to complex direction routes we can overlay atop our map.</li></ul><p>Here's a quick look at the Map style editor:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/Screen-Shot-2018-12-07-at-4.29.43-PM.png\" class=\"kg-image\"><figcaption>I want to wake up, in a city that doesn't sleep.</figcaption></figure><p>Save your styled map once you find it to be adequately attractive. We'll need it for later.</p><h2 id=\"step-4-start-a-flask-app\">Step 4: Start a Flask App</h2><p>Of course we're making a Flask app; is there even any other kind? We'll be using the Flask Application Factory setup as we usually do, so we should end up with a file structure as below. If you feel like you're getting ahead of ourself, checkout our post on <a href=\"https://hackersandslackers.com/structuring-your-flask-app/\">structuring Flask applications</a>.</p><pre><code class=\"language-bash\">mapbox-app\n├── /application\n│   └── __init__.py\n├── /datasets\n│   ├── data.json\n│   └── output.csv   \n├── /maps\n│   ├── __init__.py\n│   ├── /templates\n│   │    └── index.html\n│   ├── views.py\n│   └── plots.py\n├── start.sh\n├── settings.py\n├── wsgi.py\n├── Pipfile\n├── README.md\n└── requirements.txt\n</code></pre>\n<p>To mix things up a bit we'll use a shell script this time to handle envars and running our script. Start by creating <strong>start.sh</strong>:</p><pre><code class=\"language-bash\"># start.sh\n\nexport FLASK_APP=wsgi.py\nexport FLASK_DEBUG=1\nexport APP_CONFIG_FILE=settings.py\nflask run\n</code></pre>\n<p>Yes, we'll be using <code>settings.py</code> as our config file for a change. Ahhh, just like the Django days. This file should contain a Mapbox <strong>access token</strong>. Mapbox provides you with a public token by default in many of its tutorials (noted by the <em><strong>pk</strong> </em>prefix for <em>'public key' - </em>contrast this with <strong><em>sk</em></strong> for <em>'secret key'</em>). If you'd like to do anything meaningful with Mapbox, you'll have to retrieve a secret key via the UI. Then we can add this token to <code>settings.py</code> as such:</p><pre><code class=\"language-bash\">MAPBOX_ACCESS_TOKEN=&quot;sk.eyJ1IB&amp;F^&amp;f^R&amp;DFRUYFTRUctyrcTYRUFrtCFTYDYTuEg&quot;\n</code></pre>\n<p>Finally, here's a look at <code>application/__init__.py</code> just to make sure we're on the same page:</p><pre><code class=\"language-python\"># application/__init__.py\n\nimport os\nfrom flask import Flask, g\n\ndef create_app():\n    &quot;&quot;&quot;Construct the core application.&quot;&quot;&quot;\n    app = Flask(__name__)\n    app.config.from_envvar('APP_CONFIG_FILE', silent=True)\n\n    with app.app_context():\n        # Construct map blueprint\n        from maps import mapviews\n        app.register_blueprint(mapviews.map_blueprint)\n\n        return app\n</code></pre>\n<h2 id=\"step-5-create-a-blueprint-for-your-map\">Step 5: Create a Blueprint for Your Map</h2><p>You may have noticed we registered this Blueprint in the previous step. Create a <code>/maps</code> directory which we'll set as a module; we'll need this to handle the <strong>view</strong>, <strong>model </strong>(or just data),  and <strong>controller </strong>(routes.py as seen below).</p><h3 id=\"routes-py\">routes.py</h3><pre><code class=\"language-python\">import os\nfrom flask import Blueprint, render_template, request\nfrom flask import current_app as app\nfrom . import locations\n\nmap_blueprint = Blueprint('map', __name__, template_folder='templates', static_folder='static')\nplot_locations = locations.LocationData()\n\n\n# Landing Page\n@map_blueprint.route('/', methods=['GET'])\ndef map():\n    return render_template('index.html', ACCESS_KEY=app.MAPBOX_ACCESS_KEY,  locations=plot_locations.get_plots, title=&quot;CitiBike Mapbox App.&quot;)\n\n</code></pre>\n<h3 id=\"templates-index-html\">templates/index.html</h3><pre><code class=\"language-html\">&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;meta charset='utf-8' /&gt;\n  &lt;title&gt;{{title}}&lt;/title&gt;\n  &lt;meta name='viewport' content='initial-scale=1,maximum-scale=1,user-scalable=no' /&gt;\n  &lt;script src='https://api.tiles.mapbox.com/mapbox-gl-js/v0.49.0/mapbox-gl.js'&gt;&lt;/script&gt;\n  &lt;link href='https://api.tiles.mapbox.com/mapbox-gl-js/v0.49.0/mapbox-gl.css' rel='stylesheet' /&gt;\n  &lt;style&gt;\n    body { margin:0; padding:0; }\n    #map { position:absolute; top:0; bottom:0; width:100%; }\n  &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n&lt;div id='map'&gt;&lt;/div&gt;\n&lt;script&gt;\nmapboxgl.accessToken = {{MAPBOX_ACCESS_TOKEN}};\nconst map = new mapboxgl.Map({\n  container: 'map',\n  style: 'mapbox://styles/toddbirchard/cjpij1gfhghiy2spetf5w998w',\n  center: [-73.981856, 40.703820],\n  zoom: 11.1,\n\n});\n\nmap.on('load', function(e) {\n  // Add the data to your map as a layer\n  map.addLayer({\n    id: 'locations',\n    type: 'symbol',\n    // Add a GeoJSON source containing place coordinates and information.\n    source: {\n      type: 'geojson',\n      data: {{locations}}\n    },\n    layout: {\n      'icon-image': 'restaurant-15',\n      'icon-allow-overlap': true,\n    }\n  });\n});\n&lt;/script&gt;\n\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<h3 id=\"data-py\">data.py</h3><p>Normally this is where we'd use the magic of the Mapbox API to get coordinates, route objects, or whatever it is your heart hopes to plot. This is intended to be intro post, so let's break that logic out for another time and use a dataset Mapbox would be happy to receive for the sake of results.</p><h2 id=\"step-6-uploading-our-dataset-via-mapbox-studio\">Step 6: Uploading our Dataset via Mapbox Studio</h2><p>Mapbox graciously lets us upload our data via their Studio UI, which does the unthinkable; immediately upon upload, Mapbox will take the data we give it (whether it be CSV, GeoJSON, etc) and immediately parse it in a way that makes sense. Upload your dataset at <a href=\"https://www.mapbox.com/studio/datasets/\">https://www.mapbox.com/studio/datasets/</a>:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/Screen-Shot-2018-12-10-at-5.29.24-PM.png\" class=\"kg-image\"><figcaption>Uploading the raw data of our Citibike CSV.</figcaption></figure><p>Next, Mapbox shows us a preview of our data before we even know what happened:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/Screen-Shot-2018-12-10-at-5.28.24-PM.png\" class=\"kg-image\"><figcaption>It's like they don't even want us to do work.</figcaption></figure><h2 id=\"step-7-do-it-in-flask\">Step 7: Do It in Flask</h2><p>After uploading your dataset via mapbox studio, you can actually <em>redownload</em> the data with a subtle twist: your data will be automatically formatted as GeoJSON: the format of JSON objects Mapbox uses to plot points, draw routes, etc.</p><p>Since we've had a long day, I'll allow you to download this pre-formatted data and hardcore the values in to your Map view. You're getting off easy for now, but next time we're doing this programmatically ;).</p><pre><code class=\"language-html\">&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n\n&lt;head&gt;\n  &lt;meta charset='utf-8' /&gt;\n  &lt;title&gt;{{title}}&lt;/title&gt;\n  &lt;meta name='viewport' content='initial-scale=1,maximum-scale=1,user-scalable=no' /&gt;\n  &lt;script src='https://api.tiles.mapbox.com/mapbox-gl-js/v0.49.0/mapbox-gl.js'&gt;&lt;/script&gt;\n  &lt;link href='https://api.tiles.mapbox.com/mapbox-gl-js/v0.49.0/mapbox-gl.css' rel='stylesheet' /&gt;\n  &lt;style&gt;\n    body {\n      margin: 0;\n      padding: 0;\n    }\n\n    #map {\n      position: absolute;\n      top: 0;\n      bottom: 0;\n      width: 100%;\n    }\n  &lt;/style&gt;\n&lt;/head&gt;\n\n&lt;body&gt;\n\n  &lt;div id='map'&gt;&lt;/div&gt;\n  &lt;script&gt;\n    mapboxgl.accessToken = '{{ACCESS_KEY}}';\n    const map = new mapboxgl.Map({\n      container: 'map',\n      style: 'mapbox://styles/toddbirchard/cjpij1oxl3hiy2spetf5w998w',\n      center: [-73.981856, 40.703820],\n      zoom: 11.1,\n\n    });\n\n\n    map.addLayer({\n      &quot;id&quot;: &quot;points&quot;,\n      &quot;type&quot;: &quot;symbol&quot;,\n      &quot;source&quot;: {\n        &quot;features&quot;: [{\n            &quot;type&quot;: &quot;Feature&quot;,\n            &quot;properties&quot;: {\n              &quot;start_station_name&quot;: &quot;Central Park West &amp; W 76 St&quot;,\n              &quot;end_station_name&quot;: &quot;Central Park S &amp; 6 Ave&quot;,\n              &quot;end_station_latitude&quot;: &quot;40.76590936&quot;,\n              &quot;end_station_longitude&quot;: &quot;-73.97634151&quot;\n            },\n            &quot;geometry&quot;: {\n              &quot;coordinates&quot;: [\n                -73.973747,\n                40.778967\n              ],\n              &quot;type&quot;: &quot;Point&quot;\n            },\n            &quot;id&quot;: &quot;000a1f944d4dd786d9e7ed04620af02b&quot;\n          },\n          {\n            &quot;type&quot;: &quot;Feature&quot;,\n            &quot;properties&quot;: {\n              &quot;start_station_name&quot;: &quot;W 64 St &amp; West End Ave&quot;,\n              &quot;end_station_name&quot;: &quot;W 70 St &amp; Amsterdam Ave&quot;,\n              &quot;end_station_latitude&quot;: &quot;40.77748046&quot;,\n              &quot;end_station_longitude&quot;: &quot;-73.98288594&quot;\n            },\n            &quot;geometry&quot;: {\n              &quot;coordinates&quot;: [\n                -73.987537,\n                40.774528\n              ],\n              &quot;type&quot;: &quot;Point&quot;\n            },\n            &quot;id&quot;: &quot;01d8c19524f067a3f4712653265e0a49&quot;\n          },\n          {\n            &quot;type&quot;: &quot;Feature&quot;,\n            &quot;properties&quot;: {\n              &quot;start_station_name&quot;: &quot;E 20 St &amp; FDR Drive&quot;,\n              &quot;end_station_name&quot;: &quot;W 13 St &amp; 7 Ave&quot;,\n              &quot;end_station_latitude&quot;: &quot;40.73781509&quot;,\n              &quot;end_station_longitude&quot;: &quot;-73.99994661&quot;\n            },\n            &quot;geometry&quot;: {\n              &quot;coordinates&quot;: [\n                -73.975738,\n                40.733142\n              ],\n              &quot;type&quot;: &quot;Point&quot;\n            },\n            &quot;id&quot;: &quot;038ac5403b136e34874a7278f64d4e95&quot;\n          },\n          {\n              \\\\ --------------------------------------\n              (etc etc....)\n               \\\\ --------------------------------------\n          },\n          {\n            &quot;type&quot;: &quot;Feature&quot;,\n            &quot;properties&quot;: {\n              &quot;start_station_name&quot;: &quot;Mercer St &amp; Bleecker St&quot;,\n              &quot;end_station_name&quot;: &quot;1 Ave &amp; E 30 St&quot;,\n              &quot;end_station_latitude&quot;: &quot;40.74144387&quot;,\n              &quot;end_station_longitude&quot;: &quot;-73.97536082&quot;\n            },\n            &quot;geometry&quot;: {\n              &quot;coordinates&quot;: [\n                -73.996621,\n                40.727063\n              ],\n              &quot;type&quot;: &quot;Point&quot;\n            },\n            &quot;id&quot;: &quot;ff1daf9aadbf0cd6b788bd76f0a3f333&quot;\n          }\n        ],\n        &quot;type&quot;: &quot;FeatureCollection&quot;\n      },\n      &quot;layout&quot;: {\n        &quot;icon-image&quot;: &quot;{icon}-15&quot;,\n        &quot;text-field&quot;: &quot;{title}&quot;,\n        &quot;text-font&quot;: [&quot;Open Sans Semibold&quot;, &quot;Arial Unicode MS Bold&quot;],\n        &quot;text-offset&quot;: [0, 0.6],\n        &quot;text-anchor&quot;: &quot;top&quot;\n      }\n    });\n  &lt;/script&gt;\n\n&lt;/body&gt;\n\n&lt;/html&gt;\n</code></pre>\n<h2 id=\"uncharted-territory\">Uncharted Territory</h2><p>There's way more for us to explore in Mapbox. Stay tuned for the rest of this series as we explore generating GeoData programmatically, and build interactive applications to really get users involved in map data by letting them control constraints such as time, etc. </p>","url":"https://hackersandslackers.com/map-data-visualization-with-mapbox/","uuid":"3b64bf8d-b545-469c-b2df-83ee7a816e31","page":false,"codeinjection_foot":"","codeinjection_head":"  <script src='https://api.tiles.mapbox.com/mapbox-gl-js/v0.51.0/mapbox-gl.js'></script>\n    <link href='https://api.tiles.mapbox.com/mapbox-gl-js/v0.51.0/mapbox-gl.css' rel='stylesheet' />","comment_id":"5c0aafba5da6c4479ab70ff1"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673740","title":"The Many Faces and Filetypes of Python Configs","slug":"simplify-your-python-projects-configuration","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/11/config@2x.jpg","excerpt":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files.","custom_excerpt":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files.","created_at_pretty":"29 November, 2018","published_at_pretty":"29 November, 2018","updated_at_pretty":"27 December, 2018","created_at":"2018-11-29T02:24:13.000-05:00","published_at":"2018-11-29T16:40:26.000-05:00","updated_at":"2018-12-26T23:23:54.000-05:00","meta_title":"Simplify Your Python Project Configuration | Hackers and Slackers","meta_description":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files. Adopt a feel for when certain files or classes fit your needs best.","og_description":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files. Adopt a feel for when certain files or classes fit your needs best.","og_image":"https://hackersandslackers.com/content/images/2018/11/config@2x.jpg","og_title":"The Many Faces and Files of Python Configs","twitter_description":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files. Adopt a feel for when certain files or classes fit your needs best.","twitter_image":"https://hackersandslackers.com/content/images/2018/11/config@2x.jpg","twitter_title":"The Many Faces and Files of Python Configs","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"As we cling harder and harder to Dockerfiles, Kubernetes, or any modern\npreconfigured app environment, our dependency on billable boilerplate grows.\nWhether or not that is a problem is a conversation in itself. The longer I keep\nmy projects self-hosted, the more  I'm consumed by the open-ended approaches\npeople take to manage their project configuration variables.\n\nFull disclosure here: this post is probably about as boring as where you see\nthis heading. Today, I'm here to talk about Python Environment and general\nconfiguration variable handling.\n\nPick Your Poison\nSomeday, each and every one of us will die. I'm referring of course to the part\ninside of us that slowly withers away as we're forced to maintain projects we've\nhanded off. We can do our best to avoid these situations by isolating the\nvariables most subject to change in separate, easy-to-edit files for Person\nNumber 2 to pick up on.\n\nOption 1: Project Config via .ini Files\n.ini  files are simple, making them perfect for simple projects- especially\nthose to be handled by others why may not have development backgrounds. These\nare configuration files with a single-level hierarchy:\n\n[GLOBAL]\nPROJECT: Fake Example Project\nREGION: us-east-1\nINPUT_FOLDER: data/zip/\nOUTPUT_FOLDER: data/output/\nTIMEOUT: 200\nMEMORY: 512\n\n[PROD]\nDATABASE = postgresql://loser:weakpassword@localhost:5432/mydatabase\nENDPOINT = https://production.endpoint.example.com\nUSER = PROD_USERNAME\n\n[DEV]\nDATABASE = postgresql://loser:weakpassword@localhost:5432/mydatabase\nENDPOINT = https://dev.endpoint.example.com\nUSER = DEV_USERNAME\n\n\nAnother example, for instance, may be to specify AWS Services:\n\n[S3]\nBUCKET_NAME: public-bucket\nBUCKET_FOLDER: /\n\n[RDS]\nNAME: rds/prod/sensitivedata\nARN: arn:aws:rds:us-east-1:66574567568434896:secret:rds/prod/peopledata-ZvJ3Ys\nREGION: us-east-1\n\n[LAMBDA]\nFUNCTION_NAME: handler\nHANDLER: lambda.handler\nDESCRIPTION: Performs a task every now and then.\nRUNTIME: python3.7\nROLE: lambda_role\nDIST_FOLDER: lambda/dist\n\n[SECRETS]\nSECRET_NAME: rds/prod/totallysecret\nSECRET_ARN: arn:aws:secretsmanager:us-east-1:769979969:secret:rds/prod/stupidproject-5647\n\n\n.ini  files are handled in Python by the configparser  library; this is our way\nof doing something with the essentially static text in these files. Since we're\nkeeping vars separate from app source code, we now need to create a file and a\nclass which exists merely to access these values.\n\nCreating a Python Class to Extract Variables\nInstead of explicitly hardcoding a dump of all variables, we're going to create\na class that provides an easy syntax for accessing variables on demand. Check it\nout:\n\n# config_loader.py\nfrom configparser import SafeConfigParser\nimport os\n\n\nclass Config:\n    \"\"\"Interact with configuration variables.\"\"\"\n\n    configParser = SafeConfigParser()\n    configFilePath = (os.path.join(os.getcwd(), 'config.ini'))\n\n    @classmethod\n    def initialize(cls, newhire_table):\n        \"\"\"Start config by reading config.ini.\"\"\"\n        cls.configParser.read(cls.configFilePath)\n\n    @classmethod\n    def prod(cls, key):\n        \"\"\"Get prod values from config.ini.\"\"\"\n        return cls.configParser.get('PROD', key)\n\n    @classmethod\n    def dev(cls, key):\n        \"\"\"Get dev values from config.ini.\"\"\"\n        return cls.configParser.get('DEV', key)\n\n\nThis simple class goes a long way to simplify grabbing variables. The class\nnever needs to be instantiated, so we can import Config  wherever we please and\nimmediately start pulling values.\n\nTo separate variables by concern, each block in config.ini  receives its own\nclass method. Now retrieving the proper variables is as simple as \nConfig.prod('DATABASE')  will return the URI for a production database. Easy to\nuse, simple to understand.\n\nOption 2: Complex YAML Configurations\nUnless you're developing apps in isolation in an isolated third-world nation or\nunder a dictatorship which blocks internet access, you already know that .yaml \nfiles are all the rage when it comes to storing static values in text files\n(wow, this really is  an obscure topic for a post).\n\nYAML  files provide plenty of upsides to alternative file types. Where .ini \nfiles are simply grouped variables, YAML  provides a hierarchy structure. This\nmakes YAML files much easier to understand and maintain for larger applications,\nas some variables only make sense in the context of being a sub-variable (?).\n\nCheck out what a sample YAML config might look like:\n\n---\n\nappName: appName\nlogLevel: WARN\n\nAWS:\n    Region: us-east-1\n    Resources:\n      EC2: \n        Type: \"AWS::EC2::Instance\"\n        Properties: \n          ImageId: \"ami-0ff8a91507f77f867\"\n          InstanceType: t2.micro\n          KeyName: testkey\n          BlockDeviceMappings:\n            -\n              DeviceName: /dev/sdm\n              Ebs:\n                VolumeType: io1\n                Iops: 200\n                DeleteOnTermination: false\n                VolumeSize: 20\n      Lambda:\n          Type: \"AWS::Lambda::Function\"\n          Properties: \n            Handler: \"index.handler\"\n            Role: \n              Fn::GetAtt: \n                - \"LambdaExecutionRole\"\n                - \"Arn\"\n            Runtime: \"python3.7\"\n            Timeout: 25\n            TracingConfig:\n              Mode: \"Active\"\n\nroutes:\n  admin:\n    url: /admin\n    template: admin.html\n    assets:\n        templates: /templates\n        static: /static\n  dashboard:\n    url: /dashboard\n    template: dashboard.html\n    assets:\n        templates: /templates\n        static: /static\n  account:\n    url: /account\n    template: account.html\n    assets:\n        templates: /templates\n        static: /static\n        \ndatabases:\n  cassandra:\n    host: example.cassandra.db\n    username: user\n    password: password\n  redshift:\n    jdbcURL: jdbc:redshift://<IP>:<PORT>/file?user=username&password=pass\n    tempS3Dir: s3://path/to/redshift/temp/dir/ \n  redis:\n    host: hostname\n    port: port-number\n    auth: authentication\n    db: database\n\n\nThis would read horribly if we tried to fit this in an .ini  file. A more fair\ncomparison would be to JSON  configurations: JSON objects indeed share the same\nhierarchy advantages of YAML, but JSON syntax is prone to errors and unhelpful\nerror messages, thanks to being a brainchild of Old Man JavaScript. YAML doesn't\ncare if you open and close with brackets, use double quotes, or leave a trailing\ncomma. All of these stupid things are why I prefer Python.\n\nParsing YAML in Python\nI recommend the Python Confuse library [https://github.com/sampsyo/confuse]  (a\npackage name that's sure to raise some eyebrows by your company's information\nsecurity team).\n\nConfuse  allows use to interact with YAML files almost identically to how we\nwould with JSON, with the exception that we specify .get()  at the end of\nwalking through the tree hierarchy, like so:\n\nconfig = confuse.Configuration('MyApp', __name__)\n\nconfig['AWS']['Lambda']['Runtime'].get()\n\n\n.get()  can accept a datatype value such as int. Doing so ensures that the value\nwe're getting is actually of the schema we're expecting, which is a neat\nfeature.\n\nValidators\nConfuse's documentation [https://confuse.readthedocs.io/en/latest/]details\nadditional validation methods for values we pull from YAML files. Methods like \nas_filename(), as_number(), and as_str_seq()  do basically what you'd expect\nthem to.\n\nCLI Configuration\nConfuse also gets into the realm of building CLIs, allowing use to use our YAML\nfile to inform arguments which can be passed to a CLI and their potential\nvalues:\n\nconfig = confuse.Configuration('myapp')\nparser = argparse.ArgumentParser()\nparser.add_argument('--foo', help='a parameter')\nargs = parser.parse_args()\nconfig.set_args(args)\nprint(config['foo'].get())\n\n\nThere's plenty of things you can go nuts with here.\n\nOption 3: Using .env Config Files\nLastly, we can leverage the already well-known .env  format to set variables.\nWorking this way is pretty equivalent to working with .ini  files, but we're\nhuman beings so we're stupid and do things like build the same protocols over\nand over. In .env, we get to store beautiful values such as these:\n\nCONFIG_PATH=${HOME}/.config/foo\nDOMAIN=example.org\nEMAIL=admin@${DOMAIN}\n\nTo read these values, we'll be using the python-dotenv library\n[https://github.com/theskumar/python-dotenv]. This gets you started:\n\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\nload_dotenv(verbose=True)\n\nenv_path = Path('.') / '.env'\nload_dotenv(dotenv_path=env_path)\n\n\nAfter that, it's a matter of setting variables in Python to values you extract\nfrom .env:\n\nimport os\nSECRET_KEY = os.getenv(\"EMAIL\")\nDATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\")\n\n\nSo Yeah, Basically Just Use What You Want\nClearly there are plenty of ways to set environment and project variables in\nPython. We could spend all day investigating the nuances of each and how their\naccompanying Python configuration class should be structured, but we've got apps\nto build. \n\nBesides, I need to go reflect on my life after writing a thousand words about\nloading variables in Python.","html":"<p>As we cling harder and harder to Dockerfiles, Kubernetes, or any modern preconfigured app environment, our dependency on billable boilerplate grows. Whether or not that is a problem is a conversation in itself. The longer I keep my projects self-hosted, the more  I'm consumed by the open-ended approaches people take to manage their project configuration variables.</p><p>Full disclosure here: this post is probably about as boring as where you see this heading. Today, I'm here to talk about Python Environment and general configuration variable handling.</p><h2 id=\"pick-your-poison\">Pick Your Poison</h2><p>Someday, each and every one of us will die. I'm referring of course to the part inside of us that slowly withers away as we're forced to maintain projects we've handed off. We can do our best to avoid these situations by isolating the variables most subject to change in separate, easy-to-edit files for Person Number 2 to pick up on.</p><h2 id=\"option-1-project-config-via-ini-files\">Option 1: Project Config via .ini Files</h2><p><code>.ini</code> files are simple, making them perfect for simple projects- especially those to be handled by others why may not have development backgrounds. These are configuration files with a single-level hierarchy:</p><pre><code class=\"language-ini\">[GLOBAL]\nPROJECT: Fake Example Project\nREGION: us-east-1\nINPUT_FOLDER: data/zip/\nOUTPUT_FOLDER: data/output/\nTIMEOUT: 200\nMEMORY: 512\n\n[PROD]\nDATABASE = postgresql://loser:weakpassword@localhost:5432/mydatabase\nENDPOINT = https://production.endpoint.example.com\nUSER = PROD_USERNAME\n\n[DEV]\nDATABASE = postgresql://loser:weakpassword@localhost:5432/mydatabase\nENDPOINT = https://dev.endpoint.example.com\nUSER = DEV_USERNAME\n</code></pre>\n<p>Another example, for instance, may be to specify AWS Services:</p><pre><code class=\"language-ini\">[S3]\nBUCKET_NAME: public-bucket\nBUCKET_FOLDER: /\n\n[RDS]\nNAME: rds/prod/sensitivedata\nARN: arn:aws:rds:us-east-1:66574567568434896:secret:rds/prod/peopledata-ZvJ3Ys\nREGION: us-east-1\n\n[LAMBDA]\nFUNCTION_NAME: handler\nHANDLER: lambda.handler\nDESCRIPTION: Performs a task every now and then.\nRUNTIME: python3.7\nROLE: lambda_role\nDIST_FOLDER: lambda/dist\n\n[SECRETS]\nSECRET_NAME: rds/prod/totallysecret\nSECRET_ARN: arn:aws:secretsmanager:us-east-1:769979969:secret:rds/prod/stupidproject-5647\n</code></pre>\n<p><code>.ini</code> files are handled in Python by the <strong>configparser</strong> library; this is our way of doing something with the essentially static text in these files. Since we're keeping vars separate from app source code, we now need to create a file and a class which exists merely to access these values.</p><h3 id=\"creating-a-python-class-to-extract-variables\">Creating a Python Class to Extract Variables</h3><p>Instead of explicitly hardcoding a dump of all variables, we're going to create a class that provides an easy syntax for accessing variables on demand. Check it out:</p><pre><code class=\"language-python\"># config_loader.py\nfrom configparser import SafeConfigParser\nimport os\n\n\nclass Config:\n    &quot;&quot;&quot;Interact with configuration variables.&quot;&quot;&quot;\n\n    configParser = SafeConfigParser()\n    configFilePath = (os.path.join(os.getcwd(), 'config.ini'))\n\n    @classmethod\n    def initialize(cls, newhire_table):\n        &quot;&quot;&quot;Start config by reading config.ini.&quot;&quot;&quot;\n        cls.configParser.read(cls.configFilePath)\n\n    @classmethod\n    def prod(cls, key):\n        &quot;&quot;&quot;Get prod values from config.ini.&quot;&quot;&quot;\n        return cls.configParser.get('PROD', key)\n\n    @classmethod\n    def dev(cls, key):\n        &quot;&quot;&quot;Get dev values from config.ini.&quot;&quot;&quot;\n        return cls.configParser.get('DEV', key)\n</code></pre>\n<p>This simple class goes a long way to simplify grabbing variables. The class never needs to be instantiated, so we can <code>import Config</code> wherever we please and immediately start pulling values.</p><p>To separate variables by concern, each block in <code>config.ini</code> receives its own class method. Now retrieving the proper variables is as simple as <code>Config.prod('DATABASE')</code> will return the URI for a production database. Easy to use, simple to understand.</p><h2 id=\"option-2-complex-yaml-configurations\">Option 2: Complex YAML Configurations</h2><p>Unless you're developing apps in isolation in an isolated third-world nation or under a dictatorship which blocks internet access, you already know that <code>.yaml</code> files are all the rage when it comes to storing static values in text files (wow, this really <em>is</em> an obscure topic for a post).</p><p><strong>YAML</strong> files provide plenty of upsides to alternative file types. Where <strong>.ini</strong> files are simply grouped variables, <strong>YAML</strong> provides a hierarchy structure. This makes YAML files much easier to understand and maintain for larger applications, as some variables only make sense in the context of being a sub-variable (?).</p><p>Check out what a sample YAML config might look like:</p><pre><code class=\"language-yaml\">---\n\nappName: appName\nlogLevel: WARN\n\nAWS:\n    Region: us-east-1\n    Resources:\n      EC2: \n        Type: &quot;AWS::EC2::Instance&quot;\n        Properties: \n          ImageId: &quot;ami-0ff8a91507f77f867&quot;\n          InstanceType: t2.micro\n          KeyName: testkey\n          BlockDeviceMappings:\n            -\n              DeviceName: /dev/sdm\n              Ebs:\n                VolumeType: io1\n                Iops: 200\n                DeleteOnTermination: false\n                VolumeSize: 20\n      Lambda:\n          Type: &quot;AWS::Lambda::Function&quot;\n          Properties: \n            Handler: &quot;index.handler&quot;\n            Role: \n              Fn::GetAtt: \n                - &quot;LambdaExecutionRole&quot;\n                - &quot;Arn&quot;\n            Runtime: &quot;python3.7&quot;\n            Timeout: 25\n            TracingConfig:\n              Mode: &quot;Active&quot;\n\nroutes:\n  admin:\n    url: /admin\n    template: admin.html\n    assets:\n        templates: /templates\n        static: /static\n  dashboard:\n    url: /dashboard\n    template: dashboard.html\n    assets:\n        templates: /templates\n        static: /static\n  account:\n    url: /account\n    template: account.html\n    assets:\n        templates: /templates\n        static: /static\n        \ndatabases:\n  cassandra:\n    host: example.cassandra.db\n    username: user\n    password: password\n  redshift:\n    jdbcURL: jdbc:redshift://&lt;IP&gt;:&lt;PORT&gt;/file?user=username&amp;password=pass\n    tempS3Dir: s3://path/to/redshift/temp/dir/ \n  redis:\n    host: hostname\n    port: port-number\n    auth: authentication\n    db: database\n</code></pre>\n<p>This would read horribly if we tried to fit this in an <strong>.ini</strong> file. A more fair comparison would be to <strong>JSON</strong> configurations: JSON objects indeed share the same hierarchy advantages of YAML, but JSON syntax is prone to errors and unhelpful error messages, thanks to being a brainchild of Old Man JavaScript. YAML doesn't care if you open and close with brackets, use double quotes, or leave a trailing comma. All of these stupid things are why I prefer Python.</p><h3 id=\"parsing-yaml-in-python\">Parsing YAML in Python</h3><p>I recommend the <a href=\"https://github.com/sampsyo/confuse\">Python <em>Confuse</em> library</a> (a package name that's sure to raise some eyebrows by your company's information security team).</p><p><strong>Confuse</strong> allows use to interact with YAML files almost identically to how we would with JSON, with the exception that we specify <code>.get()</code> at the end of walking through the tree hierarchy, like so:</p><pre><code class=\"language-python\">config = confuse.Configuration('MyApp', __name__)\n\nconfig['AWS']['Lambda']['Runtime'].get()\n</code></pre>\n<p><strong>.get()</strong> can accept a datatype value such as <em>int. </em>Doing so ensures that the value we're getting is actually of the schema we're expecting, which is a neat feature.</p><h4 id=\"validators\">Validators</h4><p><a href=\"https://confuse.readthedocs.io/en/latest/\">Confuse's documentation </a>details additional validation methods for values we pull from YAML files. Methods like <code>as_filename()</code>, <code>as_number()</code>, and <code>as_str_seq()</code> do basically what you'd expect them to.</p><h4 id=\"cli-configuration\">CLI Configuration</h4><p>Confuse also gets into the realm of building CLIs, allowing use to use our YAML file to inform arguments which can be passed to a CLI and their potential values:</p><pre><code class=\"language-python\">config = confuse.Configuration('myapp')\nparser = argparse.ArgumentParser()\nparser.add_argument('--foo', help='a parameter')\nargs = parser.parse_args()\nconfig.set_args(args)\nprint(config['foo'].get())\n</code></pre>\n<p>There's plenty of things you can go nuts with here.</p><h2 id=\"option-3-using-env-config-files\">Option 3: Using .env Config Files</h2><p>Lastly, we can leverage the already well-known <code>.env</code> format to set variables. Working this way is pretty equivalent to working with <strong>.ini</strong> files, but we're human beings so we're stupid and do things like build the same protocols over and over. In <strong>.env</strong>, we get to store beautiful values such as these:</p><pre><code>CONFIG_PATH=${HOME}/.config/foo\nDOMAIN=example.org\nEMAIL=admin@${DOMAIN}</code></pre><p>To read these values, we'll be using the <a href=\"https://github.com/theskumar/python-dotenv\"><strong>python-dotenv</strong> library</a>. This gets you started:</p><pre><code class=\"language-python\">from dotenv import load_dotenv\nfrom pathlib import Path\n\nload_dotenv(verbose=True)\n\nenv_path = Path('.') / '.env'\nload_dotenv(dotenv_path=env_path)\n</code></pre>\n<p>After that, it's a matter of setting variables in Python to values you extract from <code>.env</code>:</p><pre><code class=\"language-python\">import os\nSECRET_KEY = os.getenv(&quot;EMAIL&quot;)\nDATABASE_PASSWORD = os.getenv(&quot;DATABASE_PASSWORD&quot;)\n</code></pre>\n<h2 id=\"so-yeah-basically-just-use-what-you-want\">So Yeah, Basically Just Use What You Want</h2><p>Clearly there are plenty of ways to set environment and project variables in Python. We could spend all day investigating the nuances of each and how their accompanying Python configuration class should be structured, but we've got apps to build. </p><p>Besides, I need to go reflect on my life after writing a thousand words about loading variables in Python.</p>","url":"https://hackersandslackers.com/simplify-your-python-projects-configuration/","uuid":"48fb64b7-b9f2-4605-ac1f-c1c45ffc5964","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5bff941deae98c3b9d4c25f4"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867373f","title":"Hacking and Hustling: Full User Auth Without Writing Code","slug":"handling-user-accounts-with-zero-code","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/11/saas-2@2x.jpg","excerpt":"Weasle your way through coding by exploiting freemium software.","custom_excerpt":"Weasle your way through coding by exploiting freemium software.","created_at_pretty":"27 November, 2018","published_at_pretty":"28 November, 2018","updated_at_pretty":"15 February, 2019","created_at":"2018-11-27T15:02:27.000-05:00","published_at":"2018-11-28T07:24:00.000-05:00","updated_at":"2019-02-15T12:45:41.000-05:00","meta_title":"Hacking and Hustling: Full User Auth Without Writing Code | Hackers and Slackers","meta_description":"Today we weasel our way through coding by exploiting freemium software: Apisentris, Byepass, Getform, & Zapier.","og_description":"Today we weasel our way through coding by exploiting freemium software: Apisentris, Byepass, Getform, & Zapier.","og_image":"https://hackersandslackers.com/content/images/2018/11/saas-2@2x.jpg","og_title":"Hacking and Hustling: Full User Auth Without Writing Code","twitter_description":"Today we weasel our way through coding by exploiting freemium software: Apisentris, Byepass, Getform, & Zapier.","twitter_image":"https://hackersandslackers.com/content/images/2018/11/saas-2@2x.jpg","twitter_title":"Hacking and Hustling: Full User Auth Without Writing Code","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"SaaS Products","slug":"saas","description":"Third-party products and services we’ve discovered to be diamonds in the rough. These are products we’ve included in our stack based on price and value add.","feature_image":null,"meta_description":"Third-party products and services we’ve discovered to be diamonds in the rough. These are products we’ve included in our stack based on price and value add.","meta_title":"Our Picks: SaaS Products | Hackers and Slackers","visibility":"public"},"tags":[{"name":"SaaS Products","slug":"saas","description":"Third-party products and services we’ve discovered to be diamonds in the rough. These are products we’ve included in our stack based on price and value add.","feature_image":null,"meta_description":"Third-party products and services we’ve discovered to be diamonds in the rough. These are products we’ve included in our stack based on price and value add.","meta_title":"Our Picks: SaaS Products | Hackers and Slackers","visibility":"public"},{"name":"Automation","slug":"automation","description":"General automation of systems and software on a macro level. Learn to automate manual processes suitable for enterprises.","feature_image":null,"meta_description":"General automation of systems and software on a macro level. Learn to automate manual processes suitable for enterprises.","meta_title":"Automation | Hackers and Slackers","visibility":"public"}],"plaintext":"The midlife crisis is a striking phenomenon common and equally inescapable to\nall of us. I’m fairly certain I’ve come to a turning point in my life where I\ntoo must admit I will never be cool again. I know this because I check Product\nHunt on a daily basis, and I thoroughly enjoy it.\n\nI’d estimate about 80% of things featured on Product Hunt are hilariously\nworthless parodies of Silicon Valley itself, real predators live for the hunt.\nThey hunt on. At least that’s what Eric Thomas told me during a podcast\n[https://www.youtube.com/watch?v=fybi42dJHD4]  on my way to the gym one morning.\nOn this fine day, my friends, the Lion has risen.\n\nWe’re in a unique period in human history where the Middle Class simply no\nlonger exists. This is great if you’re not an enterprise software giant because\nthat means all SaaS pricing models have two modes: free, or ten billion jillion\ngazillion dollars. Sometimes when we persist, those free services might align to\nlet us do something crazy. Handling user signups, authentication, sessions, and\nso forth for zero work and zero dollars is indeed crazy.\n\nWe’re going to leverage four products at once to achieve this amazing feat of\nlaziness. While each of them may be mediocre in their own right, the whole is\nsurely greater than the sum of its parts.\n\nApisentris [https://apisentris.com]: Generate a REST API for any DB Instantly\nYou get an endpoint! And YOU get an endpoint!This is a product we've briefly\ntouched on in the past: the gist is that granting Apisentris  to your database\nwill generate a full-on API which can modify any record of any table in any way\nyou can imagine. Yes, that includes users.\n\nByepass [https://byepass.co]: User Logins Without Passwords\nGood luck trying to white-label this for under 20k.Byepass is a relatively new\nproduct- if you haven’t Googled them yet, you’re in for a treat of search\nresults. Let this be a lesson in SEO. \n\nThe premise of this service is to phase out and destroy plaintext passwords.\nConsidering the standard of modern-day 2FA, it’s not too hard of a sell… the\nonly thing that truly sucks about the product is their branded confirmation\nemails (and the dreaded“contact us for pricing” estimate when considering a\nwhite label option). \n\nBesides saving the trouble of passwords, there is a key upside to Byepass\nspecifically for us: since passwords are no longer needed in user sign-ups,\nthere’s no need to pass the form along to a backend, where a framework is\nexpecting to encrypt the blah blah blah. Give it a rest, this is my Slacking\nday.\n\nGetform.io [https://getform.io/]: The Cleanest Drop-in Form Solution\nCapturing forms without doing the form work.Getform.io  started off with a strong goal in mind: to allow idiots who host\nWordpress sites collect user information via forms… while most likely having\nzero clue as to how to code or even use a CMS. When submitted, form results are\nsent to an endpoint on the Getform side. From there, Getform already tips you\noff on what you should do next: they name drop Zapier, and they’re ready to\nparty.\n\nZapier [https://zapier.com]: You Already Know the Deal\nI've simulated my entire personality in a collection of zaps.We all know the\ndeal with Zapier by now: it’s the glue in any Slacker’s arsenal. I can already\nhear the neckbeards wailing in agony at the sheer mention of Zapier. I get it,\nyou’re insisting that Zapier is a collection of API endpoints cleverly pointed\ntowards one another for convenience, and you could totally build that stuff\nyourself.\n\nTo set the record straight, you’re not  going to code anything Zapier automates\non its own. If you spent that much time on menial tasks, you’d be a developer\nvalued at minimum wage. You’re not building shit- you’re playing Rocket league\nwhen you get home from work like the rest of us.\n\nStep 1: Create a Signup Form\nThis part of the process is pretty easy considering all you need to do is copy\nand paste Getform's boilerplate from the first page you see when you log in:\n\n<form action=\"https://getform.io/f/54775468-578-45765718d-567-5474657567564\" method=\"POST\">\n    <input type=\"text\" name=\"name\">\n    <input type=\"email\" name=\"email\">\n    <input type=\"tel\" name=\"tel\">\n    <button type=\"submit\">Send</button>\n</form>\n\nStep 2: Get Zapped\nNow it’s game time. I just as easily could have named this post “dope shit you\ncan do with Zapier without paying the Ludacris 50-dollar per month free to\nincorporate pipelines.” I still haven’t ruled it out, really. Here’s what’s\nwaiting for you:\n\nchain chain chaaaaiiinnnn…As you might imagine, we're getting some pretty basic\ninput from this signup form: in my case, simply username  and password. Before\nwe go saving two values to a weak af database table somewhere, let's add a\nlittle spice to the equation in the JavaScript step.\n\nGive the People What They Want\nWhat do people want? pictures of their own dumb faces, mostly! Luckily, there's\na service called Gravatar [https://en.gravatar.com/]  which might just be able\nto provide us with just that. Sometimes when you sign up for a service, you\nmight notice they already have your mugshot on file. At some point, you signed\nup for a service that associates your email address with a profile picture,\nsimply by applying an md5  hash to your email.\n\nWe're going to do the same for our users.\n\nSet up your input data:\n\nSo far so good!Great, now all that's left is encrypting that email address in\nvanilla Javascript thanks to Zapiers inability to handle imports:\n\nvar MD5 = function(d){var result = M(V(Y(X(d),8*d.length)));return result.toLowerCase()};function M(d){for(var _,m=\"0123456789ABCDEF\",f=\"\",r=0;r<d.length;r++)_=d.charCodeAt(r),f+=m.charAt(_>>>4&15)+m.charAt(15&_);return f}function X(d){for(var _=Array(d.length>>2),m=0;m<_.length;m++)_[m]=0;for(m=0;m<8*d.length;m+=8)_[m>>5]|=(255&d.charCodeAt(m/8))<<m%32;return _}function V(d){for(var _=\"\",m=0;m<32*d.length;m+=8)_+=String.fromCharCode(d[m>>5]>>>m%32&255);return _}function Y(d,_){d[_>>5]|=128<<_%32,d[14+(_+64>>>9<<4)]=_;for(var m=1732584193,f=-271733879,r=-1732584194,i=271733878,n=0;n<d.length;n+=16){var h=m,t=f,g=r,e=i;f=md5_ii(f=md5_ii(f=md5_ii(f=md5_ii(f=md5_hh(f=md5_hh(f=md5_hh(f=md5_hh(f=md5_gg(f=md5_gg(f=md5_gg(f=md5_gg(f=md5_ff(f=md5_ff(f=md5_ff(f=md5_ff(f,r=md5_ff(r,i=md5_ff(i,m=md5_ff(m,f,r,i,d[n+0],7,-680876936),f,r,d[n+1],12,-389564586),m,f,d[n+2],17,606105819),i,m,d[n+3],22,-1044525330),r=md5_ff(r,i=md5_ff(i,m=md5_ff(m,f,r,i,d[n+4],7,-176418897),f,r,d[n+5],12,1200080426),m,f,d[n+6],17,-1473231341),i,m,d[n+7],22,-45705983),r=md5_ff(r,i=md5_ff(i,m=md5_ff(m,f,r,i,d[n+8],7,1770035416),f,r,d[n+9],12,-1958414417),m,f,d[n+10],17,-42063),i,m,d[n+11],22,-1990404162),r=md5_ff(r,i=md5_ff(i,m=md5_ff(m,f,r,i,d[n+12],7,1804603682),f,r,d[n+13],12,-40341101),m,f,d[n+14],17,-1502002290),i,m,d[n+15],22,1236535329),r=md5_gg(r,i=md5_gg(i,m=md5_gg(m,f,r,i,d[n+1],5,-165796510),f,r,d[n+6],9,-1069501632),m,f,d[n+11],14,643717713),i,m,d[n+0],20,-373897302),r=md5_gg(r,i=md5_gg(i,m=md5_gg(m,f,r,i,d[n+5],5,-701558691),f,r,d[n+10],9,38016083),m,f,d[n+15],14,-660478335),i,m,d[n+4],20,-405537848),r=md5_gg(r,i=md5_gg(i,m=md5_gg(m,f,r,i,d[n+9],5,568446438),f,r,d[n+14],9,-1019803690),m,f,d[n+3],14,-187363961),i,m,d[n+8],20,1163531501),r=md5_gg(r,i=md5_gg(i,m=md5_gg(m,f,r,i,d[n+13],5,-1444681467),f,r,d[n+2],9,-51403784),m,f,d[n+7],14,1735328473),i,m,d[n+12],20,-1926607734),r=md5_hh(r,i=md5_hh(i,m=md5_hh(m,f,r,i,d[n+5],4,-378558),f,r,d[n+8],11,-2022574463),m,f,d[n+11],16,1839030562),i,m,d[n+14],23,-35309556),r=md5_hh(r,i=md5_hh(i,m=md5_hh(m,f,r,i,d[n+1],4,-1530992060),f,r,d[n+4],11,1272893353),m,f,d[n+7],16,-155497632),i,m,d[n+10],23,-1094730640),r=md5_hh(r,i=md5_hh(i,m=md5_hh(m,f,r,i,d[n+13],4,681279174),f,r,d[n+0],11,-358537222),m,f,d[n+3],16,-722521979),i,m,d[n+6],23,76029189),r=md5_hh(r,i=md5_hh(i,m=md5_hh(m,f,r,i,d[n+9],4,-640364487),f,r,d[n+12],11,-421815835),m,f,d[n+15],16,530742520),i,m,d[n+2],23,-995338651),r=md5_ii(r,i=md5_ii(i,m=md5_ii(m,f,r,i,d[n+0],6,-198630844),f,r,d[n+7],10,1126891415),m,f,d[n+14],15,-1416354905),i,m,d[n+5],21,-57434055),r=md5_ii(r,i=md5_ii(i,m=md5_ii(m,f,r,i,d[n+12],6,1700485571),f,r,d[n+3],10,-1894986606),m,f,d[n+10],15,-1051523),i,m,d[n+1],21,-2054922799),r=md5_ii(r,i=md5_ii(i,m=md5_ii(m,f,r,i,d[n+8],6,1873313359),f,r,d[n+15],10,-30611744),m,f,d[n+6],15,-1560198380),i,m,d[n+13],21,1309151649),r=md5_ii(r,i=md5_ii(i,m=md5_ii(m,f,r,i,d[n+4],6,-145523070),f,r,d[n+11],10,-1120210379),m,f,d[n+2],15,718787259),i,m,d[n+9],21,-343485551),m=safe_add(m,h),f=safe_add(f,t),r=safe_add(r,g),i=safe_add(i,e)}return Array(m,f,r,i)}function md5_cmn(d,_,m,f,r,i){return safe_add(bit_rol(safe_add(safe_add(_,d),safe_add(f,i)),r),m)}function md5_ff(d,_,m,f,r,i,n){return md5_cmn(_&m|~_&f,d,_,r,i,n)}function md5_gg(d,_,m,f,r,i,n){return md5_cmn(_&f|m&~f,d,_,r,i,n)}function md5_hh(d,_,m,f,r,i,n){return md5_cmn(_^m^f,d,_,r,i,n)}function md5_ii(d,_,m,f,r,i,n){return md5_cmn(m^(_|~f),d,_,r,i,n)}function safe_add(d,_){var m=(65535&d)+(65535&_);return(d>>16)+(_>>16)+(m>>16)<<16|65535&m}function bit_rol(d,_){return d<<_|d>>>32-_}\n\nvar value = inputData.email;\n\nvar grav = MD5(value);\n\noutput = {username: inputData.username, email: inputData.email, gravatar: grav};\n\n\nOh yes, friend. It's like that.\n\nStep 3: Create Records in Our Database via the API\nCould we enter records into MySQL via a direct connection? Sure, if you like\nwasting time creating SSL certs for your lame boring DB connections. That’s 5\nminutes that could be spent playing Rocket League.\n\nInstead, consider the following alternative of passing a JSON object to a\nrelational database and having it turn out just fine. It feels like we’re\nprancing through a field of freemium software Unicorns- just like in my dreams:\n\nHave fun with your .pem files, losers.Step 4: Let There be Confirmation Emails\nAll that's left is welcoming our users to our family with a handwritten, generic\ntemplated email courtesy of Byepass.\n\nDon’t worry about these publicly visible email addresses btw: they’re all bots.\nIn case you're ignoring the documentation completely (understandable), our last\nrequest is a POST request to https://byepass.co/redirect. In fact, here- just\ntake the docs:\n\n\n--------------------------------------------------------------------------------\n\nEndpoint: https://byepass.co/redirect\n\nMethod: GET or POST\n\nHeaders: {\"Content-Type: application/x-www-form-urlencoded\"}  \n\nRequest Variables:\n * identifier  (email address)\n * block_proxy  (BOOL 0 for to no restriction, 1 to block verifications from\n   known proxies) (Paid accounts only)\n * key  (Byepass app key)\n\n\n--------------------------------------------------------------------------------\n\nWe've Finally Made It\nWe may never be the spring chickens we once were, but we all experience chills\nof envy when we watch those reality TV shows featuring Midwestern people with\nmental illnesses hoard coupons and score the sickest grocery store heists ever\nto air television legally. That's who we are now: we're the crazy, deal-seeking,\nthrill-chasing coupon ladies of Silicon Valley. \n\nAll I know is it feels great to not work myself further out of the debt I\naccrued while attempting to offset the crippling, burnt-out depression bestowed\nupon us by the technology industry. For this moment, life is fine. Finally.","html":"<p>The midlife crisis is a striking phenomenon common and equally inescapable to all of us. I’m fairly certain I’ve come to a turning point in my life where I too must admit I will never be cool again. I know this because I check Product Hunt on a daily basis, and I thoroughly enjoy it.</p><p>I’d estimate about 80% of things featured on Product Hunt are hilariously worthless parodies of Silicon Valley itself, real predators live for the hunt. They hunt on. At least that’s what <a href=\"https://www.youtube.com/watch?v=fybi42dJHD4\" rel=\"noopener\">Eric Thomas told me during a podcast</a> on my way to the gym one morning. On this fine day, my friends, the Lion has risen.</p><p>We’re in a unique period in human history where the Middle Class simply no longer exists. This is great if you’re not an enterprise software giant because that means all SaaS pricing models have two modes: free, or ten billion jillion gazillion dollars. Sometimes when we persist, those free services might align to let us do something crazy. Handling user signups, authentication, sessions, and so forth for zero work and zero dollars is indeed crazy.</p><p>We’re going to leverage four products at once to achieve this amazing feat of laziness. While each of them may be mediocre in their own right, the whole is surely greater than the sum of its parts.</p><h2 id=\"apisentris-generate-a-rest-api-for-any-db-instantly\"><a href=\"https://apisentris.com\">Apisentris</a>: Generate a REST API for any DB Instantly</h2><figure class=\"kg-card kg-image-card\"><img src=\"http://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-27-at-7.15.49-PM_o_o.png\" class=\"kg-image\"><figcaption>You get an endpoint! And YOU get an endpoint!</figcaption></figure><p>This is a product we've briefly touched on in the past: the gist is that granting <strong>Apisentris</strong> to your database will generate a full-on API which can modify any record of any table in any way you can imagine. Yes, that includes users.</p><h2 id=\"byepass-user-logins-without-passwords\"><a href=\"https://byepass.co\">Byepass</a>: User Logins Without Passwords</h2><figure class=\"kg-card kg-image-card\"><img src=\"http://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-27-at-7.15.04-PM_o_o.png\" class=\"kg-image\"><figcaption><em>Good luck trying to white-label this for under 20k.</em></figcaption></figure><p>Byepass is a relatively new product- if you haven’t Googled them yet, you’re in for a treat of search results. Let this be a lesson in SEO. </p><p>The premise of this service is to phase out and destroy plaintext passwords. Considering the standard of modern-day 2FA, it’s not too hard of a sell… the only thing that truly sucks about the product is their branded confirmation emails (and the dreaded“contact us for pricing” estimate when considering a white label option). </p><p>Besides saving the trouble of passwords, there is a key upside to Byepass specifically for us: since passwords are no longer needed in user sign-ups, there’s no need to pass the form along to a backend, where a framework is expecting to encrypt the blah blah blah. Give it a rest, this is my Slacking day.</p><h2 id=\"getform-io-the-cleanest-drop-in-form-solution\"><a href=\"https://getform.io/\">Getform.io</a>: The Cleanest Drop-in Form Solution</h2><figure class=\"kg-card kg-image-card\"><img src=\"http://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-12-26-at-6.59.46-PM.png\" class=\"kg-image\"><figcaption>Capturing forms without doing the form work.</figcaption></figure><p><strong>Getform.io</strong> started off with a strong goal in mind: to allow idiots who host Wordpress sites collect user information via forms… while most likely having zero clue as to how to code or even use a CMS. When submitted, form results are sent to an endpoint on the Getform side. From there, Getform already tips you off on what you should do next: they name drop Zapier, and they’re ready to party.</p><h2 id=\"zapier-you-already-know-the-deal\"><a href=\"https://zapier.com\">Zapier</a>: You Already Know the Deal</h2><figure class=\"kg-card kg-image-card\"><img src=\"http://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-27-at-7.35.34-PM_o_o.png\" class=\"kg-image\"><figcaption>I've simulated my entire personality in a collection of zaps.</figcaption></figure><p>We all know the deal with Zapier by now: it’s the glue in any Slacker’s arsenal. I can already hear the neckbeards wailing in agony at the sheer mention of Zapier. I get it, you’re insisting that Zapier is a collection of API endpoints cleverly pointed towards one another for convenience, and you could totally build that stuff yourself.</p><p>To set the record straight, you’re <em>not</em> going to code anything Zapier automates on its own. If you spent that much time on menial tasks, you’d be a developer valued at minimum wage. You’re not building shit- you’re playing Rocket league when you get home from work like the rest of us.</p><h2 id=\"step-1-create-a-signup-form\">Step 1: Create a Signup Form</h2><p>This part of the process is pretty easy considering all you need to do is copy and paste Getform's boilerplate from the first page you see when you log in:</p><pre><code>&lt;form action=\"https://getform.io/f/54775468-578-45765718d-567-5474657567564\" method=\"POST\"&gt;\n    &lt;input type=\"text\" name=\"name\"&gt;\n    &lt;input type=\"email\" name=\"email\"&gt;\n    &lt;input type=\"tel\" name=\"tel\"&gt;\n    &lt;button type=\"submit\"&gt;Send&lt;/button&gt;\n&lt;/form&gt;</code></pre><h2 id=\"step-2-get-zapped\">Step 2: Get Zapped</h2><p>Now it’s game time. I just as easily could have named this post “dope shit you can do with Zapier without paying the Ludacris 50-dollar per month free to incorporate pipelines.” I still haven’t ruled it out, really. Here’s what’s waiting for you:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-27-at-7.43.18-PM_o_o.png\" class=\"kg-image\"><figcaption>chain chain chaaaaiiinnnn…</figcaption></figure><p>As you might imagine, we're getting some pretty basic input from this signup form: in my case, simply <strong>username</strong> and <strong>password</strong>. Before we go saving two values to a weak af database table somewhere, let's add a little spice to the equation in the JavaScript step.</p><h3 id=\"give-the-people-what-they-want\">Give the People What They Want</h3><p>What do people want? pictures of their own dumb faces, mostly! Luckily, there's a service called <a href=\"https://en.gravatar.com/\">Gravatar</a> which might just be able to provide us with just that. Sometimes when you sign up for a service, you might notice they already have your mugshot on file. At some point, you signed up for a service that associates your email address with a profile picture, simply by applying an <strong>md5</strong> hash to your email.</p><p>We're going to do the same for our users.</p><p>Set up your input data:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-12-26-at-7.03.30-PM.png\" class=\"kg-image\"><figcaption>So far so good!</figcaption></figure><p>Great, now all that's left is encrypting that email address in vanilla Javascript thanks to Zapiers inability to handle imports:</p><pre><code class=\"language-javascript\">var MD5 = function(d){var result = M(V(Y(X(d),8*d.length)));return result.toLowerCase()};function M(d){for(var _,m=&quot;0123456789ABCDEF&quot;,f=&quot;&quot;,r=0;r&lt;d.length;r++)_=d.charCodeAt(r),f+=m.charAt(_&gt;&gt;&gt;4&amp;15)+m.charAt(15&amp;_);return f}function X(d){for(var _=Array(d.length&gt;&gt;2),m=0;m&lt;_.length;m++)_[m]=0;for(m=0;m&lt;8*d.length;m+=8)_[m&gt;&gt;5]|=(255&amp;d.charCodeAt(m/8))&lt;&lt;m%32;return _}function V(d){for(var _=&quot;&quot;,m=0;m&lt;32*d.length;m+=8)_+=String.fromCharCode(d[m&gt;&gt;5]&gt;&gt;&gt;m%32&amp;255);return _}function Y(d,_){d[_&gt;&gt;5]|=128&lt;&lt;_%32,d[14+(_+64&gt;&gt;&gt;9&lt;&lt;4)]=_;for(var m=1732584193,f=-271733879,r=-1732584194,i=271733878,n=0;n&lt;d.length;n+=16){var h=m,t=f,g=r,e=i;f=md5_ii(f=md5_ii(f=md5_ii(f=md5_ii(f=md5_hh(f=md5_hh(f=md5_hh(f=md5_hh(f=md5_gg(f=md5_gg(f=md5_gg(f=md5_gg(f=md5_ff(f=md5_ff(f=md5_ff(f=md5_ff(f,r=md5_ff(r,i=md5_ff(i,m=md5_ff(m,f,r,i,d[n+0],7,-680876936),f,r,d[n+1],12,-389564586),m,f,d[n+2],17,606105819),i,m,d[n+3],22,-1044525330),r=md5_ff(r,i=md5_ff(i,m=md5_ff(m,f,r,i,d[n+4],7,-176418897),f,r,d[n+5],12,1200080426),m,f,d[n+6],17,-1473231341),i,m,d[n+7],22,-45705983),r=md5_ff(r,i=md5_ff(i,m=md5_ff(m,f,r,i,d[n+8],7,1770035416),f,r,d[n+9],12,-1958414417),m,f,d[n+10],17,-42063),i,m,d[n+11],22,-1990404162),r=md5_ff(r,i=md5_ff(i,m=md5_ff(m,f,r,i,d[n+12],7,1804603682),f,r,d[n+13],12,-40341101),m,f,d[n+14],17,-1502002290),i,m,d[n+15],22,1236535329),r=md5_gg(r,i=md5_gg(i,m=md5_gg(m,f,r,i,d[n+1],5,-165796510),f,r,d[n+6],9,-1069501632),m,f,d[n+11],14,643717713),i,m,d[n+0],20,-373897302),r=md5_gg(r,i=md5_gg(i,m=md5_gg(m,f,r,i,d[n+5],5,-701558691),f,r,d[n+10],9,38016083),m,f,d[n+15],14,-660478335),i,m,d[n+4],20,-405537848),r=md5_gg(r,i=md5_gg(i,m=md5_gg(m,f,r,i,d[n+9],5,568446438),f,r,d[n+14],9,-1019803690),m,f,d[n+3],14,-187363961),i,m,d[n+8],20,1163531501),r=md5_gg(r,i=md5_gg(i,m=md5_gg(m,f,r,i,d[n+13],5,-1444681467),f,r,d[n+2],9,-51403784),m,f,d[n+7],14,1735328473),i,m,d[n+12],20,-1926607734),r=md5_hh(r,i=md5_hh(i,m=md5_hh(m,f,r,i,d[n+5],4,-378558),f,r,d[n+8],11,-2022574463),m,f,d[n+11],16,1839030562),i,m,d[n+14],23,-35309556),r=md5_hh(r,i=md5_hh(i,m=md5_hh(m,f,r,i,d[n+1],4,-1530992060),f,r,d[n+4],11,1272893353),m,f,d[n+7],16,-155497632),i,m,d[n+10],23,-1094730640),r=md5_hh(r,i=md5_hh(i,m=md5_hh(m,f,r,i,d[n+13],4,681279174),f,r,d[n+0],11,-358537222),m,f,d[n+3],16,-722521979),i,m,d[n+6],23,76029189),r=md5_hh(r,i=md5_hh(i,m=md5_hh(m,f,r,i,d[n+9],4,-640364487),f,r,d[n+12],11,-421815835),m,f,d[n+15],16,530742520),i,m,d[n+2],23,-995338651),r=md5_ii(r,i=md5_ii(i,m=md5_ii(m,f,r,i,d[n+0],6,-198630844),f,r,d[n+7],10,1126891415),m,f,d[n+14],15,-1416354905),i,m,d[n+5],21,-57434055),r=md5_ii(r,i=md5_ii(i,m=md5_ii(m,f,r,i,d[n+12],6,1700485571),f,r,d[n+3],10,-1894986606),m,f,d[n+10],15,-1051523),i,m,d[n+1],21,-2054922799),r=md5_ii(r,i=md5_ii(i,m=md5_ii(m,f,r,i,d[n+8],6,1873313359),f,r,d[n+15],10,-30611744),m,f,d[n+6],15,-1560198380),i,m,d[n+13],21,1309151649),r=md5_ii(r,i=md5_ii(i,m=md5_ii(m,f,r,i,d[n+4],6,-145523070),f,r,d[n+11],10,-1120210379),m,f,d[n+2],15,718787259),i,m,d[n+9],21,-343485551),m=safe_add(m,h),f=safe_add(f,t),r=safe_add(r,g),i=safe_add(i,e)}return Array(m,f,r,i)}function md5_cmn(d,_,m,f,r,i){return safe_add(bit_rol(safe_add(safe_add(_,d),safe_add(f,i)),r),m)}function md5_ff(d,_,m,f,r,i,n){return md5_cmn(_&amp;m|~_&amp;f,d,_,r,i,n)}function md5_gg(d,_,m,f,r,i,n){return md5_cmn(_&amp;f|m&amp;~f,d,_,r,i,n)}function md5_hh(d,_,m,f,r,i,n){return md5_cmn(_^m^f,d,_,r,i,n)}function md5_ii(d,_,m,f,r,i,n){return md5_cmn(m^(_|~f),d,_,r,i,n)}function safe_add(d,_){var m=(65535&amp;d)+(65535&amp;_);return(d&gt;&gt;16)+(_&gt;&gt;16)+(m&gt;&gt;16)&lt;&lt;16|65535&amp;m}function bit_rol(d,_){return d&lt;&lt;_|d&gt;&gt;&gt;32-_}\n\nvar value = inputData.email;\n\nvar grav = MD5(value);\n\noutput = {username: inputData.username, email: inputData.email, gravatar: grav};\n</code></pre>\n<p>Oh yes, friend. It's like that.</p><h2 id=\"step-3-create-records-in-our-database-via-the-api\">Step 3: Create Records in Our Database via the API</h2><p>Could we enter records into MySQL via a direct connection? Sure, if you like wasting time creating SSL certs for your lame boring DB connections. That’s 5 minutes that could be spent playing Rocket League.</p><p>Instead, consider the following alternative of passing a JSON object to a relational database and having it turn out just fine. It feels like we’re prancing through a field of freemium software Unicorns- just like in my dreams:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-27-at-7.59.37-PM_o_o.png\" class=\"kg-image\"><figcaption>Have fun with your .pem files, losers.</figcaption></figure><h2 id=\"step-4-let-there-be-confirmation-emails\">Step 4: Let There be Confirmation Emails</h2><p>All that's left is welcoming our users to our family with a handwritten, generic templated email courtesy of Byepass.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-12-13-at-11.02.09-PM_o.png\" class=\"kg-image\"><figcaption>Don’t worry about these publicly visible email addresses btw: they’re all bots.</figcaption></figure><p>In case you're ignoring the documentation completely (understandable), our last request is a POST request to <strong>https://byepass.co/redirect. </strong>In fact, here- just take the docs:</p><hr><p><strong>Endpoint</strong>: <a href=\"https://byepass.co/redirect\">https://byepass.co/redirect</a></p><p><strong>Method</strong>: GET or POST</p><p><strong>Headers: </strong>{\"Content-Type: application/x-www-form-urlencoded\"}<strong> </strong></p><h3 id=\"request-variables-\">Request Variables:</h3><ul><li><strong>identifier</strong> (email address)</li><li><strong>block_proxy</strong> (BOOL 0 for to no restriction, 1 to block verifications from known proxies) (Paid accounts only)</li><li><strong>key</strong> (Byepass app key)</li></ul><hr><h2 id=\"we-ve-finally-made-it\">We've Finally Made It</h2><p>We may never be the spring chickens we once were, but we all experience chills of envy when we watch those reality TV shows featuring Midwestern people with mental illnesses hoard coupons and score the sickest grocery store heists ever to air television legally. That's who we are now: we're the crazy, deal-seeking, thrill-chasing coupon ladies of Silicon Valley. </p><p>All I know is it feels great to not work myself further out of the debt I accrued while attempting to offset the crippling, burnt-out depression bestowed upon us by the technology industry. For this moment, life is fine. Finally.</p>","url":"https://hackersandslackers.com/handling-user-accounts-with-zero-code/","uuid":"004ac673-36dd-47fe-ba74-df134235a200","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5bfda2d3eae98c3b9d4c25d8"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c9","title":"MongoDB Stitch Serverless Functions","slug":"mongodb-stitch-serverless-functions","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/stitch3@2x.jpg","excerpt":"A crash course in MongoDB Stitch serverless functions: the bread and butter of MongoDB Cloud.","custom_excerpt":"A crash course in MongoDB Stitch serverless functions: the bread and butter of MongoDB Cloud.","created_at_pretty":"06 August, 2018","published_at_pretty":"26 November, 2018","updated_at_pretty":"05 April, 2019","created_at":"2018-08-06T19:35:37.000-04:00","published_at":"2018-11-26T08:00:00.000-05:00","updated_at":"2019-04-04T21:42:58.000-04:00","meta_title":"Using Serverless Functions in MongoDB Stitch  | Hackers And Slackers","meta_description":"You have a database, and you want to get data out of it. MongoDB Stitch can achieve this without building an API and can do it securely via frontend code.","og_description":"A crash course in MongoDB Stitch serverless functions: the bread and butter of MongoDB Cloud.\n","og_image":"https://hackersandslackers.com/content/images/2018/08/stitch3@2x.jpg","og_title":"MongoDB Stitch Serverless Functions","twitter_description":"A crash course in MongoDB Stitch serverless functions: the bread and butter of MongoDB Cloud.\n","twitter_image":"https://hackersandslackers.com/content/images/2018/08/stitch3@2x.jpg","twitter_title":"MongoDB Stitch Serverless Functions","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"At times, I've found my opinion of MongoDB Atlas  and MongoDB Stitch  to waver\nbetween two extremes. Sometimes I'm struck by the allure of a cloud which\nfundamentally disregards schemas (wooo no schema party!). Other times, such as\nwhen Mongo decides to upgrade to a new version and you find all your production\ninstances broken, I like the ecosystem a bit less. \n\nMy biggest qualm with MongoDB is poor documentation. The \"tutorials\" and sample\ncode seems hacked-together, unmaintained, and worst of all, inconsistent with\nitself. Reading through the docs seems to always end up with Mongo forcing\nTwilio down my throat my for some miserable reason. \n\nJust to illustrate how bad things can get, below are two totally sets of\ndocumentation for what is supposed to be the same product. Mongo's main\ndocumentation on the left frequently references the bastardized documentation on\nthe right. What is the documentation on the right? It's a collection of\nnonsense\nliving on an S3 bucket\n[https://s3.amazonaws.com/stitch-sdks/js/docs/4.0.0/index.html]  which lists the\nmethods black-boxed into Stitch, often with zero explanation on how to actually\nutilize functionality.\n\nWhich one is real? And WHY?!How frustrating is this? I've had email user\nauthentication \"working\" for weeks as far as Stitch's logs say, although not a\nsingle user has actually been registered in that time. Anyways, I digress.\n\nMaking a Serverless Function\nStitch Serverless functions are of course strictly Javascript (MongoDB abides by\nECMA2015 features). In your Stitch console, check out the \"functions\" link in\nthe left hand nav:\n\nGo ahead and create a new function.There are just a few things we need to\nspecify when creating a new function:\n\n * The name of the function (duh).\n * Whether or not the function can be accessed \"publicly\". A \"Private\" function\n   is the equivalent of a function that only accessible to the VPC it belongs to\n   (although technically MongoDB Cloud doesn't use this terminology).\n * A condition which needs to be met in order for the function to execute.\n\nHere's a screenshot of everything we just went over. Because whatever.Switch\nover to the function editor to start really F*&king Sh!t up.\n\nMongo's Serverless Function Editor\nWe can call a Serverless function in a number of ways, with one of those ways\nbeing directly from our frontend code. In this case, we're basically just taking\na Javascript function which could  live in our frontend codebase and moving it\nto the cloud, thus functions can be passed any number of arguments (just like a\nnormal function).\n\nLuckily for us, Mongo provides some commented out boilerplate code when creating\na new function, which gives us an idea of what we might want to use these\nfunctions for:\n\nexports = function(arg){\n  /*\n    Accessing application's values:\n    var x = context.values.get(\"value_name\");\n\n    Accessing a mongodb service:\n    var collection = context.services.get(\"mongodb-atlas\").db(\"dbname\").collection(\"coll_name\");\n    var doc = collection.findOne({owner_id: context.user.id});\n\n    To call other named functions:\n    var result = context.functions.execute(\"function_name\", arg1, arg2);\n\n    Try running in the console below.\n  */\n  return {arg: arg};\n};\n\n\nPay special attention to context.services  here. When using a serverless\nfunction to access MongoDB services such as our database or endpoints, we can\naccess these via context.services  along with whichever service we're trying to\nmess with.\n\nQuerying our Database Within a Function\nLet's grab a single record from a collection in our Atlas collection:\n\nexports = function(arg){\n      const mongodb = context.services.get(\"mongodb-atlas\");\n      const collection = mongodb.db(\"blog\").collection(\"authors\");\n      var result = collection.findOne({\"author\": arg});\n      return result;\n};\n\n\nWe use findOne here to return an object, whereas we'd probably use toArray  if\nwe'd be expecting multiple results. The query we're running is contained within \nfindOne({\"author\": arg}). Our function takes an argument and returns a record\nwhere the value matches the argument: this makes our functions highly reusable,\nof course.\n\nCalling Our Function via Our App\nAs a recap, you have the option of including Stitch in your app either via a\nlink to a script or by installing the appropriate NPM modules. It's preferable\nto do the latter, but for the sake of this post, my patience with dealing with\nJavascript's babel browserify webpack gulp yarn npm requires package-lock .env\npipify facepunch  ecosystem has reached its limit. \n\nFeel free to follow in my footsteps of worst practices by embedding stitch\ndirectly:\n\n<script src=\"https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js\"></script>\n\n\nAuthenticating Before Calling Functions\nBefore making queries or interacting with any serverless functions of any kind,\nwe need to authenticate a 'user' with the server; even if that user is an\nanonymous one (it's in our own best benefit to know which user crashed the\nserver, even if that 'users' is a random string of numbers). Because we allowed\nanonymous users to peruse through our data, this is easy:\n\n// Authenticates anonymous user\nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => {\n  console.log('logged in anonymously as user')\n});\n\n\nCalling our Function\nNow that that's done, we can call our function immediately after:\n\n// Authenticates anonymous user\nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => {\n  console.log('logged in anonymously as user')\n});\n\n// Calls function\nclient.callFunction(\"getUsers\", [\"{{author}}\"]).then(result => {\n  console.log(result)\n});\n\n\nOur function is called get users  and we're passing a single parameter of \n{{author}}. Even though one parameter is being passed, we pass parameters as\nlists as Mongo Serverless functions, as these functions are agnostic to what\nmight be coming their way.\n\nUsing Functions to Grab Stored Values\nLet's look at one more use case where calling a Stitch Serverless function might\ncome in handy.\n\nBack in the Stitch UI, check out the \"values\" tab in the left-hand nav. This is\na place where we can store constant values which should accessible through our\napplication, or even a place to retrieve secrets:\n\n2secret4uValues can only be retrieved by functions, and this would be a good\ntime to ensure those particular functions are marked \"private\" For instance, if\nyou have an API call you need to make, It would be best to create a function\nthat handles the logic of that API call, and within that function, invoke\nanother private function whose job it is simply to retrieve the key in question.\nMake sense?  Ah well, you'll figure it out.\n\nMaking a Serverless Function that Does Something\nAnyway, let's apply our knowledge of functions to actually do something. On our\nsite we currently use a third party Medium widget which fetches stories from a\nuser's Medium account. Here's how that would look in its entirety:\n\n<script src=\"https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js\"></script>\n\n<script src=\"https://medium-widget.pixelpoint.io/widget.js\"></script>\n\n<script>\nfunction createMediumCard(medium){\n  console.log('medium= ' + medium);\n  MediumWidget.Init({\n    renderTo: '#medium-widget',\n    params: {\n      \"resource\": 'https://medium.com/' + medium,\n      \"postsPerLine\": 1,\n      \"limit\": 3,\n      \"picture\": \"small\",\n      \"fields\": [\"description\", \"publishAt\"],\n      \"ratio\": \"square\"\n    }\n  })\n  $('#medium').css('display', 'block');\n}\n    \nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => {\n  console.log('logged in anonymously as user')\n});\n    \nclient.callFunction(\"getUsers\", [\"{{author}}\"]).then(result => {\n  console.log(result)\n});\n</script>\n\n\nNormally, \"resource\": medium,  would actually read the URL of the Medium profile\nwe're trying to embed. However, when you blog on a platform like Ghost which\nonly allows your authors to have either Facebook or Twitter profiles, we need to\nessentially go out of our way to build a second, nonintrusive database to pull\ndata from to add functionality like this. Yeah - I'll have to show you what MY\n\"stack\" looks like for a single blog theme some day. It's ridiculous.\n\nAnyway, that’s all I’ve got for now. I hope these ramblings help you assess\nMongoDB Cloud for yourself. No matter the provider, Enterprise Clouds target fat\nbudgets and are designed to rake in big money. It almost makes you wonder why\nsomebody would pay out of pocket for three of them just to write a stupid blog.","html":"<p>At times, I've found my opinion of <strong>MongoDB Atlas</strong> and <strong>MongoDB Stitch</strong> to waver between two extremes. Sometimes I'm struck by the allure of a cloud which fundamentally disregards schemas (wooo no schema party!). Other times, such as when Mongo decides to upgrade to a new version and you find all your production instances broken, I like the ecosystem a bit less. </p><p><strong>My biggest qualm with MongoDB is poor documentation. </strong>The \"tutorials\" and sample code seems hacked-together, unmaintained, and worst of all, inconsistent with itself. Reading through the docs seems to always end up with Mongo forcing Twilio down my throat my for some miserable reason. </p><p>Just to illustrate how bad things can get, below are two totally sets of documentation for what is supposed to be the same product. Mongo's main documentation on the left frequently references the bastardized documentation on the right. What is the documentation on the right? It's a <a href=\"https://s3.amazonaws.com/stitch-sdks/js/docs/4.0.0/index.html\">collection of nonsense living on an S3 bucket</a> which lists the methods black-boxed into Stitch, often with zero explanation on how to actually utilize functionality.</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/mongodocs.jpg\" class=\"kg-image\"><figcaption>Which one is real? And WHY?!</figcaption></figure><!--kg-card-end: image--><p>How frustrating is this? I've had email user authentication \"working\" for weeks as far as Stitch's logs say, although not a single user has actually been registered in that time. Anyways, I digress.</p><h2 id=\"making-a-serverless-function\">Making a Serverless Function</h2><p>Stitch Serverless functions are of course strictly Javascript (MongoDB abides by ECMA2015 features). In your Stitch console, check out the \"functions\" link in the left hand nav:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-25-at-10.28.24-PM.png\" class=\"kg-image\"><figcaption>Go ahead and create a new function.</figcaption></figure><!--kg-card-end: image--><p>There are just a few things we need to specify when creating a new function:</p><ul><li>The name of the function (duh).</li><li>Whether or not the function can be accessed \"publicly\". A \"Private\" function is the equivalent of a function that only accessible to the VPC it belongs to (although technically MongoDB Cloud doesn't use this terminology).</li><li>A condition which needs to be met in order for the function to execute.</li></ul><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-25-at-10.31.05-PM_o.png\" class=\"kg-image\"><figcaption>Here's a screenshot of everything we just went over. Because whatever.</figcaption></figure><!--kg-card-end: image--><p>Switch over to the function editor to start really F*&amp;king Sh!t up.</p><h2 id=\"mongo-s-serverless-function-editor\">Mongo's Serverless Function Editor</h2><p>We can call a Serverless function in a number of ways, with one of those ways being directly from our frontend code. In this case, we're basically just taking a Javascript function which <em>could</em> live in our frontend codebase and moving it to the cloud, thus functions can be passed any number of arguments (just like a normal function).</p><p>Luckily for us, Mongo provides some commented out boilerplate code when creating a new function, which gives us an idea of what we might want to use these functions for:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">exports = function(arg){\n  /*\n    Accessing application's values:\n    var x = context.values.get(&quot;value_name&quot;);\n\n    Accessing a mongodb service:\n    var collection = context.services.get(&quot;mongodb-atlas&quot;).db(&quot;dbname&quot;).collection(&quot;coll_name&quot;);\n    var doc = collection.findOne({owner_id: context.user.id});\n\n    To call other named functions:\n    var result = context.functions.execute(&quot;function_name&quot;, arg1, arg2);\n\n    Try running in the console below.\n  */\n  return {arg: arg};\n};\n</code></pre>\n<!--kg-card-end: markdown--><p>Pay special attention to <code>context.services</code> here. When using a serverless function to access MongoDB services such as our database or endpoints, we can access these via <code>context.services</code> along with whichever service we're trying to mess with.</p><h3 id=\"querying-our-database-within-a-function\">Querying our Database Within a Function</h3><p>Let's grab a single record from a collection in our Atlas collection:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">exports = function(arg){\n      const mongodb = context.services.get(&quot;mongodb-atlas&quot;);\n      const collection = mongodb.db(&quot;blog&quot;).collection(&quot;authors&quot;);\n      var result = collection.findOne({&quot;author&quot;: arg});\n      return result;\n};\n</code></pre>\n<!--kg-card-end: markdown--><p>We use <strong>findOne </strong>here to return an object, whereas we'd probably use <strong>toArray</strong> if we'd be expecting multiple results. The query we're running is contained within <code>findOne({\"author\": arg})</code>. Our function takes an argument and returns a record where the value matches the argument: this makes our functions highly reusable, of course.</p><h2 id=\"calling-our-function-via-our-app\">Calling Our Function via Our App</h2><p>As a recap, you have the option of including Stitch in your app either via a link to a script or by installing the appropriate NPM modules. It's preferable to do the latter, but for the sake of this post, my patience with dealing with Javascript's <strong>babel browserify webpack gulp yarn npm requires package-lock .env pipify facepunch</strong> ecosystem has reached its limit. </p><p>Feel free to follow in my footsteps of worst practices by embedding stitch directly:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">&lt;script src=&quot;https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js&quot;&gt;&lt;/script&gt;\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"authenticating-before-calling-functions\">Authenticating Before Calling Functions</h3><p>Before making queries or interacting with any serverless functions of any kind, we need to authenticate a 'user' with the server; even if that user is an anonymous one (it's in our own best benefit to know which user crashed the server, even if that 'users' is a random string of numbers). Because we allowed anonymous users to peruse through our data, this is easy:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">// Authenticates anonymous user\nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; {\n  console.log('logged in anonymously as user')\n});\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"calling-our-function\">Calling our Function</h3><p>Now that that's done, we can call our function immediately after:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">// Authenticates anonymous user\nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; {\n  console.log('logged in anonymously as user')\n});\n\n// Calls function\nclient.callFunction(&quot;getUsers&quot;, [&quot;{{author}}&quot;]).then(result =&gt; {\n  console.log(result)\n});\n</code></pre>\n<!--kg-card-end: markdown--><p>Our function is called <code>get users</code> and we're passing a single parameter of <code>{{author}}</code>. Even though one parameter is being passed, we pass parameters as lists as Mongo Serverless functions, as these functions are agnostic to what might be coming their way.</p><h2 id=\"using-functions-to-grab-stored-values\">Using Functions to Grab Stored Values</h2><p>Let's look at one more use case where calling a Stitch Serverless function might come in handy.</p><p>Back in the Stitch UI, check out the \"values\" tab in the left-hand nav. This is a place where we can store constant values which should accessible through our application, or even a place to retrieve secrets:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-26-at-8.04.25-AM_o.png\" class=\"kg-image\"><figcaption>2secret4u</figcaption></figure><!--kg-card-end: image--><p>Values can only be retrieved by functions, and this would be a good time to ensure those particular functions are marked \"private\" For instance, if you have an API call you need to make, It would be best to create a function that handles the logic of that API call, and within that function, invoke another private function whose job it is simply to retrieve the key in question. Make sense?  Ah well, you'll figure it out.</p><h2 id=\"making-a-serverless-function-that-does-something\">Making a Serverless Function that Does Something</h2><p>Anyway, let's apply our knowledge of functions to actually do something. On our site we currently use a third party Medium widget which fetches stories from a user's Medium account. Here's how that would look in its entirety:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">&lt;script src=&quot;https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js&quot;&gt;&lt;/script&gt;\n\n&lt;script src=&quot;https://medium-widget.pixelpoint.io/widget.js&quot;&gt;&lt;/script&gt;\n\n&lt;script&gt;\nfunction createMediumCard(medium){\n  console.log('medium= ' + medium);\n  MediumWidget.Init({\n    renderTo: '#medium-widget',\n    params: {\n      &quot;resource&quot;: 'https://medium.com/' + medium,\n      &quot;postsPerLine&quot;: 1,\n      &quot;limit&quot;: 3,\n      &quot;picture&quot;: &quot;small&quot;,\n      &quot;fields&quot;: [&quot;description&quot;, &quot;publishAt&quot;],\n      &quot;ratio&quot;: &quot;square&quot;\n    }\n  })\n  $('#medium').css('display', 'block');\n}\n    \nclient.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; {\n  console.log('logged in anonymously as user')\n});\n    \nclient.callFunction(&quot;getUsers&quot;, [&quot;{{author}}&quot;]).then(result =&gt; {\n  console.log(result)\n});\n&lt;/script&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>Normally, <code>\"resource\": medium,</code> would actually read the URL of the Medium profile we're trying to embed. However, when you blog on a platform like Ghost which only allows your authors to have either Facebook or Twitter profiles, we need to essentially go out of our way to build a second, nonintrusive database to pull data from to add functionality like this. Yeah - I'll have to show you what MY \"stack\" looks like for a single blog theme some day. It's ridiculous.</p><p>Anyway, that’s all I’ve got for now. I hope these ramblings help you assess MongoDB Cloud for yourself. No matter the provider, Enterprise Clouds target fat budgets and are designed to rake in big money. It almost makes you wonder why somebody would pay out of pocket for three of them just to write a stupid blog.</p>","url":"https://hackersandslackers.com/mongodb-stitch-serverless-functions/","uuid":"96e26ca1-02d4-41d6-afa8-db92b2e9c171","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b68db4904d65d1246ebd1eb"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673665","title":"Stitch's “Query Anywhere”: Executing Business Logic via Frontend","slug":"mongodb-stitch-query-anywhere","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/06/stitch5@2x.jpg","excerpt":"MongoDB Stitch vs the impossible: secure database queries via frontend JS.","custom_excerpt":"MongoDB Stitch vs the impossible: secure database queries via frontend JS.","created_at_pretty":"02 June, 2018","published_at_pretty":"23 November, 2018","updated_at_pretty":"05 January, 2019","created_at":"2018-06-02T12:07:57.000-04:00","published_at":"2018-11-23T07:00:00.000-05:00","updated_at":"2019-01-04T21:09:07.000-05:00","meta_title":"MongoDB Stitch \"Query Anywhere\" | Hackers and Slackers","meta_description":"Use MongoDB Stitch to query databases via Frontend code.","og_description":"Use MongoDB Stitch to query databases via Frontend code.","og_image":"https://hackersandslackers.com/content/images/2018/06/stitch5@2x.jpg","og_title":"MongoDB Stitch \"Query Anywhere\"","twitter_description":"Use MongoDB Stitch to query databases via Frontend code.","twitter_image":"https://hackersandslackers.com/content/images/2018/06/stitch5@2x.jpg","twitter_title":"MongoDB Stitch \"Query Anywhere\"","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"Some tools are simply the right tool for the job. I imagine this must have been\nthe thinking behind the wave of JSON-like NoSQL databases at their peak, and\neven so today. If we figure we’ll be passing information as JSON to an endpoint,\nto then have it structured into a schema, only to be promptly broken down again\nfor our request seconds later, if you will, it’s fair to question the\ncost-benefit of schemas in some cases. A lot of those cases cover the apps we\nbuild for ourselves: ones that let us do stupid things like spamming selfies or\nfilling the internet with vast mindless thoughts.\n\nMongoDB Atlas  is a hell of product in its own right, being a cloud NoSQL\ndatabase with the ability to execute queries similar to SQL JOINs, countless\naggregations, and more possibilities to work into a pipeline than I’ve even had\ntime to explore (we’ll get there). If you’ve ever been tasked to build endpoints\nfor yourself, chances are you already appreciate side-stepping the manual\none-to-one key association that comes with passing JSON to Lambda Functions or\nwhat-have-you.\n\nTake our situation at Hackers And Slackers, for instance. We’re running a Ghost\nblog, which is a young piece of software built by a non-profit organization:\nthis software is constantly being updated and improved, which means if we want\nto modify the logic of our Node app at all, our choices are:\n\n 1. Modify the Ghost source and refuse future updates\n 2. Merge our custom backend with Ghost changes in the event of an update\n 3. Build a third-party API using a platform such as AWS\n\nMongoDB Stitch  gives us a new fourth option: extend our app without all the\nrepetitive boilerplate.  I say extend  because it empowers us to build on top of\nthings which were previously black-boxed to us, such developing a theme atop a\nblogging system.\n\nCarrying on the Legacy\nMongoDB Stitch extends the philosophy of avoiding repetition. In a similar way\nto how NoSQL removed a pain point for many developers, Stitch wants you to keep\ndoing what you do best, which is probably writing NodeJS apps. Forever.\n\nIf I worked for Mongo, I’d sell the product like this:\n\nMongoDB Stitch empowers you to build powerful features without ever switching\ngears to the menial aspects of development.What I’m really saying is that MongoDB Stitch  is Google Firebase. Both products\ntarget the frontend  and mobile  developer markets, and both are very young and\nearly in fully achieving this goal. I’m watching the MongoDB product video for\nthe first time, and it feels like what I’ve assumed from using the product\naligns with their sell (good job on their part, I suppose):\n\nAs warm and uppity as that video is, Mongo has been rather bashful about their\nCloud. I'm guessing that has something to do with an IPO.\n\nOn the other hand, Google Firebase  has been tooting its own horn loudly for a\nyoung product, with a level of growth which feels almost reckless at times (I\nwon't get into it):\n\nAnyway, we're not here to compare. We're here to judge.\n\nGetting Started with a New Database\nFeel free to follow along by setting up a free tier cluster\n[https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/]. \n\nProper Mongo accounts are managed at https://cloud.mongodb.com  once created.\nThis landing dash has plenty of useful info and stats regarding the cluster\nitself. We'll also need to be sure that a database exists before we crate any\napps, otherwise we'll just be interacting with nothing.\n\nI highly  suggest using the MongoDB Compass  desktop app to connect to your your\ncluster. It's easy to download, and even saves you the time of entering\ncredentials by connecting with a copy+pasted URI:\n\nConnect with your database; emotionally.Within Compass, simply create a database\nand collection:\n\nIn MongoWorld, \"collections\" are the equivalent of \"tables\".Let's Get Stitched\nWith all that out of the way, head back to your account on the Mongo Cloud. Now\nour interest is entirely in the Stitch Apps  link on the left side nav:\n\nThere’s so much to explore!Create and name a new Stitch application, and we'll\nland on the \"getting started\" page. \n\nEnable anonymous auth & point to your collectionOnce we create our app, Stitch\nimmediately throws us in to a quick 101 of how to interact with our database.\nWe're going to use the exact example that Stitch gives us; it's important to\nhave the \"A-ha\" moment where everything comes together. \n\nBefore getting to any code, the only two things we need to do are:\n\n 1. Enable Anonymous Authentication: This is fancy language for creating a user\n    type where anybody who accesses our app can make queries\n 2. Pointing to our Mongo Collection: We need somewhere to store the data we'll\n    be messing with.\n\nConnecting Your App\nWe're going to copy and paste this code on to a page of our app. Once this is\nlive, visit the page and keep an eye on the console:\n\n<script src=\"https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js\"></script>\n\n<script>\n  const clientPromise = stitch.StitchClientFactory.create('hackerjira-bzmfe');\n  clientPromise.then(client => {\n    const db = client.service('mongodb', 'mongodb-atlas').db('HackersBlog');\n    client.login().then(() =>\n      db.collection('jira').updateOne({owner_id: client.authedId()}, {$set:{number:42}}, {upsert:true})\n    ).then(()=>\n      db.collection('jira').find({owner_id: client.authedId()}).limit(100).execute()\n    ).then(docs => {\n      console.log(\"Found docs\", docs)\n      console.log(\"[MongoDB Stitch] Connected to Stitch\")\n    }).catch(err => {\n      console.error(err)\n    });\n  });\n</script>\n\n\nChecking this on the live sites looks like this:\n\nNote the \"docs\" found in the console on the right.It worked, but what exactly?\nThe first thing the snippet tells the database to do is to upsert a row where\n\"number\" is equal to 42:\n\ndb.collection('jira').updateOne({owner_id: client.authedId()}, {$set:{number:42}}, {upsert:true})\n\n\nFor sanity, let's check the database to see what's up:\n\nIs that… a new record?!?!Sure enough, a new entry has been added to our database\nin the collection we specified. That's fun and all, but what about our actual\ndata? Isn't that what we came here for? Consider the next line:\n\ndb.collection('jira').find({owner_id: client.authedId()}).limit(100).execute()\n\n\nAhhh, we’re querying based on entries only  created from the current user!\nBecause the sample code we pasted creates a record, we can then query the\ndatabase for records created by that user. Let’s not ignore how cool that is\nhaving not actually done any work: we already have logic in place to allow\nanonymous users to create records and recognize them based on their session.\n\n.find()  is our bread and butter for retrieving records, much like SQL SELECT.\nSo in theory, to show all issues from this collection we'd just need to run the\nfollowing, right?\n\ndb.collection('jira').find({}).execute()\n\n\nSlow down there, buddy- but yes, pretty much. We just need to make read\npermissions public on the MongoDB Stitch side first. Back in the Stitch UI,\nselect \"Rules\" from the sidebar. Here, we can modify the rules for who can\nread/write which records from which DB:\n\nIt's less complicated than it looks.We can create rules as advanced as we'd\nlike, but the rules we need right now are simple enough to handle purely via the\nUI.\n\nGet All The Records\nGo ahead and add a bunch of records to your database collection. Experiment with\nimporting data via JSON or CSV, or just add some records one-by-one.\n\nWhen that's done, go back to your app and see what .find({})  comes back with:\n\nNow that's a collection.There they are: every record from a database collection,\ngrabbed with a single line of code on our frontend. Feel free to take a moment\nto reflect on this: we didn’t need to create an API, write logic, or log in to\nany shitty IAM policy management UIs. We didn’t even need to write a query; the\n‘query’ in this case is just a JSON object.\n\nStitching it All Together\nWhen I first reached this point, I experienced a rush of emotions: can creating\nnew features truly be this simple? If so, what have we been doing with our lives\nuntil this moment- repeating the same boilerplate and relearning the same\nconcepts as millions before us? Is this knowledge all worthless now? Does the\nexistence of Stitch reduce our lives’ greatest accomplishments to something that\ncan now be reproduced in minutes?\n\nWhile there are a great number of things that come easily with Stitch, there are\na fair share of headaches that come along with them. Many intricacies of complex\nflows and user management lack documentation or examples altogether. Creating a\ncloud based on ease-of-use even more frustrating: there’s not much that sucks\nmore than knowing something should be simple, but lacking the few lines of code\nto do it.\n\nThat’s where we’ll be filling in the blanks. Next time, we’ll take a look into\nStitch’s Serverless functions.","html":"<p>Some tools are simply the right tool for the job. I imagine this must have been the thinking behind the wave of JSON-like NoSQL databases at their peak, and even so today. If we figure we’ll be passing information as JSON to an endpoint, to then have it structured into a schema, only to be promptly broken down again for our request seconds later, if you will, it’s fair to question the cost-benefit of schemas in some cases. A lot of those cases cover the apps we build for ourselves: ones that let us do stupid things like spamming selfies or filling the internet with vast mindless thoughts.</p><p><strong><strong>MongoDB Atlas</strong></strong> is a hell of product in its own right, being a cloud NoSQL database with the ability to execute queries similar to SQL JOINs, countless aggregations, and more possibilities to work into a pipeline than I’ve even had time to explore (we’ll get there). If you’ve ever been tasked to build endpoints for yourself, chances are you already appreciate side-stepping the manual one-to-one key association that comes with passing JSON to Lambda Functions or what-have-you.</p><p>Take our situation at Hackers And Slackers, for instance. We’re running a Ghost blog, which is a young piece of software built by a non-profit organization: this software is constantly being updated and improved, which means if we want to modify the logic of our Node app at all, our choices are:</p><ol><li>Modify the Ghost source and refuse future updates</li><li>Merge our custom backend with Ghost changes in the event of an update</li><li>Build a third-party API using a platform such as AWS</li></ol><p><strong><strong>MongoDB Stitch</strong></strong> gives us a new fourth option: <em>extend our app without all the repetitive boilerplate.</em> I say <em>extend</em> because it empowers us to build on top of things which were previously black-boxed to us, such developing a theme atop a blogging system.</p><h2 id=\"carrying-on-the-legacy\">Carrying on the Legacy</h2><p><strong><strong>MongoDB Stitch </strong></strong>extends the philosophy of avoiding repetition. In a similar way to how NoSQL removed a pain point for many developers, Stitch wants you to keep doing what you do best, which is probably writing NodeJS apps. Forever.</p><p>If I worked for Mongo, I’d sell the product like this:</p><blockquote><em><em>MongoDB Stitch empowers you to build powerful features without ever switching gears to the menial aspects of development.</em></em></blockquote><p>What I’m really saying is that <strong><strong>MongoDB Stitch</strong></strong> is <strong><strong>Google Firebase</strong></strong>. Both products target the <em>frontend</em> and <em>mobile</em> developer markets, and both are very young and early in fully achieving this goal. I’m watching the MongoDB product video for the first time, and it feels like what I’ve assumed from using the product aligns with their sell (good job on their part, I suppose):</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"480\" height=\"270\" src=\"https://www.youtube.com/embed/H3P0lW94L2Q?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>As warm and uppity as that video is, Mongo has been rather bashful about their Cloud. I'm guessing that has something to do with an IPO.</p><p>On the other hand, <strong>Google Firebase</strong> has been tooting its own horn loudly for a young product, with a level of growth which feels almost reckless at times (I won't get into it):</p><figure class=\"kg-card kg-embed-card\"><iframe width=\"480\" height=\"270\" src=\"https://www.youtube.com/embed/iosNuIdQoy8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><p>Anyway, we're not here to compare. We're here to judge.</p><h2 id=\"getting-started-with-a-new-database\">Getting Started with a New Database</h2><p>Feel free to follow along by <a href=\"https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/\">setting up a free tier cluster</a>. </p><p>Proper Mongo accounts are managed at <a href=\"https://cloud.mongodb.com\">https://cloud.mongodb.com</a> once created. This landing dash has plenty of useful info and stats regarding the cluster itself. We'll also need to be sure that a database exists before we crate any apps, otherwise we'll just be interacting with nothing.</p><p>I <em>highly</em> suggest using the <strong>MongoDB Compass</strong> desktop app to connect to your your cluster. It's easy to download, and even saves you the time of entering credentials by connecting with a copy+pasted URI:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/connectcompass.gif\" class=\"kg-image\"><figcaption>Connect with your database; emotionally.</figcaption></figure><p>Within Compass, simply create a database and collection:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/createdatabase_o.jpg\" class=\"kg-image\"><figcaption>In MongoWorld, \"collections\" are the equivalent of \"tables\".</figcaption></figure><h2 id=\"let-s-get-stitched\">Let's Get Stitched</h2><p>With all that out of the way, head back to your account on the Mongo Cloud. Now our interest is entirely in the <strong>Stitch Apps</strong> link on the left side nav:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/selectstitch.png\" class=\"kg-image\"><figcaption>There’s so much to explore!</figcaption></figure><p>Create and name a new Stitch application, and we'll land on the \"getting started\" page. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/cf61a09bd893c453854634988b71d500.gif\" class=\"kg-image\"><figcaption><em>Enable anonymous auth &amp; point to your collection</em></figcaption></figure><p>Once we create our app, Stitch immediately throws us in to a quick 101 of how to interact with our database. We're going to use the exact example that Stitch gives us; it's important to have the \"A-ha\" moment where everything comes together. </p><p>Before getting to any code, the only two things we need to do are:</p><ol><li><strong>Enable Anonymous Authentication</strong>: This is fancy language for creating a user type where anybody who accesses our app can make queries</li><li><strong>Pointing to our Mongo Collection</strong>: We need somewhere to store the data we'll be messing with.</li></ol><h3 id=\"connecting-your-app\">Connecting Your App</h3><p>We're going to copy and paste this code on to a page of our app. Once this is live, visit the page and keep an eye on the console:</p><pre><code class=\"language-javascript\">&lt;script src=&quot;https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js&quot;&gt;&lt;/script&gt;\n\n&lt;script&gt;\n  const clientPromise = stitch.StitchClientFactory.create('hackerjira-bzmfe');\n  clientPromise.then(client =&gt; {\n    const db = client.service('mongodb', 'mongodb-atlas').db('HackersBlog');\n    client.login().then(() =&gt;\n      db.collection('jira').updateOne({owner_id: client.authedId()}, {$set:{number:42}}, {upsert:true})\n    ).then(()=&gt;\n      db.collection('jira').find({owner_id: client.authedId()}).limit(100).execute()\n    ).then(docs =&gt; {\n      console.log(&quot;Found docs&quot;, docs)\n      console.log(&quot;[MongoDB Stitch] Connected to Stitch&quot;)\n    }).catch(err =&gt; {\n      console.error(err)\n    });\n  });\n&lt;/script&gt;\n</code></pre>\n<p>Checking this on the live sites looks like this:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screenshot-2018-06-02-16.40.43.png\" class=\"kg-image\"><figcaption>Note the \"docs\" found in the console on the right.</figcaption></figure><p>It worked, but what exactly? The first thing the snippet tells the database to do is to upsert a row where \"number\" is equal to 42:</p><pre><code class=\"language-javascript\">db.collection('jira').updateOne({owner_id: client.authedId()}, {$set:{number:42}}, {upsert:true})\n</code></pre>\n<p>For sanity, let's check the database to see what's up:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/createdatabase_o.jpg\" class=\"kg-image\"><figcaption>Is that… a new record?!?!</figcaption></figure><p>Sure enough, a new entry has been added to our database in the collection we specified. That's fun and all, but what about our actual data? Isn't that what we came here for? Consider the next line:</p><pre><code class=\"language-javascript\">db.collection('jira').find({owner_id: client.authedId()}).limit(100).execute()\n</code></pre>\n<p>Ahhh, we’re querying based on entries <em>only</em> created from the current user! Because the sample code we pasted creates a record, we can then query the database for records created by that user. Let’s not ignore how cool that is having not actually done any work: we already have logic in place to allow anonymous users to create records and recognize them based on their session.</p><p><code>.find()</code> is our bread and butter for retrieving records, much like SQL <code>SELECT</code>. So in theory, to show all issues from this collection we'd just need to run the following, right?</p><pre><code class=\"language-javascript\">db.collection('jira').find({}).execute()\n</code></pre>\n<p>Slow down there, buddy- but yes, pretty much. We just need to make read permissions public on the MongoDB Stitch side first. Back in the Stitch UI, select \"Rules\" from the sidebar. Here, we can modify the rules for who can read/write which records from which DB:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screenshot-2018-06-02-16.43.31.png\" class=\"kg-image\"><figcaption>It's less complicated than it looks.</figcaption></figure><p>We can create rules as advanced as we'd like, but the rules we need right now are simple enough to handle purely via the UI.</p><h2 id=\"get-all-the-records\">Get All The Records</h2><p>Go ahead and add a bunch of records to your database collection. Experiment with importing data via JSON or CSV, or just add some records one-by-one.</p><p>When that's done, go back to your app and see what <code>.find({})</code> comes back with:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-11-24-at-4.45.50-PM_o.png\" class=\"kg-image\"><figcaption>Now that's a collection.</figcaption></figure><p>There they are: every record from a database collection, grabbed with a single line of code on our frontend. Feel free to take a moment to reflect on this: we didn’t need to create an API, write logic, or log in to any shitty IAM policy management UIs. We didn’t even need to write a query; the ‘query’ in this case is just a JSON object.</p><h3 id=\"stitching-it-all-together\">Stitching it All Together</h3><p>When I first reached this point, I experienced a rush of emotions: can creating new features truly be this simple? If so, what have we been doing with our lives until this moment- repeating the same boilerplate and relearning the same concepts as millions before us? Is this knowledge all worthless now? Does the existence of Stitch reduce our lives’ greatest accomplishments to something that can now be reproduced in minutes?</p><p>While there are a great number of things that come easily with Stitch, there are a fair share of headaches that come along with them. Many intricacies of complex flows and user management lack documentation or examples altogether. Creating a cloud based on ease-of-use even more frustrating: there’s not much that sucks more than knowing something should be simple, but lacking the few lines of code to do it.</p><p>That’s where we’ll be filling in the blanks. Next time, we’ll take a look into Stitch’s Serverless functions.</p>","url":"https://hackersandslackers.com/mongodb-stitch-query-anywhere/","uuid":"76a0bed5-d98a-47a1-a00a-64cff37d16a8","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b12c0ddb5ac11477416d88d"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867373e","title":"Image Compression Using Gulp and Imagemin","slug":"simple-image-size-optimization-using-imagemin-and-gulp","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/11/imagemin-6@2x.jpg","excerpt":"The simplest way to optimize page speed without breaking everything.\n","custom_excerpt":"The simplest way to optimize page speed without breaking everything.\n","created_at_pretty":"16 November, 2018","published_at_pretty":"22 November, 2018","updated_at_pretty":"27 December, 2018","created_at":"2018-11-16T18:46:04.000-05:00","published_at":"2018-11-21T20:49:01.000-05:00","updated_at":"2018-12-26T23:25:33.000-05:00","meta_title":"Image Compression Using Gulp and Imagemin | Hackers and Slackers","meta_description":"The simplest way to optimize page speed without breaking everything.\n","og_description":"The simplest way to optimize page speed without breaking everything\n","og_image":"https://hackersandslackers.com/content/images/2018/11/imagemin-6@2x.jpg","og_title":"Image Compression Using Gulp and Imagemin | Hackers and Slackers","twitter_description":"The simplest way to optimize page speed without breaking everything\n","twitter_image":"https://hackersandslackers.com/content/images/2018/11/imagemin-6@2x.jpg","twitter_title":"Image Compression Using Gulp and Imagemin | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},"tags":[{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"}],"plaintext":"I promised myself I wouldn’t get involved in any more Gulp tutorials; task\nrunners aren’t exactly the sexiest topic in the world, and chances are if you’ve\nmade it to this blog, you’ve either solidified a CI/CD pipeline for going live\nwith software, or you simply don’t need one. We’ll make an exception this time,\nbecause gulp-imagemin  is particularly dope.\n\nImagemin [https://github.com/imagemin/imagemin]  is a standalone Node library\nwhich also comes with a CLI [https://github.com/imagemin/imagemin-cli], and of\ncourse, a Gulp plugin [https://github.com/sindresorhus/gulp-imagemin]. In short,\n imagemin  compresses images in a given directory and is intelligent enough to\nrecognize images it has already compressed. This is huge because it means we can\nrecklessly tell imagemin  to compress the same folder of images hundreds of\ntimes, and each image will only be compressed exactly once.\n\nFor this tutorial, we’ll be taking gulp-imagemin and creating a task to compress\nimages in complex folder structures.\n\nUsing Imagemin on Complex Folder Structures\nWe’ve probably mentioned this once or twice before, but this blog is a theme\nrunning on a Ghost [https://ghost.org/]  stack. The thing about Ghost (and\nprobably any other blogging platform) is that it stores content in a date-based\nfolder hierarchy. /images  looks like this:\n\n/images\n├─ /2017\n│  └─ 01\n│  └─ 02\n│  └─ 03\n│  └─ 04\n│  └─ 05\n│  └─ 06\n│  └─ 07\n│  └─ 08\n│  └─ 09\n│  └─ 10\n│  └─ 11\n│  └─ 12\n└─ /2018\n   └─ 01\n   └─ 02\n   └─ 03\n   └─ 04\n   └─ 05\n   └─ 06\n   └─ 07\n   └─ 08\n   └─ 09\n   └─ 10\n   └─ 11\n\n\nImagemin  does not  work recursively, so we’ll need to handle looping through\nthis file structure ourselves.\n\nStarting our Gulpfile\nLet’s get started by going through the barebones of the libraries required to\nmake this happen:\n\nvar gulp = require('gulp'),\n  imagemin = require('gulp-imagemin'),\n  fs = require('fs'),\n  path = require('path');\n\n\ngulp-imagemin is the core Gulp plugin we need to compress our images, but is\nactually useless on it’s own — we need to also import plugins-for-a-plugin; \ngulp-imagemin requires a separate plugin for each image type we need to express.\n\nWe’re also requiring fs and path  here, which will let us walk through folder\nstructures programmatically.\n\nImagemin Plugins\nAs mentioned imagemin itself has plugins per image type: only require the ones\nyou think you’ll need:\n\nvar gulp = require('gulp'),\n  imagemin = require('gulp-imagemin'),\n  imageminWebp = require('imagemin-webp'),\n  imageminJpegtran = require('imagemin-jpegtran'),\n  imageminPngquant = require('imagemin-pngquant'),\n  imageminGifSicle = require('imagemin-gifsicle'),\n  imageminOptiPng = require('imagemin-optipng'),\n  imageminSvgo = require('imagemin-svgo'),\n  fs = require('fs'),\n  path = require('path');\n\n\nFor the sake of keeping this tutorial simple, we’ll limit our use case to JPGs.\n\nA particular standout here worth mentioning here is WebP\n[https://developers.google.com/speed/webp/]: a “next-gen” image compression for\nthe web which supposedly offers the best image quality for the smallest file\nsize available.\n\nLet’s Get This Going\nSome people (myself included) like to specify paths to their assets as a single\nvariable in their Gulpfile. This is even more relevant in the case of anybody\nusing Ghost, where images are in a totally different file structure from where\nour Gulpfile lives.\n\nvar gulp = require('gulp'),\n  imagemin = require('gulp-imagemin'),\n  imageminJpegtran = require('imagemin-jpegtran'),\n  fs = require('fs'),\n  path = require('path');\nvar paths = {\n  styles: {\n    src: 'src/less/*.less',\n    dest: 'assets/css'\n  },\n  scripts: {\n    src: 'src/js/*.js',\n    dest: 'assets/js'\n  },\n  html: {\n    src: 'views/*.hbs',\n    dest: 'assets/'\n  },\n  images: {\n    src: '/var/www/my-theme/content/images/2018/',\n    dest: '/var/www/my-theme/content/images/2018/'\n  }\n};\n\n\nLooping Through Folders\nWe need to look in our /images  folder are recursively find all folders\ncontaining images. Referencing the image path we set in paths, we’ll build an\narray of targeted folders:\n\nfunction image_loop() {\n  var folder_arr = []\n  fs.readdir(paths.images.src, function(err, folders) {\n    for(var i =0; i < folders.length; i++){\n      var folder_path = path.join(paths.images.src, folders[i]);\n      folder_arr.push(folder_path);\n    }\n    for(var i =0; i < folder_arr.length; i++) {\n        images(folder_arr[i]);\n    }\n  });\n}\n\n\nfs.readdir()  is a method that returns the contents of any directory. We'll\ncreate a function called image_loop which loops through all folders in the\ntarget directory, and will then call another function to compress the contents:\n\nfunction image_loop() { \n   fs.readdir(paths.images.src, function(err, folders) { \n      for(var i =0; i < folders.length; i++){ \n         var folder_path = path.join(paths.images.src, folders[i]);   \n         images(folders[i]); \n       } \n   }); \n }\n\n\nCompressing Images in Each Folder\nimage_loop  calls function images  once per folder to compress the contents of\neach folder. Here’s where we actually get to use imagemin:\n\nfunction image_loop() {\n  fs.readdir(paths.images.src, function(err, folders) {\n    for(var i =0; i < folders.length; i++){\n      var folder_path = path.join(paths.images.src, folders[i]);\n      images(folders[i]);\n    }\n  });\n}\n\n\nSimple enough, all we’re doing is:\n\n * Looking for files ending in .jpg  in each folder\n * Running imageminJpegtran to compress each JPG file\n * Specifying verbose, which prints the result to the console (for example: \n   “Minified 0 images”)\n * Writing files to the destination (which is the same as the source, thus\n   overwriting our files)\n\nPut it All Together\nvar gulp = require('gulp'),\n  imagemin = require('gulp-imagemin'),\n  imageminJpegtran = require('imagemin-jpegtran'),\n  fs = require('fs'),\n  path = require('path');\nvar paths = {\n  styles: {\n    src: 'src/less/*.less',\n    dest: 'assets/css'\n  },\n  scripts: {\n    src: 'src/js/*.js',\n    dest: 'assets/js'\n  },\n  html: {\n    src: 'views/*.hbs',\n    dest: 'assets/'\n  },\n  images: {\n    src: '/var/www/my-theme/content/images/2018/',\n    dest: '/var/www/my-theme/content/images/2018/'\n  }\n};\nfunction images(folder_path) {\n  return gulp.src(folder_path + '/*.jpg')\n  .pipe(imagemin(\n    [imageminJpegtran({progressive: true})],\n    {verbose: true}\n  ))\n  .pipe(gulp.dest(paths.images.dest));\n}\nfunction image_loop() {\n  fs.readdir(paths.images.src, function(err, folders) {\n    for(var i =0; i < folders.length; i++){\n      var folder_path = path.join(paths.images.src, folders[i]);\n      images(folders[i]);\n    }\n  });\n}\nvar build = gulp.parallel(styles, scripts, image_loop);\ngulp.task('default', build);\n\n\nAnd there you have it; a Gulpfile which compresses your images without intruding\nrequiring any sort of relinking.\n\nIf you’re interested in imagemin  or further optimizing your site, I highly\nrecommend Google’s recently announced beta of https://web.dev [https://web.dev/]\n. This is an excellent resource for auditing your site for opportunities on\nspeed, SEO, and more.","html":"<p>I promised myself I wouldn’t get involved in any more Gulp tutorials; task runners aren’t exactly the sexiest topic in the world, and chances are if you’ve made it to this blog, you’ve either solidified a CI/CD pipeline for going live with software, or you simply don’t need one. We’ll make an exception this time, because <strong><strong>gulp-imagemin</strong></strong> is particularly dope.</p><p><a href=\"https://github.com/imagemin/imagemin\" rel=\"noopener\"><strong><strong>Imagemin</strong></strong></a> is a standalone Node library which also comes with a <a href=\"https://github.com/imagemin/imagemin-cli\" rel=\"noopener\">CLI</a>, and of course, a <a href=\"https://github.com/sindresorhus/gulp-imagemin\" rel=\"noopener\">Gulp plugin</a>. In short, <em>imagemin</em> compresses images in a given directory and is intelligent enough to recognize images it has already compressed. This is huge because it means we can recklessly tell <em>imagemin</em> to compress the same folder of images hundreds of times, and each image will only be compressed exactly once.</p><p>For this tutorial, we’ll be taking <strong><strong>gulp-imagemin </strong></strong>and creating a task to compress images in complex folder structures.</p><h3 id=\"using-imagemin-on-complex-folder-structures\">Using Imagemin on Complex Folder Structures</h3><p>We’ve probably mentioned this once or twice before, but this blog is a theme running on a <a href=\"https://ghost.org/\" rel=\"noopener\"><strong><strong>Ghost</strong></strong></a><strong><strong> </strong></strong>stack. The thing about Ghost (and probably any other blogging platform) is that it stores content in a date-based folder hierarchy. <strong><strong>/images</strong></strong> looks like this:</p><pre><code class=\"language-bash\">/images\n├─ /2017\n│  └─ 01\n│  └─ 02\n│  └─ 03\n│  └─ 04\n│  └─ 05\n│  └─ 06\n│  └─ 07\n│  └─ 08\n│  └─ 09\n│  └─ 10\n│  └─ 11\n│  └─ 12\n└─ /2018\n   └─ 01\n   └─ 02\n   └─ 03\n   └─ 04\n   └─ 05\n   └─ 06\n   └─ 07\n   └─ 08\n   └─ 09\n   └─ 10\n   └─ 11\n</code></pre>\n<p><strong><strong>Imagemin</strong></strong> does <em>not</em> work recursively, so we’ll need to handle looping through this file structure ourselves.</p><h3 id=\"starting-our-gulpfile\">Starting our Gulpfile</h3><p>Let’s get started by going through the barebones of the libraries required to make this happen:</p><pre><code class=\"language-javascript\">var gulp = require('gulp'),\n  imagemin = require('gulp-imagemin'),\n  fs = require('fs'),\n  path = require('path');\n</code></pre>\n<p><strong><strong>gulp-imagemin </strong></strong>is the core Gulp plugin we need to compress our images, but is actually useless on it’s own — we need to also import <em>plugins-for-a-plugin; </em>gulp-imagemin requires a separate plugin for each image type we need to express.</p><p>We’re also requiring <strong><strong>fs </strong></strong>and <strong><strong>path</strong></strong> here, which will let us walk through folder structures programmatically.</p><h3 id=\"imagemin-plugins\">Imagemin Plugins</h3><p>As mentioned imagemin itself has plugins per image type: only require the ones you think you’ll need:</p><pre><code class=\"language-javascript\">var gulp = require('gulp'),\n  imagemin = require('gulp-imagemin'),\n  imageminWebp = require('imagemin-webp'),\n  imageminJpegtran = require('imagemin-jpegtran'),\n  imageminPngquant = require('imagemin-pngquant'),\n  imageminGifSicle = require('imagemin-gifsicle'),\n  imageminOptiPng = require('imagemin-optipng'),\n  imageminSvgo = require('imagemin-svgo'),\n  fs = require('fs'),\n  path = require('path');\n</code></pre>\n<p>For the sake of keeping this tutorial simple, we’ll limit our use case to JPGs.</p><p>A particular standout here worth mentioning here is <a href=\"https://developers.google.com/speed/webp/\" rel=\"noopener\">WebP</a>: a “next-gen” image compression for the web which supposedly offers the best image quality for the smallest file size available.</p><h3 id=\"let-s-get-this-going\">Let’s Get This Going</h3><p>Some people (myself included) like to specify paths to their assets as a single variable in their Gulpfile. This is even more relevant in the case of anybody using <strong><strong>Ghost, </strong></strong>where images are in a totally different file structure from where our Gulpfile lives.</p><pre><code class=\"language-javascript\">var gulp = require('gulp'),\n  imagemin = require('gulp-imagemin'),\n  imageminJpegtran = require('imagemin-jpegtran'),\n  fs = require('fs'),\n  path = require('path');\nvar paths = {\n  styles: {\n    src: 'src/less/*.less',\n    dest: 'assets/css'\n  },\n  scripts: {\n    src: 'src/js/*.js',\n    dest: 'assets/js'\n  },\n  html: {\n    src: 'views/*.hbs',\n    dest: 'assets/'\n  },\n  images: {\n    src: '/var/www/my-theme/content/images/2018/',\n    dest: '/var/www/my-theme/content/images/2018/'\n  }\n};\n</code></pre>\n<h3 id=\"looping-through-folders\">Looping Through Folders</h3><p>We need to look in our <strong><strong>/images</strong></strong> folder are recursively find all folders containing images. Referencing the image path we set in <strong><strong>paths</strong></strong>, we’ll build an array of targeted folders:</p><pre><code class=\"language-javascript\">function image_loop() {\n  var folder_arr = []\n  fs.readdir(paths.images.src, function(err, folders) {\n    for(var i =0; i &lt; folders.length; i++){\n      var folder_path = path.join(paths.images.src, folders[i]);\n      folder_arr.push(folder_path);\n    }\n    for(var i =0; i &lt; folder_arr.length; i++) {\n        images(folder_arr[i]);\n    }\n  });\n}\n</code></pre>\n<p><code>fs.readdir()</code> is a method that returns the contents of any directory. We'll create a function called <strong><strong>image_loop </strong></strong>which loops through all folders in the target directory, and will then call another function to compress the contents:</p><pre><code class=\"language-javascript\">function image_loop() { \n   fs.readdir(paths.images.src, function(err, folders) { \n      for(var i =0; i &lt; folders.length; i++){ \n         var folder_path = path.join(paths.images.src, folders[i]);   \n         images(folders[i]); \n       } \n   }); \n }\n</code></pre>\n<h3 id=\"compressing-images-in-each-folder\">Compressing Images in Each Folder</h3><p><strong><strong>image_loop</strong></strong> calls function <strong><strong>images</strong></strong> once per folder to compress the contents of each folder. Here’s where we actually get to use <strong><strong>imagemin:</strong></strong></p><pre><code class=\"language-javascript\">function image_loop() {\n  fs.readdir(paths.images.src, function(err, folders) {\n    for(var i =0; i &lt; folders.length; i++){\n      var folder_path = path.join(paths.images.src, folders[i]);\n      images(folders[i]);\n    }\n  });\n}\n</code></pre>\n<p>Simple enough, all we’re doing is:</p><ul><li>Looking for files ending in <strong><strong>.jpg</strong></strong> in each folder</li><li>Running <strong><strong>imageminJpegtran </strong></strong>to compress each JPG file</li><li>Specifying <strong><strong>verbose</strong></strong>, which prints the result to the console (for example: <em>“Minified 0 images”</em>)</li><li>Writing files to the destination (which is the same as the source, thus overwriting our files)</li></ul><h2 id=\"put-it-all-together\">Put it All Together</h2><pre><code class=\"language-javascript\">var gulp = require('gulp'),\n  imagemin = require('gulp-imagemin'),\n  imageminJpegtran = require('imagemin-jpegtran'),\n  fs = require('fs'),\n  path = require('path');\nvar paths = {\n  styles: {\n    src: 'src/less/*.less',\n    dest: 'assets/css'\n  },\n  scripts: {\n    src: 'src/js/*.js',\n    dest: 'assets/js'\n  },\n  html: {\n    src: 'views/*.hbs',\n    dest: 'assets/'\n  },\n  images: {\n    src: '/var/www/my-theme/content/images/2018/',\n    dest: '/var/www/my-theme/content/images/2018/'\n  }\n};\nfunction images(folder_path) {\n  return gulp.src(folder_path + '/*.jpg')\n  .pipe(imagemin(\n    [imageminJpegtran({progressive: true})],\n    {verbose: true}\n  ))\n  .pipe(gulp.dest(paths.images.dest));\n}\nfunction image_loop() {\n  fs.readdir(paths.images.src, function(err, folders) {\n    for(var i =0; i &lt; folders.length; i++){\n      var folder_path = path.join(paths.images.src, folders[i]);\n      images(folders[i]);\n    }\n  });\n}\nvar build = gulp.parallel(styles, scripts, image_loop);\ngulp.task('default', build);\n</code></pre>\n<p>And there you have it; a Gulpfile which compresses your images without intruding requiring any sort of relinking.</p><p>If you’re interested in <strong><strong>imagemin</strong></strong> or further optimizing your site, I highly recommend Google’s recently announced beta of <a href=\"https://web.dev/\" rel=\"noopener\">https://web.dev</a>. This is an excellent resource for auditing your site for opportunities on speed, SEO, and more.</p>","url":"https://hackersandslackers.com/simple-image-size-optimization-using-imagemin-and-gulp/","uuid":"e80f7a95-da5e-417f-8a71-683772fd93a9","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5bef56bc5bebbe659bef57c0"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867373d","title":"MongoDB Cloud: \"Backend as a Service\" with Atlas & Stitch","slug":"mongodb-cloud-backend-as-a-service-with-atlas-and-stitch","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/11/mongodbcloud@2x.jpg","excerpt":"MongoDB's silent transformation from an open-source database to enterprise cloud provider.","custom_excerpt":"MongoDB's silent transformation from an open-source database to enterprise cloud provider.","created_at_pretty":"13 November, 2018","published_at_pretty":"15 November, 2018","updated_at_pretty":"15 February, 2019","created_at":"2018-11-13T16:05:20.000-05:00","published_at":"2018-11-15T08:00:00.000-05:00","updated_at":"2019-02-15T12:49:05.000-05:00","meta_title":"MongoDB Cloud: \"Backend as a Service\" | Hackers and Slackers","meta_description":"Breaking down MongoDB Atlas and MongoDB Stitch to fully assess the capabilities of an unlikely cloud platform.","og_description":"Breaking down MongoDB Atlas and MongoDB Stitch to fully assess the capabilities of an unlikely cloud platform.","og_image":"https://hackersandslackers.com/content/images/2018/11/mongodbcloud@2x.jpg","og_title":"MongoDB Cloud: \"Backend as a Service\" with Atlas And Stitch","twitter_description":"Breaking down MongoDB Atlas and MongoDB Stitch to fully assess the capabilities of an unlikely cloud platform.","twitter_image":"https://hackersandslackers.com/content/images/2018/11/mongodbcloud@2x.jpg","twitter_title":"MongoDB Cloud: \"Backend as a Service\" with Atlas And Stitch","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"Unless you've been living under a rock (or only visit this site via work-related\nGoogle Searches, like most people) you've probably heard me drone on here and\nthere about MongoDB Atlas  and MongoDB Stitch. I even went so far as to hack\ntogether an awful workflow that somehow utilized Tableau as an ETL tool to feed\nJIRA information into Mongo. I'd like to formally apologize for that entire\nseries: I can't imagine there's a single soul on this planet interested in\nlearning about all of those things simultaneously. Such hobbies reserved for\nmasochists with blogging addictions. I apologize. Let's start over.\n\nFirst off, this is not a tutorial on how to use MongoDB: the database. I have\nzero interest cluttering the internet by reiterating what a MEAN stack is for\nthe ten thousandth time, nor will I bore you with core NoSQL concepts you\nalready understand. I'm here to talk about the giant on the horizon we didn't\nsee coming, where MongoDB the database decided to become MongoDB Inc\n[https://en.wikipedia.org/wiki/MongoDB_Inc.]:  the enterprise cloud provider.\nThe same MongoDB that recently purchased mLab\n[https://www.mongodb.com/press/mongodb-strengthens-global-cloud-database-with-acquisition-of-mlab]\n, the other  cloud-hosted solution for Mongo databases. MongoDB the company is\nbold enough to place its bets on building a cloud far  simpler and restricted\nthan either AWS or GCloud. The core of that bet implies that most of us aren't\nexactly building unicorn products as much as we're reinventing the wheel: and\nthey're probably right.\n\nWelcome to our series on MongoDB cloud, where we break down every service\nMongoDB has to offer; one by one.\n\nWhat is MongoDB Cloud, and Does it Exist?\nWhat I refer to as \"MongoDB Cloud\" (which, for some reason, isn't the actual\nname of the suite MongoDB offers) is actually two products:\n\n * MongoDB Atlas: A cloud-hosted MongoDB cluster with a beefy set of features.\n   Real-time dashboards, high-availability, security features,  an awesome\n   desktop client, and a CLI to top it all off.\n * MongoDB Stitch: A group of services designed to interact with Atlas in every\n   conceivable way, including creating endpoints, triggers, user authentication\n   flows, serverless functions, and a UI to handle all of this.\n\nI'm spying on you and every query you make.Atlas as a Standalone Database\nThere are plenty of people who simply want an instance of MongoDB hosted in the\ncloud as-is: just ask the guys at mLab. This was in fact how I got pulled into\nMongo's cloud myself.\n\nMongoDB Atlas has plenty of advantages over a self-hosted instance of Mongo,\nwhich Mongo itself is confident in by offering a free tier\n[https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/]  of Atlas to\nprospective buyers. If you're a company or enterprise, the phrases High\nAvailability, Horizontal Scalability, relatively Higher Performance  will\nprobably be enough for you. But for us hobbyists, why pay for a Mongo cloud\ninstance?\n\nMongo themselves gives this comparison:\n\nOverview\n MongoDB Atlas\n Compose\n ObjectRocket\n Free Tier\n Yes\nStorage: 512 MB\nRAM: Variable\n No\n30-day free trial\n No\n30-day free trial\n Live migration\n Yes\nNo\nNo\nChoice of cloud providers\n AWS, Azure & GCP\n AWS, Softlayer & GCP\nAvailable in 2 regions for each provider\n Rackspace\n Choice of instance configuration\n Yes\n No\nConfiguration based on required storage capacity only. No way to independently\nselect underlying hardware configurations\n No\nConfiguration based on required storage capacity only. No way to independently\nselect underlying hardware configurations\n Availability of latest MongoDB version\n Yes\nNew versions of the database are available on MongoDB Atlas as soon as they are\nreleased\n No\nNew versions typically available 1-2 quarters following database release\nNo\nNew versions typically available 1-2 quarters following database release\nReplica Set Configuration\n Up to 7 replicas\nAll replicas configured as data-bearing nodes\n 3 data-bearing nodes\nOne of the data-bearing nodes is hidden and used for backups only\n 3 data-bearing nodes\nAutomatic Sharding Support\n Yes\nNo\nYes\nData explorer\n Yes\nYes\nNo\nSQL-based BI Connectivity\n Yes\nNo\nNo\nPause and resume clusters\n Yes\nNo\nNo\nDatabase supported in on-premise deployments\n Yes\nMongoDB Enterprise Advanced [/products/mongodb-enterprise-advanced]\n No\nNo\nGlobal writes Low-latency writes from anywhere in the world Yes\n No\n No\n Cross-region replication Distribute data around the world for multi-region\nfault tolerance and local reads Yes\n No\n No\n Monitoring of database health with automated alerting\n Yes\nMongoDB Atlas UI & support for APM platforms (New Relic)\n Yes\nNew Relic\n Yes\nNew Relic\n Continuous backup\n Yes\nBackups maintained\nseconds behind production cluster\n No\nBackups taken with mongodump against hidden replica set member\n No\nBackups taken with mongodump\n Queryable backups\n Yes\nNo\nNo\nAutomated & consistent snapshots of sharded clusters\n Yes\nNot Applicable\nNo support for auto-sharding\n No\nRequires manually coordinating the recovery of mongodumps across shards\n Access control & IP whitelisting\n Yes\nYes\nYes\nAWS VPC Peering\n Yes\nBeta Release\nYes\nAdditional Charge\n Encryption of data in-flight\n Yes\nTLS/SSL as standard\n Yes\nYes\nEncryption of data at-rest\n Yes\nAvailable for AWS deployments; always on with Azure and GCP\n No\nYes\nAvailable only with specific pricing plans and data centers\n LDAP Integration\n Yes\n No\nNo\n Database-level auditing\nTrack DDL, DML, DCL operations\n Yes\n No\nNo\n Bring your own KMS\n Yes\n No\nNo\n Realistically there are probably only a number of items that stand out on the\ncomparison list when we go strictly database-to-database. Freedom over instance\nconfiguration sounds great, but in practice is more similar to putting a cap on\nhow much MongoDB decides to charge you that month (by the way, it's usually a\nlot; keep this mind). Having the Latest Version  seems great, but this can just\nas easily mean breaking production unannounced as much as it means new features.\n\nMongoDB clearly wins over the enterprise space with Continuous & queryable\nbackups, integration with LDAP, and automatic sharding support. Truthfully if\nthis were merely a database-level feature and cost comparison, the decision to\ngo with  MongoDB Atlas  would come down to how much you like their pretty\ndesktop interface:\n\nA perfectly legitimate reason to pay up, imho.So let's say MongoDB Atlas is\nmarginally better than a competitor in the confined realm of \"being a database.\"\nAre Stitch microservices enough to justify keeping your instance with the\nMongoDB team?\n\nService-by-Service Breakdown of Stitch\nStitch is kind of like if AWS exited in an alternative universe, where JSON and\nJavaScript were earth's only technologies. Thinking back to how we create APIs\nin AWS, the status quo almost always involves spinning up a Dynamo  (NoSQL)\ndatabase to put behind Lambda functions, accessible by API Gateway endpoints.\nStitch's core use case revolves around this use-case of end-user-accessing-data,\nwith a number of services dedicated specifically to supporting or improving this\nflow. The closest comparison to Stitch would be GCloud's Firebase. \n\nSo what makes Stitch so special?\n\nService 1: Querying Atlas Securely via Frontend Code\nSomething that cannot be understated is the ability to query Atlas via frontend\nJavascript. We're not passing API keys, Secrets, or any sort of nonsense;\nbecause you're configured things correctly, whitelisted domains can run queries\nof any complexity without ever interacting with an app's backend.  This is not a\ncrazy use case: consider this blog for example, or more so lately, mobile\napplications:\n\n<script src=\"https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js\"></script>\n<script>\n  const client = stitch.Stitch.initializeDefaultAppClient('myapp');\n\n  const db = client.getServiceClient(stitch.RemoteMongoClient.factory, 'mongodb-atlas').db('<DATABASE>');\n\n  client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => \n    db.collection('<COLLECTION>').updateOne({owner_id: client.auth.user.id}, {$set:{number:42}}, {upsert:true})\n  ).then(() => \n    db.collection('<COLLECTION>').find({owner_id: client.auth.user.id}, { limit: 100}).asArray()\n  ).then(docs => {\n      console.log(\"Found docs\", docs)\n      console.log(\"[MongoDB Stitch] Connected to Stitch\")\n  }).catch(err => {\n    console.error(err)\n  });\n</script>\n\n\nThis isn't to say we're allowing any user to query any data all willy-nilly just\nbecause they're on our whitelisted IP: all data stored in Atlas is restricted to\nspecified Users  by defining User Roles. Joe Schmoe can't just inject a query\ninto any presumed database and wreak havoc, because Joe Schmoe can only access\ndata we've permitted his user account to view or write to. What is this \"user\naccount\" you ask? This brings us to the next big feature...\n\nService 2: End-User Account Creation & Management\nStitch will handle user account creation for you without the boilerplate.\nCreating an app with user accounts is a huge pain in the ass. Cheeky phrases\nlike 'Do the OAuth Dance'  can't ever hope to minimize the agonizing repetitive\npain of creating user accounts or managing relationships between users and data\n(can user X  see a comment from user Y?). Stitch allows most of the intolerably\nbenign logic behind these features to be handled via a UI.\n\nIt would be a far cry to say these processes have been \"trivialized\", but the\ntime saved is perhaps just enough to keep a coding hobbyist interested in their\nside projects as opposed to giving up and playing Rocket League.\n\nAs far as the permissions to read comments go... well, here's a self-explanatory\nscreenshot of how Stitch handles read/write document permission in its simplest\nform:\n\nOwners of comments can write their comments. Everybody else reads. Seems simple.\nService 3: Serverless Functions\nStitch functions are akin to AWS Lambda functions, but much easier to configure\nfor cross-service integration (and also limited to JavaScript ECMA 2015 or\nsomething). Functions benefit from the previous two features, in that they too\ncan be triggered from a whitelisted app's frontend, and are governed by a simple\n\"rules\" system, eliminating the need for security group configurations etc.\n\nThis is what calling a function from an app's frontend looks like:\n\n<script>\n    client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => {\n     client.callFunction(\"numCards\", [\"In Progress\"]).then(results => {\n       $('#progress .count').text(results + ' issues');\n     })\n    });\n</script>\n\n\nFunctions can run any query against Atlas, retrieve values  (such as environment\nvariables), and even call other functions. Functions can also be fired by\ndatabase triggers,  where a change to a collection will prompt an action such as\nan alert.\n\nService 4: HTTP Webhooks\nWebhooks are a fast way to toss up endpoints. Stitch endpoints are agnostic to\none another in that they are one-off URLs to perform single tasks. We could\nnever build a well-designed API using Stitch Webhooks, as we could with API\nGateway; this simply isn't the niche MongoDB is trying to hit (the opposite, in\nfact). \n\nConfiguration for a single Webhook.This form with a mere 6 fields clearly\nillustrates what Stitch intends to do: trivializing the creation of\ntraditionally non-trivial features.\n\nService 5: Storing 'Values' in Stitch\nA \"value\" is equivalent to an environment variable. These can be used to store\nAPI keys, secrets, or whatever. Of course, values are retrieved via functions.\n\nShhh, it's a secret ;)Service 6+: A Bunch of Mostly Bloated Extras\nFinally, Stitch has thrown in a few third-party integrations for good measure.\nSome integrations like S3 Integration could definitely come in handy, but it's\nworth asking why Mongo constantly over advertises their integrations with Github \n and Twilio. We've already established that we can create endpoints which accept\ninformation, and we can make functions which GET  information... so isn't\nanything with an API pretty easy to 'integrate' with?\n\nThis isn't to say the extra services aren't useful, they just seem a bit... odd.\nIt feels a lot like bloating the catalog, but the catalog isn't nearly bloated\nenough where it feels normal (like Heroku add-ons, for example). The choice to\nlaunch Stitch with a handful of barely-useful integrations only comes off as\nmore and more aimless as time passes; as months turn to years and no additions\nor updates are made to service offerings, it's worth questioning what the vision\nhad been for the product in the first place. In my experience, feature sets like\nthese happen when Product Managers are more powerful than they are useful.\n\nThe Breathtaking Climax: Is Stitch Worth It?\nI've been utilizing Stitch to fill in the blanks in development for months now,\nperhaps nearly a year. Each time I find myself working with Stitch or looking at\nthe bill, I can't decide if it's been a Godsend for its nich\u001dé, or an expensive\ntoy with an infuriating lack of accurate documentation.\n\n  Stitch is very much a copy-and-paste-cookie-cutter-code  type of product,\nwhich begs the question of why their tutorials are recklessly outdated;\nsometimes to the point where MongoDB's own tutorial source code doesn't work. \nThere are so many use cases and potential benefits to Stitch, so why is the \nGithub repo [https://github.com/mongodb/stitch-examples]  containing example\ncode snippets so unmaintained, and painfully irrelevant? Lastly, why am I\nselling this product harder than their own internal team?\n\nStitch is a good product with a lot of unfortunate oversight. That said, Google\nFirebase still doesn't even have an \"import data\" feature, so I suppose it's\ntime to dig deep into this vendor lock and write a 5-post series about it before\nSilicon Valley's best and brightest get their shit together enough to actually\ncreate something useful and intuitive for other human beings to use. In the\nmeantime, feel free to steal source from tutorials I'll be posting, because\nthey'll be sure to, you know, actually work.","html":"<p>Unless you've been living under a rock (or only visit this site via work-related Google Searches, like most people) you've probably heard me drone on here and there about <strong>MongoDB Atlas</strong> and <strong>MongoDB Stitch</strong>. I even went so far as to hack together an awful workflow that somehow utilized Tableau as an ETL tool to feed JIRA information into Mongo. I'd like to formally apologize for that entire series: I can't imagine there's a single soul on this planet interested in learning about all of those things simultaneously. Such hobbies reserved for masochists with blogging addictions. I apologize. Let's start over.</p><p>First off, this is not a tutorial on how to use <em>MongoDB: the database</em>. I have zero interest cluttering the internet by reiterating what a MEAN stack is for the ten thousandth time, nor will I bore you with core NoSQL concepts you already understand. I'm here to talk about the giant on the horizon we didn't see coming, where MongoDB the database decided to become <a href=\"https://en.wikipedia.org/wiki/MongoDB_Inc.\"><strong>MongoDB Inc</strong></a><strong>:</strong> the enterprise cloud provider. The same MongoDB that recently purchased <a href=\"https://www.mongodb.com/press/mongodb-strengthens-global-cloud-database-with-acquisition-of-mlab\">mLab</a>, the <em>other</em> cloud-hosted solution for Mongo databases. MongoDB the company is bold enough to place its bets on building a cloud <em>far</em> simpler and restricted than either AWS or GCloud. The core of that bet implies that most of us aren't exactly building unicorn products as much as we're reinventing the wheel: and they're probably right.</p><p>Welcome to our series on MongoDB cloud, where we break down every service MongoDB has to offer; one by one.</p><h2 id=\"what-is-mongodb-cloud-and-does-it-exist\">What is MongoDB Cloud, and Does it Exist?</h2><p>What I refer to as \"MongoDB Cloud\" (which, for some reason, isn't the actual name of the suite MongoDB offers) is actually two products:</p><ul><li><strong>MongoDB Atlas</strong>: A cloud-hosted MongoDB cluster with a beefy set of features. Real-time dashboards, high-availability, security features,  an awesome desktop client, and a CLI to top it all off.</li><li><strong>MongoDB Stitch: </strong>A group of services designed to interact with Atlas in every conceivable way, including creating endpoints, triggers, user authentication flows, serverless functions, and a UI to handle all of this.</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/metrics.gif\" class=\"kg-image\"><figcaption>I'm spying on you and every query you make.</figcaption></figure><h3 id=\"atlas-as-a-standalone-database\">Atlas as a Standalone Database</h3><p>There are plenty of people who simply want an instance of MongoDB hosted in the cloud as-is: just ask the guys at mLab. This was in fact how I got pulled into Mongo's cloud myself.</p><p>MongoDB Atlas has plenty of advantages over a self-hosted instance of Mongo, which Mongo itself is confident in by offering a <a href=\"https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/\">free tier</a> of Atlas to prospective buyers. If you're a company or enterprise, the phrases <strong>High Availability</strong>, <strong>Horizontal Scalability, </strong>relatively <strong>Higher Performance</strong> will probably be enough for you. But for us hobbyists, why pay for a Mongo cloud instance?</p><p>Mongo themselves gives this comparison:</p><div class=\"tableContainer\">\n<table class=\"table left\">\n  <thead>\n    <tr>\n      <th>\n        <strong>Overview</strong>\n      </th>\n      <th>\n        <strong>MongoDB Atlas</strong>\n      </th>\n      <th>\n        <strong>Compose</strong>\n      </th>\n      <th>\n        <strong>ObjectRocket</strong>\n      </th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\n        Free Tier\n      </td>\n      <td>\n        Yes<br><small>Storage: 512 MB<br>RAM: Variable</small>\n      </td>\n      <td>\n        No<br><small>30-day free trial</small>\n      </td>\n      <td>\n        No<br><small>30-day free trial</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Live migration\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Choice of cloud providers\n      </td>\n      <td>\n        AWS, Azure &amp; GCP\n      </td>\n      <td>\n        AWS, Softlayer &amp; GCP<br><small>Available in 2 regions for each provider</small>\n      </td>\n      <td>\n        Rackspace\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Choice of instance configuration\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small>Configuration based on required storage capacity only. No way to independently select underlying hardware configurations</small>\n      </td>\n      <td>\n        No<br><small>Configuration based on required storage capacity only. No way to independently select underlying hardware configurations</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Availability of latest MongoDB version\n      </td>\n      <td>\n        Yes<br><small>New versions of the database are available on MongoDB Atlas as soon as they are released</small>\n      </td>\n      <td>\n        No<br><small>New versions typically available 1-2 quarters following database release<br></small>\n      </td>\n      <td>\n        No<br><small>New versions typically available 1-2 quarters following database release<br></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Replica Set Configuration\n      </td>\n      <td>\n        Up to 7 replicas<br><small>All replicas configured as data-bearing nodes</small>\n      </td>\n      <td>\n        3 data-bearing nodes<br><small>One of the data-bearing nodes is hidden and used for backups only</small>\n      </td>\n      <td>\n        3 data-bearing nodes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Automatic Sharding Support\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Data explorer\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        SQL-based BI Connectivity\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Pause and resume clusters\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Database supported in on-premise deployments\n      </td>\n      <td>\n        Yes<br><small><a href=\"/products/mongodb-enterprise-advanced\">MongoDB Enterprise Advanced</a></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Global writes <small>Low-latency writes from anywhere in the world </small>\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Cross-region replication <small>Distribute data around the world for multi-region fault tolerance and local reads </small>\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No\n      </td>\n      <td>\n        No\n      </td>\n    </tr><tr>\n      <td>\n        Monitoring of database health with automated alerting\n      </td>\n      <td>\n        Yes<br><small>MongoDB Atlas UI &amp; support for APM platforms (New Relic)</small>\n      </td>\n      <td>\n        Yes<br><small>New Relic</small>\n      </td>\n      <td>\n        Yes<br><small>New Relic</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Continuous backup\n      </td>\n      <td>\n        Yes<br><small>Backups maintained<br>seconds behind production cluster</small>\n      </td>\n      <td>\n        No<br><small>Backups taken with mongodump against hidden replica set member</small>\n      </td>\n      <td>\n        No<br><small>Backups taken with mongodump</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Queryable backups\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Automated &amp; consistent snapshots of sharded clusters\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Not Applicable<br><small>No support for auto-sharding</small>\n      </td>\n      <td>\n        No<br><small>Requires manually coordinating the recovery of mongodumps across shards</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Access control &amp; IP whitelisting\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        AWS VPC Peering\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Beta Release<br><small></small>\n      </td>\n      <td>\n        Yes<br><small>Additional Charge</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Encryption of data in-flight\n      </td>\n      <td>\n        Yes<br><small>TLS/SSL as standard</small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Encryption of data at-rest\n      </td>\n      <td>\n        Yes<br><small>Available for AWS deployments; always on with Azure and GCP</small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        Yes<br><small>Available only with specific pricing plans and data centers</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        LDAP Integration\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Database-level auditing<br><small>Track DDL, DML, DCL operations</small>\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Bring your own KMS\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Realistically there are probably only a number of items that stand out on the comparison list when we go strictly database-to-database. Freedom over <strong>instance configuration </strong>sounds great, but in practice is more similar to putting a cap on how much MongoDB decides to charge you that month (by the way, it's usually a lot; keep this mind). Having the <strong>Latest Version</strong> seems great, but this can just as easily mean breaking production unannounced as much as it means new features.</p><p>MongoDB clearly wins over the enterprise space with <strong>Continuous &amp; queryable backups</strong>, integration with <strong>LDAP, </strong>and <strong>automatic sharding support. </strong>Truthfully if this were merely a database-level feature and cost comparison, the decision to go with<strong> MongoDB Atlas</strong> would come down to how much you like their pretty desktop interface:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/compass.gif\" class=\"kg-image\"><figcaption>A perfectly legitimate reason to pay up, imho.</figcaption></figure><p>So let's say MongoDB Atlas is marginally better than a competitor in the confined realm of \"being a database.\" Are Stitch microservices enough to justify keeping your instance with the MongoDB team?</p><h2 id=\"service-by-service-breakdown-of-stitch\">Service-by-Service Breakdown of Stitch</h2><p>Stitch is kind of like if AWS exited in an alternative universe, where JSON and JavaScript were earth's only technologies. Thinking back to how we create APIs in AWS, the status quo almost always involves spinning up a <strong>Dynamo</strong> (NoSQL) database to put behind <strong>Lambda </strong>functions, accessible by <strong>API Gateway </strong>endpoints. Stitch's core use case revolves around this use-case of <em>end-user-accessing-data</em>, with a number of services dedicated specifically to supporting or improving this flow. The closest comparison to Stitch would be GCloud's <strong>Firebase</strong>. </p><p>So what makes Stitch so special?</p><h3 id=\"service-1-querying-atlas-securely-via-frontend-code\">Service 1: Querying Atlas Securely via Frontend Code</h3><p>Something that cannot be understated is the ability to query Atlas via frontend Javascript. We're not passing API keys, Secrets, or any sort of nonsense; because you're configured things correctly, whitelisted domains can run queries of any complexity <em>without ever interacting with an app's backend.</em> This is not a crazy use case: consider this blog for example, or more so lately, mobile applications:</p><pre><code class=\"language-javascript\">&lt;script src=&quot;https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js&quot;&gt;&lt;/script&gt;\n&lt;script&gt;\n  const client = stitch.Stitch.initializeDefaultAppClient('myapp');\n\n  const db = client.getServiceClient(stitch.RemoteMongoClient.factory, 'mongodb-atlas').db('&lt;DATABASE&gt;');\n\n  client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; \n    db.collection('&lt;COLLECTION&gt;').updateOne({owner_id: client.auth.user.id}, {$set:{number:42}}, {upsert:true})\n  ).then(() =&gt; \n    db.collection('&lt;COLLECTION&gt;').find({owner_id: client.auth.user.id}, { limit: 100}).asArray()\n  ).then(docs =&gt; {\n      console.log(&quot;Found docs&quot;, docs)\n      console.log(&quot;[MongoDB Stitch] Connected to Stitch&quot;)\n  }).catch(err =&gt; {\n    console.error(err)\n  });\n&lt;/script&gt;\n</code></pre>\n<p>This isn't to say we're allowing any user to query any data all willy-nilly just because they're on our whitelisted IP: all data stored in Atlas is restricted to specified <strong>Users</strong> by defining <strong>User Roles. </strong>Joe Schmoe can't just inject a query into any presumed database and wreak havoc, because Joe Schmoe can only access data we've permitted his user account to view or write to. What is this \"user account\" you ask? This brings us to the next big feature...</p><h3 id=\"service-2-end-user-account-creation-management\">Service 2: End-User Account Creation &amp; Management</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-13-at-5.59.03-PM.png\" class=\"kg-image\"><figcaption>Stitch will handle user account creation for you without the boilerplate.</figcaption></figure><p>Creating an app with user accounts is a huge pain in the ass. Cheeky phrases like '<strong>Do the OAuth Dance'</strong> can't ever hope to minimize the agonizing repetitive pain of creating user accounts or managing relationships between users and data (can <em>user X</em> see a comment from <em>user Y</em>?). Stitch allows most of the intolerably benign logic behind these features to be handled via a UI.</p><p>It would be a far cry to say these processes have been \"trivialized\", but the time saved is perhaps just enough to keep a coding hobbyist interested in their side projects as opposed to giving up and playing Rocket League.</p><p>As far as the permissions to read comments go... well, here's a self-explanatory screenshot of how Stitch handles read/write document permission in its simplest form:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-13-at-6.09.25-PM.png\" class=\"kg-image\"><figcaption>Owners of comments can write their comments. Everybody else reads. Seems simple.</figcaption></figure><h3 id=\"service-3-serverless-functions\">Service 3: Serverless Functions</h3><p>Stitch functions are akin to AWS Lambda functions, but much easier to configure for cross-service integration (and also limited to JavaScript ECMA 2015 or something). Functions benefit from the previous two features, in that they too can be triggered from a whitelisted app's frontend, and are governed by a simple \"rules\" system, eliminating the need for security group configurations etc.</p><p>This is what calling a function from an app's frontend looks like:</p><pre><code class=\"language-javascript\">&lt;script&gt;\n    client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; {\n     client.callFunction(&quot;numCards&quot;, [&quot;In Progress&quot;]).then(results =&gt; {\n       $('#progress .count').text(results + ' issues');\n     })\n    });\n&lt;/script&gt;\n</code></pre>\n<p>Functions can run any query against Atlas, retrieve <em>values</em> (such as environment variables), and even call other functions. Functions can also be fired by database <strong>triggers,</strong> where a change to a collection will prompt an action such as an alert.</p><h3 id=\"service-4-http-webhooks\">Service 4: HTTP Webhooks</h3><p>Webhooks are a fast way to toss up endpoints. Stitch endpoints are agnostic to one another in that they are one-off URLs to perform single tasks. We could never build a well-designed API using Stitch Webhooks, as we could with <strong>API Gateway</strong>; this simply isn't the niche MongoDB is trying to hit (the opposite, in fact). </p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-14-at-4.33.27-PM.png\" class=\"kg-image\"><figcaption>Configuration for a single Webhook.</figcaption></figure><p>This form with a mere 6 fields clearly illustrates what Stitch intends to do: trivializing the creation of traditionally non-trivial features.</p><h3 id=\"service-5-storing-values-in-stitch\">Service 5: Storing 'Values' in Stitch</h3><p>A \"value\" is equivalent to an environment variable. These can be used to store API keys, secrets, or whatever. Of course, values are retrieved via functions.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-14-at-7.45.28-PM.png\" class=\"kg-image\"><figcaption>Shhh, it's a secret ;)</figcaption></figure><h3 id=\"service-6-a-bunch-of-mostly-bloated-extras\">Service 6+: A Bunch of Mostly Bloated Extras</h3><p>Finally, Stitch has thrown in a few third-party integrations for good measure. Some integrations like <strong>S3 Integration </strong>could definitely come in handy, but it's worth asking why Mongo constantly over advertises their integrations with <strong>Github</strong> and <strong>Twilio</strong>. We've already established that we can create endpoints which accept information, and we can make functions which <em>GET</em> information... so isn't anything with an API pretty easy to 'integrate' with?</p><p>This isn't to say the extra services aren't useful, they just seem a bit... odd. It feels a lot like bloating the catalog, but the catalog isn't nearly bloated enough where it feels normal (like Heroku add-ons, for example). The choice to launch Stitch with a handful of barely-useful integrations only comes off as more and more aimless as time passes; as months turn to years and no additions or updates are made to service offerings, it's worth questioning what the vision had been for the product in the first place. In my experience, feature sets like these happen when Product Managers are more powerful than they are useful.</p><h2 id=\"the-breathtaking-climax-is-stitch-worth-it\">The Breathtaking Climax: Is Stitch Worth It?</h2><p>I've been utilizing Stitch to fill in the blanks in development for months now, perhaps nearly a year. Each time I find myself working with Stitch or looking at the bill, I can't decide if it's been a Godsend for its nich\u001dé, or an expensive toy with an infuriating lack of accurate documentation.</p><p> Stitch is very much a <em>copy-and-paste-cookie-cutter-code</em> type of product, which begs the question of why their tutorials are recklessly outdated; sometimes to the point where MongoDB's own tutorial source code <em>doesn't work. </em>There are so many use cases and potential benefits to Stitch, so why is the <a href=\"https://github.com/mongodb/stitch-examples\">Github repo</a> containing example code snippets so unmaintained, and painfully irrelevant? Lastly, why am I selling this product harder than their own internal team?</p><p>Stitch is a good product with a lot of unfortunate oversight. That said, Google Firebase still doesn't even have an \"import data\" feature, so I suppose it's time to dig deep into this vendor lock and write a 5-post series about it before Silicon Valley's best and brightest get their shit together enough to actually create something useful and intuitive for other human beings to use. In the meantime, feel free to steal source from tutorials I'll be posting, because they'll be sure to, you know, actually work.</p>","url":"https://hackersandslackers.com/mongodb-cloud-backend-as-a-service-with-atlas-and-stitch/","uuid":"5555fa6e-07f0-4f9a-8069-e1e68868e608","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5beb3c900dbec217f3ce801b"}}]}},"pageContext":{"slug":"todd","limit":12,"skip":24,"numberOfPages":8,"humanPageNumber":3,"prevPageNumber":2,"nextPageNumber":4,"previousPagePath":"/author/todd/page/2/","nextPagePath":"/author/todd/page/4/"}}