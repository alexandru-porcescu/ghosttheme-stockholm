{"data":{"ghostTag":{"slug":"architecture","name":"Architecture","visibility":"public","feature_image":null,"description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc."},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736aa","title":"Create a VPS with Google Cloud: Introducing Compute Engine","slug":"setting-up-dns-with-google-cloud-platform","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","excerpt":"Spin up a VPS and configure DNS with relative ease.","custom_excerpt":"Spin up a VPS and configure DNS with relative ease.","created_at_pretty":"14 July, 2018","published_at_pretty":"14 July, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-07-14T10:28:34.000-04:00","published_at":"2018-07-14T14:55:03.000-04:00","updated_at":"2019-02-14T02:29:40.000-05:00","meta_title":"Google Cloud Platform: Creating a VPS | Hackers and Slackers","meta_description":"Google Cloud Platform is a compelling choice for respectable enterprises, particularly those with a sense of style and curiosity.","og_description":"The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity just yet. Let's set up a server to see what the hype is about. Today'll we'll be creating a standard Linux instance and walking through the steps to configure an existing DNS for said instance.","og_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","og_title":"Create a VPS with Google Cloud: Compute Engine","twitter_description":"The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity just yet. Let's set up a server to see what the hype is about. Today'll we'll be creating a standard Linux instance and walking through the steps to configure an existing DNS for said instance.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","twitter_title":"Create a VPS with Google Cloud: Compute Engine","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"}],"plaintext":"For the last few weeks I've been enamored with Google's cloud platform, aptly\nnamed Google Cloud Platform. GCP contains the things you might expect from a\nyoung player in the 'screw AWS' space: much of what exists on AWS has an\nequivalent on GPC, but certain subtleties exist, such as the lack of Python\nserverless functions and so forth. That said, GCP makes up for any shortcomings\nby leveraging services exclusive to Google.\n\nIn my opinion, GCP is the first contender in the market to package enterprise\ncloud computing in a satisfying way. It's clear GCP has assigned UI and Product\nManagement resources to their platform, where Amazon clearly did not. while not\nwithout its shortcomings, it's obvious Google has chosen usability as a key\ndifferentiator from AWS.\n\nAside from the UI, GCP offers plenty of fun functionality such as their cloud\nlauncher. This is the equivalent of one-click deploys for cool stuff, whether\nthey be services to add to your VPC, Google APIs, Datasets, or what have you.\nThe ease of plug-and-play these plug-and-play services make GCP a compelling\nchoice for a respectable enterprise which hasn't lost the gift of curiosity.\n\nIt's like product hunt... on crack.The best way to get a feel for what value a\nproduct has would be use it, of course. In the interest of becoming familiar\nwith Google Cloud, we'll execute the most basic task of setting up a VPS to\ndeploy code to. This practice will end up touching on many of GCP's core\nservices which will allow us to grasp the basic offerings of the product, as\nwell as its strengths and weakness.\n\nDoes in Fact Compute \nGCP cutely names their server's Compute Engines,  which are at least more\ntolerable than, say, EC2 instances. I'm just going to call them servers because\nI'm not the type of person who orders a \"tall\" at Starbucks.\n\nCreate a \"project\" in Google Cloud, and you'll immediately land at a dashboard.\nAll Google's services are tucked away in the left-hand menu. Open that bad boy\nup and find Compute Engine.\n\nShhh, it's thinking.Select create. As opposed to the preset choices of VPCS you might be used to,\nGoogle allows us to customize our VPS to our exact technical specifications on a\nsliding scale. Want 96 processing cores, but only a single GB of RAM? No\nproblem, if that's what you're into. Weirdo.\n\nAs well as picking between the usual Linux distributions, Compute Engine also\nallows customers to select their number of GPUs, as well as the generation of\nIntel CPU their instance will run on.\n\nDat customization thoWe want traffic to hit this instance, so make sure you\ncheck Allow HTTP  traffic  and Allow HTTPS traffic  before continuing. Once your\ninstance is created, you should immediately able to SSH into your server via\nGCP's browser client.\n\nThe App Engine\nGCP is not without its own fair share of arbitrary product classifications. DNS\nrecords and hosts are contained within the App Engine  service of the platform.\nFind the App Engine service in the left hand navigation, and scroll down to the \nsettings  link:\n\nAllllll the way at the bottom.Here's we'll be able to see a \"custom domains\" tab\nwhich allows us to point a domain we've purchased from a service like Namecheap \n or what-have-you to Google Cloud. I'll personally be walking though this\nexample by directing a pointless domain called memegenerator.io  I purchased on\nNamecheap for no good reason.\n\nWhen you add a custom domain via this screen, you'll immediately be asked to\nverify ownership over the domain via the familiar Google Webmaster tool, which\nyou'll be redirected to automatically.\n\nBack to Your Registrar\nChances are you've dealt with verification via Google webmaster before, but this\ntime we've only given the option to do this via DNS. Select your registrar in\nthe dropdown in order to reveal a Google-generated record used to verify your\ndomain. \n\nPlease don't tell me you use GoDaddy.The resulting value will need to be added\nas a .txt record before we can actually point your domain to Google's servers.\n\nIf you're using Namecheap like I am, log in to your dashboard and find your\ndomain by clicking \"manage domain\". Make sure you're under the \"advanced DNS\"\ntab:\n\nEven if you're not using Namecheap, this shouldn't be much different.Delete all\nexisting records. Then create a TXT record (with @ as the host) and input the\nvalue that Google provided you earlier. Now, when you return to the webmaster\ntool, clicking verify tool should  pick up on this change. \n\nIf the webmaster tool does not pick up on this verification right away, don't\npanic. This happens fairly often - just frantically keep making sure everything\nis set up correctly while mashing the verify button.Navigate back to the Custom\nDomains tab in GCP and continue the process- you should see that your domain is\nverified. You'll be prompted to enter any subdomains you'd GCP to pick up on\nhere. Wrap that up and save.\n\n\n\nMake it Rain with Records\nOh, we're far from over buddy. We need to go back to update our A and AAAA\nrecords, now that Google as bestowed that privilege upon us. You should see a\ntable such as the one below:\n\nType\n Data\n Alias\n A\n 216.239.32.21\n A\n 216.239.34.21\n A\n 216.239.36.21\n A\n 216.239.38.21\n AAAA\n 2001:4860:4802:32::15\n AAAA\n 2001:4860:4802:34::15\n AAAA\n 2001:4860:4802:36::15\n AAAA\n 2001:4860:4802:38::15\n CNAME\n ghs.googlehosted.com\n www\n Copy that into your registrar's custom DNS records. Have fun with that.\n\nCloud DNS\nYou may have noticed that we haven't actually specified our Nameservers yet.\nNobody said this was going to be fun; if it were, we probably wouldn't need this\ntutorial. In the GCP search bar, search for Cloud DNS. Create a Zone, and leave\nDNSSEC off.\n\n\n\nBefore we do this next part, I'd like to interject and mention that you did a\nspectacular job of creating all those records and pasting all those values\nearlier. Considering you seem to have a knack for this, it probably won't hurt\nto know that we need to go back into our registrar a third time to paste some\nvalues. You got this. \n\nGoogle's nameservers have now been generated and exposed to you so we can \nactually  point our domain to something meaningful now. You should have 4\nnameservers like the following:\n\nName\n Type\n TTL\n Data\n memegenerator.io.\n NS\n 21600\n ns-cloud-b1.googledomains.com.\n ns-cloud-b2.googledomains.com.\n ns-cloud-b3.googledomains.com.\n ns-cloud-b4.googledomains.com.\n Assign a Static IP\nOkay, we're officially done messing around with our registrar. In the GCP search\nbar, search for External IP addresses.  From there, click the \"Reserve static\nAddress\" button at the top of the screen. This will prompt you with a short\nform: the only important field to fill out here is the \"Attached to\"  dropdown,\nwhich denotes which server instance the IP will be assigned to.\n\nCompute Engine Instance Settings\nShit, is there even more? OK, we're almost done here. Go to your Compute Engine\ninstance you set up earlier. Click \"Edit\". Scroll to the Network Interface \nsection and map the Static IP we created from earlier. Also, go ahead and enter\nyour PTR record:\n\nWhen will it end... please send help.FINAL CHAPTER: Firewall Settings\nLook, I just want to say you're all doing a great job so far. All of you. We're\nall a team here; let's stick together and see this through. Search for Firewall\nRules  and selected Create a Firewall Rule. Name it whatever you want.\n\n * Targets  - This will be where our traffic routes. We want to route to our\n   instance, which is a specified service account.\n * Target service account  - Referring to the above, this is where we select the\n   computer instance we want to hit.\n * Target service account  scope  - Select \"in this project\".\n * Source Filter - Once again, select specified service account.\n * Source service account  scope - Select \"in this project\"\n * Source service account  - This is where we say where the traffic is coming\n   from. It's coming from the App engine, as this is where we specified our DNS.\n * For IPs  and ports, well, do what you want. It's your server. \n\nGet at it\nWell, there you have it. Hopefully by now the domain you've painstaking\nconfigured now points to your server, so you can go ahead and configure your\nwebserver settings or whatever it is you do.\n\nAlright fine, so GCP isn't completely free of its own redundancies. As much as I\nlove to hate on AWS, it seems almost inevitable at this point that any\nenterprise cloud service will maintain a certain level of obscure processes.\nThis is great for flexibility when scaling, but let's be honest: if these\nplatforms were easy to use, who would pay for the certifications?\n\nCheekiness aside, I've become a strong fan of GCP. Google seems to have hit a\nmiddle ground between being user-friendly and powerful, which fills a niché\nwe'll realize was desperately needed. For a fair review of the platform itself,\nI find myself agreeing mostly with this stranger from the internet: \nhttps://www.deps.co/blog/google-cloud-platform-good-bad-ugly/","html":"<p>For the last few weeks I've been enamored with Google's cloud platform, aptly named Google Cloud Platform. GCP contains the things you might expect from a young player in the 'screw AWS' space: much of what exists on AWS has an equivalent on GPC, but certain subtleties exist, such as the lack of Python serverless functions and so forth. That said, GCP makes up for any shortcomings by leveraging services exclusive to Google.</p><p>In my opinion, GCP is the first contender in the market to package enterprise cloud computing in a satisfying way. It's clear GCP has assigned UI and Product Management resources to their platform, where Amazon clearly did not. while not without its shortcomings, it's obvious Google has chosen usability as a key differentiator from AWS.</p><p>Aside from the UI, GCP offers plenty of fun functionality such as their cloud launcher. This is the equivalent of one-click deploys for cool stuff, whether they be services to add to your VPC, Google APIs, Datasets, or what have you. The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-07-14_10-36-02.gif\" class=\"kg-image\"><figcaption>It's like product hunt... on crack.</figcaption></figure><p>The best way to get a feel for what value a product has would be use it, of course. In the interest of becoming familiar with Google Cloud, we'll execute the most basic task of setting up a VPS to deploy code to. This practice will end up touching on many of GCP's core services which will allow us to grasp the basic offerings of the product, as well as its strengths and weakness.</p><h2 id=\"does-in-fact-compute\">Does in Fact Compute </h2><p>GCP cutely names their server's <em>Compute Engines,</em> which are at least more tolerable than, say, EC2 instances. I'm just going to call them servers because I'm not the type of person who orders a \"tall\" at Starbucks.</p><p>Create a \"project\" in Google Cloud, and you'll immediately land at a dashboard. All Google's services are tucked away in the left-hand menu. Open that bad boy up and find Compute Engine.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-07-14_10-44-14.gif\" class=\"kg-image\"><figcaption>Shhh, it's thinking.</figcaption></figure><p>Select <em>create</em>. As opposed to the preset choices of VPCS you might be used to, Google allows us to customize our VPS to our exact technical specifications on a sliding scale. Want 96 processing cores, but only a single GB of RAM? No problem, if that's what you're into. Weirdo.</p><p>As well as picking between the usual Linux distributions, Compute Engine also allows customers to select their number of GPUs, as well as the generation of Intel CPU their instance will run on.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-10.48.02-AM.png\" class=\"kg-image\"><figcaption>Dat customization tho</figcaption></figure><p>We want traffic to hit this instance, so make sure you check <strong>Allow HTTP</strong> <strong>traffic</strong> and <strong>Allow HTTPS traffic</strong> before continuing. Once your instance is created, you should immediately able to SSH into your server via GCP's browser client.</p><h2 id=\"the-app-engine\">The App Engine</h2><p>GCP is not without its own fair share of arbitrary product classifications. DNS records and hosts are contained within the <strong>App Engine</strong> service of the platform. Find the App Engine service in the left hand navigation, and scroll down to the <em>settings</em> link:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-10.58.19-AM.png\" class=\"kg-image\"><figcaption>Allllll the way at the bottom.</figcaption></figure><p>Here's we'll be able to see a \"custom domains\" tab which allows us to point a domain we've purchased from a service like <strong>Namecheap</strong><em> </em>or what-have-you to Google Cloud. I'll personally be walking though this example by directing a pointless domain called <em>memegenerator.io</em> I purchased on Namecheap for no good reason.</p><p>When you add a custom domain via this screen, you'll immediately be asked to verify ownership over the domain via the familiar Google Webmaster tool, which you'll be redirected to automatically.</p><h2 id=\"back-to-your-registrar\">Back to Your Registrar</h2><p>Chances are you've dealt with verification via Google webmaster before, but this time we've only given the option to do this via DNS. Select your registrar in the dropdown in order to reveal a Google-generated record used to verify your domain. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.04.07-AM.png\" class=\"kg-image\"><figcaption>Please don't tell me you use GoDaddy.</figcaption></figure><p>The resulting value will need to be added as a .txt record before we can actually point your domain to Google's servers.</p><p>If you're using Namecheap like I am, log in to your dashboard and find your domain by clicking \"manage domain\". Make sure you're under the \"advanced DNS\" tab:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.08.58-AM.png\" class=\"kg-image\"><figcaption>Even if you're not using Namecheap, this shouldn't be much different.</figcaption></figure><p>Delete all existing records. Then create a TXT record (with @ as the host) and input the value that Google provided you earlier. Now, when you return to the webmaster tool, clicking verify tool <em>should</em> pick up on this change. </p><div class=\"protip\">\nIf the webmaster tool does not pick up on this verification right away, don't panic. This happens fairly often - just frantically keep making sure everything is set up correctly while mashing the verify button.\n</div><p>Navigate back to the Custom Domains tab in GCP and continue the process- you should see that your domain is verified. You'll be prompted to enter any subdomains you'd GCP to pick up on here. Wrap that up and save.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.13.27-AM.png\" class=\"kg-image\"></figure><p></p><h2 id=\"make-it-rain-with-records\">Make it Rain with Records</h2><p>Oh, we're far from over buddy. We need to go back to update our A and AAAA records, now that Google as bestowed that privilege upon us. You should see a table such as the one below:</p><div class=\"tablecontainer\">\n<table>\n  <thead>\n    <tr>\n      <th>Type</th>\n      <th>Data</th>\n      <th>Alias</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>A</td>\n      <td>216.239.32.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.34.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.36.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.38.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:32::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:34::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:36::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:38::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>CNAME</td>\n      <td>ghs.googlehosted.com</td>\n      <td>www</td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Copy that into your registrar's custom DNS records. Have fun with that.</p><h2 id=\"cloud-dns\">Cloud DNS</h2><p>You may have noticed that we haven't actually specified our Nameservers yet. Nobody said this was going to be fun; if it were, we probably wouldn't need this tutorial. In the GCP search bar, search for <em>Cloud DNS</em>. Create a Zone, and leave DNSSEC off.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.25.33-AM.png\" class=\"kg-image\"></figure><p></p><p>Before we do this next part, I'd like to interject and mention that you did a spectacular job of creating all those records and pasting all those values earlier. Considering you seem to have a knack for this, it probably won't hurt to know that we need to go back into our registrar a third time to paste some values. You got this. </p><p>Google's nameservers have now been generated and exposed to you so we can <em>actually</em> point our domain to something meaningful now. You should have 4 nameservers like the following:</p><table>\n  <thead>\n    <tr>\n      <th>Name</th>\n      <th>Type</th>\n      <th>TTL</th>\n      <th>Data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>memegenerator.io.</td>\n      <td>NS</td>\n      <td>21600</td>\n      <td>ns-cloud-b1.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b2.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b3.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b4.googledomains.com.</td>\n    </tr>\n  </tbody>\n</table><h2 id=\"assign-a-static-ip\">Assign a Static IP</h2><p>Okay, we're officially done messing around with our registrar. In the GCP search bar, search for <strong>External IP addresses.</strong> From there, click the \"Reserve static Address\" button at the top of the screen. This will prompt you with a short form: the only important field to fill out here is the <em>\"Attached to\"</em> dropdown, which denotes which server instance the IP will be assigned to.</p><h2 id=\"compute-engine-instance-settings\">Compute Engine Instance Settings</h2><p>Shit, is there even more? OK, we're almost done here. Go to your Compute Engine instance you set up earlier. Click \"Edit\". Scroll to the <em>Network Interface</em> section and map the Static IP we created from earlier. Also, go ahead and enter your PTR record:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.47.24-AM.png\" class=\"kg-image\"><figcaption>When will it end... please send help.</figcaption></figure><h2 id=\"final-chapter-firewall-settings\">FINAL CHAPTER: Firewall Settings</h2><p>Look, I just want to say you're all doing a great job so far. All of you. We're all a team here; let's stick together and see this through. Search for <strong>Firewall Rules</strong> and selected <em>Create a Firewall Rule. </em>Name it whatever you want.</p><ul><li><strong>Targets</strong> - This will be where our traffic routes. We want to route to our instance, which is a <em>specified service account.</em></li><li><strong>Target service account</strong> - Referring to the above, this is where we select the computer instance we want to hit.</li><li><strong>Target service account</strong> <strong>scope</strong> - Select \"in this project\".</li><li><strong>Source Filter </strong>- Once again, select <em>specified service account.</em></li><li><strong>Source service account</strong> <strong>scope </strong>- Select \"in this project\"</li><li><strong>Source service account</strong> - This is where we say where the traffic is coming from. It's coming from the <em>App engine</em>, as this is where we specified our DNS.</li><li>For <strong>IPs</strong> and <strong>ports, </strong>well, do what you want. It's your server. </li></ul><h2 id=\"get-at-it\">Get at it</h2><p>Well, there you have it. Hopefully by now the domain you've painstaking configured now points to your server, so you can go ahead and configure your webserver settings or whatever it is you do.</p><p>Alright fine, so GCP isn't completely free of its own redundancies. As much as I love to hate on AWS, it seems almost inevitable at this point that any enterprise cloud service will maintain a certain level of obscure processes. This is great for flexibility when scaling, but let's be honest: if these platforms were easy to use, who would pay for the certifications?</p><p>Cheekiness aside, I've become a strong fan of GCP. Google seems to have hit a middle ground between being user-friendly and powerful, which fills a niché we'll realize was desperately needed. For a fair review of the platform itself, I find myself agreeing mostly with this stranger from the internet: <a href=\"https://www.deps.co/blog/google-cloud-platform-good-bad-ugly/\">https://www.deps.co/blog/google-cloud-platform-good-bad-ugly/</a></p>","url":"https://hackersandslackers.com/setting-up-dns-with-google-cloud-platform/","uuid":"ed22ae1a-b636-48dd-8502-141ae08fa9d9","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b4a08921c20005e9422c108"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867369f","title":"Creating Your First Flask Application","slug":"creating-your-first-flask-application","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/flask-gettingstarted@2x.jpg","excerpt":"After achieving market dominance, Flask is a Python framework impossible to avoid.","custom_excerpt":"After achieving market dominance, Flask is a Python framework impossible to avoid.","created_at_pretty":"08 July, 2018","published_at_pretty":"08 July, 2018","updated_at_pretty":"21 February, 2019","created_at":"2018-07-08T16:06:24.000-04:00","published_at":"2018-07-08T17:51:42.000-04:00","updated_at":"2019-02-21T17:05:15.000-05:00","meta_title":"Creating Your First Flask Application | Hackers and Slackers","meta_description":"After achieving market dominance, Flask is a Python framework impossible to avoid. Learn the basics of creating a Flask web app or API.","og_description":"After achieving market dominance, Flask is a Python framework impossible to avoid. Learn the basics of creating a Flask web app or API.","og_image":"https://hackersandslackers.com/content/images/2018/07/flask-gettingstarted@2x.jpg","og_title":"Creating Your First Flask Application","twitter_description":"After achieving market dominance, Flask is a Python framework impossible to avoid. Learn the basics of creating a Flask web app or API.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/flask-gettingstarted@2x.jpg","twitter_title":"Creating Your First Flask Application","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"Evidence of Flask’s rise to power has been all around us for a couple of years\nnow. Anybody paying close attention to the technology stacks chosen by startups\nhas undoubtedly noticed a flip: at some point, the industry standard flipped\naway from Django entirely. \n\nHuge bets are being placed on Flask across the industry. Plotly’s  famous Dash \nproduct is an extension of Flask which has seen significant success. Even major\ncloud providers, namely Google Cloud, are choosing to default to Flask for\nPython implementations of serverless apps. Google Cloud Functions and Google App\nEngine both ship with Flask running at their core. JetBrains finally put an\nofficial number to this trend with their 2018 Python survey\n[https://www.jetbrains.com/research/python-developers-survey-2018/]: 47%  of\ndevs report using Flask to Django’s 45%. Game: Blouses.\n\nFlask wins market dominence in 2018.Put down the pitchforks: this isn’t a Flask\nvs. Django post, nor are we implying that one framework is superior to the\nother. Both frameworks have their place, with that “place” being in the realm of\npreference.\n\nWhy Flask?\nDeveloping apps in Flask has a much different narrative than when developing in\nmore traditional MVC Frameworks. In the past, the setup of a framework would\neasily take hours: with the assumption that our app needed all the bells and\nwhistles, it was impossible to get a “Hello world!” off the ground without a\nfull understanding of database configurations, static assets, templates, and\nother things our app may not even need. This is especially a concern for the\nPython ecosystem. Few people turn to Python for the sole purpose of building a\nweb app: the vast majority of Python developers are in the field of data\nanalysis without a traditional background in application development. Asking\ndata analysts (who have mostly become accustomed to Jupyter notebooks) to pick\nup all the fundamentals of web development before even getting started is just\nunrealistic.\n\nFlask's setup is merely a copy+paste of the following five lines:\n\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    return \"Hello World!\"\n\n\nThose five lines create a live Flask application. Without any other knowledge\nabout the framework, we can immediately plug in any Python logic we already have\nto change “Hello world!” to match any output imaginable. While it's possible to\ncreate an entire Flask application as a single tiny file, Flask can be as\nextended to be just as powerful and complex as its predecessors. When the author\nof a Flask application deems it necessary, various Flask plugins can be pulled\nin to give us robust application logic. Examples include:\n\n * Flask-SQLAlchemy  for database interaction.\n * Flask-Sessions  for user session management.\n * Flask-Login  to manage user logins.\n * Literally hundreds [https://github.com/humiaozuzu/awesome-flask]  of other\n   libraries.\n\nThis plug-and-play structure makes Flask projects feel more expressive while\nsimultaneously providing simplicity to developers starting from 0. Not only\nthat, but reading somebody else’s source suddenly becomes simple: I know this\napp must do XYZ, because this person has imported XYZ.\n\nDissecting Flask’s “Hello World!”\nLet's go back to our 5-line application to pick apart the specifics:\n\nfrom flask import Flask \napp = Flask(__name__)\n\n\nThe most important part of the Flask Python library is Flask  with a capital “F”\n(as in: from flask import Flask).  This five-letter word creates an object which\nrefers to the entirety of the app itself: when we state app = Flask(__name__),\nwe are creating the variable app  which represents our application. Therefore,\nwhen we configure the variable app,  we’re configuring the way our entire\napplication works. For example, setting app = Flask()  can accept a few\nattributes:\n\nfrom flask import Flask\n\napp = Flask(__name__,\n            instance_relative_config=False,\n            template_folder=\"templates\",\n            static_folder=\"static\"\n            )\n\n\nThis is an example of creating a Flask app with a few specifics: the location of\nour config file, the folder in which we'll store pages templates, and the folder\nin which we'll store frontend assets (JS, CSS, images, etc.).\n\nA Basic Flask Route\nThe primary function of our app is called hello(), which is importantly wrapped\nby Flask's most important decorator: .route(). If you aren't familiar with \ndecorators  in Python, a decorator is a function for us to wrap other functions\nwith. It isn't critically important to know all the details, other than that\nFlask comes with a route decorator which allows us to serve up functions based\non which page of the app the user is loading. By setting @app.route(\"/\"), we are\nspecifying that the function hello()  should fire whenever somebody uses our\napp.\n\nOf course, we can return any value besides \"Hello world!\" if we wanted. Let's\nsay you've already a script which returns the square of a number, plus 9. We\ncould save that logic in a function called squareOfNumberPlusNine(), in a file\ncalled logic.py. Now, our script can look like this:\n\nfrom flask import Flask\nfrom logic import squareOfNumberPlusNine\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    value = squareOfNumberPlusNine(5)\n    return value\n\n\nThis would return 34  as opposed to \"Hello world!\". Without any prior knowledge\nof Python web development, we can already use Flask to plug into logic we've\nwritten and serve up a result.\n\nOther Parts of Flask's Core Library\nWe can import other things from flask  besides Flask. Here are some examples:\n\nServing Raw HTML\nMarkup  allows us to return an HTML page by rendering a string as HTML:\n\nfrom flask import Flask, Markup\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    return Markup(\"<h1>Hello World!</h1>\")\n\n\nServing an HTML Page Template\nreturn_template  will return an HTML page by finding the page in our /templates \nfolder:\n\nfrom flask import Flask, render_template\napp = Flask(__name__, template_folder=\"templates\")\n\n@app.route(\"/\")\ndef hello():\n    return render_template(\"index.html\")\n\n\nServing a JSON Response \nmake_response  is suitable if our application is an API and we'd like to return\na response object:\n\nfrom flask import Flask, make_response\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    headers = {\"Content-Type\": \"application/json\"}\n    return make_response('it worked!', 200, headers=headers)\n\n\nOn the topic of creating APIs with Flask, we can also specify whether the route\nat hand is a POST, GET, or some other method. This is handled easily within the\nroute decorator:\n\nfrom flask import Flask, make_response, request\napp = Flask(__name__)\n\n@app.route(\"/\", methods=['GET'])\ndef hello():\n    if request.method != 'GET':\n        return make_response('Malformed request', 400)\n    headers = {\"Content-Type\": \"application/json\"}\n    return make_response('it worked!', 200, headers=headers)\n\n\nThe above function checks to make sure the user is accessing the endpoint with\nthe correct method first. If they've used the incorrect method, we return an\nerror.\n\nSuccumb to Flask\nEven if you chose to stick to your large Frameworks, it's easy to see why Flask\nis useful as a drop-in solution for many tasks. There are undoubtedly plenty of\nuseful Python scripts which go wasted because the final step of making them\neasily consumable by other people was never completed. Flask is an excellent way\nto achieve this last step, and the best part is: you already know how to use it.","html":"<p>Evidence of Flask’s rise to power has been all around us for a couple of years now. Anybody paying close attention to the technology stacks chosen by startups has undoubtedly noticed a flip: at some point, the industry standard flipped away from Django entirely. </p><p>Huge bets are being placed on Flask across the industry. <strong>Plotly’s</strong> famous <strong>Dash</strong> product is an extension of Flask which has seen significant success. Even major cloud providers, namely <strong>Google Cloud</strong>, are choosing to default to Flask for Python implementations of serverless apps. Google Cloud Functions and Google App Engine both ship with Flask running at their core. JetBrains finally put an official number to this trend with their <a href=\"https://www.jetbrains.com/research/python-developers-survey-2018/\">2018 Python survey</a>: <strong>47%</strong> of devs report using Flask to Django’s <strong>45%</strong>. Game: Blouses.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/Screen-Shot-2019-02-13-at-4.36.00-PM.png\" class=\"kg-image\"><figcaption>Flask wins market dominence in 2018.</figcaption></figure><p>Put down the pitchforks: this isn’t a Flask vs. Django post, nor are we implying that one framework is superior to the other. Both frameworks have their place, with that “place” being in the realm of preference.</p><h2 id=\"why-flask\">Why Flask?</h2><p>Developing apps in Flask has a much different narrative than when developing in more traditional MVC Frameworks. In the past, the setup of a framework would easily take hours: with the assumption that our app needed all the bells and whistles, it was impossible to get a “Hello world!” off the ground without a full understanding of database configurations, static assets, templates, and other things our app may not even need. This is especially a concern for the Python ecosystem. Few people turn to Python for the sole purpose of building a web app: the vast majority of Python developers are in the field of data analysis without a traditional background in application development. Asking data analysts (who have mostly become accustomed to Jupyter notebooks) to pick up all the fundamentals of web development before even getting started is just unrealistic.</p><p>Flask's setup is merely a copy+paste of the following five lines:</p><pre><code class=\"language-python\">from flask import Flask\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    return &quot;Hello World!&quot;\n</code></pre>\n<p>Those five lines create a live Flask application. Without any other knowledge about the framework, we can immediately plug in any Python logic we already have to change “Hello world!” to match any output imaginable. While it's possible to create an entire Flask application as a single tiny file, Flask can be as extended to be just as powerful and complex as its predecessors. When the author of a Flask application deems it necessary, various Flask plugins can be pulled in to give us robust application logic. Examples include:</p><ul><li><strong>Flask-SQLAlchemy</strong> for database interaction.</li><li><strong>Flask-Sessions</strong> for user session management.</li><li><strong>Flask-Login</strong> to manage user logins.</li><li>Literally <a href=\"https://github.com/humiaozuzu/awesome-flask\">hundreds</a> of other libraries.</li></ul><p>This plug-and-play structure makes Flask projects feel more expressive while simultaneously providing simplicity to developers starting from 0. Not only that, but reading somebody else’s source suddenly becomes simple: I know this app must do XYZ, because this person has imported XYZ.</p><h2 id=\"dissecting-flask-s-hello-world-\">Dissecting Flask’s “Hello World!”</h2><p>Let's go back to our 5-line application to pick apart the specifics:</p><pre><code class=\"language-python\">from flask import Flask \napp = Flask(__name__)\n</code></pre>\n<p>The most important part of the Flask Python library is <strong>Flask</strong> with a capital “F” (as in: <code>from flask import Flask</code>).  This five-letter word creates an object which refers to the entirety of the app itself: when we state <code>app = Flask(__name__)</code>, we are creating the variable <strong>app</strong> which represents our application. Therefore, when we configure the variable <strong>app,</strong> we’re configuring the way our entire application works. For example, setting <code>app = Flask()</code> can accept a few attributes:</p><pre><code class=\"language-python\">from flask import Flask\n\napp = Flask(__name__,\n            instance_relative_config=False,\n            template_folder=&quot;templates&quot;,\n            static_folder=&quot;static&quot;\n            )\n</code></pre>\n<p>This is an example of creating a Flask app with a few specifics: the location of our config file, the folder in which we'll store pages templates, and the folder in which we'll store frontend assets (JS, CSS, images, etc.).</p><h3 id=\"a-basic-flask-route\">A Basic Flask Route</h3><p>The primary function of our app is called <code>hello()</code>, which is importantly wrapped by Flask's most important decorator: <code>.route()</code>. If you aren't familiar with <strong>decorators</strong> in Python, a decorator is a function for us to wrap other functions with. It isn't critically important to know all the details, other than that Flask comes with a route decorator which allows us to serve up functions based on which page of the app the user is loading. By setting <code>@app.route(\"/\")</code>, we are specifying that the function <code>hello()</code> should fire whenever somebody uses our app.</p><p>Of course, we can return any value besides \"Hello world!\" if we wanted. Let's say you've already a script which returns the square of a number, plus 9. We could save that logic in a function called <code>squareOfNumberPlusNine()</code>, in a file called <code>logic.py</code>. Now, our script can look like this:</p><pre><code class=\"language-python\">from flask import Flask\nfrom logic import squareOfNumberPlusNine\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    value = squareOfNumberPlusNine(5)\n    return value\n</code></pre>\n<p>This would return <strong>34</strong> as opposed to \"<strong>Hello world!\"</strong>. Without any prior knowledge of Python web development, we can already use Flask to plug into logic we've written and serve up a result.</p><h2 id=\"other-parts-of-flask-s-core-library\">Other Parts of Flask's Core Library</h2><p>We can import other things <code>from flask</code> besides <code>Flask</code>. Here are some examples:</p><h3 id=\"serving-raw-html\">Serving Raw HTML</h3><p><code>Markup</code> allows us to return an HTML page by rendering a string as HTML:</p><pre><code class=\"language-python\">from flask import Flask, Markup\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    return Markup(&quot;&lt;h1&gt;Hello World!&lt;/h1&gt;&quot;)\n</code></pre>\n<h3 id=\"serving-an-html-page-template\">Serving an HTML Page Template</h3><p><code>return_template</code> will return an HTML page by finding the page in our <code>/templates</code> folder:</p><pre><code class=\"language-python\">from flask import Flask, render_template\napp = Flask(__name__, template_folder=&quot;templates&quot;)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    return render_template(&quot;index.html&quot;)\n</code></pre>\n<h3 id=\"serving-a-json-response\">Serving a JSON Response </h3><p><code>make_response</code> is suitable if our application is an API and we'd like to return a response object:</p><pre><code class=\"language-python\">from flask import Flask, make_response\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    headers = {&quot;Content-Type&quot;: &quot;application/json&quot;}\n    return make_response('it worked!', 200, headers=headers)\n</code></pre>\n<p>On the topic of creating APIs with Flask, we can also specify whether the route at hand is a POST, GET, or some other method. This is handled easily within the route decorator:</p><pre><code class=\"language-python\">from flask import Flask, make_response, request\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;, methods=['GET'])\ndef hello():\n    if request.method != 'GET':\n        return make_response('Malformed request', 400)\n    headers = {&quot;Content-Type&quot;: &quot;application/json&quot;}\n    return make_response('it worked!', 200, headers=headers)\n</code></pre>\n<p>The above function checks to make sure the user is accessing the endpoint with the correct method first. If they've used the incorrect method, we return an error.</p><h2 id=\"succumb-to-flask\">Succumb to Flask</h2><p>Even if you chose to stick to your large Frameworks, it's easy to see why Flask is useful as a drop-in solution for many tasks. There are undoubtedly plenty of useful Python scripts which go wasted because the final step of making them easily consumable by other people was never completed. Flask is an excellent way to achieve this last step, and the best part is: you already know how to use it.</p>","url":"https://hackersandslackers.com/creating-your-first-flask-application/","uuid":"dac63aa8-2a5d-4d3e-a6b1-cccc5785764c","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b426ec02d99b9040e300f74"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673682","title":"Using Pandas with AWS Lambda Functions","slug":"using-pandas-with-aws-lambda","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/pandas-lambdas-2-3.jpg","excerpt":"Forcefully use the Pandas library in your AWS Lambda functions.","custom_excerpt":"Forcefully use the Pandas library in your AWS Lambda functions.","created_at_pretty":"20 June, 2018","published_at_pretty":"21 June, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-06-20T18:21:31.000-04:00","published_at":"2018-06-21T07:30:00.000-04:00","updated_at":"2019-03-28T08:49:25.000-04:00","meta_title":"Using Pandas with AWS Lambda Functions | Hackers and Slackers","meta_description":"Learn how to forcefully use Python's Pandas library in AWS Lambda functions.","og_description":"Learn how to forcefully use Python's Pandas library in AWS Lambda functions.","og_image":"https://hackersandslackers.com/content/images/2019/03/pandas-lambdas-2-3.jpg","og_title":"Using Pandas with AWS Lambda","twitter_description":"Learn how to forcefully use Python's Pandas library in AWS Lambda functions.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/pandas-lambdas-2-2.jpg","twitter_title":"Using Pandas with AWS Lambda","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#Creating APIs in AWS","slug":"create-an-aws-api","description":"Create a REST API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pythonlambda.jpg","meta_description":"Create an API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","meta_title":"Create a REST API in AWS","visibility":"internal"}],"plaintext":"In one corner we have Pandas: Python's beloved data analysis library. In the\nother, AWS: the unstoppable cloud provider we're obligated to use for all\neternity. We should have known this day would come.\n\nWhile not the prettiest workflow, uploaded Python package dependencies for usage\nin AWS Lambda is typically straightforward. We install the packages locally to a\nvirtual env, package them with our app logic, and upload a neat CSV to Lambda.\nIn some cases this doesn't always work: some packages result in a cryptic error\nmessage with absolutely no helpful instruction. Pandas is one of those packages.\n\nWhy is this? I can't exactly speak to that, but I can speak to how to fix it.\n\nSpin up an EC2 Instance\nCertain Python packages need to be installed and compiled on an EC2 instance in\norder to work properly with AWS microservices. I wish I could say that this fun\nlittle fact is well-documented somewhere in AWS with a perfectly good\nexplanation. It's not, and it doesn't.  It's probably best not to ask questions.\n\nSpin up a free tier EC2 instance, update your system packages, and make sure\nPython3 is installed. Some people theorize that the Python dependency package\nerrors happen when said dependencies are installed via versions of Python which\ndiffer from the version AWS is running. Those people are wrong.  I've already\nwasted the time to debunk this. They are liars.\n\nWith Python installed,  create a virtual environment inside any empty directory:\n\n$ apt-get install virtualenv\n$ virtualenv pandasenv\n$ source pandasenv/bin/activate\n\n\nWith the environment active, install pandas via pip3 install pandas. This will\nsave pandas and all its dependencies to the site-packages  folder our\nenvironment is running from, resulting in a URL such as this: \npandasenv/lib/python3.6/site-packages.\n\nPandas is actually 5 packages total. We're going to add each of these libraries\nto a zip file by installing zip, and adding each folder to the zip file\none-by-one. Finally, we'll apply some liberal permissions to the zip file we\njust created so we can grab it via FTP.\n\n$ cd pandasenv/lib/python3.6/site-packages\n$ apt-get install zip\n$ zip -r pandas_archive.zip pandas\n$ zip -r pandas_archive.zip numpy\n$ zip -r pandas_archive.zip pytz\n$ zip -r pandas_archive.zip six.py\n$ zip -r pandas_archive.zip dateutil\n$ chmod 777 pandas_archive.zip\n\n\nThis should be ready for you to FTP in your instance and grab as a zip file now\n(assuming you want to work locally). Alternatively, we could always copy those\npackages into the directory we'd like to work out of and zip everything once\nwe're done.\n\nUpload Source Code to S3\nAt this point, you should have been able to grab the AWS friendly version of\nPandas which is ready to be included in the final source code which will become\nyour Lambda Function.  You might notice that pandas alone nearly 30Mb: which is\nroughly the file size of countless intelligent people creating their life's\nwork. When Lambda Functions go above this file size, it's best to upload our\nfinal package (with source and dependencies) as a zip file to S3, and link it to\nLambda that way. This is considerably faster than the alternative of uploading\nthe zip to Lambda directly.\n\nBonus Round: Saving Exports\nWhat? You want to save a CSV result of all the cool stuff you're doing in\nPandas? You really are needy.\n\nBecause AWS is invoking the function, any attempt to read_csv()  will be\nworthless to us. To get around this, we can use boto3  to write files to an S3\nbucket instead:\n\nimport pandas as pd\nfrom io import StringIO\nimport boto3\n\ns3 = boto3.client('s3', aws_access_key_id=ACCESSKEY, aws_secret_access_key=SECRETYKEY)\ns3_resource = boto3.resource('s3')\nbucket = 'your_bucket_name'\n\ncsv_buffer = StringIO()\n\nexample_df = pd.DataFrame()\nexample_df.to_csv(csv_buffer)\ns3_resource.Object(bucket, 'export.csv').put(Body=csv_buffer.getvalue())\n\n\nWord of Advice\nThis isn't the prettiest process in the world, but we're somewhat at fault here.\nLambda functions are intended to be small tidbits of logic aimed to serve a\nsingle simple purpose. We just jammed 30Mbs of Python libraries into that simple\npurpose.\n\nThere are alternatives to Pandas that are better suited for usage in Lambda,\nsuch as Toolz  (thanks to Snkia for the heads up). Enjoy your full Pandas\nlibrary for now, but remember to feel bad about what you’ve done for next time.","html":"<p>In one corner we have Pandas: Python's beloved data analysis library. In the other, AWS: the unstoppable cloud provider we're obligated to use for all eternity. We should have known this day would come.</p><p>While not the prettiest workflow, uploaded Python package dependencies for usage in AWS Lambda is typically straightforward. We install the packages locally to a virtual env, package them with our app logic, and upload a neat CSV to Lambda. In some cases this doesn't always work: some packages result in a cryptic error message with absolutely no helpful instruction. Pandas is one of those packages.</p><p>Why is this? I can't exactly speak to that, but I can speak to how to fix it.</p><h2 id=\"spin-up-an-ec2-instance\">Spin up an EC2 Instance</h2><p>Certain Python packages need to be installed and compiled on an EC2 instance in order to work properly with AWS microservices. I wish I could say that this fun little fact is well-documented somewhere in AWS with a perfectly good explanation. It's not, and it doesn't.  It's probably best not to ask questions.</p><p>Spin up a free tier EC2 instance, update your system packages, and make sure Python3 is installed. Some people theorize that the Python dependency package errors happen when said dependencies are installed via versions of Python which differ from the version AWS is running. <em>Those people are wrong.</em> I've already wasted the time to debunk this. They are liars.</p><p>With Python installed,  create a virtual environment inside any empty directory:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ apt-get install virtualenv\n$ virtualenv pandasenv\n$ source pandasenv/bin/activate\n</code></pre>\n<!--kg-card-end: markdown--><p>With the environment active, install pandas via <code>pip3 install pandas</code>. This will save pandas and all its dependencies to the <em>site-packages</em> folder our environment is running from, resulting in a URL such as this: <code>pandasenv/lib/python3.6/site-packages</code>.</p><p>Pandas is actually 5 packages total. We're going to add each of these libraries to a zip file by installing <code>zip</code>, and adding each folder to the zip file one-by-one. Finally, we'll apply some liberal permissions to the zip file we just created so we can grab it via FTP.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ cd pandasenv/lib/python3.6/site-packages\n$ apt-get install zip\n$ zip -r pandas_archive.zip pandas\n$ zip -r pandas_archive.zip numpy\n$ zip -r pandas_archive.zip pytz\n$ zip -r pandas_archive.zip six.py\n$ zip -r pandas_archive.zip dateutil\n$ chmod 777 pandas_archive.zip\n</code></pre>\n<!--kg-card-end: markdown--><p>This should be ready for you to FTP in your instance and grab as a zip file now (assuming you want to work locally). Alternatively, we could always copy those packages into the directory we'd like to work out of and zip everything once we're done.</p><h3 id=\"upload-source-code-to-s3\">Upload Source Code to S3</h3><p>At this point, you should have been able to grab the <em>AWS friendly </em>version of Pandas which is ready to be included in the final source code which will become your Lambda Function.  You might notice that pandas alone nearly <em>30Mb</em>: which is roughly the file size of countless intelligent people creating their life's work. When Lambda Functions go above this file size, it's best to upload our final package (with source and dependencies) as a zip file to S3, and link it to Lambda that way. This is considerably faster than the alternative of uploading the zip to Lambda directly.</p><h2 id=\"bonus-round-saving-exports\">Bonus Round: Saving Exports</h2><p>What? You want to save a CSV result of all the cool stuff you're doing in Pandas? You really are needy.</p><p>Because AWS is invoking the function, any attempt to <code>read_csv()</code> will be worthless to us. To get around this, we can use <strong>boto3</strong> to write files to an S3 bucket instead:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\nfrom io import StringIO\nimport boto3\n\ns3 = boto3.client('s3', aws_access_key_id=ACCESSKEY, aws_secret_access_key=SECRETYKEY)\ns3_resource = boto3.resource('s3')\nbucket = 'your_bucket_name'\n\ncsv_buffer = StringIO()\n\nexample_df = pd.DataFrame()\nexample_df.to_csv(csv_buffer)\ns3_resource.Object(bucket, 'export.csv').put(Body=csv_buffer.getvalue())\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"word-of-advice\">Word of Advice</h3><p>This isn't the prettiest process in the world, but we're somewhat at fault here. Lambda functions are intended to be small tidbits of logic aimed to serve a single simple purpose. We just jammed 30Mbs of Python libraries into that simple purpose.</p><p>There are alternatives to Pandas that are better suited for usage in Lambda, such as <em>Toolz</em> (thanks to Snkia for the heads up). Enjoy your full Pandas library for now, but remember to feel bad about what you’ve done for next time.</p>","url":"https://hackersandslackers.com/using-pandas-with-aws-lambda/","uuid":"3d2d6592-5614-4485-b9cd-15d905a28c46","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b2ad36cded32f5af8fd674d"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867364d","title":"Preparing your AWS Project to Build an API","slug":"building-an-api-using-aws","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/awsapi-1-3.jpg","excerpt":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","custom_excerpt":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","created_at_pretty":"06 May, 2018","published_at_pretty":"06 May, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-05-06T07:30:47.000-04:00","published_at":"2018-05-06T08:58:41.000-04:00","updated_at":"2019-03-28T08:54:39.000-04:00","meta_title":"Preparing your AWS Project to Build an API | Hackers and Slackers","meta_description":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","og_description":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","og_image":"https://hackersandslackers.com/content/images/2019/03/awsapi-1-3.jpg","og_title":"Preparing your AWS Project to Build an API | Hackers and Slackers","twitter_description":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/awsapi-1-2.jpg","twitter_title":"Preparing your AWS Project to Build an API | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},"tags":[{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"#Creating APIs in AWS","slug":"create-an-aws-api","description":"Create a REST API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pythonlambda.jpg","meta_description":"Create an API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","meta_title":"Create a REST API in AWS","visibility":"internal"}],"plaintext":"There comes a surreal moment in nearly every profession in which perspective\nviolently forces itself into our self-awareness. People with cooler jobs\nprobably have that moment when they save their first patient or launch their\nfirst rocket. For me, the idea of building an API was this moment in software\ndevelopment. All those past black boxes which spat out results your life\ndepended on: we can make those now.\n\nFeel free to remain unfazed by this as I'm sure most are... for those of us who\ncan't remember how they became an \"engineer\" in the first place, API design\nfeels like reaching a final frontier. Granted, this may happen at least 20 more\ntimes in your software career, so don’t pause too long now.\n\nIf you managed to catch the tutorial on setting up RDS on AWS\n[https://hackersandslackers.com/setting-up-mysql-on-aws/], you're already a step\nahead. We're going to make our way through this slowly, which is probably a good\nidea even if you've done this before. There are so many pitfalls and nuances in\nAWS's architecture that I'm not even sure I fully understand what's happening,\neven when everything works.\n\nQuick Overview\nHere are the services we'll be using to hook this baby up:\n\n *   RDS:  Amazon's cloud-hosted relational databases. These databases come\n   preconfigured with an endpoint, which can be made accessible to other AWS\n   services or even to external manipulation. \n *   Lambda:  Snippets of code which can be invoked without setting up a web\n   server (hence: \"serverless\"). Lambda functions are intended to serve simple,\n   specific functions (such as serving as the logic for an endpoint, for\n   instance). Lambda functions play well with other AWS services: we'll be using\n   this as the glue between our API and interacting with the Database.\n *   API Gateway:  Amazon's visual editor for creating an API. API Gateway\n   allows developers to architect the structure and logic of APIs without having\n   to worry about setting up routes via code.\n *   IAM:  Amazon's headache of a user & permissions manager. IAM is needed to\n   specify exactly with AWS services have access to other services, which users\n   are permitted to interact with your API, etc. \n\nGameplan\nSo here's the deal. Our RDS  database will be where all the data we provide and\nreceive will live. Lambda  functions will be the snippets of code actually\ninteracting with information from the database; all of our queries will be done\nthrough Lambda. API Gateway  will control the \"design\" of the API, as in the\nstructure of endpoints, their respective methods, and how all these should\ninteract with Lambda.\n\nIt sounds simple enough, but the devil is in the details. And trust me, there\nare a lot of details.\n\nSetting the Correct Role Permissions\nUsually, I'd say we should jump into the fun stuff and deal with the details\nwhen we get to them. I won't let you steer down that road with AWS... let's\navoid smashing our heads on keyboards where possible and kick things off slow.\n\nIf you were to attempt to create a Lambda function off the bat, the first prompt\nto appear would demand a \"role\" to be specified. Roles are one of the types of\npermission packages (?) we mentioned earlier. Roles limit exactly which services\nyour Lambda function can interact with off the bat. Start with the wrong role,\nand you won't be able to do much of anything.\n\nHead over the IAM console\n[https://console.aws.amazon.com/iam/home?region=us-east-1#/home]  to set up an\nappropriate role:\n\nWhat a God-awful way to handle permissions.Let's pause for a moment to take this\nall in. You'll see we have users, groups, roles, policies and a whole bunch of\nother garbage. Policies can be attached to roles. Policies can also be attached\nto users, and also attached to groups. Users can be in groups. Wait, so what if\na user has a bunch of policies, but then joins a group with a bunch of policies?\nWhat even is a \"policy\"? These are the real questions. The short answer is none\nof it makes sense; it's just extra job security for those who make it work.\n\nClick on \"Roles\" in the sidebar. Create a role. Select \"Lambda\" and click next.\n\nThis interface only seems to get worse.Ok cool. The role  we're creating is basically just going to be a collection of\npermissions we can attached directly to the role. Go ahead and attach these:\n\n * AmazonVPCFullAccess\n * AmazonAPIGatewayInvokeFullAccess\n * AmazonRDSFullAccess\n * AWSLambdaFullAccess\n * CloudWatchLogsFullAccess\n\nSave the role, and remember what you name it. You'll need it.\n\nGetting Started with Lambda Functions\nGo back to the Lambda console. It's game time. We're going to create a function\nfrom scratch (sadly, I haven't found any of the blueprints to be very useful\njust yet).\n\nIgnore Amazon's silly Blueprints.Under “runtime”, you’ll need to pick which\nprogramming language we’ll be writing our function in. I’m doing Python 3\nbecause I don’t mess with semicolons, ya dig. Most people seem to stick with\nNode, which makes sense: Node is much faster at runtime, especially when you\nconsider that AWS runs Node natively. The choice is your preference.\n\nAha, see the “Role” dropdown? This is what I warned you about. Select the role\nyou just created earlier from existing roles.\n\nLambda Function Editor\nWelcome to Lambda's web UIBehold, the Lambda visual editor. That tree you're\nseeing is a representation of the integration this function will handle. The\ncurrent function is the box top-middle, the trigger is on the left, and the list\nof potential AWS services we can touch is on the right; these were automatically\npopulated by that role I forced you to create. You're welcome.\n\nNOTE:  The entire interface below this section depends on which service you've\nclicked in the tree. It's not the most intuitive at first. I have my Lambda\nfunction selected, so that's the interface I can interact with below.\n\nInline Code Editor\nWe can create Lambdas directly in the browser, or by uploading souce via zip\nfile.Real quick, we need to go over what each field here does. The dropdown\ncurrently set to \"edit code inline\" can be expanded, which gives you the option\nto upload a zip file of source code. THIS WILL DELETE ALL PREEXISTING WORK. \nThey don't tell you that, hah. Ha hah. I recommend doing everything offline to\nbe uploaded later - this needs to be done with python packages anyway.\n\nHandler  specifies which function should be called upon initialization.\n\"lambda_function\" is referring to the function, so \"handler\" here specifies that\nthe function handler within lambda_function.py  is what will get called upon\nexecution.\n\nOur Lambda’s VPC Settings\nScroll down until you hit this pretty little gem:\n\nAWS is filled with complicated network concepts, and zero attempts to explain\nthem.We need to specify the VPC this function will interact with. If you created\nan RDS already, go ahead select the VPC you created. Add a bunch of subnets\n(whichever ones). Finally, select a security group. Remember that the\npermissions of this group determine whether or not your VPC is allowed to speak\nto this function. If you're struggling with this, check out the AWS MySQL post\nagain. I'm not going to link it twice in one post, sorry. I have self-respect\nyou know.\n\nThat's Enough For Now\nThere's a lot to take in when playing around in AWS. The combination of\ngibberish terminology and horrible documentation doesn't exactly make for solid\nuser experience. If you're new to AWS and any of this seems frustrating, know\nit's supposed to be. Amazon owns you, and they hate you. Kind of like God.\n\nI'd suggest messing around the interface, and maybe even check out API Gateway a\nbit to get a feel for how that stuff looks. They set you up with a cute demo to\nmake you think it's going to be easy, so maybe you'll enjoy that. Next time,\nwe're going to crank out some Lambdas.","html":"<p>There comes a surreal moment in nearly every profession in which perspective violently forces itself into our self-awareness. People with cooler jobs probably have that moment when they save their first patient or launch their first rocket. For me, the idea of building an API was this moment in software development. All those past black boxes which spat out results your life depended on: we can make those now.</p><p>Feel free to remain unfazed by this as I'm sure most are... for those of us who can't remember how they became an \"engineer\" in the first place, API design feels like reaching a final frontier. Granted, this may happen at least 20 more times in your software career, so don’t pause too long now.</p><p>If you managed to catch the tutorial on <a href=\"https://hackersandslackers.com/setting-up-mysql-on-aws/\">setting up RDS on AWS</a>, you're already a step ahead. We're going to make our way through this slowly, which is probably a good idea even if you've done this before. There are so many pitfalls and nuances in AWS's architecture that I'm not even sure I fully understand what's happening, even when everything works.</p><h2 id=\"quick-overview\">Quick Overview</h2><p>Here are the services we'll be using to hook this baby up:</p><ul><li> <strong>RDS:</strong> Amazon's cloud-hosted relational databases. These databases come preconfigured with an endpoint, which can be made accessible to other AWS services or even to external manipulation. </li><li> <strong>Lambda:</strong> Snippets of code which can be invoked without setting up a web server (hence: \"<em>serverless</em>\"). Lambda functions are intended to serve simple, specific functions (such as serving as the logic for an endpoint, for instance). Lambda functions play well with other AWS services: we'll be using this as the glue between our API and interacting with the Database.</li><li> <strong>API Gateway:</strong> Amazon's visual editor for creating an API. API Gateway allows developers to architect the structure and logic of APIs without having to worry about setting up routes via code.</li><li> <strong>IAM:</strong> Amazon's headache of a user &amp; permissions manager. IAM is needed to specify exactly with AWS services have access to other services, which users are permitted to interact with your API, etc. </li></ul><h3 id=\"gameplan\">Gameplan</h3><p>So here's the deal. Our <strong>RDS</strong> database will be where all the data we provide and receive will live. <strong>Lambda</strong> functions will be the snippets of code actually interacting with information from the database; all of our queries will be done through Lambda. <strong>API Gateway</strong> will control the \"design\" of the API, as in the structure of endpoints, their respective methods, and how all these should interact with Lambda.</p><p>It sounds simple enough, but the devil is in the details. And trust me, there are a lot of details.</p><h2 id=\"setting-the-correct-role-permissions\">Setting the Correct Role Permissions</h2><p>Usually, I'd say we should jump into the fun stuff and deal with the details when we get to them. I won't let you steer down that road with AWS... let's avoid smashing our heads on keyboards where possible and kick things off slow.</p><p>If you were to attempt to create a Lambda function off the bat, the first prompt to appear would demand a \"<strong>role</strong>\" to be specified. Roles are one of the types of permission packages (?) we mentioned earlier. Roles limit exactly which services your Lambda function can interact with off the bat. Start with the wrong role, and you won't be able to do much of anything.</p><p>Head over the <a href=\"https://console.aws.amazon.com/iam/home?region=us-east-1#/home\">IAM console</a> to set up an appropriate role:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.06.13.png\" class=\"kg-image\" alt=\"Screenshot-2018-05-06-08.06.13\"><figcaption>What a God-awful way to handle permissions.</figcaption></figure><!--kg-card-end: image--><p>Let's pause for a moment to take this all in. You'll see we have users, groups, roles, policies and a whole bunch of other garbage. Policies can be attached to roles. Policies can also be attached to users, and also attached to groups. Users can be in groups. Wait, so what if a user has a bunch of policies, but then joins a group with a bunch of policies? What even is a \"policy\"? These are the real questions. The short answer is none of it makes sense; it's just extra job security for those who make it work.</p><p>Click on \"Roles\" in the sidebar. Create a role. Select \"Lambda\" and click <em>next</em>.</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.18.21.png\" class=\"kg-image\" alt=\"Screenshot-2018-05-06-08.18.21\"><figcaption>This interface only seems to get worse.</figcaption></figure><!--kg-card-end: image--><p>Ok cool. The <strong>role</strong> we're creating is basically just going to be a collection of permissions we can attached directly to the role. Go ahead and attach these:</p><ul><li>AmazonVPCFullAccess</li><li>AmazonAPIGatewayInvokeFullAccess</li><li>AmazonRDSFullAccess</li><li>AWSLambdaFullAccess</li><li>CloudWatchLogsFullAccess</li></ul><p>Save the role, and remember what you name it. You'll need it.</p><h2 id=\"getting-started-with-lambda-functions\">Getting Started with Lambda Functions</h2><p>Go back to the Lambda console. It's game time. We're going to create a function from scratch (sadly, I haven't found any of the blueprints to be very useful just yet).</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.25.16.png\" class=\"kg-image\" alt=\"Lambda\"><figcaption>Ignore Amazon's silly Blueprints.</figcaption></figure><!--kg-card-end: image--><p>Under “runtime”, you’ll need to pick which programming language we’ll be writing our function in. I’m doing Python 3 because I don’t mess with semicolons, ya dig. Most people seem to stick with Node, which makes sense: Node is much faster at runtime, especially when you consider that AWS runs Node natively. The choice is your preference.</p><p>Aha, see the “Role” dropdown? This is what I warned you about. Select the role you just created earlier from existing roles.</p><h3 id=\"lambda-function-editor\">Lambda Function Editor</h3><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screenshot-2018-05-06-08.30.00.png\" class=\"kg-image\"><figcaption>Welcome to Lambda's web UI</figcaption></figure><!--kg-card-end: image--><p>Behold, the Lambda visual editor. That tree you're seeing is a representation of the integration this function will handle. The current function is the box top-middle, the trigger is on the left, and the list of potential AWS services we can touch is on the right; these were automatically populated by that role I forced you to create. You're welcome.</p><p><strong>NOTE:</strong> The entire interface below this section depends on which service you've clicked in the tree. It's not the most intuitive at first. I have my Lambda function selected, so that's the interface I can interact with below.</p><h3 id=\"inline-code-editor\">Inline Code Editor</h3><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.35.20.png\" class=\"kg-image\" alt=\"Function code\"><figcaption>We can create Lambdas directly in the browser, or by uploading souce via zip file.</figcaption></figure><!--kg-card-end: image--><p>Real quick, we need to go over what each field here does. The dropdown currently set to \"edit code inline\" can be expanded, which gives you the option to upload a zip file of source code. <em>THIS WILL DELETE ALL PREEXISTING WORK.</em> They don't tell you that, hah. Ha hah. I recommend doing everything offline to be uploaded later - this needs to be done with python packages anyway.</p><p><strong>Handler</strong> specifies which function should be called upon initialization. \"lambda_function\" is referring to the function, so \"handler\" here specifies that the function handler within <code>lambda_function.py</code> is what will get called upon execution.</p><h3 id=\"our-lambda-s-vpc-settings\">Our Lambda’s VPC Settings</h3><p>Scroll down until you hit this pretty little gem:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.41.02.png\" class=\"kg-image\" alt=\"VPC\"><figcaption>AWS is filled with complicated network concepts, and zero attempts to explain them.</figcaption></figure><!--kg-card-end: image--><p>We need to specify the VPC this function will interact with. If you created an RDS already, go ahead select the VPC you created. Add a bunch of subnets (whichever ones). Finally, select a <em>security group</em>. Remember that the permissions of this group determine whether or not your VPC is allowed to speak to this function. If you're struggling with this, check out the AWS MySQL post again. I'm not going to link it twice in one post, sorry. I have self-respect you know.</p><h2 id=\"that-s-enough-for-now\">That's Enough For Now</h2><p>There's a lot to take in when playing around in AWS. The combination of gibberish terminology and horrible documentation doesn't exactly make for solid user experience. If you're new to AWS and any of this seems frustrating, know it's supposed to be. Amazon owns you, and they hate you. Kind of like God.</p><p>I'd suggest messing around the interface, and maybe even check out API Gateway a bit to get a feel for how that stuff looks. They set you up with a cute demo to make you think it's going to be easy, so maybe you'll enjoy that. Next time, we're going to crank out some Lambdas.</p>","url":"https://hackersandslackers.com/building-an-api-using-aws/","uuid":"45101fbc-527b-432b-994e-31d855e76aff","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5aeee767926f095edfccda8e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673648","title":"MySQL on the Cloud with AWS RDS","slug":"setting-up-mysql-on-aws","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/04/aws_mysql@2x.jpg","excerpt":"Spinning up a standalone MySQL Database with Amazon.","custom_excerpt":"Spinning up a standalone MySQL Database with Amazon.","created_at_pretty":"30 April, 2018","published_at_pretty":"01 May, 2018","updated_at_pretty":"27 November, 2018","created_at":"2018-04-29T23:12:26.000-04:00","published_at":"2018-04-30T20:14:57.000-04:00","updated_at":"2018-11-27T03:54:21.000-05:00","meta_title":"Setting up MySQL on AWS | Hackers and Slackers","meta_description":"Spinning up a standalone MySQL Database with Amazon","og_description":"Spinning up a standalone MySQL Database with Amazon","og_image":"https://hackersandslackers.com/content/images/2018/04/aws_mysql@2x.jpg","og_title":"Setting up MySQL on AWS","twitter_description":"Spinning up a standalone MySQL Database with Amazon","twitter_image":"https://hackersandslackers.com/content/images/2018/04/aws_mysql@2x.jpg","twitter_title":"Setting up MySQL on AWS","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"#Working with MySQL","slug":"working-with-mysql","description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysql1_o-1.jpg","meta_description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","meta_title":"Working with MySQL","visibility":"internal"}],"plaintext":"Last time we became familiar with the handiwork of setting up MySQL locally,\nnavigating databases via command line, and exposing your database to external\naccess. While badass, it has come to my attention that most people don't bother\ndoing things this way. Unless you're getting deep into some heavy architecture,\nmost people opt to use cloud services such as AWS to set up databases which are\nintended to be interacted with by multiple services.\n\nA perfect example is one we ran into over the weekend while working on this very\nblog. We're running a Ghost instance, which is respectably complex\nproduction-ready app. For a bunch of guys just looking to make some stupid blog\nwidgets, it became obvious that reverse engineering the undocumented inner\nworkings of an open source node app was a rabbit hole of complexity.\n\nHosting on AWS\nIn our case, AWS is useful for enforcing separation of concerns. Instead of\nbuilding new logic into a live app, we can build that logic elsewhere in a way\nthat's reusable across multiple apps.\n\nThe end goal here is simply to read/write to a database. That said, there's\nstill a fair amount of complexity involved. We'll need to leverage the following\nAWS services:\n\n * RDS (Relational Database Service): A cloud hosted database\n * API Gateway: An interface for building APIs\n * Lambda: The necessary serverless connector between RDS and Gateway\n * IAM: Amazon's god-awful user and policy manager\n\nFor now, all we're going to worry about is RDS.\n\nData is the New Kale is the New Money is the new Bitcoin Oil Gold ETFs\nHead to the AWS console and create a new RDS instance. Once prompted, go with\nMySQL:\n\nAs though some of these are real options. Please.Stick with MySQL Production  on the next screen.\n\nDo everything in production. AlwaysConfiguration Settings\nThis is where we set our configurations. You'll notice immediately how\nconvoluted AWS tends to be with their naming conventions. I personally hate how\nintentionally unintuitive all of AWS tends to be (what the hell is a \ndb.t2.medium)? This sort of absurdity is just something we need to deal with\nforever. Amazon is technically outside the realm of enforceable Monopoly laws,\nand there's no reason to believe their reign of mediocre products and talking\nrobots is ever going to end.\n\n * License: Select general-public-license\n * Version: Choose whichever, just don't do an old one\n * Instance class: Most of these instances are huge and unnecessary. Go with\n   something small: I would also advise looking at the pricing plan.\n * Multi AZ: Create a replica.\n * Storage type: General.\n * Allocated storage: Feel free to allocate more for latency.\n * Publicly Accessible: True.\n\nGod I love configuring esoteric shit.Once configuration is complete, it takes a\ngood amount of time for the database to be created. While we wait, let's move on\nto creating to a user to access this. We can do this with IAM: another AWS\nproduct with an even more terrible interface.\n\nAccess\nFair warning: user roles and permissions are the worst part of AWS. I could\nwrite an entire series on how deep this mess of a scheme goes, but quite\nhonestly I still barely understand what I'm doing most of the time.\n\nCreating a User\nCreate a new user that will access the database. Go to the Users panel  and\ncreate a user:\n\nModifying permission policies\nPermissions works by \"attaching\" existing \"policies\" to users, groups, etc. AWS\nhas some default policies that we can leverage for our purposes, so this should\nluckily be somewhat straightforward.\n\nPolicies can also be combined so that users have multiple policies across AWS\nproducts.\n\nNative Client\nOnce your DB pops up in AWS, we're going to need to get you a GUI to modify your\nDB. Don't even try to be a hotshot by setting up all your tables via command\nline. It sucks, it's slower, and nobody is impressed. Don't bother downloading\nthe AWS CLI either. Do not pass GO. Do not collect 500 dollars.\n\nIn case you need to install MySQL locally, an OSX download can be found here.\nCome to think of it, that step was probably unnecessary. I'm not sure why I did\nthat.\n\nI settled on Sequel Pro [https://www.sequelpro.com/]  as a client. It's good\nenough, and their logo looks like pancakes. That's really the only metric I\nneeded tbh.\n\nTo connect to your database, you'll need to retrieve the endpoint and port\nnumber from your RDS console:\n\nConnect to that ish:\n\nHopefully everything went well! If not, I'm sure the problem will be a quick and\neasy fix. Surely it won't involve mindlessly swapping permissions for an entire\nday. You defintely won't somehow end up corrupting your .bash_profile, making\nPython invisible to your OS, and effectively destroying your computer. Only an\nidiot would do something like that. Yesterday evening.\n\nGo ahead and get accustomed to the UI of Sequel Pro - it's pretty\nstraightforward, and ten thousand million times less effort than creating tables\nvia terminal. Create columns under the \"structure\" tab - the terminology should\nimmediately seem familiar if you've been following the series until this point.\n\nProtip: Issues with Security Groups\nIf you're running into an issue connecting to your DB externally, I happened to\nrun in to a nice little issue the other day with security groups. RDS instances\nlimit what kinds of connections they accept via \"security groups.\" This is yet\nanother layer of AWS security hassle where you'll need to specify which hosts\nare permitted to access your DB, by type of connection, port range, etc.\n\nIf you'd like to get this over with as soon as possible, this configuration will\nopen you up to the entire world:\n\nHappy Trails\nNext time we're going to sink deeper into this rabbit hole by exploring the\nwonderful world of serverless functions. Setting up AWS Lambda will allow us to\nconfigure endpoints which will allow us to read and write data to our brand new\ntable in the sky.\n\nWe'll still need to get into API Gateway after that, but let's not think about\nthat just yet. Let's not address the absurd amount of time and effort we're\nabout to spend just to make a god damn widget that shows Github commits.","html":"<p>Last time we became familiar with the handiwork of setting up MySQL locally, navigating databases via command line, and exposing your database to external access. While badass, it has come to my attention that most people don't bother doing things this way. Unless you're getting deep into some heavy architecture, most people opt to use cloud services such as AWS to set up databases which are intended to be interacted with by multiple services.</p><p>A perfect example is one we ran into over the weekend while working on this very blog. We're running a Ghost instance, which is respectably complex production-ready app. For a bunch of guys just looking to make some stupid blog widgets, it became obvious that reverse engineering the undocumented inner workings of an open source node app was a rabbit hole of complexity.</p><h2 id=\"hosting-on-aws\">Hosting on AWS</h2><p>In our case, AWS is useful for enforcing separation of concerns. Instead of building new logic into a live app, we can build that logic elsewhere in a way that's reusable across multiple apps.</p><p>The end goal here is simply to read/write to a database. That said, there's still a fair amount of complexity involved. We'll need to leverage the following AWS services:</p><ul><li>RDS (Relational Database Service): A cloud hosted database</li><li>API Gateway: An interface for building APIs</li><li>Lambda: The necessary serverless connector between RDS and Gateway</li><li>IAM: Amazon's god-awful user and policy manager</li></ul><p>For now, all we're going to worry about is RDS.</p><h2 id=\"data-is-the-new-kale-is-the-new-money-is-the-new-bitcoin-oil-gold-etfs\">Data is the New Kale is the New Money is the new Bitcoin Oil Gold ETFs</h2><p>Head to the AWS console and create a new RDS instance. Once prompted, go with MySQL:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-04-30-19.59.13.png\" class=\"kg-image\" alt=\"Database Type\"><figcaption>As though some of these are real options. Please.</figcaption></figure><p>Stick with <strong>MySQL Production</strong> on the next screen.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-04-30-19.59.22.png\" class=\"kg-image\" alt=\"Use case\"><figcaption>Do everything in production. Always</figcaption></figure><h3 id=\"configuration-settings\">Configuration Settings</h3><p>This is where we set our configurations. You'll notice immediately how convoluted AWS tends to be with their naming conventions. I personally hate how intentionally unintuitive all of AWS tends to be (what the hell is a <em>db.t2.medium</em>)? This sort of absurdity is just something we need to deal with forever. Amazon is technically outside the realm of enforceable Monopoly laws, and there's no reason to believe their reign of mediocre products and talking robots is ever going to end.</p><ul><li><strong>License</strong>: Select <em>general-public-license</em></li><li><strong>Version</strong>: Choose whichever, just don't do an old one</li><li><strong>Instance class</strong>: Most of these instances are huge and unnecessary. Go with something small: I would also advise looking at the pricing plan.</li><li><strong>Multi AZ</strong>: Create a replica.</li><li><strong>Storage type</strong>: General.</li><li><strong>Allocated storage</strong>: Feel free to allocate more for latency.</li><li><strong>Publicly Accessible</strong>: True.</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-04-30-19.59.46.png\" class=\"kg-image\" alt=\"Configuration\"><figcaption>God I love configuring esoteric shit.</figcaption></figure><p>Once configuration is complete, it takes a good amount of time for the database to be created. While we wait, let's move on to creating to a user to access this. We can do this with IAM: another AWS product with an even more terrible interface.</p><h2 id=\"access\">Access</h2><p>Fair warning: user roles and permissions are the worst part of AWS. I could write an entire series on how deep this mess of a scheme goes, but quite honestly I still barely understand what I'm doing most of the time.</p><h3 id=\"creating-a-user\">Creating a User</h3><p>Create a new user that will access the database. Go to the <a href=\"https://console.aws.amazon.com/iam/home?region=us-east-1#/users\">Users panel</a> and create a user:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/04/Screenshot-2018-04-30-19.37.20.png\" class=\"kg-image\" alt=\"Users\"></figure><h3 id=\"modifying-permission-policies\">Modifying permission policies</h3><p>Permissions works by \"attaching\" existing \"policies\" to users, groups, etc. AWS has some default policies that we can leverage for our purposes, so this should luckily be somewhat straightforward.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/04/Screenshot-2018-04-30-19.39.15.png\" class=\"kg-image\" alt=\"Permissions\"></figure><p>Policies can also be combined so that users have multiple policies across AWS products.</p><h2 id=\"native-client\">Native Client</h2><p>Once your DB pops up in AWS, we're going to need to get you a GUI to modify your DB. Don't even try to be a hotshot by setting up all your tables via command line. It sucks, it's slower, and nobody is impressed. Don't bother downloading the AWS CLI either. Do not pass GO. Do not collect 500 dollars.</p><p>In case you need to install MySQL locally, an OSX download can be found <a href=\"https://dev.mysql.com/downloads/mysql/5.5.html#macosx-dmg\">here</a>. Come to think of it, that step was probably unnecessary. I'm not sure why I did that.</p><p>I settled on <a href=\"https://www.sequelpro.com/\">Sequel Pro</a> as a client. It's good enough, and their logo looks like pancakes. That's really the only metric I needed tbh.</p><p>To connect to your database, you'll need to retrieve the endpoint and port number from your RDS console:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/04/Screenshot-2018-04-30-19.51.44.png\" class=\"kg-image\" alt=\"Endpoint\"></figure><p>Connect to that ish:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/04/Screenshot-2018-04-30-19.51.28.png\" class=\"kg-image\" alt=\"Sequel Pro\"></figure><p>Hopefully everything went well! If not, I'm sure the problem will be a quick and easy fix. Surely it won't involve mindlessly swapping permissions for an entire day. You defintely won't somehow end up corrupting your .bash_profile, making Python invisible to your OS, and effectively destroying your computer. Only an idiot would do something like that. Yesterday evening.</p><p>Go ahead and get accustomed to the UI of Sequel Pro - it's pretty straightforward, and ten thousand million times less effort than creating tables via terminal. Create columns under the \"structure\" tab - the terminology should immediately seem familiar if you've been following the series until this point.</p><h2 id=\"protip-issues-with-security-groups\">Protip: Issues with Security Groups</h2><p>If you're running into an issue connecting to your DB externally, I happened to run in to a nice little issue the other day with security groups. RDS instances limit what kinds of connections they accept via \"security groups.\" This is yet another layer of AWS security hassle where you'll need to specify which hosts are permitted to access your DB, by type of connection, port range, etc.</p><p>If you'd like to get this over with as soon as possible, this configuration will open you up to the entire world:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-07.15.26.png\" class=\"kg-image\" alt=\"Security Groups\"></figure><h2 id=\"happy-trails\">Happy Trails</h2><p>Next time we're going to sink deeper into this rabbit hole by exploring the wonderful world of serverless functions. Setting up AWS Lambda will allow us to configure endpoints which will allow us to read and write data to our brand new table in the sky.</p><p>We'll still need to get into API Gateway after that, but let's not think about that just yet. Let's not address the absurd amount of time and effort we're about to spend just to make a god damn widget that shows Github commits.</p>","url":"https://hackersandslackers.com/setting-up-mysql-on-aws/","uuid":"bf9a9804-206a-4556-ade4-b7cbdd896ecc","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5ae6899aed09bd1cb7110e51"}},{"node":{"id":"Ghost__Post__5c64981a7c8ecc6ee30c6870","title":"Starting a Python Web App with Heroku","slug":"starting-a-python-web-app-with-heroku","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/flask2@2x.jpg","excerpt":"Pairing Flask with zero-effort container deployments is a deadly path to addiction.","custom_excerpt":"Pairing Flask with zero-effort container deployments is a deadly path to addiction.","created_at_pretty":"13 February, 2019","published_at_pretty":"13 February, 2018","updated_at_pretty":"13 February, 2019","created_at":"2019-02-13T17:20:10.000-05:00","published_at":"2018-02-13T17:20:00.000-05:00","updated_at":"2019-02-13T17:57:20.000-05:00","meta_title":"Starting a Python Application with Heroku | Hackers and Slackers","meta_description":"Flask is a gift to developers who value the act of development. Pairing Python with zero-effort container deployments is a deadly path to addiction.","og_description":"Flask is a gift to developers who value the act of development. Pairing Python with zero-effort container deployments is a deadly path to addiction.","og_image":"https://hackersandslackers.com/content/images/2019/02/flask2@2x.jpg","og_title":"Starting a Python Application with Heroku | Hackers and Slackers","twitter_description":"Flask is a gift to developers who value the act of development. Pairing Python with zero-effort container deployments is a deadly path to addiction.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/flask2@2x.jpg","twitter_title":"Starting a Python Application with Heroku | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"}],"plaintext":"It's difficult to cover every cloud solution on the market without at least\nmentioning Heroku. Heroku contrasts nearly every cloud hosting solution by\noffering a clear purpose: make deploying apps of any kind as easy as possible.\nDeploying to a VPS requires knowledge of web servers and configurations.\nDeploying to containers requires knowledge of Docker or Kubernetes. Deploying to\nHeroku requires nearly no prior knowledge of anything.\n\nHeroku is great for getting MVPs out the door, or for devs who want to jump into\ndeveloping web applications with knowledge of a specific language. Even\ndevelopers with advanced knowledge of how to deploy production applications may\nwant to use Heroku for fast internal deployments, or as a platform for\n\"sketching out\" a quick prototype.\n\nIn this exploration, we'll be using Heroku to deploy a Python application using\nthe Flask framework.\n\nWhy Heroku?\nWe're on the topic of simplicity, so let's keep that theme going. Heroku's\ninfrastructure offering is unique in that Heroku obfuscates the DevOps aspect of\nweb development completely. That means that configuring web servers, managing\nLinux packages, and supplying SSL certs are entirely taken care of by Heroku. \n\nLet's consider Heroku's ease-of-use services to be luxuries which save us time.\nThey are NOT  a replacement for grasping these concepts.\n\nPipelines\nAside from VPS upkeep, Heroku obfuscates the process of moving an app through\ndevelopment and production environments by defining pipelines. That's right,\nCI/CD is built directly into Heroku's interface.\n\nAdd-ons\nThe most addictive aspect of Heroku is probably the Elements marketplace. This\nis a place to window-shop for set-it-and-forget-it plugins for your app, most of\nwhich are very easy to integrate with. \n\nMost add-ons fall under a few major categories: database resellers, analytics,\nand Redis, to name a few (interestingly enough, using the base Redis add-on in\nHeroku is free, while the equivalent instance would cost you 5 dollars from the\nsame provider had you used them directly. Add-ons are \"deployed\" after a single\nclick, and the ensuing configuration process varies from vendor-to-vendor after\nthat.\n\nSpeaking of single-click, they handle single-click deployments of popular build\npacks, too. You, the thing that made DigitalOcean a big deal way back. You get\nthe idea.\n\nCreating your Project\nLog in to the Heroku UI and create an app on a fresh Dyno. A Dyno is merely a\nfancy, overly branded word for \"container.\" Next, you'll be prompted to download\nthe Heroku CLI locally on your OS of choice, which is quick and painless. Now\nwe're cooking with gas.\n\nCreate an empty local directory and type the following command to be prompted\nfor your Heroku account credentials:\n\n$ heroku login\nEnter your Heroku credentials.\nEmail: python@example.com\nPassword:\n\n\nAt this point, Heroku has already magically created a git repository for your\napplication from which you'll be doing development from.\n\n$ git clone https://github.com/heroku/example-flask-project.git\n$ cd example-flask-project\n\n$ heroku create\nCreating example-flask-project in organization heroku... done, stack is cedar-14\nhttp://example-flask-project.herokuapp.com/ | https://git.heroku.com/example-flask-project.git\nGit remote heroku added\n\n\nWow, that sure looks a lot like we're working with Github huh? That's actually\nthe point: if you so chose, you can configure the Heroku CLI to recognize your\nGithub username with a simple heroku config:get GITHUB_USERNAME=yourname. With\nthis configured, Heroku will actually allow you to simply deploy to your\npersonal Github repo and mimic the changes on your Dyno. Now let's configure\nthis thing.\n\nA Project For Ants\nWe're going to get started by building you obligatory \"hello world\" app. The\nresulting file structure is going to end up looking like this:\n\nexample-flask-project\n├── app.py\n├── Procfile\n├── Pipfile\n├── Pipfile.lock\n├── runtime.txt\n├── requirements.txt\n├── Pipfile.lock\n└── setup.py\n\n\nNote the existence of two files you may not have seen before if you're new to\nHeroku: the Procfile  (no file extension) and requirements.txt. These are tiny\nfiles which specify which language we're using and how to start our app, but\nwe'll get to that in a moment.\n\nManaging Your Python Packages \nHeroku impressively supports Pipenv out-of-the-box for handling and installing\ndependencies. Every time you deploy your application, Heroku will install the\npackage version specified in Pipfile.lock to build your app from scratch. If\nyou're new to using Pipenv consider quickly picking up the basics from this\nquick tutorial\n[https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/]\n. If you're still using virtualenv, you should consider switching to Pipenv\nregardless.\n\nCreate a local folder for your project. In that folder, start a Pipenv shell:\n\n$ pip install pipenv\npipenv shell\n\n\nWith the shell activated, we can now install dependencies specific to our\nenvironment. At a bare minimum, we need to install two packages: Flask  as our\nframework, and Gunicorn  to run our app process.\n\n(my-project)$ pip3 install flask gunicorn\n\n\nGood job; now let's build out the files in our tree one-by-one.\n\nProcfile\nThe Procfile (no file extension) is a unique file to Heroku which is essentially\na build command. This will be a one-liner to tell Gunicorn  to startup our\napplication from our base app.py  file.\n\nweb: gunicorn app:app\n\nA quick breakdown here: web  is our process 'type'. other types exists, such as \nworker, urgentworker, and clock, but that's not important for now.\n\napp:app  signifies looking for the 'app' module in our app.py  file. If you'd\nlike to move app.py to . a different folder down the line, this can be adjusted\nas such:\n\nweb: gunicorn differentfolder app:app\n\nRuntime\nThe runtime.txt  file notifies Heroku of the language it's dealing with as well\nas the proper version. Heroku only supports up to a particular version of Python\nat any given moment (which is currently Python-3.7.1), but specifying a higher\nversion will default to the latest version Heroku supports.\n\nPython-3.7.1\n\nRequirements.txt\nEven though Heroku uses your Pipfile to build dependencies, it's still best\npractice to keep a requirements.txt  present for numerous reasons. For example,\nif you remove dependencies from your Pipfile without uninstalling them, \nrequirements.txt  is a useful way of identifying old packages in your\nenvironment that can be uninstalled.\n\n(my-project)$ pip freeze > requirements.txt\n\n\nAs I'm sure you know, pip freeze  will print all packages and their versions\ninto the designated file as such:\n\nasn1crypto==0.24.0\nbcrypt==3.1.4\nbeautifulsoup4==4.6.0\nblinker==1.4\ncffi==1.11.5\nclick==6.7\ncryptography==2.2.2\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Mail==0.9.1\nflask-mongoengine==0.9.5\nFlask-SQLAlchemy==2.3.2\nFlask-Static-Compress==1.0.2\nFlask-User==1.0.1.5\nFlask-WTF==0.14.2\ngunicorn==19.9.0\nidna==2.7\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nMarkupSafe==1.0\nmongoengine==0.15.0\nordereddict==1.1\npasslib==1.7.1\npycparser==2.18\npymongo==3.7.0\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.9\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\n\n\nPipfile\nOur Pipfile is automatically generated by Pipenv by default, but be sure to call\nout packages which are essential to the build our app as. Packages which are\nrequired for your app to work belong under the [packages]  section.\n\n[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\ngunicorn = \"*\"\nflask = \"*\"\nrequests = \"*\"\nwtforms = \"*\"\nflask_assets = \"*\"\nflask_static_compress = \"*\"\n\n[dev-packages]\n\n[requires]\npython_version = \"3.7.1\"\n\n\nPipfile.lock\nHeroku looks at Pipfile.lock  every time our app builds to know which packages\nto install on the server side. Changing dependencies locally without updating\nthe Pipfile.lock  will not carry the changes over to your Dyno. Thus, be sure to\ngenerate this file when needed:\n\n(my-project)$ pipenv lock\n\n\nBetter yet, running the following will check your Pipfile for packages which can\nbe updated, will update those packages, and then  generate a lock file:\n\n(my-project)$ pipenv update\n\n\nSetup.py\nTechnically this file isn't required, but is a general best practice when\ncreating projects. Most of Setup.py's purpose comes in to play if you plan on\nsubmitting your project as a standalone package,\n\nfrom setuptools import setup, find_packages\n\nsetup(\n    name='my-project',\n    version='1.0',\n    long_description=__doc__,\n    packages=find_packages(),\n    include_package_data=True,\n    zip_safe=False,\n    install_requires=['Flask'],\n)\n\n\n.env\nOkay, okay, just one last thing. Heroku will be upset unless there's a .env \nfile in its root directory at run time. .env  is where we would store sensitive\ninformation (such as secrets), but feel free to leave this empty for now. \n\nHeroku allows you to manage environment variables via their web UI as well.\nThese can then be conveniently saved to your local environment to run your app\nlocally, but let's stay focused on the task at hand: saying \"hello\" to the\nworld.\n\nDeployment\nRunning your app locally is as simple as two words: heroku local. This spins up\nan instance of your app on your machine at 0.0.0.0:5000.\n\nDeploying to your Heroku Dyno is much like deploying to Github (they can in fact\nbe the exact same if you configure it as such). Here's how deployment via the\nHeroku CLI looks:\n\ngit add .\ngit commit -am 'initial commit'\ngit push heroku master\n\n\nIf all went well, your app should be live at the URL Heroku generated for you\nwhen you created your project. Go ahead and checkout the Heroku UI to see how\nthings went. \n\nI highly suggest checking out the logs on the Heroku UI after each deploy. Often\ntimes issues which don't appear on your local environment will pop up on the\nserver:\n\nHeroku's logging system is surprisingly both helpful and aesthetically pleasing.\nWhat Do We Make Of This?\nThere are two general takeaways I suppose I'm getting at:\n\n * Heroku is easy and fun to use.\n * Flask is awesome. \n\nAs much as #1 is true, I think it's important to distinguish Heroku's place in a\ncrowded cloud market. Heroku is a platform best suited for dumping MVPs and side\nprojects... NOT production applications. While you certainly can host large apps\non Heroku, I consider it to highly unprofessional. Remember: Heroku is basically\na reseller. They host their containers on AWS, and sell add-ons from other\nvendors. If you depend too heavily on Heroku, you are essentially just adding a\nmiddle man to your billing cycle.\n\nOn the Flask side: Flask's development may not be as vast as the npm  packages\noffered by Node, there's more or less a package for anything you possibly need.\nI'd recommend checking out Flask's official list of packages\n[http://flask.pocoo.org/extensions/].\n\nWhile we may have set up our first Flask application, as it stands we've only\nbuilt something useless so far. Consider this to be the beginning of many, many\nFlask tips to come.","html":"<p>It's difficult to cover every cloud solution on the market without at least mentioning Heroku. Heroku contrasts nearly every cloud hosting solution by offering a clear purpose: make deploying apps of any kind as easy as possible. Deploying to a VPS requires knowledge of web servers and configurations. Deploying to containers requires knowledge of Docker or Kubernetes. Deploying to Heroku requires nearly no prior knowledge of anything.</p><p>Heroku is great for getting MVPs out the door, or for devs who want to jump into developing web applications with knowledge of a specific language. Even developers with advanced knowledge of how to deploy production applications may want to use Heroku for fast internal deployments, or as a platform for \"sketching out\" a quick prototype.</p><p>In this exploration, we'll be using Heroku to deploy a Python application using the Flask framework.</p><h2 id=\"why-heroku\">Why Heroku?</h2><p>We're on the topic of simplicity, so let's keep that theme going. Heroku's infrastructure offering is unique in that Heroku obfuscates the DevOps aspect of web development completely. That means that configuring web servers, managing Linux packages, and supplying SSL certs are entirely taken care of by Heroku. </p><p>Let's consider Heroku's ease-of-use services to be luxuries which save us time. They are <strong>NOT</strong> a replacement for grasping these concepts.</p><h3 id=\"pipelines\">Pipelines</h3><p>Aside from VPS upkeep, Heroku obfuscates the process of moving an app through development and production environments by defining <em>pipelines. </em>That's right, CI/CD is built directly into Heroku's interface.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-10-at-10.19.41-AM.png\" class=\"kg-image\"></figure><h3 id=\"add-ons\">Add-ons</h3><p>The most addictive aspect of Heroku is probably the Elements marketplace. This is a place to window-shop for set-it-and-forget-it plugins for your app, most of which are very easy to integrate with. </p><p>Most add-ons fall under a few major categories: database resellers, analytics, and Redis, to name a few (interestingly enough, using the base Redis add-on in Heroku is free, while the equivalent instance would cost you 5 dollars from the same provider had you used them directly. Add-ons are \"deployed\" after a single click, and the ensuing configuration process varies from vendor-to-vendor after that.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screenshot-2018-07-08-17.30.07.png\" class=\"kg-image\"></figure><p>Speaking of single-click, they handle single-click deployments of popular build packs, too. You, the thing that made DigitalOcean a big deal way back. You get the idea.</p><h2 id=\"creating-your-project\">Creating your Project</h2><p>Log in to the Heroku UI and create an app on a fresh Dyno. A Dyno is merely a fancy, overly branded word for \"container.\" Next, you'll be prompted to download the Heroku CLI locally on your OS of choice, which is quick and painless. Now we're cooking with gas.</p><p>Create an empty local directory and type the following command to be prompted for your Heroku account credentials:</p><pre><code class=\"language-bash\">$ heroku login\nEnter your Heroku credentials.\nEmail: python@example.com\nPassword:\n</code></pre>\n<p>At this point, Heroku has already magically created a git repository for your application from which you'll be doing development from.</p><pre><code class=\"language-bash\">$ git clone https://github.com/heroku/example-flask-project.git\n$ cd example-flask-project\n\n$ heroku create\nCreating example-flask-project in organization heroku... done, stack is cedar-14\nhttp://example-flask-project.herokuapp.com/ | https://git.heroku.com/example-flask-project.git\nGit remote heroku added\n</code></pre>\n<p>Wow, that sure looks a lot like we're working with Github huh? That's actually the point: if you so chose, you can configure the Heroku CLI to recognize your Github username with a simple <code>heroku config:get GITHUB_USERNAME=yourname</code>. With this configured, Heroku will actually allow you to simply deploy to your personal Github repo and mimic the changes on your Dyno. Now let's configure this thing.</p><h2 id=\"a-project-for-ants\">A Project For Ants</h2><p>We're going to get started by building you obligatory \"hello world\" app. The resulting file structure is going to end up looking like this:</p><pre><code class=\"language-bash\">example-flask-project\n├── app.py\n├── Procfile\n├── Pipfile\n├── Pipfile.lock\n├── runtime.txt\n├── requirements.txt\n├── Pipfile.lock\n└── setup.py\n</code></pre>\n<p>Note the existence of two files you may not have seen before if you're new to Heroku: the <strong>Procfile</strong> (no file extension) and <strong>requirements.txt</strong>. These are tiny files which specify which language we're using and how to start our app, but we'll get to that in a moment.</p><h3 id=\"managing-your-python-packages\">Managing Your Python Packages </h3><p>Heroku impressively supports Pipenv out-of-the-box for handling and installing dependencies. Every time you deploy your application, Heroku will install the package version specified in Pipfile.lock to build your app from scratch. If you're new to using Pipenv consider quickly picking up the basics from <a href=\"https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/\">this quick tutorial</a>. If you're still using virtualenv, you should consider switching to Pipenv regardless.</p><p>Create a local folder for your project. In that folder, start a Pipenv shell:</p><pre><code class=\"language-bash\">$ pip install pipenv\npipenv shell\n</code></pre>\n<p>With the shell activated, we can now install dependencies specific to our environment. At a bare minimum, we need to install two packages: <strong>Flask</strong> as our framework, and <strong>Gunicorn</strong> to run our app process.</p><pre><code class=\"language-bash\">(my-project)$ pip3 install flask gunicorn\n</code></pre>\n<p>Good job; now let's build out the files in our tree one-by-one.</p><h3 id=\"procfile\">Procfile</h3><p>The Procfile (no file extension) is a unique file to Heroku which is essentially a build command. This will be a one-liner to tell <strong>Gunicorn</strong> to startup our application from our base <code>app.py</code> file.</p><pre><code>web: gunicorn app:app</code></pre><p>A quick breakdown here: <code>web</code> is our process 'type'. other types exists, such as <code>worker</code>, <code>urgentworker</code>, and <code>clock</code>, but that's not important for now.</p><p><code>app:app</code> signifies looking for the 'app' module in our <em>app.py</em> file. If you'd like to move app.py to . a different folder down the line, this can be adjusted as such:</p><pre><code>web: gunicorn differentfolder app:app</code></pre><h3 id=\"runtime\">Runtime</h3><p>The runtime.txt  file notifies Heroku of the language it's dealing with as well as the proper version. Heroku only supports up to a particular version of Python at any given moment (which is currently <em>Python-3.7.1</em>), but specifying a higher version will default to the latest version Heroku supports.</p><pre><code>Python-3.7.1</code></pre><h3 id=\"requirements-txt\">Requirements.txt</h3><p>Even though Heroku uses your Pipfile to build dependencies, it's still best practice to keep a <code>requirements.txt</code> present for numerous reasons. For example, if you remove dependencies from your Pipfile without uninstalling them, <code>requirements.txt</code> is a useful way of identifying old packages in your environment that can be uninstalled.</p><pre><code class=\"language-bash\">(my-project)$ pip freeze &gt; requirements.txt\n</code></pre>\n<p>As I'm sure you know, <code>pip freeze</code> will print all packages and their versions into the designated file as such:</p><pre><code class=\"language-bash\">asn1crypto==0.24.0\nbcrypt==3.1.4\nbeautifulsoup4==4.6.0\nblinker==1.4\ncffi==1.11.5\nclick==6.7\ncryptography==2.2.2\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Mail==0.9.1\nflask-mongoengine==0.9.5\nFlask-SQLAlchemy==2.3.2\nFlask-Static-Compress==1.0.2\nFlask-User==1.0.1.5\nFlask-WTF==0.14.2\ngunicorn==19.9.0\nidna==2.7\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nMarkupSafe==1.0\nmongoengine==0.15.0\nordereddict==1.1\npasslib==1.7.1\npycparser==2.18\npymongo==3.7.0\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.9\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\n</code></pre>\n<h3 id=\"pipfile\">Pipfile</h3><p>Our Pipfile is automatically generated by Pipenv by default, but be sure to call out packages which are essential to the build our app as. Packages which are required for your app to work belong under the <code>[packages]</code> section.</p><pre><code>[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\ngunicorn = \"*\"\nflask = \"*\"\nrequests = \"*\"\nwtforms = \"*\"\nflask_assets = \"*\"\nflask_static_compress = \"*\"\n\n[dev-packages]\n\n[requires]\npython_version = \"3.7.1\"\n</code></pre><h3 id=\"pipfile-lock\">Pipfile.lock</h3><p>Heroku looks at <code>Pipfile.lock</code><em> </em>every time our app builds to know which packages to install on the server side. Changing dependencies locally without updating the <code>Pipfile.lock</code> will not carry the changes over to your Dyno. Thus, be sure to generate this file when needed:</p><pre><code class=\"language-bash\">(my-project)$ pipenv lock\n</code></pre>\n<p>Better yet, running the following will check your Pipfile for packages which can be updated, will update those packages, and <em>then</em> generate a lock file:</p><pre><code class=\"language-bash\">(my-project)$ pipenv update\n</code></pre>\n<h3 id=\"setup-py\">Setup.py</h3><p>Technically this file isn't required, but is a general best practice when creating projects. Most of <code>Setup.py</code>'s purpose comes in to play if you plan on submitting your project as a standalone package,</p><pre><code class=\"language-python\">from setuptools import setup, find_packages\n\nsetup(\n    name='my-project',\n    version='1.0',\n    long_description=__doc__,\n    packages=find_packages(),\n    include_package_data=True,\n    zip_safe=False,\n    install_requires=['Flask'],\n)\n</code></pre>\n<h2 id=\"-env\">.env</h2><p>Okay, okay, just one last thing. Heroku will be upset unless there's a <code>.env</code> file in its root directory at run time. <code>.env</code> is where we would store sensitive information (such as secrets), but feel free to leave this empty for now. </p><p>Heroku allows you to manage environment variables via their web UI as well. These can then be conveniently saved to your local environment to run your app locally, but let's stay focused on the task at hand: saying \"hello\" to the world.</p><h2 id=\"deployment\">Deployment</h2><p>Running your app locally is as simple as two words: <code>heroku local</code>. This spins up an instance of your app on your machine at <code>0.0.0.0:5000</code>.</p><p>Deploying to your Heroku Dyno is much like deploying to Github (they can in fact be the exact same if you configure it as such). Here's how deployment via the Heroku CLI looks:</p><pre><code class=\"language-bash\">git add .\ngit commit -am 'initial commit'\ngit push heroku master\n</code></pre>\n<p>If all went well, your app should be live at the URL Heroku generated for you when you created your project. Go ahead and checkout the Heroku UI to see how things went. </p><p>I highly suggest checking out the logs on the Heroku UI after each deploy. Often times issues which don't appear on your local environment will pop up on the server:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screenshot-2018-07-08-17.16.33.png\" class=\"kg-image\"><figcaption>Heroku's logging system is surprisingly both helpful and aesthetically pleasing.</figcaption></figure><h2 id=\"what-do-we-make-of-this\">What Do We Make Of This?</h2><p>There are two general takeaways I suppose I'm getting at:</p><ul><li>Heroku is easy and fun to use.</li><li>Flask is awesome. </li></ul><p>As much as #1 is true, I think it's important to distinguish Heroku's place in a crowded cloud market. Heroku is a platform best suited for dumping MVPs and side projects... NOT production applications. While you certainly can host large apps on Heroku, I consider it to highly unprofessional. Remember: Heroku is basically a reseller. They host their containers on AWS, and sell add-ons from other vendors. If you depend too heavily on Heroku, you are essentially just adding a middle man to your billing cycle.</p><p>On the Flask side: Flask's development may not be as vast as the <code>npm</code> packages offered by Node, there's more or less a package for anything you possibly need. I'd recommend checking out Flask's official list of <a href=\"http://flask.pocoo.org/extensions/\">packages</a>.</p><p>While we may have set up our first Flask application, as it stands we've only built something useless so far. Consider this to be the beginning of many, many Flask tips to come.</p>","url":"https://hackersandslackers.com/starting-a-python-web-app-with-heroku/","uuid":"c426aeae-5f78-405e-8452-57e8fc110b12","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c64981a7c8ecc6ee30c6870"}}]}},"pageContext":{"slug":"architecture","limit":12,"skip":12,"numberOfPages":2,"humanPageNumber":2,"prevPageNumber":1,"nextPageNumber":null,"previousPagePath":"/tag/architecture/","nextPagePath":null}}