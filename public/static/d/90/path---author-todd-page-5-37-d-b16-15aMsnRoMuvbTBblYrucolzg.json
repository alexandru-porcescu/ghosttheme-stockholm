{"data":{"ghostAuthor":{"slug":"todd","name":"Todd Birchard","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","cover_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/fox_o_o.jpg","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","location":"New York City","website":"https://toddbirchard.com","twitter":"@ToddRBirchard","facebook":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736fe","title":"So You've Fucked up your Python Path","slug":"so-youve-fucked-up-your-python-path","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/pythonpath-3@2x.jpg","excerpt":"A timeless hazing ritual for new Python devs, and how to fix it.","custom_excerpt":"A timeless hazing ritual for new Python devs, and how to fix it.","created_at_pretty":"11 September, 2018","published_at_pretty":"12 September, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-09-11T07:56:57.000-04:00","published_at":"2018-09-12T08:04:00.000-04:00","updated_at":"2019-02-02T04:47:15.000-05:00","meta_title":"How to Recover from a Broken Python Path | Hackers and Slackers","meta_description":"Deleting your native system Python: a coming of age story. Learn how to fix your broken Python path without wiping your machine.","og_description":"Deleting your native system Python: a coming of age story. Learn how to fix your broken Python path without wiping your machine.","og_image":"https://hackersandslackers.com/content/images/2018/09/pythonpath-3@2x.jpg","og_title":"How to Recover from a Broken Python Path | Hackers and Slackers","twitter_description":"Deleting your native system Python: a coming of age story. Learn how to fix your broken Python path without wiping your machine.","twitter_image":"https://hackersandslackers.com/content/images/2018/09/pythonpath-3@2x.jpg","twitter_title":"How to Recover from a Broken Python Path | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"}],"plaintext":"I remember back to when I first learned Python. It was a strange decision for a\nhappily employed post-graduate to make, especially for a time when many were\nscreaming for the death of the language with Guido's (outrageous?) grand reveal\nof Python 3.  The Ruby on Rails guys seemed to be doing just fine. Those were\nthe days.\n\nAfter weeks of sweating over a keyboard in the basement of an illegal BedStuy\nhostel, I had finally set out what I had hoped to achieve. It was the greatest\ncredential any programmer could possibly strive for: yes ladies and gentlemen,\nnone other than yours truly became an officially recognized licensed\nprofessional: I had just completed the last Python course in Codecademy.\n\nCongrats! You know nothing.Armed with this new unfathomable knowledge, I was\nready to take on the world. I did have a few gaps in my knowledge, such as:\n\n * Experience with Linux\n * General idea of what a terminal is and why anybody would use one\n * Basic understanding of the internet\n * Motor skills needed to survive\n\nThat aside, I was determined. Nothing could stop me, which turns out to be a\nreally bad attitude when you're SSHed into a VPS with root access, and zero\nhesitation to wreak havoc upon any and all system files. You see where this is\ngoing.\n\nDear Stack Overflow: I Think I Deleted Python\nDisabling your system's native Python version, whether via deletion or a\nmisconfigured PATH, is a coming-of-age cliché as timeless as losing one's\nvirginity on prom night. Young developers flock to Stack Overflow pleading for\nhelp, while those senior enough to reply sigh a gasp of nostalgia before\nreassuring them that their efforts are pointless. \"Ah yes,\" they reminisce, \"I\nremember my first devastating life-altering failure. To be young again.\"\n\nIf you're lucky enough to be unaware, UNIX based systems depend on their\nnatively installed version of Python to run, well, almost everything. If Python\nis unavailable for just a moment, the developer loses the ability to use:\n\n * vi\n * vim\n * nano\n * grep\n * source\n * wait, SOURCE?\n\nYep, the command you'd normally use to relaunch a corrupted startup file (such\nas the one that holds your PATH  variable) is totally unusable. Not that it\nmatters, what are you going to do, edit it?  Oh right, you just ruined every\nbash text editor. I'd actually be more interested in seeing what DOES work\nwithout Python configuring on Mac/Linux, other than moving up and down your file\nstructure helplessly, trying to quantify the damage you just wrecked upon your\nwork, life, and career.\n\nSo, Should I Kill Myself?\nHow to destroy everything ever.Calm yourself and stick with me here; I have no\ninterest in writing long-winded posts without providing any sort of solution.\nThat said, I have no problem making you sit down and think about what you've\ndone while I bother getting to the point. Nobody else has fixed this for you\nyet, and I need to improve my site's metrics, so it seems like we need each\nother on this one.\n\nBesides, don't be so hard on yourself. Not even a week ago, I sat with a Senior\nDeveloper to review my development stack, and how that would fit into the\ncurrent ecosystem of the department. Naturally I explained that I prefer running\n Flask  on Python 3.7, as I adjusted my motorcycle jacket and sat forward to\ncasually   extinguish a cigarette on his desk. Even through my vision was\nobstructed by the timelessly classic aviators resting on my face, I could see\nthe letters roll across the terminal window before him as he typed. The poor\nbastard running a 4-year old Linux distribution had just checked if Python 3 was\ninstalled on his live production instance, when his fingertips unleashed the\nunmistakable export PATH=..., seconds away from linking CentOS' native Python\nfrom Python 2.7 to Python 3.7. My exact reaction was something along the lines\nof \"OH GOD NO DON'T DO THAT STOP HOLY MOTHER OF JESUS FUCK!\" \n\nHe stopped typing. The day was saved, and I was able to explain the importance\nof leaving native Python versions intact on the systems they come installed on.\nThen, I myself fucked up the Python path maybe an hour later. On production.\n\nWe all do dumb things sometimes. That doesn't mean you're dumb. Well, except in\nmy case, having done this countless times before. Some of us simply like to live\ndangerously. Fortune favors the bold, and so on.\n\nRetro meme outta nowhere!Getting out of this Mess\nNow that we've hit rock bottom, where do we go from here? Well, two things to\nkeep in mind:\n\n 1. Not everything  is broken without Python. Extreme foreshadowing.\n 2. Restarting a terminal will automatically run all startup scripts.\n\nBy now you know that .bash_profile  and .bashrc  are critically important to\nyour system, considering how badly you've fucked things up just now. These files\nset important variables for your system every time you open your terminal; more\nspecifically, .bash_profile  kicks in on any sort of user log in (such as SSH)\nwhere .bashrc  fires every time a new additional terminal window is opened. Even\nif your startup files are corrupted, the system will always love them and turn\nto them regardless of how horribly disfigured you left them. Talk about a spark\nof hope.\n\nOn Mac OSX\nI'll admit I'm a bit embarrassed at how long it took me to realize this: even\nthough you ruined every text editor known to man, there's one resilient enough\nto hold strong. The name? TextEdit.\n\nReveal hidden files in OSX easily.In your root directory, a combo ofShift + Cmd + .  displays all hidden files.\nCheck out bash_profile. Fix it, save it, reopen terminal. Cancel the suicide\nparty. Pop the Champagne.\n\nOn Linux\nNo GUI can save us now, but what can? Perhaps a command so stupid, so simple,\nthat it couldn't possibly need Python to work:\n\necho 'export PATH=\"/YOUR/ORIGINAL/PATH/2.7/bin:${PATH}\"' >> ~/.bash_profile\n\n\nThis appends the text you provide to the end of an existing file. .bash_profile \nand .bashrc  both only pay attention to the last exported PATH in the document,\nwhich means the rest of your file will work, and the only PATH which is\nrespected is the one which you've presumably entered correctly this time around.\nRestart your terminal. Get back in the game son: it ain't about how hard you\nhit, but how hard you can get hit and keep moving forward.\n\nSidenote\nWe're not exactly conducting rocket science here (data science is a close second\nperhaps? Just kidding. We barely know what's going on most of the time). I felt\ncompelled to write this post for two reasons: one being how common and\ndestructive this pitfall can be for most people, but more importantly, the\nknee-jerk reaction veterans have in response to this problem is \"good luck,\nyou're fucked.\" \n\nI'm not here to comment on the integrity of our fine anonymous internet\ncommunities, but the discrepancy between how devastating losing a server can be\ndoesn't seem to met with much urgency by anybody with insight. Nobody taught me\nhow to work around these issues. Had I listened to anonymous internet advice, I\nprobably wouldn't let entire servers of sensitive data for dead, including my\npersonal machines. I worked through it, and quite frankly, I'm kind of a fucking\nidiot [https://hackersandslackers.com/about/], as is our mission statement. If\nan idiot who majored in nonsense and learned a programming language before\nlearning Linux can work through this, I would expect the same of those with much\nmore intelligence than I to, at the very least, attempt the same.","html":"<p>I remember back to when I first learned Python. It was a strange decision for a happily employed post-graduate to make, especially for a time when many were screaming for the death of the language with Guido's (outrageous?) grand reveal of Python 3.  The Ruby on Rails guys seemed to be doing just fine. Those were the days.</p><p>After weeks of sweating over a keyboard in the basement of an illegal BedStuy hostel, I had finally set out what I had hoped to achieve. It was the greatest credential any programmer could possibly strive for: yes ladies and gentlemen, none other than yours truly became an <em>officially recognized licensed professional</em>: I had just completed the last Python course in Codecademy.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/python-codecademy-champion.png\" class=\"kg-image\"><figcaption>Congrats! You know nothing.</figcaption></figure><p>Armed with this new unfathomable knowledge, I was ready to take on the world. I did have a few gaps in my knowledge, such as:</p><ul><li>Experience with Linux</li><li>General idea of what a terminal is and why anybody would use one</li><li>Basic understanding of the internet</li><li>Motor skills needed to survive</li></ul><p>That aside, I was determined. Nothing could stop me, which turns out to be a really bad attitude when you're SSHed into a VPS with root access, and zero hesitation to wreak havoc upon any and all system files. You see where this is going.</p><h2 id=\"dear-stack-overflow-i-think-i-deleted-python\">Dear Stack Overflow: I Think I Deleted Python</h2><style>\n    iframe{\n    height: 423px !important;\n        margin-bottom: 20px;\n    }\n</style>  <script type=\"text/javascript\" src=\"https://ssl.gstatic.com/trends_nrtr/1709_RC01/embed_loader.js\"></script>\n  <script type=\"text/javascript\">\n    trends.embed.renderExploreWidget(\"TIMESERIES\", {\"comparisonItem\":[{\"keyword\":\"python path\",\"geo\":\"US\",\"time\":\"2004-01-01 2019-02-02\"}],\"category\":0,\"property\":\"\"}, {\"exploreQuery\":\"date=all&geo=US&q=python%20path\",\"guestPath\":\"https://trends.google.com:443/trends/embed/\"});\n  </script><p>Disabling your system's native Python version, whether via deletion or a misconfigured <code>PATH</code>, is a coming-of-age cliché as timeless as losing one's virginity on prom night. Young developers flock to Stack Overflow pleading for help, while those senior enough to reply sigh a gasp of nostalgia before reassuring them that their efforts are pointless. \"<em>Ah yes,\" </em>they reminisce, \"<em>I remember my first devastating life-altering failure. To be young again.\"</em></p><p>If you're lucky enough to be unaware, UNIX based systems depend on their natively installed version of Python to run, well, almost everything. If Python is unavailable for just a moment, the developer loses the ability to use:</p><ul><li>vi</li><li>vim</li><li>nano</li><li>grep</li><li>source</li><li>wait, <em>SOURCE?</em></li></ul><p>Yep, the command you'd normally use to relaunch a corrupted startup file (such as the one that holds your <code>PATH</code> variable) is totally unusable. Not that it matters, what are you going to do, <em>edit it?</em> Oh right, you just ruined <em>every bash text editor. </em>I'd actually be more interested in seeing what DOES work without Python configuring on Mac/Linux, other than moving up and down your file structure helplessly, trying to quantify the damage you just wrecked upon your work, life, and career.</p><h3 id=\"so-should-i-kill-myself\">So, Should I Kill Myself?</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/nRrH6Gn.gif\" class=\"kg-image\"><figcaption>How to destroy everything ever.</figcaption></figure><p>Calm yourself and stick with me here; I have no interest in writing long-winded posts without providing any sort of solution. That said, I have no problem making you sit down and think about what you've done while I bother getting to the point. Nobody else has fixed this for you yet, and I need to improve my site's metrics, so it seems like we need each other on this one.</p><p>Besides, don't be so hard on yourself. Not even a week ago, I sat with a Senior Developer to review my development stack, and how that would fit into the current ecosystem of the department. Naturally I explained that I prefer running <strong>Flask</strong> on <strong>Python 3.7</strong>, as I adjusted my motorcycle jacket and sat forward to casually   extinguish a cigarette on his desk. Even through my vision was obstructed by the timelessly classic aviators resting on my face, I could see the letters roll across the terminal window before him as he typed. The poor bastard running a 4-year old Linux distribution had just checked if Python 3 was installed <strong>on his live production instance</strong>, when his fingertips unleashed the unmistakable <code>export PATH=...</code>, seconds away from linking CentOS' native Python from Python 2.7 to Python 3.7. My exact reaction was something along the lines of \"OH GOD NO DON'T DO THAT STOP HOLY MOTHER OF JESUS FUCK!\" </p><p>He stopped typing. The day was saved, and I was able to explain the importance of leaving native Python versions intact on the systems they come installed on. Then, I myself fucked up the Python path maybe an hour later. On production.  </p><p>We all do dumb things sometimes. That doesn't mean you're dumb. Well, except in my case, having done this countless times before. Some of us simply like to live dangerously. Fortune favors the bold, and so on.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/arNjoZz.gif\" class=\"kg-image\"><figcaption>Retro meme outta nowhere!</figcaption></figure><h2 id=\"getting-out-of-this-mess\">Getting out of this Mess</h2><p>Now that we've hit rock bottom, where do we go from here? Well, two things to keep in mind:</p><ol><li>Not <em>everything</em> is broken without Python. Extreme foreshadowing.</li><li>Restarting a terminal will automatically run all startup scripts.</li></ol><p>By now you know that <code>.bash_profile</code> and <code>.bashrc</code> are critically important to your system, considering how badly you've fucked things up just now. These files set important variables for your system every time you open your terminal; more specifically, <code>.bash_profile</code> kicks in on any sort of user log in (such as SSH) where <code>.bashrc</code> fires every time a new additional terminal window is opened. Even if your startup files are corrupted, the system will always love them and turn to them regardless of how horribly disfigured you left them. Talk about a spark of hope.</p><h3 id=\"on-mac-osx\">On Mac OSX</h3><p>I'll admit I'm a bit embarrassed at how long it took me to realize this: even though you ruined every text editor known to man, there's one resilient enough to hold strong. The name? <strong>TextEdit.</strong></p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ngA6gj0.gif\" class=\"kg-image\"><figcaption>Reveal hidden files in OSX easily.</figcaption></figure><p>In your root directory, a combo of  <code>Shift + Cmd + .</code> displays all hidden files. Check out bash_profile. Fix it, save it, reopen terminal. Cancel the suicide party. Pop the Champagne.</p><h3 id=\"on-linux\">On Linux</h3><p>No GUI can save us now, but what can? Perhaps a command so stupid, so simple, that it couldn't possibly need Python to work:</p><pre><code class=\"language-bash\">echo 'export PATH=&quot;/YOUR/ORIGINAL/PATH/2.7/bin:${PATH}&quot;' &gt;&gt; ~/.bash_profile\n</code></pre>\n<p>This <em>appends </em>the text you provide to the end of an existing file. <code>.bash_profile</code> and <code>.bashrc</code> both only pay attention to the last exported PATH in the document, which means the rest of your file will work, and the only PATH which is respected is the one which you've <em>presumably entered correctly this time around</em>. Restart your terminal. Get back in the game son: it ain't about how hard you hit, but how hard you can get hit and keep moving forward.</p><h2 id=\"sidenote\">Sidenote</h2><p>We're not exactly conducting rocket science here (data science is a close second perhaps? Just kidding. We barely know what's going on most of the time). I felt compelled to write this post for two reasons: one being how common and destructive this pitfall can be for most people, but more importantly, the knee-jerk reaction veterans have in response to this problem is \"good luck, you're fucked.\" </p><p>I'm not here to comment on the integrity of our fine anonymous internet communities, but the discrepancy between how devastating losing a server can be doesn't seem to met with much urgency by anybody with insight. Nobody taught me how to work around these issues. Had I listened to anonymous internet advice, I probably wouldn't let entire servers of sensitive data for dead, including my personal machines. I worked through it, and quite frankly, I'm <a href=\"https://hackersandslackers.com/about/\">kind of a <em>fucking idiot</em></a><em>, </em>as is our mission statement. If an idiot who majored in nonsense and learned a programming language before learning Linux can work through this, I would expect the same of those with much more intelligence than I to, at the very least, attempt the same.</p>","url":"https://hackersandslackers.com/so-youve-fucked-up-your-python-path/","uuid":"5de62a8f-94c9-4e70-8034-d46fb9369a73","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b97ad891fc1fc7d92b5c537"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736a9","title":"Connect to your Google Cloud Compute Engine","slug":"connect-to-your-google-cloud-eompute-engine","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/gcp_instance@2x.jpg","excerpt":"Configuring SSH and file transfers in Google Cloud.","custom_excerpt":"Configuring SSH and file transfers in Google Cloud.","created_at_pretty":"14 July, 2018","published_at_pretty":"05 September, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-07-14T10:10:50.000-04:00","published_at":"2018-09-05T08:00:00.000-04:00","updated_at":"2019-02-02T04:52:29.000-05:00","meta_title":"Configuring SSH and file transfers in Google Cloud | Hackers And Slackers","meta_description":"Now that you've joined the Google Cloud club, you may have found yourself asking the inevitable: \"how do I connect to my damn instance?\"","og_description":"Now that you've joined the Google Cloud club, you may have found yourself asking the inevitable: \"how do I connect to my damn instance?\"","og_image":"https://hackersandslackers.com/content/images/2018/07/gcp_instance@2x.jpg","og_title":"Connect to your Google Cloud Compute Engine","twitter_description":"Now that you've joined the Google Cloud club, you may have found yourself asking the inevitable: \"how do I connect to my damn instance?\"","twitter_image":"https://hackersandslackers.com/content/images/2018/07/gcp_instance@2x.jpg","twitter_title":"Connect to your Google Cloud Compute Engine","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"}],"plaintext":"So you've taken a leap and decided to host your VPS on Google Cloud: let me be\nthe first to congratulate you on joining the clearly superior cloud platform of\nour modern era. I would apologize for being so openly opinionated, but so far\nI've only stated objective facts.\n\nNow that you've joined the club, you may have found yourself asking the\ninevitable: \"how do I connect to my damn instance?\"  If you're like me, you're\nprobably not the kind of person who enjoys this as their main solution:\n\nGoogle Cloud's in-browser terminal.Luckily for us, there are a few ways to\ninteract with your Compute Engine. Let's take a look at all of them.\n\nSet up the gcloud CLI\nIn order to SSH natively, we need to install the gcloud CLI  on our machine. Mac\nusers can download this here\n[https://cloud.google.com/sdk/docs/quickstart-macos], and Windows users can\ndownload from here [https://cloud.google.com/sdk/docs/quickstart-windows].\nClicking the downloaded file will extract the package. With your package\nextracted, run the install script install.sh  (or install.bat  for Windows) to\nstart the installation:\n\n$ ~/Downloads/google-cloud-sdk/install.sh\nWelcome to the Google Cloud SDK!\n\nTo help improve the quality of this product, we collect anonymized usage data\nand anonymized stacktraces when crashes are encountered; additional information\nis available at <https://cloud.google.com/sdk/usage-statistics>. You may choose\nto opt out of this collection now (by choosing 'N' at the below prompt), or at\nany time in the future by running the following command:\n\n    gcloud config set disable_usage_reporting true\n\nDo you want to help improve the Google Cloud SDK (Y/n)?\n\n\nContinuing the script will list the 'components' gcloud can install on your\nlocal machine, where each component is a Google Cloud product:\n\nYour current Cloud SDK version is: 214.0.0\nThe latest available version is: 214.0.0\n\n┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n│                                                  Components                                                 │\n├───────────────┬──────────────────────────────────────────────────────┬──────────────────────────┬───────────┤\n│     Status    │                         Name                         │            ID            │    Size   │\n├───────────────┼──────────────────────────────────────────────────────┼──────────────────────────┼───────────┤\n│ Not Installed │ App Engine Go Extensions                             │ app-engine-go            │ 152.8 MiB │\n│ Not Installed │ Cloud Bigtable Command Line Tool                     │ cbt                      │   6.3 MiB │\n│ Not Installed │ Cloud Bigtable Emulator                              │ bigtable                 │   4.3 MiB │\n│ Not Installed │ Cloud Datalab Command Line Tool                      │ datalab                  │   < 1 MiB │\n│ Not Installed │ Cloud Datastore Emulator                             │ cloud-datastore-emulator │  17.7 MiB │\n│ Not Installed │ Cloud Datastore Emulator (Legacy)                    │ gcd-emulator             │  38.1 MiB │\n│ Not Installed │ Cloud Pub/Sub Emulator                               │ pubsub-emulator          │  33.4 MiB │\n│ Not Installed │ Cloud SQL Proxy                                      │ cloud_sql_proxy          │   2.5 MiB │\n│ Not Installed │ Emulator Reverse Proxy                               │ emulator-reverse-proxy   │  14.5 MiB │\n│ Not Installed │ Google Cloud Build Local Builder                     │ cloud-build-local        │   4.4 MiB │\n│ Not Installed │ Google Container Local Builder                       │ container-builder-local  │   4.4 MiB │\n│ Not Installed │ Google Container Registry's Docker credential helper │ docker-credential-gcr    │   1.8 MiB │\n│ Not Installed │ gcloud Alpha Commands                                │ alpha                    │   < 1 MiB │\n│ Not Installed │ gcloud Beta Commands                                 │ beta                     │   < 1 MiB │\n│ Not Installed │ gcloud app Java Extensions                           │ app-engine-java          │ 118.6 MiB │\n│ Not Installed │ gcloud app PHP Extensions                            │ app-engine-php           │  21.9 MiB │\n│ Not Installed │ gcloud app Python Extensions                         │ app-engine-python        │   6.2 MiB │\n│ Not Installed │ gcloud app Python Extensions (Extra Libraries)       │ app-engine-python-extras │  28.5 MiB │\n│ Not Installed │ kubectl                                              │ kubectl                  │   < 1 MiB │\n│ Installed     │ BigQuery Command Line Tool                           │ bq                       │   < 1 MiB │\n│ Installed     │ Cloud SDK Core Libraries                             │ core                     │   8.3 MiB │\n│ Installed     │ Cloud Storage Command Line Tool                      │ gsutil                   │   3.6 MiB │\n└───────────────┴──────────────────────────────────────────────────────┴──────────────────────────┴───────────┘\nTo install or remove components at your current SDK version [214.0.0], run:\n  $ gcloud components install COMPONENT_ID\n  $ gcloud components remove COMPONENT_ID\n\nTo update your SDK installation to the latest version [214.0.0], run:\n  $ gcloud components update\n\n\nModify profile to update your $PATH and enable shell command\ncompletion?\n\nDo you want to continue (Y/n)?\n\n\nOnce installed, run gcloud init  in your terminal. This will prompt you to\nlogin:\n\nTo continue, you must log in. Would you like to log in (Y/n)?\n\n\nPressing 'Y' will prompt a simple browser window from which you can authenticate\nwith Google by simply selecting your Google account, as though we were using any\nother app with Google OAuth authentication. That's correct: you don't even need\nto go through the trouble of typing a password, assuming you've logged in to\nyour Google account before (I'm guessing you have).\n\n2ez authentication.Next, the terminal will prompt to specify which of your\nprojects to use. Select the project which contains your instance by entering the\nnumber seen in the resulting list:\n\nPick cloud project to use:\n [1] [my-project-1]\n [2] [my-project-2]\n ...\n Please enter your numeric choice:\n\n\nNow you're in the clear to go nuts with the gcloud  CLI:\n\ngcloud has now been configured!\nYou can use [gcloud config] to change more gcloud settings.\n\nYour active configuration is: [default]\n\n\nSSH via a Native Terminal\nUgh, so now we need to go through the process of creating public and private\nkeys etc to SSH into our instance, right? Wrong: gcloud  is so mo effin' dope\nthat there's a one-line command which will actually do this for you:\n\n$ gcloud compute config-ssh\n\nYou should now be able to use ssh/scp with your instances.\nFor example, try running:\n\n$ ssh instancename.region-b.projectname-173869\n\n\nBut there's no way it's that easy, right?\n\n$ gcloud compute ssh instancename\nEnter passphrase for key '/Users/username/.ssh/google_compute_engine':\n\nWelcome to Ubuntu 16.04.4 LTS (GNU/Linux 4.15.0-1018-gcp x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/advantage\n\n  Get cloud support with Ubuntu Advantage Cloud Guest:\n    http://www.ubuntu.com/business/services/cloud\n\n30 packages can be updated.\n0 updates are security updates.\n\n\nIt really is that easy. For as long as you use your local machine, you will only\never need to used the command gcloud compute ssh instancename  to connect to\nyour instance.\n\nGet and Put Files\nYou might be thinking that the next order of business would be to config SFTP in\norder to manage files on your instance. Believe it or not, there's a simpler\nway.\n\nDownloading Files from your Instance\ngcloud  comes with a built-in tool to download and upload files to your instance\nvia the CLI. To download files from your server, check out this one-liner:\n\ngcloud compute scp [LOCAL_FILE_PATH] [INSTANCE_NAME]:~/path/to/file/on/server\n\n\nUploading Files to your Instance\nThe same command can be reversed to upload as well:\n\ngcloud compute scp --recurse [INSTANCE_NAME]:[REMOTE_DIR] [LOCAL_DIR]\n\n\nOther Methods\nWhen we begin to look into other methods of interacting with our Computer Engine\ninstance, the general youth of GCP becomes apparent.\n\nAt the time of writing, Google's own documentation lacks information on how to\nconnect via SFTP, as the only mention of SFTP is this broken anchor link. Google\nalso provides a RDP  Chrome add-on\n[https://chrome.google.com/webstore/detail/chrome-rdp-for-google-clo/mpbbnannobiobpnfblimoapbephgifkm/] \n specifically for connecting to Compute instances, but my own attempts have\nshown this to be broken as well:\n\nWhy can't I click on you?!?!Despite these setbacks, the combination of SSH and\ngetting/putting files should be more than enough to satisfy anybody's needs for\nnow. Google Cloud Platform is only getting better with time, and is doing so at\na pace which scare other providers.","html":"<p>So you've taken a leap and decided to host your VPS on Google Cloud: let me be the first to congratulate you on joining the clearly superior cloud platform of our modern era. I would apologize for being so openly opinionated, but so far I've only stated objective facts.</p><p>Now that you've joined the club, you may have found yourself asking the inevitable: \"<em>how do I connect to my damn instance?\"</em> If you're like me, you're probably not the kind of person who enjoys this as their main solution:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ssh.gif\" class=\"kg-image\"><figcaption>Google Cloud's in-browser terminal.</figcaption></figure><p>Luckily for us, there are a few ways to interact with your Compute Engine. Let's take a look at all of them.</p><h2 id=\"set-up-the-gcloud-cli\">Set up the gcloud CLI</h2><p>In order to SSH natively, we need to install the <strong>gcloud CLI</strong> on our machine. Mac users can download this <a href=\"https://cloud.google.com/sdk/docs/quickstart-macos\">here</a>, and Windows users can download from <a href=\"https://cloud.google.com/sdk/docs/quickstart-windows\">here</a>. Clicking the downloaded file will extract the package. With your package extracted, run the install script <code>install.sh</code> (or <code>install.bat</code> for Windows) to start the installation:</p><pre><code class=\"language-bash\">$ ~/Downloads/google-cloud-sdk/install.sh\nWelcome to the Google Cloud SDK!\n\nTo help improve the quality of this product, we collect anonymized usage data\nand anonymized stacktraces when crashes are encountered; additional information\nis available at &lt;https://cloud.google.com/sdk/usage-statistics&gt;. You may choose\nto opt out of this collection now (by choosing 'N' at the below prompt), or at\nany time in the future by running the following command:\n\n    gcloud config set disable_usage_reporting true\n\nDo you want to help improve the Google Cloud SDK (Y/n)?\n</code></pre>\n<p>Continuing the script will list the 'components' gcloud can install on your local machine, where each component is a Google Cloud product:</p><pre><code class=\"language-bash\">Your current Cloud SDK version is: 214.0.0\nThe latest available version is: 214.0.0\n\n┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n│                                                  Components                                                 │\n├───────────────┬──────────────────────────────────────────────────────┬──────────────────────────┬───────────┤\n│     Status    │                         Name                         │            ID            │    Size   │\n├───────────────┼──────────────────────────────────────────────────────┼──────────────────────────┼───────────┤\n│ Not Installed │ App Engine Go Extensions                             │ app-engine-go            │ 152.8 MiB │\n│ Not Installed │ Cloud Bigtable Command Line Tool                     │ cbt                      │   6.3 MiB │\n│ Not Installed │ Cloud Bigtable Emulator                              │ bigtable                 │   4.3 MiB │\n│ Not Installed │ Cloud Datalab Command Line Tool                      │ datalab                  │   &lt; 1 MiB │\n│ Not Installed │ Cloud Datastore Emulator                             │ cloud-datastore-emulator │  17.7 MiB │\n│ Not Installed │ Cloud Datastore Emulator (Legacy)                    │ gcd-emulator             │  38.1 MiB │\n│ Not Installed │ Cloud Pub/Sub Emulator                               │ pubsub-emulator          │  33.4 MiB │\n│ Not Installed │ Cloud SQL Proxy                                      │ cloud_sql_proxy          │   2.5 MiB │\n│ Not Installed │ Emulator Reverse Proxy                               │ emulator-reverse-proxy   │  14.5 MiB │\n│ Not Installed │ Google Cloud Build Local Builder                     │ cloud-build-local        │   4.4 MiB │\n│ Not Installed │ Google Container Local Builder                       │ container-builder-local  │   4.4 MiB │\n│ Not Installed │ Google Container Registry's Docker credential helper │ docker-credential-gcr    │   1.8 MiB │\n│ Not Installed │ gcloud Alpha Commands                                │ alpha                    │   &lt; 1 MiB │\n│ Not Installed │ gcloud Beta Commands                                 │ beta                     │   &lt; 1 MiB │\n│ Not Installed │ gcloud app Java Extensions                           │ app-engine-java          │ 118.6 MiB │\n│ Not Installed │ gcloud app PHP Extensions                            │ app-engine-php           │  21.9 MiB │\n│ Not Installed │ gcloud app Python Extensions                         │ app-engine-python        │   6.2 MiB │\n│ Not Installed │ gcloud app Python Extensions (Extra Libraries)       │ app-engine-python-extras │  28.5 MiB │\n│ Not Installed │ kubectl                                              │ kubectl                  │   &lt; 1 MiB │\n│ Installed     │ BigQuery Command Line Tool                           │ bq                       │   &lt; 1 MiB │\n│ Installed     │ Cloud SDK Core Libraries                             │ core                     │   8.3 MiB │\n│ Installed     │ Cloud Storage Command Line Tool                      │ gsutil                   │   3.6 MiB │\n└───────────────┴──────────────────────────────────────────────────────┴──────────────────────────┴───────────┘\nTo install or remove components at your current SDK version [214.0.0], run:\n  $ gcloud components install COMPONENT_ID\n  $ gcloud components remove COMPONENT_ID\n\nTo update your SDK installation to the latest version [214.0.0], run:\n  $ gcloud components update\n\n\nModify profile to update your $PATH and enable shell command\ncompletion?\n\nDo you want to continue (Y/n)?\n</code></pre>\n<p>Once installed, run <code>gcloud init</code> in your terminal. This will prompt you to login:</p><pre><code class=\"language-bash\">To continue, you must log in. Would you like to log in (Y/n)?\n</code></pre>\n<p>Pressing 'Y' will prompt a simple browser window from which you can authenticate with Google by simply selecting your Google account, as though we were using any other app with Google OAuth authentication. That's correct: you don't even need to go through the trouble of typing a password, assuming you've logged in to your Google account before (I'm guessing you have).</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-09-04-at-3.36.26-PM.png\" class=\"kg-image\"><figcaption>2ez authentication.</figcaption></figure><p>Next, the terminal will prompt to specify which of your projects to use. Select the project which contains your instance by entering the number seen in the resulting list:</p><pre><code class=\"language-bash\">Pick cloud project to use:\n [1] [my-project-1]\n [2] [my-project-2]\n ...\n Please enter your numeric choice:\n</code></pre>\n<p>Now you're in the clear to go nuts with the <strong>gcloud</strong> CLI:</p><pre><code class=\"language-bash\">gcloud has now been configured!\nYou can use [gcloud config] to change more gcloud settings.\n\nYour active configuration is: [default]\n</code></pre>\n<h2 id=\"ssh-via-a-native-terminal\">SSH via a Native Terminal</h2><p>Ugh, so now we need to go through the process of creating public and private keys etc to SSH into our instance, right? Wrong: <strong>gcloud</strong> is so mo effin' dope that there's a one-line command which will actually do this for you:</p><pre><code class=\"language-bash\">$ gcloud compute config-ssh\n\nYou should now be able to use ssh/scp with your instances.\nFor example, try running:\n\n$ ssh instancename.region-b.projectname-173869\n</code></pre>\n<p>But there's no way it's that easy, right?</p><pre><code class=\"language-bash\">$ gcloud compute ssh instancename\nEnter passphrase for key '/Users/username/.ssh/google_compute_engine':\n\nWelcome to Ubuntu 16.04.4 LTS (GNU/Linux 4.15.0-1018-gcp x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/advantage\n\n  Get cloud support with Ubuntu Advantage Cloud Guest:\n    http://www.ubuntu.com/business/services/cloud\n\n30 packages can be updated.\n0 updates are security updates.\n</code></pre>\n<p>It really is that easy. For as long as you use your local machine, you will only ever need to used the command <code>gcloud compute ssh instancename</code> to connect to your instance.</p><h2 id=\"get-and-put-files\">Get and Put Files</h2><p>You might be thinking that the next order of business would be to config SFTP in order to manage files on your instance. Believe it or not, there's a simpler way.</p><h3 id=\"downloading-files-from-your-instance\">Downloading Files from your Instance</h3><p><strong>gcloud</strong> comes with a built-in tool to download and upload files to your instance via the CLI. To download files from your server, check out this one-liner:</p><pre><code class=\"language-bash\">gcloud compute scp [LOCAL_FILE_PATH] [INSTANCE_NAME]:~/path/to/file/on/server\n</code></pre>\n<h3 id=\"uploading-files-to-your-instance\">Uploading Files to your Instance</h3><p>The same command can be reversed to upload as well:</p><pre><code class=\"language-bash\">gcloud compute scp --recurse [INSTANCE_NAME]:[REMOTE_DIR] [LOCAL_DIR]\n</code></pre>\n<h2 id=\"other-methods\">Other Methods</h2><p>When we begin to look into other methods of interacting with our Computer Engine instance, the general youth of GCP becomes apparent.</p><p>At the time of writing, Google's own documentation lacks information on how to connect via <strong>SFTP, </strong>as the only mention of SFTP is this <a href=\"https://cloud.google.com/compute/docs/instances/transfer-files#filebrowser\">broken anchor link</a>. Google also provides a <strong>RDP</strong> <a href=\"https://chrome.google.com/webstore/detail/chrome-rdp-for-google-clo/mpbbnannobiobpnfblimoapbephgifkm/\">Chrome add-on</a> specifically for connecting to Compute instances, but my own attempts have shown this to be broken as well:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/rdp.png\" class=\"kg-image\"><figcaption>Why can't I click on you?!?!</figcaption></figure><p>Despite these setbacks, the combination of SSH and getting/putting files should be more than enough to satisfy anybody's needs for now. Google Cloud Platform is only getting better with time, and is doing so at a pace which scare other providers.</p>","url":"https://hackersandslackers.com/connect-to-your-google-cloud-eompute-engine/","uuid":"774f9ff4-8fe2-4951-b240-5de2f80bc266","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b4a046a1c20005e9422c102"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736d2","title":"Recreate JIRA Service Desk in Python & Flask","slug":"building-a-better-jira","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/jsd@2x.jpg","excerpt":"When SaaS doesn't cut it, beat it down and take everything its got.","custom_excerpt":"When SaaS doesn't cut it, beat it down and take everything its got.","created_at_pretty":"11 August, 2018","published_at_pretty":"31 August, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-08-11T14:02:52.000-04:00","published_at":"2018-08-31T10:25:00.000-04:00","updated_at":"2019-02-02T05:11:05.000-05:00","meta_title":"When SaaS doesn't cut it, beat it down and take everything its got | Hackers And Slackers","meta_description":"Vanilla helpdesks tend to dehumanize customers. We all think we're special, but a cold support queue reminds us otherwise. We can build something  better.","og_description":"Vanilla helpdesks tend to dehumanize customers. We all think we're special, but a cold support queue reminds us otherwise. We can build something  better.","og_image":"https://hackersandslackers.com/content/images/2018/08/jsd@2x.jpg","og_title":"Recreate JIRA Service Desk in Python & Flask","twitter_description":"Vanilla helpdesks tend to dehumanize customers. We all think we're special, but a cold support queue reminds us otherwise. We can build something  better.","twitter_image":"https://hackersandslackers.com/content/images/2018/08/jsd@2x.jpg","twitter_title":"Recreate JIRA Service Desk in Python & Flask","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"}],"plaintext":"When it comes to SaaS products in the realm of Service desks, JIRA Service Desk\nis at the very least, just as powerful as the next solution (Zendesk comes to\nmind). This naturally begs the question: Why is JIRA Service Desk's pricing\nmodel roughly 1/10th of that of it's competitor?\n\nThe answer lies within ease of use,  but more importantly, presentation. While\nAtlassian's cloud offering is slowly playing catchup, Atlassian as a company has\nnever quite seemed to nail down the importance of a friendly user interface, nor\nthe importance of this when it comes to worldwide adoption. To see what I mean,\nhere's an example that Atlassian themselves tout on their own documentation as a\n\"ready for production\" customer portal:\n\nI'm convinced this is purposefully hideous to force the purchase of plugins.To\nyour average software developer (Atlassian's core demographic for years), one\nmight see nothing wrong with this interface, but as somebody `who has rolled out\nover 30 of these desks for over 6 thousand people, layouts such as these commit\nnumerous UI atrocities which simply are not acceptable for top enterprise\nsoftware.\n\nWhat do we do about this? We build an alternative, of course.\n\nMethod to This Madness\nOur focus is not on JIRA as a product,  but rather an API. Instead of attempting\nto work within JIRA’s boundaries via customization or add-ons, we can take\nmatters into our own hands by owning the application that users use to interact\nwith a JIRA instance. By using the JIRA API, we can not only extend features but\nactually ‘rebuild’ the application to gain full control over the UI or\nadditional logic. JIRA is a hideous yet entirely necessary Java application,\nwhich makes it a perfect candidate for recreation.\n\nWe're going to use Flask for this. Shocking, I know. Here's the obligatory file\nstructure of our project:\n\nmyproject\n├─ app.py\n├─ jira.py\n├─ /static\n│  └─ js\n│  └─ less\n│  └─ img\n└─ /templates\n   └─ layout.html\n   └─ index.html\n\n\nThis tutorial will be working against the JIRA Server  API for Service Desk -\nthat said, Cloud users should still find this applicable.\n\nPulling Your Service Desk Form\nBefore we get nuts building our application, we’ll need to be sure that a\nService Desk already exists in JIRA with our expected intake form. Remember: our\nend goal is to simply consume JIRA as an API, but that entails interacting with\nsomething that exists in the first place.\n\nWith your Service Desk created, there’s one annoyance we need to resolve before\ngetting into code: determining your Service Desk’s ID number. Like most things\nin JIRA, Service Desks are identified by an ID which is simply an arbitrary\ngrouping of integers in some way. What is the official way to find this ID, you\nmight ask? Why, by extracting it from the portal’s URL or by inspecting your XHR\nrequests, of course! Remember: JIRA hates you, that’s why we’re doing this in\nthe first place.\n\nWith your Service Desk ID handy, we can finally break into retrieving our desk\nvia the Service Desk API:\n\nimport requests\nfrom jira_config import jira_username, jira_password\n\nrequest_types_endpoint = \"https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/\"\n\nheaders = {'Content-Type': 'application/json'}\n\ndef fieldsPerRequest(id):\n    \"\"\"Get form fields per request type.\"\"\"\n    r = requests.get(request_types_endpoint + id + '/field', auth=(jira_username, jira_password), headers=headers)\n    form = r.json()\n    return form\n\n\ndef serviceDeskRequestTypes():\n    \"\"\"Get request types.\"\"\"\n    request_array = []\n    r = requests.get(request_types_endpoint, auth=(jira_username, jira_password), headers=headers)\n    for requesttype in r.json()['values']:\n        id = requesttype['id']\n        request_dict = {\n            'name': requesttype['name'],\n            'description': requesttype['description'],\n            'icon': requesttype['icon']['_links']['iconUrls']['32x32'],\n            'fields': fieldsPerRequest(id)\n        }\n        request_array.append(request_dict)\n    return request_array\n\n\nserviceDeskRequestTypes()\nBy using the request_types_endpoint  URL, our function serviceDeskRequestTypes() \n returns the request types  of a given JIRA service desk; or in other words, the\n types of requests users can submit.  This alone only gives us high-level\ninformation about the types of requests we allow but doesn't go into further\ndetail such as the actual resulting form. That's where our next function comes\nin.\n\nfieldsPerRequest()\nThis function gets passed the ID of each request type. With that, we extend our\nendpoint to look like \n'https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/[REQUESTID]/field'\n. Looping through each request type gives up exactly what we need: every request\ntype and every form field per request type.\n\nuserSession()\nThere's another thing left to consider: what if the user isn't currently logged\nin to JIRA? At the very least, we need to check to see if a JIRA session is\nactive:\n\nuser_session_endpoint = 'https://jira.we.co/rest/auth/1/session'\n\ndef getUserSession():\n    \"\"\"Get logged-in user.\"\"\"\n    r = requests.get(user_session_endpoint, headers=headers)\n    if r.status_code == 200:\n        return r.json()\n    else:\n        return False\n\n\nIf the user is logged in to JIRA, we'll receive a 200 code letting us know\neverything is alright. The body of the response will also contain the name of\nthe user plus some extra metadata. What if the user isn't  logged in? Let's get\nto that in a bit.\n\nEasy Routing\nOur view will be nice and simple:\n\nfrom jira import request_forms, user_details\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    \"\"\"Landing page.\"\"\"\n    if user_details == False:\n        return redirect('https://example.com')\n    else:\n        return render_template('/index.html', requests=request_forms)\n\n\nNotice that all we're doing is making sure the user is signed in to JIRA. But\nwhat's with the example.com, you ask? Well, because I'm leaving this part up to\nyou, dear friend. There's really a number of things we can do, but it depends\nentirely on your situation. For instance:\n\n * You can handle basic auth on your own\n * Register an OAuth application to handle sign-ins (perhaps the most robust\n   solution)\n * If your JIRA instance is behind SSO, you may want to send users to your\n   company's  SAML partner\n * Simply throw an error message\n\nWhatever you decide to do, it's not really my problem. Obligatory smiley face\nemoji :).\n\nThe Template\nRemember: the main reason most of you are probably doing this is to control the\npresentation layer as you see fit. That said, here comes a call of presentation\nlayer text, in the form of a Jinja template:\n\n{% block form %}\n  <div>\n    <h3 class=\"subtitle\">Submit new requests here</h3>\n    <ul class=\"collapsible\">\n      {% for request in requests %}\n      <li class=\"{{request.name}}\">\n        <div class=\"collapsible-header\">\n          <img src=\"{{request.icon}}\">\n          <div class=\"info\">\n            <h5>{{request.name}}</h5>\n            <p>{{request.description}}</p>\n          </div>\n        </div>\n        <div class=\"collapsible-body\">\n          <div class=\"row\">\n            <form method=\"post\">\n              <div>\n                {% for field in request.fields.requestTypeFields %}\n                  {% if field.name in ('Category', 'Product') %}\n                    <div class=\"input-field\">\n                      <select id=\"{{request.name}} {{field.name}}\">\n                        <option value=\"Choose your option\" disabled selected>Choose your option</option>\n                        {% for option in field.validValues %}\n                          <option value=\"{{option.label}}\">{{option.label}}</option>\n                        {% endfor %}\n                      </select>\n                      <label>{{field.name}}</label>\n                    </div>\n                  {% elif field.name == 'Description' %}\n                    <div class=\"input-field\">\n                      <textarea id=\"{{field.name}}\" class=\"materialize-textarea\" placeholder=\"{{field.description}}\"></textarea>\n                      <label for=\"{{request.name}} {{field.name}}\">{{field.name}}</label>\n                    </div>\n                  {% else %}\n                    <div class=\"input-field\">\n                      <input placeholder=\"{{field.description}}\" id=\"{{request.name}} {{field.name}}\" type=\"text\" class=\"validate\">\n                      <label for=\"{{request.name}} {{field.name}}\">{{field.name}}</label>\n                    </div>\n                  {% endif %}\n                {% endfor %}\n                <input type=\"button\" value=\"Submit\" class=\"btn cyan lighten-3 formsubmit\">\n              </div>\n            </form>\n          </div>\n        </div>\n      </li>\n      {% endfor %}\n    </ul>\n  </div>\n{% endblock %}\n\n\nBecause we passed the Service Desk JSON we extracted from the JIRA API to our\nform, we can go crazy setting our labels, placeholder text, or whatever,\nanywhere we please. In my example, I utilize Material Design\n[https://materializecss.com/]'s pretty package of pre-made frontend elements,\nbecause God knows nobody wants to deal with designing that shit. Sorry, I was\njust having a brief flashback to Frontend dev.\n\nThe code above explicitly looks for fields we know are dropdowns, so that we may\nfill the select options accordingly. Same goes for textarea fields. That said,\nthe way I've handled this above is, well, stupid. Instead of hardcoding if\nstatements to look for certain fields, leverage our JSON to determine the type\nof each field as you iterate over them. Do as I say, not as I do.\n\nGoing Further\nThere's so much more we can add here. Take a list of the user's opened tickets,\nfor instance. The great thing about controlling your own portal UI is that you\ncan now control the narrative of your own workload: perhaps the person in\nmarketing who started 2 weeks ago could benefit from seeing the 200 tickets\nbeing addressed before her, thus second-guessing the urge to type URGENT across\na subject line only to be violently shoved down your throat.\n\nIn all seriousness, nobody likes the experience of a vanilla helpdesk because it\ndehumanizes the customer. While our personal beliefs reassure us that we are\nspecial, entering a cold support queue is a stark suggestion that we may not be\nso special after all, which isn't exactly a fact Millennials or Executives like\nto ponder on. If nothing else, take this as a chance to build software friendly\ntowards humans with full transparency, and both parties will surely benefit.\nRemember: happy humans bides times for the inevitable robot revolution on the\nhorizon destined to eradicate mankind. Do your part!","html":"<p>When it comes to SaaS products in the realm of Service desks, JIRA Service Desk is at the very <em>least</em>, just as powerful as the next solution (Zendesk comes to mind). This naturally begs the question: Why is JIRA Service Desk's pricing model roughly 1/10th of that of it's competitor?</p><p>The answer lies within <em>ease of use,</em> but more importantly, <em>presentation</em>. While Atlassian's cloud offering is slowly playing catchup, Atlassian as a company has never quite seemed to nail down the importance of a friendly user interface, nor the importance of this when it comes to worldwide adoption. To see what I mean, here's an example that Atlassian themselves tout on their own documentation as a \"ready for production\" customer portal:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/customer-portal.png\" class=\"kg-image\"><figcaption>I'm convinced this is purposefully hideous to force the purchase of plugins.</figcaption></figure><p>To your average software developer (Atlassian's core demographic for years), one might see nothing wrong with this interface, but as somebody `who has rolled out over 30 of these desks for over 6 thousand people, layouts such as these commit numerous UI atrocities which simply are not acceptable for top enterprise software.</p><p>What do we do about this? We build an alternative, of course.</p><h2 id=\"method-to-this-madness\">Method to This Madness</h2><p>Our focus is not on JIRA as a <em>product,</em> but rather an <em>API. </em>Instead of attempting to work within JIRA’s boundaries via customization or add-ons, we can take matters into our own hands by owning the application that users use to interact with a JIRA instance. By using the JIRA API, we can not only extend features but actually ‘rebuild’ the application to gain full control over the UI or additional logic. JIRA is a hideous yet entirely necessary Java application, which makes it a perfect candidate for recreation.</p><p>We're going to use Flask for this. Shocking, I know. Here's the obligatory file structure of our project:</p><pre><code class=\"language-bash\">myproject\n├─ app.py\n├─ jira.py\n├─ /static\n│  └─ js\n│  └─ less\n│  └─ img\n└─ /templates\n   └─ layout.html\n   └─ index.html\n</code></pre>\n<p>This tutorial will be working against the JIRA <em>Server</em> API for Service Desk - that said, Cloud users should still find this applicable.</p><h2 id=\"pulling-your-service-desk-form\">Pulling Your Service Desk Form</h2><p>Before we get nuts building our application, we’ll need to be sure that a Service Desk already exists in JIRA with our expected intake form. Remember: our end goal is to simply consume JIRA as an API, but that entails interacting with something that exists in the first place.</p><p>With your Service Desk created, there’s one annoyance we need to resolve before getting into code: determining your Service Desk’s ID number. Like most things in JIRA, Service Desks are identified by an ID which is simply an arbitrary grouping of integers in some way. What is the official way to find this ID, you might ask? Why, by extracting it from the portal’s URL or by inspecting your XHR requests, of course! Remember: JIRA hates you, that’s why we’re doing this in the first place.</p><p>With your Service Desk ID handy, we can finally break into retrieving our desk via the Service Desk API:</p><pre><code class=\"language-python\">import requests\nfrom jira_config import jira_username, jira_password\n\nrequest_types_endpoint = &quot;https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/&quot;\n\nheaders = {'Content-Type': 'application/json'}\n\ndef fieldsPerRequest(id):\n    &quot;&quot;&quot;Get form fields per request type.&quot;&quot;&quot;\n    r = requests.get(request_types_endpoint + id + '/field', auth=(jira_username, jira_password), headers=headers)\n    form = r.json()\n    return form\n\n\ndef serviceDeskRequestTypes():\n    &quot;&quot;&quot;Get request types.&quot;&quot;&quot;\n    request_array = []\n    r = requests.get(request_types_endpoint, auth=(jira_username, jira_password), headers=headers)\n    for requesttype in r.json()['values']:\n        id = requesttype['id']\n        request_dict = {\n            'name': requesttype['name'],\n            'description': requesttype['description'],\n            'icon': requesttype['icon']['_links']['iconUrls']['32x32'],\n            'fields': fieldsPerRequest(id)\n        }\n        request_array.append(request_dict)\n    return request_array\n</code></pre>\n<h3 id=\"servicedeskrequesttypes-\">serviceDeskRequestTypes()</h3><p>By using the <em>request_types_endpoint</em> URL, our function <code>serviceDeskRequestTypes()</code> returns the <strong>request types</strong> of a given JIRA service desk; or in other words, the <em>types of requests users can submit.</em> This alone only gives us high-level information about the types of requests we allow but doesn't go into further detail such as the actual resulting form. That's where our next function comes in.</p><h3 id=\"fieldsperrequest-\">fieldsPerRequest()</h3><p>This function gets passed the ID of each request type. With that, we extend our endpoint to look like <code>'https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/[REQUESTID]/field'</code>. Looping through each request type gives up exactly what we need: every request type and every form field per request type.</p><h3 id=\"usersession-\">userSession()</h3><p>There's another thing left to consider: what if the user isn't currently logged in to JIRA? At the very least, we need to check to see if a JIRA session is active:</p><pre><code class=\"language-python\">user_session_endpoint = 'https://jira.we.co/rest/auth/1/session'\n\ndef getUserSession():\n    &quot;&quot;&quot;Get logged-in user.&quot;&quot;&quot;\n    r = requests.get(user_session_endpoint, headers=headers)\n    if r.status_code == 200:\n        return r.json()\n    else:\n        return False\n</code></pre>\n<p>If the user is logged in to JIRA, we'll receive a 200 code letting us know everything is alright. The body of the response will also contain the name of the user plus some extra metadata. What if the user <em>isn't</em> logged in? Let's get to that in a bit.</p><h2 id=\"easy-routing\">Easy Routing</h2><p>Our view will be nice and simple:</p><pre><code class=\"language-python\">from jira import request_forms, user_details\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    &quot;&quot;&quot;Landing page.&quot;&quot;&quot;\n    if user_details == False:\n        return redirect('https://example.com')\n    else:\n        return render_template('/index.html', requests=request_forms)\n</code></pre>\n<p>Notice that all we're doing is making sure the user is signed in to JIRA. But what's with the <em>example.com</em>, you ask? Well, because I'm leaving this part up to you, dear friend. There's really a number of things we can do, but it depends entirely on your situation. For instance:</p><ul><li>You can handle basic auth on your own</li><li>Register an OAuth application to handle sign-ins (perhaps the most robust solution)</li><li>If your JIRA instance is behind SSO, you may want to send users to your company's  SAML partner</li><li>Simply throw an error message</li></ul><p>Whatever you decide to do, it's not really my problem. Obligatory smiley face emoji :).</p><h2 id=\"the-template\">The Template</h2><p>Remember: the main reason most of you are probably doing this is to control the presentation layer as you see fit. That said, here comes a call of presentation layer text, in the form of a Jinja template:</p><pre><code class=\"language-jinja\">{% block form %}\n  &lt;div&gt;\n    &lt;h3 class=&quot;subtitle&quot;&gt;Submit new requests here&lt;/h3&gt;\n    &lt;ul class=&quot;collapsible&quot;&gt;\n      {% for request in requests %}\n      &lt;li class=&quot;{{request.name}}&quot;&gt;\n        &lt;div class=&quot;collapsible-header&quot;&gt;\n          &lt;img src=&quot;{{request.icon}}&quot;&gt;\n          &lt;div class=&quot;info&quot;&gt;\n            &lt;h5&gt;{{request.name}}&lt;/h5&gt;\n            &lt;p&gt;{{request.description}}&lt;/p&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div class=&quot;collapsible-body&quot;&gt;\n          &lt;div class=&quot;row&quot;&gt;\n            &lt;form method=&quot;post&quot;&gt;\n              &lt;div&gt;\n                {% for field in request.fields.requestTypeFields %}\n                  {% if field.name in ('Category', 'Product') %}\n                    &lt;div class=&quot;input-field&quot;&gt;\n                      &lt;select id=&quot;{{request.name}} {{field.name}}&quot;&gt;\n                        &lt;option value=&quot;Choose your option&quot; disabled selected&gt;Choose your option&lt;/option&gt;\n                        {% for option in field.validValues %}\n                          &lt;option value=&quot;{{option.label}}&quot;&gt;{{option.label}}&lt;/option&gt;\n                        {% endfor %}\n                      &lt;/select&gt;\n                      &lt;label&gt;{{field.name}}&lt;/label&gt;\n                    &lt;/div&gt;\n                  {% elif field.name == 'Description' %}\n                    &lt;div class=&quot;input-field&quot;&gt;\n                      &lt;textarea id=&quot;{{field.name}}&quot; class=&quot;materialize-textarea&quot; placeholder=&quot;{{field.description}}&quot;&gt;&lt;/textarea&gt;\n                      &lt;label for=&quot;{{request.name}} {{field.name}}&quot;&gt;{{field.name}}&lt;/label&gt;\n                    &lt;/div&gt;\n                  {% else %}\n                    &lt;div class=&quot;input-field&quot;&gt;\n                      &lt;input placeholder=&quot;{{field.description}}&quot; id=&quot;{{request.name}} {{field.name}}&quot; type=&quot;text&quot; class=&quot;validate&quot;&gt;\n                      &lt;label for=&quot;{{request.name}} {{field.name}}&quot;&gt;{{field.name}}&lt;/label&gt;\n                    &lt;/div&gt;\n                  {% endif %}\n                {% endfor %}\n                &lt;input type=&quot;button&quot; value=&quot;Submit&quot; class=&quot;btn cyan lighten-3 formsubmit&quot;&gt;\n              &lt;/div&gt;\n            &lt;/form&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/li&gt;\n      {% endfor %}\n    &lt;/ul&gt;\n  &lt;/div&gt;\n{% endblock %}\n</code></pre>\n<p>Because we passed the Service Desk JSON we extracted from the JIRA API to our form, we can go crazy setting our labels, placeholder text, or whatever, anywhere we please. In my example, I utilize <a href=\"https://materializecss.com/\">Material Design</a>'s pretty package of pre-made frontend elements, because God knows nobody wants to deal with designing that shit. Sorry, I was just having a brief flashback to Frontend dev.</p><p>The code above explicitly looks for fields we know are dropdowns, so that we may fill the select options accordingly. Same goes for textarea fields. That said, the way I've handled this above is, well, stupid. Instead of hardcoding if statements to look for certain fields, leverage our JSON to determine the type of each field as you iterate over them. Do as I say, not as I do.</p><h2 id=\"going-further\">Going Further</h2><p>There's so much more we can add here. Take a list of the user's opened tickets, for instance. The great thing about controlling your own portal UI is that you can now control the narrative of your own workload: perhaps the person in marketing who started 2 weeks ago could benefit from seeing the 200 tickets being addressed before her, thus second-guessing the urge to type <strong>URGENT </strong>across a subject line only to be violently shoved down your throat.</p><p>In all seriousness, nobody likes the experience of a vanilla helpdesk because it dehumanizes the customer. While our personal beliefs reassure us that we are special, entering a cold support queue is a stark suggestion that we may not be so special after all, which isn't exactly a fact Millennials or Executives like to ponder on. If nothing else, take this as a chance to build software friendly towards humans with full transparency, and both parties will surely benefit. Remember: happy humans bides times for the inevitable robot revolution on the horizon destined to eradicate mankind. Do your part!</p>","url":"https://hackersandslackers.com/building-a-better-jira/","uuid":"789d1406-0dbf-432e-aaa0-32d10f7d6337","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b6f24cc0cd9b8583e46ab5b"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736eb","title":"Pipenv: Better Environment Management for Python","slug":"pipenv-python-environment-management","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/pipenv.jpg","excerpt":"Effortlessly manage your Python environment and dependencies.","custom_excerpt":"Effortlessly manage your Python environment and dependencies.","created_at_pretty":"27 August, 2018","published_at_pretty":"30 August, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-08-27T19:40:53.000-04:00","published_at":"2018-08-30T07:36:00.000-04:00","updated_at":"2019-04-10T09:09:36.000-04:00","meta_title":"Effortlessly manage your Python environment | Hackers And Slackers","meta_description":"Pipenv serves as both an environment management tool as well as a sort of 'package.json' for your Python app.","og_description":"Pipenv serves as both an environment management tool as well as a sort of 'package.json' for your Python app.","og_image":"https://hackersandslackers.com/content/images/2019/04/pipenv-2.jpg","og_title":"Pipenv: Better Environment Management for Python","twitter_description":"Pipenv serves as both an environment management tool as well as a sort of 'package.json' for your Python app.","twitter_image":"https://hackersandslackers.com/content/images/2019/04/pipenv-1.jpg","twitter_title":"Pipenv: Better Environment Management for Python","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"As a shoutout to my fellow Data Engineers, I'm going to take a step back from\ntypical data science workflows. When we build standalone applications, we\nprobably don't want to be tossing around Miniconda's 720 software packages in\nproduction, nor would we ever want to commit the source of any dependencies to\nGithub. This is where Pipenv comes in handy: it serves as both an environment\nmanagement tool, as well as a sort of package.json  for your Python app.\n\nThe combination of virtualenv  and virtualenvwrapper  have reigned supreme for\nsome time. While this combination is a totally fine solution, I've noticed even\nsenior developers gloss over the existence of a better alternative, pipenv,\nwhich makes package management way, way easier. This is especially important in\ncases such as building apps for Heroku, where we're pushing to an otherwise\nagnostic environment which must explicitly be kept in sync with our local setup\nto ensure anything works.\n\nApologies in advance for what might seem a bit like Python 101, but I've been\nfinding that the following information might be more relevant to some than we\nmight presume.\n\nWhy Pipenv?\nPipenv's shell interface is entirely user-friendly. Rarely will developers find\nthemselves needing to type more than two words, perhaps a single argument, to\nachieve a series of tasks which were previously less trivial. Pipenv also does\nan excellent job of documenting all dependencies in the resulting Pipfile  and \nPipfile.lock, which are easily generated and capture our project's dependencies\nto be handed off to the next poor bloke. Finally, Pipenv does us the luxury of\nkeeping installed dependencies out of our project folder and instead creates\nvirtual environments in parallel with our Python Path. This keeps folders\npotentially holding hundreds of dependencies out of our project folders,\n mitigates any risk of us committing these packages to any git repos (if you're\na nodejs person, you know what I mean with npm  and node_modules).\n\nCreating Environments\nUnsurprisingly, we get started with pip3 install pipenv. This may as well be the\nfirst and last package you install on your python path.\n\nWhile in your project folder, give ‘pipenv shell’ a go. If an environment has\nnot been created in this folder previously, this will create a new environment\nfor this directory. If an environment does exist, this same command will be used\nto activate the environment. Compare this to the syntax of virtualenv:\n\n$ virtualenv myenv\n$ source myenv/bin/activate\n\n\nWhen creating environments, ‘pipenv shell’ can also take additional arguments\nsuch as —python, which allows you to specify which installed version of python\nto use for this environment:\n\n$ pipenv shell —python 3.7\n\n\nWhile in the shell, we can install packages using pip as expected.\n\nManaging packages\nThe point of environments is not only to isolate dependencies, but also to track\nthem so that our environment is both transferable and easily reproducible.\nChances are you’re familiar with the typical output of pip freeze:\n\naadict==0.2.3\nasset==0.6.12\nbeautifulsoup4==4.6.1\ncertifi==2018.4.16\nchardet==3.0.4\nclick==6.7\ndecorator==4.3.0\ndnspython==1.15.0\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Static-Compress==1.0.2\nglobre==0.1.5\ngunicorn==19.9.0\nidna==2.7\ninfinity==1.4\nintervals==0.8.1\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nlessc==0.1.2\nlesscpy==0.13.0\nMarkupSafe==1.0\nordereddict==1.1\nply==3.11\npymongo==3.7.1\nrequests==2.19.1\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.10\nSQLAlchemy-Utils==0.33.3\nurllib3==1.23\nvalidators==0.12.2\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\nWTForms-Alchemy==0.16.7\nWTForms-Components==0.10.3\n\npip freeze  is a great human-friendly way to see what you have installed in your\nenvironment; but what about robots? This wouldn't be Hackers And Slackers if we\ndidn't have a robot-friendly solution, now would it? Check out the output of \npipenv lock, which writes to a file called Pipfile.lock  in your local\nenvironment:\n\n{\n    \"_meta\": {\n        \"hash\": {\n            \"sha256\": \"668ab7d6f7db268048ca01a717c1cf77b8b4f373ed8074e48a9f22517975a306\"\n        },\n        \"pipfile-spec\": 6,\n        \"requires\": {\n            \"python_version\": \"3.7\"\n        },\n        \"sources\": [\n            {\n                \"name\": \"pypi\",\n                \"url\": \"https://pypi.org/simple\",\n                \"verify_ssl\": true\n            }\n        ]\n    },\n    \"default\": {\n        \"asn1crypto\": {\n            \"hashes\": [\n                \"sha256:2f1adbb7546ed199e3c90ef23ec95c5cf3585bac7d11fb7eb562a3fe89c64e87\",\n                \"sha256:9d5c20441baf0cb60a4ac34cc447c6c189024b6b4c6cd7877034f4965c464e49\"\n            ],\n            \"version\": \"==0.24.0\"\n        },\n        \"certifi\": {\n            \"hashes\": [\n                \"sha256:13e698f54293db9f89122b0581843a782ad0934a4fe0172d2a980ba77fc61bb7\",\n                \"sha256:9fa520c1bacfb634fa7af20a76bcbd3d5fb390481724c597da32c719a7dca4b0\"\n            ],\n            \"version\": \"==2018.4.16\"\n        },\n        \"cffi\": {\n            \"hashes\": [\n                \"sha256:151b7eefd035c56b2b2e1eb9963c90c6302dc15fbd8c1c0a83a163ff2c7d7743\",\n                \"sha256:1553d1e99f035ace1c0544050622b7bc963374a00c467edafac50ad7bd276aef\",\n                \"sha256:1b0493c091a1898f1136e3f4f991a784437fac3673780ff9de3bcf46c80b6b50\",\n                \"sha256:2ba8a45822b7aee805ab49abfe7eec16b90587f7f26df20c71dd89e45a97076f\",\n                \"sha256:3bb6bd7266598f318063e584378b8e27c67de998a43362e8fce664c54ee52d30\",\n                \"sha256:3c85641778460581c42924384f5e68076d724ceac0f267d66c757f7535069c93\",\n                \"sha256:3eb6434197633b7748cea30bf0ba9f66727cdce45117a712b29a443943733257\",\n                \"sha256:495c5c2d43bf6cebe0178eb3e88f9c4aa48d8934aa6e3cddb865c058da76756b\",\n                \"sha256:4c91af6e967c2015729d3e69c2e51d92f9898c330d6a851bf8f121236f3defd3\",\n                \"sha256:57b2533356cb2d8fac1555815929f7f5f14d68ac77b085d2326b571310f34f6e\",\n                \"sha256:770f3782b31f50b68627e22f91cb182c48c47c02eb405fd689472aa7b7aa16dc\",\n                \"sha256:79f9b6f7c46ae1f8ded75f68cf8ad50e5729ed4d590c74840471fc2823457d04\",\n                \"sha256:7a33145e04d44ce95bcd71e522b478d282ad0eafaf34fe1ec5bbd73e662f22b6\",\n                \"sha256:857959354ae3a6fa3da6651b966d13b0a8bed6bbc87a0de7b38a549db1d2a359\",\n                \"sha256:87f37fe5130574ff76c17cab61e7d2538a16f843bb7bca8ebbc4b12de3078596\",\n                \"sha256:95d5251e4b5ca00061f9d9f3d6fe537247e145a8524ae9fd30a2f8fbce993b5b\",\n                \"sha256:9d1d3e63a4afdc29bd76ce6aa9d58c771cd1599fbba8cf5057e7860b203710dd\",\n                \"sha256:a36c5c154f9d42ec176e6e620cb0dd275744aa1d804786a71ac37dc3661a5e95\",\n                \"sha256:a6a5cb8809091ec9ac03edde9304b3ad82ad4466333432b16d78ef40e0cce0d5\",\n                \"sha256:ae5e35a2c189d397b91034642cb0eab0e346f776ec2eb44a49a459e6615d6e2e\",\n                \"sha256:b0f7d4a3df8f06cf49f9f121bead236e328074de6449866515cea4907bbc63d6\",\n                \"sha256:b75110fb114fa366b29a027d0c9be3709579602ae111ff61674d28c93606acca\",\n                \"sha256:ba5e697569f84b13640c9e193170e89c13c6244c24400fc57e88724ef610cd31\",\n                \"sha256:be2a9b390f77fd7676d80bc3cdc4f8edb940d8c198ed2d8c0be1319018c778e1\",\n                \"sha256:ca1bd81f40adc59011f58159e4aa6445fc585a32bb8ac9badf7a2c1aa23822f2\",\n                \"sha256:d5d8555d9bfc3f02385c1c37e9f998e2011f0db4f90e250e5bc0c0a85a813085\",\n                \"sha256:e55e22ac0a30023426564b1059b035973ec82186ddddbac867078435801c7801\",\n                \"sha256:e90f17980e6ab0f3c2f3730e56d1fe9bcba1891eeea58966e89d352492cc74f4\",\n                \"sha256:ecbb7b01409e9b782df5ded849c178a0aa7c906cf8c5a67368047daab282b184\",\n                \"sha256:ed01918d545a38998bfa5902c7c00e0fee90e957ce036a4000a88e3fe2264917\",\n                \"sha256:edabd457cd23a02965166026fd9bfd196f4324fe6032e866d0f3bd0301cd486f\",\n                \"sha256:fdf1c1dc5bafc32bc5d08b054f94d659422b05aba244d6be4ddc1c72d9aa70fb\"\n            ],\n            \"version\": \"==1.11.5\"\n        },\n        \"chardet\": {\n            \"hashes\": [\n                \"sha256:84ab92ed1c4d4f16916e05906b6b75a6c0fb5db821cc65e70cbd64a3e2a5eaae\",\n                \"sha256:fc323ffcaeaed0e0a02bf4d117757b98aed530d9ed4531e3e15460124c106691\"\n            ],\n            \"version\": \"==3.0.4\"\n        },\n        \"cryptography\": {\n            \"hashes\": [\n                \"sha256:21af753934f2f6d1a10fe8f4c0a64315af209ef6adeaee63ca349797d747d687\",\n                \"sha256:27bb401a20a838d6d0ea380f08c6ead3ccd8c9d8a0232dc9adcc0e4994576a66\",\n                \"sha256:29720c4253263cff9aea64585adbbe85013ba647f6e98367efff9db2d7193ded\",\n                \"sha256:2a35b7570d8f247889784010aac8b384fd2e4a47b33e15c4a60b45a7c1944120\",\n                \"sha256:42c531a6a354407f42ee07fda5c2c0dc822cf6d52744949c182f2b295fbd4183\",\n                \"sha256:5eb86f03f9c4f0ac2336ac5431271072ddf7ecc76b338e26366732cfac58aa19\",\n                \"sha256:67f7f57eae8dede577f3f7775957f5bec93edd6bdb6ce597bb5b28e1bdf3d4fb\",\n                \"sha256:6ec84edcbc966ae460560a51a90046503ff0b5b66157a9efc61515c68059f6c8\",\n                \"sha256:7ba834564daef87557e7fcd35c3c3183a4147b0b3a57314e53317360b9b201b3\",\n                \"sha256:7d7f084cbe1fdb82be5a0545062b59b1ad3637bc5a48612ac2eb428ff31b31ea\",\n                \"sha256:82409f5150e529d699e5c33fa8fd85e965104db03bc564f5f4b6a9199e591f7c\",\n                \"sha256:87d092a7c2a44e5f7414ab02fb4145723ebba411425e1a99773531dd4c0e9b8d\",\n                \"sha256:8c56ef989342e42b9fcaba7c74b446f0cc9bed546dd00034fa7ad66fc00307ef\",\n                \"sha256:9449f5d4d7c516a6118fa9210c4a00f34384cb1d2028672100ee0c6cce49d7f6\",\n                \"sha256:bc2301170986ad82d9349a91eb8884e0e191209c45f5541b16aa7c0cfb135978\",\n                \"sha256:c132bab45d4bd0fff1d3fe294d92b0a6eb8404e93337b3127bdec9f21de117e6\",\n                \"sha256:c3d945b7b577f07a477700f618f46cbc287af3a9222cd73035c6ef527ef2c363\",\n                \"sha256:cee18beb4c807b5c0b178f4fa2fae03cef9d51821a358c6890f8b23465b7e5d2\",\n                \"sha256:d01dfc5c2b3495184f683574e03c70022674ca9a7be88589c5aba130d835ea90\"\n            ],\n            \"version\": \"==2.3\"\n        },\n        \"defusedxml\": {\n            \"hashes\": [\n                \"sha256:24d7f2f94f7f3cb6061acb215685e5125fbcdc40a857eff9de22518820b0a4f4\",\n                \"sha256:702a91ade2968a82beb0db1e0766a6a273f33d4616a6ce8cde475d8e09853b20\"\n            ],\n            \"version\": \"==0.5.0\"\n        },\n        \"idna\": {\n            \"hashes\": [\n                \"sha256:156a6814fb5ac1fc6850fb002e0852d56c0c8d2531923a51032d1b70760e186e\",\n                \"sha256:684a38a6f903c1d71d6d5fac066b58d7768af4de2b832e426ec79c30daa94a16\"\n            ],\n            \"version\": \"==2.7\"\n        },\n        \"jira\": {\n            \"hashes\": [\n                \"sha256:9adeead4d5f5a6aff74c630787f8bd2d4b0e154f3a3036641298064e91b2d25d\",\n                \"sha256:e2a94adff98e45b29ded030adc76103eab34fa7d4d57303f211f572bedba0e93\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.0.0\"\n        },\n        \"numpy\": {\n            \"hashes\": [\n                \"sha256:14fb76bde161c87dcec52d91c78f65aa8a23aa2e1530a71f412dabe03927d917\",\n                \"sha256:21041014b7529237994a6b578701c585703fbb3b1bea356cdb12a5ea7804241c\",\n                \"sha256:24f3bb9a5f6c3936a8ccd4ddfc1210d9511f4aeb879a12efd2e80bec647b8695\",\n                \"sha256:34033b581bc01b1135ca2e3e93a94daea7c739f21a97a75cca93e29d9f0c8e71\",\n                \"sha256:3fbccb399fe9095b1c1d7b41e7c7867db8aa0d2347fc44c87a7a180cedda112b\",\n                \"sha256:50718eea8e77a1bedcc85befd22c8dbf5a24c9d2c0c1e36bbb8d7a38da847eb3\",\n                \"sha256:55daf757e5f69aa75b4477cf4511bf1f96325c730e4ad32d954ccb593acd2585\",\n                \"sha256:61efc65f325770bbe787f34e00607bc124f08e6c25fdf04723848585e81560dc\",\n                \"sha256:62cb836506f40ce2529bfba9d09edc4b2687dd18c56cf4457e51c3e7145402fd\",\n                \"sha256:64c6acf5175745fd1b7b7e17c74fdbfb7191af3b378bc54f44560279f41238d3\",\n                \"sha256:674ea7917f0657ddb6976bd102ac341bc493d072c32a59b98e5b8c6eaa2d5ec0\",\n                \"sha256:73a816e441dace289302e04a7a34ec4772ed234ab6885c968e3ca2fc2d06fe2d\",\n                \"sha256:78c35dc7ad184aebf3714dbf43f054714c6e430e14b9c06c49a864fb9e262030\",\n                \"sha256:7f17efe9605444fcbfd990ba9b03371552d65a3c259fc2d258c24fb95afdd728\",\n                \"sha256:816645178f2180be257a576b735d3ae245b1982280b97ae819550ce8bcdf2b6b\",\n                \"sha256:924f37e66db78464b4b85ed4b6d2e5cda0c0416e657cac7ccbef14b9fa2c40b5\",\n                \"sha256:a17a8fd5df4fec5b56b4d11c9ba8b9ebfb883c90ec361628d07be00aaa4f009a\",\n                \"sha256:aaa519335a71f87217ca8a680c3b66b61960e148407bdf5c209c42f50fe30f49\",\n                \"sha256:ae3864816287d0e86ead580b69921daec568fe680857f07ee2a87bf7fd77ce24\",\n                \"sha256:b5f8c15cb9173f6cdf0f994955e58d1265331029ae26296232379461a297e5f2\",\n                \"sha256:c3ac359ace241707e5a48fe2922e566ac666aacacf4f8031f2994ac429c31344\",\n                \"sha256:c7c660cc0209fdf29a4e50146ca9ac9d8664acaded6b6ae2f5d0ae2e91a0f0cd\",\n                \"sha256:d690a2ff49f6c3bc35336693c9924fe5916be3cc0503fe1ea6c7e2bf951409ee\",\n                \"sha256:e2317cf091c2e7f0dacdc2e72c693cc34403ca1f8e3807622d0bb653dc978616\",\n                \"sha256:f28e73cf18d37a413f7d5de35d024e6b98f14566a10d82100f9dc491a7d449f9\",\n                \"sha256:f2a778dd9bb3e4590dbe3bbac28e7c7134280c4ec97e3bf8678170ee58c67b21\",\n                \"sha256:f5a758252502b466b9c2b201ea397dae5a914336c987f3a76c3741a82d43c96e\",\n                \"sha256:fb4c33a404d9eff49a0cdc8ead0af6453f62f19e071b60d283f9dc05581e4134\"\n            ],\n            \"markers\": \"python_version >= '2.7' and python_version != '3.2.*' and python_version != '3.3.*' and python_version != '3.0.*' and python_version != '3.1.*'\",\n            \"version\": \"==1.15.0\"\n        },\n        \"oauthlib\": {\n            \"hashes\": [\n                \"sha256:ac35665a61c1685c56336bda97d5eefa246f1202618a1d6f34fccb1bdd404162\",\n                \"sha256:d883b36b21a6ad813953803edfa563b1b579d79ca758fe950d1bc9e8b326025b\"\n            ],\n            \"version\": \"==2.1.0\"\n        },\n        \"pandas\": {\n            \"hashes\": [\n                \"sha256:11975fad9edbdb55f1a560d96f91830e83e29bed6ad5ebf506abda09818eaf60\",\n                \"sha256:12e13d127ca1b585dd6f6840d3fe3fa6e46c36a6afe2dbc5cb0b57032c902e31\",\n                \"sha256:1c87fcb201e1e06f66e23a61a5fea9eeebfe7204a66d99df24600e3f05168051\",\n                \"sha256:242e9900de758e137304ad4b5663c2eff0d798c2c3b891250bd0bd97144579da\",\n                \"sha256:26c903d0ae1542890cb9abadb4adcb18f356b14c2df46e4ff657ae640e3ac9e7\",\n                \"sha256:2e1e88f9d3e5f107b65b59cd29f141995597b035d17cc5537e58142038942e1a\",\n                \"sha256:31b7a48b344c14691a8e92765d4023f88902ba3e96e2e4d0364d3453cdfd50db\",\n                \"sha256:4fd07a932b4352f8a8973761ab4e84f965bf81cc750fb38e04f01088ab901cb8\",\n                \"sha256:5b24ca47acf69222e82530e89111dd9d14f9b970ab2cd3a1c2c78f0c4fbba4f4\",\n                \"sha256:647b3b916cc8f6aeba240c8171be3ab799c3c1b2ea179a3be0bd2712c4237553\",\n                \"sha256:66b060946046ca27c0e03e9bec9bba3e0b918bafff84c425ca2cc2e157ce121e\",\n                \"sha256:6efa9fa6e1434141df8872d0fa4226fc301b17aacf37429193f9d70b426ea28f\",\n                \"sha256:be4715c9d8367e51dbe6bc6d05e205b1ae234f0dc5465931014aa1c4af44c1ba\",\n                \"sha256:bea90da782d8e945fccfc958585210d23de374fa9294a9481ed2abcef637ebfc\",\n                \"sha256:d785fc08d6f4207437e900ffead930a61e634c5e4f980ba6d3dc03c9581748c7\",\n                \"sha256:de9559287c4fe8da56e8c3878d2374abc19d1ba2b807bfa7553e912a8e5ba87c\",\n                \"sha256:f4f98b190bb918ac0bc0e3dd2ab74ff3573da9f43106f6dba6385406912ec00f\",\n                \"sha256:f71f1a7e2d03758f6e957896ed696254e2bc83110ddbc6942018f1a232dd9dad\",\n                \"sha256:fb944c8f0b0ab5c1f7846c686bc4cdf8cde7224655c12edcd59d5212cd57bec0\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==0.23.4\"\n        },\n        \"pbr\": {\n            \"hashes\": [\n                \"sha256:1b8be50d938c9bb75d0eaf7eda111eec1bf6dc88a62a6412e33bf077457e0f45\",\n                \"sha256:b486975c0cafb6beeb50ca0e17ba047647f229087bd74e37f4a7e2cac17d2caa\"\n            ],\n            \"version\": \"==4.2.0\"\n        },\n        \"psycopg2-binary\": {\n            \"hashes\": [\n                \"sha256:04afb59bbbd2eab3148e6816beddc74348078b8c02a1113ea7f7822f5be4afe3\",\n                \"sha256:098b18f4d8857a8f9b206d1dc54db56c2255d5d26458917e7bcad61ebfe4338f\",\n                \"sha256:0bf855d4a7083e20ead961fda4923887094eaeace0ab2d76eb4aa300f4bbf5bd\",\n                \"sha256:197dda3ffd02057820be83fe4d84529ea70bf39a9a4daee1d20ffc74eb3d042e\",\n                \"sha256:278ef63afb4b3d842b4609f2c05ffbfb76795cf6a184deeb8707cd5ed3c981a5\",\n                \"sha256:3cbf8c4fc8f22f0817220891cf405831559f4d4c12c4f73913730a2ea6c47a47\",\n                \"sha256:4305aed922c4d9d6163ab3a41d80b5a1cfab54917467da8168552c42cad84d32\",\n                \"sha256:47ee296f704fb8b2a616dec691cdcfd5fa0f11943955e88faa98cbd1dc3b3e3d\",\n                \"sha256:4a0e38cb30457e70580903367161173d4a7d1381eb2f2cfe4e69b7806623f484\",\n                \"sha256:4d6c294c6638a71cafb82a37f182f24321f1163b08b5d5ca076e11fe838a3086\",\n                \"sha256:4f3233c366500730f839f92833194fd8f9a5c4529c8cd8040aa162c3740de8e5\",\n                \"sha256:5221f5a3f4ca2ddf0d58e8b8a32ca50948be9a43351fda797eb4e72d7a7aa34d\",\n                \"sha256:5c6ca0b507540a11eaf9e77dee4f07c131c2ec80ca0cffa146671bf690bc1c02\",\n                \"sha256:789bd89d71d704db2b3d5e67d6d518b158985d791d3b2dec5ab85457cfc9677b\",\n                \"sha256:7b94d29239efeaa6a967f3b5971bd0518d2a24edd1511edbf4a2c8b815220d07\",\n                \"sha256:89bc65ef3301c74cf32db25334421ea6adbe8f65601ea45dcaaf095abed910bb\",\n                \"sha256:89d6d3a549f405c20c9ae4dc94d7ed2de2fa77427a470674490a622070732e62\",\n                \"sha256:97521704ac7127d7d8ba22877da3c7bf4a40366587d238ec679ff38e33177498\",\n                \"sha256:a395b62d5f44ff6f633231abe568e2203b8fabf9797cd6386aa92497df912d9a\",\n                \"sha256:a6d32c37f714c3f34158f3fa659f3a8f2658d5f53c4297d45579b9677cc4d852\",\n                \"sha256:a89ee5c26f72f2d0d74b991ce49e42ddeb4ac0dc2d8c06a0f2770a1ab48f4fe0\",\n                \"sha256:b4c8b0ef3608e59317bfc501df84a61e48b5445d45f24d0391a24802de5f2d84\",\n                \"sha256:b5fcf07140219a1f71e18486b8dc28e2e1b76a441c19374805c617aa6d9a9d55\",\n                \"sha256:b86f527f00956ecebad6ab3bb30e3a75fedf1160a8716978dd8ce7adddedd86f\",\n                \"sha256:be4c4aa22ba22f70de36c98b06480e2f1697972d49eb20d525f400d204a6d272\",\n                \"sha256:c2ac7aa1a144d4e0e613ac7286dae85671e99fe7a1353954d4905629c36b811c\",\n                \"sha256:de26ef4787b5e778e8223913a3e50368b44e7480f83c76df1f51d23bd21cea16\",\n                \"sha256:e70ebcfc5372dc7b699c0110454fc4263967f30c55454397e5769eb72c0eb0ce\",\n                \"sha256:eadbd32b6bc48b67b0457fccc94c86f7ccc8178ab839f684eb285bb592dc143e\",\n                \"sha256:ecbc6dfff6db06b8b72ae8a2f25ff20fbdcb83cb543811a08f7cb555042aa729\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.7.5\"\n        },\n        \"pycparser\": {\n            \"hashes\": [\n                \"sha256:99a8ca03e29851d96616ad0404b4aad7d9ee16f25c9f9708a11faf2810f7b226\"\n            ],\n            \"version\": \"==2.18\"\n        },\n        \"pyjwt\": {\n            \"hashes\": [\n                \"sha256:30b1380ff43b55441283cc2b2676b755cca45693ae3097325dea01f3d110628c\",\n                \"sha256:4ee413b357d53fd3fb44704577afac88e72e878716116270d722723d65b42176\"\n            ],\n            \"version\": \"==1.6.4\"\n        },\n        \"python-dateutil\": {\n            \"hashes\": [\n                \"sha256:1adb80e7a782c12e52ef9a8182bebeb73f1d7e24e374397af06fb4956c8dc5c0\",\n                \"sha256:e27001de32f627c22380a688bcc43ce83504a7bc5da472209b4c70f02829f0b8\"\n            ],\n            \"version\": \"==2.7.3\"\n        },\n        \"pytz\": {\n            \"hashes\": [\n                \"sha256:a061aa0a9e06881eb8b3b2b43f05b9439d6583c206d0a6c340ff72a7b6669053\",\n                \"sha256:ffb9ef1de172603304d9d2819af6f5ece76f2e85ec10692a524dd876e72bf277\"\n            ],\n            \"version\": \"==2018.5\"\n        },\n        \"requests\": {\n            \"hashes\": [\n                \"sha256:63b52e3c866428a224f97cab011de738c36aec0185aa91cfacd418b5d58911d1\",\n                \"sha256:ec22d826a36ed72a7358ff3fe56cbd4ba69dd7a6718ffd450ff0e9df7a47ce6a\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.19.1\"\n        },\n        \"requests-oauthlib\": {\n            \"hashes\": [\n                \"sha256:8886bfec5ad7afb391ed5443b1f697c6f4ae98d0e5620839d8b4499c032ada3f\",\n                \"sha256:e21232e2465808c0e892e0e4dbb8c2faafec16ac6dc067dd546e9b466f3deac8\"\n            ],\n            \"version\": \"==1.0.0\"\n        },\n        \"requests-toolbelt\": {\n            \"hashes\": [\n                \"sha256:42c9c170abc2cacb78b8ab23ac957945c7716249206f90874651971a4acff237\",\n                \"sha256:f6a531936c6fa4c6cfce1b9c10d5c4f498d16528d2a54a22ca00011205a187b5\"\n            ],\n            \"version\": \"==0.8.0\"\n        },\n        \"six\": {\n            \"hashes\": [\n                \"sha256:70e8a77beed4562e7f14fe23a786b54f6296e34344c23bc42f07b15018ff98e9\",\n                \"sha256:832dc0e10feb1aa2c68dcc57dbb658f1c7e65b9b61af69048abc87a2db00a0eb\"\n            ],\n            \"version\": \"==1.11.0\"\n        },\n        \"sqlalchemy\": {\n            \"hashes\": [\n                \"sha256:72325e67fb85f6e9ad304c603d83626d1df684fdf0c7ab1f0352e71feeab69d8\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==1.2.10\"\n        },\n        \"urllib3\": {\n            \"hashes\": [\n                \"sha256:a68ac5e15e76e7e5dd2b8f94007233e01effe3e50e8daddf69acfd81cb686baf\",\n                \"sha256:b5725a0bd4ba422ab0e66e89e030c806576753ea3ee08554382c14e685d117b5\"\n            ],\n            \"markers\": \"python_version != '3.0.*' and python_version != '3.3.*' and python_version != '3.1.*' and python_version != '3.2.*' and python_version < '4' and python_version >= '2.6'\",\n            \"version\": \"==1.23\"\n        }\n    },\n    \"develop\": {}\n}\n\n\nPipfile.lock  is Python's very own equivalent to package-lock.json. With \nPipfile.lock  present, future developers need only to type the command pipenv\ninstall  to install the exact dependencies in your project with all the correct\nversions. What's more, Pipfile.lock is actually a must-have for Heroku \ndevelopment, which uses this file to wisely produce environments upon\ndeployment.\n\nWhat about updating all packages past their locked version, you might ask? Check\nout the output of pipenv update, which updates all packages to their latest, and\nupdates the corresponding .lock file accordingly:\n\nYou had me at Snake emoji.When to Use Conda or Virtualenv\nIf you're strictly in the data science  profession, chances are that none of\nthis nonsense interests you - you and all your friends are always working with\nthe full Anaconda suite (which has its own similar environment manager), and you\ndon't care for shipping products. You're a scientist, not some sort of blue\ncollar data equivalent of manufacturing. \n\nEven if you're engineer, virtualenv  still has it's place. Take Lambda Functions\nin AWS for example: if you're looking to create a zip of dependencies to upload\nto your Lambda, it's much simpler to have those packages to live in your local\nworking folder. \n\nI'm sure you're itching to hear more on the topic of Python environment\nmanagement, but the analytics say that 90% of readers have already bounced by\nthis point. To the remaining 10%... you are all that I live for.","html":"<p>As a shoutout to my fellow Data Engineers, I'm going to take a step back from typical data science workflows. When we build standalone applications, we probably don't want to be tossing around Miniconda's 720 software packages in production, nor would we ever want to commit the source of any dependencies to Github. This is where Pipenv comes in handy: it serves as both an environment management tool, as well as a sort of <em>package.json</em> for your Python app.</p><p>The combination of <code>virtualenv</code> and <code>virtualenvwrapper</code> have reigned supreme for some time. While this combination is a totally fine solution, I've noticed even senior developers gloss over the existence of a better alternative, <code>pipenv</code>, which makes package management way, way easier. This is especially important in cases such as building apps for Heroku, where we're pushing to an otherwise agnostic environment which must explicitly be kept in sync with our local setup to ensure anything works.</p><p>Apologies in advance for what might seem a bit like Python 101, but I've been finding that the following information might be more relevant to some than we might presume.</p><h2 id=\"why-pipenv\">Why Pipenv?</h2><p>Pipenv's shell interface is entirely user-friendly. Rarely will developers find themselves needing to type more than two words, perhaps a single argument, to achieve a series of tasks which were previously less trivial. Pipenv also does an excellent job of documenting all dependencies in the resulting <strong>Pipfile</strong> and <strong>Pipfile.lock</strong>, which are easily generated and capture our project's dependencies to be handed off to the next poor bloke. Finally, Pipenv does us the luxury of keeping installed dependencies out of our project folder and instead creates virtual environments in parallel with our Python Path. This keeps folders potentially holding hundreds of dependencies out of our project folders,  mitigates any risk of us committing these packages to any git repos (if you're a nodejs person, you know what I mean with <em>npm</em> and <em>node_modules</em>).</p><h2 id=\"creating-environments\">Creating Environments</h2><p>Unsurprisingly, we get started with <code>pip3 install pipenv</code>. This may as well be the first and last package you install on your python path.</p><p>While in your project folder, give ‘pipenv shell’ a go. If an environment has not been created in this folder previously, this will create a new environment for this directory. If an environment does exist, this same command will be used to activate the environment. Compare this to the syntax of virtualenv:</p><pre><code class=\"language-shell\">$ virtualenv myenv\n$ source myenv/bin/activate\n</code></pre>\n<p>When creating environments, ‘pipenv shell’ can also take additional arguments such as —python, which allows you to specify which installed version of python to use for this environment:</p><pre><code class=\"language-shell\">$ pipenv shell —python 3.7\n</code></pre>\n<p>While in the shell, we can install packages using pip as expected.</p><h2 id=\"managing-packages\">Managing packages</h2><p>The point of environments is not only to isolate dependencies, but also to track them so that our environment is both transferable and easily reproducible. Chances are you’re familiar with the typical output of <code>pip freeze</code>:</p><pre><code>aadict==0.2.3\nasset==0.6.12\nbeautifulsoup4==4.6.1\ncertifi==2018.4.16\nchardet==3.0.4\nclick==6.7\ndecorator==4.3.0\ndnspython==1.15.0\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Static-Compress==1.0.2\nglobre==0.1.5\ngunicorn==19.9.0\nidna==2.7\ninfinity==1.4\nintervals==0.8.1\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nlessc==0.1.2\nlesscpy==0.13.0\nMarkupSafe==1.0\nordereddict==1.1\nply==3.11\npymongo==3.7.1\nrequests==2.19.1\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.10\nSQLAlchemy-Utils==0.33.3\nurllib3==1.23\nvalidators==0.12.2\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\nWTForms-Alchemy==0.16.7\nWTForms-Components==0.10.3</code></pre><p><code>pip freeze</code> is a great human-friendly way to see what you have installed in your environment; but what about robots? This wouldn't be Hackers And Slackers if we didn't have a robot-friendly solution, now would it? Check out the output of <code>pipenv lock</code>, which writes to a file called <code>Pipfile.lock</code> in your local environment:</p><pre><code>{\n    \"_meta\": {\n        \"hash\": {\n            \"sha256\": \"668ab7d6f7db268048ca01a717c1cf77b8b4f373ed8074e48a9f22517975a306\"\n        },\n        \"pipfile-spec\": 6,\n        \"requires\": {\n            \"python_version\": \"3.7\"\n        },\n        \"sources\": [\n            {\n                \"name\": \"pypi\",\n                \"url\": \"https://pypi.org/simple\",\n                \"verify_ssl\": true\n            }\n        ]\n    },\n    \"default\": {\n        \"asn1crypto\": {\n            \"hashes\": [\n                \"sha256:2f1adbb7546ed199e3c90ef23ec95c5cf3585bac7d11fb7eb562a3fe89c64e87\",\n                \"sha256:9d5c20441baf0cb60a4ac34cc447c6c189024b6b4c6cd7877034f4965c464e49\"\n            ],\n            \"version\": \"==0.24.0\"\n        },\n        \"certifi\": {\n            \"hashes\": [\n                \"sha256:13e698f54293db9f89122b0581843a782ad0934a4fe0172d2a980ba77fc61bb7\",\n                \"sha256:9fa520c1bacfb634fa7af20a76bcbd3d5fb390481724c597da32c719a7dca4b0\"\n            ],\n            \"version\": \"==2018.4.16\"\n        },\n        \"cffi\": {\n            \"hashes\": [\n                \"sha256:151b7eefd035c56b2b2e1eb9963c90c6302dc15fbd8c1c0a83a163ff2c7d7743\",\n                \"sha256:1553d1e99f035ace1c0544050622b7bc963374a00c467edafac50ad7bd276aef\",\n                \"sha256:1b0493c091a1898f1136e3f4f991a784437fac3673780ff9de3bcf46c80b6b50\",\n                \"sha256:2ba8a45822b7aee805ab49abfe7eec16b90587f7f26df20c71dd89e45a97076f\",\n                \"sha256:3bb6bd7266598f318063e584378b8e27c67de998a43362e8fce664c54ee52d30\",\n                \"sha256:3c85641778460581c42924384f5e68076d724ceac0f267d66c757f7535069c93\",\n                \"sha256:3eb6434197633b7748cea30bf0ba9f66727cdce45117a712b29a443943733257\",\n                \"sha256:495c5c2d43bf6cebe0178eb3e88f9c4aa48d8934aa6e3cddb865c058da76756b\",\n                \"sha256:4c91af6e967c2015729d3e69c2e51d92f9898c330d6a851bf8f121236f3defd3\",\n                \"sha256:57b2533356cb2d8fac1555815929f7f5f14d68ac77b085d2326b571310f34f6e\",\n                \"sha256:770f3782b31f50b68627e22f91cb182c48c47c02eb405fd689472aa7b7aa16dc\",\n                \"sha256:79f9b6f7c46ae1f8ded75f68cf8ad50e5729ed4d590c74840471fc2823457d04\",\n                \"sha256:7a33145e04d44ce95bcd71e522b478d282ad0eafaf34fe1ec5bbd73e662f22b6\",\n                \"sha256:857959354ae3a6fa3da6651b966d13b0a8bed6bbc87a0de7b38a549db1d2a359\",\n                \"sha256:87f37fe5130574ff76c17cab61e7d2538a16f843bb7bca8ebbc4b12de3078596\",\n                \"sha256:95d5251e4b5ca00061f9d9f3d6fe537247e145a8524ae9fd30a2f8fbce993b5b\",\n                \"sha256:9d1d3e63a4afdc29bd76ce6aa9d58c771cd1599fbba8cf5057e7860b203710dd\",\n                \"sha256:a36c5c154f9d42ec176e6e620cb0dd275744aa1d804786a71ac37dc3661a5e95\",\n                \"sha256:a6a5cb8809091ec9ac03edde9304b3ad82ad4466333432b16d78ef40e0cce0d5\",\n                \"sha256:ae5e35a2c189d397b91034642cb0eab0e346f776ec2eb44a49a459e6615d6e2e\",\n                \"sha256:b0f7d4a3df8f06cf49f9f121bead236e328074de6449866515cea4907bbc63d6\",\n                \"sha256:b75110fb114fa366b29a027d0c9be3709579602ae111ff61674d28c93606acca\",\n                \"sha256:ba5e697569f84b13640c9e193170e89c13c6244c24400fc57e88724ef610cd31\",\n                \"sha256:be2a9b390f77fd7676d80bc3cdc4f8edb940d8c198ed2d8c0be1319018c778e1\",\n                \"sha256:ca1bd81f40adc59011f58159e4aa6445fc585a32bb8ac9badf7a2c1aa23822f2\",\n                \"sha256:d5d8555d9bfc3f02385c1c37e9f998e2011f0db4f90e250e5bc0c0a85a813085\",\n                \"sha256:e55e22ac0a30023426564b1059b035973ec82186ddddbac867078435801c7801\",\n                \"sha256:e90f17980e6ab0f3c2f3730e56d1fe9bcba1891eeea58966e89d352492cc74f4\",\n                \"sha256:ecbb7b01409e9b782df5ded849c178a0aa7c906cf8c5a67368047daab282b184\",\n                \"sha256:ed01918d545a38998bfa5902c7c00e0fee90e957ce036a4000a88e3fe2264917\",\n                \"sha256:edabd457cd23a02965166026fd9bfd196f4324fe6032e866d0f3bd0301cd486f\",\n                \"sha256:fdf1c1dc5bafc32bc5d08b054f94d659422b05aba244d6be4ddc1c72d9aa70fb\"\n            ],\n            \"version\": \"==1.11.5\"\n        },\n        \"chardet\": {\n            \"hashes\": [\n                \"sha256:84ab92ed1c4d4f16916e05906b6b75a6c0fb5db821cc65e70cbd64a3e2a5eaae\",\n                \"sha256:fc323ffcaeaed0e0a02bf4d117757b98aed530d9ed4531e3e15460124c106691\"\n            ],\n            \"version\": \"==3.0.4\"\n        },\n        \"cryptography\": {\n            \"hashes\": [\n                \"sha256:21af753934f2f6d1a10fe8f4c0a64315af209ef6adeaee63ca349797d747d687\",\n                \"sha256:27bb401a20a838d6d0ea380f08c6ead3ccd8c9d8a0232dc9adcc0e4994576a66\",\n                \"sha256:29720c4253263cff9aea64585adbbe85013ba647f6e98367efff9db2d7193ded\",\n                \"sha256:2a35b7570d8f247889784010aac8b384fd2e4a47b33e15c4a60b45a7c1944120\",\n                \"sha256:42c531a6a354407f42ee07fda5c2c0dc822cf6d52744949c182f2b295fbd4183\",\n                \"sha256:5eb86f03f9c4f0ac2336ac5431271072ddf7ecc76b338e26366732cfac58aa19\",\n                \"sha256:67f7f57eae8dede577f3f7775957f5bec93edd6bdb6ce597bb5b28e1bdf3d4fb\",\n                \"sha256:6ec84edcbc966ae460560a51a90046503ff0b5b66157a9efc61515c68059f6c8\",\n                \"sha256:7ba834564daef87557e7fcd35c3c3183a4147b0b3a57314e53317360b9b201b3\",\n                \"sha256:7d7f084cbe1fdb82be5a0545062b59b1ad3637bc5a48612ac2eb428ff31b31ea\",\n                \"sha256:82409f5150e529d699e5c33fa8fd85e965104db03bc564f5f4b6a9199e591f7c\",\n                \"sha256:87d092a7c2a44e5f7414ab02fb4145723ebba411425e1a99773531dd4c0e9b8d\",\n                \"sha256:8c56ef989342e42b9fcaba7c74b446f0cc9bed546dd00034fa7ad66fc00307ef\",\n                \"sha256:9449f5d4d7c516a6118fa9210c4a00f34384cb1d2028672100ee0c6cce49d7f6\",\n                \"sha256:bc2301170986ad82d9349a91eb8884e0e191209c45f5541b16aa7c0cfb135978\",\n                \"sha256:c132bab45d4bd0fff1d3fe294d92b0a6eb8404e93337b3127bdec9f21de117e6\",\n                \"sha256:c3d945b7b577f07a477700f618f46cbc287af3a9222cd73035c6ef527ef2c363\",\n                \"sha256:cee18beb4c807b5c0b178f4fa2fae03cef9d51821a358c6890f8b23465b7e5d2\",\n                \"sha256:d01dfc5c2b3495184f683574e03c70022674ca9a7be88589c5aba130d835ea90\"\n            ],\n            \"version\": \"==2.3\"\n        },\n        \"defusedxml\": {\n            \"hashes\": [\n                \"sha256:24d7f2f94f7f3cb6061acb215685e5125fbcdc40a857eff9de22518820b0a4f4\",\n                \"sha256:702a91ade2968a82beb0db1e0766a6a273f33d4616a6ce8cde475d8e09853b20\"\n            ],\n            \"version\": \"==0.5.0\"\n        },\n        \"idna\": {\n            \"hashes\": [\n                \"sha256:156a6814fb5ac1fc6850fb002e0852d56c0c8d2531923a51032d1b70760e186e\",\n                \"sha256:684a38a6f903c1d71d6d5fac066b58d7768af4de2b832e426ec79c30daa94a16\"\n            ],\n            \"version\": \"==2.7\"\n        },\n        \"jira\": {\n            \"hashes\": [\n                \"sha256:9adeead4d5f5a6aff74c630787f8bd2d4b0e154f3a3036641298064e91b2d25d\",\n                \"sha256:e2a94adff98e45b29ded030adc76103eab34fa7d4d57303f211f572bedba0e93\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.0.0\"\n        },\n        \"numpy\": {\n            \"hashes\": [\n                \"sha256:14fb76bde161c87dcec52d91c78f65aa8a23aa2e1530a71f412dabe03927d917\",\n                \"sha256:21041014b7529237994a6b578701c585703fbb3b1bea356cdb12a5ea7804241c\",\n                \"sha256:24f3bb9a5f6c3936a8ccd4ddfc1210d9511f4aeb879a12efd2e80bec647b8695\",\n                \"sha256:34033b581bc01b1135ca2e3e93a94daea7c739f21a97a75cca93e29d9f0c8e71\",\n                \"sha256:3fbccb399fe9095b1c1d7b41e7c7867db8aa0d2347fc44c87a7a180cedda112b\",\n                \"sha256:50718eea8e77a1bedcc85befd22c8dbf5a24c9d2c0c1e36bbb8d7a38da847eb3\",\n                \"sha256:55daf757e5f69aa75b4477cf4511bf1f96325c730e4ad32d954ccb593acd2585\",\n                \"sha256:61efc65f325770bbe787f34e00607bc124f08e6c25fdf04723848585e81560dc\",\n                \"sha256:62cb836506f40ce2529bfba9d09edc4b2687dd18c56cf4457e51c3e7145402fd\",\n                \"sha256:64c6acf5175745fd1b7b7e17c74fdbfb7191af3b378bc54f44560279f41238d3\",\n                \"sha256:674ea7917f0657ddb6976bd102ac341bc493d072c32a59b98e5b8c6eaa2d5ec0\",\n                \"sha256:73a816e441dace289302e04a7a34ec4772ed234ab6885c968e3ca2fc2d06fe2d\",\n                \"sha256:78c35dc7ad184aebf3714dbf43f054714c6e430e14b9c06c49a864fb9e262030\",\n                \"sha256:7f17efe9605444fcbfd990ba9b03371552d65a3c259fc2d258c24fb95afdd728\",\n                \"sha256:816645178f2180be257a576b735d3ae245b1982280b97ae819550ce8bcdf2b6b\",\n                \"sha256:924f37e66db78464b4b85ed4b6d2e5cda0c0416e657cac7ccbef14b9fa2c40b5\",\n                \"sha256:a17a8fd5df4fec5b56b4d11c9ba8b9ebfb883c90ec361628d07be00aaa4f009a\",\n                \"sha256:aaa519335a71f87217ca8a680c3b66b61960e148407bdf5c209c42f50fe30f49\",\n                \"sha256:ae3864816287d0e86ead580b69921daec568fe680857f07ee2a87bf7fd77ce24\",\n                \"sha256:b5f8c15cb9173f6cdf0f994955e58d1265331029ae26296232379461a297e5f2\",\n                \"sha256:c3ac359ace241707e5a48fe2922e566ac666aacacf4f8031f2994ac429c31344\",\n                \"sha256:c7c660cc0209fdf29a4e50146ca9ac9d8664acaded6b6ae2f5d0ae2e91a0f0cd\",\n                \"sha256:d690a2ff49f6c3bc35336693c9924fe5916be3cc0503fe1ea6c7e2bf951409ee\",\n                \"sha256:e2317cf091c2e7f0dacdc2e72c693cc34403ca1f8e3807622d0bb653dc978616\",\n                \"sha256:f28e73cf18d37a413f7d5de35d024e6b98f14566a10d82100f9dc491a7d449f9\",\n                \"sha256:f2a778dd9bb3e4590dbe3bbac28e7c7134280c4ec97e3bf8678170ee58c67b21\",\n                \"sha256:f5a758252502b466b9c2b201ea397dae5a914336c987f3a76c3741a82d43c96e\",\n                \"sha256:fb4c33a404d9eff49a0cdc8ead0af6453f62f19e071b60d283f9dc05581e4134\"\n            ],\n            \"markers\": \"python_version &gt;= '2.7' and python_version != '3.2.*' and python_version != '3.3.*' and python_version != '3.0.*' and python_version != '3.1.*'\",\n            \"version\": \"==1.15.0\"\n        },\n        \"oauthlib\": {\n            \"hashes\": [\n                \"sha256:ac35665a61c1685c56336bda97d5eefa246f1202618a1d6f34fccb1bdd404162\",\n                \"sha256:d883b36b21a6ad813953803edfa563b1b579d79ca758fe950d1bc9e8b326025b\"\n            ],\n            \"version\": \"==2.1.0\"\n        },\n        \"pandas\": {\n            \"hashes\": [\n                \"sha256:11975fad9edbdb55f1a560d96f91830e83e29bed6ad5ebf506abda09818eaf60\",\n                \"sha256:12e13d127ca1b585dd6f6840d3fe3fa6e46c36a6afe2dbc5cb0b57032c902e31\",\n                \"sha256:1c87fcb201e1e06f66e23a61a5fea9eeebfe7204a66d99df24600e3f05168051\",\n                \"sha256:242e9900de758e137304ad4b5663c2eff0d798c2c3b891250bd0bd97144579da\",\n                \"sha256:26c903d0ae1542890cb9abadb4adcb18f356b14c2df46e4ff657ae640e3ac9e7\",\n                \"sha256:2e1e88f9d3e5f107b65b59cd29f141995597b035d17cc5537e58142038942e1a\",\n                \"sha256:31b7a48b344c14691a8e92765d4023f88902ba3e96e2e4d0364d3453cdfd50db\",\n                \"sha256:4fd07a932b4352f8a8973761ab4e84f965bf81cc750fb38e04f01088ab901cb8\",\n                \"sha256:5b24ca47acf69222e82530e89111dd9d14f9b970ab2cd3a1c2c78f0c4fbba4f4\",\n                \"sha256:647b3b916cc8f6aeba240c8171be3ab799c3c1b2ea179a3be0bd2712c4237553\",\n                \"sha256:66b060946046ca27c0e03e9bec9bba3e0b918bafff84c425ca2cc2e157ce121e\",\n                \"sha256:6efa9fa6e1434141df8872d0fa4226fc301b17aacf37429193f9d70b426ea28f\",\n                \"sha256:be4715c9d8367e51dbe6bc6d05e205b1ae234f0dc5465931014aa1c4af44c1ba\",\n                \"sha256:bea90da782d8e945fccfc958585210d23de374fa9294a9481ed2abcef637ebfc\",\n                \"sha256:d785fc08d6f4207437e900ffead930a61e634c5e4f980ba6d3dc03c9581748c7\",\n                \"sha256:de9559287c4fe8da56e8c3878d2374abc19d1ba2b807bfa7553e912a8e5ba87c\",\n                \"sha256:f4f98b190bb918ac0bc0e3dd2ab74ff3573da9f43106f6dba6385406912ec00f\",\n                \"sha256:f71f1a7e2d03758f6e957896ed696254e2bc83110ddbc6942018f1a232dd9dad\",\n                \"sha256:fb944c8f0b0ab5c1f7846c686bc4cdf8cde7224655c12edcd59d5212cd57bec0\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==0.23.4\"\n        },\n        \"pbr\": {\n            \"hashes\": [\n                \"sha256:1b8be50d938c9bb75d0eaf7eda111eec1bf6dc88a62a6412e33bf077457e0f45\",\n                \"sha256:b486975c0cafb6beeb50ca0e17ba047647f229087bd74e37f4a7e2cac17d2caa\"\n            ],\n            \"version\": \"==4.2.0\"\n        },\n        \"psycopg2-binary\": {\n            \"hashes\": [\n                \"sha256:04afb59bbbd2eab3148e6816beddc74348078b8c02a1113ea7f7822f5be4afe3\",\n                \"sha256:098b18f4d8857a8f9b206d1dc54db56c2255d5d26458917e7bcad61ebfe4338f\",\n                \"sha256:0bf855d4a7083e20ead961fda4923887094eaeace0ab2d76eb4aa300f4bbf5bd\",\n                \"sha256:197dda3ffd02057820be83fe4d84529ea70bf39a9a4daee1d20ffc74eb3d042e\",\n                \"sha256:278ef63afb4b3d842b4609f2c05ffbfb76795cf6a184deeb8707cd5ed3c981a5\",\n                \"sha256:3cbf8c4fc8f22f0817220891cf405831559f4d4c12c4f73913730a2ea6c47a47\",\n                \"sha256:4305aed922c4d9d6163ab3a41d80b5a1cfab54917467da8168552c42cad84d32\",\n                \"sha256:47ee296f704fb8b2a616dec691cdcfd5fa0f11943955e88faa98cbd1dc3b3e3d\",\n                \"sha256:4a0e38cb30457e70580903367161173d4a7d1381eb2f2cfe4e69b7806623f484\",\n                \"sha256:4d6c294c6638a71cafb82a37f182f24321f1163b08b5d5ca076e11fe838a3086\",\n                \"sha256:4f3233c366500730f839f92833194fd8f9a5c4529c8cd8040aa162c3740de8e5\",\n                \"sha256:5221f5a3f4ca2ddf0d58e8b8a32ca50948be9a43351fda797eb4e72d7a7aa34d\",\n                \"sha256:5c6ca0b507540a11eaf9e77dee4f07c131c2ec80ca0cffa146671bf690bc1c02\",\n                \"sha256:789bd89d71d704db2b3d5e67d6d518b158985d791d3b2dec5ab85457cfc9677b\",\n                \"sha256:7b94d29239efeaa6a967f3b5971bd0518d2a24edd1511edbf4a2c8b815220d07\",\n                \"sha256:89bc65ef3301c74cf32db25334421ea6adbe8f65601ea45dcaaf095abed910bb\",\n                \"sha256:89d6d3a549f405c20c9ae4dc94d7ed2de2fa77427a470674490a622070732e62\",\n                \"sha256:97521704ac7127d7d8ba22877da3c7bf4a40366587d238ec679ff38e33177498\",\n                \"sha256:a395b62d5f44ff6f633231abe568e2203b8fabf9797cd6386aa92497df912d9a\",\n                \"sha256:a6d32c37f714c3f34158f3fa659f3a8f2658d5f53c4297d45579b9677cc4d852\",\n                \"sha256:a89ee5c26f72f2d0d74b991ce49e42ddeb4ac0dc2d8c06a0f2770a1ab48f4fe0\",\n                \"sha256:b4c8b0ef3608e59317bfc501df84a61e48b5445d45f24d0391a24802de5f2d84\",\n                \"sha256:b5fcf07140219a1f71e18486b8dc28e2e1b76a441c19374805c617aa6d9a9d55\",\n                \"sha256:b86f527f00956ecebad6ab3bb30e3a75fedf1160a8716978dd8ce7adddedd86f\",\n                \"sha256:be4c4aa22ba22f70de36c98b06480e2f1697972d49eb20d525f400d204a6d272\",\n                \"sha256:c2ac7aa1a144d4e0e613ac7286dae85671e99fe7a1353954d4905629c36b811c\",\n                \"sha256:de26ef4787b5e778e8223913a3e50368b44e7480f83c76df1f51d23bd21cea16\",\n                \"sha256:e70ebcfc5372dc7b699c0110454fc4263967f30c55454397e5769eb72c0eb0ce\",\n                \"sha256:eadbd32b6bc48b67b0457fccc94c86f7ccc8178ab839f684eb285bb592dc143e\",\n                \"sha256:ecbc6dfff6db06b8b72ae8a2f25ff20fbdcb83cb543811a08f7cb555042aa729\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.7.5\"\n        },\n        \"pycparser\": {\n            \"hashes\": [\n                \"sha256:99a8ca03e29851d96616ad0404b4aad7d9ee16f25c9f9708a11faf2810f7b226\"\n            ],\n            \"version\": \"==2.18\"\n        },\n        \"pyjwt\": {\n            \"hashes\": [\n                \"sha256:30b1380ff43b55441283cc2b2676b755cca45693ae3097325dea01f3d110628c\",\n                \"sha256:4ee413b357d53fd3fb44704577afac88e72e878716116270d722723d65b42176\"\n            ],\n            \"version\": \"==1.6.4\"\n        },\n        \"python-dateutil\": {\n            \"hashes\": [\n                \"sha256:1adb80e7a782c12e52ef9a8182bebeb73f1d7e24e374397af06fb4956c8dc5c0\",\n                \"sha256:e27001de32f627c22380a688bcc43ce83504a7bc5da472209b4c70f02829f0b8\"\n            ],\n            \"version\": \"==2.7.3\"\n        },\n        \"pytz\": {\n            \"hashes\": [\n                \"sha256:a061aa0a9e06881eb8b3b2b43f05b9439d6583c206d0a6c340ff72a7b6669053\",\n                \"sha256:ffb9ef1de172603304d9d2819af6f5ece76f2e85ec10692a524dd876e72bf277\"\n            ],\n            \"version\": \"==2018.5\"\n        },\n        \"requests\": {\n            \"hashes\": [\n                \"sha256:63b52e3c866428a224f97cab011de738c36aec0185aa91cfacd418b5d58911d1\",\n                \"sha256:ec22d826a36ed72a7358ff3fe56cbd4ba69dd7a6718ffd450ff0e9df7a47ce6a\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.19.1\"\n        },\n        \"requests-oauthlib\": {\n            \"hashes\": [\n                \"sha256:8886bfec5ad7afb391ed5443b1f697c6f4ae98d0e5620839d8b4499c032ada3f\",\n                \"sha256:e21232e2465808c0e892e0e4dbb8c2faafec16ac6dc067dd546e9b466f3deac8\"\n            ],\n            \"version\": \"==1.0.0\"\n        },\n        \"requests-toolbelt\": {\n            \"hashes\": [\n                \"sha256:42c9c170abc2cacb78b8ab23ac957945c7716249206f90874651971a4acff237\",\n                \"sha256:f6a531936c6fa4c6cfce1b9c10d5c4f498d16528d2a54a22ca00011205a187b5\"\n            ],\n            \"version\": \"==0.8.0\"\n        },\n        \"six\": {\n            \"hashes\": [\n                \"sha256:70e8a77beed4562e7f14fe23a786b54f6296e34344c23bc42f07b15018ff98e9\",\n                \"sha256:832dc0e10feb1aa2c68dcc57dbb658f1c7e65b9b61af69048abc87a2db00a0eb\"\n            ],\n            \"version\": \"==1.11.0\"\n        },\n        \"sqlalchemy\": {\n            \"hashes\": [\n                \"sha256:72325e67fb85f6e9ad304c603d83626d1df684fdf0c7ab1f0352e71feeab69d8\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==1.2.10\"\n        },\n        \"urllib3\": {\n            \"hashes\": [\n                \"sha256:a68ac5e15e76e7e5dd2b8f94007233e01effe3e50e8daddf69acfd81cb686baf\",\n                \"sha256:b5725a0bd4ba422ab0e66e89e030c806576753ea3ee08554382c14e685d117b5\"\n            ],\n            \"markers\": \"python_version != '3.0.*' and python_version != '3.3.*' and python_version != '3.1.*' and python_version != '3.2.*' and python_version &lt; '4' and python_version &gt;= '2.6'\",\n            \"version\": \"==1.23\"\n        }\n    },\n    \"develop\": {}\n}\n</code></pre><p><code>Pipfile.lock</code> is Python's very own equivalent to <code>package-lock.json</code>. With <code>Pipfile.lock</code> present, future developers need only to type the command <code>pipenv install</code> to install the exact dependencies in your project with all the correct versions. What's more, Pipfile.lock is actually a must-have for <strong>Heroku</strong> development, which uses this file to wisely produce environments upon deployment.</p><p>What about updating all packages past their locked version, you might ask? Check out the output of <code>pipenv update</code>, which updates all packages to their latest, and updates the corresponding .lock file accordingly:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-08-29_18-52-30.gif\" class=\"kg-image\"><figcaption>You had me at Snake emoji.</figcaption></figure><h2 id=\"when-to-use-conda-or-virtualenv\">When to Use Conda or Virtualenv</h2><p>If you're strictly in the data <em>science</em> profession, chances are that none of this nonsense interests you - you and all your friends are always working with the full Anaconda suite (which has its own similar environment manager), and you don't care for shipping products. You're a scientist, not some sort of blue collar data equivalent of manufacturing. </p><p>Even if you're engineer, <code>virtualenv</code> still has it's place. Take Lambda Functions in AWS for example: if you're looking to create a zip of dependencies to upload to your Lambda, it's much simpler to have those packages to live in your local working folder. </p><p>I'm sure you're itching to hear more on the topic of Python environment management, but the analytics say that 90% of readers have already bounced by this point. To the remaining 10%... you are all that I live for.</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p>","url":"https://hackersandslackers.com/pipenv-python-environment-management/","uuid":"0d7b1982-a0a4-4e69-abdb-ecca53665ed3","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b848c058d5a814c505a70b6"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736d8","title":"The End-to-End Guide to Handling Forms in Flask","slug":"guide-to-building-forms-in-flask","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/forms@2x.jpg","excerpt":"The subtle art of consensually capturing personal data.","custom_excerpt":"The subtle art of consensually capturing personal data.","created_at_pretty":"15 August, 2018","published_at_pretty":"15 August, 2018","updated_at_pretty":"09 April, 2019","created_at":"2018-08-14T22:13:40.000-04:00","published_at":"2018-08-15T06:25:00.000-04:00","updated_at":"2019-04-08T23:17:31.000-04:00","meta_title":"The End-to-End Guide to Handling Forms in Flask | Hackers And Slackers","meta_description":"Learn how to build complex form logic in Flask using the WTForms Python library! Cover the backend logic as well as best practices for form Jinja templates.","og_description":"Learn how to build complex form logic in Flask using the WTForms Python library! Cover the backend logic as well as best practices for form Jinja templates.","og_image":"https://hackersandslackers.com/content/images/2018/08/forms@2x.jpg","og_title":"The End-to-End Guide to Building Forms in Flask","twitter_description":"Learn how to build complex form logic in Flask using the WTForms Python library! Cover the backend logic as well as best practices for form Jinja templates.","twitter_image":"https://hackersandslackers.com/content/images/2018/08/forms@2x.jpg","twitter_title":"The End-to-End Guide to Building Forms in Flask","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"Happy Tuesday everybody! To start this week hot, let's talk about something that\neverybody hates: forms. The only thing more painful than filling out a web form\nis creating one, much less a functional one with feedback. Listen, if you're\ninto creating pleasant form UI experiences, you're probably into some freaky\nshit. Call me.\n\nFlask's youth is an advantage in one regard, in that there are only so many\nlibraries available to handle any given task. In this case, there's only one:\nthe aptly named WTForms.\n\nIf you don't have an immediate pressing need to create a Flask form and feel\nlike ditching this post to check out Instagram, be my guest, but know this:\nhandling form authentication, data submission, and session management is the\npinnacle of app development. This weird data collection traditional we\nexperience every day actually touches on nearly all aspects of app development.\nYou could argue that he who creates forms is a harbinger of a golden age: a hero\nwho brings us to the pinnacle of Western technology. Then again, there's always\nInstagram.\n\nThe Gist of it All\nBefore laying down some code snippets for you to mindlessly copy+paste, it helps\nto understand conceptually what we're about to throw down.\n\nAt a minimum, creating a form has us working routes, form  models, and templates\n. Since you already understand the concept of MVC, that entire last sentence was\nprobably redundant, and I should probably just delete it as opposed to\ncontinuing to write this second sentence contemplating my own redundancy. Oh\nwell.\n\nWe'll keep our routes in app.py  for a compact little app.\n\nmyproject\n├─ app.py\n├─ config.py\n├─ forms.py\n├─ db.py\n├─ /static\n│  ├─ /src\n│  │  ├─ js\n│  │  └─ less\n│  └─ /dist\n│     ├─ js\n│     ├─ css\n│     └─ img\n└─ /templates\n   └─ layout.html\n   └─ index.html\n   └─ form.html\n\n\nHere's the game plan: our form, with all its fields, labels, and potential error\nmessages, will live in forms.py. app.py  will contain the logic of not only\nrouting to the page serving the form, but also validating user input, which\ncovers anything from error checking to session creation. \n\nform.html  will be the presentation layer template which will get loaded into \nindex.html  in this case. Both of those templates are wrapped by layout.html \nwhich is basically just metadata and shit you already know — we’ve been through\nthis. Let’s start off by creating our forms.py.\n\nWhat The Form\nWTForms  has a nice little monopoly over the Python form handling industry\ndating back to Django, so at least we aren't burdened with choices here. Set up\nyour environment and let's install everything we need:\n\npipenv shell\npip3 install Flask WTForms Flask-Login\n\n\nThat'll hold us over for now. In forms.py,  we're going to do two main imports:\n\nfrom wtforms import Form, StringField, PasswordField, validators, SubmitField, SelectField\n\nfrom wtforms.validators import ValidationError, DataRequired, Email, EqualTo, Length\n\n\nForms really boil down into these two things: types of input, and validation of\nsaid input. There are plenty more fields and validators available, but this is\nwhat we'd need for a user signup form. Guess what we're making. \n\nClassy as Form\nForms in your app will always be defined 1-to-1 with a Python class declaration.\nIt's kind of like working with models, except they're forms. Just wait until\nyour forms work with models.\n\nfrom wtforms import Form, StringField, PasswordField, validators, SubmitField, SelectField\nfrom wtforms.validators import ValidationError, DataRequired, Email, EqualTo, Length\n\n\nclass SignupForm(Form):\n    \"\"\"User Signup Form.\"\"\"\n\n    name = StringField('Name', [\n        validators.DataRequired(message=('Don\\'t be shy!'))\n    ])\n    email = StringField('Email', [\n        Length(min=6, message=(u'Little short for an email address?')),\n        Email(message=('That\\'s not a valid email address.')),\n        DataRequired(message=('That\\'s not a valid email address.'))\n    ])\n    password = PasswordField('Password', validators=[\n        DataRequired(message=\"Please enter a password.\"),\n    ])\n    confirm = PasswordField('Repeat Password', validators=[\n            EqualTo(password, message='Passwords must match.')\n            ])\n    website = StringField('Website')\n    submit = SubmitField('Register')\n\n    def validate_email(self, email):\n        \"\"\"Email validation.\"\"\"\n        user = User.query.filter_by(email=email.data).first()\n        if user is not None:\n            raise ValidationError('Please use a different email address.')\n\n\nAs expected, every variable child of our class is a field. Field types are\ndeclared immediately (such as StringField()) and accept a label (name of the\nfield) as well as validators, which are conditions which must be met for the\nfield to be considered valid. A single field can accept an infinite number of\nvalidators, which would come in handy if you're a stickler for password\nsecurity. As well as setting the validators, we also set the error message to\npass to the user for that particular field if they are to submit invalid\ninformation. Fields accept other parameters as well, such as placeholder text,\nif you're interested in that side of things\n[https://wtforms.readthedocs.io/en/stable/fields.html#the-field-base-class].\n\nSome validators are more sophisticated enough to handle heavy-lifting: note how \nEmail()  is a validator in itself which handles the nonsense of looking for an\n'@' symbol (or whatever it is PHP guys did in the 90's). There’s even a regex\nvalidator available if you want to go full pro-mode.\n\nHardcore Validation XXX\nYou'll notice the example provided contains a validate_email()  function to\ncheck the database for a user record match. We can basically write any custom\nlogic we want to validate forms this way, in case the event that the standard\nvalidators just don't cut it.\n\nForming the Actual Form\nAlright, it's that time. Jinja's form handling isn't as daunting as this next\nwall of text might seem, once you get in the groove of things:\n\n{% block content %}\n<div class=\"formwrapper\">\n  <form method=post>\n    <div class=\"name\">\n      {{ form.name(placeholder='Joe Blah') }} {{ form.name.label }}\n      {% if form.name.errors %}\n        <ul class=\"errors\">{% for error in form.name.errors %}<li>{{ error }}</li>{% endfor %}</ul>\n      {% endif %}\n    </div>\n    <div class=\"email\">\n      {{ form.email }} {{ form.email.label }}\n      {% if form.email.errors %}\n        <ul class=\"errors\">{% for error in form.email.errors %}<li>{{ error }}</li>{% endfor %}</ul>\n      {% endif %}\n    </div>\n    <div class=\"password\">\n      {{ form.password }} {{ form.password.label }}\n      {% if form.password.errors %}\n        <ul class=\"errors\">{% for error in form.password.errors %}<li>{{ error }}</li>{% endfor %}</ul>\n      {% endif %}\n    </div>\n    <div class=\"confirm\">\n      {{ form.confirm }} {{ form.confirm.label }}\n      {% if form.confirm.errors %}\n        <ul class=\"errors\">{% for error in form.password.errors %}<li>{{ error }}</li>{% endfor %}</ul>\n      {% endif %}\n    </div>\n    <div class=\"website\">\n      {{ form.website(placeholder='http://example.com') }} {{ form.website.label }}\n    </div>\n    <div class=\"submitbutton\">\n      <input id=\"submit\" type=\"submit\" value=\"Submit\">\n    </div>\n  </form>\n</div>\n\n{% for message in get_flashed_messages() %}\n<div class=\"alert alert-warning\">\n    <button type=\"button\" class=\"close\" data-dismiss=\"alert\">&times;</button>\n    {{ message }}\n</div>\n{% endfor %}\n\n\nNotice that our form contains a method, but neither a destination nor an action.\nMore on that late.\n\nEach form field is pulling in three dynamic assets: the form itself, the display\nname, and a space reserved for error handling. This general layout is robust\nenough to handle returning multiple errors per field, which we obviously would\nprefer to keep in-line with the offending fields for UI purposes.\n\nAnother way of handling errors is by utilizing Flask's flash  module. A 'flash'\nis a temporary modal telling the user what they did wrong, which can be closed\nor simply expire after a number of seconds. We're using both forms of error\nhandling here for educational purposes, but you probably won't need to most of\nthe time.\n\nDrop Some Logic on These Fools\napp.py  contains the route to the form, which allows for both GET and POST \nmethods. Submitting a form in Flask cleverly routes the user to the page they're\nalready on. Depending on what the logic decides, the user will experience\neither: \n\n * Instant in-line errors, with no visible change of page.\n * A successful redirect to wherever they hoped the form would take them.\n\nfrom flask import Flask, url_for, render_template, Markup, redirect, request, flash\nfrom flask import session as login_session\nfrom forms import SignupForm\nimport config\nfrom models import User, users, login_manager\nfrom db import users_col\nimport logging\nimport sys\nimport json\n\n\napp = Flask(__name__, static_url_path='', static_folder=\"static\", template_folder=\"templates\")\ncompress = FlaskStaticCompress(app)\napp.config.from_object('config.Config')\n\n\n@app.route('/signup', methods=['GET', 'POST'])\ndef signup():\n    \"\"\"Signup Form.\"\"\"\n    signup_form = SignupForm()\n    if request.method == 'POST':\n        if signup_form.validate():\n            flash('Logged in successfully.')\n            return render_template('/dashboard.html', template=\"dashbord-template\")\n    return render_template('/signup.html', form=signup_form, template=\"form-page\")\n\n\nYou'll recognize SignupForm() as our good old buddy from forms.py  which has\nbeen imported here. Because the user submitted their form, they will experience\nthe page with everything that lives within if request.method == 'POST':  this\ntime around. Determining validation is as simple as the next line: if\nsignup_form.validate():. This one-liner will validate each field individually,\nand deliver the proper errors to the offending fields. This level of black magic\nsaves us a huge headache and actually means that creating additional forms in\nthe future won't be all that different from simply adjusting the class and\ntemplate we already made. All that negative form talk I dropped earlier was a\ntest. You passed.\n\nWhat happens next?\nAs you might infer from the conditional statements, the user will either\nsuccessfully complete the form and move on to the next page, or they might find\nthemselves in a Ancient Greek version of hell where they find themselves\nincorrectly filling out the same form forever. Sucks to suck.\n\nIf this were a real signup form, we'd handle user creation and database\ninteraction here as well. As great as that sounds, I'll save your time as I know\nyou still have an Instagram to check. Hats off to anybody who has made it\nthrough this rambling nonsense  - you deserve it.","html":"<p>Happy Tuesday everybody! To start this week hot, let's talk about something that everybody hates: forms. The only thing more painful than filling out a web form is creating one, much less a functional one with feedback. Listen, if you're into creating pleasant form UI experiences, you're probably into some freaky shit. Call me.</p><p>Flask's youth is an advantage in one regard, in that there are only so many libraries available to handle any given task. In this case, there's only one: the aptly named WTForms.</p><p>If you don't have an immediate pressing need to create a Flask form and feel like ditching this post to check out Instagram, be my guest, but know this: handling form authentication, data submission, and session management is the pinnacle of app development. This weird data collection traditional we experience every day actually touches on nearly all aspects of app development. You could argue that he who creates forms is a harbinger of a golden age: a hero who brings us to the pinnacle of Western technology. Then again, there's always Instagram.</p><h2 id=\"the-gist-of-it-all\">The Gist of it All</h2><p>Before laying down some code snippets for you to mindlessly copy+paste, it helps to understand conceptually what we're about to throw down.</p><p>At a minimum, creating a form has us working <strong>routes</strong>, form<strong> models</strong>, and <strong>templates</strong>. Since you already understand the concept of MVC, that entire last sentence was probably redundant, and I should probably just delete it as opposed to continuing to write this second sentence contemplating my own redundancy. Oh well.</p><p>We'll keep our routes in <code>app.py</code> for a compact little app.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">myproject\n├─ app.py\n├─ config.py\n├─ forms.py\n├─ db.py\n├─ /static\n│  ├─ /src\n│  │  ├─ js\n│  │  └─ less\n│  └─ /dist\n│     ├─ js\n│     ├─ css\n│     └─ img\n└─ /templates\n   └─ layout.html\n   └─ index.html\n   └─ form.html\n</code></pre>\n<!--kg-card-end: markdown--><p>Here's the game plan: our form, with all its fields, labels, and potential error messages, will live in <code>forms.py</code>. <code>app.py</code><strong> </strong>will contain the logic of not only routing to the page serving the form, but also validating user input, which covers anything from error checking to session creation. </p><p><code>form.html</code> will be the presentation layer template which will get loaded into <code>index.html</code> in this case. Both of those templates are wrapped by <code>layout.html</code> which is basically just metadata and shit you already know — we’ve been through this. Let’s start off by creating our <code>forms.py</code><strong>.</strong></p><h2 id=\"what-the-form\">What The Form</h2><p><code>WTForms</code> has a nice little monopoly over the Python form handling industry dating back to Django, so at least we aren't burdened with choices here. Set up your environment and let's install everything we need:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">pipenv shell\npip3 install Flask WTForms Flask-Login\n</code></pre>\n<!--kg-card-end: markdown--><p>That'll hold us over for now. In <code>forms.py</code><strong>,</strong> we're going to do two main imports:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from wtforms import Form, StringField, PasswordField, validators, SubmitField, SelectField\n\nfrom wtforms.validators import ValidationError, DataRequired, Email, EqualTo, Length\n</code></pre>\n<!--kg-card-end: markdown--><p>Forms really boil down into these two things: types of input, and validation of said input. There are plenty more fields and validators available, but this is what we'd need for a user signup form. Guess what we're making. </p><h3 id=\"classy-as-form\">Classy as Form</h3><p>Forms in your app will always be defined 1-to-1 with a Python class declaration. It's kind of like working with models, except they're forms. Just wait until your forms work with models.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from wtforms import Form, StringField, PasswordField, validators, SubmitField, SelectField\nfrom wtforms.validators import ValidationError, DataRequired, Email, EqualTo, Length\n\n\nclass SignupForm(Form):\n    &quot;&quot;&quot;User Signup Form.&quot;&quot;&quot;\n\n    name = StringField('Name', [\n        validators.DataRequired(message=('Don\\'t be shy!'))\n    ])\n    email = StringField('Email', [\n        Length(min=6, message=(u'Little short for an email address?')),\n        Email(message=('That\\'s not a valid email address.')),\n        DataRequired(message=('That\\'s not a valid email address.'))\n    ])\n    password = PasswordField('Password', validators=[\n        DataRequired(message=&quot;Please enter a password.&quot;),\n    ])\n    confirm = PasswordField('Repeat Password', validators=[\n            EqualTo(password, message='Passwords must match.')\n            ])\n    website = StringField('Website')\n    submit = SubmitField('Register')\n\n    def validate_email(self, email):\n        &quot;&quot;&quot;Email validation.&quot;&quot;&quot;\n        user = User.query.filter_by(email=email.data).first()\n        if user is not None:\n            raise ValidationError('Please use a different email address.')\n</code></pre>\n<!--kg-card-end: markdown--><p>As expected, every variable child of our class is a field. Field types are declared immediately (such as StringField()) and accept a <em>label </em>(name of the field) as well as <em>validators</em>, which are conditions which must be met for the field to be considered valid. A single field can accept an infinite number of validators, which would come in handy if you're a stickler for password security. As well as setting the validators, we also set the error message to pass to the user for that particular field if they are to submit invalid information. Fields accept other parameters as well, such as placeholder text, if you're interested in <a href=\"https://wtforms.readthedocs.io/en/stable/fields.html#the-field-base-class\">that side of things</a>.</p><p>Some validators are more sophisticated enough to handle heavy-lifting: note how <em>Email()</em> is a validator in itself which handles the nonsense of looking for an '@' symbol (or whatever it is PHP guys did in the 90's). There’s even a regex validator available if you want to go full pro-mode.</p><h3 id=\"hardcore-validation-xxx\">Hardcore Validation XXX</h3><p>You'll notice the example provided contains a <strong>validate_email()</strong> function to check the database for a user record match. We can basically write any custom logic we want to validate forms this way, in case the event that the standard validators just don't cut it.</p><h2 id=\"forming-the-actual-form\">Forming the Actual Form</h2><p>Alright, it's that time. Jinja's form handling isn't as daunting as this next wall of text might seem, once you get in the groove of things:</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">{% block content %}\n&lt;div class=&quot;formwrapper&quot;&gt;\n  &lt;form method=post&gt;\n    &lt;div class=&quot;name&quot;&gt;\n      {{ form.name(placeholder='Joe Blah') }} {{ form.name.label }}\n      {% if form.name.errors %}\n        &lt;ul class=&quot;errors&quot;&gt;{% for error in form.name.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}&lt;/ul&gt;\n      {% endif %}\n    &lt;/div&gt;\n    &lt;div class=&quot;email&quot;&gt;\n      {{ form.email }} {{ form.email.label }}\n      {% if form.email.errors %}\n        &lt;ul class=&quot;errors&quot;&gt;{% for error in form.email.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}&lt;/ul&gt;\n      {% endif %}\n    &lt;/div&gt;\n    &lt;div class=&quot;password&quot;&gt;\n      {{ form.password }} {{ form.password.label }}\n      {% if form.password.errors %}\n        &lt;ul class=&quot;errors&quot;&gt;{% for error in form.password.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}&lt;/ul&gt;\n      {% endif %}\n    &lt;/div&gt;\n    &lt;div class=&quot;confirm&quot;&gt;\n      {{ form.confirm }} {{ form.confirm.label }}\n      {% if form.confirm.errors %}\n        &lt;ul class=&quot;errors&quot;&gt;{% for error in form.password.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}&lt;/ul&gt;\n      {% endif %}\n    &lt;/div&gt;\n    &lt;div class=&quot;website&quot;&gt;\n      {{ form.website(placeholder='http://example.com') }} {{ form.website.label }}\n    &lt;/div&gt;\n    &lt;div class=&quot;submitbutton&quot;&gt;\n      &lt;input id=&quot;submit&quot; type=&quot;submit&quot; value=&quot;Submit&quot;&gt;\n    &lt;/div&gt;\n  &lt;/form&gt;\n&lt;/div&gt;\n\n{% for message in get_flashed_messages() %}\n&lt;div class=&quot;alert alert-warning&quot;&gt;\n    &lt;button type=&quot;button&quot; class=&quot;close&quot; data-dismiss=&quot;alert&quot;&gt;&amp;times;&lt;/button&gt;\n    {{ message }}\n&lt;/div&gt;\n{% endfor %}\n</code></pre>\n<!--kg-card-end: markdown--><p>Notice that our form contains a method, but neither a destination nor an action. More on that late.</p><p>Each form field is pulling in three dynamic assets: the form itself, the display name, and a space reserved for error handling. This general layout is robust enough to handle returning multiple errors per field, which we obviously would prefer to keep in-line with the offending fields for UI purposes.</p><p>Another way of handling errors is by utilizing Flask's <em>flash</em> module. A 'flash' is a temporary modal telling the user what they did wrong, which can be closed or simply expire after a number of seconds. We're using both forms of error handling here for educational purposes, but you probably won't need to most of the time.</p><h2 id=\"drop-some-logic-on-these-fools\">Drop Some Logic on These Fools</h2><p><code>app.py</code> contains the route to the form, which allows for both <strong>GET </strong>and <strong>POST</strong> methods. Submitting a form in Flask cleverly routes the user to the <em>page they're already on. </em>Depending on what the logic decides, the user will experience either: </p><ul><li>Instant in-line errors, with no visible change of page.</li><li>A successful redirect to wherever they hoped the form would take them.</li></ul><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask, url_for, render_template, Markup, redirect, request, flash\nfrom flask import session as login_session\nfrom forms import SignupForm\nimport config\nfrom models import User, users, login_manager\nfrom db import users_col\nimport logging\nimport sys\nimport json\n\n\napp = Flask(__name__, static_url_path='', static_folder=&quot;static&quot;, template_folder=&quot;templates&quot;)\ncompress = FlaskStaticCompress(app)\napp.config.from_object('config.Config')\n\n\n@app.route('/signup', methods=['GET', 'POST'])\ndef signup():\n    &quot;&quot;&quot;Signup Form.&quot;&quot;&quot;\n    signup_form = SignupForm()\n    if request.method == 'POST':\n        if signup_form.validate():\n            flash('Logged in successfully.')\n            return render_template('/dashboard.html', template=&quot;dashbord-template&quot;)\n    return render_template('/signup.html', form=signup_form, template=&quot;form-page&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>You'll recognize SignupForm() as our good old buddy from <code>forms.py</code> which has been imported here. Because the user submitted their form, they will experience the page with everything that lives within <code>if request.method == 'POST':</code> this time around. Determining validation is as simple as the next line: <code>if signup_form.validate():</code>. This one-liner will validate each field individually, and deliver the proper errors to the offending fields. This level of black magic saves us a huge headache and actually means that creating additional forms in the future won't be all that different from simply adjusting the class and template we already made. All that negative form talk I dropped earlier was a test. You passed.</p><h3 id=\"what-happens-next\">What happens next?</h3><p>As you might infer from the conditional statements, the user will either successfully complete the form and move on to the next page, or they might find themselves in a Ancient Greek version of hell where they find themselves incorrectly filling out the same form forever. Sucks to suck.</p><p>If this were a real signup form, we'd handle user creation and database interaction here as well. As great as that sounds, I'll save your time as I know you still have an Instagram to check. Hats off to anybody who has made it through this rambling nonsense  - you deserve it.</p>","url":"https://hackersandslackers.com/guide-to-building-forms-in-flask/","uuid":"7cb4b740-9bda-4d96-a28d-83487d6581ce","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b738c54c43a944face384b1"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ca","title":"PostgreSQL Cloud Database on Google Cloud","slug":"cloud-sql-postgres-on-gcp","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/postgres4.jpg","excerpt":"Deep Dive into Cloud SQL and its out-of-the-box API.","custom_excerpt":"Deep Dive into Cloud SQL and its out-of-the-box API.","created_at_pretty":"09 August, 2018","published_at_pretty":"10 August, 2018","updated_at_pretty":"28 February, 2019","created_at":"2018-08-09T12:49:05.000-04:00","published_at":"2018-08-10T05:52:00.000-04:00","updated_at":"2019-02-27T23:37:34.000-05:00","meta_title":"Cloud-Hosted Postgres on Google Cloud | Hackers and Slackers","meta_description":"A sexy relational database on the hottest cloud provider on the market is hard to resist. Especially when it comes with a REST API.","og_description":"A sexy relational database on the hottest cloud provider on the market is hard to resist. Especially when it comes with a REST API.\n\n#Postgres #GoogleCloud #Databases","og_image":"https://hackersandslackers.com/content/images/2019/02/postgres4.jpg","og_title":"Cloud SQL Postgres on GCP","twitter_description":"A sexy relational database on the hottest cloud provider on the market is hard to resist. Especially when it comes with a REST API.\n\n#Postgres #GoogleCloud #Databases\n\n","twitter_image":"https://hackersandslackers.com/content/images/2019/02/postgres4.jpg","twitter_title":"Cloud SQL Postgres on GCP","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"PostgreSQL","slug":"postgresql","description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","feature_image":null,"meta_description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","meta_title":"Working with PostgreSQL | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"}],"plaintext":"Well folks, I have a confession to make. I've been maintaining an affair with\ntwo lovers. That's right; they're none other than PostgreSQL, and Google Cloud.\nWhile such polygamy may be shunned by the masses, I believe that somehow, some\nway, we can just make this ménage à trois work. What entices me about Cloud SQL\nis the existence of the Cloud SQL API\n[https://cloud.google.com/sql/docs/postgres/admin-api/]  , which generates\npredictable REST endpoints for presumably reading and writing to your database.\nPlease allow a moment of silence for the old workflow of API Gateways and Lambda\nfunctions. RIP.\n\nWe’ll get to APIs eventually, but for now we have one glaring obstacle: creating\nour DB, and connecting to it in a way vaguely resembles something secure*.\n\nNote: today may or may not be opposite day.Creating Our Cloud Database\nHit up the Cloud SQL [https://console.cloud.google.com/sql/]  section of your\nconsole to get this party started. Database creation on GCP is surprisingly\neasy.\n\nThat's pretty much it tbh.Databases Gone Wild: Postgres Exposed\nThere are plenty of correct ways to connect to your Postgres database correctly\nand securely. You can set up SSL for an IP\n[https://cloud.google.com/sql/docs/postgres/connect-admin-ip], connect using a\nproxy [https://cloud.google.com/sql/docs/postgres/connect-admin-proxy], or even\nvia internal cloud functions\n[https://cloud.google.com/sql/docs/postgres/connect-cloud-functions]. You may\nwant to consider doing one of those things. I'll be doing this a different way,\nbecause I'd rather get my useless data on a hackable public database than\nrewrite Google tutorials:\n\nDo as I say, not as I do.This is where you can feel free to go ahead and\npopulate data into your DB via whichever GUI you'd prefer. It'll be easier to\nsee which API calls work if there's actual data involved.\n\nPick whichever overpriced client suits you best!Enabling the API\nAs always with GCP, we need to explicitly activate the API for SQL; that way,\nthey can charge us money forever, long after we've forgotten this tutorial. We\ncan do this here\n[https://console.cloud.google.com/flows/enableapi?apiid=sqladmin]. Are you\nstarting to feel excited? I know I am; just think, all those API calls right\naround the corner, coming from a real SQL database. Wow. \n\nIn the overall process, we've made it here: the part where we run into OAuth2:\n\nRefresh tokens? Scopes? Uh oh.I'll admit it took me a good amount of time to\ndecrypt the information which failed to conveyed here. After clicking into every\nrelated link and failing at attempts to hit the API via Postman, the bad vibes\nstarted kicking in. What if this isn't the dream after all? To spare you the\nprocess, let me introduce you to a very useful GCP tool.\n\nGoogle API Explorer\nGoogle's API explorer is a GUI for playing with any API, connected to any of\nyour services. This is a cool way to preview what the exact scope of an API is\nbefore you sign up for it. Better yet, you can use placeholder User_IDs  and \nUser_Secrets  since this is basically just a sandbox.\n\nInteractive API learning tools beat reading documentation any day.After\nselecting an 'endpoint' and specifying some details like your project and\ndatabase instance, you can immediately see (theoretical) results of what the\nlive API can do. This is very useful, but I'm afraid this is where things get\ndark.\n\nHello Darkness My Old Friend\nYou may have noticed a lot of similar words or phrases popping up in these\nendpoints. Words such as \"admin\"  and \"list\", while lacking phrases such as \n\"show me my god damn data\". Google's Cloud SQL API  is NOT, in fact, an API to\ninteract with your data, but rather an admin API which enables you to do things\nprobably better suited for, you know, admin consoles.\n\nAs a big fan of GCP, this is but one of a number of growing pains I've\nexperienced with the platform so far. For instance, this entire blog along with\nits VPC has temporary deleted today, because apparently the phrases \"remove my\nproject from Firebase\"  and \"delete my project along with everything I love\" are\nsentimentally similar enough to leave that language vague and awkward.\n\nWhere Do We Go From Here?\nTo reiterate, the problem we were originally looking to solve was to find a\nservice which could (after what, 30 years?) make relational database reading and\nwriting trivial, especially in the case of apps which are simply themes without\na configurable backend, such as this blog.\n\nMongoDB Atlas  is an organizational mess which can't even describe their own\nproduct. Firebase  has yet to implement an import feature, so unless you feel\nlike writing loops to write to an experimental NoSQL database (I don't), we're\nstill kind of screwed. I know there are guys like Dreamfactory out there, but\nthese services are the sketchy ones who email you every day just for looking at\na trial. Also, anything related to Oracle or running on Oracle products (by\nchoice) sucks. There, I said it. Java developers will probably be too bust with\ngarbage collection and getting sued to argue with me anyway.\n\nAll that said, it feels like the \"Backend as a service\" thing is looming over\nthe horizon. There just doesn't seem to be anybody who's executed this\neffectively yet.\n\nUPDATE:  As it turns out, there is a service out there that accomplishes\neverything we hoped to achieve in Google cloud, and it is called Apisentris\n[https://apisentris.com/]. It's awesome, it's free, and the guy behind it is a\nchill dude.","html":"<p>Well folks, I have a confession to make. I've been maintaining an affair with two lovers. That's right; they're none other than PostgreSQL, and Google Cloud. While such polygamy may be shunned by the masses, I believe that somehow, some way, we can just make this ménage à trois work. What entices me about Cloud SQL is the existence of the <a href=\"https://cloud.google.com/sql/docs/postgres/admin-api/\">Cloud SQL API</a> , which generates predictable REST endpoints for presumably reading and writing to your database. Please allow a moment of silence for the old workflow of API Gateways and Lambda functions. RIP.</p><p>We’ll get to APIs eventually, but for now we have one glaring obstacle: creating our DB, and connecting to it in a way vaguely resembles something secure*.</p><span style=\"color: #669ab5; font-style: italic; font-size: 15px; float: right;\">Note: today may or may not be opposite day.</span><h2 id=\"creating-our-cloud-database\">Creating Our Cloud Database</h2><p>Hit up the <a href=\"https://console.cloud.google.com/sql/\">Cloud SQL</a> section of your console to get this party started. Database creation on GCP is surprisingly easy.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/setuppostgres.png\" class=\"kg-image\"><figcaption>That's pretty much it tbh.</figcaption></figure><h2 id=\"databases-gone-wild-postgres-exposed\">Databases Gone Wild: Postgres Exposed  </h2><p>There are plenty of <em>correct </em>ways to connect to your Postgres database correctly and securely. You can <a href=\"https://cloud.google.com/sql/docs/postgres/connect-admin-ip\">set up SSL for an IP</a>, connect <a href=\"https://cloud.google.com/sql/docs/postgres/connect-admin-proxy\">using a proxy</a>, or even via internal <a href=\"https://cloud.google.com/sql/docs/postgres/connect-cloud-functions\">cloud functions</a>. You may want to consider doing one of those things. I'll be doing this a different way, because I'd rather get my useless data on a hackable public database than rewrite Google tutorials:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/public.png\" class=\"kg-image\"><figcaption>Do as I say, not as I do.</figcaption></figure><p>This is where you can feel free to go ahead and populate data into your DB via whichever GUI you'd prefer. It'll be easier to see which API calls work if there's actual data involved.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-08-10-at-4.15.22-AM.png\" class=\"kg-image\"><figcaption>Pick whichever overpriced client suits you best!</figcaption></figure><h2 id=\"enabling-the-api\">Enabling the API</h2><p>As always with GCP, we need to explicitly activate the API for SQL; that way, they can charge us money forever, long after we've forgotten this tutorial. We can do this <a href=\"https://console.cloud.google.com/flows/enableapi?apiid=sqladmin\">here</a>. Are you starting to feel excited? I know I am; just think, all those API calls right around the corner, coming from a real SQL database. Wow. </p><p>In the overall process, we've made it <em>here</em>: the part where we run into OAuth2:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-08-10-at-4.21.55-AM.png\" class=\"kg-image\"><figcaption>Refresh tokens? Scopes? Uh oh.</figcaption></figure><p>I'll admit it took me a good amount of time to decrypt the information which failed to conveyed here. After clicking into every related link and failing at attempts to hit the API via Postman, the bad vibes started kicking in. What if this isn't the dream after all? To spare you the process, let me introduce you to a very useful GCP tool.</p><h2 id=\"google-api-explorer\">Google API Explorer</h2><p>Google's API explorer is a GUI for playing with any API, connected to any of your services. This is a cool way to preview what the exact scope of an API is before you sign up for it. Better yet, you can use placeholder <em>User_IDs</em> and <em>User_Secrets</em> since this is basically just a sandbox.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sandbox.gif\" class=\"kg-image\"><figcaption>Interactive API learning tools beat reading documentation any day.</figcaption></figure><p>After selecting an 'endpoint' and specifying some details like your project and database instance, you can immediately see (theoretical) results of what the live API can do. This is very useful, but I'm afraid this is where things get dark.</p><h3 id=\"hello-darkness-my-old-friend\">Hello Darkness My Old Friend</h3><p>You may have noticed a lot of similar words or phrases popping up in these endpoints. Words such as <em>\"admin\"</em> and \"<em>list\"</em>, while lacking phrases such as <em>\"show me my god damn data\". </em>Google's <strong>Cloud SQL API</strong> is NOT, in fact, an API to interact with your data, but rather an <em>admin </em>API which enables you to do things probably better suited for, you know, admin consoles.</p><p>As a big fan of GCP, this is but one of a number of growing pains I've experienced with the platform so far. For instance, this entire blog along with its VPC has temporary deleted today, because apparently the phrases <em>\"remove my project from Firebase\"</em> and <em>\"delete my project along with everything I love\" </em>are sentimentally similar enough to leave that language vague and awkward.</p><h2 id=\"where-do-we-go-from-here\">Where Do We Go From Here?</h2><p>To reiterate, the problem we were originally looking to solve was to find a service which could (after what, 30 years?) make relational database reading and writing trivial, especially in the case of apps which are simply themes without a configurable backend, such as this blog.</p><p><em>MongoDB Atlas</em> is an organizational mess which can't even describe their own product. <em>Firebase</em> has yet to implement an import feature, so unless you feel like writing loops to write to an experimental NoSQL database (I don't), we're still kind of screwed. I know there are guys like <em>Dreamfactory </em>out there, but these services are the sketchy ones who email you every day just for looking at a trial. Also, anything related to Oracle or running on Oracle products (by choice) sucks. There, I said it. Java developers will probably be too bust with garbage collection and getting sued to argue with me anyway.</p><p>All that said, it feels like the \"Backend as a service\" thing is looming over the horizon. There just doesn't seem to be anybody who's executed this effectively yet.</p><p><strong>UPDATE:</strong> As it turns out, there is a service out there that accomplishes everything we hoped to achieve in Google cloud, and it is called <a href=\"https://apisentris.com/\">Apisentris</a>. It's awesome, it's free, and the guy behind it is a chill dude.</p>","url":"https://hackersandslackers.com/cloud-sql-postgres-on-gcp/","uuid":"76daacf1-55b4-4ede-b21d-29fd727e1d50","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b6c70819dcd9d3270b58635"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c7","title":"Hacking Tableau to Handle ETL Workflows","slug":"turning-tableau-into-an-etl-tool-using-the-rest-api","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/fucktableau@2x.jpg","excerpt":"Weaponizing APIs against tyrannical software.","custom_excerpt":"Weaponizing APIs against tyrannical software.","created_at_pretty":"01 August, 2018","published_at_pretty":"03 August, 2018","updated_at_pretty":"28 February, 2019","created_at":"2018-08-01T08:49:36.000-04:00","published_at":"2018-08-03T08:57:00.000-04:00","updated_at":"2019-02-28T03:18:22.000-05:00","meta_title":"Hacking Tableau to Handle ETL Workflows | Hackers and Slackers","meta_description":"The presence of ETL as an acronym is a perfect reflection of where we are in data engineering's growth trajectory. ","og_description":"The presence of ETL as an acronym is a perfect reflection of where we are in data engineering's growth trajectory. The lack of effective Extract, Transform, and Load workflow products tell us a couple things: we have too many data sources (whether they be APIs or private data sets), and the raw data is virtually unusable until cleaned.","og_image":"https://hackersandslackers.com/content/images/2018/08/fucktableau@2x.jpg","og_title":"Hacking Tableau to Handle ETL Workflows","twitter_description":"The lack of effective Extract, Transform, and Load workflow products tell us a couple things: we have too many data sources, and the raw data is virtually unusable until cleaned.","twitter_image":"https://hackersandslackers.com/content/images/2018/08/fucktableau@2x.jpg","twitter_title":"Hacking Tableau to Handle ETL Workflows","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Hacking Tableau Server","slug":"hacking-tableau-server","description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauseries-2.jpg","meta_description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","meta_title":"Hacking Tableau Server","visibility":"internal"}],"plaintext":"Before we get into the specifics of how to sadistically abuse Tableau, let's\nclear the air: there's something about inaccessible, expensive, proprietary\nenterprise software that tends to put me in a touchy mood. As we know, B2B\nsoftware pricing has nothing to do with code quality or even value-add, but\nrather the tendency of businesses to create time-based urgencies without\nwarning; the kinds of urgencies which may be solved by, say, a tool of sorts.\n\nMy first interaction with Tableau actually took place after I had committed\nmyself to the cult of Python's Pandas library and all that comes with it.\nTableau does little to hide the fact that it is a GUI for data manipulation and\nSQL queries; in most cases, the calculation syntax is exactly the same. From my\nperspective, Tableau could be a tool to save time: instead of rewriting\nvariations of the same scripts over and over, I could use Tableau to do these\ntasks visually for both speed and transparency's sake. It was a win-win for\ntrivial tasks, except for one: the ability to write back to a database. You'd\nthink I wouldn't think that far ahead before purchasing my own Tableau server\nand license, conveniently billed upfront annually.\n\nThe Rise of ETL\nThe presence of ETL as an acronym is a perfect reflection of where we are in\ndata engineering's growth trajectory. The lack of effective Extract, Transform,\nand Load  workflow products tell us a couple things: we have too many data\nsources (whether they be APIs or private data sets), and the raw data is\nvirtually unusable until cleaned. This process could be relatively trivial with\nthe right software. There are plenty of contenders to make this process simple,\nand I'd like to express in unadulterated astonishment that they are all  failing\nmiserably  at solving this task effectively, mostly thanks to poor decision\nmaking and human error alone.\n\nThe ETL Market\nAs it stands, Parabola.io  tops my list of ETL products. Parabola hits the nail\non the head when it comes to UI and ease of use. This begs the question: why,\nthen, are their latest releases focused on support for extraction to garbage\nproducts like Smartsheet? Currently the only extract location which is actually\na database  is MySQL. As much as I want Parabola to succeed, nothing has\nimproved if our workflow still involves manually setting up a third party DB\nwith a schema which perfectly matches our output.\n\nGoogle Cloud is doing its best to somehow tie separate products together such as\n Dataprep  and Bigquery. We'll see how that goes- there's no mention of data\nextraction from APIs in this flow just yet. We might be waiting for some time\nfor Google's perfect answer to mature.\n\nGithub Labs supposedly just announced recent efforts to tackle this space as\nwell with the upcoming Melatano\n[https://about.gitlab.com/2018/08/01/hey-data-teams-we-are-working-on-a-tool-just-for-you/]\n. Hopefully they have their heads on straight.\n\nAnyway, since the world has failed us, we'll just exploit a Tableau backdoor to\ndo this while humanity catches up.\n\nTableau's Rest API\nAs hard as Tableau tries to obfuscate anything and everything, their REST API\ngets us exactly what we want after a bit of red tape. We need to run 3 API\ncalls:\n\n * POST /api/[api-version]/auth/signin: Generate a token so we can actually use\n   the API\n * GET /api/3.0/sites/[site-id]/views:  List all view metadata in a Tableau\n   \"site.\"\n * GET /api/3.0/sites/[site-id]/views/[view-id]/data: Receive a comma\n   delimitated response of the content of your target view\n\nWhat R U Token about\nTo receive our token, we'll use basic auth to hit this simple endpoint via POST:\n \n\nPOST http://mywebsite/api/3.0/auth/signin\n\n\nThe response will come in the form of XML and give us two critical items: our \ntoken, and our site ID:\n\nClearly a user-friendly experience.List Views by Site\nNext up we're GETing the following endpoint:\n\nhttp://mywebsite/api/3.0/sites/543fc0-4123572-483276-9345d8c-96005d532b2fb33/views\n\n\nNote that Tableau asks for the site ID from the previous response to be part of\nthe URL string.\n\nWe'll also need to set headers, so do that.\n\nX-Tableau-Auth: SPMJsdfgHIDUFihdwPqf-5k8GCZJA|sXhFBHzzqksB6K567fsQvtCfTtakqrJLuQ6Cf\n\n\nThe motherload of views.Reap your Reward\nPick the notebook ID you're looking to extract data from. Chose wisely. Your\ntime now. Enter that view into the final endpoint URL:\n\nhttp://mysite/api/3.0/sites/983445c0-4172-4876-9d8c-96005db2gfdgdfb33/views/c0357db9-71b1-4besdfgd1-a14e-5a5f7a36d410/data\n\n\nWhoa mama.Well, Well, Well.\nSo now you know how to generate a Tableau REST API token at will. You also know\nall your view IDs, and how to extract the data from any of those views in a\nfriendly CSV format which happens to play nice with databases. There's a Pandas\nscript waiting to be written here somewhere.\n\nAt this point, you know have all the tools you need to automate the systematic\npillaging of your Tableau Server data. Take a brief moment to remember the days\nwhen Tableau would wave their flags through the countryside as a sign of\ntaunting warfare. They've collected your company's checks and gave you iFrames\nin return.\n\nGo onwards my brethren. For one chance, discover the lands of Plot.ly and D3 as\nFree Men. They may take our paychecks, but they will never take our data.","html":"<p>Before we get into the specifics of how to sadistically abuse Tableau, let's clear the air: there's something about inaccessible, expensive, proprietary enterprise software that tends to put me in a touchy mood. As we know, B2B software pricing has nothing to do with code quality or even value-add, but rather the tendency of businesses to create time-based urgencies without warning; the kinds of urgencies which may be solved by, say, a tool of sorts.</p><p>My first interaction with Tableau actually took place after I had committed myself to the cult of Python's Pandas library and all that comes with it. Tableau does little to hide the fact that it is a GUI for data manipulation and SQL queries; in most cases, the calculation syntax is exactly the same. From my perspective, Tableau could be a tool to save time: instead of rewriting variations of the same scripts over and over, I could use Tableau to do these tasks visually for both speed and transparency's sake. It was a win-win for trivial tasks, except for one: the ability to write back to a database. You'd think I wouldn't think that far ahead before purchasing my own Tableau server and license, conveniently billed upfront annually.</p><h2 id=\"the-rise-of-etl\">The Rise of ETL</h2><p>The presence of ETL as an acronym is a perfect reflection of where we are in data engineering's growth trajectory. The lack of effective <strong>Extract, Transform, and Load</strong> workflow products tell us a couple things: we have too many data sources (whether they be APIs or private data sets), and the raw data is virtually unusable until cleaned. This process could be relatively trivial with the right software. There are plenty of contenders to make this process simple, and I'd like to express in unadulterated astonishment that they are all<strong> failing miserably</strong> at solving this task effectively, mostly thanks to poor decision making and human error alone.</p><h3 id=\"the-etl-market\">The ETL Market</h3><p>As it stands, <a href=\"Parabola.io\">Parabola.io</a> tops my list of ETL products. Parabola hits the nail on the head when it comes to UI and ease of use. This begs the question: why, then, are their latest releases focused on support for extraction to garbage products like <strong>Smartsheet</strong>? Currently the only extract location which is <em>actually a database</em> is MySQL. As much as I want Parabola to succeed, nothing has improved if our workflow still involves manually setting up a third party DB with a schema which perfectly matches our output.</p><p>Google Cloud is doing its best to somehow tie separate products together such as <strong>Dataprep</strong> and <strong>Bigquery</strong>. We'll see how that goes- there's no mention of data extraction from APIs in this flow just yet. We might be waiting for some time for Google's perfect answer to mature.</p><p>Github Labs supposedly just announced recent efforts to tackle this space as well with the upcoming <a href=\"https://about.gitlab.com/2018/08/01/hey-data-teams-we-are-working-on-a-tool-just-for-you/\">Melatano</a>. Hopefully they have their heads on straight.</p><p>Anyway, since the world has failed us, we'll just exploit a Tableau backdoor to do this while humanity catches up.</p><h2 id=\"tableau-s-rest-api\">Tableau's Rest API</h2><p>As hard as Tableau tries to obfuscate anything and everything, their REST API gets us exactly what we want after a bit of red tape. We need to run 3 API calls:</p><ul><li><strong>POST /api/[<em>api-version]</em>/auth/signin</strong>: Generate a token so we can actually use the API</li><li><strong>GET /api/3.0/sites/[site-id]/views</strong>:<strong> </strong>List all view metadata in a Tableau \"site.\"</li><li><strong>GET /api/3.0/sites/[site-id]/views/[view-id]/data</strong>: Receive a comma delimitated response of the content of your target view</li></ul><h3 id=\"what-r-u-token-about\">What R U Token about</h3><p>To receive our token, we'll use basic auth to hit this simple endpoint via POST: </p><pre><code class=\"language-shell\">POST http://mywebsite/api/3.0/auth/signin\n</code></pre>\n<p>The response will come in the form of XML and give us two critical items: our <strong>token</strong>, and our <strong>site ID</strong>:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-08-03-at-7.50.59-AM.png\" class=\"kg-image\"><figcaption>Clearly a user-friendly experience.</figcaption></figure><h3 id=\"list-views-by-site\">List Views by Site</h3><p>Next up we're GETing the following endpoint:</p><pre><code class=\"language-shell\">http://mywebsite/api/3.0/sites/543fc0-4123572-483276-9345d8c-96005d532b2fb33/views\n</code></pre>\n<p>Note that Tableau asks for the <strong>site ID </strong>from the previous response to be part of the URL string.</p><p>We'll also need to set headers, so do that.</p><pre><code class=\"language-shell\">X-Tableau-Auth: SPMJsdfgHIDUFihdwPqf-5k8GCZJA|sXhFBHzzqksB6K567fsQvtCfTtakqrJLuQ6Cf\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-08-03-at-7.57.47-AM.png\" class=\"kg-image\"><figcaption>The motherload of views.</figcaption></figure><h3 id=\"reap-your-reward\">Reap your Reward</h3><p>Pick the notebook ID you're looking to extract data from. Chose wisely. Your time now. Enter that view into the final endpoint URL:</p><pre><code class=\"language-shell\">http://mysite/api/3.0/sites/983445c0-4172-4876-9d8c-96005db2gfdgdfb33/views/c0357db9-71b1-4besdfgd1-a14e-5a5f7a36d410/data\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-08-03-at-8.01.24-AM.png\" class=\"kg-image\"><figcaption>Whoa mama.</figcaption></figure><h2 id=\"well-well-well-\">Well, Well, Well.</h2><p>So now you know how to generate a Tableau REST API token at will. You also know all your view IDs, and how to extract the data from any of those views in a friendly CSV format which happens to play nice with databases. There's a Pandas script waiting to be written here somewhere.</p><p>At this point, you know have all the tools you need to automate the systematic pillaging of your Tableau Server data. Take a brief moment to remember the days when Tableau would wave their flags through the countryside as a sign of taunting warfare. They've collected your company's checks and gave you iFrames in return.</p><p>Go onwards my brethren. For one chance, discover the lands of Plot.ly and D3 as Free Men. They may take our paychecks, but they will <strong>never </strong>take our data.</p>","url":"https://hackersandslackers.com/turning-tableau-into-an-etl-tool-using-the-rest-api/","uuid":"7b86dd9c-7d93-4518-8f3a-b593a6cdb7f0","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b61ac60d2852c0dc51d9217"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c6","title":"Using MongoDB Atlas as your Flask Database","slug":"using-mongodb-atlas-as-your-flask-database","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/flaskpymongo@2x.jpg","excerpt":"Since you prefer using Python and Flask, I’ll assume we both prefer enjoyable dev.","custom_excerpt":"Since you prefer using Python and Flask, I’ll assume we both prefer enjoyable dev.","created_at_pretty":"28 July, 2018","published_at_pretty":"31 July, 2018","updated_at_pretty":"07 March, 2019","created_at":"2018-07-28T13:42:54.000-04:00","published_at":"2018-07-31T16:59:00.000-04:00","updated_at":"2019-03-07T01:02:11.000-05:00","meta_title":"Using MongoDB Atlas as your Flask Database | Hackers And Slackers","meta_description":"MongoDB Atlas and Stitch are easy to use, making Mongo’s cloud offering a natural choice for quick Flask-based applications.","og_description":"MongoDB Atlas and Stitch are easy to use, making Mongo’s cloud offering a natural choice for quick Flask-based applications.","og_image":"https://hackersandslackers.com/content/images/2019/03/flaskpymongo@2x.jpg","og_title":"Using MongoDB Atlas as your Flask Database","twitter_description":"MongoDB Atlas and Stitch are easy to use, making Mongo’s cloud offering a natural choice for quick Flask-based applications.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/flaskpymongo@2x.jpg","twitter_title":"Using MongoDB Atlas as your Flask Database","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"It's been roughly a year since MongoDB launched their Stitch: a \"back-end as a\nservice\" cloud offering. I've been tinkering with Mongo on the cloud ever\nsince... Alright fine, \"tinkering with\"  may better be described as\"accidentally\nbecame dependent on it after developing new features in production\nenvironments,\" but I can't really complain thus-far. If you're not familiar, \nMongoDB Atlas  is MongoDB's cloud-hosted database offering; that is to say, the\nsame as any other MongoDB database, except very expensive.\n\nThe jury is still out on how MongoDB Atlas  and its counterpart Stitch  will fit\ninto the picture of next generation cloud services. That said, I can vouch that\nMongo products are simply fun to use  for developers, especially when compared\nto  traditional rigid alternatives. Since I would also group Python  and Flask \nin the 'fun to use' category, selecting MongoDB as the database for your Flask\napp makes a lot of sense.\n\nFor this tutorial we're going to set up a simple app where users can submit\ninformation via a form to MongoDB. After writing to our database, we'll query\nthe db to see the results. The result will be a Flask app with the following\nfile structure:\n\nmy-flask-project\n├── templates/\n├── static/\n├── app.py\n├── config.py\n├── currenttime.py\n└── form.py\n\n\nConnect to your Database with PyMongo\nPyMongo  is Python's go-to library for interacting with MongoDB. \n\nWe'll keep all database connection logic within db.py. After importing PyMongo,\nmost of the configuration we need to handle happens in a single line containing\nour MongoDB URI: the massive string which contains our DB location, creds, and\nauthorization DB. The string is broken down like this:\n\nmongodb+srv://[username]:[password]@[projectname]-gktww.gcp.mongodb.net/[authDB]\n\n\nAuthenticate with a [username]  and [password] you’ve set up in whichever\ndatabase handles authentication for your MongoDB instance (this is also what \n[authDB]  is referring to). \n\n[projectname]  is the unique name of your cloud instance. The rest of the URI\ncontains some nonsense, including the host of your particular instance (I’m\nusing Google Cloud, hence the .gcp in the URI). Most of this information can be\nfound just by jumping on mongodb.com [https://www.mongodb.com/]  and\ninvestigating your URI via the \"connect\" popup:\n\nThat should make things a bit easier.Now we can set up our connection:\n\nimport pymongo\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@hackerdata-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\n\nNote that we intentionally set the connection to False. Otherwise, we're going\nto find ourselves in a hell of managing open connections every time we interact\nwith the DB.\n\nSpeaking of the DB, we need to specify which database and collection we want to\ninteract with. This brings our config file to something as follows:\n\nimport pymongo\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@myInstance-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\ndb = pymongo.database.Database(mongo, 'mydatabase')\ncol = pymongo.collection.Collection(db, 'mycollection')\n\n\nLastly, if you'd like to access, say, all the objects inside of a collection (or\nsimilar query), we'll just need to add a few lines line to ensure we're reading\nthe collection's data:\n\nimport pymongo\nfrom bson.json_util import dumps\nimport json\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@myInstance-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\ndb = pymongo.database.Database(mongo, 'mydatabase')\ncol = pymongo.collection.Collection(db, 'mycollection')\n\ncol_results = json.loads(dumps(col.find().limit(5).sort(\"time\", -1)))\n\n\nRemember that Mongo returns BSON objects as opposed to JSON objects, which isn't\nvery useful for our purposes. To alleviate this we'll do a messy little dance to\nconvert Mongo's BSON into a string, and convert this to JSON using json.dumps().\n\nNote: the need to do this may have been something changed in recent versions of\nMongo, as I have older application functioning where this wasn't the case.\n¯\\_(ツ)_/¯.\n\nCreating a Form\nHeading over to form.py, we just need to set up a simple single-field form for\nusers to submit their URLs. For the sake of Python, let's say we're only\naccepting URLs for Jupyter noteboooks:\n\nfrom wtforms import Form, StringField, validators\nfrom wtforms.validators import DataRequired, Regexp\n\nclass myForm(Form):\n    \"\"\"Homepage form.\"\"\"\n    PlotlyURL = StringField('Provide a raw .ipynb URL from Github',\n    validators=[\n            DataRequired(),\n            Regexp(\".*\\.ipynb$\",\n            message=\"Please provide a URL ending in ipynb\"),\n          ])\n\n\nWe could have an entire tutorial just about Flask's WTForms\n[http://flask.pocoo.org/docs/1.0/patterns/wtforms/], but let's stay on topic\n and move on to currenttime.py.\n\nAdding Time Metadata\nIn a lot of cases where we store information to a database, we at least want to\nadd certain metadata such as the time something was added. This allows us to\narrange results by most recently updated, which we'll be doing in this example.\n\nfrom datetime import datetime, timezone\n\ndef getTime():\n    \"\"\"Get user's current time\"\"\"\n    rightnow = datetime.today()\n    return rightnow\n\ndef getPrettyTime():\n    \"\"\"Get user's pretty current time\"\"\"\n    rightnow = datetime.today()\n    prettytime = rightnow.ctime()\n    return prettytime\n\nyourtime = getTime()\nprettytime = getPrettyTime()\n\n\nThe variable yourtime  will be a datetime string representing the local time of\nthe user creating a new record. We will use this value to sort the queried\nresults by time. On the contrary,prettytime  will be the same time, only\nformatted in a way that is readable to humans.\n\nPutting the Pieces Together\nFinally we get to move on app.py and get this thing moving. We'll initiate our\napp by importing the necessary libraries, as well as the scripts we just\ncreated:\n\nfrom flask import Flask, render_template, Markup, request, redirect\nfrom config import col, col_results\nimport requests\nfrom form import myForm\nfrom flask_static_compress import FlaskStaticCompress\nfrom currenttime import yourtime, prettytime\nimport logging\n\n\nNote that we need to import from the DB config we set earlier is the \"col\"\nvariable; we'll only be interacting directly with the collection we want to\nmodify, and the rest is assumed within the config file itself. Now let's build a\nroute for our homepage that does two things:\n\n * Allows users to submit a URL via the simple form we created\n * Displays all previous searches by all users.\n\nfrom flask import Flask, render_template, Markup, request, redirect\nfrom config import col, col_results\nimport requests\nfrom form import myForm\nfrom flask_static_compress import FlaskStaticCompress\nfrom currenttime import yourtime, prettytime\nimport logging\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    \"\"\"Landing page.\"\"\"\n    recent_searches = list(col_results)\n    return render_template('/index.html', form=myForm(), recents=recent_searches, template=\"home-template\")\n\n\nThere's only two significant lines here, but let's break them down piece by\npiece.\n\nrecent_searches\nFirst we set a recent_searches  variable which is essentially a query against\nour collection to retrieve a list of previous searches. We ask that these be\nreturned as a list()  upfront. Typically the find() method would contain the\nconstraints of our query, but we're simply asking to return all  results in the\ncollection, with a limit()  up to 5. Finally, we sort()  the results by the\nfield we refer to as 'time' is descending order, as noted by the -1 argument.\n\nThis is all probably very difficult to visualize without a graphic. Here's a\nsnapshot of the collection we're defining with dummy data added:\n\nSee why we need to differentiate \"time\" and \"prettytime\"?render_template\nWe already know [https://hackersandslackers.com/serving-static-assets-in-flask/] \n the basics of serving templates and assets in Flask, so it shouldn't be too\ndifficult to break down the last line in our route:\n\n * '/index.html'  specifies the base template we'll be serving up.\n * form=myForm()  passes the form class we created earlier to the form partial\n   we're including as part of the index page.\n * recents=recent_searches  passes the query of previous searches to the\n   template, with which we can build a widget.\n * template=\"home-template\" is a simple variable passed which we'll utilize as a\n   class on the page we're loading.\n\nThe Result\nFrom everything we've completed, you should be expecting to see a somewhat\nworthless page where users can submit links via a form, simply to see results\nposted by previous posters. If we expand on this idea just a bit, we can see how\nsomething so simple can actually be extended to a full product: \n\n> Planet Jupyter [https://planetjupyter.com]\nStyle your Jupyter Notebooks.\n\n\nPlanet Jupyter is demo product we built at H&S to style Jupyter notebooks.\nPerhaps 60% of the logic behind Planet Jupyter is the simple DB interactions we\njust covered, with the rest being added flair.\n\nThis is not a shameless plug for the barely functioning toys we've built, mind\nyou, but rather an example of simple DB interactions using Flask can be easily\nextensible into relevant, useful, products.\n\nWe hope you’ve found this tutorial to be useful!","html":"<p>It's been roughly a year since MongoDB launched their <strong>Stitch: </strong>a \"back-end as a service\" cloud offering. I've been tinkering with Mongo on the cloud ever since... Alright fine, <em>\"tinkering with\"</em> may better be described as  <em>\"accidentally became dependent on it after developing new features in production environments,\" </em>but I can't really complain thus-far. If you're not familiar, <strong>MongoDB Atlas</strong> is MongoDB's cloud-hosted database offering; that is to say, the same as any other MongoDB database, except very expensive.</p><p>The jury is still out on how MongoDB <strong>Atlas</strong> and its counterpart <strong>Stitch</strong> will fit into the picture of next generation cloud services. That said, I can vouch that Mongo products are simply <em>fun to use</em> for developers, especially when compared to  traditional rigid alternatives. Since I would also group <em>Python</em> and <em>Flask</em> in the 'fun to use' category, selecting MongoDB as the database for your Flask app makes a lot of sense.</p><p>For this tutorial we're going to set up a simple app where users can submit information via a form to MongoDB. After writing to our database, we'll query the db to see the results. The result will be a Flask app with the following file structure:</p><pre><code class=\"language-shell\">my-flask-project\n├── templates/\n├── static/\n├── app.py\n├── config.py\n├── currenttime.py\n└── form.py\n</code></pre>\n<h2 id=\"connect-to-your-database-with-pymongo\">Connect to your Database with PyMongo</h2><p><strong>PyMongo</strong> is Python's go-to library for interacting with MongoDB. </p><p>We'll keep all database connection logic within <strong>db.py</strong>. After importing PyMongo, most of the configuration we need to handle happens in a single line containing our MongoDB URI: the massive string which contains our DB location, creds, and authorization DB. The string is broken down like this:</p><pre><code class=\"language-shell\">mongodb+srv://[username]:[password]@[projectname]-gktww.gcp.mongodb.net/[authDB]\n</code></pre>\n<p>Authenticate with a <strong>[username]</strong> and <strong>[password] </strong>you’ve set up in whichever database handles authentication for your MongoDB instance (this is also what<strong> [authDB]</strong> is referring to). </p><p><strong>[projectname]</strong> is the unique name of your cloud instance. The rest of the URI contains some nonsense, including the host of your particular instance (I’m using Google Cloud, hence the .gcp in the URI). Most of this information can be found just by jumping on <a href=\"https://www.mongodb.com/\">mongodb.com</a> and investigating your URI via the \"connect\" popup:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-30-at-9.46.42-PM.png\" class=\"kg-image\"><figcaption>That should make things a bit easier.</figcaption></figure><p>Now we can set up our connection:</p><pre><code class=\"language-python\">import pymongo\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@hackerdata-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n</code></pre>\n<p>Note that we intentionally set the connection to <strong>False. </strong>Otherwise, we're going to find ourselves in a hell of managing open connections every time we interact with the DB.</p><p>Speaking of the DB, we need to specify which database and collection we want to interact with. This brings our config file to something as follows:</p><pre><code class=\"language-python\">import pymongo\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@myInstance-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\ndb = pymongo.database.Database(mongo, 'mydatabase')\ncol = pymongo.collection.Collection(db, 'mycollection')\n</code></pre>\n<p>Lastly, if you'd like to access, say, all the objects inside of a collection (or similar query), we'll just need to add a few lines line to ensure we're reading the collection's data:</p><pre><code class=\"language-python\">import pymongo\nfrom bson.json_util import dumps\nimport json\n\nmongo = pymongo.MongoClient('mongodb+srv://username:password@myInstance-gktww.gcp.mongodb.net/admin', maxPoolSize=50, connect=False)\n\ndb = pymongo.database.Database(mongo, 'mydatabase')\ncol = pymongo.collection.Collection(db, 'mycollection')\n\ncol_results = json.loads(dumps(col.find().limit(5).sort(&quot;time&quot;, -1)))\n</code></pre>\n<p>Remember that Mongo returns BSON objects as opposed to JSON objects, which isn't very useful for our purposes. To alleviate this we'll do a messy little dance to convert Mongo's BSON into a string, and convert this to JSON using <strong>json.dumps()</strong>.</p><p><strong>Note: </strong>the need to do this may have been something changed in recent versions of Mongo, as I have older application functioning where this wasn't the case. ¯\\_(ツ)_/¯.</p><h2 id=\"creating-a-form\">Creating a Form</h2><p>Heading over to <strong>form.py, </strong>we just need to set up a simple single-field form for users to submit their URLs. For the sake of Python, let's say we're only accepting URLs for Jupyter noteboooks:</p><pre><code class=\"language-python\">from wtforms import Form, StringField, validators\nfrom wtforms.validators import DataRequired, Regexp\n\nclass myForm(Form):\n    &quot;&quot;&quot;Homepage form.&quot;&quot;&quot;\n    PlotlyURL = StringField('Provide a raw .ipynb URL from Github',\n    validators=[\n            DataRequired(),\n            Regexp(&quot;.*\\.ipynb$&quot;,\n            message=&quot;Please provide a URL ending in ipynb&quot;),\n          ])\n</code></pre>\n<p>We could have an entire tutorial just about Flask's WTF<a href=\"http://flask.pocoo.org/docs/1.0/patterns/wtforms/\">orms</a>, but let's stay on topic  and move on to <strong>currenttime.py.</strong></p><h2 id=\"adding-time-metadata\">Adding Time Metadata</h2><p>In a lot of cases where we store information to a database, we at least want to add certain metadata such as the time something was added. This allows us to arrange results by most recently updated, which we'll be doing in this example.</p><pre><code class=\"language-python\">from datetime import datetime, timezone\n\ndef getTime():\n    &quot;&quot;&quot;Get user's current time&quot;&quot;&quot;\n    rightnow = datetime.today()\n    return rightnow\n\ndef getPrettyTime():\n    &quot;&quot;&quot;Get user's pretty current time&quot;&quot;&quot;\n    rightnow = datetime.today()\n    prettytime = rightnow.ctime()\n    return prettytime\n\nyourtime = getTime()\nprettytime = getPrettyTime()\n</code></pre>\n<p>The variable <strong>yourtime</strong> will be a datetime string representing the local time of the user creating a new record. We will use this value to sort the queried results by time. On the contrary,  <strong>prettytime</strong> will be the same time, only formatted in a way that is readable to humans.</p><h2 id=\"putting-the-pieces-together\">Putting the Pieces Together</h2><p>Finally we get to move on <strong>app.py </strong>and get this thing moving. We'll initiate our app by importing the necessary libraries, as well as the scripts we just created:</p><pre><code class=\"language-python\">from flask import Flask, render_template, Markup, request, redirect\nfrom config import col, col_results\nimport requests\nfrom form import myForm\nfrom flask_static_compress import FlaskStaticCompress\nfrom currenttime import yourtime, prettytime\nimport logging\n</code></pre>\n<p>Note that we need to import from the DB config we set earlier is the \"col\" variable; we'll only be interacting directly with the collection we want to modify, and the rest is assumed within the config file itself. Now let's build a route for our homepage that does two things:</p><ul><li>Allows users to submit a URL via the simple form we created</li><li>Displays all previous searches by all users.</li></ul><pre><code class=\"language-python\">from flask import Flask, render_template, Markup, request, redirect\nfrom config import col, col_results\nimport requests\nfrom form import myForm\nfrom flask_static_compress import FlaskStaticCompress\nfrom currenttime import yourtime, prettytime\nimport logging\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    &quot;&quot;&quot;Landing page.&quot;&quot;&quot;\n    recent_searches = list(col_results)\n    return render_template('/index.html', form=myForm(), recents=recent_searches, template=&quot;home-template&quot;)\n</code></pre>\n<p>There's only two significant lines here, but let's break them down piece by piece.</p><h3 id=\"recent_searches\">recent_searches</h3><p>First we set a <strong>recent_searches</strong> variable which is essentially a query against our collection to retrieve a list of previous searches. We ask that these be returned as a <strong>list()</strong> upfront. Typically the <strong>find() </strong>method would contain the constraints of our query, but we're simply asking to return <em>all</em> results in the collection, with a <strong>limit()</strong> up to 5. Finally, we <strong>sort()</strong> the results by the field we refer to as 'time' is descending order, as noted by the -1 argument.</p><p>This is all probably very difficult to visualize without a graphic. Here's a snapshot of the collection we're defining with dummy data added:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-31-at-11.08.44-AM.png\" class=\"kg-image\"><figcaption>See why we need to differentiate \"time\" and \"prettytime\"?</figcaption></figure><h3 id=\"render_template\">render_template</h3><p>We <a href=\"https://hackersandslackers.com/serving-static-assets-in-flask/\">already know</a> the basics of serving templates and assets in Flask, so it shouldn't be too difficult to break down the last line in our route:</p><ul><li><strong>'/index.html'</strong> specifies the base template we'll be serving up.</li><li><strong>form=myForm()</strong> passes the form class we created earlier to the form partial we're including as part of the index page.</li><li><strong>recents=recent_searches</strong> passes the query of previous searches to the template, with which we can build a widget.</li><li><strong>template=\"home-template\" </strong>is a simple variable passed which we'll utilize as a class on the page we're loading.</li></ul><h2 id=\"the-result\">The Result</h2><p>From everything we've completed, you should be expecting to see a somewhat worthless page where users can submit links via a form, simply to see results posted by previous posters. If we expand on this idea just a bit, we can see how something so simple can actually be extended to a full product: </p><blockquote class=\"embedly-card\" data-card-controls=\"0\"><h4><a href=\"https://planetjupyter.com\">Planet Jupyter</a></h4><p>Style your Jupyter Notebooks.</p></blockquote>\n<script async src=\"//cdn.embedly.com/widgets/platform.js\" charset=\"UTF-8\"></script><p>Planet Jupyter is demo product we built at H&amp;S to style Jupyter notebooks. Perhaps 60% of the logic behind Planet Jupyter is the simple DB interactions we just covered, with the rest being added flair.</p><p>This is not a shameless plug for the barely functioning toys we've built, mind you, but rather an example of simple DB interactions using Flask can be easily extensible into relevant, useful, products.</p><p>We hope you’ve found this tutorial to be useful!</p>","url":"https://hackersandslackers.com/using-mongodb-atlas-as-your-flask-database/","uuid":"e8c92cbd-6845-45b5-acfc-a744810eafcd","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b5cab1e2189c353565a2adf"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c5","title":"Hacking Your Tableau Linux Server","slug":"hacking-linux-tableau-server","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/hacktableau@2x.jpg","excerpt":"Cracking Tableau's master Postgres account.","custom_excerpt":"Cracking Tableau's master Postgres account.","created_at_pretty":"26 July, 2018","published_at_pretty":"26 July, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-07-26T03:17:59.000-04:00","published_at":"2018-07-26T05:55:50.000-04:00","updated_at":"2019-02-02T04:23:43.000-05:00","meta_title":"Cracking Tableau's master Postgres account | Hackers And Slackers","meta_description":"BI tools are great for understanding preexisting data, but they don't allow us to go much further. Your data is with them, and it's not going anywhere else.","og_description":"BI tools are great for understanding preexisting data, they don't go much further. Your data is with them, and it's not going anywhere else.","og_image":"https://hackersandslackers.com/content/images/2018/07/hacktableau@2x.jpg","og_title":"Hacking Your Tableau Linux Server","twitter_description":"BI tools are great for understanding preexisting data, they don't go much further. Your data is with them, and it's not going anywhere else.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/hacktableau@2x.jpg","twitter_title":"Hacking Your Tableau Linux Server","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#Hacking Tableau Server","slug":"hacking-tableau-server","description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauseries-2.jpg","meta_description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","meta_title":"Hacking Tableau Server","visibility":"internal"}],"plaintext":"Let's say you're a Data Scientist. Well, maybe not a data scientist- I mean,\nthose online data analysis courses were definitely worth it, and you'd made it\nthis far without being quizzed on Bayesian linear regression. So maybe you're an\nanalyst or something, but whatever:  you use Tableau, So you must be a\nScientist™.\n\nI've admitted a few times in the past to have purchased a personal Tableau\nServer license in my more ignorant years (aka a few months ago). While BI tools\nare great for understanding preexisting data, they don't allow us to go much\nfurther. This is is entirely by design. Sure, you can clean and slice your data\nand put it into a cute iFrame dashboard, but Tableau explicitly makes one thing\nexplicitly clear in their product design choices: your data is with them, and\nit's not going anywhere else. Today we're going to take a step towards changing\nthat.\n\nProprietary Product Design: Crimes Against Customers\nTableau has explicit hierarchies for information, but let's start with \nworkbooks.  Workbooks are basically spreadsheets, or in other words,  \ncollections of SQL query outputs against a data source (or multiple data\nsources) via a clean UI. The resulting tabular data is referred to as views. An\nExcel user might equate these to \"sheets\", but a SQL user understands that these\nfunction more like a materialized view of sorts. One would think the tables we\ncreate (from our own data) inherently belongs to us, but it doesn't. Not until\nyou get clever.\n\nI realize Tableau maybe be at the top of the market for its niche.... so the\nthings I'm claiming may seem a little farfetched. Why am I so convinced that\nTableau wants to lock your data? Stay with me here, and let me count the ways.\n\nCommon Courtesy API Visibility\nCommon knowledge suggest that visible APIs attracts development talent. The more\nintelligent people are exposed to your product, the more like they are to\ncontribute. What happens if we check out the API response calls in our browser\nwhen viewing  Worksheet on Tableau Server?\n\nLet's just agree this is all useless.While this level of unnecessary paranoia on\nTableau's part is distasteful, let's not forget that we're dealing with a\nproduct archaic enough to preview Windows server support over Linux. The\nnarrative begins to make sense.\n\nPostgres Hide and Seek\nTableau Server is running a Postgres database; really nothing magical happening\nhere. Well, other than the database has been renamed, protected, and obfuscated\nin a way that even the server owner would struggle with. The default commands to\ninteract with PostgreSQL are hidden from server admins altogether.\n\n$ psql postgres -u toddbirchard -p\nThe program 'psql' is currently not installed. To run 'psql' please ask your administrator to install the package 'postgresql-client-common'\n\n-------------------\n\n$ sudo -u postgres psql postgres\nsudo: unknown user: postgres\nsudo: unable to initialize policy plugin\n\n-------------------\n\n$ sudo -u toddbirchard psql postgres\nsudo: psql: command not found\n\n-------------------\n\n$ psql\npsql: could not connect to server: No such file or directory\n        Is the server running locally and accepting\n        connections on Unix domain socket \"/var/run/postgresql/.s.PGSQL.5432\"?\n\n-------------------\n\n$ pgsql\nNo command 'pgsql' found, did you mean:\n Command 'psql' from package 'postgresql-client-common' (main)\npgsql: command not found\n\n\nWhat if we do a search?\n\n$ locate postgresql\n\n/etc/postgresql-common\n/etc/postgresql-common/user_clusters\n/opt/tableau-postgresql-odbc_9.5.3_amd64.deb\n/opt/tableau/tableau_driver/postgresql-odbc\n/opt/tableau/tableau_driver/postgresql-odbc/psqlodbcw.so\n/opt/tableau/tableau_server/packages/bin.20181.18.0510.1418/repo-jars/postgresql-9.4.1209.jar\n/opt/tableau/tableau_server/packages/clientfileservice.20181.18.0510.1418/postgresql-9.4.1208.jar\n/opt/tableau/tableau_server/packages/lib.20181.18.0510.1418/postgresql-9.4.1208.jar\n/opt/tableau/tableau_server/packages/lib.20181.18.0510.1418/postgresql-9.4.1209.jar\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/_int.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/adminpack.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/ascii_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/auth_delay.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/auto_explain.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/autoinc.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/btree_gin.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/btree_gist.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/chkpass.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/citext.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/cube.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/cyrillic_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dblink.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_int.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_snowball.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_xsyn.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/earthdistance.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc2004_sjis2004.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_cn_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_jp_and_sjis.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_kr_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_tw_and_big5.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/file_fdw.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/fuzzystrmatch.so\n\n\n...And so forth. There are over a thousand results. Postgres is definitely up\nand running, Tableau just hates you. Unfortunately for Tableau, this drove me to\nhate them back.\n\nEnter TSM: The Linux Tableau CLI\nOn Linux exclusively, TSM is intended to be your one tool to configure Tableau\nServer. It's a fine tool, but it just so happens to omit critical information\nand capabilities that somebody who owns their data  might want to know. At first\nglance, it seems innocent and helpful:\n\nCommand\n Explanation\n tsm configuration [parameters]\n -- Set customization for Tableau Server.\n tsm customize [parameters] -- Set customization for Tableau Server.\n tsm data-access [parameters]\n -- Category of commands related to data-access.\n tsm help | [category]\n -- Help for tsm commands\n .tsm initialize [parameters]\n -- Initialize Tableau Server\n tsm jobs [parameters]\n -- Category of commands related to async jobs.\n tsm licenses [parameters]\n -- Category of commands related to licensing.\n tsm login [parameters] -- Sign in to the TSM agent\n tsm logout -- Sign out from the TSM agent\n tsm maintenance [parameters]\n -- Category of commands related to maintenance.\n tsm pending-changes [parameters]\n -- Category of commands for pending changes.\n tsm register [parameters]\n -- Register the product\n tsm reset [parameters]\n -- Clears the initial admin user so you can enter a new one. Once reset is\ncompleted you will need to use the tabcmd initialuser command to create a new\ninitial user before remote users can sign in again\n tsm restart [parameters]\n -- Restart Tableau Server\n tsm security [parameters]\n -- Category of commands related to security configuration\n tsm settings [parameters]\n -- Category of commands related to configuration and topology settings\n tsm sites [parameters]\n -- Category of commands related to site import and export\n tsm start [parameters]\n -- Start Tableau Server\n tsm status [parameters]\n -- View Tableau Server status\n tsm stop [parameters]\n -- Stop Tableau Server\n tsm topology [parameters] -- Category of commands related to server topology\n tsm user-identity-store [parameters]\n -- Category of commands related to user-identity-store\n tsm version -- Displays version information.\n The Red Herring\nTableau owns Google results, period. Any search query containing the word\n\"Tableau\" is dominated with pages of content Tableau would prefer  you abide by,\nand of these things is the creation of a readonly  user to access the Postgres\ndatabase. The catch here is that the readonly  user can't read all tables at\nall: there are certain tables reserved specifically for a Postgres tableau\n\"Superuser\", which is utterly and entirely undocumented on Linux.  For all I\nknow, I my be the first to publish an article of this sort, but let's hope not.\n\nFirst, let's see which users exist on Postgres using TSM:\n\n$ tsm data-access repository-access list\n\nUser       Access\nTableau    true\nReadonly   true\n\n\nThere's that Readonly user we talked about: feel free to play around with that\nuser to create meaningless insights if you so please. On the other hand we have\na Tableau  user, which happens to be a Postgres superuser. If you don't feel\ncomfortable accessing Superuser privileges, I suggest you leave now. This is \nHackers And Slackers,  and we don't fuck around; especially when software to the\ntune of 1 thousand dollars hides our data from us.\n\nOperation Shock and Awe\nThere's a little command called tsm configuration  which lets you set some cute\nvariables for your server. The documentation is here\n[https://onlinehelp.tableau.com/current/server-linux/en-us/cli_configuration-set_tsm.htm]\n, but there's just one piece missing, and it's the one we need.\n\nTableau may be our Postgres Superuser, but what would its password possibly be?\nThis isn't documented anywhere. Consider this my gift to you:\n\n$ tsm configuration get -k pgsql.adminpassword\n145v756270d3467bv3140af5f01v5c7e4976bcee\n\n\nCould it be? Did Tableau intentionally prevent users from access PostgreSQL\ndirectly from command line and hide an undocumented password? Yes, it does all\nof those things. It's time to fuck shit up.\n\nClaim Ownership\nWe've made it this far. The bullet is in the chamber. Go ahead and take what is\nrightfully yours.\n\ntsm data-access repository-access enable --repository-username Tableau\n--repository-password 145v756270d3467bv3140af5f01v5c7e4976bcee\n\n\nJust make sure port 8060 is open on your VPC and you're in. Considering that\nthere are zero search results for accomplishing this on Linux, it looks like\nit's just you and me now. One of us may likely go mad with power and turn on one\nanother. That is the way of the Sith. Welcome.\n\nUnspeakable treasures lie within.Moving on Up\nFeel free to cruise the workgroup  database for now and wreck havoc. As fun as\nthis has been, I have another trick up my sleeve. You've spent a lot of time\nbuilding Worksheets and views; what if you could programmatically sync to an\nexternal database and autogenerate a schema for these views, updated on a\nscheduler, to source data for products you're building?\n\nThats sounds a lot like what a useful product would do. Stick around, and next\ntime we'll be beating Tableau down for everything its worth.","html":"<p>Let's say you're a Data Scientist. Well, maybe not a <em>data scientist- </em>I mean, those online data analysis courses were definitely worth it, and you'd made it this far without being quizzed on Bayesian linear regression. So maybe you're an analyst or something, but whatever:  you use Tableau, So you must be a Scientist™.</p><p>I've admitted a few times in the past to have purchased a personal Tableau Server license in my more ignorant years (aka a few months ago). While BI tools are great for understanding preexisting data, they don't allow us to go much further. This is is entirely by design. Sure, you can clean and slice your data and put it into a cute iFrame dashboard, but Tableau explicitly makes one thing explicitly clear in their product design choices: your data is with them, and it's not going anywhere else. Today we're going to take a step towards changing that.</p><h2 id=\"proprietary-product-design-crimes-against-customers\">Proprietary Product Design: Crimes Against Customers</h2><p>Tableau has explicit hierarchies for information, but let's start with <strong>workbooks.</strong> Workbooks are basically spreadsheets, or in other words,<strong> </strong>collections of SQL query outputs against a data source (or multiple data sources) via a clean UI. The resulting tabular data is referred to as <strong>views</strong>. An Excel user might equate these to \"sheets\", but a SQL user understands that these function more like a materialized view of sorts. One would think the tables we create (from our own data) inherently belongs to us, but it doesn't. Not until you get clever.</p><p>I realize Tableau maybe be at the top of the market for its niche.... so the things I'm claiming may seem a little farfetched. Why am I so convinced that Tableau wants to lock your data? Stay with me here, and let me count the ways.</p><h2 id=\"common-courtesy-api-visibility\">Common Courtesy API Visibility</h2><p>Common knowledge suggest that visible APIs attracts development talent. The more intelligent people are exposed to your product, the more like they are to contribute. What happens if we check out the API response calls in our browser when viewing  Worksheet on Tableau Server?</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ezgif.com-gif-maker.gif\" class=\"kg-image\"><figcaption>Let's just agree this is all useless.</figcaption></figure><p>While this level of unnecessary paranoia on Tableau's part is distasteful, let's not forget that we're dealing with a product archaic enough to preview Windows server support over Linux. The narrative begins to make sense.</p><h3 id=\"postgres-hide-and-seek\">Postgres Hide and Seek</h3><p>Tableau Server is running a Postgres database; really nothing magical happening here. Well, other than the database has been renamed, protected, and obfuscated in a way that even the server owner would struggle with. The default commands to interact with PostgreSQL are hidden from server admins altogether.</p><pre><code class=\"language-bash\">$ psql postgres -u toddbirchard -p\nThe program 'psql' is currently not installed. To run 'psql' please ask your administrator to install the package 'postgresql-client-common'\n\n-------------------\n\n$ sudo -u postgres psql postgres\nsudo: unknown user: postgres\nsudo: unable to initialize policy plugin\n\n-------------------\n\n$ sudo -u toddbirchard psql postgres\nsudo: psql: command not found\n\n-------------------\n\n$ psql\npsql: could not connect to server: No such file or directory\n        Is the server running locally and accepting\n        connections on Unix domain socket &quot;/var/run/postgresql/.s.PGSQL.5432&quot;?\n\n-------------------\n\n$ pgsql\nNo command 'pgsql' found, did you mean:\n Command 'psql' from package 'postgresql-client-common' (main)\npgsql: command not found\n</code></pre>\n<p>What if we do a search?</p><pre><code class=\"language-bash\">$ locate postgresql\n\n/etc/postgresql-common\n/etc/postgresql-common/user_clusters\n/opt/tableau-postgresql-odbc_9.5.3_amd64.deb\n/opt/tableau/tableau_driver/postgresql-odbc\n/opt/tableau/tableau_driver/postgresql-odbc/psqlodbcw.so\n/opt/tableau/tableau_server/packages/bin.20181.18.0510.1418/repo-jars/postgresql-9.4.1209.jar\n/opt/tableau/tableau_server/packages/clientfileservice.20181.18.0510.1418/postgresql-9.4.1208.jar\n/opt/tableau/tableau_server/packages/lib.20181.18.0510.1418/postgresql-9.4.1208.jar\n/opt/tableau/tableau_server/packages/lib.20181.18.0510.1418/postgresql-9.4.1209.jar\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/_int.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/adminpack.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/ascii_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/auth_delay.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/auto_explain.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/autoinc.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/btree_gin.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/btree_gist.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/chkpass.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/citext.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/cube.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/cyrillic_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dblink.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_int.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_snowball.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_xsyn.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/earthdistance.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc2004_sjis2004.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_cn_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_jp_and_sjis.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_kr_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_tw_and_big5.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/file_fdw.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/fuzzystrmatch.so\n</code></pre>\n<p>...And so forth. There are over a thousand results. Postgres is definitely up and running, Tableau just hates you. Unfortunately for Tableau, this drove me to hate them back.</p><h2 id=\"enter-tsm-the-linux-tableau-cli\">Enter TSM: The Linux Tableau CLI</h2><p>On Linux exclusively, TSM is intended to be your one tool to configure Tableau Server. It's a fine tool, but it just so happens to omit critical information and capabilities that somebody who <em>owns their data</em> might want to know. At first glance, it seems innocent and helpful:</p><style>\n    td{\n        min-width: 224px;\n            text-align: left;\n    padding: 10px 20px !important;\n            line-height: 1.3;\n        text-align: left !important;\n    }\n    </style>\n\n<table style=\"cellpadding=\" 10px\"=\"\">\n  <thead>\n    <th>Command</th>\n    <th>Explanation</th>\n  </thead>\n  <tbody>\n    <tr>\n      <td>tsm configuration [parameters]</td>\n      <td>-- Set customization for Tableau Server.</td>\n    </tr>\n    <tr>\n      <td>tsm customize [parameters] </td>\n      <td>-- Set customization for Tableau Server.</td>\n    </tr>\n    <tr>\n      <td>tsm data-access [parameters]</td>\n      <td>-- Category of commands related to data-access.</td>\n    </tr>\n    <tr>\n      <td>tsm help  | [category]</td>\n      <td>-- Help for tsm commands</td>\n    </tr>\n    <tr>\n      <td>.tsm initialize [parameters]</td>\n      <td>-- Initialize Tableau Server</td>\n    </tr>\n    <tr>\n      <td>tsm jobs [parameters]</td>\n      <td> -- Category of commands related to async jobs.</td>\n    </tr>\n    <tr>\n      <td>tsm licenses [parameters]</td>\n      <td>-- Category of commands related to licensing.</td>\n    </tr>\n    <tr>\n      <td>tsm login [parameters] </td>\n      <td>-- Sign in to the TSM agent</td>\n    </tr>\n    <tr>\n      <td>tsm logout </td>\n      <td>-- Sign out from the TSM agent</td>\n    </tr>\n    <tr>\n      <td>tsm maintenance  [parameters]</td>\n      <td>-- Category of commands related to maintenance.</td>\n    </tr>\n    <tr>\n      <td>tsm pending-changes [parameters]</td>\n      <td>-- Category of commands for pending changes.</td>\n    </tr>\n    <tr>\n      <td>tsm register [parameters]</td>\n      <td>-- Register the product</td>\n    </tr>\n    <tr>\n      <td>tsm reset [parameters]</td>\n      <td>-- Clears the initial admin user so you can enter a new one. Once reset is completed you will need to use the tabcmd initialuser command to create a new initial user before remote users can sign in again</td>\n    </tr>\n    <tr>\n      <td>tsm restart [parameters]</td>\n      <td>-- Restart Tableau Server</td>\n    </tr>\n    <tr>\n      <td>tsm security [parameters]</td>\n      <td>-- Category of commands related to security configuration</td>\n    </tr>\n    <tr>\n      <td>tsm settings [parameters]</td>\n      <td>-- Category of commands related to configuration and topology settings</td>\n    </tr>\n    <tr>\n      <td>tsm sites [parameters]</td>\n      <td>-- Category of commands related to site import and export</td>\n    </tr>\n    <tr>\n      <td>tsm start [parameters]</td>\n      <td>-- Start Tableau Server</td>\n    </tr>\n    <tr>\n      <td>tsm status [parameters]</td>\n      <td>-- View Tableau Server status</td>\n    </tr>\n    <tr>\n      <td>tsm stop [parameters]</td>\n      <td>-- Stop Tableau Server</td>\n    </tr>\n    <tr>\n      <td>tsm topology  [parameters] </td>\n      <td>-- Category of commands related to server topology</td>\n    </tr>\n    <tr>\n      <td>tsm user-identity-store [parameters]</td>\n      <td>-- Category of commands related to user-identity-store</td>\n    </tr>\n    <tr>\n      <td>tsm version </td>\n      <td>-- Displays version information.</td>\n    </tr>\n  </tbody>\n</table>\n<!-- DivTable.com -->\n<h2 id=\"the-red-herring\">The Red Herring</h2><p>Tableau owns Google results, period. Any search query containing the word \"Tableau\" is dominated with pages of content Tableau would <em>prefer</em> you abide by, and of these things is the creation of a <em>readonly</em> user to access the Postgres database. The catch here is that the <strong>readonly</strong> user can't read all tables at all: there are certain tables reserved specifically for a Postgres tableau \"Superuser\", which is <em>utterly and entirely undocumented on Linux.</em> For all I know, I my be the first to publish an article of this sort, but let's hope not.</p><p>First, let's see which users exist on Postgres using TSM:</p><pre><code class=\"language-bash\">$ tsm data-access repository-access list\n\nUser       Access\nTableau    true\nReadonly   true\n</code></pre>\n<p>There's that Readonly user we talked about: feel free to play around with that user to create meaningless insights if you so please. On the other hand we have a <strong>Tableau</strong> user, which happens to be a Postgres superuser. If you don't feel comfortable accessing Superuser privileges, I suggest you leave now. This is <strong>Hackers And Slackers,</strong> and we don't fuck around; especially when software to the tune of 1 thousand dollars hides our data from us.</p><h2 id=\"operation-shock-and-awe\">Operation Shock and Awe</h2><p>There's a little command called <code>tsm configuration</code> which lets you set some cute variables for your server. The documentation is <a href=\"https://onlinehelp.tableau.com/current/server-linux/en-us/cli_configuration-set_tsm.htm\">here</a>, but there's just one piece missing, and it's the one we need.</p><p><strong>Tableau </strong>may be our Postgres Superuser, but what would its password possibly be? This isn't documented anywhere. Consider this my gift to you:</p><pre><code class=\"language-bash\">$ tsm configuration get -k pgsql.adminpassword\n145v756270d3467bv3140af5f01v5c7e4976bcee\n</code></pre>\n<p>Could it be? Did Tableau intentionally prevent users from access PostgreSQL directly from command line and hide an undocumented password? Yes, it does all of those things. It's time to fuck shit up.</p><h2 id=\"claim-ownership\">Claim Ownership</h2><p>We've made it this far. The bullet is in the chamber. Go ahead and take what is rightfully yours.</p><pre><code class=\"language-bash\">tsm data-access repository-access enable --repository-username Tableau\n--repository-password 145v756270d3467bv3140af5f01v5c7e4976bcee\n</code></pre>\n<p>Just make sure port 8060 is open on your VPC and you're in. Considering that there are zero search results for accomplishing this on Linux, it looks like it's just you and me now. One of us may likely go mad with power and turn on one another. That is the way of the Sith. Welcome.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/winner.png\" class=\"kg-image\"><figcaption>Unspeakable treasures lie within.</figcaption></figure><h2 id=\"moving-on-up\">Moving on Up</h2><p>Feel free to cruise the <strong>workgroup</strong> database for now and wreck havoc. As fun as this has been, I have another trick up my sleeve. You've spent a lot of time building Worksheets and views; what if you could programmatically sync to an external database and autogenerate a schema for these views, updated on a scheduler, to source data for products you're building?</p><p>Thats sounds a lot like what a useful product would do. Stick around, and next time we'll be beating Tableau down for everything its worth. </p>","url":"https://hackersandslackers.com/hacking-linux-tableau-server/","uuid":"4bcb1c4b-bbe2-428c-b7ee-fa7adc751973","page":false,"codeinjection_foot":"<script>\n    hljs.configure({languages:['bash']});\n</script>","codeinjection_head":"","comment_id":"5b5975a75c6b8259b902b66a"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c2","title":"Serving Frontend Assets in Flask","slug":"serving-static-assets-in-flask","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/flaskstatic.jpg","excerpt":"When Python developers manage presentation layers.","custom_excerpt":"When Python developers manage presentation layers.","created_at_pretty":"23 July, 2018","published_at_pretty":"23 July, 2018","updated_at_pretty":"05 April, 2019","created_at":"2018-07-22T23:56:52.000-04:00","published_at":"2018-07-23T06:22:21.000-04:00","updated_at":"2019-04-04T22:10:24.000-04:00","meta_title":"Serving Frontend Assets in Flask | Hackers And Slackers","meta_description":"flask_static_compress is a library for compressing flask assets. It can be considered to be a Python equivalent to Gulp in the context of asset compression.","og_description":"flask_static_compress is a library for compressing flask assets. It can be considered to be a Python equivalent to Gulp in the context of asset compression.","og_image":"https://hackersandslackers.com/content/images/2019/03/flaskstatic.jpg","og_title":"Serving Frontend Assets in Flask","twitter_description":"flask_static_compress is a library for compressing flask assets. It can be considered to be a Python equivalent to Gulp in the context of asset compression.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/flaskstatic.jpg","twitter_title":"Serving Frontend Assets in Flask","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"If you're familiar with Django (or Python to any extent), you've probably\naccepted the concept of what Python guys refer to as \"static assets.\" Let's take\na moment to consider this: at some point in Django's conception a design\ndecision was made: all JavaScript, CSS, or  any assets pertaining to the\npresentation layer  belong tucked away into an isolated corner of the framework.\nAlas, it was decreed: henceforward, only two types of code exist in the\nuniverse: Python, and not-Python. Anything that isn't Python is simply a\n\"static\" asset to be dealt with either locally or via a CDN somewhere. \n\nThe implied mindset is both somewhat absurd yet also unsurprising. It's easy to\nimagine a couple of backend nerds nonchalantly writing off frontend development\nas a concept  to be stuck in a single folder. You know, all those things which\nmake an app an app? Like, anything visible to a user? These are simply\nthings-to-be-dealt-with when the frontend guys are ready with their \"make it\npretty\" nonsense. Screw it, throw it all in the /static  folder. We accept this\ndistinction to this day with little thought. Flask has carried over the same\nterminology and concept of a \"static\" folder, so this amusing cultural relic is\nhere to stay.\n\nAnyhow, we're here today to help you serve those beautiful assets of yours, as\nstatic as they may be. We'll do so by exploring the top-two libraries available\nto us: Flask-Static-Compress, and Flask-Assets.\n\nApplication Structure For Flask Apps with Frontend\nBest practices aside, we'll start with the most straightforward project\nstructure for a Flask web app. Let's work with this structure:\n\nmyproject\n├─ /static\n│  └─ /js\n│  └─ /less\n│  └─ /img\n│  └─ /build\n├─ /templates\n└─ app.py\n\n\nAll the Python we need is going to sit in a plump little app.py  file. \n\nTemplates  hold the same concept as they do to equivalent frameworks such as\nExpress: this is where we contain pages, partials, and layouts.  Flask's default\n Jinja2  templating engine has personally served me well enough to never\ninvestigate an alternative.\n\n/Static is where we'll store the raw  source  files for things like preprocessed\nstylesheets and JavaScript. At runtime, these sources files will be compressed\nand stored elsewhere in a production setting, such as that nifty /build  folder\nwe created (or feel free to call it /dist, whatever, it's your party man). \n\nIt's best practice to serve these from a CDN at runtime, but whatever.\n\nIn contrast to NodeJS apps, things like images and fonts are stored in the\n/static folder as well. This distinguishes Python's concept of /static  from,\nsay, another framework's concept of /src: instead of being a folder of only\nsource code, we pretty much have a folder of all that shit which isn't Python. \nAnd we've come full circle.\n\nCreating The Flask App Object\nfrom flask import Flask, url_for, render_template, request, Response\n\napp = Flask(__name__, static_folder=\"static\", template_folder=\"templates\")\n\n\nWe initiate our app on line 4 with app = Flask().  We create our app with three\nparameters/attributes:\n\n * __name__: Now that I think about it, I've never actually considered what this\n   first parameter is doing. Just know that you need it,\n * static_folder: Specifies the name of the folder where static assets will be\n   served. This is based on where your app believes the root folder lives.\n   Because our app is a single directory, it knows that /static  is in the\n   current directory.\n * template_folder: Same as above, but contains Jinja2 templates, AKA the files\n   which become HTML.\n\nIt's important to reiterate that these folders default to being relative to the\ncurrent location of app.py.  If we want to change this behavior, we can pass \ninstance_path=/path/to/desired/dir/  to override this behavior.\n\nMethod 1: Flask-Static-Compress\nThere's more than one way to skin a cat, and there's certainly more than one\nlibrary or philosophy for serving pages and styles in Flask. \nflask_static_compress is one such library, which we'll include in app.py:  \n\nfrom flask import Flask, url_for, render_template, request, Response\nfrom flask_static_compress import FlaskStaticCompress\n\n\nflask_static_compress [https://github.com/alanhamlett/flask-static-compress]  is\na cool library for compressing and joining assets together. If you've ever used\nGulp, it achieves some of the common tasks Gulp might, but with a MUCH different\nphilosophy. Some key differences are:\n\n * The ability to served compressed assets individually, as opposed to one giant\n   site bundle.\n * Never needing to explicitly fun a build command to create files served at\n   runtime.\n\nBefore serving any assets, we'll need a landing page for our app. While still in\n app.py,  we need to set a route for anybody who visits our site:\n\nfrom flask import Flask, url_for, render_template, request, Response\nfrom flask_static_compress import FlaskStaticCompress\n\napp = Flask(__name__, static_folder=\"static\", template_folder=\"templates\")\n\n@app.route('/', methods=['GET'])\ndef home():\n    \"\"\"Landing page.\"\"\"\n    return render_template('/index.html', title=\"Lame Site\")\n\n\nOur route listens for traffic hitting \"/\" (our root directory) and kindly serves\nthem the page index.html  as you might expect. Because we set the value of \ntemplates_folder  just now, Flask knows to serve a file living in /\ntemplates/index.html. \n\nIf you need some pointers on creating basic templates in Flask in which to load\nyour frontend assets, I'd suggest taking a look back at the previous post.\n\nFrontend YOLO Swag\nBack to your project, make .less  file and a .js  file in the appropriate\nplaces:\n\nmyproject\n├─ /build\n├─ /static\n│  └─ js\n│  │  └─ main.js\n│  └─ less\n│  │  └─ style.js\n│  └─ img\n├─ /templates\n│  └─ layout.html\n│  └─ index.html\n└─ app.py\n\n\nUse these files to brand your site accordingly. Add some images, memes,\npropaganda, viruses, etc. Whatever your heart desires.\n\nBack in app.py  we need to finish configuring our library:\n\nfrom flask import Flask, url_for, render_template, request, Response\nfrom flask_static_compress import FlaskStaticCompress\n\napp = Flask(__name__)\napp.config['COMPRESSOR_DEBUG'] = app.config.get('DEBUG')\napp.config['COMPRESSOR_STATIC_PREFIX'] = 'static'\napp.config['COMPRESSOR_OUTPUT_DIR'] = 'build'\napp.static_folder = 'static'\ncompress = FlaskStaticCompress(app)\n\n\n@app.route('/', methods=['GET'])\ndef home():\n    \"\"\"Landing page.\"\"\"\n    return render_template('/index.html', title=\"Lame Site\")\n\n\nCongrats! the main part of your application is pretty much done, just note a few\nthings:\n\n * Notice this time we set our folder paths via app.config[]  as opposed to\n   inline, in the earlier example. This is simply a matter of preference.\n * compress = FlaskStaticCompress(app) initializes our library, so definitely do\n   that.\n * Fun tidbit: app.static_folder = 'static' is a snippet which can live within\n   any route to override  the default app settings for where your folders are\n   located. \n\nCompressed 2 deff\nLet's wrap this bad boy up. Back in layout.html, let's add those static files we\ncreated.\n\n<!doctype html>\n<html>\n<head>\n  <title>{% block title %}{% endblock %} - My Lame Site</title>\n  <!-- Meta Data -->\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, viewport-fit=cover\">\n    \n  <!-- CSS -->\n  {% compress 'css' %}\n     <link href=\"{{ url_for('static', filename='less/home.less') }}\" type=\"text/less\">\n  {% endcompress %}\n    \n  <!-- JS -->\n    {% compress 'js' %}\n      <script src=\"{{ url_for('static', filename='js/previews.js') }}\"></script>\n\t{% endcompress %}\n</head>\n<body>\n  {% block content %}{% endblock %}\n</body>\n</html>\n\n\nLet's analyze this real quick:\n\n{% compress 'css' %}\n   <link href=\"{{ url_for('static', filename='less/home.less') }}\" type=\"text/less\">\n{% endcompress %}\n\n\nAll files within the {% compress 'css' %}  block will be minified and joined\ninto a single file, and then moved to the build folder we specified earlier.\nIt's that easy- no jobs to run beforehand, etc.\n\nWhat might also catch your eye is how we define the path:\n\n{{ url_for('static', filename='less/home.less') }}\n\n\nThis is a Jinja path dynamically locating our source file from our specified\nstatic doc. Well, I'll be darned.\n\nMethod 2: Flask-Assets\nFlaskStaticCompress  is great, but Flask_assets\n[http://flask-assets.readthedocs.io/en/latest/]  might even be better. If you're\nfamiliar with Webpack, consider the philosophy behind bundling.  Creating \nbundles  of frontend assets makes sense when we can draw clear distinctions of\nalike-screens in our app: this way, users don't download the entirety of our\nassets for screens they might not visit upfront, while pre-loading assets for\npages they'll probably  visit.\n\nThe Flask-Assets  library goes hand-in-hand with the concept of Flask Blueprints\n. If you aren't familiar with Blueprints just yet, I encourage you to become\nfamiliar here [https://hackersandslackers.com/structuring-your-flask-app/].\n\nTo get started, we'll install the necessary libraries:\n\n$ pip3 install flask-assets lesscpy cssmin jsmin\n\n\nThis is working under the assumption that we're be writing styles in LESS. If\nyou prefer sass, libsass  can take the place of lesscpy.\n\nThe other two libraries, cssmin  and jsmin, are for minifying CSS and JS assets\nrespectively.\n\nLet's see how we pull this off:\n\n...\nfrom flask_assets import Environment, Bundle\n\n\n# Flask-Assets Configuration\nless_bundle = Bundle('src/less/*.less',\n                     filters='less,cssmin',\n                     output='dist/css/account.css',\n                     extra={'rel': 'stylesheet/less'})\njs_bundle = Bundle('src/js/*.js',\n                   filters='jsmin',\n                   output='dist/js/main.min.js')\nassets.register('less_all', less_bundle)\nassets.register('js_all', js_bundle)\nless_bundle.build()\njs_bundle.build()\n``\n\nNotice how we only import flask_assets of all the libraries we installed- this\nis intentional. The other libraries do not need to be imported anywhere.\n\nless_bundle  and js_bundle  represent groupings of LESS and JS files to be\nstitched into one single file. Any positional arguments to be passed in to \nBundle()  will be taken as paths of sources files to bundle: we can bundle as\nmany or as few files as we want (or in our case , just import *).\n\nThe filters  argument is where we tell our Bundle()  how to treat the files\nwe've passed. In the case of less_bundle, passing less,cssmin  indicates that\nthe incoming files will be LESS files, to be compiled into CSS files, and then\noutputted as minified CSS files. the output destination, of course, is handled\nby the argument output.\n\nFinal Thoughts\nThe great thing about Flask (and Python in general) is that you're provided the\nluxury to write code in a manner which you find enjoyable. Considering Flask is\na relatively young framework, we're in a bit of a golden age where there are\njust enough libraries to suit your tastes, but not enough to get lost in an NPM\nlevel hell.\n\nIn my completely biased and untrustworthy opinion, it's hard to imagine getting\ninvolved with a Framework in a sweeter spot than where Flask is right now.","html":"<p>If you're familiar with Django (or Python to any extent), you've probably accepted the concept of what Python guys refer to as \"static assets.\" Let's take a moment to consider this: at some point in Django's conception a design decision was made: all <em>JavaScript</em>, <em>CSS</em>, or<em> any assets pertaining to the presentation layer</em> belong tucked away into an isolated corner of the framework. Alas, it was decreed: henceforward, only two types of code exist in the universe: Python, and not-Python. Anything that isn't Python is simply a \"static\" asset to be dealt with either locally or via a CDN somewhere. </p><p>The implied mindset is both somewhat absurd yet also unsurprising. It's easy to imagine a couple of backend nerds nonchalantly writing off <em>frontend development as a concept</em> to be stuck in a single folder. You know, all those things which make an app an app? Like, anything visible to a user? These are simply things-to-be-dealt-with when the frontend guys are ready with their \"make it pretty\" nonsense. Screw it, throw it all in the <strong>/static</strong> folder. We accept this distinction to this day with little thought. Flask has carried over the same terminology and concept of a \"static\" folder, so this amusing cultural relic is here to stay.</p><p>Anyhow, we're here today to help you serve those beautiful assets of yours, as static as they may be. We'll do so by exploring the top-two libraries available to us: <strong>Flask-Static-Compress</strong>, and <strong>Flask-Assets</strong>.</p><h2 id=\"application-structure-for-flask-apps-with-frontend\">Application Structure For Flask Apps with Frontend</h2><p>Best practices aside, we'll start with the most straightforward project structure for a Flask web app. Let's work with this structure:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">myproject\n├─ /static\n│  └─ /js\n│  └─ /less\n│  └─ /img\n│  └─ /build\n├─ /templates\n└─ app.py\n</code></pre>\n<!--kg-card-end: markdown--><p>All the Python we need is going to sit in a plump little <strong>app.py</strong><em> </em>file. </p><p><strong>Templates</strong> hold the same concept as they do to equivalent frameworks such as Express: this is where we contain <em>pages</em>, <em>partials</em>, and <em>layouts.</em> Flask's default <strong>Jinja2</strong> templating engine has personally served me well enough to never investigate an alternative.</p><p><strong>/Static </strong>is where we'll store the <em>raw</em> <em>source</em> files for things like preprocessed stylesheets and JavaScript. At runtime, these sources files will be compressed and stored elsewhere in a production setting, such as that nifty <strong>/build</strong> folder we created (or feel free to call it <em>/dist</em>, whatever, it's your party man). </p><p>It's best practice to serve these from a CDN at runtime, but whatever.</p><p>In contrast to NodeJS apps, things like images and fonts are stored in the /static folder as well. This distinguishes Python's concept of /<em>static</em> from, say, another framework's concept of /<em>src: </em>instead of being a folder of only source code, we pretty much have a folder of <em>all that shit which isn't Python. </em>And we've come full circle.</p><h2 id=\"creating-the-flask-app-object\">Creating The Flask App Object</h2><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask, url_for, render_template, request, Response\n\napp = Flask(__name__, static_folder=&quot;static&quot;, template_folder=&quot;templates&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>We initiate our app on line 4 with <code>app = Flask()</code>.  We create our app with three parameters/attributes:</p><ul><li><code>__name__</code>: Now that I think about it, I've never actually considered what this first parameter is doing. Just know that you need it,</li><li><code>static_folder</code>: Specifies the name of the folder where static assets will be served. This is based on where your app believes the root folder lives. Because our app is a single directory, it knows that /<em>static</em> is in the current directory.</li><li><code>template_folder</code>: Same as above, but contains Jinja2 templates, AKA the files which become HTML.</li></ul><p>It's important to reiterate that these folders default to being <em>relative to the current location of </em><strong>app.py</strong><em>.</em> If we want to change this behavior, we can pass <code>instance_path=/path/to/desired/dir/</code> to override this behavior.</p><h2 id=\"method-1-flask-static-compress\">Method 1: Flask-Static-Compress</h2><p>There's more than one way to skin a cat, and there's certainly more than one library or philosophy for serving pages and styles in Flask. <strong>flask_static_compress </strong>is one such library, which we'll include in <strong>app.py</strong><em>:</em> </p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask, url_for, render_template, request, Response\nfrom flask_static_compress import FlaskStaticCompress\n</code></pre>\n<!--kg-card-end: markdown--><p><strong><a href=\"https://github.com/alanhamlett/flask-static-compress\">flask_static_compress</a></strong> is a cool library for compressing and joining assets together. If you've ever used Gulp, it achieves some of the common tasks Gulp might, but with a MUCH different philosophy. Some key differences are:</p><ul><li>The ability to served compressed assets individually, as opposed to one giant site bundle.</li><li>Never needing to explicitly fun a build command to create files served at runtime.</li></ul><p>Before serving any assets, we'll need a landing page for our app. While still in <strong>app.py,</strong> we need to set a route for anybody who visits our site:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask, url_for, render_template, request, Response\nfrom flask_static_compress import FlaskStaticCompress\n\napp = Flask(__name__, static_folder=&quot;static&quot;, template_folder=&quot;templates&quot;)\n\n@app.route('/', methods=['GET'])\ndef home():\n    &quot;&quot;&quot;Landing page.&quot;&quot;&quot;\n    return render_template('/index.html', title=&quot;Lame Site&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>Our route listens for traffic hitting \"/\" (our root directory) and kindly serves them the page <strong>index.html</strong> as you might expect. Because we set the value of <code>templates_folder</code> just now, Flask knows to serve a file living in /<strong>templates/index.html</strong>. </p><p>If you need some pointers on creating basic templates in Flask in which to load your frontend assets, I'd suggest taking a look back at the previous post.</p><h3 id=\"frontend-yolo-swag\">Frontend YOLO Swag</h3><p>Back to your project, make <strong>.less</strong> file and a <strong>.js</strong> file in the appropriate places:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">myproject\n├─ /build\n├─ /static\n│  └─ js\n│  │  └─ main.js\n│  └─ less\n│  │  └─ style.js\n│  └─ img\n├─ /templates\n│  └─ layout.html\n│  └─ index.html\n└─ app.py\n</code></pre>\n<!--kg-card-end: markdown--><p>Use these files to brand your site accordingly. Add some images, memes, propaganda, viruses, etc. Whatever your heart desires.</p><p>Back in <strong>app.py</strong><em> </em>we need to finish configuring our library:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask, url_for, render_template, request, Response\nfrom flask_static_compress import FlaskStaticCompress\n\napp = Flask(__name__)\napp.config['COMPRESSOR_DEBUG'] = app.config.get('DEBUG')\napp.config['COMPRESSOR_STATIC_PREFIX'] = 'static'\napp.config['COMPRESSOR_OUTPUT_DIR'] = 'build'\napp.static_folder = 'static'\ncompress = FlaskStaticCompress(app)\n\n\n@app.route('/', methods=['GET'])\ndef home():\n    &quot;&quot;&quot;Landing page.&quot;&quot;&quot;\n    return render_template('/index.html', title=&quot;Lame Site&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>Congrats! the main part of your application is pretty much done, just note a few things:</p><ul><li>Notice this time we set our folder paths via <em><strong>app.config[]</strong></em> as opposed to inline, in the earlier example. This is simply a matter of preference.</li><li><strong>compress = FlaskStaticCompress(app) </strong>initializes our library, so definitely do that.</li><li>Fun tidbit: <strong>app.static_folder = 'static' </strong>is a snippet which can live within any route to <em>override</em> the default app settings for where your folders are located. </li></ul><h2 id=\"compressed-2-deff\">Compressed 2 deff</h2><p>Let's wrap this bad boy up. Back in layout.html, let's add those static files we created.</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">&lt;!doctype html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;{% block title %}{% endblock %} - My Lame Site&lt;/title&gt;\n  &lt;!-- Meta Data --&gt;\n  &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;\n  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, viewport-fit=cover&quot;&gt;\n    \n  &lt;!-- CSS --&gt;\n  {% compress 'css' %}\n     &lt;link href=&quot;{{ url_for('static', filename='less/home.less') }}&quot; type=&quot;text/less&quot;&gt;\n  {% endcompress %}\n    \n  &lt;!-- JS --&gt;\n    {% compress 'js' %}\n      &lt;script src=&quot;{{ url_for('static', filename='js/previews.js') }}&quot;&gt;&lt;/script&gt;\n\t{% endcompress %}\n&lt;/head&gt;\n&lt;body&gt;\n  {% block content %}{% endblock %}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>Let's analyze this real quick:</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">{% compress 'css' %}\n   &lt;link href=&quot;{{ url_for('static', filename='less/home.less') }}&quot; type=&quot;text/less&quot;&gt;\n{% endcompress %}\n</code></pre>\n<!--kg-card-end: markdown--><p>All files within the <code>{% compress 'css' %}</code> block will be minified and joined into a single file, and then moved to the build folder we specified earlier. It's that easy- no jobs to run beforehand, etc.</p><p>What might also catch your eye is how we define the path:</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">{{ url_for('static', filename='less/home.less') }}\n</code></pre>\n<!--kg-card-end: markdown--><p>This is a Jinja path dynamically locating our source file from our specified static doc. Well, I'll be darned.</p><h2 id=\"method-2-flask-assets\">Method 2: Flask-Assets</h2><p><strong>FlaskStaticCompress</strong> is great, but <strong><a href=\"http://flask-assets.readthedocs.io/en/latest/\">Flask_assets</a> </strong>might even be better. If you're familiar with Webpack, consider the philosophy behind <em>bundling.</em> Creating <em>bundles</em> of frontend assets makes sense when we can draw clear distinctions of alike-screens in our app: this way, users don't download the entirety of our assets for screens they might not visit upfront, while pre-loading assets for pages they'll <em>probably</em> visit.</p><p>The <strong>Flask-Assets</strong> library goes hand-in-hand with the concept of Flask <strong>Blueprints</strong>. If you aren't familiar with Blueprints just yet, I encourage you to become familiar <a href=\"https://hackersandslackers.com/structuring-your-flask-app/\">here</a>.</p><p>To get started, we'll install the necessary libraries:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ pip3 install flask-assets lesscpy cssmin jsmin\n</code></pre>\n<!--kg-card-end: markdown--><p>This is working under the assumption that we're be writing styles in LESS. If you prefer sass, <strong>libsass</strong> can take the place of <strong>lesscpy</strong>.</p><p>The other two libraries, <strong>cssmin</strong> and <strong>jsmin</strong>, are for minifying CSS and JS assets respectively.</p><p>Let's see how we pull this off:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">...\nfrom flask_assets import Environment, Bundle\n\n\n# Flask-Assets Configuration\nless_bundle = Bundle('src/less/*.less',\n                     filters='less,cssmin',\n                     output='dist/css/account.css',\n                     extra={'rel': 'stylesheet/less'})\njs_bundle = Bundle('src/js/*.js',\n                   filters='jsmin',\n                   output='dist/js/main.min.js')\nassets.register('less_all', less_bundle)\nassets.register('js_all', js_bundle)\nless_bundle.build()\njs_bundle.build()\n``</code></pre>\n<!--kg-card-end: markdown--><p>Notice how we only import flask_assets of all the libraries we installed- this is intentional. The other libraries do not need to be imported anywhere.</p><p><strong>less_bundle</strong> and <strong>js_bundle</strong> represent groupings of LESS and JS files to be stitched into one single file. Any positional arguments to be passed in to <code>Bundle()</code> will be taken as paths of sources files to bundle: we can bundle as many or as few files as we want (or in our case , just import *).</p><p>The <strong>filters</strong> argument is where we tell our <code>Bundle()</code> how to treat the files we've passed. In the case of <strong>less_bundle, </strong>passing <code>less,cssmin</code> indicates that the incoming files will be LESS files, to be compiled into CSS files, and then outputted as minified CSS files. the output destination, of course, is handled by the argument <code>output</code>.</p><h2 id=\"final-thoughts\">Final Thoughts</h2><p>The great thing about Flask (and Python in general) is that you're provided the luxury to write code in a manner which you find enjoyable. Considering Flask is a relatively young framework, we're in a bit of a golden age where there are just enough libraries to suit your tastes, but not enough to get lost in an NPM level hell.</p><p>In my completely biased and untrustworthy opinion, it's hard to imagine getting involved with a Framework in a sweeter spot than where Flask is right now. </p>","url":"https://hackersandslackers.com/serving-static-assets-in-flask/","uuid":"d1c8d104-6392-411b-86d4-75326e8e0960","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b5552047c9c156d9440c0ae"}},{"node":{"id":"Ghost__Post__5c5822200a214230dae40906","title":"Powerful Page Templates in Flask With Jinja","slug":"powerful-page-templates-in-flask-with-jinja","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/jinja@2x.jpg","excerpt":"Work with markup that writes itself using Flask's built-in Jinja library.","custom_excerpt":"Work with markup that writes itself using Flask's built-in Jinja library.","created_at_pretty":"04 February, 2019","published_at_pretty":"20 July, 2018","updated_at_pretty":"28 March, 2019","created_at":"2019-02-04T06:29:36.000-05:00","published_at":"2018-07-20T06:30:00.000-04:00","updated_at":"2019-03-28T05:18:50.000-04:00","meta_title":"Powerful Page Templates in Flask With Jinja | Hackers and Slackers","meta_description":"Work with markup that writes itself. Flask's built-in Jinja library allows you to create Python applications with smarter page templates.","og_description":"Work with markup that writes itself. Flask's built-in Jinja library allows you to create Python applications with smarter page templates.","og_image":"https://hackersandslackers.com/content/images/2019/02/jinja@2x.jpg","og_title":"Powerful Page Templates in Flask With Jinja","twitter_description":"Work with markup that writes itself. Flask's built-in Jinja library allows you to create Python applications with smarter page templates.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/jinja@2x.jpg","twitter_title":"Powerful Page Templates in Flask With Jinja","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"}],"plaintext":"So you want to build a web application in Python, eh? Hasn't anybody told you...\nPython is SLOW! Python is subject to CONTEXT SWITCHING! Oh, the HORROR!\n\nChances are most of these people aren't well-versed in Python at all. I enjoy\ncreating web applications in Flask more-so than I do in Node. Even if we were to\nput aside somehow the thousands of potentially malicious Javascript libraries\nneeded to stand up a simple app, or the decades of legacy knowledge needed to\ntolerate the JavaScript ecosystem without going insane: the simplicity of Flask\npaired and its libraries get the job done faster in most cases. Oh yeah, and you\ncan write backend logic in a language intended to do  so at the drop of a dime.\n\nOne of Flask's early surprises hits you when working with Jinja2. Jinja is\nFlask's default templating system, which processes templates into HTML markup to\nbe served to users at runtime. In addition to the inheritance and partial\ninclusion we've come to expect from templating systems, Jinja is particularly\nwell-equipped build pages out of raw data. You'll see what I mean.\n\nLayouts, Pages, and Partials\nLet's add three pages to our templates  folder, which is a directory typically\nreserved for template files. We'll add 3 files: layout.html, index.html, and \nnav.html.  Each of these templates represents one of three common template\n\"types\" when building in Jinja. \n\nOh, and disregard the fact that these files retain an HTML file extension- they\nare oh, so much more than that.\n\nmyproject\n├─ /templates\n│  ├─ layout.html\n│  ├─ index.html\n│  └─ nav.html\n└─ app.py\n\n\nCreate a Simple Route to Get Started\nWe'll make a brief stop in app.py  to set up the most basic logic an app can\nhave: serving up a homepage:\n\nfrom flask import Flask, render_template\n\napp = Flask(__name__, template_folder=\"templates\")\n\n@app.route('/')\ndef home():\n    \"\"\"Landing page.\"\"\"\n    return render_template('/index.html', title=\"Lame Site\")\n\n\nNote how we specify template_folder=\"templates\"  when instantiating our app\nobject; this is critical to let Flask know where templates are going to be\nstored in the project directory. Be aware that this directory is almost always\nexplicitly set as /templates. If you store your templates anywhere else, you\nhave a mental health problem.\n\nThe Bread and Butter of Template Inheritance\nLayout.html  is going to be our base template. In other words, this barebones\nfile will represent elements which should be common to all  of our app's pages,\nsuch as metadata, analytics, etc. It is the 'page we load other pages into.'  \n\nIf you're familiar with Handlebars\n[https://hackersandslackers.com/handlebars-templating-in-expressjs/], Jinja's\ntemplating concepts are the same deal with slightly different syntax. Here's a\ndecent layout.html  example:\n\n<!-- layout.html -->\n<!doctype html>\n<html>\n<head>\n  <title>{{title}}</title>\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, viewport-fit=cover\">\n    <!-- Google Analytics -->\n    <script>\n    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;\n    ga('create', 'UA-XXXXX-Y', 'auto');\n    ga('send', 'pageview');\n    </script>\n    <script async src='https://www.google-analytics.com/analytics.js'></script>\n    <!-- End Google Analytics -->\n</head>\n<body>\n  {% include 'nav.html' %}\n  {% block content %}{% endblock %}\n  {% include 'footer.html' %}\n</body>\n</html>\n\n\nNote the bracketed values in our otherwise-HTML! Each of these represents a\nreservation of \"stuff to come.\" That \"stuff\" could come in the form of a\nvariable, a partial, or code from another template. \n\nWe've just utilized three templating concepts in the above example:\n\n * The double-bracket {{title}}  is reserved to be replaced with a variable\n   named 'title' when we serve this view in Flask. We pass variables to\n   templates when we render them in the 'routes' part of our app.\n * Includes such as {% include 'nav.html' %}  are saying \"load the entirety of a\n   separate HTML file named nav.html  into this spot right here.\" This is called\n   a partial. Partials are encapsulated, standalone components intended to be\n   frequently reused throughout our app.\n * Things get real interesting with blocks, as seen in {% block content %}{%\n   endblock %}. This statement is reserving a chunk  of our template to receive\n   a corresponding chunk  of another template when such a template is loaded\n   into layout.hml. Remember: layouts are just barebones commonalities between\n   pages. To build meaningful pages, we must combine the parts of unique pages\n   (such as index.html) with layouts to create full pages. \n\nLet's look at index.html:  the file we're about to shove into layout.html:\n\n<!-- index.html -->\n{% extends 'layout.html' %}\n\n{% block content %}\n<div class=\"container\">\n<h1>My Lame site</h1>\n    <p>Hello, and welcome to my lame site! I'm so glad you're here. I'm so lonely.</p>\n</div>\n{% endblock %}\n\n\nRemember in the route we created in app.py:  our function states \"load\nindex.html when users visit /.\" We never mention layout.html  at all. That is\nbecause by including {% extends 'layout.html' %}  in  index.html, we're  stating\nthat index.html  should extend  layout.html. index.html  is our unique snowflake\nof a page, and layout  is our boring skeleton.\n\nBack to talking about blocks:  templates can contain multiple \"blocks\" of code.\nEach named block (such as  {% block content %}) in a page such as index.html \nshould correspond to an empty block we reserved in layout.html. When we serve\nthe final page, it's like we're plugging plugs into their respective sockets. We\ncan reserve as many \"blocks\" in our layout as we want, and thus serve multiple\nblocks within the same template. \n\nTo help illustrate this, let's say you're building a horrible clickbait site\nwhere your requirements dictate that horrible, invasive ads should appear\nbetween pieces of content of every page of your site. If we keep that page\nstructure to layout.html, then we can retrofit our layout to have multiple slots\nfor incoming content from index.html:  both before  and after  the horrible\nmonstrosity of an idea I already regret imagining. If index.html  contained both\n {% block content1 %}...{% endblock %}  and {% block content2 %}...{% endblock\n%}, those blocks are now independent entities which can be loaded to their\nrespective slots.\n\nPassing Data to Templates\nWhen we passed title=\"Lame Site\"  to index.html in our route, we were passing a\nsimple variable to replace {{title}}. Check out this example of what we can do\nwhen we pass JSON objects to templates:\n\n<form action=\"/submitted\" method=post>\n  {% if error %}\n   <p class=error><strong>Error:</strong> {{ error }}</p>\n  {% endif %}\n  {% for field in request.fields.requestTypeFields %}\n     {% if field.name in ('Category', 'Product', 'Dashboard Name') %}\n          <select id=\"{{request.name}} {{field.name}}\" \n                  name=\"{{field.name}}\" \n                  label=\"{{field.name}}\" \n                  class=\"input-field\">\n           <option value=\"Choose your option\" \n                   disabled \n                   selected>\n               {{field.description}}\n            </option>\n            {% for option in field.validValues %}\n                <option value=\"{{option.value}}\">\n                    {{option.label}}\n                </option>\n                {% endfor %}\n            </select>\n            <label>{{field.name}}</label>\n       {% elif field.name == 'Description' %}\n            <label for=\"{{request.name}} {{field.name}}\">\n                {{field.name}}\n            </label>\n            <textarea id=\"{{field.name}}\" \n                      class=\"materialize-textarea input-field\" \n                      placeholder=\"{{field.description}}\" \n                      name=\"{{field.name}}\">\n             </textarea>\n         {% else %}\n         <label for=\"{{request.name}} {{field.name}}\">\n             {{field.name}}\n         </label>\n         <input placeholder=\"{{field.description}}\" \n                id=\"{{request.name}} {{field.name}}\" \n                type=\"text\" \n                class=\"input-field validate\" \n                name=\"{{field.name}}\">\n         {% endif %}\n    {% endfor %}\n    <input type=\"submit\" value=\"Submit\" class=\"btn cyan formsubmit\">\n</form>\n\n\nThose are for  loops and if  statements all working against a single JSON\nobject. This specific example demonstrates building a form based on a JSON\nobject; one we've happened to fetch from JIRA. Just by passing this JSON to a\nJinja template, we can recreate an entire enterprise system's form logic in a\nsimple template block.\n\nHere's another example. This one returns feedback to a user who presumably\nfilled out a form incorrectly, thus must be chastised with popup error messages:\n\n{% with messages = get_flashed_messages() %}\n  {% if messages %}\n    <ul class=flashes>\n    {% for message in messages %}\n      <li>{{ message }}</li>\n    {% endfor %}\n    </ul>\n  {% endif %}\n{% endwith %}\n\n\nSmall But Powerful\nTemplates are one small part of Flask, but they demonstrate a greater philosophy\ngenerally consistent throughout the framework: small libraries can do big\nthings. Sometimes it may take some courage to maneuver with the tools at hand\ncleverly, but the power of the Triforce is with you. You are Hyrule's last hope,\ngreat warrior... now you must make haste in your duties to build little apps. Or\nwhatever.","html":"<p>So you want to build a web application in Python, eh? Hasn't anybody told you... Python is <em>SLOW</em>! Python is subject to <em>CONTEXT SWITCHING</em>! Oh, the <em>HORROR</em>!</p><p>Chances are most of these people aren't well-versed in Python at all. I enjoy creating web applications in Flask more-so than I do in Node. Even if we were to put aside somehow the thousands of potentially malicious Javascript libraries needed to stand up a simple app, or the decades of legacy knowledge needed to tolerate the JavaScript ecosystem without going insane: the simplicity of Flask paired and its libraries get the job done faster in most cases. Oh yeah, and you can write backend logic in a language <em>intended to do</em> so at the drop of a dime.</p><p>One of Flask's early surprises hits you when working with <strong>Jinja2</strong>. Jinja is Flask's default templating system, which processes templates into HTML markup to be served to users at runtime. In addition to the inheritance and partial inclusion we've come to expect from templating systems, Jinja is particularly well-equipped build pages out of raw data. You'll see what I mean.</p><h2 id=\"layouts-pages-and-partials\">Layouts, Pages, and Partials</h2><p>Let's add three pages to our <em>templates</em> folder, which is a directory typically reserved for template files. We'll add 3 files: <strong>layout.html, index.html, </strong>and <strong>nav.html.</strong> Each of these templates represents one of three common template \"types\" when building in Jinja. </p><p>Oh, and disregard the fact that these files retain an HTML file extension- they are oh, so much more than that.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">myproject\n├─ /templates\n│  ├─ layout.html\n│  ├─ index.html\n│  └─ nav.html\n└─ app.py\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"create-a-simple-route-to-get-started\">Create a Simple Route to Get Started</h2><p>We'll make a brief stop in <strong>app.py</strong> to set up the most basic logic an app can have: serving up a homepage:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask, render_template\n\napp = Flask(__name__, template_folder=&quot;templates&quot;)\n\n@app.route('/')\ndef home():\n    &quot;&quot;&quot;Landing page.&quot;&quot;&quot;\n    return render_template('/index.html', title=&quot;Lame Site&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>Note how we specify <code>template_folder=\"templates\"</code> when instantiating our app object; this is critical to let Flask know where templates are going to be stored in the project directory. Be aware that this directory is almost always explicitly set as /<em>templates. </em>If you store your templates anywhere else, you have a mental health problem.</p><h2 id=\"the-bread-and-butter-of-template-inheritance\">The Bread and Butter of Template Inheritance</h2><p><strong>Layout.html</strong> is going to be our base template. In other words, this barebones file will represent elements which should be common to <em>all</em> of our app's pages, such as metadata, analytics, etc. It is the '<em>page we load other pages into.'</em> </p><p>If you're familiar with <a href=\"https://hackersandslackers.com/handlebars-templating-in-expressjs/\">Handlebars</a>, Jinja's templating concepts are the same deal with slightly different syntax. Here's a decent <strong>layout.html</strong> example:</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">&lt;!-- layout.html --&gt;\n&lt;!doctype html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;{{title}}&lt;/title&gt;\n  &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;\n  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, viewport-fit=cover&quot;&gt;\n    &lt;!-- Google Analytics --&gt;\n    &lt;script&gt;\n    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;\n    ga('create', 'UA-XXXXX-Y', 'auto');\n    ga('send', 'pageview');\n    &lt;/script&gt;\n    &lt;script async src='https://www.google-analytics.com/analytics.js'&gt;&lt;/script&gt;\n    &lt;!-- End Google Analytics --&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  {% include 'nav.html' %}\n  {% block content %}{% endblock %}\n  {% include 'footer.html' %}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>Note the bracketed values in our otherwise-HTML! Each of these represents a reservation of \"stuff to come.\" That \"stuff\" could come in the form of a variable, a partial, or code from another template. </p><p>We've just utilized three templating concepts in the above example:</p><ul><li>The double-bracket <code>{{title}}</code> is reserved to be replaced with a variable named 'title' when we serve this view in Flask. We pass variables to templates when we render them in the 'routes' part of our app.</li><li>Includes such as <code>{% include 'nav.html' %}</code> are saying \"load the entirety of a separate HTML file named <strong>nav.html</strong> into this spot right here.\" This is called a <em>partial</em>. Partials are encapsulated, standalone components intended to be frequently reused throughout our app.</li><li>Things get real interesting with <em>blocks</em>, as seen in <code>{% block content %}{% endblock %}</code>. This statement is reserving a <em>chunk</em> of our template to receive a <em>corresponding chunk</em> of another template when such a template is loaded into <strong>layout.hml</strong>. Remember: layouts are just barebones commonalities between pages. To build meaningful pages, we must combine the parts of unique pages (such as <strong>index.html</strong>) with layouts to create full pages. </li></ul><p>Let's look at <strong>index.html:</strong> the file we're about to shove into <strong>layout.html:</strong></p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">&lt;!-- index.html --&gt;\n{% extends 'layout.html' %}\n\n{% block content %}\n&lt;div class=&quot;container&quot;&gt;\n&lt;h1&gt;My Lame site&lt;/h1&gt;\n    &lt;p&gt;Hello, and welcome to my lame site! I'm so glad you're here. I'm so lonely.&lt;/p&gt;\n&lt;/div&gt;\n{% endblock %}\n</code></pre>\n<!--kg-card-end: markdown--><p>Remember in the route we created in <strong>app.py:</strong> our function states <em>\"load index.html when users visit /.\" </em>We never mention <strong>layout.html</strong> at all. That is because by including <code>{% extends 'layout.html' %}</code><strong> </strong>in<strong> index.html, </strong>we're<strong> </strong>stating that <strong>index.html</strong> should <em>extend</em> <strong>layout.html. index.html</strong> is our unique snowflake of a page, and <strong>layout</strong> is our boring skeleton.</p><p>Back to talking about blocks:  templates can contain multiple \"blocks\" of code. Each named block (such as<strong> </strong><code>{% block content %}</code>) in a page such as <strong>index.html</strong> should correspond to an empty block we reserved in <strong>layout.html</strong>. When we serve the final page, it's like we're plugging plugs into their respective sockets. We can reserve as many \"blocks\" in our layout as we want, and thus serve multiple blocks within the same template. </p><p>To help illustrate this, let's say you're building a horrible clickbait site where your requirements dictate that horrible, invasive ads should appear between pieces of content of every page of your site. If we keep that page structure to <strong>layout.html</strong>, then we can retrofit our layout to have multiple slots for incoming content from <strong>index.html:</strong> both <em>before</em> and <em>after</em> the horrible monstrosity of an idea I already regret imagining. If <strong>index.html</strong> contained both <code>{% block content1 %}...{% endblock %}</code> and <code>{% block content2 %}...{% endblock %}</code>, those blocks are now independent entities which can be loaded to their respective slots.</p><h2 id=\"passing-data-to-templates\">Passing Data to Templates</h2><p>When we passed <code>title=\"Lame Site\"</code> to <strong>index.html </strong>in our route, we were passing a simple variable to replace <code>{{title}}</code>. Check out this example of what we can do when we pass JSON objects to templates:</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">&lt;form action=&quot;/submitted&quot; method=post&gt;\n  {% if error %}\n   &lt;p class=error&gt;&lt;strong&gt;Error:&lt;/strong&gt; {{ error }}&lt;/p&gt;\n  {% endif %}\n  {% for field in request.fields.requestTypeFields %}\n     {% if field.name in ('Category', 'Product', 'Dashboard Name') %}\n          &lt;select id=&quot;{{request.name}} {{field.name}}&quot; \n                  name=&quot;{{field.name}}&quot; \n                  label=&quot;{{field.name}}&quot; \n                  class=&quot;input-field&quot;&gt;\n           &lt;option value=&quot;Choose your option&quot; \n                   disabled \n                   selected&gt;\n               {{field.description}}\n            &lt;/option&gt;\n            {% for option in field.validValues %}\n                &lt;option value=&quot;{{option.value}}&quot;&gt;\n                    {{option.label}}\n                &lt;/option&gt;\n                {% endfor %}\n            &lt;/select&gt;\n            &lt;label&gt;{{field.name}}&lt;/label&gt;\n       {% elif field.name == 'Description' %}\n            &lt;label for=&quot;{{request.name}} {{field.name}}&quot;&gt;\n                {{field.name}}\n            &lt;/label&gt;\n            &lt;textarea id=&quot;{{field.name}}&quot; \n                      class=&quot;materialize-textarea input-field&quot; \n                      placeholder=&quot;{{field.description}}&quot; \n                      name=&quot;{{field.name}}&quot;&gt;\n             &lt;/textarea&gt;\n         {% else %}\n         &lt;label for=&quot;{{request.name}} {{field.name}}&quot;&gt;\n             {{field.name}}\n         &lt;/label&gt;\n         &lt;input placeholder=&quot;{{field.description}}&quot; \n                id=&quot;{{request.name}} {{field.name}}&quot; \n                type=&quot;text&quot; \n                class=&quot;input-field validate&quot; \n                name=&quot;{{field.name}}&quot;&gt;\n         {% endif %}\n    {% endfor %}\n    &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; class=&quot;btn cyan formsubmit&quot;&gt;\n&lt;/form&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>Those are <code>for</code> loops and <code>if</code> statements all working against a single JSON object. This specific example demonstrates building a form based on a JSON object; one we've happened to fetch from JIRA. Just by passing this JSON to a Jinja template, we can recreate an entire enterprise system's form logic in a simple template block.</p><p>Here's another example. This one returns feedback to a user who presumably filled out a form incorrectly, thus must be chastised with popup error messages:</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">{% with messages = get_flashed_messages() %}\n  {% if messages %}\n    &lt;ul class=flashes&gt;\n    {% for message in messages %}\n      &lt;li&gt;{{ message }}&lt;/li&gt;\n    {% endfor %}\n    &lt;/ul&gt;\n  {% endif %}\n{% endwith %}\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"small-but-powerful\">Small But Powerful</h3><p>Templates are one small part of Flask, but they demonstrate a greater philosophy generally consistent throughout the framework: small libraries can do big things. Sometimes it may take some courage to maneuver with the tools at hand cleverly, but the power of the Triforce is with you. You are Hyrule's last hope, great warrior... now you must make haste in your duties to build little apps. Or whatever.</p>","url":"https://hackersandslackers.com/powerful-page-templates-in-flask-with-jinja/","uuid":"055ba6eb-f177-4b9d-b85e-2c7730850bf1","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c5822200a214230dae40906"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867369b","title":"Data Could Save Humanity if it Weren't for Humanity","slug":"data-could-save-humanity","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/savehumanity@2x.jpg","excerpt":"A compelling case for robot overlords.","custom_excerpt":"A compelling case for robot overlords.","created_at_pretty":"03 July, 2018","published_at_pretty":"20 July, 2018","updated_at_pretty":"19 February, 2019","created_at":"2018-07-03T03:41:14.000-04:00","published_at":"2018-07-20T00:14:00.000-04:00","updated_at":"2019-02-19T03:42:08.000-05:00","meta_title":"Data Could Solve Humanity's Problems, if it Weren't for Humanity | Hackers and Slackers","meta_description":"We all agree that 'data addiction' is reaching a peak, yet clueless about what's next. Specualation of “The Future of AI” is unimaginative at best.","og_description":"We all agree that 'data addiction' is reaching a peak, yet clueless about what's next. Specualation of “The Future of AI” is unimaginative at best.","og_image":"https://hackersandslackers.com/content/images/2018/07/savehumanity@2x.jpg","og_title":"Data Could Solve Humanity's Problems, if it Weren't for Humanity","twitter_description":"We all agree that 'data addiction' is reaching a peak, yet clueless about what's next. Specualation of “The Future of AI” is unimaginative at best.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/savehumanity@2x.jpg","twitter_title":"Data Could Solve Humanity's Problems, if it Weren't for Humanity","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},{"name":"Big Data","slug":"bigdata","description":"Work with unstructured data across file types and schemas. Tools such as data warehouses, Hadoop, Spark, BigQuery, etc.","feature_image":null,"meta_description":"Work with massive amounts of unstandardized data across file types and schemas. Includes working with data warehouses, Hadoop, Spark, BigQuery, etc.","meta_title":"Big Data | Hackers and Slackers","visibility":"public"}],"plaintext":"A decade has passed since I stumbled into technical product development. Looking\nback, I've spent that time almost exclusively in the niche of data-driven\nproducts and engineering. While it seems obvious now, I realized in the 2000s\nthat you could generally create two types of product: you could either build a\n(likely uninspired) UI for existing data, or you could build products which\nproduced new data or interpreted existing data in a new useful way. Betting on\nthe latter seemed like an obvious choice. The late 2000’s felt like building\napps for the sake of apps most of the time. Even today Product Hint is littered\nwith weather apps and rehashed tools, solving problems so insignificant that\nthey almost seem satirical.\n\nYears passed, thus our data-centric tools evolved to fit cultural mind shifts in\nbusinesses which speculated on how these tools could be used. This began to\nbuild a clear yet slowly-growing narrative about how enterprises consider data\nanalysis in their org structures. Unfortunately, I can't say that much about\nthat shift has been positive. There are a number of major problems I believe we\nneed to address:\n\n *   SaaS is created with the goal of selling the product to enterprises. While\n   humanity's understanding of data science reach unprecedented territory, we\n   choose to perfect the  sales pitch  while neglecting education on these\n   tools.\n * As an atrocity to science, individual actors commonly cherry pick information\n   to confirm conclusions for personal benefit, without checks and balances. \n * Data which contradicts knee jerk assumptions made by executives are sometimes\n   taken as personal threats or attacks.\n * Most importantly, data professionals are horribly siloed. Analysts,\n   scientists, and engineers waste far too much time drawing lines between\n   roles: I find it absolutely absurd  to unanimously agree that tool X is for\n   BI  while tool Y is for data cleanup. Considering we all know  these tools\n   are running stacks on Python, R, SQL, etc, there is no reason to succumb to\n   the limitations of proprietary software (such as Tableau). We've turned a\n   blind eye to the possibility of 'data as a service': a chance to overlap\n   responsibilities by building a better  tool to reduce friction, as opposed to\n   increase it in the interest of selling more software.\n\nWhile we might all agree that collective 'data addiction' is reaching a peak,\nmost of us barely know what we mean by that. We conceptually understand that\ndata is important, but our imaginations on how to utilize this power effectively\nleaves a lot to be desired. IBM Watson probably had profound capabilities, but\nits failure lies with the humans tasked to make this technology relevant and\nuseful for humankind.\n\nThe Analytics Honeymoon\nAs I imagine most in the Product Management professionals do, I originally\nconsidered  data analysis to come in the form of web and app analytics. This was\na one-dimensional era; consumer-facing data served the sole purpose of\noptimizing sales and ad revenue, and there were much fewer choices of\nEnterprise-level tools to fall in love with. While the cheaper tools were just\nfine, corporate America had already fallen in love with a fickle mistress known\nas Omniture. \n\nOmniture was in fact in many ways the superior product on the market. As I'm\nsure Sales reps explained in those years, Omniture allowed for a vast level of\nevent tracking customization which was otherwise rare at the time: with the\nproper logic, effort, and willingness, executives could theoretically identify\ngranular issues in their product's conversation flow: issues which came attached\nwith cold hard facts in the form of numbers.\n\nThus, a game of numbers it was: in order to receive the level of granular detail\nexecutives wanted, there came a nominal fee. Well, many fees in fact: the\nproduct out-priced competitors tenfold upfront for the license itself. Since you\njust agreed to spend that much money on proprietary software, it only makes\nsense at that point that you should then hire a certified affiliated consultant\nto implement the custom reports, and then of course pay the lifelong upkeep that\ncomes with tracking events in ever-changing software. Despite all of these\ncosts, companies consistently moved forward with the choice under the\nrealization that the money saved from this data could far outweigh the cost.\n\nSo what happened when we actually collected all that data?\n\nIf You Could Get That Analytics Report, That Would be Great.\nEnterprises and data analysis were made for each other... but in a way that most\nclosely resembles a cliché romcom starring Julia Roberts. This romance follows\nthe beat of a metronome: while executives begin to grasp the impact of\ndata-based decisions, the commitment to actually acknowledge the abundance of\nthis information has its own lifespan. A/B testing, conversation funnels,\nsegmentation, etc: while the foreplay of implementing these buzzwords rolls on\nfor a number of weeks, it gives powerful figures time to reflect on one thing in\nparticular: they've owed their success to a lack of quantifiable accountability,\nand numbers are right around the corner. While this might not be a conscious\nact, it is an entirely real phenomenon.\n\nI've traditionally been a product manager, yet during that period of my career,\nI've found myself nominated to be Gatekeeper of Digital and Financial Data...\nfor whatever reason (it's worth reiterating that I am not nor ever have been an\nanalyst). The phenomenon followed a pattern. Given their expectations,\nexecutives reach their nerves end when the budget they allocated for\nenterprise-level sotftware is still under configuration, and has produced no\nresults. There's a reason why patience is a virtue isn't a phrase you see in\nmany sales pitches: we want what we're being sold, and we want it now. \n\nThats where I'd typically come in. As a product manager, analytics is a valuable\nweapon, so unspeakable amounts of unsolicited data thrown into my lap  seemed\nlike ammunition for change. When a company's problems are become as large as\nthey are obvious, some numerical correlations are nearly common sense..\n\nCue the dashboards, custom reports, event tracking, you name it. Often times\nexecutives would set aside a weekly cadence to review the expensive conclusions\nour software could finally produce. The weekly email newsletters I would produce\nwould be met with a euphoric chain of satisfied stakeholders, time and time\nagain. Finally it seemed, the conclusions were clear and our problems were\nquantifiable. And yet, nothing seemed to change.\n\nHuman Insecurities Versus World Problems\nAs a data enthusiast, I did what we all would've done: I placed analytics\ntracking on our analytics reports themselves. \"Great stuff, groundbreaking work\nhere\" said one CEO, who I'd seen had not bothered to click the link provided. At\na certain point, I began attaching empty Excel spreadsheets and posting dead\nlinks as the content of our beloved reports. Those too were 'groundbreaking',\napparently.\n\nThis is far from an isolated phenomenon in technology. Meeting after meeting,\nclient after client, I took front-row seats to blatant dismissal of numerical\nevidence in favor of  ego-driven decisions. Test A would prove to yield 30%\nhigher conversion rates than Test B, but Test B would prevail thanks to the\nsubjective emotional opinions of talking heads. In retrospect, I can see now how\na grown adult with a household would find the sudden introduction of facts\nthreatening. We have have imposter syndrome, and the twenty-something year old\nanalyst attempting to improve a company will almost always lose to an adult\nprotecting a family.\n\nConsider a recent example uncovered by mistake. While auditing usage for a\nwidely-know project management tool, something seemed off about our volume of\nusage with a product costing us unspeakable dollars. Our department had mostly\nbeen tasked  to upkeep this 'critical' internal system at all costs. As it turns\nout, over 80% of all activity had been out own internal upkeep. That's millions\nof dollars invested in something never used over the course of several years,\nall for the purpose of upholding a guise of value-add.\n\nBI, Data Science, and the Choice to Make That Distinction\nI've spent the last several months working deep under the hood attempting to\ndismantle our undisputed BI overlords over at Tableau. Fair warning: I'm about\nto rip in to a Tableau tangent here, but I promise there's a point.\n\nI was introduced to Tableau as a tool to fill a niche: quick analysis and\none-off extracts on tight timelines. The type of timelines where digging into\nPandas and potentially entering a .bash_profile hell with Anaconda simply wasn’t\nan option. I was pleased with its ability to serve this purpose- such that it\nsparked a spontaneous 1 thousand purchase for a personal license. Tableau\nDesktop, Tableau Prep, and Tableau server; a decision I’ll likely regret for the\nrest of my life.\n\nFrom my naïve perspective it seemed logical that Tableau could help assist in\nthe data cleanup and automation I had been handling in scripts previously. This\ncould not be more incorrect. Even with full access to my own Tableau instance,\nit is clear that Tableau has one motive only: to show you your data, and ensure\nyou don't take it elsewhere. Consider this:\n\nCheck out the worksheets and and dashboards you've published to Server.\nConsidering these are equivalent to simple database views, you'd expect the API\ncalls to be exposed in your dev tools... why not? They aren't.\n\nTableau runs on a Postgres database on your personal server. However, no mention\nof \"postgres\" or anything of the sort is searchable to a useful degree. There is\na highly protected Tableau superadmin account which has controls to all tables\nand views in this server, but most research will point users to unlock the\n\"readonly\" user which is essentially a red herring account, or perhaps useful if\nyou're spying on your employee's actions.\n\nAnd then we have the Tableau server API. Ah, what a gift it would be to query\nthose views we created, running on scheduled extracts, so that we might build\nsomething from this information. As it turns out, Tableau's REST API does little\nmore than reveal meta data about files you already knew about. Just in case you\nwere wondering the date it was created, for some weird useless reason.\n\nI'm not just picking on Tableau here (although I'll continue my series about\nhacking them soon enough). This has exposed a massive dichotomy in the way we\nsee and treat data as a profession, or rather, a series of professions. between\nthose who look at data, and those who manipulate, iterate one, and create things\nwith Data. Nobody has ever expressed this realization to me, and many of you\nlikely still don't see what the big deal is. That, to me, is the big deal.\n\nData should be a passion to those looking to improve humanity, without a doubt.\nIf we know personalities are wining the battles against numbers, and feel numb\nto the fact that our proprietary tools prevent us from using data effectively,\nthere's something to be said about the complacency of humanity as we commit to\nconsumption over production. \n\nCompany attitudes towards data are one thing, but individuals are an entirely\ndifferent story. That's a long-winded post for another time.","html":"<p>A decade has passed since I stumbled into technical product development. Looking back, I've spent that time almost exclusively in the niche of data-driven products and engineering. While it seems obvious now, I realized in the 2000s that you could generally create two types of product: you could either build a (likely uninspired) UI for existing data, or you could build products which produced new data or interpreted existing data in a new useful way. Betting on the latter seemed like an obvious choice. The late 2000’s felt like building apps for the sake of apps most of the time. Even today Product Hint is littered with weather apps and rehashed tools, solving problems so insignificant that they almost seem satirical.</p><p>Years passed, thus our data-centric tools evolved to fit cultural mind shifts in businesses which speculated on how these tools could be used. This began to build a clear yet slowly-growing narrative about how enterprises consider data analysis in their org structures. Unfortunately, I can't say that much about that shift has been positive. There are a number of major problems I believe we need to address:</p><ul><li><em> </em>SaaS is created with the goal of <em>selling </em>the product to enterprises. While humanity's understanding of data science reach unprecedented territory, we choose to perfect the<em> sales pitch</em> while neglecting education on these tools.</li><li>As an atrocity to science, individual actors commonly cherry pick information to confirm conclusions for personal benefit, without checks and balances. </li><li>Data which contradicts knee jerk assumptions made by executives are sometimes taken as personal threats or attacks.</li><li>Most importantly, data professionals are <em><strong>horribly siloed. </strong></em>Analysts, scientists, and engineers waste far too much time drawing lines between roles: I find it <em><strong>absolutely absurd</strong></em> to unanimously agree that <strong>tool X is for BI</strong> while <strong>tool Y is for data cleanup</strong>. Considering we <em>all know</em> these tools are running stacks on Python, R, SQL, etc, there is no reason to succumb to the limitations of proprietary software (such as Tableau). We've turned a blind eye to the possibility of 'data as a service': a chance to overlap responsibilities by building a <em>better</em> tool to reduce friction, as opposed to increase it in the interest of selling more software.</li></ul><p>While we might all agree that collective 'data addiction' is reaching a peak, most of us barely know what we mean by that. We conceptually understand that data is important, but our imaginations on how to utilize this power effectively leaves a lot to be desired. IBM Watson probably had profound capabilities, but its failure lies with the humans tasked to make this technology relevant and useful for humankind.</p><h2 id=\"the-analytics-honeymoon\">The Analytics Honeymoon</h2><p>As I imagine most in the Product Management professionals do, I originally considered  data analysis to come in the form of web and app analytics. This was a one-dimensional era; consumer-facing data served the sole purpose of optimizing sales and ad revenue, and there were much fewer choices of Enterprise-level tools to fall in love with. While the cheaper tools were just fine, corporate America had already fallen in love with a fickle mistress known as Omniture. </p><p>Omniture was in fact in many ways the superior product on the market. As I'm sure Sales reps explained in those years, Omniture allowed for a vast level of event tracking customization which was otherwise rare at the time: with the proper logic, effort, and willingness, executives could theoretically identify granular issues in their product's conversation flow: issues which came attached with cold hard facts in the form of numbers.</p><p>Thus, a game of numbers it was: in order to receive the level of granular detail executives wanted, there came a nominal fee. Well, many fees in fact: the product out-priced competitors tenfold upfront for the license itself. Since you just agreed to spend that much money on proprietary software, it only makes sense at that point that you should then hire a certified affiliated consultant to implement the custom reports, and then of course pay the lifelong upkeep that comes with tracking events in ever-changing software. Despite all of these costs, companies consistently moved forward with the choice under the realization that the money saved from this data could far outweigh the cost.</p><p>So what happened when we actually collected all that data?</p><h2 id=\"if-you-could-get-that-analytics-report-that-would-be-great-\">If You Could Get That Analytics Report, That Would be Great.</h2><p>Enterprises and data analysis were made for each other... but in a way that most closely resembles a cliché romcom starring Julia Roberts. This romance follows the beat of a metronome: while executives begin to grasp the impact of data-based decisions, the commitment to actually acknowledge the abundance of this information has its own lifespan. A/B testing, conversation funnels, segmentation, etc: while the foreplay of implementing these buzzwords rolls on for a number of weeks, it gives powerful figures time to reflect on one thing in particular: they've owed their success to a lack of quantifiable accountability, and numbers are right around the corner. While this might not be a conscious act, it is an entirely real phenomenon.</p><p>I've traditionally been a product manager, yet during that period of my career, I've found myself nominated to be Gatekeeper of Digital and Financial Data... for whatever reason (it's worth reiterating that I am not nor ever have been an analyst). The phenomenon followed a pattern. Given their expectations, executives reach their nerves end when the budget they allocated for enterprise-level sotftware is still under configuration, and has produced no results. There's a reason why patience is a virtue isn't a phrase you see in many sales pitches: we want what we're being sold, and we want it now. </p><p>Thats where I'd typically come in. As a product manager, analytics is a valuable weapon, so unspeakable amounts of unsolicited data thrown into my lap  seemed like ammunition for change. When a company's problems are become as large as they are obvious, some numerical correlations are nearly common sense..</p><p>Cue the dashboards, custom reports, event tracking, you name it. Often times executives would set aside a weekly cadence to review the expensive conclusions our software could finally produce. The weekly email newsletters I would produce would be met with a euphoric chain of satisfied stakeholders, time and time again. Finally it seemed, the conclusions were clear and our problems were quantifiable. And yet, nothing seemed to change.</p><h2 id=\"human-insecurities-versus-world-problems\">Human Insecurities Versus World Problems</h2><p>As a data enthusiast, I did what we all would've done: I placed analytics tracking on our analytics reports themselves. \"Great stuff, groundbreaking work here\" said one CEO, who I'd seen had not bothered to click the link provided. At a certain point, I began attaching empty Excel spreadsheets and posting dead links as the content of our beloved reports. Those too were 'groundbreaking', apparently.</p><p>This is far from an isolated phenomenon in technology. Meeting after meeting, client after client, I took front-row seats to blatant dismissal of numerical evidence in favor of  ego-driven decisions. Test A would prove to yield 30% higher conversion rates than Test B, but Test B would prevail thanks to the subjective emotional opinions of talking heads. In retrospect, I can see now how a grown adult with a household would find the sudden introduction of facts threatening. We have have imposter syndrome, and the twenty-something year old analyst attempting to improve a company will almost always lose to an adult protecting a family.</p><p>Consider a recent example uncovered by mistake. While auditing usage for a widely-know project management tool, something seemed off about our volume of usage with a product costing us unspeakable dollars. Our department had mostly been tasked  to upkeep this 'critical' internal system at all costs. As it turns out, over 80% of all activity had been out own internal upkeep. That's millions of dollars invested in something never used over the course of several years, all for the purpose of upholding a guise of value-add.</p><h2 id=\"bi-data-science-and-the-choice-to-make-that-distinction\">BI, Data Science, and the Choice to Make That Distinction</h2><p>I've spent the last several months working deep under the hood attempting to dismantle our undisputed BI overlords over at Tableau. Fair warning: I'm about to rip in to a Tableau tangent here, but I promise there's a point.</p><p>I was introduced to Tableau as a tool to fill a niche: quick analysis and one-off extracts on tight timelines. The type of timelines where digging into Pandas and potentially entering a .bash_profile hell with Anaconda simply wasn’t an option. I was pleased with its ability to serve this purpose- such that it sparked a spontaneous 1 thousand purchase for a personal license. Tableau Desktop, Tableau Prep, and Tableau server; a decision I’ll likely regret for the rest of my life.</p><p>From my naïve perspective it seemed logical that Tableau could help assist in the data cleanup and automation I had been handling in scripts previously. This could not be more incorrect. Even with full access to my own Tableau instance, it is clear that Tableau has one motive only: to show you your data, and ensure you don't take it elsewhere. Consider this:</p><p>Check out the worksheets and and dashboards you've published to Server. Considering these are equivalent to simple database views, you'd expect the API calls to be exposed in your dev tools... why not? They aren't.</p><p>Tableau runs on a Postgres database on your personal server. However, no mention of \"postgres\" or anything of the sort is searchable to a useful degree. There is a highly protected Tableau superadmin account which has controls to all tables and views in this server, but most research will point users to unlock the \"readonly\" user which is essentially a red herring account, or perhaps useful if you're spying on your employee's actions.</p><p>And then we have the Tableau server API. Ah, what a gift it would be to query those views we created, running on scheduled extracts, so that we might build something from this information. As it turns out, Tableau's REST API does little more than reveal meta data about files you already knew about. Just in case you were wondering the date it was created, for some weird useless reason.</p><p>I'm not just picking on Tableau here (although I'll continue my series about hacking them soon enough). This has exposed a massive dichotomy in the way we see and treat data as a profession, or rather, a series of professions. between those who look at data, and those who manipulate, iterate one, and create things with Data. Nobody has ever expressed this realization to me, and many of you likely still don't see what the big deal is. That, to me, is the big deal.</p><p>Data should be a passion to those looking to improve humanity, without a doubt. If we know personalities are wining the battles against numbers, and feel numb to the fact that our proprietary tools prevent us from using data effectively, there's something to be said about the complacency of humanity as we commit to consumption over production. </p><p>Company attitudes towards data are one thing, but individuals are an entirely different story. That's a long-winded post for another time.</p>","url":"https://hackersandslackers.com/data-could-save-humanity/","uuid":"01f56f59-a9ad-494a-993d-216716f68a7d","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b3b289ad0ac8a143588f360"}}]}},"pageContext":{"slug":"todd","limit":12,"skip":48,"numberOfPages":8,"humanPageNumber":5,"prevPageNumber":4,"nextPageNumber":6,"previousPagePath":"/author/todd/page/4/","nextPagePath":"/author/todd/page/6/"}}