{"data":{"ghostTag":{"slug":"the-rise-of-google-cloud","name":"#The Rise of Google Cloud","visibility":"internal","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole."},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c47584f4f3823107c9e8f23","title":"Google BigQuery's Python SDK: Creating Tables Programmatically","slug":"getting-started-google-big-query-python","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/bigquery101@2x.jpg","excerpt":"Create tables in Google BigQuery, auto-generate their schemas, and retrieve said schemas.","custom_excerpt":"Create tables in Google BigQuery, auto-generate their schemas, and retrieve said schemas.","created_at_pretty":"22 January, 2019","published_at_pretty":"02 February, 2019","updated_at_pretty":"28 March, 2019","created_at":"2019-01-22T12:52:15.000-05:00","published_at":"2019-02-02T09:24:00.000-05:00","updated_at":"2019-03-28T17:06:20.000-04:00","meta_title":"Google BigQuery's Python SDK: Creating Tables | Hackers and Slackers","meta_description":"Leverage Google Cloud's Python SDK to create tables in Google BigQuery, auto-generate their schemas, and retrieve said schemas.","og_description":"Leverage Google Cloud's Python SDK to create tables in Google BigQuery, auto-generate their schemas, and retrieve said schemas.","og_image":"https://hackersandslackers.com/content/images/2019/02/bigquery101@2x.jpg","og_title":"Google BigQuery's Python SDK: Creating Tables Programmatically","twitter_description":"Leverage Google Cloud's Python SDK to create tables in Google BigQuery, auto-generate their schemas, and retrieve said schemas.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/bigquery101@2x.jpg","twitter_title":"Google BigQuery's Python SDK: Creating Tables Programmatically","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Big Data","slug":"bigdata","description":"Work with unstructured data across file types and schemas. Tools such as data warehouses, Hadoop, Spark, BigQuery, etc.","feature_image":null,"meta_description":"Work with massive amounts of unstandardized data across file types and schemas. Includes working with data warehouses, Hadoop, Spark, BigQuery, etc.","meta_title":"Big Data | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Big Data","slug":"bigdata","description":"Work with unstructured data across file types and schemas. Tools such as data warehouses, Hadoop, Spark, BigQuery, etc.","feature_image":null,"meta_description":"Work with massive amounts of unstandardized data across file types and schemas. Includes working with data warehouses, Hadoop, Spark, BigQuery, etc.","meta_title":"Big Data | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"GCP is on the rise, and it's getting harder and harder to have conversations\naround data without addressing the 500-pound gorilla in the room: Google\nBigQuery. With most enterprises comfortably settled into their Apache-based Big\nData stacks, BigQuery rattles the cages of convention for many. Luckily, Hackers\nAnd Slackers is no such enterprise. Thus, we aren't afraid to ask the Big\nquestion: how much easier would life be with BigQuery?\n\nBig Data, BigQuery\nIn short, BigQuery trivializes the act of querying against multiple,\nunpredictable data sources. To better understand when this is useful, it would\nbetter serve us to identify the types of questions BigQuery can answer. Such as:\n\n * What are our users doing across our multiple systems? How do we leverage log\n   files outputted by multiple systems to find out?\n * How can we consolidate information about employee information, payroll, and\n   benefits, when these all live in isolated systems?\n * What the hell am I supposed to do with all these spreadsheets?\n\nUnlike previous solutions, BigQuery solves these problems in a single product\nand does so with SQL-like query syntax,  a web interface, and 7 native Client\nLibraries.  There are plenty of reasons to love BigQuery, but let's start with\none we've recently already talked about: the auto-generation of table schemas. \n\nMatt has demonstrated how to approach this problem manually with the help of\nPandas\n[https://hackersandslackers.com/downcast-numerical-columns-python-pandas/]. I\nprovided a more gimmicky approach by leveraging the Python table-schema library\n[https://hackersandslackers.com/infer-datatypes-from-csvs-to-create/]. With\nBigQuery, we find yet another alternative which is neither manual or gimmicky:\nperfect for those who are lazy, rich, and demand perfection (AKA: your clients,\nprobably).\n\nFirst, we'll need to get our data into BigQuery\n\nUploading Data into Google Cloud Storage via the Python SDK\nBigQuery requires us to go through Google Cloud Storage as a buffer before\ninputting data into tables. No big deal, we'll write a script!\n\nWe're assuming that you have a basic knowledge of Google Cloud, Google Cloud\nStorage, and how to download a JSON Service Account key\n[https://cloud.google.com/bigquery/docs/reference/libraries]  to store locally\n(hint: click the link).\n\nfrom google.cloud import storage\n\nbucket_uri = 'gs://your-bucket/'\nbucket_name = 'your-bucket'\nbucket_target = 'datasets/data_upload.csv'\nlocal_dataset = 'data/test.csv'\n\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    \"\"\"Upload a CSV to Google Cloud Storage.\n\n    1. Retrieve the target bucket.\n    2. Set destination of data to be uploaded.\n    3. Upload local CSV.\n    \"\"\"\n    storage_client = storage.Client()\n    bucket = storage_client.get_bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n    # Commence Upload\n    blob.upload_from_filename(source_file_name)\n    print('File {} uploaded to {}.'.format(\n        source_file_name,\n        destination_blob_name))\n        \n        \nupload_blob(bucket_name, local_dataset, bucket_target)\n\n\nThe above is nearly a copy + paste of Google Cloud's sample code for the Google\nCloud Storage Python SDK:\n\n * bucket_uri  is found by inspecting any bucket's information on Google Cloud.\n * bucket_name  is... well, you know.\n * bucket_target  represents the resulting file structure representing the saved\n   CSV when completed.\n * local_dataset  is the path to a CSV we've stored locally: we can assume that\n   we've grabbed some data from somewhere, like an API, and tossed into a local\n   file temporarily.\n\nSuccessfully executing the above results in the following message:\n\nFile data/test.csv uploaded to datasets/data_upload.csv.\n\n\nInserting Data from Cloud Storage to BigQuery\nThat was the easy part. Let's move on to the good stuff:\n\nfrom google.cloud import storage\nfrom google.cloud import bigquery\n\nbucket_uri = 'gs://your-bucket/'\nbucket_name = 'your-bucket'\nbucket_target = 'datasets/data_upload.csv'\nlocal_dataset = 'data/test.csv'\nbucket_target_uri = bucket_uri + bucket_target\nbigquery_dataset = 'uploadtest'\nbigquery_table = 'my_table'\n\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    \"\"\"Upload a CSV to Google Cloud Storage.\n\n    1. Retrieve the target bucket.\n    2. Set destination of data to be uploaded.\n    3. Upload local CSV.\n    \"\"\"\n    storage_client = storage.Client()\n    bucket = storage_client.get_bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n    # Commence Upload\n    blob.upload_from_filename(source_file_name)\n    print('File {} uploaded to {}.'.format(\n        source_file_name,\n        destination_blob_name))\n\n\ndef insert_bigquery(target_uri, dataset_id, table_id):\n    \"\"\"Insert CSV from Google Storage to BigQuery Table.\n\n    1. Specify target dataset within BigQuery.\n    2. Create a Job configuration.\n    3. Specify that we are autodetecting datatypes.\n    4. Reserve row #1 for headers.\n    5. Specify the source format of the file (defaults to CSV).\n    6. Pass the URI of the data storage on Google Cloud Storage from.\n    7. Load BigQuery Job.\n    8. Execute BigQuery Job.\n    \"\"\"\n    bigquery_client = bigquery.Client()\n    dataset_ref = bigquery_client.dataset(dataset_id)\n    job_config = bigquery.LoadJobConfig()\n    job_config.autodetect = True\n    job_config.skip_leading_rows = 1\n    job_config.source_format = bigquery.SourceFormat.CSV\n    uri = target_uri\n    load_job = bigquery_client.load_table_from_uri(\n        uri,\n        dataset_ref.table(table_id),\n        job_config=job_config)  # API request\n    print('Starting job {}'.format(load_job.job_id))\n    # Waits for table load to complete.\n    load_job.result()\n    print('Job finished.')\n\n\nupload_blob(bucket_name, local_dataset, bucket_target)\ninsert_bigquery(bucket_target_uri, bigquery_dataset, bigquery_table)\n\n\nWe've added the function insert_bigquery()  to handle creating a BigQuery table\nout of a CSV.\n\nAfter we set our client, we create a dataset reference. In BigQuery, tables can\nbelong to a 'dataset,' which is a grouping of tables. Compare this concept to\nMongoDB's collections, or PostgreSQL's schemas. Note that this process is made\nmuch easier by the fact that we stored our project key locally: otherwise, we'd\nhave to specify which Google Cloud project we're looking for, etc.\n\nWith the dataset specified, we begin to build our \"job\" object with \nLoadJobConfig. This is like loading a gun before unleashing a shotgun blast into\nthe face of our problems. Alternatively, a more relevant comparison could be\nwith the Python requests  library and the act of prepping an API request before\nexecution.\n\nWe set job_config.autodetect  to be True, obviously. \njob_config.skip_leading_rows  reserves our header row from screwing things up.\n\nload_job  puts our request together, and load_job.result()  executes said job.\nThe .result()  method graciously puts the rest of our script on hold until the\nspecified job is completed. In our case, we want this happen: it simplifies our\nscript so that we don't need to verify this manually before moving on.\n\nLet's see what running that job with our fake data looks like in the BigQuery\nUI:\n\nAll my fake friends are here!Getting Our Flawlessly Inferred Table Schema\nBigQuery surely gets table schemas wrong some of the time. That said, I have yet\nto see it happen. Let's wrap this script up:\n\nfrom google.cloud import storage\nfrom google.cloud import bigquery\nimport pprint\n\nbucket_uri = 'gs://your-bucket/'\nbucket_name = 'your-bucket'\nbucket_target = 'datasets/data_upload.csv'\nlocal_dataset = 'data/test.csv'\nbucket_target_uri = bucket_uri + bucket_target\nbigquery_dataset = 'uploadtest'\nbigquery_table = 'my_table'\n\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    \"\"\"Upload a CSV to Google Cloud Storage.\n\n    1. Retrieve the target bucket.\n    2. Set destination of data to be uploaded.\n    3. Upload local CSV.\n    \"\"\"\n    storage_client = storage.Client()\n    bucket = storage_client.get_bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n    # Commence Upload\n    blob.upload_from_filename(source_file_name)\n    print('File {} uploaded to {}.'.format(\n        source_file_name,\n        destination_blob_name))\n\n\ndef insert_bigquery(target_uri, dataset_id, table_id):\n    \"\"\"Insert CSV from Google Storage to BigQuery Table.\n\n    1. Specify target dataset within BigQuery.\n    2. Create a Job configuration.\n    3. Specify that we are autodetecting datatypes.\n    4. Reserve row #1 for headers.\n    5. Specify the source format of the file (defaults to CSV).\n    6. Pass the URI of the data storage on Google Cloud Storage from.\n    7. Load BigQuery Job.\n    8. Execute BigQuery Job.\n    \"\"\"\n    bigquery_client = bigquery.Client()\n    dataset_ref = bigquery_client.dataset(dataset_id)\n    job_config = bigquery.LoadJobConfig()\n    job_config.autodetect = True\n    job_config.skip_leading_rows = 1\n    job_config.source_format = bigquery.SourceFormat.CSV\n    uri = target_uri\n    load_job = bigquery_client.load_table_from_uri(\n        uri,\n        dataset_ref.table(table_id),\n        job_config=job_config)  # API request\n    print('Starting job {}'.format(load_job.job_id))\n    # Waits for table load to complete.\n    load_job.result()\n    print('Job finished.')\n\n\ndef get_schema(dataset_id, table_id):\n    \"\"\"Get BigQuery Table Schema.\n\n    1. Specify target dataset within BigQuery.\n    2. Specify target table within given dataset.\n    3. Create Table class instance from existing BigQuery Table.\n    4. Print results to console.\n    5. Return the schema dict.\n    \"\"\"\n    bigquery_client = bigquery.Client()\n    dataset_ref = bigquery_client.dataset(dataset_id)\n    bg_tableref = bigquery.table.TableReference(dataset_ref, table_id)\n    bg_table = bigquery_client.get_table(bg_tableref)\n    # Print Schema to Console\n    pp = pprint.PrettyPrinter(indent=4)\n    pp.pprint(bg_table.schema)\n    return bg_table.schema\n\n\nupload_blob(bucket_name, local_dataset, bucket_target)\ninsert_bigquery(bucket_target_uri, bigquery_dataset, bigquery_table)\nbigquery_table_schema = get_schema(bigquery_dataset, bigquery_table)\n\n\nWith the addition of get_bigquery_schema(), our script is complete!\n\nTableReference()  is similar to the dataset reference we went over earlier, only\nfor tables (duh). This allows us to call upon get_table(), which returns a Table\nclass representing the table we just created. Amongst the methods of that class,\nwe can call .schema(), which gives us precisely what we want: a beautiful\nrepresentation of a Table schema, generated from raw CSV information, where\nthere previously was none.\n\nBehold the fruits of your labor:\n\n[   SchemaField('id', 'INTEGER', 'NULLABLE', None, ()),\n    SchemaField('initiated', 'TIMESTAMP', 'NULLABLE', None, ()),\n    SchemaField('hiredate', 'DATE', 'NULLABLE', None, ()),\n    SchemaField('email', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('firstname', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('lastname', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('title', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('department', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('location', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('country', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('type', 'STRING', 'NULLABLE', None, ())]\n\n\nThere you have it; a correctly inferred schema, from data which wasn't entirely\nclean in the first place (our dates are in MM/DD/YY  format as opposed to \nMM/DD/YYYY, but Google still gets it right. How? Because Google).\n\nIt Doesn't End Here\nI hope it goes without saying that abusing Google BigQuery's API to generate\nschemas for you is only a small, obscure use case of what Google BigQuery is\nintended to do, and what it can do for you. That said, I need to stop this\nfanboying post before anybody realizes I'll promote their products for free\nforever (I think I may have passed that point).\n\nIn case you're interested, the source code for this script has been uploaded as\na Gist here\n[https://gist.github.com/toddbirchard/a743db3b8805dfe9834e73c530dc8a6e]. Have at\nit, and remember to think Big™*.\n\n*Not a real trademark, I'm making things up again.","html":"<p>GCP is on the rise, and it's getting harder and harder to have conversations around data without addressing the 500-pound gorilla in the room: Google BigQuery. With most enterprises comfortably settled into their Apache-based Big Data stacks, BigQuery rattles the cages of convention for many. Luckily, Hackers And Slackers is no such enterprise. Thus, we aren't afraid to ask the Big question: how much easier would life be with BigQuery?</p><h2 id=\"big-data-bigquery\">Big Data, BigQuery</h2><p>In short, BigQuery trivializes the act of querying against multiple, unpredictable data sources. To better understand when this is useful, it would better serve us to identify the types of questions BigQuery can answer. Such as:</p><ul><li>What are our users doing across our multiple systems? How do we leverage log files outputted by multiple systems to find out?</li><li>How can we consolidate information about employee information, payroll, and benefits, when these all live in isolated systems?</li><li>What the hell am I supposed to do with all these spreadsheets?</li></ul><p>Unlike previous solutions, BigQuery solves these problems in a single product and does so with <strong>SQL-like query syntax,</strong> a <strong>web interface</strong>, and <strong>7 native Client Libraries.</strong> There are plenty of reasons to love BigQuery, but let's start with one we've recently already talked about: the <em>auto-generation of table schemas</em>. </p><p>Matt has demonstrated how to approach this problem <a href=\"https://hackersandslackers.com/downcast-numerical-columns-python-pandas/\">manually with the help of Pandas</a>. I provided a more gimmicky approach by leveraging the <a href=\"https://hackersandslackers.com/infer-datatypes-from-csvs-to-create/\">Python table-schema library</a>. With BigQuery, we find yet another alternative which is neither manual or gimmicky: perfect for those who are lazy, rich, and demand perfection (AKA: your clients, probably).</p><p>First, we'll need to get our data into BigQuery</p><h2 id=\"uploading-data-into-google-cloud-storage-via-the-python-sdk\">Uploading Data into Google Cloud Storage via the Python SDK</h2><p>BigQuery requires us to go through Google Cloud Storage as a buffer before inputting data into tables. No big deal, we'll write a script!</p><p>We're assuming that you have a basic knowledge of Google Cloud, Google Cloud Storage, and how to download a <a href=\"https://cloud.google.com/bigquery/docs/reference/libraries\">JSON Service Account key</a> to store locally (hint: click the link).</p><pre><code class=\"language-python\">from google.cloud import storage\n\nbucket_uri = 'gs://your-bucket/'\nbucket_name = 'your-bucket'\nbucket_target = 'datasets/data_upload.csv'\nlocal_dataset = 'data/test.csv'\n\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    &quot;&quot;&quot;Upload a CSV to Google Cloud Storage.\n\n    1. Retrieve the target bucket.\n    2. Set destination of data to be uploaded.\n    3. Upload local CSV.\n    &quot;&quot;&quot;\n    storage_client = storage.Client()\n    bucket = storage_client.get_bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n    # Commence Upload\n    blob.upload_from_filename(source_file_name)\n    print('File {} uploaded to {}.'.format(\n        source_file_name,\n        destination_blob_name))\n        \n        \nupload_blob(bucket_name, local_dataset, bucket_target)\n</code></pre>\n<p>The above is nearly a copy + paste of Google Cloud's sample code for the Google Cloud Storage Python SDK:</p><ul><li><code>bucket_uri</code> is found by inspecting any bucket's information on Google Cloud.</li><li><code>bucket_name</code> is... well, you know.</li><li><code>bucket_target</code><strong> </strong>represents the resulting file structure representing the saved CSV when completed.</li><li><code>local_dataset</code> is the path to a CSV we've stored locally: we can assume that we've grabbed some data from somewhere, like an API, and tossed into a local file temporarily.</li></ul><p>Successfully executing the above results in the following message:</p><pre><code class=\"language-shell\">File data/test.csv uploaded to datasets/data_upload.csv.\n</code></pre>\n<h2 id=\"inserting-data-from-cloud-storage-to-bigquery\">Inserting Data from Cloud Storage to BigQuery</h2><p>That was the easy part. Let's move on to the good stuff:</p><pre><code class=\"language-python\">from google.cloud import storage\nfrom google.cloud import bigquery\n\nbucket_uri = 'gs://your-bucket/'\nbucket_name = 'your-bucket'\nbucket_target = 'datasets/data_upload.csv'\nlocal_dataset = 'data/test.csv'\nbucket_target_uri = bucket_uri + bucket_target\nbigquery_dataset = 'uploadtest'\nbigquery_table = 'my_table'\n\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    &quot;&quot;&quot;Upload a CSV to Google Cloud Storage.\n\n    1. Retrieve the target bucket.\n    2. Set destination of data to be uploaded.\n    3. Upload local CSV.\n    &quot;&quot;&quot;\n    storage_client = storage.Client()\n    bucket = storage_client.get_bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n    # Commence Upload\n    blob.upload_from_filename(source_file_name)\n    print('File {} uploaded to {}.'.format(\n        source_file_name,\n        destination_blob_name))\n\n\ndef insert_bigquery(target_uri, dataset_id, table_id):\n    &quot;&quot;&quot;Insert CSV from Google Storage to BigQuery Table.\n\n    1. Specify target dataset within BigQuery.\n    2. Create a Job configuration.\n    3. Specify that we are autodetecting datatypes.\n    4. Reserve row #1 for headers.\n    5. Specify the source format of the file (defaults to CSV).\n    6. Pass the URI of the data storage on Google Cloud Storage from.\n    7. Load BigQuery Job.\n    8. Execute BigQuery Job.\n    &quot;&quot;&quot;\n    bigquery_client = bigquery.Client()\n    dataset_ref = bigquery_client.dataset(dataset_id)\n    job_config = bigquery.LoadJobConfig()\n    job_config.autodetect = True\n    job_config.skip_leading_rows = 1\n    job_config.source_format = bigquery.SourceFormat.CSV\n    uri = target_uri\n    load_job = bigquery_client.load_table_from_uri(\n        uri,\n        dataset_ref.table(table_id),\n        job_config=job_config)  # API request\n    print('Starting job {}'.format(load_job.job_id))\n    # Waits for table load to complete.\n    load_job.result()\n    print('Job finished.')\n\n\nupload_blob(bucket_name, local_dataset, bucket_target)\ninsert_bigquery(bucket_target_uri, bigquery_dataset, bigquery_table)\n</code></pre>\n<p>We've added the function <code>insert_bigquery()</code> to handle creating a BigQuery table out of a CSV.</p><p>After we set our client, we create a <strong>dataset reference</strong>. In BigQuery, tables can belong to a 'dataset,' which is a grouping of tables. Compare this concept to MongoDB's <strong>collections, </strong>or PostgreSQL's <strong>schemas</strong>. Note that this process is made much easier by the fact that we stored our project key locally: otherwise, we'd have to specify which Google Cloud project we're looking for, etc.</p><p>With the dataset specified, we begin to build our \"job\" object with <code>LoadJobConfig</code>. This is like loading a gun before unleashing a shotgun blast into the face of our problems. Alternatively, a more relevant comparison could be with the Python <code>requests</code> library and the act of prepping an API request before execution.</p><p>We set <code>job_config.autodetect</code> to be <code>True</code>, obviously. <code>job_config.skip_leading_rows</code> reserves our header row from screwing things up.</p><p><code>load_job</code> puts our request together, and <code>load_job.result()</code> executes said job. The <code>.result()</code> method graciously puts the rest of our script on hold until the specified job is completed. In our case, we want this happen: it simplifies our script so that we don't need to verify this manually before moving on.</p><p>Let's see what running that job with our fake data looks like in the BigQuery UI:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2019-02-01-at-7.42.52-PM.png\" class=\"kg-image\"><figcaption>All my fake friends are here!</figcaption></figure><h2 id=\"getting-our-flawlessly-inferred-table-schema\">Getting Our Flawlessly Inferred Table Schema</h2><p>BigQuery surely gets table schemas wrong <em>some </em>of the time. That said, I have yet to see it happen. Let's wrap this script up:</p><pre><code class=\"language-python\">from google.cloud import storage\nfrom google.cloud import bigquery\nimport pprint\n\nbucket_uri = 'gs://your-bucket/'\nbucket_name = 'your-bucket'\nbucket_target = 'datasets/data_upload.csv'\nlocal_dataset = 'data/test.csv'\nbucket_target_uri = bucket_uri + bucket_target\nbigquery_dataset = 'uploadtest'\nbigquery_table = 'my_table'\n\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    &quot;&quot;&quot;Upload a CSV to Google Cloud Storage.\n\n    1. Retrieve the target bucket.\n    2. Set destination of data to be uploaded.\n    3. Upload local CSV.\n    &quot;&quot;&quot;\n    storage_client = storage.Client()\n    bucket = storage_client.get_bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name)\n    # Commence Upload\n    blob.upload_from_filename(source_file_name)\n    print('File {} uploaded to {}.'.format(\n        source_file_name,\n        destination_blob_name))\n\n\ndef insert_bigquery(target_uri, dataset_id, table_id):\n    &quot;&quot;&quot;Insert CSV from Google Storage to BigQuery Table.\n\n    1. Specify target dataset within BigQuery.\n    2. Create a Job configuration.\n    3. Specify that we are autodetecting datatypes.\n    4. Reserve row #1 for headers.\n    5. Specify the source format of the file (defaults to CSV).\n    6. Pass the URI of the data storage on Google Cloud Storage from.\n    7. Load BigQuery Job.\n    8. Execute BigQuery Job.\n    &quot;&quot;&quot;\n    bigquery_client = bigquery.Client()\n    dataset_ref = bigquery_client.dataset(dataset_id)\n    job_config = bigquery.LoadJobConfig()\n    job_config.autodetect = True\n    job_config.skip_leading_rows = 1\n    job_config.source_format = bigquery.SourceFormat.CSV\n    uri = target_uri\n    load_job = bigquery_client.load_table_from_uri(\n        uri,\n        dataset_ref.table(table_id),\n        job_config=job_config)  # API request\n    print('Starting job {}'.format(load_job.job_id))\n    # Waits for table load to complete.\n    load_job.result()\n    print('Job finished.')\n\n\ndef get_schema(dataset_id, table_id):\n    &quot;&quot;&quot;Get BigQuery Table Schema.\n\n    1. Specify target dataset within BigQuery.\n    2. Specify target table within given dataset.\n    3. Create Table class instance from existing BigQuery Table.\n    4. Print results to console.\n    5. Return the schema dict.\n    &quot;&quot;&quot;\n    bigquery_client = bigquery.Client()\n    dataset_ref = bigquery_client.dataset(dataset_id)\n    bg_tableref = bigquery.table.TableReference(dataset_ref, table_id)\n    bg_table = bigquery_client.get_table(bg_tableref)\n    # Print Schema to Console\n    pp = pprint.PrettyPrinter(indent=4)\n    pp.pprint(bg_table.schema)\n    return bg_table.schema\n\n\nupload_blob(bucket_name, local_dataset, bucket_target)\ninsert_bigquery(bucket_target_uri, bigquery_dataset, bigquery_table)\nbigquery_table_schema = get_schema(bigquery_dataset, bigquery_table)\n</code></pre>\n<p>With the addition of <code>get_bigquery_schema()</code>, our script is complete!</p><p><code>TableReference()</code> is similar to the dataset reference we went over earlier, only for tables (duh). This allows us to call upon <code>get_table()</code>, which returns a Table class representing the table we just created. Amongst the methods of that class, we can call <code>.schema()</code>, which gives us precisely what we want: a beautiful representation of a Table schema, generated from raw CSV information, where there previously was none.</p><p>Behold the fruits of your labor:</p><pre><code class=\"language-python\">[   SchemaField('id', 'INTEGER', 'NULLABLE', None, ()),\n    SchemaField('initiated', 'TIMESTAMP', 'NULLABLE', None, ()),\n    SchemaField('hiredate', 'DATE', 'NULLABLE', None, ()),\n    SchemaField('email', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('firstname', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('lastname', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('title', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('department', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('location', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('country', 'STRING', 'NULLABLE', None, ()),\n    SchemaField('type', 'STRING', 'NULLABLE', None, ())]\n</code></pre>\n<p>There you have it; a correctly inferred schema, from data which wasn't entirely clean in the first place (our dates are in <strong>MM/DD/YY</strong> format as opposed to <strong>MM/DD/YYYY</strong>, but Google still gets it right. How? Because Google).</p><h3 id=\"it-doesn-t-end-here\">It Doesn't End Here</h3><p>I hope it goes without saying that abusing Google BigQuery's API to generate schemas for you is only a small, obscure use case of what Google BigQuery is intended to do, and what it can do for you. That said, I need to stop this fanboying post before anybody realizes I'll promote their products for free forever (I think I may have passed that point).</p><p>In case you're interested, the source code for this script has been uploaded as a Gist <a href=\"https://gist.github.com/toddbirchard/a743db3b8805dfe9834e73c530dc8a6e\">here</a>. Have at it, and remember to think Big<strong>™*</strong>.</p><span style=\"color: #a6a6a6;font-style: italic; font-size: .8em;\">*Not a real trademark, I'm making things up again.</span>","url":"https://hackersandslackers.com/getting-started-google-big-query-python/","uuid":"30051eb2-7fa7-4a09-91fd-c3f11966b398","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c47584f4f3823107c9e8f23"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867372f","title":"Deploy Isolated Applications with Google App Engine","slug":"deploy-app-containters-with-gcp-app-engine","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/10/appengine@2x.jpg","excerpt":"Doing everything to avoid server configuration or any mild discomfort.","custom_excerpt":"Doing everything to avoid server configuration or any mild discomfort.","created_at_pretty":"25 October, 2018","published_at_pretty":"25 October, 2018","updated_at_pretty":"06 January, 2019","created_at":"2018-10-24T20:30:22.000-04:00","published_at":"2018-10-25T07:30:00.000-04:00","updated_at":"2019-01-06T11:26:06.000-05:00","meta_title":"Deploy App Containters with GCP App Engine | Hackers and Slackers","meta_description":"Doing everything to avoid server configuration or any mild discomfort.","og_description":"Doing everything to avoid server configuration or any mild discomfort.","og_image":"https://hackersandslackers.com/content/images/2018/10/appengine@2x.jpg","og_title":"Deploy App Containters with GCP App Engine | Hackers and Slackers","twitter_description":"Doing everything to avoid server configuration or any mild discomfort.","twitter_image":"https://hackersandslackers.com/content/images/2018/10/appengine@2x.jpg","twitter_title":"Deploy App Containters with GCP App Engine | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"}],"plaintext":"We've been on a bit of a tear lately on Google Cloud lately (or at least I\nhave), and I have no desire to stop any time soon. I probably should though...\n our analytics show that half our viewers are just people struggling to us AWS.\nSpeaking of capitalizing on shitty UI, stay tuned in the future where we'll\noffer grossly overpriced unauthorized AWS certification programs.\n\nAWS aside, I'm here to talk about the other  Cloud in town - in particular,\nGoogle's solution to make sure you never configure a webserver again. This is a\ntrend that's been grinding my gears a bit: as much as I appreciate the reduction\nin effort, the costs of choosing proprietary (paid) services to avoid opening a\nLinux shell seems like a dangerous prospect over time as every day developers\nbecome more and more reliant on convenience. Then again, I'm probably just angry\nthat nobody will have to endure the pain of Python development circa 2012. \n\nRandom Old-Man Tangent About Configuring Webservers\nRemember when we all ran Apache servers, and the world decided that mod_python \nshould stop existing for no reason? The replacement was, of course, mod_wsgi:  \nan entirely undocumented way of running Python on an Apache server created by a\nsingle guy from Google (who has apparently opted to spend the entirety of his\nlife attempting to explain mod_wsgi on StackOverflow\n[https://stackoverflow.com/users/128141/graham-dumpleton]). \n\nBesides mod_wsgi, the Nginx alternatives (Gunicorn  and uWSGI) are almost\nequally insufferable to implement. Much of this can be attributed to tutorials\n(such as those posted by DigitalOcean) which dominate SEO, merely because those\ntutorials include glaring inexcusable typos  in their configuration files. This\nresults in an infinite Google search feedback loop, where you find what seems to\nbe a perfectly fine tutorial... plus 10 pages of frustrated developers\nbacklinking to said tutorial, trying to figure out where the hell the missing\ncolon is in their Nginx config. Spoiler alert: that's not the only typo, and I'm\npretty sure at this point nobody cares to put up with monetized troubleshooting\nbullshit schemes (calling it now: the slightly-false-tutorial is an elaborate\nSEO scam).  So yeah, app containers it is then.\n\nThe Benefits of App Engine\nBesides not needing to know anything about Linux, hosting on App Engine provides\na few other benefits. Considering all microservices are obfuscated in the cloud,\nwe can easily hook into other services such as setting up CRON jobs, Tasks, and\nDNS, for instance. GCP's catalogue of offerings is destined to grow, whether\nthose offerings are ferociously released from Google's ambitious backlog, or the\nresult of a partnership utilizing Google Cloud for architecture, such as MongoDB\ncloud and others. Prepare to witness fierce and unapologetic growth from GCP by\nevery metric, year-over-year. \n\nApp Engine  is also intimately close with your source code. Despite the\ndynamically typed nature of Python and Javascript, App Engine will catch fatal\nerrors when attempting to deploy your app which would not happen otherwise.\nAdding this type of interpreter adds a convenient level of 'easy mode,' where\npotentially fatal production errors are caught before deployment is even\npermitted. I even tried deploying some personal projects to App Engine which had\nbeen running live elsewhere, and App Engine was able to catch errors existing in\nmy code which had been shamelessly running in production. Oops.\n\nEven while the app is live, all errors are conveniently detected and reported\nfront and center in the app engine dashboard:\n\n\"No module named App\" seems like a pretty bad error.So yes, there are plenty of\nbenefits and reasons to use App Engine over a VPS: removal of webserver\nconfiguration, build errors caught at runtime, and easy command-line deployments\nname a few of such benefits. The question of whether or not these perks are\nworth the price tag and vendor-lock are a personal decision.\n\nCreating your First App... Engine\nGoogle provides the luxury of creating apps in a variety of languages, including\nhot new -comer to the game, PHP. Lucky us!\n\nHah, .NET is still a thing too.Google will forcefully insist you complete their\nown step-by-step tutorial, which essentially teaches you how to use git clone \nand explains the contents of their YAML file. You can follow this if you want. \n\nMore interestingly is what you'll find when you open the GCP browser shell.\nWhile working through this tutorial, it's impossible to ignore that Google Cloud\nis essentially just a giant VPS across all your projects:\n\nAll of these directories were created in different projects.Just when we were\ndone ranting, it turns out every service we pay for is just a thinly veiled\nobfuscation of something we could probably do on a 10 dollar Droplet. Fuck,\nlet's just move on.\n\nSimple Project Configuration\nPerhaps majority of what one needs to learn to deploy apps is contained within a\nsingle YAML file. Add a YAML file in your directory:\n\nruntime: python37\napi_version: 1\n\nhandlers:\n  # This configures Google App Engine to serve the files in the app's static\n  # directory.\n- url: static\n  static_dir: static\n\n  # This handler routes all requests not caught above to your main app.\n  # Required when static routes are defined. \n  # Can be omitted when there are no static files defined.\n- url: /.*\n  script: auto\n\n\nSet your Static directory if you're working in Python. Use Python 3.7.\n\nGoogle also invented its own version of .gitignore  for App Engine called \n.gcloudignore, so be aware of that.\n\nHaving worked with Flask in the past, you should presumably be familiar with a\nstartup script such as the following:\n\nfrom framewrk import create_app\n\napp = create_app()\n\nif __name__ == \"__main__\":\n    app.run(host='0.0.0.0')\n\n\nThat's pretty much it man. Just remember that Google prefers requirements.txt \nover other forms of package management (Google will actually bar Pipfile from\nbeing committed, interestingly enough). \n\nIf you're working locally, gcloud app deploy  is all you need to push to\nproduction (doesn't require a git commit, interestingly enough. gcloud app\nbrowse  will open you newly deployed app, and gcloud app logs tail -s default \nwill display your logs when something goes horribly wrong.\n\nAnd there you have it: the practical and completely cynical guide to embracing\nmodern architecture. Join us next time when we pay 50 dollars to deploy a\nsingle-click app simply because we're too lazy or unmotivated to set anything up\nourselves.","html":"<p>We've been on a bit of a tear lately on Google Cloud lately (or at least I have), and I have no desire to stop any time soon. I probably should though...  our analytics show that half our viewers are just people struggling to us AWS. Speaking of capitalizing on shitty UI, stay tuned in the future where we'll offer grossly overpriced unauthorized AWS certification programs.</p><p>AWS aside, I'm here to talk about the <em>other</em> Cloud in town - in particular, Google's solution to make sure you never configure a webserver again. This is a trend that's been grinding my gears a bit: as much as I appreciate the reduction in effort, the costs of choosing proprietary (paid) services to avoid opening a Linux shell seems like a dangerous prospect over time as every day developers become more and more reliant on convenience. Then again, I'm probably just angry that nobody will have to endure the pain of Python development circa 2012. </p><h3 id=\"random-old-man-tangent-about-configuring-webservers\">Random Old-Man Tangent About Configuring Webservers</h3><p>Remember when we all ran Apache servers, and the world decided that <strong>mod_python</strong> should stop existing for no reason? The replacement was, of course, <strong>mod_wsgi</strong>:<strong> </strong>an entirely undocumented way of running Python on an Apache server created by a single guy from Google (who has apparently opted to spend the entirety of his life attempting to <a href=\"https://stackoverflow.com/users/128141/graham-dumpleton\">explain <strong>mod_wsgi</strong> on StackOverflow</a>). </p><p>Besides <strong>mod_wsgi</strong>, the Nginx alternatives (<strong>Gunicorn</strong> and <strong>uWSGI</strong>) are almost equally insufferable to implement. Much of this can be attributed to tutorials (such as those posted by DigitalOcean) which dominate SEO, merely because those tutorials include <em>glaring inexcusable typos</em> in their configuration files. This results in an infinite Google search feedback loop, where you find what seems to be a perfectly fine tutorial... plus 10 pages of frustrated developers backlinking to said tutorial, trying to figure out where the hell the missing colon is in their Nginx config. Spoiler alert: that's not the only typo, and I'm pretty sure at this point nobody cares to put up with monetized troubleshooting bullshit schemes (calling it now: the slightly-false-tutorial is an elaborate SEO scam).  So yeah, app containers it is then.</p><h2 id=\"the-benefits-of-app-engine\">The Benefits of App Engine</h2><p>Besides not needing to know anything about Linux, hosting on App Engine provides a few other benefits. Considering all microservices are obfuscated in the cloud, we can easily hook into other services such as setting up CRON jobs, Tasks, and DNS, for instance. GCP's catalogue of offerings is destined to grow, whether those offerings are ferociously released from Google's ambitious backlog, or the result of a partnership utilizing Google Cloud for architecture, such as MongoDB cloud and others. Prepare to witness fierce and unapologetic growth from GCP by every metric, year-over-year. </p><p><strong>App Engine</strong> is also intimately close with your source code. Despite the dynamically typed nature of Python and Javascript, App Engine will catch fatal errors when attempting to deploy your app which would not happen otherwise. Adding this type of interpreter adds a convenient level of 'easy mode,' where potentially fatal production errors are caught before deployment is even permitted. I even tried deploying some personal projects to App Engine which had been running live elsewhere, and App Engine was able to catch errors existing in my code which had been shamelessly running in production. Oops.</p><p>Even while the app is live, all errors are conveniently detected and reported front and center in the app engine dashboard:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-10-24-at-10.12.19-PM.png\" class=\"kg-image\"><figcaption>\"No module named App\" seems like a pretty bad error.</figcaption></figure><p>So yes, there are plenty of benefits and reasons to use App Engine over a VPS: removal of webserver configuration, build errors caught at runtime, and easy command-line deployments name a few of such benefits. The question of whether or not these perks are worth the price tag and vendor-lock are a personal decision.</p><h2 id=\"creating-your-first-app-engine\">Creating your First App... Engine</h2><p>Google provides the luxury of creating apps in a variety of languages, including hot new -comer to the game, PHP. Lucky us!</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-10-24-at-10.17.59-PM.png\" class=\"kg-image\"><figcaption>Hah, .NET is still a thing too.</figcaption></figure><p>Google will forcefully insist you complete their own step-by-step tutorial, which essentially teaches you how to use <strong>git clone</strong> and explains the contents of their YAML file. You can follow this if you want. </p><p>More interestingly is what you'll find when you open the GCP browser shell. While working through this tutorial, it's impossible to ignore that Google Cloud is essentially just a giant VPS <em>across all your projects:</em></p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-10-24-at-10.26.44-PM.png\" class=\"kg-image\"><figcaption>All of these directories were created in different projects.</figcaption></figure><p>Just when we were done ranting, it turns out every service we pay for is just a thinly veiled obfuscation of something we could probably do on a 10 dollar Droplet. Fuck, let's just move on.</p><h3 id=\"simple-project-configuration\">Simple Project Configuration</h3><p>Perhaps majority of what one needs to learn to deploy apps is contained within a single YAML file. Add a YAML file in your directory:</p><pre><code class=\"language-yaml\">runtime: python37\napi_version: 1\n\nhandlers:\n  # This configures Google App Engine to serve the files in the app's static\n  # directory.\n- url: static\n  static_dir: static\n\n  # This handler routes all requests not caught above to your main app.\n  # Required when static routes are defined. \n  # Can be omitted when there are no static files defined.\n- url: /.*\n  script: auto\n</code></pre>\n<p>Set your Static directory if you're working in Python. Use Python 3.7.</p><p>Google also invented its own version of <code>.gitignore</code> for App Engine called <code>.gcloudignore</code>, so be aware of that.</p><p>Having worked with Flask in the past, you should presumably be familiar with a startup script such as the following:</p><pre><code class=\"language-python\">from framewrk import create_app\n\napp = create_app()\n\nif __name__ == &quot;__main__&quot;:\n    app.run(host='0.0.0.0')\n</code></pre>\n<p>That's pretty much it man. Just remember that Google prefers <strong>requirements.txt </strong>over other forms of package management (Google will actually bar Pipfile from being committed, interestingly enough). </p><p>If you're working locally, <code>gcloud app deploy</code> is all you need to push to production (doesn't require a git commit, interestingly enough. <code>gcloud app browse</code> will open you newly deployed app, and <code>gcloud app logs tail -s default</code> will display your logs when something goes horribly wrong.</p><p>And there you have it: the practical and completely cynical guide to embracing modern architecture. Join us next time when we pay 50 dollars to deploy a single-click app simply because we're too lazy or unmotivated to set anything up ourselves.</p>","url":"https://hackersandslackers.com/deploy-app-containters-with-gcp-app-engine/","uuid":"70f7a025-6774-4555-9eff-e63eb40c4fdf","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5bd10e9e4ba34679679904f2"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867372d","title":"Create Google Cloud Functions Running Python 3.7","slug":"creating-a-python-google-cloud-function","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/10/googlefunc-1@2x.jpg","excerpt":"GCP scores another victory by trivializing serverless functions.","custom_excerpt":"GCP scores another victory by trivializing serverless functions.","created_at_pretty":"18 October, 2018","published_at_pretty":"19 October, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-10-18T19:44:02.000-04:00","published_at":"2018-10-18T22:33:07.000-04:00","updated_at":"2019-02-13T23:13:40.000-05:00","meta_title":"Creating Google Cloud Functions Running Python | Hackers and Slackers","meta_description":"Create cloud functions and endpoints with ease using Google Cloud's Cloud Functions and Source Repositories.","og_description":"Create cloud functions and endpoints with ease using Google Cloud's Cloud Functions and Source Repositories.","og_image":"https://hackersandslackers.com/content/images/2018/10/googlefunc-1@2x.jpg","og_title":"Creating Google Cloud Functions Running Python | Hackers and Slackers","twitter_description":"Create cloud functions and endpoints with ease using Google Cloud's Cloud Functions and Source Repositories.","twitter_image":"https://hackersandslackers.com/content/images/2018/10/googlefunc-1@2x.jpg","twitter_title":"Creating Google Cloud Functions Running Python | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"The more I explore Google Cloud's endless catalog of cloud services, the more I\nreally like Google Cloud. This is why before moving forward, I'd like to be\ntransparent that this blog has become little more than thinly veiled Google\npropaganda, where I will henceforth bombard you with persuasive and subtle\nmessaging to sell your soul to Google. Let's be honest; they've probably\nsimulated it anyway.\n\nIt should be safe to assume that you're fairly familiar with AWS Lambda\nFunctions [https://hackersandslackers.com/creating-endpoints-with-lambda/],\nwhich have served as the backbone of what we refer to as \"serverless.\" These\ncode snippets in the cloud have restructured entire IT departments and are\npartially why almost nobody knows enough basic Linux to configure a web server\nor build anything without a vendor. In my opinion, Google Cloud Functions are\nbetter than that, so strap in.\n\nAWS vs GCP Comparison\nFirst off, let's talk about a big one: price. AWS charges based on Lambda usage,\nwhereas Google Cloud Functions are free. The only exception to this is when you\nbreak 2 million invocations/month, at which point you'll be hemorrhaging as\nghastly 40 cents per additional million. That's ridiculous. I think we've just\ndiscovered Google Cloud's lead generation strategy.\n\nWhat about in terms of workflow? AWS holds an architecture philosophy of\nchaining services together, into what inevitably becomes a web of self-contained\nbillable items on your invoice. A fine illustration of this is a fine post on \ncommon AWS patterns\n[https://www.jeremydaly.com/serverless-microservice-patterns-for-aws/]  which\nprovides a decent visual of this complexity, while also revealing how much\npeople apparently love this kind of shit, as though SaaS is the new Legos. To\ninteract with a Lambda function in AWS via HTTP requests, you need to set up an\nAPI Gateway in front. I hate setting up API Gateways: it's a feat more\nconvoluted and difficult than actually coding. Pair this with an inevitable user\npermission struggle just to get the right Lambda roles set up, and you quickly\nhave yourself a nightmare- especially  if you're just trying to get a single\nfunction live.  Eventually you’ll get to write some code or upload a horrendous\nzip file like some sort of neanderthal (friendly reminder: I am entirely\nbiased).\n\nGCP has clearly been taking notes on the sidelines on how to improve this\nprocess by removing red tape around service setup or policy configuration. AWS\nand GCP are tackling opposites approaches; AWS allows you to build a Robust API\ncomplete with staging and testing with the intent that some of these APIs can\neven be sold as standalone products to consumers. GCP takes the opposite\napproach: cloud functions are services intended for developers to develop, which\ncovers the vast majority of use cases in my opinion.\n\nCloud Function Deployment\nTo create our first function to serve as an endpoint, we'll utilize the\nfollowing:\n\n * A new Cloud Function  running Python 3.7\n * Google's Source Repositories: AKA a Github/Bitbucket clone with auto-syncing\n   to your real repos, along with direct access to GCP services (think Heroku's\n   source control).\n * The gcloud  CLI to enable us to work locally.\n\nYou should immediately notice the glaring lack of any mentions of API endpoints,\nmethods, stages, or anything related to handling web requests. It should not be\nunderstated that Cloud Functions are preconfigured with an endpoint, and all\nnonsense regarding whether endpoints accept GET or POST or AUTH or OPTIONs is\nmissing entirely. These things are handled in the function itself, and because\nGoogle Cloud functions running Python are preconfigured with Flask, all of that\nstuff is really trivially easy.  That's right, we've got Flask, Python,  and GCP \n all in a single post. Typing these words feels like eating cake while Dwyane\nThe Rock Johnson reads me bedtime stories and caresses me as I fall asleep. It's\ngreat.\n\nCreate your Function\nOur function will intend to serve as a Python HTTP endpoint:\n\nSingle-page setup. Easy. * Trigger  specifies what will have access to this function. By selecting HTTP,\n   we will immediately receive a URL.\n * Source code  gives us a few options to deploy our code with cloud source\n   repository  being by far the easiest solution, especially when working\n   locally.\n * Runtime  allows you to select NodeJS by accident.\n\nBefore we get to code, let's talk Python libraries.\n\nIncluding Dependencies in your Function\nOur function comes prepared with two files: main.py  and our friend \nrequirements.txt. These files do exactly what you'd expect, as per every project\never:\n\nUnfortunately, ease-of-use ensures that GCP certifications will be in low\ndemand.Our function immediately installs all dependencies in requirements.txt  for use\nupon deployment. Once deployed, we can import these libraries as expected. So,\nlet's deploy something.\n\nGoogle Source Repositories\nGoogle's source repositories can serve as a stand-in replacement for Github\n(unlikely), or auto-sync to any repo on the version control behemoth of your\nchoice. The advantage of this extra layer is mostly to trigger deployments upon\ncommits, which in turn feed into GCP's own CI/CD processes (which remain young\nfor now). Create a repo locally using gcloud:\n\n$ gcloud source repos create real-repo\n$ cd myproject/\n$ git init\n--------------------------------------------------------\n(take a moment to write or save some actual code here)\n--------------------------------------------------------\n$ git add --all\n$ git remote add google https://source.developers.google.com/p/hackers/r/real-repo\n$ git commit -m 'cheesey init message'\n$ git push --all google\n\n\nNow make that puppy go live with gcloud functions deploy totally-dope-function,\nwhere totally-dope-function  is name of your function, as it should be.\n\nNow let's get to the coding part.\n\nThe Coding Part (ft. Flask)\nHere's perhaps the most basic endpoint you'll ever create:\n\nimport requests\n\ndef endpoint(request):\n    \"\"\"Does the things.\"\"\"\n    if request.method == 'POST':\n    # Allows POST requests from any origin with the Content-Type\n    # header and caches preflight response for an 3600s\n    headers = {\n        'Access-Control-Allow-Origin': '*',\n        'Access-Control-Allow-Methods': 'POST',\n        'Access-Control-Allow-Headers': 'Content-Type',\n        'Access-Control-Max-Age': '3600'\n    }\n    request_json = request.get_json()\n    if request_json:\n        plaintext = request_json['plain']\n        html = request_json['html']\n        return html\n    else:\n        return 'You didn't pass a JSON body you idiot.'\n\n\nIf you're familiar with Flask (you are, because you're on this blog) you already\nknow what all of this does. Look at that simple copy-paste of headers, as\nopposed to working them into a horrible web interface. Gasp in disbelief as you\nrealize that typing if request.method == 'POST':  would be a 10-minute task in a\nvisual API building tool. We've made it fam.\n\nEase of Logging\nBecause we have a real endpoint to work with, we don't need to waste any time\nsimulating stupid fucking tests where we send fake JSON to our function. We can\nuse postman or anything to immediately interact with our endpoint, and the logs\nare a click away:\n\nEasy. Breezy. Beautiful.There's no point in me droning on at this point because\nyou've surely already ventured into the Google Cloud console in blissful\ndisbelief as a good obedient drone would. If adopting Google Cloud is the last\nshred of hope we have to resist Google's all-knowing algorithms which have\nalready replaced the illusion of free will, I'd gladly take that dystopia over\nsetting up monolithic API Gateways any day.\n\nThe Downsides\nTime for the asterisks to kill that euphoric buzz you might've experienced for a\nbrief moment. My sole purpose as an engineer is to have my dreams crushed\nfull-time; I simply cant resist returning the favor.\n\nFirst notable drawback of Cloud functions is a lack of out-of-the-box custom DNS \n configuration. Firebase has workarounds for this, but Firebase is a beast of\nits own.\n\nWhen it comes to debugging, functions tend to fall short in comparison to their\nLambda rivals. Most Cloud Function debugging involves deploying, testing in dev,\nand sifting through cryptic error logs (they can be quite bad). There's nearly\nno UI mock testing  to speak of. You'd better brush up on PyTest.\n\nMy best advice is to be careful with what services you play around with on GCP.\nLet's not forget this is a platform geared exclusively towards enterprises; the\nfact that we're even playing ball here makes us weirdos in the first place.\nDon't let yourself hemorrhage money like an enterprise.","html":"<p>The more I explore Google Cloud's endless catalog of cloud services, the more I really like Google Cloud. This is why before moving forward, I'd like to be transparent that this blog has become little more than thinly veiled Google propaganda, where I will henceforth bombard you with persuasive and subtle messaging to sell your soul to Google. Let's be honest; they've probably simulated it anyway.</p><p>It should be safe to assume that you're fairly familiar with AWS <a href=\"https://hackersandslackers.com/creating-endpoints-with-lambda/\">Lambda Functions</a>, which have served as the backbone of what we refer to as \"serverless.\" These code snippets in the cloud have restructured entire IT departments and are partially why almost nobody knows enough basic Linux to configure a web server or build anything without a vendor. In my opinion, Google Cloud Functions are better than <em>that</em>, so strap in.</p><h2 id=\"aws-vs-gcp-comparison\">AWS vs GCP Comparison</h2><p>First off, let's talk about a big one: price. AWS charges based on Lambda usage, whereas Google Cloud Functions are <strong>free</strong>. The only exception to this is when you break 2 million invocations/month, at which point you'll be hemorrhaging as ghastly <strong>40 cents per additional million. </strong>That's ridiculous. I think we've just discovered Google Cloud's lead generation strategy.</p><p>What about in terms of workflow? AWS holds an architecture philosophy of chaining services together, into what inevitably becomes a web of self-contained billable items on your invoice. A fine illustration of this is a fine post on <a href=\"https://www.jeremydaly.com/serverless-microservice-patterns-for-aws/\">common AWS patterns</a> which provides a decent visual of this complexity, while also revealing how much people apparently love this kind of shit, as though SaaS is the new Legos. To interact with a Lambda function in AWS via HTTP requests, you need to set up an API Gateway in front. I hate setting up API Gateways: it's a feat more convoluted and difficult than actually coding. Pair this with an inevitable user permission struggle just to get the right Lambda roles set up, and you quickly have yourself a nightmare- <em>especially</em> if you're just trying to get a single function live.<em> </em>Eventually you’ll get to write some code or upload a horrendous zip file like some sort of neanderthal (friendly reminder: I am entirely biased).</p><p>GCP has clearly been taking notes on the sidelines on how to improve this process by removing red tape around service setup or policy configuration. AWS and GCP are tackling opposites approaches; AWS allows you to build a Robust API complete with staging and testing with the intent that some of these APIs can even be sold as standalone products to consumers. GCP takes the opposite approach: cloud functions are services intended for developers to develop, which covers the vast majority of use cases in my opinion.</p><h2 id=\"cloud-function-deployment\">Cloud Function Deployment</h2><p>To create our first function to serve as an endpoint, we'll utilize the following:</p><ul><li>A new <strong>Cloud Function</strong> running Python 3.7</li><li>Google's <strong>Source Repositories: </strong>AKA a Github/Bitbucket clone with auto-syncing to your real repos, along with direct access to GCP services (think Heroku's source control).</li><li>The <strong>gcloud</strong> CLI to enable us to work locally.</li></ul><p>You should immediately notice the glaring lack of any mentions of API endpoints, methods, stages, or anything related to handling web requests. It should not be understated that <em>Cloud Functions are preconfigured with an endpoint</em>, and all nonsense regarding whether endpoints accept GET or POST or AUTH or OPTIONs is missing entirely. These things are handled in the function itself, and because Google Cloud functions running Python are preconfigured with <strong>Flask, </strong>all of that stuff is <em>really trivially easy.</em> That's right, we've got <em>Flask</em>, <em>Python</em>,<em> </em>and <em>GCP</em> all in a single post. Typing these words feels like eating cake while Dwyane The Rock Johnson reads me bedtime stories and caresses me as I fall asleep. It's great.</p><h3 id=\"create-your-function\">Create your Function</h3><p>Our function will intend to serve as a Python HTTP endpoint:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/func.gif\" class=\"kg-image\"><figcaption>Single-page setup. Easy.</figcaption></figure><ul><li><strong>Trigger</strong> specifies what will have access to this function. By selecting HTTP, we will immediately receive a URL.</li><li><strong>Source code</strong> gives us a few options to deploy our code with <em>cloud source repository</em> being by far the easiest solution, especially when working locally.</li><li><strong>Runtime</strong> allows you to select NodeJS by accident.</li></ul><p>Before we get to code, let's talk Python libraries.</p><h3 id=\"including-dependencies-in-your-function\">Including Dependencies in your Function</h3><p>Our function comes prepared with two files: <code>main.py</code> and our friend <code>requirements.txt</code>. These files do exactly what you'd expect, as per every project ever:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-10-18-at-9.14.17-PM.png\" class=\"kg-image\"><figcaption>Unfortunately, ease-of-use ensures that GCP certifications will be in low demand.</figcaption></figure><p>Our function immediately installs all dependencies in <code>requirements.txt</code> for use upon deployment. Once deployed, we can import these libraries as expected. So, let's deploy something.</p><h3 id=\"google-source-repositories\">Google Source Repositories</h3><p>Google's source repositories can serve as a stand-in replacement for Github (unlikely), or auto-sync to any repo on the version control behemoth of your choice. The advantage of this extra layer is mostly to trigger deployments upon commits, which in turn feed into GCP's own CI/CD processes (which remain young for now). Create a repo locally using gcloud:</p><pre><code class=\"language-bash\">$ gcloud source repos create real-repo\n$ cd myproject/\n$ git init\n--------------------------------------------------------\n(take a moment to write or save some actual code here)\n--------------------------------------------------------\n$ git add --all\n$ git remote add google https://source.developers.google.com/p/hackers/r/real-repo\n$ git commit -m 'cheesey init message'\n$ git push --all google\n</code></pre>\n<p>Now make that puppy go live with <code>gcloud functions deploy totally-dope-function</code>, where <em><strong>totally-dope-function</strong> </em>is name of your function, as it should be.</p><p>Now let's get to the coding part.</p><h2 id=\"the-coding-part-ft-flask-\">The Coding Part (ft. Flask)</h2><p>Here's perhaps the most basic endpoint you'll ever create:</p><pre><code class=\"language-python\">import requests\n\ndef endpoint(request):\n    &quot;&quot;&quot;Does the things.&quot;&quot;&quot;\n    if request.method == 'POST':\n    # Allows POST requests from any origin with the Content-Type\n    # header and caches preflight response for an 3600s\n    headers = {\n        'Access-Control-Allow-Origin': '*',\n        'Access-Control-Allow-Methods': 'POST',\n        'Access-Control-Allow-Headers': 'Content-Type',\n        'Access-Control-Max-Age': '3600'\n    }\n    request_json = request.get_json()\n    if request_json:\n        plaintext = request_json['plain']\n        html = request_json['html']\n        return html\n    else:\n        return 'You didn't pass a JSON body you idiot.'\n</code></pre>\n<p>If you're familiar with Flask (you are, because you're on this blog) you already know what all of this does. Look at that simple copy-paste of headers, as opposed to working them into a horrible web interface. Gasp in disbelief as you realize that typing <code>if request.method == 'POST':</code> would be a 10-minute task in a visual API building tool. We've made it fam.</p><h3 id=\"ease-of-logging\">Ease of Logging</h3><p>Because we have a real endpoint to work with, we don't need to waste any time simulating stupid fucking tests where we send fake JSON to our function. We can use postman or anything to immediately interact with our endpoint, and the logs are a click away:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/logs.gif\" class=\"kg-image\"><figcaption>Easy. Breezy. Beautiful.</figcaption></figure><p>There's no point in me droning on at this point because you've surely already ventured into the Google Cloud console in blissful disbelief as a good obedient drone would. If adopting Google Cloud is the last shred of hope we have to resist Google's all-knowing algorithms which have already replaced the illusion of free will, I'd gladly take that dystopia over setting up monolithic <em>API Gateways </em>any day.</p><h2 id=\"the-downsides\">The Downsides</h2><p>Time for the asterisks to kill that euphoric buzz you might've experienced for a brief moment. My sole purpose as an engineer is to have my dreams crushed full-time; I simply cant resist returning the favor.</p><p>First notable drawback of Cloud functions is a <strong>lack of out-of-the-box custom DNS</strong> configuration. Firebase has workarounds for this, but Firebase is a beast of its own.</p><p>When it comes to debugging, functions tend to fall short in comparison to their Lambda rivals. Most Cloud Function debugging involves deploying, testing in dev, and sifting through cryptic error logs (they can be quite bad). There's nearly no <strong>UI mock testing</strong> to speak of. You'd better brush up on PyTest.</p><p>My best advice is to <em>be careful </em>with what services you play around with on GCP. Let's not forget this is a platform geared exclusively towards enterprises; the fact that we're even playing ball here makes us weirdos in the first place. Don't let yourself hemorrhage money like an enterprise.</p>","url":"https://hackersandslackers.com/creating-a-python-google-cloud-function/","uuid":"ec428cb9-976e-4578-a3de-9120a0dd7352","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5bc91ac23d1eab214413b12b"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736a9","title":"Connect to your Google Cloud Compute Engine","slug":"connect-to-your-google-cloud-eompute-engine","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/gcp_instance@2x.jpg","excerpt":"Configuring SSH and file transfers in Google Cloud.","custom_excerpt":"Configuring SSH and file transfers in Google Cloud.","created_at_pretty":"14 July, 2018","published_at_pretty":"05 September, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-07-14T10:10:50.000-04:00","published_at":"2018-09-05T08:00:00.000-04:00","updated_at":"2019-02-02T04:52:29.000-05:00","meta_title":"Configuring SSH and file transfers in Google Cloud | Hackers And Slackers","meta_description":"Now that you've joined the Google Cloud club, you may have found yourself asking the inevitable: \"how do I connect to my damn instance?\"","og_description":"Now that you've joined the Google Cloud club, you may have found yourself asking the inevitable: \"how do I connect to my damn instance?\"","og_image":"https://hackersandslackers.com/content/images/2018/07/gcp_instance@2x.jpg","og_title":"Connect to your Google Cloud Compute Engine","twitter_description":"Now that you've joined the Google Cloud club, you may have found yourself asking the inevitable: \"how do I connect to my damn instance?\"","twitter_image":"https://hackersandslackers.com/content/images/2018/07/gcp_instance@2x.jpg","twitter_title":"Connect to your Google Cloud Compute Engine","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"}],"plaintext":"So you've taken a leap and decided to host your VPS on Google Cloud: let me be\nthe first to congratulate you on joining the clearly superior cloud platform of\nour modern era. I would apologize for being so openly opinionated, but so far\nI've only stated objective facts.\n\nNow that you've joined the club, you may have found yourself asking the\ninevitable: \"how do I connect to my damn instance?\"  If you're like me, you're\nprobably not the kind of person who enjoys this as their main solution:\n\nGoogle Cloud's in-browser terminal.Luckily for us, there are a few ways to\ninteract with your Compute Engine. Let's take a look at all of them.\n\nSet up the gcloud CLI\nIn order to SSH natively, we need to install the gcloud CLI  on our machine. Mac\nusers can download this here\n[https://cloud.google.com/sdk/docs/quickstart-macos], and Windows users can\ndownload from here [https://cloud.google.com/sdk/docs/quickstart-windows].\nClicking the downloaded file will extract the package. With your package\nextracted, run the install script install.sh  (or install.bat  for Windows) to\nstart the installation:\n\n$ ~/Downloads/google-cloud-sdk/install.sh\nWelcome to the Google Cloud SDK!\n\nTo help improve the quality of this product, we collect anonymized usage data\nand anonymized stacktraces when crashes are encountered; additional information\nis available at <https://cloud.google.com/sdk/usage-statistics>. You may choose\nto opt out of this collection now (by choosing 'N' at the below prompt), or at\nany time in the future by running the following command:\n\n    gcloud config set disable_usage_reporting true\n\nDo you want to help improve the Google Cloud SDK (Y/n)?\n\n\nContinuing the script will list the 'components' gcloud can install on your\nlocal machine, where each component is a Google Cloud product:\n\nYour current Cloud SDK version is: 214.0.0\nThe latest available version is: 214.0.0\n\n┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n│                                                  Components                                                 │\n├───────────────┬──────────────────────────────────────────────────────┬──────────────────────────┬───────────┤\n│     Status    │                         Name                         │            ID            │    Size   │\n├───────────────┼──────────────────────────────────────────────────────┼──────────────────────────┼───────────┤\n│ Not Installed │ App Engine Go Extensions                             │ app-engine-go            │ 152.8 MiB │\n│ Not Installed │ Cloud Bigtable Command Line Tool                     │ cbt                      │   6.3 MiB │\n│ Not Installed │ Cloud Bigtable Emulator                              │ bigtable                 │   4.3 MiB │\n│ Not Installed │ Cloud Datalab Command Line Tool                      │ datalab                  │   < 1 MiB │\n│ Not Installed │ Cloud Datastore Emulator                             │ cloud-datastore-emulator │  17.7 MiB │\n│ Not Installed │ Cloud Datastore Emulator (Legacy)                    │ gcd-emulator             │  38.1 MiB │\n│ Not Installed │ Cloud Pub/Sub Emulator                               │ pubsub-emulator          │  33.4 MiB │\n│ Not Installed │ Cloud SQL Proxy                                      │ cloud_sql_proxy          │   2.5 MiB │\n│ Not Installed │ Emulator Reverse Proxy                               │ emulator-reverse-proxy   │  14.5 MiB │\n│ Not Installed │ Google Cloud Build Local Builder                     │ cloud-build-local        │   4.4 MiB │\n│ Not Installed │ Google Container Local Builder                       │ container-builder-local  │   4.4 MiB │\n│ Not Installed │ Google Container Registry's Docker credential helper │ docker-credential-gcr    │   1.8 MiB │\n│ Not Installed │ gcloud Alpha Commands                                │ alpha                    │   < 1 MiB │\n│ Not Installed │ gcloud Beta Commands                                 │ beta                     │   < 1 MiB │\n│ Not Installed │ gcloud app Java Extensions                           │ app-engine-java          │ 118.6 MiB │\n│ Not Installed │ gcloud app PHP Extensions                            │ app-engine-php           │  21.9 MiB │\n│ Not Installed │ gcloud app Python Extensions                         │ app-engine-python        │   6.2 MiB │\n│ Not Installed │ gcloud app Python Extensions (Extra Libraries)       │ app-engine-python-extras │  28.5 MiB │\n│ Not Installed │ kubectl                                              │ kubectl                  │   < 1 MiB │\n│ Installed     │ BigQuery Command Line Tool                           │ bq                       │   < 1 MiB │\n│ Installed     │ Cloud SDK Core Libraries                             │ core                     │   8.3 MiB │\n│ Installed     │ Cloud Storage Command Line Tool                      │ gsutil                   │   3.6 MiB │\n└───────────────┴──────────────────────────────────────────────────────┴──────────────────────────┴───────────┘\nTo install or remove components at your current SDK version [214.0.0], run:\n  $ gcloud components install COMPONENT_ID\n  $ gcloud components remove COMPONENT_ID\n\nTo update your SDK installation to the latest version [214.0.0], run:\n  $ gcloud components update\n\n\nModify profile to update your $PATH and enable shell command\ncompletion?\n\nDo you want to continue (Y/n)?\n\n\nOnce installed, run gcloud init  in your terminal. This will prompt you to\nlogin:\n\nTo continue, you must log in. Would you like to log in (Y/n)?\n\n\nPressing 'Y' will prompt a simple browser window from which you can authenticate\nwith Google by simply selecting your Google account, as though we were using any\nother app with Google OAuth authentication. That's correct: you don't even need\nto go through the trouble of typing a password, assuming you've logged in to\nyour Google account before (I'm guessing you have).\n\n2ez authentication.Next, the terminal will prompt to specify which of your\nprojects to use. Select the project which contains your instance by entering the\nnumber seen in the resulting list:\n\nPick cloud project to use:\n [1] [my-project-1]\n [2] [my-project-2]\n ...\n Please enter your numeric choice:\n\n\nNow you're in the clear to go nuts with the gcloud  CLI:\n\ngcloud has now been configured!\nYou can use [gcloud config] to change more gcloud settings.\n\nYour active configuration is: [default]\n\n\nSSH via a Native Terminal\nUgh, so now we need to go through the process of creating public and private\nkeys etc to SSH into our instance, right? Wrong: gcloud  is so mo effin' dope\nthat there's a one-line command which will actually do this for you:\n\n$ gcloud compute config-ssh\n\nYou should now be able to use ssh/scp with your instances.\nFor example, try running:\n\n$ ssh instancename.region-b.projectname-173869\n\n\nBut there's no way it's that easy, right?\n\n$ gcloud compute ssh instancename\nEnter passphrase for key '/Users/username/.ssh/google_compute_engine':\n\nWelcome to Ubuntu 16.04.4 LTS (GNU/Linux 4.15.0-1018-gcp x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/advantage\n\n  Get cloud support with Ubuntu Advantage Cloud Guest:\n    http://www.ubuntu.com/business/services/cloud\n\n30 packages can be updated.\n0 updates are security updates.\n\n\nIt really is that easy. For as long as you use your local machine, you will only\never need to used the command gcloud compute ssh instancename  to connect to\nyour instance.\n\nGet and Put Files\nYou might be thinking that the next order of business would be to config SFTP in\norder to manage files on your instance. Believe it or not, there's a simpler\nway.\n\nDownloading Files from your Instance\ngcloud  comes with a built-in tool to download and upload files to your instance\nvia the CLI. To download files from your server, check out this one-liner:\n\ngcloud compute scp [LOCAL_FILE_PATH] [INSTANCE_NAME]:~/path/to/file/on/server\n\n\nUploading Files to your Instance\nThe same command can be reversed to upload as well:\n\ngcloud compute scp --recurse [INSTANCE_NAME]:[REMOTE_DIR] [LOCAL_DIR]\n\n\nOther Methods\nWhen we begin to look into other methods of interacting with our Computer Engine\ninstance, the general youth of GCP becomes apparent.\n\nAt the time of writing, Google's own documentation lacks information on how to\nconnect via SFTP, as the only mention of SFTP is this broken anchor link. Google\nalso provides a RDP  Chrome add-on\n[https://chrome.google.com/webstore/detail/chrome-rdp-for-google-clo/mpbbnannobiobpnfblimoapbephgifkm/] \n specifically for connecting to Compute instances, but my own attempts have\nshown this to be broken as well:\n\nWhy can't I click on you?!?!Despite these setbacks, the combination of SSH and\ngetting/putting files should be more than enough to satisfy anybody's needs for\nnow. Google Cloud Platform is only getting better with time, and is doing so at\na pace which scare other providers.","html":"<p>So you've taken a leap and decided to host your VPS on Google Cloud: let me be the first to congratulate you on joining the clearly superior cloud platform of our modern era. I would apologize for being so openly opinionated, but so far I've only stated objective facts.</p><p>Now that you've joined the club, you may have found yourself asking the inevitable: \"<em>how do I connect to my damn instance?\"</em> If you're like me, you're probably not the kind of person who enjoys this as their main solution:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ssh.gif\" class=\"kg-image\"><figcaption>Google Cloud's in-browser terminal.</figcaption></figure><p>Luckily for us, there are a few ways to interact with your Compute Engine. Let's take a look at all of them.</p><h2 id=\"set-up-the-gcloud-cli\">Set up the gcloud CLI</h2><p>In order to SSH natively, we need to install the <strong>gcloud CLI</strong> on our machine. Mac users can download this <a href=\"https://cloud.google.com/sdk/docs/quickstart-macos\">here</a>, and Windows users can download from <a href=\"https://cloud.google.com/sdk/docs/quickstart-windows\">here</a>. Clicking the downloaded file will extract the package. With your package extracted, run the install script <code>install.sh</code> (or <code>install.bat</code> for Windows) to start the installation:</p><pre><code class=\"language-bash\">$ ~/Downloads/google-cloud-sdk/install.sh\nWelcome to the Google Cloud SDK!\n\nTo help improve the quality of this product, we collect anonymized usage data\nand anonymized stacktraces when crashes are encountered; additional information\nis available at &lt;https://cloud.google.com/sdk/usage-statistics&gt;. You may choose\nto opt out of this collection now (by choosing 'N' at the below prompt), or at\nany time in the future by running the following command:\n\n    gcloud config set disable_usage_reporting true\n\nDo you want to help improve the Google Cloud SDK (Y/n)?\n</code></pre>\n<p>Continuing the script will list the 'components' gcloud can install on your local machine, where each component is a Google Cloud product:</p><pre><code class=\"language-bash\">Your current Cloud SDK version is: 214.0.0\nThe latest available version is: 214.0.0\n\n┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n│                                                  Components                                                 │\n├───────────────┬──────────────────────────────────────────────────────┬──────────────────────────┬───────────┤\n│     Status    │                         Name                         │            ID            │    Size   │\n├───────────────┼──────────────────────────────────────────────────────┼──────────────────────────┼───────────┤\n│ Not Installed │ App Engine Go Extensions                             │ app-engine-go            │ 152.8 MiB │\n│ Not Installed │ Cloud Bigtable Command Line Tool                     │ cbt                      │   6.3 MiB │\n│ Not Installed │ Cloud Bigtable Emulator                              │ bigtable                 │   4.3 MiB │\n│ Not Installed │ Cloud Datalab Command Line Tool                      │ datalab                  │   &lt; 1 MiB │\n│ Not Installed │ Cloud Datastore Emulator                             │ cloud-datastore-emulator │  17.7 MiB │\n│ Not Installed │ Cloud Datastore Emulator (Legacy)                    │ gcd-emulator             │  38.1 MiB │\n│ Not Installed │ Cloud Pub/Sub Emulator                               │ pubsub-emulator          │  33.4 MiB │\n│ Not Installed │ Cloud SQL Proxy                                      │ cloud_sql_proxy          │   2.5 MiB │\n│ Not Installed │ Emulator Reverse Proxy                               │ emulator-reverse-proxy   │  14.5 MiB │\n│ Not Installed │ Google Cloud Build Local Builder                     │ cloud-build-local        │   4.4 MiB │\n│ Not Installed │ Google Container Local Builder                       │ container-builder-local  │   4.4 MiB │\n│ Not Installed │ Google Container Registry's Docker credential helper │ docker-credential-gcr    │   1.8 MiB │\n│ Not Installed │ gcloud Alpha Commands                                │ alpha                    │   &lt; 1 MiB │\n│ Not Installed │ gcloud Beta Commands                                 │ beta                     │   &lt; 1 MiB │\n│ Not Installed │ gcloud app Java Extensions                           │ app-engine-java          │ 118.6 MiB │\n│ Not Installed │ gcloud app PHP Extensions                            │ app-engine-php           │  21.9 MiB │\n│ Not Installed │ gcloud app Python Extensions                         │ app-engine-python        │   6.2 MiB │\n│ Not Installed │ gcloud app Python Extensions (Extra Libraries)       │ app-engine-python-extras │  28.5 MiB │\n│ Not Installed │ kubectl                                              │ kubectl                  │   &lt; 1 MiB │\n│ Installed     │ BigQuery Command Line Tool                           │ bq                       │   &lt; 1 MiB │\n│ Installed     │ Cloud SDK Core Libraries                             │ core                     │   8.3 MiB │\n│ Installed     │ Cloud Storage Command Line Tool                      │ gsutil                   │   3.6 MiB │\n└───────────────┴──────────────────────────────────────────────────────┴──────────────────────────┴───────────┘\nTo install or remove components at your current SDK version [214.0.0], run:\n  $ gcloud components install COMPONENT_ID\n  $ gcloud components remove COMPONENT_ID\n\nTo update your SDK installation to the latest version [214.0.0], run:\n  $ gcloud components update\n\n\nModify profile to update your $PATH and enable shell command\ncompletion?\n\nDo you want to continue (Y/n)?\n</code></pre>\n<p>Once installed, run <code>gcloud init</code> in your terminal. This will prompt you to login:</p><pre><code class=\"language-bash\">To continue, you must log in. Would you like to log in (Y/n)?\n</code></pre>\n<p>Pressing 'Y' will prompt a simple browser window from which you can authenticate with Google by simply selecting your Google account, as though we were using any other app with Google OAuth authentication. That's correct: you don't even need to go through the trouble of typing a password, assuming you've logged in to your Google account before (I'm guessing you have).</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-09-04-at-3.36.26-PM.png\" class=\"kg-image\"><figcaption>2ez authentication.</figcaption></figure><p>Next, the terminal will prompt to specify which of your projects to use. Select the project which contains your instance by entering the number seen in the resulting list:</p><pre><code class=\"language-bash\">Pick cloud project to use:\n [1] [my-project-1]\n [2] [my-project-2]\n ...\n Please enter your numeric choice:\n</code></pre>\n<p>Now you're in the clear to go nuts with the <strong>gcloud</strong> CLI:</p><pre><code class=\"language-bash\">gcloud has now been configured!\nYou can use [gcloud config] to change more gcloud settings.\n\nYour active configuration is: [default]\n</code></pre>\n<h2 id=\"ssh-via-a-native-terminal\">SSH via a Native Terminal</h2><p>Ugh, so now we need to go through the process of creating public and private keys etc to SSH into our instance, right? Wrong: <strong>gcloud</strong> is so mo effin' dope that there's a one-line command which will actually do this for you:</p><pre><code class=\"language-bash\">$ gcloud compute config-ssh\n\nYou should now be able to use ssh/scp with your instances.\nFor example, try running:\n\n$ ssh instancename.region-b.projectname-173869\n</code></pre>\n<p>But there's no way it's that easy, right?</p><pre><code class=\"language-bash\">$ gcloud compute ssh instancename\nEnter passphrase for key '/Users/username/.ssh/google_compute_engine':\n\nWelcome to Ubuntu 16.04.4 LTS (GNU/Linux 4.15.0-1018-gcp x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/advantage\n\n  Get cloud support with Ubuntu Advantage Cloud Guest:\n    http://www.ubuntu.com/business/services/cloud\n\n30 packages can be updated.\n0 updates are security updates.\n</code></pre>\n<p>It really is that easy. For as long as you use your local machine, you will only ever need to used the command <code>gcloud compute ssh instancename</code> to connect to your instance.</p><h2 id=\"get-and-put-files\">Get and Put Files</h2><p>You might be thinking that the next order of business would be to config SFTP in order to manage files on your instance. Believe it or not, there's a simpler way.</p><h3 id=\"downloading-files-from-your-instance\">Downloading Files from your Instance</h3><p><strong>gcloud</strong> comes with a built-in tool to download and upload files to your instance via the CLI. To download files from your server, check out this one-liner:</p><pre><code class=\"language-bash\">gcloud compute scp [LOCAL_FILE_PATH] [INSTANCE_NAME]:~/path/to/file/on/server\n</code></pre>\n<h3 id=\"uploading-files-to-your-instance\">Uploading Files to your Instance</h3><p>The same command can be reversed to upload as well:</p><pre><code class=\"language-bash\">gcloud compute scp --recurse [INSTANCE_NAME]:[REMOTE_DIR] [LOCAL_DIR]\n</code></pre>\n<h2 id=\"other-methods\">Other Methods</h2><p>When we begin to look into other methods of interacting with our Computer Engine instance, the general youth of GCP becomes apparent.</p><p>At the time of writing, Google's own documentation lacks information on how to connect via <strong>SFTP, </strong>as the only mention of SFTP is this <a href=\"https://cloud.google.com/compute/docs/instances/transfer-files#filebrowser\">broken anchor link</a>. Google also provides a <strong>RDP</strong> <a href=\"https://chrome.google.com/webstore/detail/chrome-rdp-for-google-clo/mpbbnannobiobpnfblimoapbephgifkm/\">Chrome add-on</a> specifically for connecting to Compute instances, but my own attempts have shown this to be broken as well:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/rdp.png\" class=\"kg-image\"><figcaption>Why can't I click on you?!?!</figcaption></figure><p>Despite these setbacks, the combination of SSH and getting/putting files should be more than enough to satisfy anybody's needs for now. Google Cloud Platform is only getting better with time, and is doing so at a pace which scare other providers.</p>","url":"https://hackersandslackers.com/connect-to-your-google-cloud-eompute-engine/","uuid":"774f9ff4-8fe2-4951-b240-5de2f80bc266","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b4a046a1c20005e9422c102"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ca","title":"PostgreSQL Cloud Database on Google Cloud","slug":"cloud-sql-postgres-on-gcp","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/postgres4.jpg","excerpt":"Deep Dive into Cloud SQL and its out-of-the-box API.","custom_excerpt":"Deep Dive into Cloud SQL and its out-of-the-box API.","created_at_pretty":"09 August, 2018","published_at_pretty":"10 August, 2018","updated_at_pretty":"28 February, 2019","created_at":"2018-08-09T12:49:05.000-04:00","published_at":"2018-08-10T05:52:00.000-04:00","updated_at":"2019-02-27T23:37:34.000-05:00","meta_title":"Cloud-Hosted Postgres on Google Cloud | Hackers and Slackers","meta_description":"A sexy relational database on the hottest cloud provider on the market is hard to resist. Especially when it comes with a REST API.","og_description":"A sexy relational database on the hottest cloud provider on the market is hard to resist. Especially when it comes with a REST API.\n\n#Postgres #GoogleCloud #Databases","og_image":"https://hackersandslackers.com/content/images/2019/02/postgres4.jpg","og_title":"Cloud SQL Postgres on GCP","twitter_description":"A sexy relational database on the hottest cloud provider on the market is hard to resist. Especially when it comes with a REST API.\n\n#Postgres #GoogleCloud #Databases\n\n","twitter_image":"https://hackersandslackers.com/content/images/2019/02/postgres4.jpg","twitter_title":"Cloud SQL Postgres on GCP","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"PostgreSQL","slug":"postgresql","description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","feature_image":null,"meta_description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","meta_title":"Working with PostgreSQL | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"}],"plaintext":"Well folks, I have a confession to make. I've been maintaining an affair with\ntwo lovers. That's right; they're none other than PostgreSQL, and Google Cloud.\nWhile such polygamy may be shunned by the masses, I believe that somehow, some\nway, we can just make this ménage à trois work. What entices me about Cloud SQL\nis the existence of the Cloud SQL API\n[https://cloud.google.com/sql/docs/postgres/admin-api/]  , which generates\npredictable REST endpoints for presumably reading and writing to your database.\nPlease allow a moment of silence for the old workflow of API Gateways and Lambda\nfunctions. RIP.\n\nWe’ll get to APIs eventually, but for now we have one glaring obstacle: creating\nour DB, and connecting to it in a way vaguely resembles something secure*.\n\nNote: today may or may not be opposite day.Creating Our Cloud Database\nHit up the Cloud SQL [https://console.cloud.google.com/sql/]  section of your\nconsole to get this party started. Database creation on GCP is surprisingly\neasy.\n\nThat's pretty much it tbh.Databases Gone Wild: Postgres Exposed\nThere are plenty of correct ways to connect to your Postgres database correctly\nand securely. You can set up SSL for an IP\n[https://cloud.google.com/sql/docs/postgres/connect-admin-ip], connect using a\nproxy [https://cloud.google.com/sql/docs/postgres/connect-admin-proxy], or even\nvia internal cloud functions\n[https://cloud.google.com/sql/docs/postgres/connect-cloud-functions]. You may\nwant to consider doing one of those things. I'll be doing this a different way,\nbecause I'd rather get my useless data on a hackable public database than\nrewrite Google tutorials:\n\nDo as I say, not as I do.This is where you can feel free to go ahead and\npopulate data into your DB via whichever GUI you'd prefer. It'll be easier to\nsee which API calls work if there's actual data involved.\n\nPick whichever overpriced client suits you best!Enabling the API\nAs always with GCP, we need to explicitly activate the API for SQL; that way,\nthey can charge us money forever, long after we've forgotten this tutorial. We\ncan do this here\n[https://console.cloud.google.com/flows/enableapi?apiid=sqladmin]. Are you\nstarting to feel excited? I know I am; just think, all those API calls right\naround the corner, coming from a real SQL database. Wow. \n\nIn the overall process, we've made it here: the part where we run into OAuth2:\n\nRefresh tokens? Scopes? Uh oh.I'll admit it took me a good amount of time to\ndecrypt the information which failed to conveyed here. After clicking into every\nrelated link and failing at attempts to hit the API via Postman, the bad vibes\nstarted kicking in. What if this isn't the dream after all? To spare you the\nprocess, let me introduce you to a very useful GCP tool.\n\nGoogle API Explorer\nGoogle's API explorer is a GUI for playing with any API, connected to any of\nyour services. This is a cool way to preview what the exact scope of an API is\nbefore you sign up for it. Better yet, you can use placeholder User_IDs  and \nUser_Secrets  since this is basically just a sandbox.\n\nInteractive API learning tools beat reading documentation any day.After\nselecting an 'endpoint' and specifying some details like your project and\ndatabase instance, you can immediately see (theoretical) results of what the\nlive API can do. This is very useful, but I'm afraid this is where things get\ndark.\n\nHello Darkness My Old Friend\nYou may have noticed a lot of similar words or phrases popping up in these\nendpoints. Words such as \"admin\"  and \"list\", while lacking phrases such as \n\"show me my god damn data\". Google's Cloud SQL API  is NOT, in fact, an API to\ninteract with your data, but rather an admin API which enables you to do things\nprobably better suited for, you know, admin consoles.\n\nAs a big fan of GCP, this is but one of a number of growing pains I've\nexperienced with the platform so far. For instance, this entire blog along with\nits VPC has temporary deleted today, because apparently the phrases \"remove my\nproject from Firebase\"  and \"delete my project along with everything I love\" are\nsentimentally similar enough to leave that language vague and awkward.\n\nWhere Do We Go From Here?\nTo reiterate, the problem we were originally looking to solve was to find a\nservice which could (after what, 30 years?) make relational database reading and\nwriting trivial, especially in the case of apps which are simply themes without\na configurable backend, such as this blog.\n\nMongoDB Atlas  is an organizational mess which can't even describe their own\nproduct. Firebase  has yet to implement an import feature, so unless you feel\nlike writing loops to write to an experimental NoSQL database (I don't), we're\nstill kind of screwed. I know there are guys like Dreamfactory out there, but\nthese services are the sketchy ones who email you every day just for looking at\na trial. Also, anything related to Oracle or running on Oracle products (by\nchoice) sucks. There, I said it. Java developers will probably be too bust with\ngarbage collection and getting sued to argue with me anyway.\n\nAll that said, it feels like the \"Backend as a service\" thing is looming over\nthe horizon. There just doesn't seem to be anybody who's executed this\neffectively yet.\n\nUPDATE:  As it turns out, there is a service out there that accomplishes\neverything we hoped to achieve in Google cloud, and it is called Apisentris\n[https://apisentris.com/]. It's awesome, it's free, and the guy behind it is a\nchill dude.","html":"<p>Well folks, I have a confession to make. I've been maintaining an affair with two lovers. That's right; they're none other than PostgreSQL, and Google Cloud. While such polygamy may be shunned by the masses, I believe that somehow, some way, we can just make this ménage à trois work. What entices me about Cloud SQL is the existence of the <a href=\"https://cloud.google.com/sql/docs/postgres/admin-api/\">Cloud SQL API</a> , which generates predictable REST endpoints for presumably reading and writing to your database. Please allow a moment of silence for the old workflow of API Gateways and Lambda functions. RIP.</p><p>We’ll get to APIs eventually, but for now we have one glaring obstacle: creating our DB, and connecting to it in a way vaguely resembles something secure*.</p><span style=\"color: #669ab5; font-style: italic; font-size: 15px; float: right;\">Note: today may or may not be opposite day.</span><h2 id=\"creating-our-cloud-database\">Creating Our Cloud Database</h2><p>Hit up the <a href=\"https://console.cloud.google.com/sql/\">Cloud SQL</a> section of your console to get this party started. Database creation on GCP is surprisingly easy.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/setuppostgres.png\" class=\"kg-image\"><figcaption>That's pretty much it tbh.</figcaption></figure><h2 id=\"databases-gone-wild-postgres-exposed\">Databases Gone Wild: Postgres Exposed  </h2><p>There are plenty of <em>correct </em>ways to connect to your Postgres database correctly and securely. You can <a href=\"https://cloud.google.com/sql/docs/postgres/connect-admin-ip\">set up SSL for an IP</a>, connect <a href=\"https://cloud.google.com/sql/docs/postgres/connect-admin-proxy\">using a proxy</a>, or even via internal <a href=\"https://cloud.google.com/sql/docs/postgres/connect-cloud-functions\">cloud functions</a>. You may want to consider doing one of those things. I'll be doing this a different way, because I'd rather get my useless data on a hackable public database than rewrite Google tutorials:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/public.png\" class=\"kg-image\"><figcaption>Do as I say, not as I do.</figcaption></figure><p>This is where you can feel free to go ahead and populate data into your DB via whichever GUI you'd prefer. It'll be easier to see which API calls work if there's actual data involved.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-08-10-at-4.15.22-AM.png\" class=\"kg-image\"><figcaption>Pick whichever overpriced client suits you best!</figcaption></figure><h2 id=\"enabling-the-api\">Enabling the API</h2><p>As always with GCP, we need to explicitly activate the API for SQL; that way, they can charge us money forever, long after we've forgotten this tutorial. We can do this <a href=\"https://console.cloud.google.com/flows/enableapi?apiid=sqladmin\">here</a>. Are you starting to feel excited? I know I am; just think, all those API calls right around the corner, coming from a real SQL database. Wow. </p><p>In the overall process, we've made it <em>here</em>: the part where we run into OAuth2:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-08-10-at-4.21.55-AM.png\" class=\"kg-image\"><figcaption>Refresh tokens? Scopes? Uh oh.</figcaption></figure><p>I'll admit it took me a good amount of time to decrypt the information which failed to conveyed here. After clicking into every related link and failing at attempts to hit the API via Postman, the bad vibes started kicking in. What if this isn't the dream after all? To spare you the process, let me introduce you to a very useful GCP tool.</p><h2 id=\"google-api-explorer\">Google API Explorer</h2><p>Google's API explorer is a GUI for playing with any API, connected to any of your services. This is a cool way to preview what the exact scope of an API is before you sign up for it. Better yet, you can use placeholder <em>User_IDs</em> and <em>User_Secrets</em> since this is basically just a sandbox.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sandbox.gif\" class=\"kg-image\"><figcaption>Interactive API learning tools beat reading documentation any day.</figcaption></figure><p>After selecting an 'endpoint' and specifying some details like your project and database instance, you can immediately see (theoretical) results of what the live API can do. This is very useful, but I'm afraid this is where things get dark.</p><h3 id=\"hello-darkness-my-old-friend\">Hello Darkness My Old Friend</h3><p>You may have noticed a lot of similar words or phrases popping up in these endpoints. Words such as <em>\"admin\"</em> and \"<em>list\"</em>, while lacking phrases such as <em>\"show me my god damn data\". </em>Google's <strong>Cloud SQL API</strong> is NOT, in fact, an API to interact with your data, but rather an <em>admin </em>API which enables you to do things probably better suited for, you know, admin consoles.</p><p>As a big fan of GCP, this is but one of a number of growing pains I've experienced with the platform so far. For instance, this entire blog along with its VPC has temporary deleted today, because apparently the phrases <em>\"remove my project from Firebase\"</em> and <em>\"delete my project along with everything I love\" </em>are sentimentally similar enough to leave that language vague and awkward.</p><h2 id=\"where-do-we-go-from-here\">Where Do We Go From Here?</h2><p>To reiterate, the problem we were originally looking to solve was to find a service which could (after what, 30 years?) make relational database reading and writing trivial, especially in the case of apps which are simply themes without a configurable backend, such as this blog.</p><p><em>MongoDB Atlas</em> is an organizational mess which can't even describe their own product. <em>Firebase</em> has yet to implement an import feature, so unless you feel like writing loops to write to an experimental NoSQL database (I don't), we're still kind of screwed. I know there are guys like <em>Dreamfactory </em>out there, but these services are the sketchy ones who email you every day just for looking at a trial. Also, anything related to Oracle or running on Oracle products (by choice) sucks. There, I said it. Java developers will probably be too bust with garbage collection and getting sued to argue with me anyway.</p><p>All that said, it feels like the \"Backend as a service\" thing is looming over the horizon. There just doesn't seem to be anybody who's executed this effectively yet.</p><p><strong>UPDATE:</strong> As it turns out, there is a service out there that accomplishes everything we hoped to achieve in Google cloud, and it is called <a href=\"https://apisentris.com/\">Apisentris</a>. It's awesome, it's free, and the guy behind it is a chill dude.</p>","url":"https://hackersandslackers.com/cloud-sql-postgres-on-gcp/","uuid":"76daacf1-55b4-4ede-b21d-29fd727e1d50","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b6c70819dcd9d3270b58635"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736aa","title":"Create a VPS with Google Cloud: Introducing Compute Engine","slug":"setting-up-dns-with-google-cloud-platform","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","excerpt":"Spin up a VPS and configure DNS with relative ease.","custom_excerpt":"Spin up a VPS and configure DNS with relative ease.","created_at_pretty":"14 July, 2018","published_at_pretty":"14 July, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-07-14T10:28:34.000-04:00","published_at":"2018-07-14T14:55:03.000-04:00","updated_at":"2019-02-14T02:29:40.000-05:00","meta_title":"Google Cloud Platform: Creating a VPS | Hackers and Slackers","meta_description":"Google Cloud Platform is a compelling choice for respectable enterprises, particularly those with a sense of style and curiosity.","og_description":"The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity just yet. Let's set up a server to see what the hype is about. Today'll we'll be creating a standard Linux instance and walking through the steps to configure an existing DNS for said instance.","og_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","og_title":"Create a VPS with Google Cloud: Compute Engine","twitter_description":"The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity just yet. Let's set up a server to see what the hype is about. Today'll we'll be creating a standard Linux instance and walking through the steps to configure an existing DNS for said instance.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","twitter_title":"Create a VPS with Google Cloud: Compute Engine","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"}],"plaintext":"For the last few weeks I've been enamored with Google's cloud platform, aptly\nnamed Google Cloud Platform. GCP contains the things you might expect from a\nyoung player in the 'screw AWS' space: much of what exists on AWS has an\nequivalent on GPC, but certain subtleties exist, such as the lack of Python\nserverless functions and so forth. That said, GCP makes up for any shortcomings\nby leveraging services exclusive to Google.\n\nIn my opinion, GCP is the first contender in the market to package enterprise\ncloud computing in a satisfying way. It's clear GCP has assigned UI and Product\nManagement resources to their platform, where Amazon clearly did not. while not\nwithout its shortcomings, it's obvious Google has chosen usability as a key\ndifferentiator from AWS.\n\nAside from the UI, GCP offers plenty of fun functionality such as their cloud\nlauncher. This is the equivalent of one-click deploys for cool stuff, whether\nthey be services to add to your VPC, Google APIs, Datasets, or what have you.\nThe ease of plug-and-play these plug-and-play services make GCP a compelling\nchoice for a respectable enterprise which hasn't lost the gift of curiosity.\n\nIt's like product hunt... on crack.The best way to get a feel for what value a\nproduct has would be use it, of course. In the interest of becoming familiar\nwith Google Cloud, we'll execute the most basic task of setting up a VPS to\ndeploy code to. This practice will end up touching on many of GCP's core\nservices which will allow us to grasp the basic offerings of the product, as\nwell as its strengths and weakness.\n\nDoes in Fact Compute \nGCP cutely names their server's Compute Engines,  which are at least more\ntolerable than, say, EC2 instances. I'm just going to call them servers because\nI'm not the type of person who orders a \"tall\" at Starbucks.\n\nCreate a \"project\" in Google Cloud, and you'll immediately land at a dashboard.\nAll Google's services are tucked away in the left-hand menu. Open that bad boy\nup and find Compute Engine.\n\nShhh, it's thinking.Select create. As opposed to the preset choices of VPCS you might be used to,\nGoogle allows us to customize our VPS to our exact technical specifications on a\nsliding scale. Want 96 processing cores, but only a single GB of RAM? No\nproblem, if that's what you're into. Weirdo.\n\nAs well as picking between the usual Linux distributions, Compute Engine also\nallows customers to select their number of GPUs, as well as the generation of\nIntel CPU their instance will run on.\n\nDat customization thoWe want traffic to hit this instance, so make sure you\ncheck Allow HTTP  traffic  and Allow HTTPS traffic  before continuing. Once your\ninstance is created, you should immediately able to SSH into your server via\nGCP's browser client.\n\nThe App Engine\nGCP is not without its own fair share of arbitrary product classifications. DNS\nrecords and hosts are contained within the App Engine  service of the platform.\nFind the App Engine service in the left hand navigation, and scroll down to the \nsettings  link:\n\nAllllll the way at the bottom.Here's we'll be able to see a \"custom domains\" tab\nwhich allows us to point a domain we've purchased from a service like Namecheap \n or what-have-you to Google Cloud. I'll personally be walking though this\nexample by directing a pointless domain called memegenerator.io  I purchased on\nNamecheap for no good reason.\n\nWhen you add a custom domain via this screen, you'll immediately be asked to\nverify ownership over the domain via the familiar Google Webmaster tool, which\nyou'll be redirected to automatically.\n\nBack to Your Registrar\nChances are you've dealt with verification via Google webmaster before, but this\ntime we've only given the option to do this via DNS. Select your registrar in\nthe dropdown in order to reveal a Google-generated record used to verify your\ndomain. \n\nPlease don't tell me you use GoDaddy.The resulting value will need to be added\nas a .txt record before we can actually point your domain to Google's servers.\n\nIf you're using Namecheap like I am, log in to your dashboard and find your\ndomain by clicking \"manage domain\". Make sure you're under the \"advanced DNS\"\ntab:\n\nEven if you're not using Namecheap, this shouldn't be much different.Delete all\nexisting records. Then create a TXT record (with @ as the host) and input the\nvalue that Google provided you earlier. Now, when you return to the webmaster\ntool, clicking verify tool should  pick up on this change. \n\nIf the webmaster tool does not pick up on this verification right away, don't\npanic. This happens fairly often - just frantically keep making sure everything\nis set up correctly while mashing the verify button.Navigate back to the Custom\nDomains tab in GCP and continue the process- you should see that your domain is\nverified. You'll be prompted to enter any subdomains you'd GCP to pick up on\nhere. Wrap that up and save.\n\n\n\nMake it Rain with Records\nOh, we're far from over buddy. We need to go back to update our A and AAAA\nrecords, now that Google as bestowed that privilege upon us. You should see a\ntable such as the one below:\n\nType\n Data\n Alias\n A\n 216.239.32.21\n A\n 216.239.34.21\n A\n 216.239.36.21\n A\n 216.239.38.21\n AAAA\n 2001:4860:4802:32::15\n AAAA\n 2001:4860:4802:34::15\n AAAA\n 2001:4860:4802:36::15\n AAAA\n 2001:4860:4802:38::15\n CNAME\n ghs.googlehosted.com\n www\n Copy that into your registrar's custom DNS records. Have fun with that.\n\nCloud DNS\nYou may have noticed that we haven't actually specified our Nameservers yet.\nNobody said this was going to be fun; if it were, we probably wouldn't need this\ntutorial. In the GCP search bar, search for Cloud DNS. Create a Zone, and leave\nDNSSEC off.\n\n\n\nBefore we do this next part, I'd like to interject and mention that you did a\nspectacular job of creating all those records and pasting all those values\nearlier. Considering you seem to have a knack for this, it probably won't hurt\nto know that we need to go back into our registrar a third time to paste some\nvalues. You got this. \n\nGoogle's nameservers have now been generated and exposed to you so we can \nactually  point our domain to something meaningful now. You should have 4\nnameservers like the following:\n\nName\n Type\n TTL\n Data\n memegenerator.io.\n NS\n 21600\n ns-cloud-b1.googledomains.com.\n ns-cloud-b2.googledomains.com.\n ns-cloud-b3.googledomains.com.\n ns-cloud-b4.googledomains.com.\n Assign a Static IP\nOkay, we're officially done messing around with our registrar. In the GCP search\nbar, search for External IP addresses.  From there, click the \"Reserve static\nAddress\" button at the top of the screen. This will prompt you with a short\nform: the only important field to fill out here is the \"Attached to\"  dropdown,\nwhich denotes which server instance the IP will be assigned to.\n\nCompute Engine Instance Settings\nShit, is there even more? OK, we're almost done here. Go to your Compute Engine\ninstance you set up earlier. Click \"Edit\". Scroll to the Network Interface \nsection and map the Static IP we created from earlier. Also, go ahead and enter\nyour PTR record:\n\nWhen will it end... please send help.FINAL CHAPTER: Firewall Settings\nLook, I just want to say you're all doing a great job so far. All of you. We're\nall a team here; let's stick together and see this through. Search for Firewall\nRules  and selected Create a Firewall Rule. Name it whatever you want.\n\n * Targets  - This will be where our traffic routes. We want to route to our\n   instance, which is a specified service account.\n * Target service account  - Referring to the above, this is where we select the\n   computer instance we want to hit.\n * Target service account  scope  - Select \"in this project\".\n * Source Filter - Once again, select specified service account.\n * Source service account  scope - Select \"in this project\"\n * Source service account  - This is where we say where the traffic is coming\n   from. It's coming from the App engine, as this is where we specified our DNS.\n * For IPs  and ports, well, do what you want. It's your server. \n\nGet at it\nWell, there you have it. Hopefully by now the domain you've painstaking\nconfigured now points to your server, so you can go ahead and configure your\nwebserver settings or whatever it is you do.\n\nAlright fine, so GCP isn't completely free of its own redundancies. As much as I\nlove to hate on AWS, it seems almost inevitable at this point that any\nenterprise cloud service will maintain a certain level of obscure processes.\nThis is great for flexibility when scaling, but let's be honest: if these\nplatforms were easy to use, who would pay for the certifications?\n\nCheekiness aside, I've become a strong fan of GCP. Google seems to have hit a\nmiddle ground between being user-friendly and powerful, which fills a niché\nwe'll realize was desperately needed. For a fair review of the platform itself,\nI find myself agreeing mostly with this stranger from the internet: \nhttps://www.deps.co/blog/google-cloud-platform-good-bad-ugly/","html":"<p>For the last few weeks I've been enamored with Google's cloud platform, aptly named Google Cloud Platform. GCP contains the things you might expect from a young player in the 'screw AWS' space: much of what exists on AWS has an equivalent on GPC, but certain subtleties exist, such as the lack of Python serverless functions and so forth. That said, GCP makes up for any shortcomings by leveraging services exclusive to Google.</p><p>In my opinion, GCP is the first contender in the market to package enterprise cloud computing in a satisfying way. It's clear GCP has assigned UI and Product Management resources to their platform, where Amazon clearly did not. while not without its shortcomings, it's obvious Google has chosen usability as a key differentiator from AWS.</p><p>Aside from the UI, GCP offers plenty of fun functionality such as their cloud launcher. This is the equivalent of one-click deploys for cool stuff, whether they be services to add to your VPC, Google APIs, Datasets, or what have you. The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-07-14_10-36-02.gif\" class=\"kg-image\"><figcaption>It's like product hunt... on crack.</figcaption></figure><p>The best way to get a feel for what value a product has would be use it, of course. In the interest of becoming familiar with Google Cloud, we'll execute the most basic task of setting up a VPS to deploy code to. This practice will end up touching on many of GCP's core services which will allow us to grasp the basic offerings of the product, as well as its strengths and weakness.</p><h2 id=\"does-in-fact-compute\">Does in Fact Compute </h2><p>GCP cutely names their server's <em>Compute Engines,</em> which are at least more tolerable than, say, EC2 instances. I'm just going to call them servers because I'm not the type of person who orders a \"tall\" at Starbucks.</p><p>Create a \"project\" in Google Cloud, and you'll immediately land at a dashboard. All Google's services are tucked away in the left-hand menu. Open that bad boy up and find Compute Engine.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-07-14_10-44-14.gif\" class=\"kg-image\"><figcaption>Shhh, it's thinking.</figcaption></figure><p>Select <em>create</em>. As opposed to the preset choices of VPCS you might be used to, Google allows us to customize our VPS to our exact technical specifications on a sliding scale. Want 96 processing cores, but only a single GB of RAM? No problem, if that's what you're into. Weirdo.</p><p>As well as picking between the usual Linux distributions, Compute Engine also allows customers to select their number of GPUs, as well as the generation of Intel CPU their instance will run on.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-10.48.02-AM.png\" class=\"kg-image\"><figcaption>Dat customization tho</figcaption></figure><p>We want traffic to hit this instance, so make sure you check <strong>Allow HTTP</strong> <strong>traffic</strong> and <strong>Allow HTTPS traffic</strong> before continuing. Once your instance is created, you should immediately able to SSH into your server via GCP's browser client.</p><h2 id=\"the-app-engine\">The App Engine</h2><p>GCP is not without its own fair share of arbitrary product classifications. DNS records and hosts are contained within the <strong>App Engine</strong> service of the platform. Find the App Engine service in the left hand navigation, and scroll down to the <em>settings</em> link:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-10.58.19-AM.png\" class=\"kg-image\"><figcaption>Allllll the way at the bottom.</figcaption></figure><p>Here's we'll be able to see a \"custom domains\" tab which allows us to point a domain we've purchased from a service like <strong>Namecheap</strong><em> </em>or what-have-you to Google Cloud. I'll personally be walking though this example by directing a pointless domain called <em>memegenerator.io</em> I purchased on Namecheap for no good reason.</p><p>When you add a custom domain via this screen, you'll immediately be asked to verify ownership over the domain via the familiar Google Webmaster tool, which you'll be redirected to automatically.</p><h2 id=\"back-to-your-registrar\">Back to Your Registrar</h2><p>Chances are you've dealt with verification via Google webmaster before, but this time we've only given the option to do this via DNS. Select your registrar in the dropdown in order to reveal a Google-generated record used to verify your domain. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.04.07-AM.png\" class=\"kg-image\"><figcaption>Please don't tell me you use GoDaddy.</figcaption></figure><p>The resulting value will need to be added as a .txt record before we can actually point your domain to Google's servers.</p><p>If you're using Namecheap like I am, log in to your dashboard and find your domain by clicking \"manage domain\". Make sure you're under the \"advanced DNS\" tab:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.08.58-AM.png\" class=\"kg-image\"><figcaption>Even if you're not using Namecheap, this shouldn't be much different.</figcaption></figure><p>Delete all existing records. Then create a TXT record (with @ as the host) and input the value that Google provided you earlier. Now, when you return to the webmaster tool, clicking verify tool <em>should</em> pick up on this change. </p><div class=\"protip\">\nIf the webmaster tool does not pick up on this verification right away, don't panic. This happens fairly often - just frantically keep making sure everything is set up correctly while mashing the verify button.\n</div><p>Navigate back to the Custom Domains tab in GCP and continue the process- you should see that your domain is verified. You'll be prompted to enter any subdomains you'd GCP to pick up on here. Wrap that up and save.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.13.27-AM.png\" class=\"kg-image\"></figure><p></p><h2 id=\"make-it-rain-with-records\">Make it Rain with Records</h2><p>Oh, we're far from over buddy. We need to go back to update our A and AAAA records, now that Google as bestowed that privilege upon us. You should see a table such as the one below:</p><div class=\"tablecontainer\">\n<table>\n  <thead>\n    <tr>\n      <th>Type</th>\n      <th>Data</th>\n      <th>Alias</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>A</td>\n      <td>216.239.32.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.34.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.36.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.38.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:32::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:34::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:36::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:38::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>CNAME</td>\n      <td>ghs.googlehosted.com</td>\n      <td>www</td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Copy that into your registrar's custom DNS records. Have fun with that.</p><h2 id=\"cloud-dns\">Cloud DNS</h2><p>You may have noticed that we haven't actually specified our Nameservers yet. Nobody said this was going to be fun; if it were, we probably wouldn't need this tutorial. In the GCP search bar, search for <em>Cloud DNS</em>. Create a Zone, and leave DNSSEC off.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.25.33-AM.png\" class=\"kg-image\"></figure><p></p><p>Before we do this next part, I'd like to interject and mention that you did a spectacular job of creating all those records and pasting all those values earlier. Considering you seem to have a knack for this, it probably won't hurt to know that we need to go back into our registrar a third time to paste some values. You got this. </p><p>Google's nameservers have now been generated and exposed to you so we can <em>actually</em> point our domain to something meaningful now. You should have 4 nameservers like the following:</p><table>\n  <thead>\n    <tr>\n      <th>Name</th>\n      <th>Type</th>\n      <th>TTL</th>\n      <th>Data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>memegenerator.io.</td>\n      <td>NS</td>\n      <td>21600</td>\n      <td>ns-cloud-b1.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b2.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b3.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b4.googledomains.com.</td>\n    </tr>\n  </tbody>\n</table><h2 id=\"assign-a-static-ip\">Assign a Static IP</h2><p>Okay, we're officially done messing around with our registrar. In the GCP search bar, search for <strong>External IP addresses.</strong> From there, click the \"Reserve static Address\" button at the top of the screen. This will prompt you with a short form: the only important field to fill out here is the <em>\"Attached to\"</em> dropdown, which denotes which server instance the IP will be assigned to.</p><h2 id=\"compute-engine-instance-settings\">Compute Engine Instance Settings</h2><p>Shit, is there even more? OK, we're almost done here. Go to your Compute Engine instance you set up earlier. Click \"Edit\". Scroll to the <em>Network Interface</em> section and map the Static IP we created from earlier. Also, go ahead and enter your PTR record:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.47.24-AM.png\" class=\"kg-image\"><figcaption>When will it end... please send help.</figcaption></figure><h2 id=\"final-chapter-firewall-settings\">FINAL CHAPTER: Firewall Settings</h2><p>Look, I just want to say you're all doing a great job so far. All of you. We're all a team here; let's stick together and see this through. Search for <strong>Firewall Rules</strong> and selected <em>Create a Firewall Rule. </em>Name it whatever you want.</p><ul><li><strong>Targets</strong> - This will be where our traffic routes. We want to route to our instance, which is a <em>specified service account.</em></li><li><strong>Target service account</strong> - Referring to the above, this is where we select the computer instance we want to hit.</li><li><strong>Target service account</strong> <strong>scope</strong> - Select \"in this project\".</li><li><strong>Source Filter </strong>- Once again, select <em>specified service account.</em></li><li><strong>Source service account</strong> <strong>scope </strong>- Select \"in this project\"</li><li><strong>Source service account</strong> - This is where we say where the traffic is coming from. It's coming from the <em>App engine</em>, as this is where we specified our DNS.</li><li>For <strong>IPs</strong> and <strong>ports, </strong>well, do what you want. It's your server. </li></ul><h2 id=\"get-at-it\">Get at it</h2><p>Well, there you have it. Hopefully by now the domain you've painstaking configured now points to your server, so you can go ahead and configure your webserver settings or whatever it is you do.</p><p>Alright fine, so GCP isn't completely free of its own redundancies. As much as I love to hate on AWS, it seems almost inevitable at this point that any enterprise cloud service will maintain a certain level of obscure processes. This is great for flexibility when scaling, but let's be honest: if these platforms were easy to use, who would pay for the certifications?</p><p>Cheekiness aside, I've become a strong fan of GCP. Google seems to have hit a middle ground between being user-friendly and powerful, which fills a niché we'll realize was desperately needed. For a fair review of the platform itself, I find myself agreeing mostly with this stranger from the internet: <a href=\"https://www.deps.co/blog/google-cloud-platform-good-bad-ugly/\">https://www.deps.co/blog/google-cloud-platform-good-bad-ugly/</a></p>","url":"https://hackersandslackers.com/setting-up-dns-with-google-cloud-platform/","uuid":"ed22ae1a-b636-48dd-8502-141ae08fa9d9","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b4a08921c20005e9422c108"}}]}},"pageContext":{"slug":"the-rise-of-google-cloud","limit":12,"skip":0,"numberOfPages":1,"humanPageNumber":1,"prevPageNumber":null,"nextPageNumber":null,"previousPagePath":null,"nextPagePath":null}}