{"data":{"ghostPost":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ea","title":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","slug":"add-db-variables-to-match-new-input-python-pandas","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/apidata@2x.jpg","excerpt":"Python, Pandas, & Functional Programming!","custom_excerpt":"Python, Pandas, & Functional Programming!","created_at_pretty":"22 August, 2018","published_at_pretty":"27 August, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-08-22T18:04:53.000-04:00","published_at":"2018-08-27T07:30:00.000-04:00","updated_at":"2019-02-13T22:48:04.000-05:00","meta_title":"Python, Pandas, & Functional Programming! | Hackers And Slackers","meta_description":"Python, Pandas, & Functional Programming!","og_description":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","og_image":"https://hackersandslackers.com/content/images/2018/08/apidata@2x.jpg","og_title":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","twitter_description":"Python, Pandas, & Functional Programming!","twitter_image":"https://hackersandslackers.com/content/images/2018/08/apidata@2x.jpg","twitter_title":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"}],"plaintext":"APIs.  They're wonderful.  For every headache they've given me, I'm glad I live\nin the age where hitting an API endpoint is a standard way of retrieving data -\nI recently had to crawl a bunch of records from the Brazilian census in 200, and\nthat was an ordeal (but this isn't about that!).\n\nThe thing about APIs is that you generally shouldn't be hitting them all day\nlong - generally you should be doing regular imports to a database (or\nwhatever).  And the other thing about APIs is that they're not quite as fussy\nabout names as databases.  There's nothing stopping you from having the first\nrow of your API's output include field names like \"Account Canceled?\", which a\ntypical SQL RDBMS will not care for one bit.\n\nHow do we translate them?  Well, simple enough - we just have to think of\neverything that might be in our input string that won't be allowed in our\ndatabase, and change that!  I'm going to use the pipe  function from my beloved \ntoolz  library, provider of Functional Programming goodies for Python.\n\nfrom toolz import pipe\nimport string\n\ndef dbReady(toConvert):\n    return pipe(toConvert,\n                lambda x: x.lower(),\n                lambda x: filter(lambda y: \n                                y in string.ascii_lowercase + \" \",\n                                x),\n                lambda x: \"\".join(x),\n                lambda x: x.split(),\n                lambda x: \"_\".join(x))\n\n\n 1. We made it lowercase.\n 2. We filtered everything that wasn't a lowercase letter or a space.\n 3. We joined the filter back into a string.\n 4. We split the resulting string (in case we wound up with any double spaces,\n    such as from deleting a &.\n 5. We joined the list of strings with underscores.\n\ndbReady(\"Account Canceled?\")\n'account_canceled'\n\n\nFor comparison's sake, here's what that same function looks like without pipe\n\ndef dbReady(toConvert):\n    return '_'.join(\n               \"\".join(\n                   filter(lambda x:\n                          x in string.ascii_lowercase + \" \",\n                          (toConvert\n                           .lower()))\n                   ).split())\n\n\nBut wait!  There's more!\n\nWhat if your API changes?  Oh no, that could break your import!\n\nWell, if you don't care about the new columns, you could just filter them out.\n Let's say we have a list of lists called latestResponse  that came from a\nrequest to our API, with the first row as the labels.\n\nimport pymysql\nfrom sqlalchemy import create_engine\nimport sqlalchemy\nimport pandas as pd\n\nlatestCols = latestResponse[0]\n\n#Change to what they'll be in the database\ndbReadies = [dbReady(x) for x in latestCols] \n\n#Grab the columns currently in the database\ncnx = create_engine('mysql+pymysql://root:cracked1@localhost/appointments', echo=False)\ndbCols = pd.io.sql.read_sql_table(\"appointments_tableau\", \n                                  cnx).columns\n\n#Make a dataframe with what the columns would be named in a database\ndf = pd.DataFrame(latestResponse[1:], columns = dbReady)\n\n#Only select the columns that are currently in the db, and upload\ndf[dbCols].to_sql(name=\"my_table\",\n                  con=cnx, \n                  if_exists='append')\n\n\n\nBut what if you DO want the new columns from now on?  But you're already in the\nzone, don't feel like manually searching for which columns are new, and opening\na new terminal window to add the new variables?  What if you are, in a word,\nlazy?  And what if it's sorta important to preserve the order of the fields, and\nthe new ones are in the middle?\n\nNever fear!\n\nFirst, let's cook up a little function to produce an SQL ALTER TABLE  statement\n(standard disclaimers apply: do NOT do this blindly, or automatically).  Oh, and\nfor our purposes let's say these new columns all have the same type ( \nVARCHAR(255)), because if that's not the case then we have to be slightly less\nlazy. \n\ndef alterStatement(existingCol, newCol):\n    return (f\"ALTER TABLE appointments_tableau \"\n            f\"ADD COLUMN {newCol} VARCHAR(255) AFTER {existingCol};\")\n\n\nLet's use the wonderful sliding_window  function from toolz  to feed us a bunch\nof column names. \n\nExample from the official docs:\n\nlist(sliding_window(2, [1, 2, 3, 4]))\n[(1, 2), (2, 3), (3, 4)]\n\n\nBack to the show!\n\nfrom toolz.itertoolz import sliding_window\n\n#Get the variables that aren't currently in the db\nnewVars = [x for x in dbReadies if x not in dbCols]\n\n#Get a list where each entry is a tuple that has every new variable, and the existing preceding one\ntuples = list(sliding_window(2, dbReadies))\nnewVarTups = [x for x in tuples if x[1] in newVars]\n\n\nAnd, finally, let's set up our statements, and have Pandas execute them!  I know\nI promised I was going to start using SQLAlchemy for this kind of thing instead\nof unsanitized raw SQL, but I'm back on my bullshit again.\n\nfor x in newVarTups:\n    pd.io.sql.execute(alterStatement(*x), cnx)","html":"<p>APIs.  They're wonderful.  For every headache they've given me, I'm glad I live in the age where hitting an API endpoint is a standard way of retrieving data - I recently had to crawl a bunch of records from the Brazilian census in 200, and that was an ordeal (but this isn't about that!).</p><p>The thing about APIs is that you generally shouldn't be hitting them all day long - generally you should be doing regular imports to a database (or whatever).  And the other thing about APIs is that they're not quite as fussy about names as databases.  There's nothing stopping you from having the first row of your API's output include field names like \"Account Canceled?\", which a typical SQL RDBMS will not care for one bit.</p><p>How do we translate them?  Well, simple enough - we just have to think of everything that might be in our input string that won't be allowed in our database, and change that!  I'm going to use the <code>pipe</code> function from my beloved <code>toolz</code> library, provider of Functional Programming goodies for Python.</p><pre><code class=\"language-python\">from toolz import pipe\nimport string\n\ndef dbReady(toConvert):\n    return pipe(toConvert,\n                lambda x: x.lower(),\n                lambda x: filter(lambda y: \n                                y in string.ascii_lowercase + &quot; &quot;,\n                                x),\n                lambda x: &quot;&quot;.join(x),\n                lambda x: x.split(),\n                lambda x: &quot;_&quot;.join(x))\n</code></pre>\n<ol><li>We made it lowercase.</li><li>We filtered everything that wasn't a lowercase letter or a space.</li><li>We joined the filter back into a string.</li><li>We split the resulting string (in case we wound up with any double spaces, such as from deleting a <code>&amp;</code>.</li><li>We joined the list of strings with underscores.</li></ol><pre><code class=\"language-python\">dbReady(&quot;Account Canceled?&quot;)\n'account_canceled'\n</code></pre>\n<p>For comparison's sake, here's what that same function looks like without <code>pipe</code></p><pre><code class=\"language-python\">def dbReady(toConvert):\n    return '_'.join(\n               &quot;&quot;.join(\n                   filter(lambda x:\n                          x in string.ascii_lowercase + &quot; &quot;,\n                          (toConvert\n                           .lower()))\n                   ).split())\n</code></pre>\n<p>But wait!  There's more!</p><p>What if your API changes?  Oh no, that could break your import!</p><p>Well, if you don't care about the new columns, you could just filter them out.  Let's say we have a list of lists called <code>latestResponse</code> that came from a request to our API, with the first row as the labels.</p><pre><code class=\"language-python\">import pymysql\nfrom sqlalchemy import create_engine\nimport sqlalchemy\nimport pandas as pd\n\nlatestCols = latestResponse[0]\n\n#Change to what they'll be in the database\ndbReadies = [dbReady(x) for x in latestCols] \n\n#Grab the columns currently in the database\ncnx = create_engine('mysql+pymysql://root:cracked1@localhost/appointments', echo=False)\ndbCols = pd.io.sql.read_sql_table(&quot;appointments_tableau&quot;, \n                                  cnx).columns\n\n#Make a dataframe with what the columns would be named in a database\ndf = pd.DataFrame(latestResponse[1:], columns = dbReady)\n\n#Only select the columns that are currently in the db, and upload\ndf[dbCols].to_sql(name=&quot;my_table&quot;,\n                  con=cnx, \n                  if_exists='append')\n\n</code></pre>\n<p>But what if you DO want the new columns from now on?  But you're already in the zone, don't feel like manually searching for which columns are new, and opening a new terminal window to add the new variables?  What if you are, in a word, lazy?  And what if it's sorta important to preserve the order of the fields, and the new ones are in the middle?  </p><p>Never fear!</p><p>First, let's cook up a little function to produce an SQL <code>ALTER TABLE</code> statement (standard disclaimers apply: do NOT do this blindly, or automatically).  Oh, and for our purposes let's say these new columns all have the same type ( <code>VARCHAR(255)</code>), because if that's not the case then we have to be slightly less lazy. </p><pre><code class=\"language-python\">def alterStatement(existingCol, newCol):\n    return (f&quot;ALTER TABLE appointments_tableau &quot;\n            f&quot;ADD COLUMN {newCol} VARCHAR(255) AFTER {existingCol};&quot;)\n</code></pre>\n<p>Let's use the wonderful <code>sliding_window</code> function from <code>toolz</code> to feed us a bunch of column names. </p><p>Example from the <a href=\"https://toolz.readthedocs.io/en/latest/api.html#toolz.itertoolz.sliding_window\">official docs</a>:</p><pre><code class=\"language-python\">list(sliding_window(2, [1, 2, 3, 4]))\n[(1, 2), (2, 3), (3, 4)]\n</code></pre>\n<p>Back to the show!</p><pre><code class=\"language-python\">from toolz.itertoolz import sliding_window\n\n#Get the variables that aren't currently in the db\nnewVars = [x for x in dbReadies if x not in dbCols]\n\n#Get a list where each entry is a tuple that has every new variable, and the existing preceding one\ntuples = list(sliding_window(2, dbReadies))\nnewVarTups = [x for x in tuples if x[1] in newVars]\n</code></pre>\n<p>And, finally, let's set up our statements, and have Pandas execute them!  I know I promised I was going to start using SQLAlchemy for this kind of thing instead of unsanitized raw SQL, but I'm back on my bullshit again.</p><pre><code class=\"language-python\">for x in newVarTups:\n    pd.io.sql.execute(alterStatement(*x), cnx)\n</code></pre>\n","url":"https://hackersandslackers.com/add-db-variables-to-match-new-input-python-pandas/","uuid":"8c2a6558-0216-46bc-aaef-ef2ab08342a3","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b7dde05a2743b50f2e9edeb"}},"pageContext":{"slug":"add-db-variables-to-match-new-input-python-pandas"}}