{"data":{"ghostPost":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c4","title":"All That Is Solid Melts Into Graphs","slug":"all-that-is-solid-melts-into-graphs","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/iceberg@2x.jpg","excerpt":"Reshaping Pandas dataframes with a real-life example, and graphing it with Altair.","custom_excerpt":"Reshaping Pandas dataframes with a real-life example, and graphing it with Altair.","created_at_pretty":"26 July, 2018","published_at_pretty":"30 July, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-07-25T21:53:23.000-04:00","published_at":"2018-07-30T07:30:00.000-04:00","updated_at":"2019-02-02T04:07:03.000-05:00","meta_title":"All That Is Solid Melts Into Graphs | Hackers and Slackers","meta_description":"Reshaping Pandas dataframes with a real-life example, and graphing it with Altair","og_description":"Reshaping Pandas dataframes with a real-life example, and graphing it with #Altair","og_image":"https://hackersandslackers.com/content/images/2018/07/iceberg@2x.jpg","og_title":"All That Is Solid Melts Into Graphs","twitter_description":"Reshaping Pandas dataframes with a real-life example, and graphing it with #Altair","twitter_image":"https://hackersandslackers.com/content/images/2018/07/iceberg@2x.jpg","twitter_title":"All That Is Solid Melts Into Graphs","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},{"name":"#Code Snippet Corner","slug":"code-snippet-corner","description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o_o.jpg","meta_description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","meta_title":"Python Code Snippet Corner","visibility":"internal"}],"plaintext":"Last few Code Snippet Corners were about using Pandas as an easy way to handle\ninput and output between files & databases.  Let's shift gears a little bit!\n Among other reasons, because earlier today I discovered a package that\nexclusively does that, which means I can stop importing the massive Pandas\npackage when all I really wanted to do with it was take advantage of its I/O\nmodules.Check it out [https://github.com/insightindustry/sqlathanor]! \n\nSo, rather than the entrances & exits, let's focus on all the crazy ways you can\nreshape data with Pandas!\n\nOur Data\nFor our demonstration, I'll use a dataset based on something I was once actually\nsent.  It was a big CSV with sensor readings from HVAC systems.  Each line had a\ndifferent house, a different room, a datetime, and readings from a bunch of\ndifferent types of sensors.  Oh, hrm, I probably shouldn't use data I got from a\nclient.  Uh...\n\nBONUS SECTION!\nGENERATING DUMMY TEMPERATURE DATA\n(Feel free to skip to next part if you don't care)\n\nWe want it to fluctuate, but we don't want to just make a bunch of totally\nrandom values - a reading should have some relationship to the reading taken a\nsecond earlier.\n\nLet's use NumPy  for some Randomness, and the accumulate  and repeat  functions\nfrom itertools.  Maybe I'll do an in-depth post on these at some point, but the\ncode I'll be writing with them will be pretty short and hopefully somewhat\nself-demonstrating.  If you wanna go deeper here's some good material: Official\nDocs [https://docs.python.org/3/library/itertools.html], Good article\n[https://realpython.com/python-itertools/]\n\nimport numpy as np\nfrom itertools import accumulate, repeat\n\n\nWe want there to be some random \"noise\", but we also want the occasional\nsubstantive change.  We'll reflect this by having it so that 90% of the time we\nget a small fluctuation, with a 10% chance of a smaller fluctuation. \n\ndef genTempDataPoint(x, *args):\n    if np.random.rand(1) <= 0.9:\n        return x + np.random.uniform(-3,3,1)[0]\n    else:\n        return x + np.random.uniform(-10,10,1)[0]\n\n\n  Now let's see some test points!\n\nlist(accumulate(repeat(70, 5), genTempDataPoint))\n[70,\n 69.00258239202094,\n 59.34919781643355,\n 56.60722073795931,\n 57.265078261782946]\n\n\nSure, fine, why not.  Good enough for our purposes!   Now let's put it all\ntogether so we can just call it with a base temp and the number of points we\nwant.\n\ndef genTempData(base, n):\n    return list(accumulate(repeat(base, n), \n                           genTempDataPoint))\n\n\nTo simulate the dataset, we actually need to mix it up.  Or else what good are\nthe GroupBys gonna be?  So, let's create a problem to fix later!  Here's a\nfunction to create a simplified version of the dataset - each row will have a\nlocation ID, a number corresponding to time (just raw ints, I'm not making\nactual datetimes - I've spent too much time on this part already).  We'll also\ngenerate humidity values, to add another monkey wrench to fix later (we'll still\nuse the genTempData  function).\n\nfrom itertools import chain\n\ndef makeLocation(name, base1, n1, base2, n2):\n    return [(x[0], name, x[1][0], x[1][1]) \n        for x in enumerate(zip(genTempData(base1, n1),\n              genTempData(base2, n2)) )]\n\nbigList = list(chain.from_iterable(makeLocation(str(x), \n                                                70, \n                                                15,\n                                                40, \n                                                15) \n                         for x in range(5)))\nnp.random.shuffle(bigList)\n\ndf = pd.DataFrame(bigList, \n                  columns = [\"Time\", \"Loc\", \"Temp\", \"Hum\"])\n\n\nBack To The Main Plot\nLet's look at some test rows!\n\n# Viewing test rows\n\ndf.iloc[:5]\nTime\tLoc\tTemp     \tHum\n10\t4\t68.396970\t34.169753\n13\t0\t80.288846\t42.076786\n7\t4\t69.923273\t37.967951\n6\t0\t71.781362\t41.186802\n5\t2\t62.678844\t37.321636\n\n\nNow, when I'm getting started with a new dataset, one of the first things I like\nto do is make some graphs.  As of late, my favorite package has been Altair\n[https://altair-viz.github.io/].  Looks very nice by default, is pretty easy to\niterate with, and has nice declarative syntax.\n\nOnly one problem!  It wants date in \"long-form\" - as in, rather than each row\nhaving several variables of interest, each row has one (or more) \"ID\" variables,\none numerical value, and the name of the variable we're measuring.  So for\ninstance, something more like this:\n\nTime\tLoc\tvariable\tvalue\n10\t4\tTemp\t        68.396970\n13\t0\tTemp\t        80.288846\n7\t4\tTemp\t        69.923273\n6\t0\tTemp\t        71.781362\n5\t2\tTemp\t        62.678844\n\n\nNot quite sure why!  Buuut, that's kind of a feature of modern coding - we're\nsitting on an inheritance of libraries that have built up over the years, and so\nmore often than not we're just building the \"plumbing\" between existing stuff.\n It's cool!  And good!  It lets us separate Function from Implementation.  We\ndon't need to know what's going on under the hood - we just need to know thing X\nwill produce an output we want, and that in order to get it we first need to\nreshape what we've already got into an input that it'll accept.  Since that's\nsuch a huge part of coding these days, Pandas' power in that realm is super\nuseful.\n\nSooo, how do we get from here to there?  Shockingly easily!\n\nmelted = pd.melt(df, id_vars=[\"Time\", \"Loc\"])\n\n\nDone!\n\nWell, obviously we're not REALLY done yet.  Half the point of having such terse,\nexpressive code is that we can do MORE things!\n\nLet's say we want to see how humidity & temperature change over the course of\nthe day.  First, we'll have to grab all the readings from a single location.\n Let's say Location 3!\n\nloc3 = melted[melted[\"Loc\"]==\"3\"]\n\n\nAltair's pretty neat.\n\n(alt.Chart(loc3)\n .mark_line()\n .encode(x='Time:O', #We're encoding time as an Ordinal \n         y='value:Q',\n         color='variable:N'))\n\n\nHrm, lot of room there at the bottom.  If we were in an interactive session, we\ncould make this interactive (zoomable and navigable!) by just adding the \n.interactive()  method to the end, but I don't know how to do that in the blog.\n Regardless, it's pretty easy to rescale if we want a closer look!\n\n(alt.Chart(loc3)\n .mark_line()\n .encode(x='Time:O',\n         y=alt.Y('value:Q', scale=alt.Scale(zero=False)),\n         color='variable:N'))\n\n\nLet's try it with just temperature, and color will encode the location!\n\nmeltedJustTemp = pd.melt(df, \n                         id_vars=[\"Time\", \"Loc\"],\n                        value_vars= [\"Temp\"])\n\n(alt.Chart(meltedJustTemp)\n .mark_line()\n .encode(x='Time:O',\n         y='value:Q',\n         color='Loc:N'))\n\n\nLet's zoom in again...\n\n(alt.Chart(meltedJustTemp)\n .mark_line()\n .encode(x='Time:O',\n         y=alt.Y('value:Q', scale=alt.Scale(zero=False)),\n         color='Loc:N'))\n\n\nAltair also lets us Facet our graphs extremely flexibly & painlessly.\n\nalt.Chart(melted).mark_line().encode(\n      x='Time:O',\n      y=alt.Y('value:Q', scale=alt.Scale(zero=False)),\n      color='Loc:N',\n      column=\"variable\")\n\n\nOr how about another way!  Let's see humidity & temp, location by location.\n\nalt.Chart(melted).mark_line().encode(\n      x='Time:O',\n      y=alt.Y('value:Q', scale=alt.Scale(zero=False)),\n      color='variable:N',\n      row=\"Loc\")\n\n\nWe could make them nicer (there's a WIDE array of customizations), but I'm\nlooking to simulate Exploratory Data Analysis.  I can't think of another\ngraphing package in Python that has quite this level of \"instant gratification\"\nfor so many different variations.","html":"<p>Last few Code Snippet Corners were about using Pandas as an easy way to handle input and output between files &amp; databases.  Let's shift gears a little bit!  Among other reasons, because earlier today I discovered a package that exclusively does that, which means I can stop importing the massive Pandas package when all I really wanted to do with it was take advantage of its I/O modules.  <a href=\"https://github.com/insightindustry/sqlathanor\">Check it out</a>! </p><p>So, rather than the entrances &amp; exits, let's focus on all the crazy ways you can reshape data with Pandas!</p><h2 id=\"our-data\">Our Data</h2><p>For our demonstration, I'll use a dataset based on something I was once actually sent.  It was a big CSV with sensor readings from HVAC systems.  Each line had a different house, a different room, a datetime, and readings from a bunch of different types of sensors.  Oh, hrm, I probably shouldn't use data I got from a client.  Uh...</p><h2 id=\"bonus-section-\">BONUS SECTION!</h2><h3 id=\"generating-dummy-temperature-data\">GENERATING DUMMY TEMPERATURE DATA</h3><p><strong>(Feel free to skip to next part if you don't care)</strong></p><p>We want it to fluctuate, but we don't want to just make a bunch of totally random values - a reading should have some relationship to the reading taken a second earlier.</p><p>Let's use <code>NumPy</code> for some Randomness, and the <code>accumulate</code> and <code>repeat</code> functions from <code>itertools</code>.  Maybe I'll do an in-depth post on these at some point, but the code I'll be writing with them will be pretty short and hopefully somewhat self-demonstrating.  If you wanna go deeper here's some good material: <a href=\"https://docs.python.org/3/library/itertools.html\">Official Docs</a>, <a href=\"https://realpython.com/python-itertools/\">Good article</a></p><pre><code class=\"language-python\">import numpy as np\nfrom itertools import accumulate, repeat\n</code></pre>\n<p>We want there to be some random \"noise\", but we also want the occasional substantive change.  We'll reflect this by having it so that 90% of the time we get a small fluctuation, with a 10% chance of a smaller fluctuation. </p><pre><code class=\"language-python\">def genTempDataPoint(x, *args):\n    if np.random.rand(1) &lt;= 0.9:\n        return x + np.random.uniform(-3,3,1)[0]\n    else:\n        return x + np.random.uniform(-10,10,1)[0]\n</code></pre>\n<p> Now let's see some test points!</p><pre><code class=\"language-python\">list(accumulate(repeat(70, 5), genTempDataPoint))\n[70,\n 69.00258239202094,\n 59.34919781643355,\n 56.60722073795931,\n 57.265078261782946]\n</code></pre>\n<p>Sure, fine, why not.  Good enough for our purposes!   Now let's put it all together so we can just call it with a base temp and the number of points we want.</p><pre><code class=\"language-python\">def genTempData(base, n):\n    return list(accumulate(repeat(base, n), \n                           genTempDataPoint))\n</code></pre>\n<p>To simulate the dataset, we actually need to mix it up.  Or else what good are the GroupBys gonna be?  So, let's create a problem to fix later!  Here's a function to create a simplified version of the dataset - each row will have a location ID, a number corresponding to time (just raw ints, I'm not making actual datetimes - I've spent too much time on this part already).  We'll also generate humidity values, to add another monkey wrench to fix later (we'll still use the <code>genTempData</code> function).</p><pre><code class=\"language-python\">from itertools import chain\n\ndef makeLocation(name, base1, n1, base2, n2):\n    return [(x[0], name, x[1][0], x[1][1]) \n        for x in enumerate(zip(genTempData(base1, n1),\n              genTempData(base2, n2)) )]\n\nbigList = list(chain.from_iterable(makeLocation(str(x), \n                                                70, \n                                                15,\n                                                40, \n                                                15) \n                         for x in range(5)))\nnp.random.shuffle(bigList)\n\ndf = pd.DataFrame(bigList, \n                  columns = [&quot;Time&quot;, &quot;Loc&quot;, &quot;Temp&quot;, &quot;Hum&quot;])\n</code></pre>\n<h2 id=\"back-to-the-main-plot\">Back To The Main Plot</h2><p>Let's look at some test rows!</p><pre><code class=\"language-python\"># Viewing test rows\n\ndf.iloc[:5]\nTime\tLoc\tTemp     \tHum\n10\t4\t68.396970\t34.169753\n13\t0\t80.288846\t42.076786\n7\t4\t69.923273\t37.967951\n6\t0\t71.781362\t41.186802\n5\t2\t62.678844\t37.321636\n</code></pre>\n<p>Now, when I'm getting started with a new dataset, one of the first things I like to do is make some graphs.  As of late, my favorite package has been <a href=\"https://altair-viz.github.io/\">Altair</a>.  Looks very nice by default, is pretty easy to iterate with, and has nice declarative syntax.</p><p>Only one problem!  It wants date in \"long-form\" - as in, rather than each row having several variables of interest, each row has one (or more) \"ID\" variables, one numerical value, and the name of the variable we're measuring.  So for instance, something more like this:</p><pre><code class=\"language-python\">Time\tLoc\tvariable\tvalue\n10\t4\tTemp\t        68.396970\n13\t0\tTemp\t        80.288846\n7\t4\tTemp\t        69.923273\n6\t0\tTemp\t        71.781362\n5\t2\tTemp\t        62.678844\n</code></pre>\n<p>Not quite sure why!  Buuut, that's kind of a feature of modern coding - we're sitting on an inheritance of libraries that have built up over the years, and so more often than not we're just building the \"plumbing\" between existing stuff.  It's cool!  And good!  It lets us separate Function from Implementation.  We don't need to know what's going on under the hood - we just need to know thing X will produce an output we want, and that in order to get it we first need to reshape what we've already got into an input that it'll accept.  Since that's such a huge part of coding these days, Pandas' power in that realm is super useful.</p><p>Sooo, how do we get from here to there?  Shockingly easily!</p><pre><code class=\"language-python\">melted = pd.melt(df, id_vars=[&quot;Time&quot;, &quot;Loc&quot;])\n</code></pre>\n<p>Done!</p><p>Well, obviously we're not REALLY done yet.  Half the point of having such terse, expressive code is that we can do MORE things!</p><p>Let's say we want to see how humidity &amp; temperature change over the course of the day.  First, we'll have to grab all the readings from a single location.  Let's say Location 3!</p><pre><code class=\"language-python\">loc3 = melted[melted[&quot;Loc&quot;]==&quot;3&quot;]\n</code></pre>\n<p>Altair's pretty neat.</p><pre><code class=\"language-python\">(alt.Chart(loc3)\n .mark_line()\n .encode(x='Time:O', #We're encoding time as an Ordinal \n         y='value:Q',\n         color='variable:N'))\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/visualization--2--1.png\" class=\"kg-image\"></figure><p>Hrm, lot of room there at the bottom.  If we were in an interactive session, we could make this interactive (zoomable and navigable!) by just adding the <code>.interactive()</code> method to the end, but I don't know how to do that in the blog.  Regardless, it's pretty easy to rescale if we want a closer look!</p><pre><code class=\"language-python\">(alt.Chart(loc3)\n .mark_line()\n .encode(x='Time:O',\n         y=alt.Y('value:Q', scale=alt.Scale(zero=False)),\n         color='variable:N'))\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/visualization--3--2.png\" class=\"kg-image\"></figure><p>Let's try it with just temperature, and color will encode the location!</p><pre><code class=\"language-python\">meltedJustTemp = pd.melt(df, \n                         id_vars=[&quot;Time&quot;, &quot;Loc&quot;],\n                        value_vars= [&quot;Temp&quot;])\n\n(alt.Chart(meltedJustTemp)\n .mark_line()\n .encode(x='Time:O',\n         y='value:Q',\n         color='Loc:N'))\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/visualization--4--2.png\" class=\"kg-image\"></figure><p>Let's zoom in again...</p><pre><code class=\"language-python\">(alt.Chart(meltedJustTemp)\n .mark_line()\n .encode(x='Time:O',\n         y=alt.Y('value:Q', scale=alt.Scale(zero=False)),\n         color='Loc:N'))\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/visualization--4--2.png\" class=\"kg-image\"></figure><p>Altair also lets us Facet our graphs extremely flexibly &amp; painlessly.</p><pre><code class=\"language-python\">alt.Chart(melted).mark_line().encode(\n      x='Time:O',\n      y=alt.Y('value:Q', scale=alt.Scale(zero=False)),\n      color='Loc:N',\n      column=&quot;variable&quot;)\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/visualization--5--1.png\" class=\"kg-image\"></figure><p>Or how about another way!  Let's see humidity &amp; temp, location by location.</p><pre><code class=\"language-python\">alt.Chart(melted).mark_line().encode(\n      x='Time:O',\n      y=alt.Y('value:Q', scale=alt.Scale(zero=False)),\n      color='variable:N',\n      row=&quot;Loc&quot;)\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/visualization--6--1.png\" class=\"kg-image\"></figure><p>We could make them nicer (there's a WIDE array of customizations), but I'm looking to simulate Exploratory Data Analysis.  I can't think of another graphing package in Python that has quite this level of \"instant gratification\" for so many different variations.</p>","url":"https://hackersandslackers.com/all-that-is-solid-melts-into-graphs/","uuid":"603156b0-ee55-4aaa-b5cd-34950389cd08","page":false,"codeinjection_foot":"<script>\n    hljs.configure({language: ['python']})\n </script>","codeinjection_head":"","comment_id":"5b5929932714bc41b8a370c5"}},"pageContext":{"slug":"all-that-is-solid-melts-into-graphs"}}