{"data":{"ghostPost":{"id":"Ghost__Post__5c95e08ef654036aa06c6a02","title":"Building an ETL Pipeline: From JIRA to SQL","slug":"building-an-etl-pipeline-from-jira-to-postgresql","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/jira-etl-3-3.jpg","excerpt":"An example data pipeline which extracts data from the JIRA Cloud API and loads it to a SQL database.","custom_excerpt":"An example data pipeline which extracts data from the JIRA Cloud API and loads it to a SQL database.","created_at_pretty":"23 March, 2019","published_at_pretty":"28 March, 2019","updated_at_pretty":"09 April, 2019","created_at":"2019-03-23T03:30:22.000-04:00","published_at":"2019-03-28T04:15:00.000-04:00","updated_at":"2019-04-08T23:34:47.000-04:00","meta_title":"Building an ETL Pipeline: From JIRA to SQL | Hackers and Slackers","meta_description":"How to build and structure a data pipeline. This example takes issue data extracted from the JIRA Cloud API, transforms it, and loads it to a SQL database.","og_description":"How to build and structure a data pipeline. This example takes issue data extracted from the JIRA Cloud API, transforms it, and loads it to a SQL database.","og_image":"https://hackersandslackers.com/content/images/2019/03/jira-etl-3-2.jpg","og_title":"Building an ETL Pipeline: From JIRA to SQL","twitter_description":"How to build and structure a data pipeline. This example takes issue data extracted from the JIRA Cloud API, transforms it, and loads it to a SQL database.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/jira-etl-3-1.jpg","twitter_title":"Building an ETL Pipeline: From JIRA to SQL","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"}],"plaintext":"Something we haven't done just yet on this site is walking through the humble\nprocess of creating data pipelines: the art of taking a bunch of data, changing\nsaid data, and putting it somewhere else. It's kind of a weird thing to be into,\nhence why the MoMA has been rejecting my submissions of Github repositories.\nDon't worry; I'll keep at it.\n\nSomething you don't see every day are people sharing their pipelines, which is\nunderstandable. Presumably, the other people who do this kind of stuff do it for\nwork; nobody is happily building stupid pipelines in their free time begging to\nbe open sourced. Except me.\n\nWe've recently revamped our projects [https://hackersandslackers.com/projects/] \npage to include a public-facing Kanban board using GraphQL. To achieve this, we\nneed to extract JIRA data from the JIRA Cloud REST API and place it securely in\nour database.\n\nStructuring our Pipeline\nAn ETL pipeline which is considered 'well-structured' is in the eyes of the\nbeholder. There are a million different ways to pull and mess with data, so\nthere isn't a \"template\" for building these things out. In my case, the\nstructure of my script just so happened to end up as three modules: one for \nextracting, one for loading, and one for transforming. This was unplanned, but\nit's a good sign when our app matches our mindset. Here's the breakdown:\n\njira-database-etl\n├── __main__.py\n├── jira_etl\n│   ├── __init__.py\n│   ├── fetch.py\n│   ├── data.py\n│   └── db.py\n├── LICENSE\n├── MANIFEST.in\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── requirements.txt\n├── setup.cfg\n└── setup.py\n\n\nmain.py  is our application entry point. The logic of our pipeline is stored in\nthree parts under the jira_etl  directory:\n\n * fetch.py  grabs the data from the source (JIRA Cloud's REST API) and handles\n   fetching all JIRA issues.\n * data.py  transforms the data we've fetched and constructs a neat DataFrame\n   containing only the information we're after.\n * db.py  finally loads the data into a SQL database.\n\nDon't look into it too much, but here's our entry point:\n\nfrom jira_etl import fetch\nfrom jira_etl import data\nfrom jira_etl import db\n\n\ndef main():\n    \"\"\"Application Entry Point.\n\n    1. Fetch all desired JIRA issues from an instance's REST API.\n    2. Sanitize the data and add secondary metadata.\n    3. Upload resulting DataFrame to database.\n    \"\"\"\n    jira_issues_json = fetch.FetchJiraIssues.fetch_all_results()\n    jira_issues_df = data.TransformData.construct_dataframe(jira_issues_json)\n    upload_status = db.DatabaseImport.upload_dataframe(jira_issues_df)\n    return upload_status\n\n\nWithout further adieu, let's dig into the logic!\n\nExtracting Our Data\nBefore doing anything, it's essential we become familiar with the data we're\nabout to pull. Firstly, JIRA's REST API returns paginated results which max out\nat 100 results per page. This means we'll have to loop through the pages\nrecursively until all results are loaded.\n\nNext, let's look at an example of a single  JIRA issue JSON object returned by\nthe API:\n\n{\n    \"expand\": \"names,schema\",\n    \"startAt\": 0,\n    \"maxResults\": 1,\n    \"total\": 888,\n    \"issues\": [\n        {\n            \"expand\": \"operations,versionedRepresentations,editmeta,changelog,renderedFields\",\n            \"id\": \"11718\",\n            \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/issue/11718\",\n            \"key\": \"HACK-756\",\n            \"fields\": {\n                \"issuetype\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/issuetype/10014\",\n                    \"id\": \"10014\",\n                    \"description\": \"Placeholder item for \\\"holy shit this is going to be a lot of work\\\"\",\n                    \"iconUrl\": \"https://hackersandslackers.atlassian.net/secure/viewavatar?size=xsmall&avatarId=10311&avatarType=issuetype\",\n                    \"name\": \"Major Functionality\",\n                    \"subtask\": false,\n                    \"avatarId\": 10311\n                },\n                \"customfield_10070\": null,\n                \"customfield_10071\": null,\n                \"customfield_10073\": null,\n                \"customfield_10074\": null,\n                \"customfield_10075\": null,\n                \"project\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/project/10015\",\n                    \"id\": \"10015\",\n                    \"key\": \"HACK\",\n                    \"name\": \"Hackers and Slackers\",\n                    \"projectTypeKey\": \"software\",\n                    \"avatarUrls\": {\n                        \"48x48\": \"https://hackersandslackers.atlassian.net/secure/projectavatar?pid=10015&avatarId=10535\",\n                        \"24x24\": \"https://hackersandslackers.atlassian.net/secure/projectavatar?size=small&pid=10015&avatarId=10535\",\n                        \"16x16\": \"https://hackersandslackers.atlassian.net/secure/projectavatar?size=xsmall&pid=10015&avatarId=10535\",\n                        \"32x32\": \"https://hackersandslackers.atlassian.net/secure/projectavatar?size=medium&pid=10015&avatarId=10535\"\n                    }\n                },\n                \"fixVersions\": [],\n                \"resolution\": null,\n                \"resolutiondate\": null,\n                \"workratio\": -1,\n                \"lastViewed\": \"2019-03-24T02:01:31.355-0400\",\n                \"watches\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/issue/HACK-756/watchers\",\n                    \"watchCount\": 1,\n                    \"isWatching\": true\n                },\n                \"created\": \"2019-02-03T00:47:36.677-0500\",\n                \"customfield_10062\": null,\n                \"customfield_10063\": null,\n                \"customfield_10064\": null,\n                \"customfield_10065\": null,\n                \"customfield_10066\": null,\n                \"priority\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/priority/2\",\n                    \"iconUrl\": \"https://hackersandslackers.atlassian.net/images/icons/priorities/high.svg\",\n                    \"name\": \"High\",\n                    \"id\": \"2\"\n                },\n                \"customfield_10067\": null,\n                \"customfield_10068\": null,\n                \"customfield_10069\": [],\n                \"labels\": [],\n                \"versions\": [],\n                \"issuelinks\": [],\n                \"assignee\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"name\": \"bro\",\n                    \"key\": \"admin\",\n                    \"accountId\": \"557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"emailAddress\": \"toddbirchard@gmail.com\",\n                    \"avatarUrls\": {\n                        \"48x48\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue\",\n                        \"24x24\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue\",\n                        \"16x16\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue\",\n                        \"32x32\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue\"\n                    },\n                    \"displayName\": \"Todd Birchard\",\n                    \"active\": true,\n                    \"timeZone\": \"America/New_York\",\n                    \"accountType\": \"atlassian\"\n                },\n                \"updated\": \"2019-03-24T02:01:30.724-0400\",\n                \"status\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/status/10004\",\n                    \"description\": \"\",\n                    \"iconUrl\": \"https://hackersandslackers.atlassian.net/\",\n                    \"name\": \"To Do\",\n                    \"id\": \"10004\",\n                    \"statusCategory\": {\n                        \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/statuscategory/2\",\n                        \"id\": 2,\n                        \"key\": \"new\",\n                        \"colorName\": \"blue-gray\",\n                        \"name\": \"To Do\"\n                    }\n                },\n                \"components\": [],\n                \"description\": {\n                    \"version\": 1,\n                    \"type\": \"doc\",\n                    \"content\": [\n                        {\n                            \"type\": \"paragraph\",\n                            \"content\": [\n                                {\n                                    \"type\": \"text\",\n                                    \"text\": \"https://mailchimp.com/help/share-your-blog-posts-with-mailchimp/\",\n                                    \"marks\": [\n                                        {\n                                            \"type\": \"link\",\n                                            \"attrs\": {\n                                                \"href\": \"https://mailchimp.com/help/share-your-blog-posts-with-mailchimp/\"\n                                            }\n                                        }\n                                    ]\n                                }\n                            ]\n                        }\n                    ]\n                },\n                \"customfield_10010\": null,\n                \"customfield_10011\": \"0|i0064j:i\",\n                \"customfield_10012\": null,\n                \"customfield_10013\": null,\n                \"security\": null,\n                \"customfield_10008\": \"HACK-143\",\n                \"customfield_10009\": {\n                    \"hasEpicLinkFieldDependency\": false,\n                    \"showField\": false,\n                    \"nonEditableReason\": {\n                        \"reason\": \"PLUGIN_LICENSE_ERROR\",\n                        \"message\": \"Portfolio for Jira must be licensed for the Parent Link to be available.\"\n                    }\n                },\n                \"summary\": \"Automate newsletter\",\n                \"creator\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"name\": \"bro\",\n                    \"key\": \"admin\",\n                    \"accountId\": \"557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"emailAddress\": \"toddbirchard@gmail.com\",\n                    \"avatarUrls\": {\n                        \"48x48\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue\",\n                        \"24x24\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue\",\n                        \"16x16\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue\",\n                        \"32x32\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue\"\n                    },\n                    \"displayName\": \"Todd Birchard\",\n                    \"active\": true,\n                    \"timeZone\": \"America/New_York\",\n                    \"accountType\": \"atlassian\"\n                },\n                \"subtasks\": [],\n                \"reporter\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"name\": \"bro\",\n                    \"key\": \"admin\",\n                    \"accountId\": \"557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"emailAddress\": \"toddbirchard@gmail.com\",\n                    \"avatarUrls\": {\n                        \"48x48\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue\",\n                        \"24x24\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue\",\n                        \"16x16\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue\",\n                        \"32x32\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue\"\n                    },\n                    \"displayName\": \"Todd Birchard\",\n                    \"active\": true,\n                    \"timeZone\": \"America/New_York\",\n                    \"accountType\": \"atlassian\"\n                },\n                \"customfield_10000\": \"{}\",\n                \"customfield_10001\": null,\n                \"customfield_10004\": null,\n                \"environment\": null,\n                \"duedate\": null,\n                \"votes\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/issue/HACK-756/votes\",\n                    \"votes\": 0,\n                    \"hasVoted\": false\n                }\n            }\n        }\n    ]\n}\n\n\nWhoa, mama! That's a ton of BS for a single issue. You can see now why we'd want\nto transform this data before importing ten million fields into any database.\nMake note of these important fields:\n\n * startAt: An integer which tells us which issue number the paginated results\n   start at.\n * maxResults: Denotes the maximum number of results page - maxes out at 100\n   issues.\n * total: The total number of issues across all pages.\n * issues: A list of objects which contain the information for exactly one JIRA\n   issue per object\n\nGreat. So the purpose of fetch.py will essentially consist of creating a list of\nall 888  issues (in my case), and passing that off for transformation. Check it\nthe source I came up with:\n\nimport os\nimport math\nimport requests\n\n\nclass FetchJiraIssues:\n    \"\"\"Fetch all public-facing issues from JIRA instance.\n\n    1. Retrieve all values from env vars.\n    2. Construct request against JIRA REST API.\n    3. Fetch paginated issues via recursion.\n    4. Pass final JSON to be transformed into a DataFrame.\n     \"\"\"\n    results_per_page = 100\n    username = os.environ.get('JIRA_USERNAME')\n    password = os.environ.get('JIRA_PASSWORD')\n    endpoint = os.environ.get('JIRA_ENDPOINT')\n    jql = os.environ.get('JIRA_QUERY')\n    headers = {\n        \"Accept\": \"application/json\"\n    }\n\n    @classmethod\n    def get_total_number_of_issues(cls):\n        \"\"\"Gets the total number of results.\"\"\"\n        params = {\n            \"jql\": cls.jql,\n            \"maxResults\": 0,\n            \"startAt\": 0\n        }\n        req = requests.get(cls.endpoint,\n                           headers=cls.headers,\n                           params=params,\n                           auth=(cls.username, cls.password)\n                           )\n        response = req.json()\n        try:\n            total_results = response['total']\n            return total_results\n        except KeyError:\n            print('Could not find any issues!')\n\n    @classmethod\n    def fetch_all_results(cls):\n        \"\"\"Recursively retrieve all pages of JIRA issues.\"\"\"\n        total_results = cls.get_total_number_of_issues()\n        issue_arr = []\n\n        def fetch_single_page():\n            \"\"\"Fetch one page of results, and determine if another page exists.\"\"\"\n            params = {\n                \"jql\": cls.jql,\n                \"maxResults\": cls.results_per_page,\n                \"startAt\": len(issue_arr)\n            }\n            req = requests.get(cls.endpoint,\n                               headers=cls.headers,\n                               params=params,\n                               auth=(cls.username, cls.password)\n                               )\n            response = req.json()\n            issues = response['issues']\n            issues_so_far = len(issue_arr) + cls.results_per_page\n            print(issues_so_far, ' out of', total_results)\n            issue_arr.extend(issues)\n            # Check if additional pages of results exist.\n        count = math.ceil(total_results/cls.results_per_page)\n        for x in range(0, count):\n            fetch_single_page()\n        return issue_arr\n\n\nYep, I'm using classes. This class has two methods:\n\n * get_total_number_of_issues: All this does is essentially pull the number of\n   issues (888) from the REST API. We'll use this number in our next function to\n   check if additional pages exist.\n * fetch_all_results: This is where things start getting fun. fetch_all_results \n   is a @classmethod  which contains a function within itself. fetch_all_results \n    gets the total number of JIRA issues and then calls upon child function \n   fetch_single_page to pull JIRA issue JSON objects and dump them into a list\n   called issue_arr  until all issues are accounted for.\n\nBecause we have 888 issues and can retrieve 100 issues  at a time, our function\nfetch_single_page  should run 9 times. And it does!\n\nTransforming Our Data\nSo now we have a list of 888 messy JIRA issues. The scope of data.py  should be\nto pull out only the data we want, and make sure that data is clean:\n\nimport os\nimport json\nfrom pandas.io.json import json_normalize\nfrom datetime import datetime\n\n\nclass TransformData:\n    \"\"\"Build JIRA issue DataFrame.\n\n    1. Loop through JIRA issues and create a dictionary of desired data.\n    2. Convert each issue dictionary into a JSON object.\n    3. Load all issues into a Pandas DataFrame.\n    \"\"\"\n\n    issue_count = 0\n\n    @classmethod\n    def construct_dataframe(cls, issue_list_chunk):\n        \"\"\"Make DataFrame out of data received from JIRA API.\"\"\"\n        issue_list = [cls.make_issue_body(issue) for issue in issue_list_chunk]\n        issue_json_list = [cls.dict_to_json_string(issue) for issue in issue_list]\n        jira_issues_df = json_normalize(issue_json_list)\n        return jira_issues_df\n\n    @staticmethod\n    def dict_to_json_string(issue_dict):\n        \"\"\"Convert dict to JSON to string.\"\"\"\n        issue_json_string = json.dumps(issue_dict)\n        issue_json = json.loads(issue_json_string)\n        return issue_json\n\n    @classmethod\n    def make_issue_body(cls, issue):\n        \"\"\"Create a JSON body for each ticket.\"\"\"\n        updated_date = datetime.strptime(issue['fields']['updated'], \"%Y-%m-%dT%H:%M:%S.%f%z\")\n        body = {\n            'id': str(cls.issue_count),\n            'key': str(issue['key']),\n            'assignee_name': str(issue['fields']['assignee']['displayName']),\n            'assignee_url': str(issue['fields']['assignee']['avatarUrls']['48x48']),\n            'summary': str(issue['fields']['summary']),\n            'status': str(issue['fields']['status']['name']),\n            'priority_url': str(issue['fields']['priority']['iconUrl']),\n            'priority_rank': int(issue['fields']['priority']['id']),\n            'issuetype_name': str(issue['fields']['issuetype']['name']),\n            'issuetype_icon': str(issue['fields']['issuetype']['iconUrl']),\n            'epic_link': str(issue['fields']['customfield_10008']),\n            'project': str(issue['fields']['project']['name']),\n            'updated': int(datetime.timestamp(updated_date)),\n            'updatedAt': str(updated_date)\n        }\n        cls.issue_count += 1\n        return body\n\n\nAgain, let's see the methods at work:\n\n * construct_dataframe: The main function we invoke to build our DataFrame\n   (mostly just calls other methods). Once all transformations are completed,\n   creates a DataFrame called jira_df  by using the Pandas json_normalize() \n   method.\n * make_issue_body: Creates a new dictionary per singular JIRA issue. Extracts \n   only  the fields we want to be imported into our database. Converts each\n   field into either a string or an int as a lazy way of avoiding null values\n   (for example, if issue['fields']['priority']['name']  contained a null value,\n   the script would error out. Wrapping this in str() is a dirty way of\n   converting null  to an empty string).\n * dict_to_json_string  Takes each issue dictionary and converts it to a JSON\n   object, which is then turned into a string (this is done for Pandas).\n\nLoading Our Data\nAnd now for the final step! Thanks to the joyful marriage of Pandas and\nSQLAlchemy, turning DataFrames into SQL tables is super simple. We never make\nthings simple, though.\n\nimport os\nimport logging\nfrom sqlalchemy import create_engine, text, MetaData\nfrom sqlalchemy.types import Integer, Text, TIMESTAMP, String\nimport pandas as pd\n\nlogging.basicConfig()\nlogging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)\n\n\nclass DatabaseImport:\n    \"\"\"Merge Epic metadata and upload JIRA issues.\n\n    1. Merge Epic metadata by fetching an existing table.\n    2. Explicitly set data types for all columns found in jira_issues_df.\n    2. Create a new table from the final jira_issues_df.\n    \"\"\"\n\n    URI = os.environ.get('SQLALCHEMY_DATABASE_URI')\n    db_epic_table = os.environ.get('SQLALCHEMY_EPIC_TABLE')\n    db_jira_table = os.environ.get('SQLALCHEMY_JIRA_TABLE')\n    db_schema = os.environ.get('SQLALCHEMY_DB_SCHEMA')\n\n    # Create Engine\n    meta = MetaData(schema=\"hackers$prod\")\n    engine = create_engine(URI, echo=True)\n\n    @staticmethod\n    def truncate_table(engine):\n        \"\"\"Clear table of data.\"\"\"\n        sql = text('TRUNCATE TABLE \"hackers$prod\".\"JiraIssue\"')\n        engine.execute(sql)\n\n    @classmethod\n    def merge_epic_metadata(cls, jira_issues_df):\n        \"\"\"Merge epic metadata from existing SQL table.\"\"\"\n        cls.truncate_table(cls.engine)\n        epics_df = pd.read_sql_table(cls.db_epic_table,\n                                     cls.engine,\n                                     schema=cls.db_schema)\n        jira_issues_df = pd.merge(jira_issues_df,\n                                  epics_df[['epic_link', 'epic_name', 'epic_color']],\n                                  how='left',\n                                  on='epic_link',\n                                  copy=False)\n        return jira_issues_df\n\n    @classmethod\n    def upload_dataframe(cls, jira_issues_df):\n        \"\"\"Upload JIRA DataFrame to PostgreSQL database.\"\"\"\n        jira_issues_df = cls.merge_epic_metadata(jira_issues_df)\n        jira_issues_df.to_sql(cls.db_jira_table,\n                              cls.engine,\n                              if_exists='append',\n                              schema=cls.db_schema,\n                              index=False,\n                              dtype={\"assignee\": String(30),\n                                     \"assignee_url\": Text,\n                                     \"epic_link\": String(50),\n                                     \"issuetype_name\": String(50),\n                                     \"issuetype_icon\": Text,\n                                     \"key\": String(10),\n                                     \"priority_name\": String(30),\n                                     \"priority_rank\": Integer,\n                                     \"priority_url\": Text,\n                                     \"project\": String(50),\n                                     \"status\": String(30),\n                                     \"summary\": Text,\n                                     \"updated\": Integer,\n                                     \"updatedAt\": TIMESTAMP,\n                                     \"createdAt\": TIMESTAMP,\n                                     \"epic_color\": String(20),\n                                     \"epic_name\": String(50)\n                                     })\n        success_message = 'Successfully uploaded' \\\n                          + str(len(jira_issues_df.index)) \\\n                          + ' rows to ' + cls.db_jira_table\n        return success_message\n\n\n * merge_epic_metadata: Due to the nature of the JIRA REST API, some metadata is\n   missing per issue. If you're interested, the data missing revolves around \n   Epics: JIRA's REST API does not include the Epic Name  or Epic Color  fields\n   of linked epics.\n * upload_dataframe: Uses Panda's to_sql()  method to upload our DataFrame into\n   a SQL table (our target happens to be PostgreSQL, so we pass schema  here).\n   To make things explicit, we set the data type of every column on upload.\n\nWell, let's see how we made out!\n\nA look at our resulting database table.Whoaaa nelly, we did it! With our data\nclean, we can now build something useful! Here's what I built:\n\nFruits of our labor!There we have it: a pipeline that takes a bunch of messy\ndata, cleans it, and puts it somewhere else for proper use.\n\nIf you're interested in how we created the frontend for our Kanban board, check\nout our series on building features with GraphQL\n[https://hackersandslackers.com/series/graphql-hype/]. For the source code,\ncheck out the Github repository\n[https://github.com/toddbirchard/jira-database-etl].","html":"<p>Something we haven't done just yet on this site is walking through the humble process of creating data pipelines: the art of taking a bunch of data, changing said data, and putting it somewhere else. It's kind of a weird thing to be into, hence why the MoMA has been rejecting my submissions of Github repositories. Don't worry; I'll keep at it.</p><p>Something you don't see every day are people sharing their pipelines, which is understandable. Presumably, the other people who do this kind of stuff do it for work; nobody is happily building stupid pipelines in their free time begging to be open sourced. Except me.</p><p>We've recently revamped our <strong><a href=\"https://hackersandslackers.com/projects/\">projects</a></strong> page to include a public-facing Kanban board using GraphQL. To achieve this, we need to extract JIRA data from the JIRA Cloud REST API and place it securely in our database.</p><h2 id=\"structuring-our-pipeline\">Structuring our Pipeline</h2><p>An ETL pipeline which is considered 'well-structured' is in the eyes of the beholder. There are a million different ways to pull and mess with data, so there isn't a \"template\" for building these things out. In my case, the structure of my script just so happened to end up as three modules: one for <em>extracting</em>, one for <em>loading</em>, and one for <em>transforming</em>. This was unplanned, but it's a good sign when our app matches our mindset. Here's the breakdown:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">jira-database-etl\n├── __main__.py\n├── jira_etl\n│   ├── __init__.py\n│   ├── fetch.py\n│   ├── data.py\n│   └── db.py\n├── LICENSE\n├── MANIFEST.in\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── requirements.txt\n├── setup.cfg\n└── setup.py\n</code></pre>\n<!--kg-card-end: markdown--><p><strong>main.py</strong> is our application entry point. The logic of our pipeline is stored in three parts under the <strong>jira_etl</strong> directory:</p><ul><li><strong>fetch.py</strong> grabs the data from the source (JIRA Cloud's REST API) and handles fetching all JIRA issues.</li><li><strong>data.py</strong> transforms the data we've fetched and constructs a neat DataFrame containing only the information we're after.</li><li><strong>db.py</strong> finally loads the data into a SQL database.</li></ul><p>Don't look into it too much, but here's our entry point:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from jira_etl import fetch\nfrom jira_etl import data\nfrom jira_etl import db\n\n\ndef main():\n    &quot;&quot;&quot;Application Entry Point.\n\n    1. Fetch all desired JIRA issues from an instance's REST API.\n    2. Sanitize the data and add secondary metadata.\n    3. Upload resulting DataFrame to database.\n    &quot;&quot;&quot;\n    jira_issues_json = fetch.FetchJiraIssues.fetch_all_results()\n    jira_issues_df = data.TransformData.construct_dataframe(jira_issues_json)\n    upload_status = db.DatabaseImport.upload_dataframe(jira_issues_df)\n    return upload_status\n</code></pre>\n<!--kg-card-end: markdown--><p>Without further adieu, let's dig into the logic!</p><h2 id=\"extracting-our-data\">Extracting Our Data</h2><p>Before doing anything, it's essential we become familiar with the data we're about to pull. Firstly, JIRA's REST API returns paginated results which max out at 100 results per page. This means we'll have to loop through the pages recursively until all results are loaded.</p><p>Next, let's look at an example of a <strong><em>single</em></strong> JIRA issue JSON object returned by the API:</p><!--kg-card-begin: markdown--><pre><code class=\"language-json\">{\n    &quot;expand&quot;: &quot;names,schema&quot;,\n    &quot;startAt&quot;: 0,\n    &quot;maxResults&quot;: 1,\n    &quot;total&quot;: 888,\n    &quot;issues&quot;: [\n        {\n            &quot;expand&quot;: &quot;operations,versionedRepresentations,editmeta,changelog,renderedFields&quot;,\n            &quot;id&quot;: &quot;11718&quot;,\n            &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/issue/11718&quot;,\n            &quot;key&quot;: &quot;HACK-756&quot;,\n            &quot;fields&quot;: {\n                &quot;issuetype&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/issuetype/10014&quot;,\n                    &quot;id&quot;: &quot;10014&quot;,\n                    &quot;description&quot;: &quot;Placeholder item for \\&quot;holy shit this is going to be a lot of work\\&quot;&quot;,\n                    &quot;iconUrl&quot;: &quot;https://hackersandslackers.atlassian.net/secure/viewavatar?size=xsmall&amp;avatarId=10311&amp;avatarType=issuetype&quot;,\n                    &quot;name&quot;: &quot;Major Functionality&quot;,\n                    &quot;subtask&quot;: false,\n                    &quot;avatarId&quot;: 10311\n                },\n                &quot;customfield_10070&quot;: null,\n                &quot;customfield_10071&quot;: null,\n                &quot;customfield_10073&quot;: null,\n                &quot;customfield_10074&quot;: null,\n                &quot;customfield_10075&quot;: null,\n                &quot;project&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/project/10015&quot;,\n                    &quot;id&quot;: &quot;10015&quot;,\n                    &quot;key&quot;: &quot;HACK&quot;,\n                    &quot;name&quot;: &quot;Hackers and Slackers&quot;,\n                    &quot;projectTypeKey&quot;: &quot;software&quot;,\n                    &quot;avatarUrls&quot;: {\n                        &quot;48x48&quot;: &quot;https://hackersandslackers.atlassian.net/secure/projectavatar?pid=10015&amp;avatarId=10535&quot;,\n                        &quot;24x24&quot;: &quot;https://hackersandslackers.atlassian.net/secure/projectavatar?size=small&amp;pid=10015&amp;avatarId=10535&quot;,\n                        &quot;16x16&quot;: &quot;https://hackersandslackers.atlassian.net/secure/projectavatar?size=xsmall&amp;pid=10015&amp;avatarId=10535&quot;,\n                        &quot;32x32&quot;: &quot;https://hackersandslackers.atlassian.net/secure/projectavatar?size=medium&amp;pid=10015&amp;avatarId=10535&quot;\n                    }\n                },\n                &quot;fixVersions&quot;: [],\n                &quot;resolution&quot;: null,\n                &quot;resolutiondate&quot;: null,\n                &quot;workratio&quot;: -1,\n                &quot;lastViewed&quot;: &quot;2019-03-24T02:01:31.355-0400&quot;,\n                &quot;watches&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/issue/HACK-756/watchers&quot;,\n                    &quot;watchCount&quot;: 1,\n                    &quot;isWatching&quot;: true\n                },\n                &quot;created&quot;: &quot;2019-02-03T00:47:36.677-0500&quot;,\n                &quot;customfield_10062&quot;: null,\n                &quot;customfield_10063&quot;: null,\n                &quot;customfield_10064&quot;: null,\n                &quot;customfield_10065&quot;: null,\n                &quot;customfield_10066&quot;: null,\n                &quot;priority&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/priority/2&quot;,\n                    &quot;iconUrl&quot;: &quot;https://hackersandslackers.atlassian.net/images/icons/priorities/high.svg&quot;,\n                    &quot;name&quot;: &quot;High&quot;,\n                    &quot;id&quot;: &quot;2&quot;\n                },\n                &quot;customfield_10067&quot;: null,\n                &quot;customfield_10068&quot;: null,\n                &quot;customfield_10069&quot;: [],\n                &quot;labels&quot;: [],\n                &quot;versions&quot;: [],\n                &quot;issuelinks&quot;: [],\n                &quot;assignee&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;name&quot;: &quot;bro&quot;,\n                    &quot;key&quot;: &quot;admin&quot;,\n                    &quot;accountId&quot;: &quot;557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;emailAddress&quot;: &quot;toddbirchard@gmail.com&quot;,\n                    &quot;avatarUrls&quot;: {\n                        &quot;48x48&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue&quot;,\n                        &quot;24x24&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue&quot;,\n                        &quot;16x16&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue&quot;,\n                        &quot;32x32&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue&quot;\n                    },\n                    &quot;displayName&quot;: &quot;Todd Birchard&quot;,\n                    &quot;active&quot;: true,\n                    &quot;timeZone&quot;: &quot;America/New_York&quot;,\n                    &quot;accountType&quot;: &quot;atlassian&quot;\n                },\n                &quot;updated&quot;: &quot;2019-03-24T02:01:30.724-0400&quot;,\n                &quot;status&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/status/10004&quot;,\n                    &quot;description&quot;: &quot;&quot;,\n                    &quot;iconUrl&quot;: &quot;https://hackersandslackers.atlassian.net/&quot;,\n                    &quot;name&quot;: &quot;To Do&quot;,\n                    &quot;id&quot;: &quot;10004&quot;,\n                    &quot;statusCategory&quot;: {\n                        &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/statuscategory/2&quot;,\n                        &quot;id&quot;: 2,\n                        &quot;key&quot;: &quot;new&quot;,\n                        &quot;colorName&quot;: &quot;blue-gray&quot;,\n                        &quot;name&quot;: &quot;To Do&quot;\n                    }\n                },\n                &quot;components&quot;: [],\n                &quot;description&quot;: {\n                    &quot;version&quot;: 1,\n                    &quot;type&quot;: &quot;doc&quot;,\n                    &quot;content&quot;: [\n                        {\n                            &quot;type&quot;: &quot;paragraph&quot;,\n                            &quot;content&quot;: [\n                                {\n                                    &quot;type&quot;: &quot;text&quot;,\n                                    &quot;text&quot;: &quot;https://mailchimp.com/help/share-your-blog-posts-with-mailchimp/&quot;,\n                                    &quot;marks&quot;: [\n                                        {\n                                            &quot;type&quot;: &quot;link&quot;,\n                                            &quot;attrs&quot;: {\n                                                &quot;href&quot;: &quot;https://mailchimp.com/help/share-your-blog-posts-with-mailchimp/&quot;\n                                            }\n                                        }\n                                    ]\n                                }\n                            ]\n                        }\n                    ]\n                },\n                &quot;customfield_10010&quot;: null,\n                &quot;customfield_10011&quot;: &quot;0|i0064j:i&quot;,\n                &quot;customfield_10012&quot;: null,\n                &quot;customfield_10013&quot;: null,\n                &quot;security&quot;: null,\n                &quot;customfield_10008&quot;: &quot;HACK-143&quot;,\n                &quot;customfield_10009&quot;: {\n                    &quot;hasEpicLinkFieldDependency&quot;: false,\n                    &quot;showField&quot;: false,\n                    &quot;nonEditableReason&quot;: {\n                        &quot;reason&quot;: &quot;PLUGIN_LICENSE_ERROR&quot;,\n                        &quot;message&quot;: &quot;Portfolio for Jira must be licensed for the Parent Link to be available.&quot;\n                    }\n                },\n                &quot;summary&quot;: &quot;Automate newsletter&quot;,\n                &quot;creator&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;name&quot;: &quot;bro&quot;,\n                    &quot;key&quot;: &quot;admin&quot;,\n                    &quot;accountId&quot;: &quot;557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;emailAddress&quot;: &quot;toddbirchard@gmail.com&quot;,\n                    &quot;avatarUrls&quot;: {\n                        &quot;48x48&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue&quot;,\n                        &quot;24x24&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue&quot;,\n                        &quot;16x16&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue&quot;,\n                        &quot;32x32&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue&quot;\n                    },\n                    &quot;displayName&quot;: &quot;Todd Birchard&quot;,\n                    &quot;active&quot;: true,\n                    &quot;timeZone&quot;: &quot;America/New_York&quot;,\n                    &quot;accountType&quot;: &quot;atlassian&quot;\n                },\n                &quot;subtasks&quot;: [],\n                &quot;reporter&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;name&quot;: &quot;bro&quot;,\n                    &quot;key&quot;: &quot;admin&quot;,\n                    &quot;accountId&quot;: &quot;557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;emailAddress&quot;: &quot;toddbirchard@gmail.com&quot;,\n                    &quot;avatarUrls&quot;: {\n                        &quot;48x48&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue&quot;,\n                        &quot;24x24&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue&quot;,\n                        &quot;16x16&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue&quot;,\n                        &quot;32x32&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue&quot;\n                    },\n                    &quot;displayName&quot;: &quot;Todd Birchard&quot;,\n                    &quot;active&quot;: true,\n                    &quot;timeZone&quot;: &quot;America/New_York&quot;,\n                    &quot;accountType&quot;: &quot;atlassian&quot;\n                },\n                &quot;customfield_10000&quot;: &quot;{}&quot;,\n                &quot;customfield_10001&quot;: null,\n                &quot;customfield_10004&quot;: null,\n                &quot;environment&quot;: null,\n                &quot;duedate&quot;: null,\n                &quot;votes&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/issue/HACK-756/votes&quot;,\n                    &quot;votes&quot;: 0,\n                    &quot;hasVoted&quot;: false\n                }\n            }\n        }\n    ]\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Whoa, mama! That's a ton of BS for a single issue. You can see now why we'd want to transform this data before importing ten million fields into any database. Make note of these important fields:</p><ul><li><code>startAt</code>: An integer which tells us which issue number the paginated results start at.</li><li><code>maxResults</code>: Denotes the maximum number of results page - maxes out at 100 issues.</li><li><code>total</code>: The total number of issues across all pages.</li><li><code>issues</code>: A list of objects which contain the information for exactly one JIRA issue per object</li></ul><p>Great. So the purpose of <strong>fetch.py </strong>will essentially consist of creating a list of all <strong>888</strong> issues (in my case), and passing that off for transformation. Check it the source I came up with:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nimport math\nimport requests\n\n\nclass FetchJiraIssues:\n    &quot;&quot;&quot;Fetch all public-facing issues from JIRA instance.\n\n    1. Retrieve all values from env vars.\n    2. Construct request against JIRA REST API.\n    3. Fetch paginated issues via recursion.\n    4. Pass final JSON to be transformed into a DataFrame.\n     &quot;&quot;&quot;\n    results_per_page = 100\n    username = os.environ.get('JIRA_USERNAME')\n    password = os.environ.get('JIRA_PASSWORD')\n    endpoint = os.environ.get('JIRA_ENDPOINT')\n    jql = os.environ.get('JIRA_QUERY')\n    headers = {\n        &quot;Accept&quot;: &quot;application/json&quot;\n    }\n\n    @classmethod\n    def get_total_number_of_issues(cls):\n        &quot;&quot;&quot;Gets the total number of results.&quot;&quot;&quot;\n        params = {\n            &quot;jql&quot;: cls.jql,\n            &quot;maxResults&quot;: 0,\n            &quot;startAt&quot;: 0\n        }\n        req = requests.get(cls.endpoint,\n                           headers=cls.headers,\n                           params=params,\n                           auth=(cls.username, cls.password)\n                           )\n        response = req.json()\n        try:\n            total_results = response['total']\n            return total_results\n        except KeyError:\n            print('Could not find any issues!')\n\n    @classmethod\n    def fetch_all_results(cls):\n        &quot;&quot;&quot;Recursively retrieve all pages of JIRA issues.&quot;&quot;&quot;\n        total_results = cls.get_total_number_of_issues()\n        issue_arr = []\n\n        def fetch_single_page():\n            &quot;&quot;&quot;Fetch one page of results, and determine if another page exists.&quot;&quot;&quot;\n            params = {\n                &quot;jql&quot;: cls.jql,\n                &quot;maxResults&quot;: cls.results_per_page,\n                &quot;startAt&quot;: len(issue_arr)\n            }\n            req = requests.get(cls.endpoint,\n                               headers=cls.headers,\n                               params=params,\n                               auth=(cls.username, cls.password)\n                               )\n            response = req.json()\n            issues = response['issues']\n            issues_so_far = len(issue_arr) + cls.results_per_page\n            print(issues_so_far, ' out of', total_results)\n            issue_arr.extend(issues)\n            # Check if additional pages of results exist.\n        count = math.ceil(total_results/cls.results_per_page)\n        for x in range(0, count):\n            fetch_single_page()\n        return issue_arr\n</code></pre>\n<!--kg-card-end: markdown--><p>Yep, I'm using classes. This class has two methods:</p><ul><li><code>get_total_number_of_issues</code>: All this does is essentially pull the number of issues (888) from the REST API. We'll use this number in our next function to check if additional pages exist.</li><li><code>fetch_all_results</code>: This is where things start getting fun. <strong>fetch_all_results</strong> is a <em>@classmethod</em> which contains a function within itself. <strong>fetch_all_results</strong> gets the total number of JIRA issues and then calls upon child function <strong>fetch_single_page </strong>to pull JIRA issue JSON objects and dump them into a list called <code>issue_arr</code> until all issues are accounted for.</li></ul><p>Because we have <em>888 issues </em>and can retrieve <em>100 issues</em> at a time, our function  <code>fetch_single_page</code> should run <em>9 times</em>. And it does!</p><h2 id=\"transforming-our-data\">Transforming Our Data</h2><p>So now we have a list of 888 messy JIRA issues. The scope of <strong>data.py</strong> should be to pull out only the data we want, and make sure that data is clean:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nimport json\nfrom pandas.io.json import json_normalize\nfrom datetime import datetime\n\n\nclass TransformData:\n    &quot;&quot;&quot;Build JIRA issue DataFrame.\n\n    1. Loop through JIRA issues and create a dictionary of desired data.\n    2. Convert each issue dictionary into a JSON object.\n    3. Load all issues into a Pandas DataFrame.\n    &quot;&quot;&quot;\n\n    issue_count = 0\n\n    @classmethod\n    def construct_dataframe(cls, issue_list_chunk):\n        &quot;&quot;&quot;Make DataFrame out of data received from JIRA API.&quot;&quot;&quot;\n        issue_list = [cls.make_issue_body(issue) for issue in issue_list_chunk]\n        issue_json_list = [cls.dict_to_json_string(issue) for issue in issue_list]\n        jira_issues_df = json_normalize(issue_json_list)\n        return jira_issues_df\n\n    @staticmethod\n    def dict_to_json_string(issue_dict):\n        &quot;&quot;&quot;Convert dict to JSON to string.&quot;&quot;&quot;\n        issue_json_string = json.dumps(issue_dict)\n        issue_json = json.loads(issue_json_string)\n        return issue_json\n\n    @classmethod\n    def make_issue_body(cls, issue):\n        &quot;&quot;&quot;Create a JSON body for each ticket.&quot;&quot;&quot;\n        updated_date = datetime.strptime(issue['fields']['updated'], &quot;%Y-%m-%dT%H:%M:%S.%f%z&quot;)\n        body = {\n            'id': str(cls.issue_count),\n            'key': str(issue['key']),\n            'assignee_name': str(issue['fields']['assignee']['displayName']),\n            'assignee_url': str(issue['fields']['assignee']['avatarUrls']['48x48']),\n            'summary': str(issue['fields']['summary']),\n            'status': str(issue['fields']['status']['name']),\n            'priority_url': str(issue['fields']['priority']['iconUrl']),\n            'priority_rank': int(issue['fields']['priority']['id']),\n            'issuetype_name': str(issue['fields']['issuetype']['name']),\n            'issuetype_icon': str(issue['fields']['issuetype']['iconUrl']),\n            'epic_link': str(issue['fields']['customfield_10008']),\n            'project': str(issue['fields']['project']['name']),\n            'updated': int(datetime.timestamp(updated_date)),\n            'updatedAt': str(updated_date)\n        }\n        cls.issue_count += 1\n        return body\n</code></pre>\n<!--kg-card-end: markdown--><p>Again, let's see the methods at work:</p><ul><li><code>construct_dataframe</code>: The main function we invoke to build our DataFrame (mostly just calls other methods). Once all transformations are completed, creates a DataFrame called <strong>jira_df</strong> by using the Pandas <em>json_normalize()</em> method.</li><li><code>make_issue_body</code>: Creates a new dictionary per singular JIRA issue. Extracts <em>only</em> the fields we want to be imported into our database. Converts each field into either a string or an int as a lazy way of avoiding null values (for example, if <code>issue['fields']['priority']['name']</code> contained a null value, the script would error out. Wrapping this in <strong>str() </strong>is a dirty way of converting <em>null</em> to an empty string).</li><li><code>dict_to_json_string</code> Takes each issue dictionary and converts it to a JSON object, which is then turned into a string (this is done for Pandas).</li></ul><h2 id=\"loading-our-data\">Loading Our Data</h2><p>And now for the final step! Thanks to the joyful marriage of Pandas and SQLAlchemy, turning DataFrames into SQL tables is super simple. We never make things simple, though.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nimport logging\nfrom sqlalchemy import create_engine, text, MetaData\nfrom sqlalchemy.types import Integer, Text, TIMESTAMP, String\nimport pandas as pd\n\nlogging.basicConfig()\nlogging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)\n\n\nclass DatabaseImport:\n    &quot;&quot;&quot;Merge Epic metadata and upload JIRA issues.\n\n    1. Merge Epic metadata by fetching an existing table.\n    2. Explicitly set data types for all columns found in jira_issues_df.\n    2. Create a new table from the final jira_issues_df.\n    &quot;&quot;&quot;\n\n    URI = os.environ.get('SQLALCHEMY_DATABASE_URI')\n    db_epic_table = os.environ.get('SQLALCHEMY_EPIC_TABLE')\n    db_jira_table = os.environ.get('SQLALCHEMY_JIRA_TABLE')\n    db_schema = os.environ.get('SQLALCHEMY_DB_SCHEMA')\n\n    # Create Engine\n    meta = MetaData(schema=&quot;hackers$prod&quot;)\n    engine = create_engine(URI, echo=True)\n\n    @staticmethod\n    def truncate_table(engine):\n        &quot;&quot;&quot;Clear table of data.&quot;&quot;&quot;\n        sql = text('TRUNCATE TABLE &quot;hackers$prod&quot;.&quot;JiraIssue&quot;')\n        engine.execute(sql)\n\n    @classmethod\n    def merge_epic_metadata(cls, jira_issues_df):\n        &quot;&quot;&quot;Merge epic metadata from existing SQL table.&quot;&quot;&quot;\n        cls.truncate_table(cls.engine)\n        epics_df = pd.read_sql_table(cls.db_epic_table,\n                                     cls.engine,\n                                     schema=cls.db_schema)\n        jira_issues_df = pd.merge(jira_issues_df,\n                                  epics_df[['epic_link', 'epic_name', 'epic_color']],\n                                  how='left',\n                                  on='epic_link',\n                                  copy=False)\n        return jira_issues_df\n\n    @classmethod\n    def upload_dataframe(cls, jira_issues_df):\n        &quot;&quot;&quot;Upload JIRA DataFrame to PostgreSQL database.&quot;&quot;&quot;\n        jira_issues_df = cls.merge_epic_metadata(jira_issues_df)\n        jira_issues_df.to_sql(cls.db_jira_table,\n                              cls.engine,\n                              if_exists='append',\n                              schema=cls.db_schema,\n                              index=False,\n                              dtype={&quot;assignee&quot;: String(30),\n                                     &quot;assignee_url&quot;: Text,\n                                     &quot;epic_link&quot;: String(50),\n                                     &quot;issuetype_name&quot;: String(50),\n                                     &quot;issuetype_icon&quot;: Text,\n                                     &quot;key&quot;: String(10),\n                                     &quot;priority_name&quot;: String(30),\n                                     &quot;priority_rank&quot;: Integer,\n                                     &quot;priority_url&quot;: Text,\n                                     &quot;project&quot;: String(50),\n                                     &quot;status&quot;: String(30),\n                                     &quot;summary&quot;: Text,\n                                     &quot;updated&quot;: Integer,\n                                     &quot;updatedAt&quot;: TIMESTAMP,\n                                     &quot;createdAt&quot;: TIMESTAMP,\n                                     &quot;epic_color&quot;: String(20),\n                                     &quot;epic_name&quot;: String(50)\n                                     })\n        success_message = 'Successfully uploaded' \\\n                          + str(len(jira_issues_df.index)) \\\n                          + ' rows to ' + cls.db_jira_table\n        return success_message\n</code></pre>\n<!--kg-card-end: markdown--><ul><li><code>merge_epic_metadata</code>: Due to the nature of the JIRA REST API, some metadata is missing per issue. If you're interested, the data missing revolves around <strong>Epics</strong>: JIRA's REST API does not include the <em>Epic Name</em> or <em>Epic Color</em> fields of linked epics.</li><li><code>upload_dataframe</code>: Uses Panda's <strong>to_sql()</strong> method to upload our DataFrame into a SQL table (our target happens to be PostgreSQL, so we pass <em>schema</em> here). To make things explicit, we set the data type of every column on upload.</li></ul><p>Well, let's see how we made out!</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-27-at-9.03.51-PM.png\" class=\"kg-image\"><figcaption>A look at our resulting database table.</figcaption></figure><!--kg-card-end: image--><p>Whoaaa nelly, we did it! With our data clean, we can now build something useful! Here's what I built:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-27-at-9.29.20-PM.png\" class=\"kg-image\"><figcaption>Fruits of our labor!</figcaption></figure><!--kg-card-end: image--><p>There we have it: a pipeline that takes a bunch of messy data, cleans it, and puts it somewhere else for proper use.</p><p>If you're interested in how we created the frontend for our Kanban board, check out our series on <a href=\"https://hackersandslackers.com/series/graphql-hype/\">building features with GraphQL</a>. For the source code, check out the <a href=\"https://github.com/toddbirchard/jira-database-etl\">Github repository</a>.</p>","url":"https://hackersandslackers.com/building-an-etl-pipeline-from-jira-to-postgresql/","uuid":"23647abe-9b47-4f58-8206-cff1fb2ae891","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c95e08ef654036aa06c6a02"}},"pageContext":{"slug":"building-an-etl-pipeline-from-jira-to-postgresql"}}