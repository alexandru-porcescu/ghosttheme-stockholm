{"data":{"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673634","title":"Starting an ExpressJS App","slug":"create-an-expressjs-app","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2017/11/expressjs@2x.jpg","excerpt":"Installation guide for ExpressJS with popular customization options.","custom_excerpt":"Installation guide for ExpressJS with popular customization options.","created_at_pretty":"18 November, 2017","published_at_pretty":"18 November, 2017","updated_at_pretty":"07 March, 2019","created_at":"2017-11-18T08:44:44.000-05:00","published_at":"2017-11-18T08:54:54.000-05:00","updated_at":"2019-03-07T01:39:46.000-05:00","meta_title":"Starting an ExpressJS App | Hackers and Slackers","meta_description":"Installation guide for ExpressJS with popular customization options","og_description":"Installation guide for ExpressJS with popular customization options","og_image":"https://hackersandslackers.com/content/images/2017/11/expressjs@2x.jpg","og_title":"Starting an ExpressJS App","twitter_description":"Installation guide for ExpressJS with popular customization options","twitter_image":"https://hackersandslackers.com/content/images/2017/11/expressjs@2x.jpg","twitter_title":"Starting an ExpressJS App","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},{"name":"ExpressJS","slug":"expressjs","description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch as a simplistic Express app can evolve into a beautiful monstrosity.","feature_image":null,"meta_description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch a simplistic Express app can evolve into a beautiful monstrosity.","meta_title":"ExpressJS Framework | Hackers and Slackers","visibility":"public"}],"plaintext":"Over the past few months I've found myself spinning up tons of new servers and\nwalking through the process of pushing express apps live.\n\nBecause this process always comes at unexpected times, I've never bothered\ndocumenting the steps it takes to get a blank box running express. Surprisingly\nit seems as though few have bothered to walk through every step involved in a\nsingle place, and most express tutorials contain outdated information which\nlikely leads to headaches for newcomers.\n\nI'll be walking through an ExpressJS setup with the tech I always opt for.\n\nStack\n * NodeJS\n * NPM\n * Nginx\n * Express\n * Express-Generator\n * Sass\n * Handlebars\n * PM2\n * Grunt\n\nInstallation\nPrep your server by installing the latest updates:\n\n$ apt-get update\n$ apt-get upgrade -y\n\n\nNodeJS\nOf the things we'll be installing prior to development, NodeJS is the trickiest.\nUnlike other packages, we cannot simply use Ubuntu's apt-get install  command\nfor Node. NodeJS for Linux distributions is best installed via NodeSource, which\nis handled as such:\n\n$ apt update\n$ apt upgrade -y\n$ curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -\n$ sudo apt-get install -y nodejs\n$ sudo apt-get install gcc g++ make\n$ sudo npm install -g npm@latest\n\n\nNote that this also hooks us up with the latest version of NPM, so we're all\ngood on that front.\n\nNginx\nLet's install Nginx before we forget. We'll come back to Nginx later to set up\nthe config.\n\napt-get install nginx\n\n\nExpress\nWe'll install express globally. This way we can support multiple apps running\nexpress, as well as use an express generator to easily create more projects down\nthe line.\n\nnpm install -g express\n\n\nExpress generator\nInstall express generator globally. Express generator is the easiest way to set\nup a new express app with the standard structure preconfigured.\n\nnpm install -g express-generator\n\n\nCreate an App\nNow we get to the fun stuff.\n\n$ cd  to the directory you'll be using to contain your apps, such as /home  or \n/var/www. When we use express-generator  in this directory, we'll be\ninitializing a new express project will most of the common boilerplate setup\npreconfigured.\n\nThis will create your Express app inside /home/myapp:\n\ncd /home\n\nexpress --view=hbs --css=less myapp\n\n\nExpress-generator prompts you to pass arguments to automatically configure your\nproject for you. We're able to specify which CSS preprocessor and templating\nsystem we prefer this way. I'm going to create a project using Handlebars and\nSass as my weapons of choice.\n\nThese are the options that come with express-generator in case you'd like to\ncustomize your installation:\n\n$ express -h\n\n  Usage: express [options] [dir]\n\n  Options:\n\n    -h, --help          output usage information\n        --version       output the version number\n    -e, --ejs           add ejs engine support\n        --hbs           add handlebars engine support\n        --pug           add pug engine support\n    -H, --hogan         add hogan.js engine support\n    -v, --view <engine> add view <engine> support (ejs|hbs|hjs|jade|pug|twig|vash) (defaults to jade)\n    -c, --css <engine>  add stylesheet <engine> support (less|stylus|compass|sass) (defaults to plain css)\n        --git           add .gitignore\n    -f, --force         force on non-empty directory\n\n\nWarning: common bug ahead\nIf your life sucks, running express generator may have given you this error:\n\n/usr/bin/env: ‘node’: No such file or directory\n\n\nThis is an issue with Debian distributions of linux which treat 'node' and\n'nodejs' as separate filepaths. To alleviate this, create the following symbolic\nlink:\n\nln -s /usr/bin/nodejs /usr/bin/node\n\n\nStart App\nInside your project directory run npm install  to install all dependancies for\nyour project. This will look at the package.json  file that express-generator\ncreated and will install the corresponding node modules.\n\ncd myapp\n\nnpm install\n\n\nHere's the result:\n\n.\n├── app.js\n├── bin\n│   └── www\n├── package.json\n├── public\n│   ├── images\n│   ├── javascripts\n│   └── stylesheets\n│       └── style.css\n├── routes\n│   ├── index.js\n│   └── users.js\n└── views\n    ├── error.pug\n    ├── index.pug\n    └── layout.pug\n\n7 directories, 9 files\n\n\nSet up Nginx Config\nBefore creating your Nginx config, it is best to verify which port express will\nbe running on. In most recent versions of express, this can be found in the www\nfile. The path to this looks like myapp/bin/www.\n\nCheck out that file and see what the value is for var port.\n\nvim bin/www\n\n\nYou should see something like this:\n\nvar port = normalizePort(process.env.PORT || '3000');\n\n\nThus, the port is 3000. Remember this.\n\nPreviously this information was stored in Express's app.js  file.\n\nNow, create a Nginx config in sites-available:\n\nvim /etc/nginx/sites-available/myapp\n\n\nFor a basic reverse proxy server configuration, use the configuration below.\n\nBe sure to replace the port with the port you found earlier.\n\nserver {\n    listen 80;\n\n    server_name example.com www.example.com;\n\n    location / {\n        proxy_pass http://127.0.0.1:3000; #Replace port here\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n\n    location ~ /.well-known {\n        allow all;\n    }\n\n    client_max_body_size 50m;\n}\n\n\nSave this out. Now create a symbolic link to have this appear in sites enabled,\nand restart Nginx.\n\nln -s /etc/nginx/sites-available/myapp /etc/nginx/sites-enabled/myapp \n\nservice nginx restart\n\n\nRun your app\nNow your web server is pointing to the correct place, but your app isn't\nactually running. To keep your app running continuously, we'll use PM2.\n\nInstall pm2 globally:\n\nnpm install pm2 -g\n\n\nGo to your app's directory, and start your app using PM2:\n\ncd /home/myapp\n\npm2 start bin/www\n\n\nIf successful, PM2 should then list your app as running.\n\nYou can run as many express apps on one server as you like:\n\n┌──────────┬────┬──────┬───────┬────────┬─────────┬────────┬─────┬───────────┬──────┬──────────┐\n│ App name │ id │ mode │ pid   │ status │ restart │ uptime │ cpu │ mem       │ user │ watching │\n├──────────┼────┼──────┼───────┼────────┼─────────┼────────┼─────┼───────────┼──────┼──────────┤\n│ www      │ 0  │ fork │ 8953  │ online │ 79      │ 35h    │ 0%  │ 44.6 MB   │ root │ disabled │\n│ www      │ 1  │ fork │ 18195 │ online │ 0       │ 3D     │ 0%  │ 22.3 MB   │ root │ disabled │\n│ www      │ 2  │ fork │ 19990 │ online │ 0       │ 33h    │ 0%  │ 49.2 MB   │ root │ disabled │\n└──────────┴────┴──────┴───────┴────────┴─────────┴────────┴─────┴───────────┴──────┴──────────┘\n\n\nYour app should now be accessible via your domain.\n\nFinal items\nYour app is up and running, but you're not in the clear yet. To have things\nfully configured, you'll need to set up grunt or gulp to compress your source\nfor production.\n\nConfiguring gulp files is a tutorial in its own right. Otherwise, you're good to\ngo to serve static files directly out of the /public  folder.","html":"<p>Over the past few months I've found myself spinning up tons of new servers and walking through the process of pushing express apps live.</p><p>Because this process always comes at unexpected times, I've never bothered documenting the steps it takes to get a blank box running express. Surprisingly it seems as though few have bothered to walk through every step involved in a single place, and most express tutorials contain outdated information which likely leads to headaches for newcomers.</p><p>I'll be walking through an ExpressJS setup with the tech I always opt for.</p><h2 id=\"stack\">Stack</h2><ul><li>NodeJS</li><li>NPM</li><li>Nginx</li><li>Express</li><li>Express-Generator</li><li>Sass</li><li>Handlebars</li><li>PM2</li><li>Grunt</li></ul><h2 id=\"installation\">Installation</h2><p>Prep your server by installing the latest updates:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ apt-get update\n$ apt-get upgrade -y\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"nodejs\">NodeJS</h3><p>Of the things we'll be installing prior to development, NodeJS is the trickiest. Unlike other packages, we cannot simply use Ubuntu's <code>apt-get install</code> command for Node. NodeJS for Linux distributions is best installed via NodeSource, which is handled as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ apt update\n$ apt upgrade -y\n$ curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -\n$ sudo apt-get install -y nodejs\n$ sudo apt-get install gcc g++ make\n$ sudo npm install -g npm@latest\n</code></pre>\n<!--kg-card-end: markdown--><p>Note that this also hooks us up with the latest version of NPM, so we're all good on that front.</p><h3 id=\"nginx\">Nginx</h3><p>Let's install Nginx before we forget. We'll come back to Nginx later to set up the config.</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">apt-get install nginx\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"express\">Express</h3><p>We'll install express globally. This way we can support multiple apps running express, as well as use an express generator to easily create more projects down the line.</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">npm install -g express\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"express-generator\">Express generator</h3><p>Install express generator globally. Express generator is the easiest way to set up a new express app with the standard structure preconfigured.</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">npm install -g express-generator\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"create-an-app\">Create an App</h2><p>Now we get to the fun stuff.</p><p><code>$ cd</code> to the directory you'll be using to contain your apps, such as <code>/home</code> or <code>/var/www</code>. When we use <code>express-generator</code> in this directory, we'll be initializing a new express project will most of the common boilerplate setup preconfigured.</p><p>This will create your Express app inside <code>/home/myapp</code>:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">cd /home\n\nexpress --view=hbs --css=less myapp\n</code></pre>\n<!--kg-card-end: markdown--><p>Express-generator prompts you to pass arguments to automatically configure your project for you. We're able to specify which CSS preprocessor and templating system we prefer this way. I'm going to create a project using Handlebars and Sass as my weapons of choice.</p><p>These are the options that come with express-generator in case you'd like to customize your installation:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ express -h\n\n  Usage: express [options] [dir]\n\n  Options:\n\n    -h, --help          output usage information\n        --version       output the version number\n    -e, --ejs           add ejs engine support\n        --hbs           add handlebars engine support\n        --pug           add pug engine support\n    -H, --hogan         add hogan.js engine support\n    -v, --view &lt;engine&gt; add view &lt;engine&gt; support (ejs|hbs|hjs|jade|pug|twig|vash) (defaults to jade)\n    -c, --css &lt;engine&gt;  add stylesheet &lt;engine&gt; support (less|stylus|compass|sass) (defaults to plain css)\n        --git           add .gitignore\n    -f, --force         force on non-empty directory\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"warning-common-bug-ahead\">Warning: common bug ahead</h2><p>If your life sucks, running express generator may have given you this error:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">/usr/bin/env: ‘node’: No such file or directory\n</code></pre>\n<!--kg-card-end: markdown--><p>This is an issue with Debian distributions of linux which treat 'node' and 'nodejs' as separate filepaths. To alleviate this, create the following symbolic link:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">ln -s /usr/bin/nodejs /usr/bin/node\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"start-app\">Start App</h2><p>Inside your project directory run <strong>npm install</strong> to install all dependancies for your project. This will look at the <code>package.json</code> file that express-generator created and will install the corresponding node modules.</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">cd myapp\n\nnpm install\n</code></pre>\n<!--kg-card-end: markdown--><p>Here's the result:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">.\n├── app.js\n├── bin\n│   └── www\n├── package.json\n├── public\n│   ├── images\n│   ├── javascripts\n│   └── stylesheets\n│       └── style.css\n├── routes\n│   ├── index.js\n│   └── users.js\n└── views\n    ├── error.pug\n    ├── index.pug\n    └── layout.pug\n\n7 directories, 9 files\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"set-up-nginx-config\">Set up Nginx Config</h2><p>Before creating your Nginx config, it is best to verify which port express will be running on. In most recent versions of express, this can be found in the www file. The path to this looks like myapp/bin/www.</p><p>Check out that file and see what the value is for var port.</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">vim bin/www\n</code></pre>\n<!--kg-card-end: markdown--><p>You should see something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">var port = normalizePort(process.env.PORT || '3000');\n</code></pre>\n<!--kg-card-end: markdown--><p>Thus, the port is 3000. Remember this.</p><p>Previously this information was stored in Express's <code>app.js</code> file.</p><p>Now, create a Nginx config in sites-available:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">vim /etc/nginx/sites-available/myapp\n</code></pre>\n<!--kg-card-end: markdown--><p>For a basic reverse proxy server configuration, use the configuration below.</p><p>Be sure to replace the port with the port you found earlier.</p><!--kg-card-begin: markdown--><pre><code class=\"language-nginx\">server {\n    listen 80;\n\n    server_name example.com www.example.com;\n\n    location / {\n        proxy_pass http://127.0.0.1:3000; #Replace port here\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n\n    location ~ /.well-known {\n        allow all;\n    }\n\n    client_max_body_size 50m;\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Save this out. Now create a symbolic link to have this appear in sites enabled, and restart Nginx.</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">ln -s /etc/nginx/sites-available/myapp /etc/nginx/sites-enabled/myapp \n\nservice nginx restart\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"run-your-app\">Run your app</h2><p>Now your web server is pointing to the correct place, but your app isn't actually running. To keep your app running continuously, we'll use PM2.</p><p>Install pm2 globally:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">npm install pm2 -g\n</code></pre>\n<!--kg-card-end: markdown--><p>Go to your app's directory, and start your app using PM2:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">cd /home/myapp\n\npm2 start bin/www\n</code></pre>\n<!--kg-card-end: markdown--><p>If successful, PM2 should then list your app as running.</p><p>You can run as many express apps on one server as you like:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">┌──────────┬────┬──────┬───────┬────────┬─────────┬────────┬─────┬───────────┬──────┬──────────┐\n│ App name │ id │ mode │ pid   │ status │ restart │ uptime │ cpu │ mem       │ user │ watching │\n├──────────┼────┼──────┼───────┼────────┼─────────┼────────┼─────┼───────────┼──────┼──────────┤\n│ www      │ 0  │ fork │ 8953  │ online │ 79      │ 35h    │ 0%  │ 44.6 MB   │ root │ disabled │\n│ www      │ 1  │ fork │ 18195 │ online │ 0       │ 3D     │ 0%  │ 22.3 MB   │ root │ disabled │\n│ www      │ 2  │ fork │ 19990 │ online │ 0       │ 33h    │ 0%  │ 49.2 MB   │ root │ disabled │\n└──────────┴────┴──────┴───────┴────────┴─────────┴────────┴─────┴───────────┴──────┴──────────┘\n</code></pre>\n<!--kg-card-end: markdown--><p>Your app should now be accessible via your domain.</p><h2 id=\"final-items\">Final items</h2><p>Your app is up and running, but you're not in the clear yet. To have things fully configured, you'll need to set up grunt or gulp to compress your source for production.</p><p>Configuring gulp files is a tutorial in its own right. Otherwise, you're good to go to serve static files directly out of the <code>/public</code> folder.</p>","url":"https://hackersandslackers.com/create-an-expressjs-app/","uuid":"048b6212-5dbf-429c-b86d-d3fc65238e06","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a10394c3858167c7082486e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673633","title":"Installing Django on Ubuntu","slug":"installing-django-on-a-linux-box","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/django2-1.jpg","excerpt":"Get started with the Python MVC framework that started it all.","custom_excerpt":"Get started with the Python MVC framework that started it all.","created_at_pretty":"18 November, 2017","published_at_pretty":"18 November, 2017","updated_at_pretty":"28 March, 2019","created_at":"2017-11-18T06:07:00.000-05:00","published_at":"2017-11-18T06:12:07.000-05:00","updated_at":"2019-03-28T04:43:32.000-04:00","meta_title":"Installing Django on Ubuntu | Hackers and Slackers","meta_description":"Get started with the Python MVC framework that started it all","og_description":"Get started with the Python MVC framework that started it all","og_image":"https://hackersandslackers.com/content/images/2019/03/django2-1.jpg","og_title":"Installing Django on Ubuntu","twitter_description":"Get started with the Python MVC framework that started it all","twitter_image":"https://hackersandslackers.com/content/images/2019/03/django2-1.jpg","twitter_title":"Installing Django on Ubuntu","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"#Getting into Django","slug":"starting-django","description":"Getting started with Django: the original daddy of Python frameworks.","feature_image":"https://hackersandslackers.com/content/images/2019/03/django2.jpg","meta_description":"Getting started with Django: the original daddy of Python frameworks.","meta_title":"Setting up Django","visibility":"internal"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"Django is the OG Grandaddy of all Python frameworks: it's by far Python's most\nfully-featured MVC framework out of the box. Today we're going to look at the\nrelatively painless process of setting up Django on a Ubuntu server.\n\nStack\n * Ubuntu\n * Python 3\n * Pip 3\n * Nginx\n * Django (latest)\n\nInstall all Dependencies\nWe'll start with the obligatory update to ensure we're getting the latest\npackages.\n\n$ apt-get update\n$ apt-get upgrade\n\n\nLet's verify that the latest version of Python 3 is installed on your box:\n\n$ python3 --version\nPython 3.6.3\n\n\nRegardless, it's probably a good idea to download the latest anyway:\n\napt-get install python3 python3-pip python3-dev\n\n\nI highly recommend setting up a Python virtual environment before moving forward\nwith any installs. If you're living in the stone age, virtualenv  and \nvirtualenvwrapper  will probably server you fine. If you're a gentleman, use \npipenv  or poetry  instead.\n\nNow let's go ahead and install Django. We can find out what the latest\ndistribution is by checking Django's download page: \nhttps://www.djangoproject.com/download/\n\nWith the version number in hand, we'll install Django using pip:\n\npip3 install Django==2.1.7\n\n\nNote that we’re using pip3  here as opposed to pip, which explicitly downloads\nDjango under our Python3 installation. If we’re installing inside our virtual\nenvironment, specifying pip3  is redundant; pip  will work under the assumption\nthat we’re using the only Python version installed to our environment.\n\nLet's verify that you've installed Django correctly. Open your Python3 shell and\ninput the following:\n\n$ python3\n>>> import django\n>>> print(django.get_version())\n1.11\n\n\nIf you receive an error along the lines of ModuleNotFoundError: No module named\n'Django', Django was probably installed on Python2 as opposed to 3. Make sure\nthat you used pip3 instead of pip to install Django, and try again.\n\nWhy is This Somewhat Convoluted?\nAll major Linux distributions come with Python 2.7 pre-installed. Python2 is\nstill critical to the core functionality of most linux distributions, therefore\nPython2 must be left intact and cannot be deleted or modified without suffering\ndamage to the operating system.\n\nUnfortunately, the python and pip commands will forever refer to Python 2 as a\nresult, thus forcing Python 3 users to forever utilize the python3  and pip3 \ncommands. This isn't that big of a deal, but is a common pitfall for those\nswitching over to the light side.","html":"<p>Django is the OG Grandaddy of all Python frameworks: it's by far Python's most fully-featured MVC framework out of the box. Today we're going to look at the relatively painless process of setting up Django on a Ubuntu server.</p><h3 id=\"stack\">Stack</h3><ul><li>Ubuntu</li><li>Python 3</li><li>Pip 3</li><li>Nginx</li><li>Django (latest)</li></ul><h2 id=\"install-all-dependencies\">Install all Dependencies</h2><p>We'll start with the obligatory update to ensure we're getting the latest packages.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ apt-get update\n$ apt-get upgrade\n</code></pre>\n<!--kg-card-end: markdown--><p>Let's verify that the latest version of Python 3 is installed on your box:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ python3 --version\nPython 3.6.3\n</code></pre>\n<!--kg-card-end: markdown--><p>Regardless, it's probably a good idea to download the latest anyway:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">apt-get install python3 python3-pip python3-dev\n</code></pre>\n<!--kg-card-end: markdown--><p>I highly recommend setting up a Python virtual environment before moving forward with any installs. If you're living in the stone age, <code>virtualenv</code> and <code>virtualenvwrapper</code> will probably server you fine. If you're a gentleman, use <code>pipenv</code> or <code>poetry</code> instead.</p><p>Now let's go ahead and install Django. We can find out what the latest distribution is by checking Django's download page: <a href=\"https://www.djangoproject.com/download/\">https://www.djangoproject.com/download/</a></p><p>With the version number in hand, we'll install Django using pip:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">pip3 install Django==2.1.7\n</code></pre>\n<!--kg-card-end: markdown--><p>Note that we’re using <strong>pip3</strong> here as opposed to <strong>pip</strong>, which explicitly downloads Django under our Python3 installation. If we’re installing inside our virtual environment, specifying <strong>pip3</strong> is redundant; <strong>pip</strong> will work under the assumption that we’re using the only Python version installed to our environment.</p><p>Let's verify that you've installed Django correctly. Open your Python3 shell and input the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ python3\n&gt;&gt;&gt; import django\n&gt;&gt;&gt; print(django.get_version())\n1.11\n</code></pre>\n<!--kg-card-end: markdown--><p>If you receive an error along the lines of <code>ModuleNotFoundError: No module named 'Django'</code>, Django was probably installed on Python2 as opposed to 3. Make sure that you used pip3 instead of pip to install Django, and try again.</p><h2 id=\"why-is-this-somewhat-convoluted\">Why is This Somewhat Convoluted?</h2><p>All major Linux distributions come with Python 2.7 pre-installed. Python2 is still critical to the core functionality of most linux distributions, therefore Python2 must be left intact and cannot be deleted or modified without suffering damage to the operating system.</p><p>Unfortunately, the python and pip commands will forever refer to Python 2 as a result, thus forcing Python 3 users to forever utilize the <em>python3</em> and <em>pip3</em> commands. This isn't that big of a deal, but is a common pitfall for those switching over to the light side.</p>","url":"https://hackersandslackers.com/installing-django-on-a-linux-box/","uuid":"77609409-5552-418d-b742-c549a2ccf01b","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a101454d201b772c140d36e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673632","title":"Merge Sets of Data in Python Using Pandas","slug":"merge-dataframes-with-pandas","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2017/11/pandasmerge@2x.jpg","excerpt":"Perform SQL-like merges of data using Python's Pandas.","custom_excerpt":"Perform SQL-like merges of data using Python's Pandas.","created_at_pretty":"18 November, 2017","published_at_pretty":"18 November, 2017","updated_at_pretty":"26 December, 2018","created_at":"2017-11-17T19:09:32.000-05:00","published_at":"2017-11-17T19:22:25.000-05:00","updated_at":"2018-12-26T04:29:22.000-05:00","meta_title":"Merging Dataframes with Pandas | Hackers and Slackers","meta_description":"Perform merges of data similar to SQL JOINs using Python's Pandas library: the essential library for data analysis in Oython. ","og_description":"Perform SQL-like merges of data using Python's Pandas","og_image":"https://hackersandslackers.com/content/images/2017/11/pandasmerge@2x.jpg","og_title":"Merging Dataframes with Pandas","twitter_description":"Perform SQL-like merges of data using Python's Pandas","twitter_image":"https://hackersandslackers.com/content/images/2017/11/pandasmerge@2x.jpg","twitter_title":"Merging Dataframes with Pandas","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Analysis","slug":"data-analysis","description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","feature_image":null,"meta_description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","meta_title":"Data Analysis | Hackers and Slackers","visibility":"public"},{"name":"#Data Analysis with Pandas","slug":"data-analysis-pandas","description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pandasseries-1.jpg","meta_description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","meta_title":"Data Analysis with Pandas","visibility":"internal"}],"plaintext":"Let's say you have two obscenely large sets of data. \n\nThese sets of data contain information on a similar topic, such as customers. \nDataset #1 might contain a high-level view of all customers of a business, while\n Datatset #2  contains a lifetime history of orders for a company.\nUnsurprisingly, the customers in Dataset #1 appear in Dataset x#2, as any\nbusiness' orders are made by customers.\n\nWelcome to Relational Databases\nWhat we just described is the core foundation for relational databases  which\nhave been running at the core of businesses since the 1970s. Starting with\nfamiliar names like MySQL,  Oracle, and Postgres,  the concept of maintaining\nmultiple -related- tables of data are the bare minimum technology stack for any\ncompany, regardless of what said company does.\n\nWhile our example of Datasets #1 and #2  can be thought of as isolated tables,\nthe process of 'joining' them (in SQL terms) or 'merging' them (in Pandas terms) \n is  trivial. What's more, we can do far more than with JOINS (or merges) than\nsimply combining our data into a single set.\n\nEnter The Panda\nPython happens to have an obscenely popular library for performing SQL-like\nlogic, dubbed Pandas. If it remains unclear as to what Pandas is, just remember:\n Databases are basically Excel spreadsheets are basically an interface for\nPandas. The technicality of that explanation may be horrendous to those who\nunderstand the differences, but the fundamental truth remains: we're dealing\nwith information, inside of cells, on a two-dimensional grid. When you hear the\nnext idiot spew a catch phrase like \"data is the new oil\", the \"data\" they're\nreferring to is akin to that sick Excel sheet you made at work.\n\nScenario: Finding Mismatches in Data\nThis scenario actually stems from a real-life example which, sure enough, was my\nfirst encounter with Pandas. One could argue I owe much 0f my data career to a\n3am Google Hangout with Snkia.\n\nIn our scenario, our company has signed up for a very expensive software product\nwhich charges by individual license. To our surprise, the number of licenses for\nthis software totaled over 1000  seats!  After giving this data a quick glance,\nhowever, it's clear that many of these employees have actually been terminated,\nthus resulting in unspeakable loss in revenue. \n\nThe good news is we have another dataset called active employees (aka: employees\nwhich have not been terminated... yet). So, how do we use these two sets of data\nto determine which software licenses are valid? First, let's look at the types \nof ways we can merge data in Pandas.\n\nTerminology\nMERGE\nSets of data can be merged in a number of ways. Merges can either be used to\nfind similarities in two Dataframes and merge associated information, or may be\nentirely non-destructive in the way that two sets of data are merged.\n\nKEY\nIn many cases (such as the one in this tutorial) you'd likely want to merge two\nDataframes based on the value of a key. A key is the authoritative column by\nwhich the Dataframes will be merged. When merging Dataframes in this way, keys\nwill stay in tact as an identifier while the values of columns in the same row\nassociated to that key.\n\nThis type of merge can be used when two Dataframes hold differing fields for\nsimilar rows. If Dataframe 1 contains the phone numbers of customers by name,\nand Dataframe 2 contains emails of a similar grouping of people, these two may\nbe merged to create a single collection of data with all of this information.\n\nAXIS\nA parameter of pandas functions which determines whether the function should be\nrun against a Dataframe's columns or rows. An axis of 0 determines that the\naction will be taken on a per-row basis, where an axis of 1 denotes column.\n\nFor example, performing a drop with axis 0 on key X will drop the row where\nvalue of a cell is equal to X.\n\nLEFT/RIGHT MERGE\nAn example of a left/right merge can be seen below:\n\nJoin on keys found in left Dataframe.The two data frames above hold similar keys\nwith different associated information per axis, thus the result is a combination\nof these two Dataframes where the keys remain intact.\n\n\"Left\" or \"right\" refer to the left or right Dataframes above. If the keys from\nboth Dataframes do not match 1-to-1, specifying a left/right merge determines\nwhich Dataframe's keys will be considered the authority to be preserved in the\nmerge.\n\nJoin on keys found in right Dataframe.INNER MERGE\nAn inner merge will merge two Dataframes based on overlap of values between keys\nin both Dataframes:\n\nJoin on keys found in right Dataframe.OUTER MERGE\nAn outer merge will preserve the most data by not dropping keys which are\nuncommon to both Dataframes. Keys which exist in a single Dataframe will be\nadded to the resulting Dataframe, with empty values populated for any columns\nbrought in by the other Dataframe:\n\nBack to our Scenario: Merging Two Dataframes via Left Merge\nLet's get it going. Enter the iPython shell.\n\nImport Pandas and read both of your CSV files.\n\nimport pandas as pd\n\ndf = pd.read_csv(\"csv1.csv\")  \ndf2 = pd.read_csv(\"csv2.csv\")\n\n\nThe above opens the CSVs as Dataframes recognizable by pandas.\nNext, we'll merge the two CSV files.\n\nHow  specifies the type of merge, and on  specifies the column to merge by\n(key). The key must be present in both Dataframes.\n\nFor the purpose of this exercise we'll be merging left, as that is the CSV which\ncontains the keys we'd like to maintain.\n\nmergedDF = df2.merge(df, how=“left”, on=\"email\")\n\nprint(mergedDF)\n\n\nThis should return a dataset of all common rows, with columns from both CSVs\nincluded in the merge.\n\nScenario 2: Missing Data\nBefore we go, let's toss in another scenario for good measure.\n\nThis time around we have two datasets which should actually probably be a single\ndataset. Dataset #1  contains all customers once again, but for some reason, \nDataset #1  contains email address where set Dataset #2  does not. Similarly, \nDataset #2  contains addresses which are  missing in Dataset #1. We assume there\nis no reason to keep these sets of data isolated other than human error.\n\nIn the case where we are confident that employees exist in both datasets but\ncontain different information, performing an inner  merge will join these two\nsets by a key such as customer ID or email. If all goes well, the final dataset\nshould equal the same number of rows found in both Datasets #1 and #2.\n\nDocumentation\nFor more on merging, check out the official Pandas documentation here\n[https://pandas.pydata.org/pandas-docs/stable/merging.html].","html":"<style>\n    img {\n        border: 0 !important;\n    }\n </style>   <p>Let's say you have two obscenely large sets of data. </p><p>These sets of data contain information on a similar topic, such as customers. <strong>Dataset #1 </strong>might contain a high-level view of all customers of a business, while <strong>Datatset #2</strong> contains a lifetime history of orders for a company. Unsurprisingly, the customers in Dataset #1 appear in Dataset x#2, as any business' orders are made by customers.</p><h2 id=\"welcome-to-relational-databases\">Welcome to Relational Databases</h2><p>What we just described is the core foundation for <em>relational databases</em> which have been running at the core of businesses since the 1970s. Starting with familiar names like <strong>MySQL</strong>,<strong> Oracle</strong>, and <strong>Postgres,</strong> the concept of maintaining multiple -<em>related- </em>tables of data are the bare minimum technology stack for any company, regardless of what said company does.</p><p>While our example of <strong>Datasets #1 and #2</strong> can be thought of as isolated tables, the process of 'joining' them <em>(in SQL terms) </em>or 'merging' them <em>(in Pandas terms)</em> is  trivial. What's more, we can do far more than with JOINS (or merges) than simply combining our data into a single set.</p><h3 id=\"enter-the-panda\">Enter The Panda</h3><p>Python happens to have an obscenely popular library for performing SQL-like logic, dubbed <strong>Pandas. </strong>If it remains unclear as to what Pandas is, just remember: <em>Databases are basically Excel spreadsheets are basically an interface for Pandas</em>. The technicality of that explanation may be horrendous to those who understand the differences, but the fundamental truth remains: we're dealing with information, inside of cells, on a two-dimensional grid. When you hear the next idiot spew a catch phrase like <em>\"data is the new oil\"</em>, the \"data\" they're referring to is akin to that sick Excel sheet you made at work.</p><h3 id=\"scenario-finding-mismatches-in-data\">Scenario: Finding Mismatches in Data</h3><p>This scenario actually stems from a real-life example which, sure enough, was my first encounter with Pandas. One could argue I owe much 0f my data career to a 3am Google Hangout with Snkia.</p><p>In our scenario, our company has signed up for a very expensive software product which charges by individual license. To our surprise, the number of licenses for this software totaled <strong>over 1000</strong> seats!<strong> </strong>After giving this data a quick glance, however, it's clear that many of these employees have actually been terminated, thus resulting in unspeakable loss in revenue. </p><p>The good news is we have another dataset called <em>active employees </em>(aka: employees which have not been terminated... yet). So, how do we use these two sets of data to determine which software licenses are valid? First, let's look at the <em>types</em> of ways we can merge data in Pandas.</p><h2 id=\"terminology\">Terminology</h2><h3 id=\"merge\">MERGE</h3><p>Sets of data can be merged in a number of ways. Merges can either be used to find similarities in two Dataframes and merge associated information, or may be entirely non-destructive in the way that two sets of data are merged.</p><h3 id=\"key\">KEY</h3><p>In many cases (such as the one in this tutorial) you'd likely want to merge two Dataframes based on the value of a key. A key is the authoritative column by which the Dataframes will be merged. When merging Dataframes in this way, keys will stay in tact as an identifier while the values of columns in the same row associated to that key.</p><p>This type of merge can be used when two Dataframes hold differing fields for similar rows. If Dataframe 1 contains the phone numbers of customers by name, and Dataframe 2 contains emails of a similar grouping of people, these two may be merged to create a single collection of data with all of this information.</p><h3 id=\"axis\">AXIS</h3><p>A parameter of pandas functions which determines whether the function should be run against a Dataframe's columns or rows. An axis of 0 determines that the action will be taken on a per-row basis, where an axis of 1 denotes column.</p><p>For example, performing a drop with axis 0 on key X will drop the row where value of a cell is equal to X.</p><h3 id=\"left-right-merge\">LEFT/RIGHT MERGE</h3><p>An example of a left/right merge can be seen below:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-4.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/pandasleftjoin.png\" class=\"kg-image\"><figcaption>Join on keys found in left Dataframe.</figcaption></figure><p>The two data frames above hold similar keys with different associated information per axis, thus the result is a combination of these two Dataframes where the keys remain intact.</p><p>\"Left\" or \"right\" refer to the left or right Dataframes above. If the keys from both Dataframes do not match 1-to-1, specifying a left/right merge determines which Dataframe's keys will be considered the authority to be preserved in the merge.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/pandasrightjoin.png\" class=\"kg-image\"><figcaption>Join on keys found in right Dataframe.</figcaption></figure><h3 id=\"inner-merge\">INNER MERGE</h3><p>An inner merge will merge two Dataframes based on overlap of values between keys in both Dataframes:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/pandasinnerjoin.png\" class=\"kg-image\"><figcaption>Join on keys found in right Dataframe.</figcaption></figure><h3 id=\"outer-merge\">OUTER MERGE</h3><p>An outer merge will preserve the most data by not dropping keys which are uncommon to both Dataframes. Keys which exist in a single Dataframe will be added to the resulting Dataframe, with empty values populated for any columns brought in by the other Dataframe:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/pandasouterjoin.png\" class=\"kg-image\"></figure><h2 id=\"back-to-our-scenario-merging-two-dataframes-via-left-merge\">Back to our Scenario: Merging Two Dataframes via Left Merge</h2><p>Let's get it going. Enter the iPython shell.</p><p>Import Pandas and read both of your CSV files.</p><pre><code class=\"language-python\">import pandas as pd\n\ndf = pd.read_csv(&quot;csv1.csv&quot;)  \ndf2 = pd.read_csv(&quot;csv2.csv&quot;)\n</code></pre>\n<p>The above opens the CSVs as Dataframes recognizable by pandas.<br>Next, we'll merge the two CSV files.</p><p><strong>How</strong> specifies the type of merge, and <strong>on</strong> specifies the column to merge by (key). The key must be present in both Dataframes.</p><p>For the purpose of this exercise we'll be merging left, as that is the CSV which contains the keys we'd like to maintain.</p><pre><code class=\"language-python\">mergedDF = df2.merge(df, how=“left”, on=&quot;email&quot;)\n\nprint(mergedDF)\n</code></pre>\n<p>This should return a dataset of all common rows, with columns from both CSVs included in the merge.</p><h2 id=\"scenario-2-missing-data\">Scenario 2: Missing Data</h2><p>Before we go, let's toss in another scenario for good measure.</p><p>This time around we have two datasets which should actually probably be a single dataset. <strong>Dataset #1</strong> contains all customers once again, but for some reason, <strong>Dataset #1</strong> contains email address where set <strong>Dataset #2</strong> does not. Similarly, <strong>Dataset #2</strong> contains addresses which are  missing in <strong>Dataset #1</strong>. We assume there is no reason to keep these sets of data isolated other than human error.</p><p>In the case where we are confident that employees exist in both datasets but contain different information, performing an <em>inner</em> merge will join these two sets by a key such as customer ID or email. If all goes well, the final dataset should equal the same number of rows found in both <strong>Datasets #1 and #2</strong>.</p><h2 id=\"documentation\">Documentation</h2><p>For more on merging, check out the official Pandas documentation <a href=\"https://pandas.pydata.org/pandas-docs/stable/merging.html\">here</a>.</p>","url":"https://hackersandslackers.com/merge-dataframes-with-pandas/","uuid":"d2c59476-d879-484c-b719-55f53b3d4980","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a0f7a3ce38d612cc8261316"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867362f","title":"Generating Tree Hierarchies with Treelib","slug":"creating-trees-in-treelib","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2017/11/tree7@2x.jpg","excerpt":"Using Python to visualize file hierarchies as trees.","custom_excerpt":"Using Python to visualize file hierarchies as trees.","created_at_pretty":"17 November, 2017","published_at_pretty":"17 November, 2017","updated_at_pretty":"28 March, 2019","created_at":"2017-11-17T15:45:10.000-05:00","published_at":"2017-11-17T15:56:40.000-05:00","updated_at":"2019-03-28T05:02:39.000-04:00","meta_title":"Tree Hierarchies with Treelib | Hackers and Slackers","meta_description":"Treelib is a Python library that allows you to create a visual tree hierarchy: a simple plaintext representation of parent-child relationships.","og_description":"Treelib is a Python library that allows you to create a visual tree hierarchy: a simple plaintext representation of parent-child relationships.","og_image":"https://hackersandslackers.com/content/images/2017/11/tree7@2x.jpg","og_title":"Tree Hierarchies with Treelib","twitter_description":"Treelib is a Python library that allows you to create a visual tree hierarchy: a simple plaintext representation of parent-child relationships.","twitter_image":"https://hackersandslackers.com/content/images/2017/11/tree7@2x.jpg","twitter_title":"Tree Hierarchies with Treelib","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"The first part of understanding any type of software is taking a glance at its\nfile structure. It may seem like an outlandish and redundant statement to make\nto a generation who grew up on GUIs. GitHub is essentially no more than a GUI\nfor Git, so it’s unsurprisingly that one of the largest company to follow a\nsimilar business model recently bought Github for millions. \n\nAll that said, a question remains: how do we being to understand closed source\napplications? If we can’t see the structure behind an app, I suppose we’ll have\nto build this model ourselves.\n\nTreelib [https://treelib.readthedocs.io/en/latest/]  is a Python library that\nallows you to create a visual tree hierarchy: a simple plaintext representation\nof parent-child relationships.\n\nAside from scraping and mapping the intellectual property of others, Treelib\ncomes in handy in situations where we have access to flat information (like a\ndatabase table) where rows actually relate to one another (such as monolithic\ncontent-heavy site).\n\nTreelib prints results like this: \n\nHarry\n├── Bill\n│   └── n1\n│       ├── n2\n│       └── n3\n└── Jane\n    ├── Diane\n    │   └── Mary\n    └── Mark \n\n\nIt’s is a simple library, and only requires knowledge of a few lines of code in\norder to be used effectively. What’s more, we’re not simply spitting out flat\nuseless data; we're storing these node relationships in memory. If needed, the\ntrees we build can be modified or used for other the future.\n\nWhere da Treez At?\nInstall the Treelib package:\n\npip install treelib\n\n\nIn your project, import Treelib:\n\n# trees.py\nimport from treelib import Node, Tree\n\n\nCreate a Tree with a Parent Node\nThe first step in utilizing Treelib is to create a tree object. We need to give\nour tree a name - this is essentially creating the top-level node that all other\nnodes will stem from. \n\nIn createNode(x, y), X is the value which will be displayed in the node, while Y\nis the unique identifier for that node. Children will be added to this parent\nnode by referencing the unique identifier.\n\nNote that in trees created with TreeLib, unique identifiers may only occur once.\nTherefore it is good to follow a sort of GUI system for identifying nodes.\n\n# tree.py\n\n# Create tree object\ntree = Tree() \n\n# Create the base node\ntree.create_node(\"Confluence\", \"confluence\") \n\n\nCreate Child Nodes\nThe last necessary part of creating a tree is, of course, populating the\nresulting children.\n\nWe will once again use create_node to add additional nodes, but these nodes will\nbe associated with parents via parent=”x”. This will locate existing nodes in\nthe tree by ID and associate these new nodes to that parent. This is why IDs\nmust be unique for each node in the tree.\n\n# tree.py\ntree.create_node(spaceName, id, parent=\"confluence\")\n\n\nView the Tree\nFinally, you'll want to view the fruits of your labor:\n\nprint(tree.show())\n\n\nWay to go Johnny Appleseed, that’s pretty much the gist of it. There are\nadditional features in the way Trees can be parse, and the way that nodes store\nadditional data.\n\nCheck the official documentation [https://treelib.readthedocs.io/en/latest/] \nfor a full list of features.\n\nBonus Round\nIf all you care about is printing the file structure of a current directory with\nzero interest in working with the actual data, you’re in luck (at least on Mac,\nhell if I know anything about Windows).\n\nUnix systems come with a package named tree  which does just what we want. On\nMac OSX, we can install tree  using Homebrew:\n\n$ brew install tree\n\n\nGo ahead and explore the various features of tree, such as writing to files or\neven doing so on a schedule. For now, here's some basic usage:\n\n$ tree -v -L 1 --charset utf-8","html":"<p>The first part of understanding any type of software is taking a glance at its file structure. It may seem like an outlandish and redundant statement to make to a generation who grew up on GUIs. GitHub is essentially no more than a GUI for Git, so it’s unsurprisingly that one of the largest company to follow a similar business model recently bought Github for millions. </p><p>All that said, a question remains: how do we being to understand closed source applications? If we can’t see the structure behind an app, I suppose we’ll have to build this model ourselves.</p><p><strong><a href=\"https://treelib.readthedocs.io/en/latest/\">Treelib</a></strong> is a Python library that allows you to create a visual tree hierarchy: a simple plaintext representation of parent-child relationships.</p><p>Aside from scraping and mapping the intellectual property of others, Treelib comes in handy in situations where we have access to flat information (like a database table) where rows actually relate to one another (such as monolithic content-heavy site).</p><p>Treelib prints results like this: </p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">Harry\n├── Bill\n│   └── n1\n│       ├── n2\n│       └── n3\n└── Jane\n    ├── Diane\n    │   └── Mary\n    └── Mark \n</code></pre>\n<!--kg-card-end: markdown--><p>It’s is a simple library, and only requires knowledge of a few lines of code in order to be used effectively. What’s more, we’re not simply spitting out flat useless data; we're storing these node relationships in memory. If needed, the trees we build can be modified or used for other the future.</p><h2 id=\"where-da-treez-at\">Where da Treez At?</h2><p>Install the Treelib package:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">pip install treelib\n</code></pre>\n<!--kg-card-end: markdown--><p>In your project, import Treelib:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># trees.py\nimport from treelib import Node, Tree\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"create-a-tree-with-a-parent-node\">Create a Tree with a Parent Node</h3><p>The first step in utilizing Treelib is to create a tree object. We need to give our tree a name - this is essentially creating the top-level node that all other nodes will stem from. </p><p>In createNode(x, y), X is the value which will be displayed in the node, while Y is the unique identifier for that node. Children will be added to this parent node by referencing the unique identifier.</p><p>Note that in trees created with TreeLib, unique identifiers may only occur once. Therefore it is good to follow a sort of GUI system for identifying nodes.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># tree.py\n\n# Create tree object\ntree = Tree() \n\n# Create the base node\ntree.create_node(&quot;Confluence&quot;, &quot;confluence&quot;) \n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"create-child-nodes\">Create Child Nodes</h2><p>The last necessary part of creating a tree is, of course, populating the resulting children.</p><p>We will once again use create_node to add additional nodes, but these nodes will be associated with parents via parent=”x”. This will locate existing nodes in the tree by ID and associate these new nodes to that parent. This is why IDs must be unique for each node in the tree.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># tree.py\ntree.create_node(spaceName, id, parent=&quot;confluence&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"view-the-tree\">View the Tree</h3><p>Finally, you'll want to view the fruits of your labor:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">print(tree.show())\n</code></pre>\n<!--kg-card-end: markdown--><p>Way to go Johnny Appleseed, that’s pretty much the gist of it. There are additional features in the way Trees can be parse, and the way that nodes store additional data.</p><p>Check the <a href=\"https://treelib.readthedocs.io/en/latest/\">official documentation</a> for a full list of features.</p><h2 id=\"bonus-round\">Bonus Round</h2><p>If all you care about is printing the file structure of a current directory with zero interest in working with the actual data, you’re in luck (at least on Mac, hell if I know anything about Windows).</p><p>Unix systems come with a package named <strong>tree</strong> which does just what we want. On Mac OSX, we can install <strong>tree</strong> using Homebrew:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ brew install tree\n</code></pre>\n<!--kg-card-end: markdown--><p>Go ahead and explore the various features of tree, such as writing to files or even doing so on a schedule. For now, here's some basic usage:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ tree -v -L 1 --charset utf-8\n</code></pre>\n<!--kg-card-end: markdown-->","url":"https://hackersandslackers.com/creating-trees-in-treelib/","uuid":"f0c176ee-c88a-443c-a7b7-b5c5e7c5b9f7","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a0f4a56e38d612cc826130d"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867363f","title":"Another \"Intro to Data Analysis in Python Using Pandas\" Post","slug":"intro-to-data-analysis-in-python-using-pandas","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/intropandas-1-4@2x.jpg","excerpt":"Obligatory Pandas tutorial by a questionably qualified stranger.","custom_excerpt":"Obligatory Pandas tutorial by a questionably qualified stranger.","created_at_pretty":"19 April, 2018","published_at_pretty":"16 November, 2017","updated_at_pretty":"10 April, 2019","created_at":"2018-04-18T21:18:27.000-04:00","published_at":"2017-11-16T10:52:00.000-05:00","updated_at":"2019-04-10T10:33:17.000-04:00","meta_title":"Intro to Data Analysis in Python Using Pandas | Hackers and Slackers","meta_description":"Obligatory introduction to Pandas by a questionably qualified stranger. Learn the anatomy of a DataFrame, how to load data, and selecting subsets of data.","og_description":"Obligatory introduction to Pandas by a questionably qualified stranger. Learn the anatomy of a DataFrame, how to load data, and selecting subsets of data.","og_image":"https://hackersandslackers.com/content/images/2019/02/intropandas-1-4@2x.jpg","og_title":"Intro to Data Analysis in Python Using Pandas","twitter_description":"Obligatory introduction to Pandas by a questionably qualified stranger. Learn the anatomy of a DataFrame, how to load data, and selecting subsets of data.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/intropandas-1-4@2x.jpg","twitter_title":"Intro to Data Analysis in Python Using Pandas","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"#Data Analysis with Pandas","slug":"data-analysis-pandas","description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pandasseries-1.jpg","meta_description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","meta_title":"Data Analysis with Pandas","visibility":"internal"},{"name":"Data Analysis","slug":"data-analysis","description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","feature_image":null,"meta_description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","meta_title":"Data Analysis | Hackers and Slackers","visibility":"public"}],"plaintext":"Let’s face it: the last thing the world needs is another “Intro to Pandas” post.\nAnybody strange enough to read this blog surely had the same reaction to\ndiscovering Pandas as I did: a manic euphoria that can only be described as love\nat first sight. We wanted to tell the world, and that we did. A lot. Yet here I\nam, about to helplessly sing cliche praises one more time. \n\nI’m a prisoner of circumstance here. As it turns out, the vast (and I mean vast)\nmajority of our fans have a raging Pandas addiction. They come to our humble\nmom-and-pop shop here at Hackers and Slackers foaming at the mouth, going on\nraging benders for all Pandas-related content. If I had half a brain, I’d rename\nthis site Pandas and Pandas  and delete all non-Pandas-related content. Talk\nabout cash money. \n\nAs a middle-ground, I’ve decided to do a bit of housekeeping. My previous “Intro\nto Pandas” post was an unflattering belligerent mess jotted into a Confluence\ninstance long ago during a Friday night  pregame. That mess snuck its way on to\nthis blog, and has gone unnoticed for a year now. I've decided that this\nprobably wasn't the best way to open up a series about the most influential\nPython library of all time. We're going to try this again... For the Pandas.\n\nIntro to Pandas Rereleased: in IMAX 8k 4D \nPandas is used to analyze and modify tabular data in Python. When we say\n“tabular data,” we mean any instance in life where data is represented in a\ntable format. Excel, SQL databases, shitty HTML tables.... they’ve all been the\nsame thing with different syntax this whole time. Pandas can achieve anything\nthat any other table can. \n\nIf you’re reasonably green to data analysis and are experiencing the \n“oh-my-God-all-data-professions-are-kinda-just-Excel”  realization as we speak,\nfeel free to take a moment. Great, that’s behind us now.\n\nThe Anatomy of a DataFrame\nTabular data in Pandas is referred to as a “DataFrame.” We can’t call everything \n “tables-” otherwise, our choice of vague terminology would grow horribly\nconfusing when we refer to data in different systems. Between you and me though,\nDataFrames are basically tables.\n\nSo how do we represent two-dimensional data via command line: a concept which\ninherently interprets and displays information one-dimensionally? \n\n\"Oh nothing, we think it's cute.\"DataFrames consist of individual parts which\nare easy-to-understand at face value. It’s the complexity of these things\ntogether, creating a sum greater than the whole of its parts, which fuels the\nseemingly endless power of DataFrames. If we want any  hope of contributing to\nthe field of Data Science, we need to not only understand the terminology but at\nleast be aware of core concepts of what a DataFrame is beneath the hood. This\nunderstanding is what separates engineers from Excel monkeys. \n\nEngineers\n1\nWinExcel Nerds\n0\nLoseParts of a DataFrame\nWere you expecting this post just to be a bunch of one-liners in Pandas? Good, I\nhope you're disappointed. Strap yourself in, we might actually learn something\ntoday. Class is now in session, baby. Let's break apart what makes a DataFrame,\npiece-by-piece:\n\nThe most basic description of any table would be a collection of columns and \nrows. Despite looking at a two-dimensional grid, columns are in fact very\ndifferent from rows. Unlike rows, all data in a column  typically abides by the\nsame data type. In the above example, any value saved in the startTime  column\nwill always be a time. Rows, on the other hand, are simply an entry- an instance\nof a \"thing\", where each thing is described by attributes stored horizontally\nacross columns.\n\nThis seems like really elementary stuff, but I mention it for a reason. By our\ndefinition, columns  are more pivotal to structuring a table than rows, because\neven empty columns have meaning, whereas an empty row with no columns will\nalways equal infinite nothingness. Rows are made up of values in columns, not\nthe other way around. Thus, columns in Pandas are actually their own type of\nobject called a Series. \n\n * Series' are objects native to Pandas (and Numpy) which refer to\n   one-dimensional sequences of data. Another example of a one-dimensional\n   sequence of data could be an array, but series' are much more than arrays:\n   they're a class of their own for many powerful reasons, which we'll see in a\n   moment.\n * Axis  refers to the 'direction' of a series, or in other words \"column\" or\n   \"row\". A series with an axis of 0  is a row, whereas a series with an axis of\n    1  is a column. \n * A series contains labels, which are given visual names for a row/column\n   specifying labels allows us to call upon any labeled series in the same way\n   we would access a value in a Python dictionary. For instance, accessing \n   dataframe['awayTeamName']  returns the entire column matching the header \n   \"awayTeamName\".\n * Every row and column has a numerical index. Most of the time, a row's label \n   will be equivalent to the row's index. While it's common practice to define\n   headers for columns, columns have indexes as well, which simply aren't shown.\n   In this regard, Series share an attribute with lists/arrays, in that they are\n   a collection of indexed values\n\nConsider the last two points: we just described a series to work the same way as\na Python dictionary, but also the same way as a Python list. That's right:\nseries' objects are like the biracial offspring of lists and dicts. We can\naccess any column by either its name or its index, and the same goes for rows.\nEven if we rip a column out from a DataFrame, each cell in that series will\nstill retain the row labels for every cell. This means we can say things like \nget me column #3, and then find me the value for whatever was in the row labeled\n\"Y\".  Of course, this works in the reverse as well. It's crazy how things get\nexponentially more powerful and complicated when we add entire dimensions, isn't\nit?\n\nLoading Data Into Pandas\nIf you've made it this far, you've earned the right to start getting hands-on.\nLuckily, Pandas has plenty of methods to load tabular data into DataFrames,\nregardless if you're using static files, SQL, or quirkier methods, Pandas has\nyou covered. Here are some of my favorite examples:\n\nimport pandas as pd\n\n# Reads a local CSV file.\ncsv_df = pd.read_csv('data.csv')\n\n# Similar to above\nexcel_df = pd.read_excel('data.xlsx')\n\n# Creating tabular data from non-tabular JSON\njson_df = pd.read_json('data.json')\n\n# Direct db access utilizing SQLAlchemy\nread_sql = read_sql('SELECT * FROM blah', conn=sqlalchemy_engine)\n\n# My personal ridiculous favorite: HTML table to DataFrame.\nread_html = read_html('examplePageWithTable.html')\n\n# The strength of Google BigQuery: already officially supported by Pandas\nread_gbq = read_gbq('SELECT * FROM test_dataset.test_table', projectid)\n\n\nAll of these achieve the same result of creating a DataFrame. No matter what\nhorrible data sources you may have been forced to inherit, Pandas is here to\nhelp. Pandas knows our pain. Pandas is love. Pandas is life.\n\nWith data loaded, let's see how we can apply our new knowledge of series'  to\ninteract with out data.\n\nFinding Data in Our Dataframe\nPandas has a method for finding a series by label, as well as a separate method\nfor finding a series by index. These methods are .iloc  and .loc, respectively.\nLet's say our DataFrame from the example above is stored as a variable named \nbaseball_df. To get the values of a column by name, we would do the following:\n\nbaseball_df = baseball_df.iloc['homeTeamName']\nprint(baseball_df)\n\n\nThis would return the following:\n\n0   Cubs\n1   Indians\n2   Padres\n3   Diamondbacks\n4   Giants\n5   Blue Jays\n6   Reds\n7   Cubs\n8   Rockies\n9   Yankees\nName: homeTeamName, dtype: object\n\n\nThat's our column! We can see the row labels being listed alongside each row's\nvalue. Told ya so. Getting a column will also return the column's dtype, or data\ntype. Data types can be set on columns explicitly. If they aren't, Pandas will\ngenerally either default to detecting that the data in the column is a float \n(returned for any column which only holds numerical values, despite number of\ndecimal points) or an 'object', which is a fancy catch-all meaning \"fuck if I\nknow, there's letters and shit in there, it could be anything probably.\" Pandas\ndoesn't try hard on its own to discern the types of data in each field.\n\nIf you're thinking ahead, you might see a looming conflict of interest with iloc\n. Since we've established that columns and rows are the same, and we're\naccessing series' based on criteria that is met by both  columns and rows (every\ntable has a first row and a first column), how does Pandas know what we want\nwith .loc()? Short answer: It doesn't, so it just returns both! \n\nbaseball_df = baseball_df.loc[3]\nprint(baseball_df)\n\n\n    homeTeamName    awayTeamName   startTime      duration_minutes\n0   Cubs            Reds           18:20:00 UTC   188\n1   Indians         Astros         18:20:00 UTC   194\n2   Padres          Giants         18:20:00 UTC   185\n3   Diamondbacks    Brewers        18:20:00 UTC   211\n\n\nAhhh, a 4x4 grid! This does, in fact, satisfy what we asked for- albiet in a\nclever, intentional way. \"Clever and intentional\"  is actually a great way to\ndescribe Pandas as a library. This combination of ease and power is what makes\nPandas so magnetic to curious newcomers. \n\nWant another example? How about leveraging the unique attributes of series'  to\nsplice DataFrames as though they were arrays?\n\nsliced_df = df.loc['homeTeamName':'awayTeamName']\nprint(sliced_df)\n\n\n    homeTeamName    awayTeamName\n0   Cubs            Reds        \n1   Indians         Astros      \n2   Padres          Giants      \n3   Diamondbacks    Brewers     \n\n\n...Did we just do that? We totally did. We were able to slice a two-dimensional\nset of data by using the same syntax that we'd used to slice arrays, thanks to\nthe power of the series object.\n\nWelcome to the Club\nThere are a lot more entertaining, mind-blowing ways to introduce people to\nPandas. If our goal had been sheer amusement, we would have leveraged the\ncookie-cutter route to Pandas tutorials: overloading readers with Pandas\n\"tricks\" displaying immense power in minimal effort. Unfortunately, we took the\napplicable approach to actually retaining information. Surely this model of\n\"informational and time consuming\" will beat out \"useless but instantly\ngratifying,\" right? RIGHT? \n\nWhatever. I’ll schedule the Pandas and Pandas rebrand for next week. From now on\nwhen people want that quick fix, you can call me Pablo Escobar. Join us next\ntime when we use Pandas data analysis to determine which private Caribbean\nisland offers the best return on investment with all the filthy money we’ll\nmake.\n\nHint: it’s definitely not the Fyre festival one.","html":"<p>Let’s face it: the last thing the world needs is another “<strong>Intro to Pandas</strong>” post. Anybody strange enough to read this blog surely had the same reaction to discovering Pandas as I did: a manic euphoria that can only be described as love at first sight. We wanted to tell the world, and that we did. A lot. Yet here I am, about to helplessly sing cliche praises one more time. </p><p>I’m a prisoner of circumstance here. As it turns out, the vast (and I mean <em><strong>vast</strong></em>) majority of our fans have a raging Pandas addiction. They come to our humble mom-and-pop shop here at <strong>Hackers and Slackers </strong>foaming at the mouth, going on raging benders for all Pandas-related content. If I had half a brain, I’d rename this site <strong>Pandas and Pandas</strong> and delete all non-Pandas-related content. Talk about cash money. </p><p>As a middle-ground, I’ve decided to do a bit of housekeeping. My previous “Intro to Pandas” post was an unflattering belligerent mess jotted into a Confluence instance long ago during a <a>Friday night</a> pregame. That mess snuck its way on to this blog, and has gone unnoticed for a year now. I've decided that this probably wasn't the best way to open up a series about the most influential Python library of all time. We're going to try this again... For the Pandas.</p><h2 id=\"intro-to-pandas-rereleased-in-imax-8k-4d\">Intro to Pandas Rereleased: in IMAX 8k 4D </h2><p>Pandas is used to analyze and modify tabular data in Python. When we say “tabular data,” we mean any instance in life where data is represented in a table format. Excel, SQL databases, shitty HTML tables.... they’ve all been the same thing with different syntax this whole time. Pandas can achieve anything that any other table can. </p><p>If you’re reasonably green to data analysis and are experiencing the <em>“oh-my-God-all-data-professions-are-kinda-just-Excel”</em> realization as we speak, feel free to take a moment. Great, that’s behind us now.</p><h2 id=\"the-anatomy-of-a-dataframe\">The Anatomy of a DataFrame</h2><p>Tabular data in Pandas is referred to as a “DataFrame.” We can’t call <em>everything</em> “tables-” otherwise, our choice of vague terminology would grow horribly confusing when we refer to data in different systems. Between you and me though, DataFrames are basically tables.</p><p>So how do we represent two-dimensional data via command line: a concept which inherently interprets and displays information one-dimensionally? </p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/moon.jpg\" class=\"kg-image\"><figcaption>\"Oh nothing, we think it's cute.\"</figcaption></figure><!--kg-card-end: image--><p>DataFrames consist of individual parts which are easy-to-understand at face value. It’s the complexity of these things together, creating a sum greater than the whole of its parts, which fuels the seemingly endless power of DataFrames. If we want <em>any</em> hope of contributing to the field of Data Science, we need to not only understand the terminology but <em>at least </em>be aware of core concepts of what a DataFrame is beneath the hood. This understanding is what separates engineers from Excel monkeys. </p><!--kg-card-begin: html--><div class=\"scoreboard\">\n\t<!-- Score Header -->\n\t<div class=\"score-header\">\n\t\t<!-- Background -->\n\t\t<div class=\"score-header-background\">\n\t\t\t<div class=\"score-header-background__left\"></div>\n\t\t\t<div class=\"score-header-background__right\"></div>\n\t\t\t<div class=\"score-header-background__logo\"></div>\n\t\t</div>\n\t\t<!-- Foreground -->\n\t\t<div class=\"score-header-foreground\">\n\t\t\t<div class=\"score-header-foreground__left\">\n\t\t\t\t<h1 class=\"score-header-foreground__title\">Engineers</h1>\n\t\t\t\t<h2 class=\"score-header-foreground__score\">1</h2>\n\t\t\t\t<span class=\"score-header-foreground__win\">Win</span>\n\t\t\t</div>\n\t\t\t<div class=\"score-header-foreground__right\">\n\t\t\t\t<h1 class=\"score-header-foreground__title\">Excel Nerds</h1>\n\t\t\t\t<h2 class=\"score-header-foreground__score\">0</h2>\n\t\t\t\t<span class=\"score-header-foreground__win\">Lose</span>\n\t\t\t</div>\n\t\t</div>\n\t</div>\n</div><!--kg-card-end: html--><h2 id=\"parts-of-a-dataframe\">Parts of a DataFrame</h2><p>Were you expecting this post just to be a bunch of one-liners in Pandas? Good, I hope you're disappointed. Strap yourself in, we might actually learn something today. Class is now in session, baby. Let's break apart what makes a DataFrame, piece-by-piece:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/03/dataframe2.jpg\" class=\"kg-image\"></figure><!--kg-card-end: image--><p>The most basic description of any table would be a collection of <strong>columns </strong>and <strong>rows. </strong>Despite looking at a two-dimensional grid, columns are in fact very different from rows. Unlike rows, all data in a <em>column</em> typically abides by the same data type. In the above example, any value saved in the <strong>startTime</strong> column will always be a <strong>time</strong>. Rows, on the other hand, are simply an entry- an instance of a \"thing\", where each thing is described by attributes stored horizontally across columns.</p><p>This seems like really elementary stuff, but I mention it for a reason. By our definition, <em>columns</em> are more pivotal to structuring a table than rows, because even empty columns have meaning, whereas an empty row with no columns will always equal infinite nothingness. <strong>Rows are made up of values in columns, not the other way around. </strong> Thus, columns in Pandas are actually their own type of object called a <strong>Series</strong>. </p><ul><li><strong>Series</strong>' are objects native to Pandas (and Numpy) which refer to one-dimensional sequences of data. Another example of a one-dimensional sequence of data could be an <strong><em>array</em></strong><em>, </em>but series' are much more than arrays: they're a class of their own for many powerful reasons, which we'll see in a moment.</li><li><strong>Axis</strong> refers to the 'direction' of a series, or in other words \"column\" or \"row\". A series with an axis of <code>0</code> is a <em>row</em>, whereas a series with an axis of <code>1</code> is a <em>column</em>. </li><li>A series contains <strong>labels</strong>, which are given visual names for a row/column specifying labels allows us to call upon any labeled series in the same way we would access a value in a Python dictionary. For instance, accessing <code>dataframe['awayTeamName']</code> returns the entire column matching the header <em>\"awayTeamName\"</em>.</li><li>Every row and column has a numerical <strong>index. </strong>Most of the time, a row's <strong>label</strong> will be equivalent to the row's <strong>index. </strong>While it's common practice to define headers for columns, columns have indexes as well, which simply aren't shown. In this regard, Series share an attribute with lists/arrays, in that they are a collection of indexed values</li></ul><p>Consider the last two points: we just described a series to work the same way as a Python dictionary, but also the same way as a Python list. That's right: series' objects are like the biracial offspring of lists and dicts. We can access any column by either its name or its index, and the same goes for rows. Even if we rip a column out from a DataFrame, each cell in that series will still retain the row labels for every cell. This means we can say things like <strong>get me column #3, and then find me the value for whatever was in the row labeled \"Y\".</strong> Of course, this works in the reverse as well. It's crazy how things get exponentially more powerful and complicated when we add entire dimensions, isn't it?</p><h2 id=\"loading-data-into-pandas\">Loading Data Into Pandas</h2><p>If you've made it this far, you've earned the right to start getting hands-on. Luckily, Pandas has plenty of methods to load tabular data into DataFrames, regardless if you're using static files, SQL, or quirkier methods, Pandas has you covered. Here are some of my favorite examples:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Reads a local CSV file.\ncsv_df = pd.read_csv('data.csv')\n\n# Similar to above\nexcel_df = pd.read_excel('data.xlsx')\n\n# Creating tabular data from non-tabular JSON\njson_df = pd.read_json('data.json')\n\n# Direct db access utilizing SQLAlchemy\nread_sql = read_sql('SELECT * FROM blah', conn=sqlalchemy_engine)\n\n# My personal ridiculous favorite: HTML table to DataFrame.\nread_html = read_html('examplePageWithTable.html')\n\n# The strength of Google BigQuery: already officially supported by Pandas\nread_gbq = read_gbq('SELECT * FROM test_dataset.test_table', projectid)\n</code></pre>\n<!--kg-card-end: markdown--><p>All of these achieve the same result of creating a DataFrame. No matter what horrible data sources you may have been forced to inherit, Pandas is here to help. Pandas knows our pain. Pandas is love. Pandas is life.</p><p>With data loaded, let's see how we can apply our new knowledge of <strong>series'</strong> to interact with out data.</p><h2 id=\"finding-data-in-our-dataframe\">Finding Data in Our Dataframe</h2><p>Pandas has a method for finding a series by label, as well as a separate method for finding a series by index. These methods are <code>.iloc</code> and <code>.loc</code>, respectively. Let's say our DataFrame from the example above is stored as a variable named <code>baseball_df</code>. To get the values of a column by name, we would do the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">baseball_df = baseball_df.iloc['homeTeamName']\nprint(baseball_df)\n</code></pre>\n<!--kg-card-end: markdown--><p>This would return the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">0   Cubs\n1   Indians\n2   Padres\n3   Diamondbacks\n4   Giants\n5   Blue Jays\n6   Reds\n7   Cubs\n8   Rockies\n9   Yankees\nName: homeTeamName, dtype: object\n</code></pre>\n<!--kg-card-end: markdown--><p>That's our column! We can see the row labels being listed alongside each row's value. Told ya so. Getting a column will also return the column's <strong>dtype</strong>, or <em>data type</em>. Data types can be set on columns explicitly. If they aren't, Pandas will generally either default to detecting that the data in the column is a <strong>float</strong> (returned for any column which only holds numerical values, despite number of decimal points) or an '<strong>object'</strong>, which is a fancy catch-all meaning \"fuck if I know, there's letters and shit in there, it could be anything probably.\" Pandas doesn't try hard on its own to discern the types of data in each field.</p><p>If you're thinking ahead, you might see a looming conflict of interest with <code>iloc</code>. Since we've established that columns and rows are the same, and we're accessing series' based on criteria that is met by <em>both</em> columns and rows (every table has a first row and a first column), how does Pandas know what we want with <code>.loc()</code>? Short answer: It doesn't, so it just returns both! </p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">baseball_df = baseball_df.loc[3]\nprint(baseball_df)\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">    homeTeamName    awayTeamName   startTime      duration_minutes\n0   Cubs            Reds           18:20:00 UTC   188\n1   Indians         Astros         18:20:00 UTC   194\n2   Padres          Giants         18:20:00 UTC   185\n3   Diamondbacks    Brewers        18:20:00 UTC   211\n</code></pre>\n<!--kg-card-end: markdown--><p>Ahhh, a 4x4 grid! This does, in fact, satisfy what we asked for- albiet in a clever, intentional way. \"<strong>Clever and intentional\"</strong> is actually a great way to describe Pandas as a library. This combination of ease and power is what makes Pandas so magnetic to curious newcomers. </p><p>Want another example? How about leveraging the unique attributes of <strong>series'</strong> to splice DataFrames as though they were arrays?</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">sliced_df = df.loc['homeTeamName':'awayTeamName']\nprint(sliced_df)\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">    homeTeamName    awayTeamName\n0   Cubs            Reds        \n1   Indians         Astros      \n2   Padres          Giants      \n3   Diamondbacks    Brewers     \n</code></pre>\n<!--kg-card-end: markdown--><p>...Did we just do that? We totally did. We were able to slice a two-dimensional set of data by using the same syntax that we'd used to slice arrays, thanks to the power of the series object.</p><h2 id=\"welcome-to-the-club\">Welcome to the Club</h2><p>There are a lot more entertaining, mind-blowing ways to introduce people to Pandas. If our goal had been sheer amusement, we would have leveraged the cookie-cutter route to Pandas tutorials: overloading readers with Pandas \"tricks\" displaying immense power in minimal effort. Unfortunately, we took the applicable approach to actually retaining information. Surely this model of \"informational and time consuming\" will beat out \"useless but instantly gratifying,\" right? <em>RIGHT? </em></p><p>Whatever. I’ll schedule the <strong>Pandas and Pandas </strong>rebrand for next week. From now on when people want that quick fix, you can call me Pablo Escobar. Join us next time when we use Pandas data analysis to determine which private Caribbean island offers the best return on investment with all the filthy money we’ll make.</p><p>Hint: it’s definitely not the Fyre festival one.</p>","url":"https://hackersandslackers.com/intro-to-data-analysis-in-python-using-pandas/","uuid":"828b4a6f-e6f2-446f-b51e-64fe19e05ba0","page":false,"codeinjection_foot":null,"codeinjection_head":"<style>\n  *,\n  *::before,\n  *::after {\n    box-sizing: inherit;\n  }\n\n  .scoreboard {\n    margin: auto;\n    max-width: 980px;\n    box-shadow: 0 0 10px #b0bddd;\n  }\n\n  .score-header {\n    position: relative;\n    height: 74px;\n    overflow: hidden;\n  }\n\n  .score-header-background {\n    position: absolute;\n    display: flex;\n    height: 100%;\n    width: calc(100% + 63px + 4px);\n    left: -33.5px;\n  }\n\n  .score-header-background .score-header-background__left,\n  .score-header-background .score-header-background__right {\n    position: relative;\n    flex: 1 1 100%;\n    overflow: hidden;\n    border-bottom: 4px solid #fff;\n    transform: skewX(-40deg);\n  }\n\n  .score-header-background .score-header-background__left::before,\n  .score-header-background .score-header-background__right::before {\n    content: \"\";\n    position: absolute;\n    width: 100%;\n    height: 100%;\n    transform: skewX(40deg);\n  }\n\n  .score-header-background .score-header-background__left::after,\n  .score-header-background .score-header-background__right::after {\n    content: \"\";\n    position: absolute;\n    width: 100%;\n    height: 100%;\n    opacity: 0.35;\n    background: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeAgMAAABGXkYxAAAACVBMVEUAAAD///8AAABzxoNxAAAAAnRSTlMAAHaTzTgAAAAlSURBVHhe3cmhEQAACMPAjIhhv+pOiahAsAGvchc6asMhjvdrAFlGOgM9VYUmAAAAAElFTkSuQmCC');\n  }\n\n  .score-header-background .score-header-background__left {\n    margin-right: 5px;\n    border-color: #19d9ff;\n  }\n\n  .score-header-background .score-header-background__left::before {\n    right: -31.5px;\n    background: linear-gradient(to left, #19d9ff 31.5px, #a9f6ff 60%);\n  }\n\n  .score-header-background .score-header-background__right {\n    margin-left: 5px;\n    border-color: #ff1979;\n  }\n\n  .score-header-background .score-header-background__right::before {\n    left: -31.5px;\n    background: linear-gradient(to right, #ff1979 31.5px, #ffb5ee 60%);\n  }\n\n  .score-header-background .score-header-background__logo {\n    position: absolute;\n    top: 0;\n    right: 0;\n    bottom: 0;\n    left: 0;\n    margin: auto;\n    width: 60px;\n    height: 60px;\n    border: 5px solid #ffffff;\n    border-radius: 100%;\n    background-color: rgba(111, 77, 238, 0.51);\n    background-image: url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiP…A3NDcsNTQ2LjMgDQoJCQkJCQkJIi8+DQoJCTwvZz4NCgk8L2c+DQo8L2c+DQo8L3N2Zz4NCg==);\n  }\n\n  .score-header-foreground {\n    position: absolute;\n    display: flex;\n    height: 100%;\n    width: 100%;\n  }\n\n  .score-header-foreground .score-header-foreground__left,\n  .score-header-foreground .score-header-foreground__right {\n    display: flex;\n    margin: 0 20px;\n    flex: 1 1 100%;\n    align-items: baseline;\n  }\n\n  .score-header-foreground .score-header-foreground__left .score-header-foreground__title {\n    color: #fff;\n  }\n\n  .score-header-foreground .score-header-foreground__left .score-header-foreground__score {\n    margin-right: 20px;\n  }\n\n  .score-header-foreground .score-header-foreground__right {\n    flex-direction: row-reverse;\n    text-align: right;\n  }\n\n  .score-header-foreground .score-header-foreground__right .score-header-foreground__title {\n    color: #fff;\n  }\n\n  .score-header-foreground .score-header-foreground__right .score-header-foreground__score {\n    margin-left: 20px;\n  }\n\n  .score-header-foreground .score-header-foreground__title,\n  .score-header-foreground .score-header-foreground__score,\n  .score-header-foreground .score-header-foreground__win {\n    margin: 0 10px;\n    line-height: 69px;\n    text-transform: uppercase;\n  }\n\n  .score-header-foreground .score-header-foreground__title {\n    margin: 0;\n    flex: 1 1 auto;\n    font-size: 30px;\n  }\n\n  .score-header-foreground .score-header-foreground__score {\n    order: 1;\n    text-shadow: 0 0 4px rgba(255, 255, 255, 0.75), 0 0 8px rgba(255, 255, 255, 0.45);\n    font-size: 30px;\n    color: white;\n  }\n\n  .score-header-foreground .score-header-foreground__win {\n    font-size: 18px;\n    font-weight: 600;\n    font-family: 'TTNorms-Medium', sans-serif;\n    color: white;\n    color: #4a47a2;\n    mix-blend-mode: color-burn;\n  }\n\n  .player-list {\n    display: flex;\n    padding: 0;\n    flex-flow: column;\n    list-style: none;\n  }\n\n  .player-row {\n    display: flex;\n    margin: 20px 0;\n    flex: 1 1 auto;\n    align-items: center;\n  }\n\n  .player {\n    display: flex;\n    padding: 20px;\n    min-width: 0;\n    flex: 1 1 auto;\n    align-items: center;\n  }\n\n  .player.player--left {\n    padding-left: 20px;\n  }\n\n  .player.player--left .player__avatar {\n    margin-right: 20px;\n    border-color: #19d9ff;\n  }\n\n  .player.player--right {\n    padding-right: 20px;\n    text-align: right;\n    flex-flow: row-reverse;\n  }\n\n  .player.player--right .player__avatar {\n    margin-left: 20px;\n    border-color: #ff1979;\n  }\n\n  .player .player__avatar {\n    position: relative;\n    min-height: 60px;\n    min-width: 60px;\n    overflow: hidden;\n    border: 3px solid #fff;\n    border-radius: 100%;\n    background-color: #222;\n  }\n\n  .player .player__avatar::before {\n    content: \"\";\n    position: absolute;\n    left: 0;\n    width: 100%;\n    height: 100%;\n    opacity: 0.1;\n    background: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAA8CAMAAAANIilAAAABTVBMVEU7PUP////4+Pj7+/v29vZAQkj6+vpCRErx8fL+/v5BQ0lNT1T9/f3t7u5HSU/8/Pz09PRGSE5aW2BOUFY8PkRJSlB/gITk5eWqq64+QEWPkJSVlppoam5KTFHZ2tvDw8XBwsPa29zP0NGdnqH6+/vExMVVV1z+/v/LzMxRUlidn6HKy8zFxce3uLuVlpmBgYZSVFnz8/SvsLOUlZhkZmv5+flRU1jg4OFDRUrExMepqqyWl5uAgYXMzc7r6+xZWl/AwMKenqFjZWnn6OjBwcJ5en7U1dZ+gIPNzs8/QUbi4+Smp6pSU1lUVVuLjI/j5OWwsLNpam9BQ0hLTFK7vL7p6ep0dXmIio3LzM339/fi4+OrrK5cXmI9P0Wlpqny8/PLy8xzdHh6e3/ExMZVVlzs7e2hoqU+QEbR0tO4ubyHiIzs7O1FR01bXWLz8/PjR6/UAAABIklEQVR4Xu3UxW7FMBCGUU+Sy8xFZmZmZmZmhvdfVuqi9rTprf8uIlXKtz+yNGON+Ke5uQ30NQb/JoMlozGimtopD259DWH6yCxfRG1pGX1WFQVxNSkVYbbOUHF8G8JNUuJPN3NcAeEcx5UQtjgeQ6yHeBaCM8TzOoZP6zmOC6Rzjqch3M/xHIRbOG6FcBvH7RDuMFXb6RNQXSruFlg9MWl7X0EcfZM4Al+xQYmHBNqwxCMwLpY46ygen5B4ElpzOjFDapHZQm06v+AlXmBpeUWHrq6tk13GxubWLzS0Y9JPBXb38sjE/sEh5e3o+MSeJs/8pNHFpc1nvTJIr/D1t9Hf3JJ2d4J3/0D6WSGOkwYBPXL8REjPLwwXQNifcgK72MXv0xEfs26TMDAAAAAASUVORK5CYII=');\n    background-size: cover;\n  }\n\n  .player .player__username {\n    font-size: 24px;\n    text-overflow: ellipsis;\n    overflow: hidden;\n    white-space: nowrap;\n  }\n\n  .language {\n    font-size: 24px;\n  }\n\n  .language.language--html {\n    color: #f69c24;\n  }\n\n  .language.language--css {\n    color: #299bf7;\n  }\n\n  .language.language--js {\n    color: #ffce22;\n  }\n\n  @media (max-width:600px) {\n    .score-header-foreground__title {\n      margin: 0;\n      font-size: 16px;\n      height: fit-content;\n      width: fit-content;\n      /* display: block; */\n      text-shadow: #12183d 1px 1px 1px;\n      position: absolute;\n      bottom: 9px;\n    }\n\n    .score-header-foreground__left,\n    .score-header-foreground__right {\n      margin: 10px 11px 0;\n      display: block;\n      position: relative;\n    }\n\n    .score-header-foreground .score-header-foreground__right .score-header-foreground__score {\n          right: 10px;\n    }\n\n    .score-header-foreground .score-header-foreground__left, .score-header-foreground .score-header-foreground__right {\n          margin: 0 10px;\n          display: block;\n    }\n\n    .score-header-foreground__left .score-header-foreground__title {\n      left:0;\n      margin: 0;\n      font-size: 16px;\n      height: fit-content;\n      width: fit-content;\n      /* display: block; */\n      text-shadow: #12183d 1px 1px 1px;\n      position: absolute;\n      bottom: 9px;\n          line-height: 1;\n    }\n\n    .score-header-foreground__right .score-header-foreground__title {\n      right:0;\n      margin: 0;\n      font-size: 16px;\n      height: fit-content;\n      width: fit-content;\n      /* display: block; */\n      text-shadow: #12183d 1px 1px 1px;\n      position: absolute;\n      bottom: 9px;\n          line-height: 1;\n    }\n\n    .score-header-foreground .score-header-foreground__win {\n      font-size: 12px;\n      font-weight: 600;\n      font-family: 'TTNorms-Medium', sans-serif;\n      color: white;\n      color: #4a47a2;\n      mix-blend-mode: multiply;\n      position: absolute;\n      width: fit-content;\n      bottom: 32px;\n    }\n\n    .score-header-foreground__score {\n      padding: 0;\n      display: block;\n      position: absolute;\n      top: 2px;\n      padding: 0 !important;\n      margin: 0 !important;\n      line-height: 1 !important;\n      height: fit-content;\n          top: 14px;\n    }\n\n    .score-header-foreground__win {\n      position: absolute;\n      bottom: 35px;\n      width: fit-content;\n    }\n\n    .score-header-foreground__right .score-header-foreground__win {\n          right: 36px;\n      bottom: 32px;\n      height: fit-content;\n      line-height: 1;\n      margin: 0;\n    }\n\n    .score-header-foreground__left .score-header-foreground__win {\n      left: 19px;\n      bottom: 32px;\n      height: fit-content;\n      line-height: 1;\n      margin: 0;\n    }\n\n    .score-header-foreground .score-header-foreground__title {\n      right: 10px;\n    }\n  }\n</style>","comment_id":"5ad7ee6365cd784d6288cb03"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673637","title":"Managing Python Environments With Virtualenv","slug":"managing-python-environments","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/virtualenv.jpg","excerpt":"Working with virtualenv and virtualenvwrapper.","custom_excerpt":"Working with virtualenv and virtualenvwrapper.","created_at_pretty":"12 April, 2018","published_at_pretty":"15 November, 2017","updated_at_pretty":"10 April, 2019","created_at":"2018-04-12T17:49:21.000-04:00","published_at":"2017-11-15T17:48:00.000-05:00","updated_at":"2019-04-09T21:05:13.000-04:00","meta_title":"Managing Python Environments | Hackers and Slackers","meta_description":"Keep your Python environments separate with virtualenv and virtualenvwrapper.","og_description":"Keep your Python environments separate with virtualenv and virtualenvwrapper.","og_image":"https://hackersandslackers.com/content/images/2019/04/virtualenv-2.jpg","og_title":"Managing Python Environments With Virtualenv","twitter_description":"Keep your Python environments separate with virtualenv and virtualenvwrapper.","twitter_image":"https://hackersandslackers.com/content/images/2019/04/virtualenv-1.jpg","twitter_title":"Managing Python Environments With Virtualenv","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"As with any programming language, Python uses package managers (pip  in this\ncase) to manage the addition of libraries to be called at runtime. By default,\ninstalling a Python library with pip  will install that package to the default \nPython path,  which is the default folder from which Python stores its installed\npackages. For reference, you can determine you Python path via the following in\nthe Python shell:\n\nimport sys\nprint(sys.path)\n\n['', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python27.zip', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload', '/Library/Python/2.7/site-packages', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/PyObjC']\n\n\nWithout any other specification, Python will always look in the Python path at\nruntime to locate and execute any packages imported by a script. For example,\nlet's say I were to run a script called myscript.py  which attempts to import\nthe 'requests' library, as such:\n\n# myscript.py\nimport requests\n\n\nRunning python myscript.py  in your terminal will attempt to look for the\nlibrary in your generic python path.\n\nEnvironments With Virtualenv\nWhile keeping all your Python packages in one place may be nice at first, this\nbecomes an unmanageable problem when you suddenly find yourself managing\nmultiple projects, each of which may contain different libraries and versions of\nsuch libraries. As such, it is best practice to always encapsulate the library\ndependancies of a project by utilizing one of python's environment manages, such\nas virtualenv.\n\nVirtualenv is the oldest and most common method for managing Python\nenvironments. Creating an environment with virtualenv will create a folder in\nthe user's current directory. This folder represents an environment which can\nthen be 'activated.' This is a way of explicitly using the new environment\ndirectory in place of PYTHONPATH to handle Python packages. As such, we can\ncreate as many environments as we want without worrying about package conflicts.\n\nINSTALLATION\nInstall virtualenv via the following:\n\n$ pip3 install virtualenv\n\n\nWith virtualenv installed, we can then create the environment. cd to the\ndirectory of your choice (preferably the one which you're planning to hold your\nproject) and create an environment with the name of your choice:\n\n$ virtualenv myenv\n\nUsing base prefix '/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6'\nNew python executable in /Users/toddbirchard/myenv/bin/python3.6\nAlso creating executable in /Users/toddbirchard/myenv/bin/python\nInstalling setuptools, pip, wheel...done.\n\n\nA folder should now have been created in the current directory. That folder is\nthe new home of your virtual environment; every time you install a Python\npackage with the environment active, that package will be saved to the directory\nof said environment (as opposed to saved on your machine's Python path).\n\nACTIVATION\nNow that the environment has been created, it must be 'activated'.\n\n$ source myenv/bin/activate\n\n\nYou should notice in the terminal that once this is activated, the command line\nwill always state that the user is working out of the activated environment\nuntil otherwise changed.\n\nAlternative Methods of Virtual Environment Management","html":"<p>As with any programming language, Python uses package managers (<em>pip</em> in this case) to manage the addition of libraries to be called at runtime. By default, installing a Python library with <em>pip</em> will install that package to the default <em>Python path,</em> which is the default folder from which Python stores its installed packages. For reference, you can determine you Python path via the following in the Python shell:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import sys\nprint(sys.path)\n\n['', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python27.zip', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old', '/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload', '/Library/Python/2.7/site-packages', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python', '/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/PyObjC']\n</code></pre>\n<!--kg-card-end: markdown--><p>Without any other specification, Python will always look in the Python path at runtime to locate and execute any packages imported by a script. For example, let's say I were to run a script called <code>myscript.py</code> which attempts to import the 'requests' library, as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># myscript.py\nimport requests\n</code></pre>\n<!--kg-card-end: markdown--><p>Running <code>python myscript.py</code> in your terminal will attempt to look for the library in your generic python path.</p><h2 id=\"environments-with-virtualenv\">Environments With Virtualenv</h2><p>While keeping all your Python packages in one place may be nice at first, this becomes an unmanageable problem when you suddenly find yourself managing multiple projects, each of which may contain different libraries and versions of such libraries. As such, it is best practice to always encapsulate the library dependancies of a project by utilizing one of python's environment manages, such as <strong>virtualenv</strong>.</p><p>Virtualenv is the oldest and most common method for managing Python environments. Creating an environment with virtualenv will create a folder in the user's current directory. This folder represents an environment which can then be 'activated.' This is a way of explicitly using the new environment directory in place of PYTHONPATH to handle Python packages. As such, we can create as many environments as we want without worrying about package conflicts.</p><h3 id=\"installation\">INSTALLATION</h3><p>Install virtualenv via the following:</p><!--kg-card-begin: markdown--><pre><code>$ pip3 install virtualenv\n</code></pre>\n<!--kg-card-end: markdown--><p>With virtualenv installed, we can then create the environment. cd to the directory of your choice (preferably the one which you're planning to hold your project) and create an environment with the name of your choice:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">$ virtualenv myenv\n\nUsing base prefix '/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6'\nNew python executable in /Users/toddbirchard/myenv/bin/python3.6\nAlso creating executable in /Users/toddbirchard/myenv/bin/python\nInstalling setuptools, pip, wheel...done.\n</code></pre>\n<!--kg-card-end: markdown--><p>A folder should now have been created in the current directory. That folder is the new home of your virtual environment; every time you install a Python package with the environment active, that package will be saved to the directory of said environment (as opposed to saved on your machine's Python path).</p><h3 id=\"activation\">ACTIVATION</h3><p>Now that the environment has been created, it must be 'activated'.</p><!--kg-card-begin: markdown--><pre><code>$ source myenv/bin/activate\n</code></pre>\n<!--kg-card-end: markdown--><p>You should notice in the terminal that once this is activated, the command line will always state that the user is working out of the activated environment until otherwise changed.</p><h2 id=\"alternative-methods-of-virtual-environment-management\">Alternative Methods of Virtual Environment Management</h2>","url":"https://hackersandslackers.com/managing-python-environments/","uuid":"e5af4c12-7a41-4152-970f-63f20b8b2fde","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5acfd461583e28622a7833f9"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867362e","title":"Welcome to Hackers and Slackers","slug":"welcome-to-hackers-and-slackers","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2017/11/welcome@2x.jpg","excerpt":"Technology for badasses.","custom_excerpt":"Technology for badasses.","created_at_pretty":"17 November, 2017","published_at_pretty":"13 November, 2017","updated_at_pretty":"25 July, 2018","created_at":"2017-11-17T15:29:13.000-05:00","published_at":"2017-11-13T15:37:00.000-05:00","updated_at":"2018-07-24T22:06:02.000-04:00","meta_title":"Welcome to Hackers and Slackers | Hackers and Slackers","meta_description":"Technology for badasses","og_description":"Technology for badasses","og_image":"https://hackersandslackers.com/content/images/2017/11/welcome@2x.jpg","og_title":"Welcome to Hackers and Slackers","twitter_description":"Technology for badasses","twitter_image":"https://hackersandslackers.com/content/images/2017/11/welcome@2x.jpg","twitter_title":"Welcome to Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":null,"tags":[],"plaintext":"Welcome to the Hackers and Slackers blog, the official counterpart to \nhackersandslackers.com [http://hackersandslackers.com].\n\nH+S is a tightly knit community of of people who code dope shit as a means to an\nend. While we may not all be developers per se, we like to blow stuff up and\nmake an impact. If we get to pick up a few programming languages in the process,\nso be it.\n\nWhile we keep most of our knowledge tucked into our confluence instance, this\nblog is intended to be the public facing fruits of our labor. When we manage to\nstumble upon making things that are actually useful, this will be our medium for\ncommunicating that.\n\nIf you're somebody who likes to learn and be casually badass, maybe you should\njoin us.","html":"<p>Welcome to the Hackers and Slackers blog, the official counterpart to <a href=\"http://hackersandslackers.com\">hackersandslackers.com</a>.</p>\n<p>H+S is a tightly knit community of of people who code dope shit as a means to an end. While we may not all be developers per se, we like to blow stuff up and make an impact. If we get to pick up a few programming languages in the process, so be it.</p>\n<p>While we keep most of our knowledge tucked into our confluence instance, this blog is intended to be the public facing fruits of our labor. When we manage to stumble upon making things that are actually useful, this will be our medium for communicating that.</p>\n<p>If you're somebody who likes to learn and be casually badass, maybe you should join us.</p>\n","url":"https://hackersandslackers.com/welcome-to-hackers-and-slackers/","uuid":"84d9b616-db30-44f3-9ef3-cfc035ae71f9","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5a0f4699e38d612cc8261306"}}]}},"pageContext":{"pageNumber":32,"humanPageNumber":33,"skip":384,"limit":12,"numberOfPages":33,"previousPagePath":"/page/32","nextPagePath":""}}