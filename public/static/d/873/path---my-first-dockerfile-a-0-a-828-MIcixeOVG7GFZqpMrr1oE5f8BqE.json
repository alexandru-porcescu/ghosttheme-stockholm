{"data":{"ghostPost":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ef","title":"My First Experience with Docker","slug":"my-first-dockerfile","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/docker2@2x.jpg","excerpt":"Reboot EC2 instances with Docker.","custom_excerpt":"Reboot EC2 instances with Docker.","created_at_pretty":"05 September, 2018","published_at_pretty":"05 September, 2018","updated_at_pretty":"30 December, 2018","created_at":"2018-09-04T21:25:10.000-04:00","published_at":"2018-09-05T13:47:18.000-04:00","updated_at":"2018-12-30T07:01:05.000-05:00","meta_title":"Reboot EC2 instances with Docker | Hackers And Slackers","meta_description":"Reboot EC2 instances with Docker","og_description":"My First Experience with Docker","og_image":"https://hackersandslackers.com/content/images/2018/09/docker2@2x.jpg","og_title":"My First Experience with Docker","twitter_description":"Reboot EC2 instances with Docker","twitter_image":"https://hackersandslackers.com/content/images/2018/09/docker2@2x.jpg","twitter_title":"My First Experience with Docker","authors":[{"name":"David Aquino","slug":"david","bio":"Spent years in the military to become a killing machine using only 2 CDJs. Automated all of life's inconveniences, including investments in the financial markets.","profile_image":"https://hackersandslackers.com/content/images/2019/03/keno2.jpg","twitter":"@_k3n0","facebook":null,"website":null}],"primary_author":{"name":"David Aquino","slug":"david","bio":"Spent years in the military to become a killing machine using only 2 CDJs. Automated all of life's inconveniences, including investments in the financial markets.","profile_image":"https://hackersandslackers.com/content/images/2019/03/keno2.jpg","twitter":"@_k3n0","facebook":null,"website":null},"primary_tag":{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},"tags":[{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"}],"plaintext":"We have a .NET application that has been running for years, but once a week, the\napplication fails to recover and needs the server needs to be rebooted.  To\npreemptively reboot the EC2 instance nightly we decided to use Docker and ECS\n scheduled tasks.\n\nHere is what the finished Dockerfile looks like:\n\nFROM amazonlinux:latest\n\nRUN yum -y update\nRUN curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\nRUN python get-pip.py\nRUN pip install boto\nCOPY ./win_reboot.py /root/\nRUN chmod +x /root/win_reboot.py\n\nCMD [\"/root/win_reboot.py\"]\n\nECS has a role with the correct access to run reboot. \n\nHere is what the python script looks like:\n\n#!/usr/bin/env python\n\nimport boto.ec2\nimport os\n\nconn = boto.ec2.connect_to_region(\"us-east-1\")\ninstance_id_list = []\nfor instance in os.environ['WINDOWS_EC2'].split(\"|\"): \nfor r in conn.get_all_instances(filters={\"tag:Name\" : instance}):\n\t[instance_id_list.append(i.id) for i in r.instances]    \nconn.reboot_instances(instance_ids=instance_id_list, dry_run=False)\n\nWe need to import boto and os here. Boto is to do the AWS magic of rebooting the\nservers and os to use an environment variable.  Here we use a pipe delimiter to\ntarget multiple EC2 instances. This will help out while testing the container on\nyour local machine because you can pass in environment variables on the command\nline using the -e flag.  There is probably a more efficient and elegant way to\ngo about this, but this works for us. \n\nKeep these files in the same directory and run: \n\ndocker build -t test-name:latest .\n\nIf you it builds successfully, you can try to run it:\n\ndocker run -it test-name:latest /bin/bash\n\nThis will run your container interactively and drop you into a bash shell.\n Alternatively, try running with environment variables passed in.\n\ndocker run test-name:latest -e WINDOWS_EC2='EC2-instance-tagName' -e AWS_DEFAULT_REGION='aws region'-e AWS_ACCESS_KEY_ID='ID GOES HERE' -e AWS_SECRET_ACCESS_KEY='KEY GOES HERE'\n\nIf all of this is working as expected, you can go to ECS in AWS and create your\ntask definition.  It will provide you commands to push your image to ECR. \n\nMaybe I'll add some screenshots here.\n\nAfter that you might find you have some extra docker images and containers to\nclean up locally. The following commands should help.  Consult the docker\ndocumentation for more information. \nhttps://docs.docker.com/engine/reference/commandline/rmi/\n\nfor i in ```docker images | grep '<none>'| awk '{ print $3 }'```; do docker rmi -f $i; done\nfor i in `docker container ls --all | awk '{ print $1 }'`; do docker container rm $i; done","html":"<p>We have a .NET application that has been running for years, but once a week, the application fails to recover and needs the server needs to be rebooted.  To preemptively reboot the EC2 instance nightly we decided to use Docker and ECS  scheduled tasks.</p><p>Here is what the finished Dockerfile looks like:</p><pre><code>FROM amazonlinux:latest\n\nRUN yum -y update\nRUN curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\nRUN python get-pip.py\nRUN pip install boto\nCOPY ./win_reboot.py /root/\nRUN chmod +x /root/win_reboot.py\n\nCMD [\"/root/win_reboot.py\"]</code></pre><p>ECS has a role with the correct access to run reboot. </p><p>Here is what the python script looks like:</p><pre><code>#!/usr/bin/env python\n\nimport boto.ec2\nimport os\n\nconn = boto.ec2.connect_to_region(\"us-east-1\")\ninstance_id_list = []\nfor instance in os.environ['WINDOWS_EC2'].split(\"|\"): \nfor r in conn.get_all_instances(filters={\"tag:Name\" : instance}):\n\t[instance_id_list.append(i.id) for i in r.instances]    \nconn.reboot_instances(instance_ids=instance_id_list, dry_run=False)</code></pre><p>We need to import boto and os here. Boto is to do the AWS magic of rebooting the servers and os to use an environment variable.  Here we use a pipe delimiter to target multiple EC2 instances. This will help out while testing the container on your local machine because you can pass in environment variables on the command line using the -e flag.  There is probably a more efficient and elegant way to go about this, but this works for us. </p><p>Keep these files in the same directory and run: </p><pre><code>docker build -t test-name:latest .</code></pre><p>If you it builds successfully, you can try to run it:</p><pre><code>docker run -it test-name:latest /bin/bash</code></pre><p>This will run your container interactively and drop you into a bash shell.  Alternatively, try running with environment variables passed in.</p><pre><code>docker run test-name:latest -e WINDOWS_EC2='EC2-instance-tagName' -e AWS_DEFAULT_REGION='aws region'-e AWS_ACCESS_KEY_ID='ID GOES HERE' -e AWS_SECRET_ACCESS_KEY='KEY GOES HERE'</code></pre><p>If all of this is working as expected, you can go to ECS in AWS and create your task definition.  It will provide you commands to push your image to ECR. </p><p>Maybe I'll add some screenshots here.</p><p>After that you might find you have some extra docker images and containers to clean up locally. The following commands should help.  Consult the docker documentation for more information. <a href=\"https://docs.docker.com/engine/reference/commandline/rmi/\">https://docs.docker.com/engine/reference/commandline/rmi/</a></p><pre><code>for i in ```docker images | grep '&lt;none&gt;'| awk '{ print $3 }'```; do docker rmi -f $i; done\nfor i in `docker container ls --all | awk '{ print $1 }'`; do docker container rm $i; done</code></pre>","url":"https://hackersandslackers.com/my-first-dockerfile/","uuid":"ddb6164b-8bb7-4a8f-b301-ac20261658eb","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b8f30761fc1fc7d92b5c4b4"}},"pageContext":{"slug":"my-first-dockerfile"}}