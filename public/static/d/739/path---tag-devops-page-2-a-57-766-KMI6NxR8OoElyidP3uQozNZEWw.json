{"data":{"ghostTag":{"slug":"devops","name":"DevOps","visibility":"public","feature_image":null,"description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp."},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736fe","title":"So You've Fucked up your Python Path","slug":"so-youve-fucked-up-your-python-path","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/pythonpath-3@2x.jpg","excerpt":"A timeless hazing ritual for new Python devs, and how to fix it.","custom_excerpt":"A timeless hazing ritual for new Python devs, and how to fix it.","created_at_pretty":"11 September, 2018","published_at_pretty":"12 September, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-09-11T07:56:57.000-04:00","published_at":"2018-09-12T08:04:00.000-04:00","updated_at":"2019-02-02T04:47:15.000-05:00","meta_title":"How to Recover from a Broken Python Path | Hackers and Slackers","meta_description":"Deleting your native system Python: a coming of age story. Learn how to fix your broken Python path without wiping your machine.","og_description":"Deleting your native system Python: a coming of age story. Learn how to fix your broken Python path without wiping your machine.","og_image":"https://hackersandslackers.com/content/images/2018/09/pythonpath-3@2x.jpg","og_title":"How to Recover from a Broken Python Path | Hackers and Slackers","twitter_description":"Deleting your native system Python: a coming of age story. Learn how to fix your broken Python path without wiping your machine.","twitter_image":"https://hackersandslackers.com/content/images/2018/09/pythonpath-3@2x.jpg","twitter_title":"How to Recover from a Broken Python Path | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"}],"plaintext":"I remember back to when I first learned Python. It was a strange decision for a\nhappily employed post-graduate to make, especially for a time when many were\nscreaming for the death of the language with Guido's (outrageous?) grand reveal\nof Python 3.  The Ruby on Rails guys seemed to be doing just fine. Those were\nthe days.\n\nAfter weeks of sweating over a keyboard in the basement of an illegal BedStuy\nhostel, I had finally set out what I had hoped to achieve. It was the greatest\ncredential any programmer could possibly strive for: yes ladies and gentlemen,\nnone other than yours truly became an officially recognized licensed\nprofessional: I had just completed the last Python course in Codecademy.\n\nCongrats! You know nothing.Armed with this new unfathomable knowledge, I was\nready to take on the world. I did have a few gaps in my knowledge, such as:\n\n * Experience with Linux\n * General idea of what a terminal is and why anybody would use one\n * Basic understanding of the internet\n * Motor skills needed to survive\n\nThat aside, I was determined. Nothing could stop me, which turns out to be a\nreally bad attitude when you're SSHed into a VPS with root access, and zero\nhesitation to wreak havoc upon any and all system files. You see where this is\ngoing.\n\nDear Stack Overflow: I Think I Deleted Python\nDisabling your system's native Python version, whether via deletion or a\nmisconfigured PATH, is a coming-of-age cliché as timeless as losing one's\nvirginity on prom night. Young developers flock to Stack Overflow pleading for\nhelp, while those senior enough to reply sigh a gasp of nostalgia before\nreassuring them that their efforts are pointless. \"Ah yes,\" they reminisce, \"I\nremember my first devastating life-altering failure. To be young again.\"\n\nIf you're lucky enough to be unaware, UNIX based systems depend on their\nnatively installed version of Python to run, well, almost everything. If Python\nis unavailable for just a moment, the developer loses the ability to use:\n\n * vi\n * vim\n * nano\n * grep\n * source\n * wait, SOURCE?\n\nYep, the command you'd normally use to relaunch a corrupted startup file (such\nas the one that holds your PATH  variable) is totally unusable. Not that it\nmatters, what are you going to do, edit it?  Oh right, you just ruined every\nbash text editor. I'd actually be more interested in seeing what DOES work\nwithout Python configuring on Mac/Linux, other than moving up and down your file\nstructure helplessly, trying to quantify the damage you just wrecked upon your\nwork, life, and career.\n\nSo, Should I Kill Myself?\nHow to destroy everything ever.Calm yourself and stick with me here; I have no\ninterest in writing long-winded posts without providing any sort of solution.\nThat said, I have no problem making you sit down and think about what you've\ndone while I bother getting to the point. Nobody else has fixed this for you\nyet, and I need to improve my site's metrics, so it seems like we need each\nother on this one.\n\nBesides, don't be so hard on yourself. Not even a week ago, I sat with a Senior\nDeveloper to review my development stack, and how that would fit into the\ncurrent ecosystem of the department. Naturally I explained that I prefer running\n Flask  on Python 3.7, as I adjusted my motorcycle jacket and sat forward to\ncasually   extinguish a cigarette on his desk. Even through my vision was\nobstructed by the timelessly classic aviators resting on my face, I could see\nthe letters roll across the terminal window before him as he typed. The poor\nbastard running a 4-year old Linux distribution had just checked if Python 3 was\ninstalled on his live production instance, when his fingertips unleashed the\nunmistakable export PATH=..., seconds away from linking CentOS' native Python\nfrom Python 2.7 to Python 3.7. My exact reaction was something along the lines\nof \"OH GOD NO DON'T DO THAT STOP HOLY MOTHER OF JESUS FUCK!\" \n\nHe stopped typing. The day was saved, and I was able to explain the importance\nof leaving native Python versions intact on the systems they come installed on.\nThen, I myself fucked up the Python path maybe an hour later. On production.\n\nWe all do dumb things sometimes. That doesn't mean you're dumb. Well, except in\nmy case, having done this countless times before. Some of us simply like to live\ndangerously. Fortune favors the bold, and so on.\n\nRetro meme outta nowhere!Getting out of this Mess\nNow that we've hit rock bottom, where do we go from here? Well, two things to\nkeep in mind:\n\n 1. Not everything  is broken without Python. Extreme foreshadowing.\n 2. Restarting a terminal will automatically run all startup scripts.\n\nBy now you know that .bash_profile  and .bashrc  are critically important to\nyour system, considering how badly you've fucked things up just now. These files\nset important variables for your system every time you open your terminal; more\nspecifically, .bash_profile  kicks in on any sort of user log in (such as SSH)\nwhere .bashrc  fires every time a new additional terminal window is opened. Even\nif your startup files are corrupted, the system will always love them and turn\nto them regardless of how horribly disfigured you left them. Talk about a spark\nof hope.\n\nOn Mac OSX\nI'll admit I'm a bit embarrassed at how long it took me to realize this: even\nthough you ruined every text editor known to man, there's one resilient enough\nto hold strong. The name? TextEdit.\n\nReveal hidden files in OSX easily.In your root directory, a combo ofShift + Cmd + .  displays all hidden files.\nCheck out bash_profile. Fix it, save it, reopen terminal. Cancel the suicide\nparty. Pop the Champagne.\n\nOn Linux\nNo GUI can save us now, but what can? Perhaps a command so stupid, so simple,\nthat it couldn't possibly need Python to work:\n\necho 'export PATH=\"/YOUR/ORIGINAL/PATH/2.7/bin:${PATH}\"' >> ~/.bash_profile\n\n\nThis appends the text you provide to the end of an existing file. .bash_profile \nand .bashrc  both only pay attention to the last exported PATH in the document,\nwhich means the rest of your file will work, and the only PATH which is\nrespected is the one which you've presumably entered correctly this time around.\nRestart your terminal. Get back in the game son: it ain't about how hard you\nhit, but how hard you can get hit and keep moving forward.\n\nSidenote\nWe're not exactly conducting rocket science here (data science is a close second\nperhaps? Just kidding. We barely know what's going on most of the time). I felt\ncompelled to write this post for two reasons: one being how common and\ndestructive this pitfall can be for most people, but more importantly, the\nknee-jerk reaction veterans have in response to this problem is \"good luck,\nyou're fucked.\" \n\nI'm not here to comment on the integrity of our fine anonymous internet\ncommunities, but the discrepancy between how devastating losing a server can be\ndoesn't seem to met with much urgency by anybody with insight. Nobody taught me\nhow to work around these issues. Had I listened to anonymous internet advice, I\nprobably wouldn't let entire servers of sensitive data for dead, including my\npersonal machines. I worked through it, and quite frankly, I'm kind of a fucking\nidiot [https://hackersandslackers.com/about/], as is our mission statement. If\nan idiot who majored in nonsense and learned a programming language before\nlearning Linux can work through this, I would expect the same of those with much\nmore intelligence than I to, at the very least, attempt the same.","html":"<p>I remember back to when I first learned Python. It was a strange decision for a happily employed post-graduate to make, especially for a time when many were screaming for the death of the language with Guido's (outrageous?) grand reveal of Python 3.  The Ruby on Rails guys seemed to be doing just fine. Those were the days.</p><p>After weeks of sweating over a keyboard in the basement of an illegal BedStuy hostel, I had finally set out what I had hoped to achieve. It was the greatest credential any programmer could possibly strive for: yes ladies and gentlemen, none other than yours truly became an <em>officially recognized licensed professional</em>: I had just completed the last Python course in Codecademy.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/python-codecademy-champion.png\" class=\"kg-image\"><figcaption>Congrats! You know nothing.</figcaption></figure><p>Armed with this new unfathomable knowledge, I was ready to take on the world. I did have a few gaps in my knowledge, such as:</p><ul><li>Experience with Linux</li><li>General idea of what a terminal is and why anybody would use one</li><li>Basic understanding of the internet</li><li>Motor skills needed to survive</li></ul><p>That aside, I was determined. Nothing could stop me, which turns out to be a really bad attitude when you're SSHed into a VPS with root access, and zero hesitation to wreak havoc upon any and all system files. You see where this is going.</p><h2 id=\"dear-stack-overflow-i-think-i-deleted-python\">Dear Stack Overflow: I Think I Deleted Python</h2><style>\n    iframe{\n    height: 423px !important;\n        margin-bottom: 20px;\n    }\n</style>  <script type=\"text/javascript\" src=\"https://ssl.gstatic.com/trends_nrtr/1709_RC01/embed_loader.js\"></script>\n  <script type=\"text/javascript\">\n    trends.embed.renderExploreWidget(\"TIMESERIES\", {\"comparisonItem\":[{\"keyword\":\"python path\",\"geo\":\"US\",\"time\":\"2004-01-01 2019-02-02\"}],\"category\":0,\"property\":\"\"}, {\"exploreQuery\":\"date=all&geo=US&q=python%20path\",\"guestPath\":\"https://trends.google.com:443/trends/embed/\"});\n  </script><p>Disabling your system's native Python version, whether via deletion or a misconfigured <code>PATH</code>, is a coming-of-age cliché as timeless as losing one's virginity on prom night. Young developers flock to Stack Overflow pleading for help, while those senior enough to reply sigh a gasp of nostalgia before reassuring them that their efforts are pointless. \"<em>Ah yes,\" </em>they reminisce, \"<em>I remember my first devastating life-altering failure. To be young again.\"</em></p><p>If you're lucky enough to be unaware, UNIX based systems depend on their natively installed version of Python to run, well, almost everything. If Python is unavailable for just a moment, the developer loses the ability to use:</p><ul><li>vi</li><li>vim</li><li>nano</li><li>grep</li><li>source</li><li>wait, <em>SOURCE?</em></li></ul><p>Yep, the command you'd normally use to relaunch a corrupted startup file (such as the one that holds your <code>PATH</code> variable) is totally unusable. Not that it matters, what are you going to do, <em>edit it?</em> Oh right, you just ruined <em>every bash text editor. </em>I'd actually be more interested in seeing what DOES work without Python configuring on Mac/Linux, other than moving up and down your file structure helplessly, trying to quantify the damage you just wrecked upon your work, life, and career.</p><h3 id=\"so-should-i-kill-myself\">So, Should I Kill Myself?</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/nRrH6Gn.gif\" class=\"kg-image\"><figcaption>How to destroy everything ever.</figcaption></figure><p>Calm yourself and stick with me here; I have no interest in writing long-winded posts without providing any sort of solution. That said, I have no problem making you sit down and think about what you've done while I bother getting to the point. Nobody else has fixed this for you yet, and I need to improve my site's metrics, so it seems like we need each other on this one.</p><p>Besides, don't be so hard on yourself. Not even a week ago, I sat with a Senior Developer to review my development stack, and how that would fit into the current ecosystem of the department. Naturally I explained that I prefer running <strong>Flask</strong> on <strong>Python 3.7</strong>, as I adjusted my motorcycle jacket and sat forward to casually   extinguish a cigarette on his desk. Even through my vision was obstructed by the timelessly classic aviators resting on my face, I could see the letters roll across the terminal window before him as he typed. The poor bastard running a 4-year old Linux distribution had just checked if Python 3 was installed <strong>on his live production instance</strong>, when his fingertips unleashed the unmistakable <code>export PATH=...</code>, seconds away from linking CentOS' native Python from Python 2.7 to Python 3.7. My exact reaction was something along the lines of \"OH GOD NO DON'T DO THAT STOP HOLY MOTHER OF JESUS FUCK!\" </p><p>He stopped typing. The day was saved, and I was able to explain the importance of leaving native Python versions intact on the systems they come installed on. Then, I myself fucked up the Python path maybe an hour later. On production.  </p><p>We all do dumb things sometimes. That doesn't mean you're dumb. Well, except in my case, having done this countless times before. Some of us simply like to live dangerously. Fortune favors the bold, and so on.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/arNjoZz.gif\" class=\"kg-image\"><figcaption>Retro meme outta nowhere!</figcaption></figure><h2 id=\"getting-out-of-this-mess\">Getting out of this Mess</h2><p>Now that we've hit rock bottom, where do we go from here? Well, two things to keep in mind:</p><ol><li>Not <em>everything</em> is broken without Python. Extreme foreshadowing.</li><li>Restarting a terminal will automatically run all startup scripts.</li></ol><p>By now you know that <code>.bash_profile</code> and <code>.bashrc</code> are critically important to your system, considering how badly you've fucked things up just now. These files set important variables for your system every time you open your terminal; more specifically, <code>.bash_profile</code> kicks in on any sort of user log in (such as SSH) where <code>.bashrc</code> fires every time a new additional terminal window is opened. Even if your startup files are corrupted, the system will always love them and turn to them regardless of how horribly disfigured you left them. Talk about a spark of hope.</p><h3 id=\"on-mac-osx\">On Mac OSX</h3><p>I'll admit I'm a bit embarrassed at how long it took me to realize this: even though you ruined every text editor known to man, there's one resilient enough to hold strong. The name? <strong>TextEdit.</strong></p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ngA6gj0.gif\" class=\"kg-image\"><figcaption>Reveal hidden files in OSX easily.</figcaption></figure><p>In your root directory, a combo of  <code>Shift + Cmd + .</code> displays all hidden files. Check out bash_profile. Fix it, save it, reopen terminal. Cancel the suicide party. Pop the Champagne.</p><h3 id=\"on-linux\">On Linux</h3><p>No GUI can save us now, but what can? Perhaps a command so stupid, so simple, that it couldn't possibly need Python to work:</p><pre><code class=\"language-bash\">echo 'export PATH=&quot;/YOUR/ORIGINAL/PATH/2.7/bin:${PATH}&quot;' &gt;&gt; ~/.bash_profile\n</code></pre>\n<p>This <em>appends </em>the text you provide to the end of an existing file. <code>.bash_profile</code> and <code>.bashrc</code> both only pay attention to the last exported PATH in the document, which means the rest of your file will work, and the only PATH which is respected is the one which you've <em>presumably entered correctly this time around</em>. Restart your terminal. Get back in the game son: it ain't about how hard you hit, but how hard you can get hit and keep moving forward.</p><h2 id=\"sidenote\">Sidenote</h2><p>We're not exactly conducting rocket science here (data science is a close second perhaps? Just kidding. We barely know what's going on most of the time). I felt compelled to write this post for two reasons: one being how common and destructive this pitfall can be for most people, but more importantly, the knee-jerk reaction veterans have in response to this problem is \"good luck, you're fucked.\" </p><p>I'm not here to comment on the integrity of our fine anonymous internet communities, but the discrepancy between how devastating losing a server can be doesn't seem to met with much urgency by anybody with insight. Nobody taught me how to work around these issues. Had I listened to anonymous internet advice, I probably wouldn't let entire servers of sensitive data for dead, including my personal machines. I worked through it, and quite frankly, I'm <a href=\"https://hackersandslackers.com/about/\">kind of a <em>fucking idiot</em></a><em>, </em>as is our mission statement. If an idiot who majored in nonsense and learned a programming language before learning Linux can work through this, I would expect the same of those with much more intelligence than I to, at the very least, attempt the same.</p>","url":"https://hackersandslackers.com/so-youve-fucked-up-your-python-path/","uuid":"5de62a8f-94c9-4e70-8034-d46fb9369a73","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b97ad891fc1fc7d92b5c537"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ef","title":"My First Experience with Docker","slug":"my-first-dockerfile","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/09/docker2@2x.jpg","excerpt":"Reboot EC2 instances with Docker.","custom_excerpt":"Reboot EC2 instances with Docker.","created_at_pretty":"05 September, 2018","published_at_pretty":"05 September, 2018","updated_at_pretty":"30 December, 2018","created_at":"2018-09-04T21:25:10.000-04:00","published_at":"2018-09-05T13:47:18.000-04:00","updated_at":"2018-12-30T07:01:05.000-05:00","meta_title":"Reboot EC2 instances with Docker | Hackers And Slackers","meta_description":"Reboot EC2 instances with Docker","og_description":"My First Experience with Docker","og_image":"https://hackersandslackers.com/content/images/2018/09/docker2@2x.jpg","og_title":"My First Experience with Docker","twitter_description":"Reboot EC2 instances with Docker","twitter_image":"https://hackersandslackers.com/content/images/2018/09/docker2@2x.jpg","twitter_title":"My First Experience with Docker","authors":[{"name":"David Aquino","slug":"david","bio":"Spent years in the military to become a killing machine using only 2 CDJs. Automated all of life's inconveniences, including investments in the financial markets.","profile_image":"https://hackersandslackers.com/content/images/2019/03/keno2.jpg","twitter":"@_k3n0","facebook":null,"website":null}],"primary_author":{"name":"David Aquino","slug":"david","bio":"Spent years in the military to become a killing machine using only 2 CDJs. Automated all of life's inconveniences, including investments in the financial markets.","profile_image":"https://hackersandslackers.com/content/images/2019/03/keno2.jpg","twitter":"@_k3n0","facebook":null,"website":null},"primary_tag":{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},"tags":[{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"}],"plaintext":"We have a .NET application that has been running for years, but once a week, the\napplication fails to recover and needs the server needs to be rebooted.  To\npreemptively reboot the EC2 instance nightly we decided to use Docker and ECS\n scheduled tasks.\n\nHere is what the finished Dockerfile looks like:\n\nFROM amazonlinux:latest\n\nRUN yum -y update\nRUN curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\nRUN python get-pip.py\nRUN pip install boto\nCOPY ./win_reboot.py /root/\nRUN chmod +x /root/win_reboot.py\n\nCMD [\"/root/win_reboot.py\"]\n\nECS has a role with the correct access to run reboot. \n\nHere is what the python script looks like:\n\n#!/usr/bin/env python\n\nimport boto.ec2\nimport os\n\nconn = boto.ec2.connect_to_region(\"us-east-1\")\ninstance_id_list = []\nfor instance in os.environ['WINDOWS_EC2'].split(\"|\"): \nfor r in conn.get_all_instances(filters={\"tag:Name\" : instance}):\n\t[instance_id_list.append(i.id) for i in r.instances]    \nconn.reboot_instances(instance_ids=instance_id_list, dry_run=False)\n\nWe need to import boto and os here. Boto is to do the AWS magic of rebooting the\nservers and os to use an environment variable.  Here we use a pipe delimiter to\ntarget multiple EC2 instances. This will help out while testing the container on\nyour local machine because you can pass in environment variables on the command\nline using the -e flag.  There is probably a more efficient and elegant way to\ngo about this, but this works for us. \n\nKeep these files in the same directory and run: \n\ndocker build -t test-name:latest .\n\nIf you it builds successfully, you can try to run it:\n\ndocker run -it test-name:latest /bin/bash\n\nThis will run your container interactively and drop you into a bash shell.\n Alternatively, try running with environment variables passed in.\n\ndocker run test-name:latest -e WINDOWS_EC2='EC2-instance-tagName' -e AWS_DEFAULT_REGION='aws region'-e AWS_ACCESS_KEY_ID='ID GOES HERE' -e AWS_SECRET_ACCESS_KEY='KEY GOES HERE'\n\nIf all of this is working as expected, you can go to ECS in AWS and create your\ntask definition.  It will provide you commands to push your image to ECR. \n\nMaybe I'll add some screenshots here.\n\nAfter that you might find you have some extra docker images and containers to\nclean up locally. The following commands should help.  Consult the docker\ndocumentation for more information. \nhttps://docs.docker.com/engine/reference/commandline/rmi/\n\nfor i in ```docker images | grep '<none>'| awk '{ print $3 }'```; do docker rmi -f $i; done\nfor i in `docker container ls --all | awk '{ print $1 }'`; do docker container rm $i; done","html":"<p>We have a .NET application that has been running for years, but once a week, the application fails to recover and needs the server needs to be rebooted.  To preemptively reboot the EC2 instance nightly we decided to use Docker and ECS  scheduled tasks.</p><p>Here is what the finished Dockerfile looks like:</p><pre><code>FROM amazonlinux:latest\n\nRUN yum -y update\nRUN curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\nRUN python get-pip.py\nRUN pip install boto\nCOPY ./win_reboot.py /root/\nRUN chmod +x /root/win_reboot.py\n\nCMD [\"/root/win_reboot.py\"]</code></pre><p>ECS has a role with the correct access to run reboot. </p><p>Here is what the python script looks like:</p><pre><code>#!/usr/bin/env python\n\nimport boto.ec2\nimport os\n\nconn = boto.ec2.connect_to_region(\"us-east-1\")\ninstance_id_list = []\nfor instance in os.environ['WINDOWS_EC2'].split(\"|\"): \nfor r in conn.get_all_instances(filters={\"tag:Name\" : instance}):\n\t[instance_id_list.append(i.id) for i in r.instances]    \nconn.reboot_instances(instance_ids=instance_id_list, dry_run=False)</code></pre><p>We need to import boto and os here. Boto is to do the AWS magic of rebooting the servers and os to use an environment variable.  Here we use a pipe delimiter to target multiple EC2 instances. This will help out while testing the container on your local machine because you can pass in environment variables on the command line using the -e flag.  There is probably a more efficient and elegant way to go about this, but this works for us. </p><p>Keep these files in the same directory and run: </p><pre><code>docker build -t test-name:latest .</code></pre><p>If you it builds successfully, you can try to run it:</p><pre><code>docker run -it test-name:latest /bin/bash</code></pre><p>This will run your container interactively and drop you into a bash shell.  Alternatively, try running with environment variables passed in.</p><pre><code>docker run test-name:latest -e WINDOWS_EC2='EC2-instance-tagName' -e AWS_DEFAULT_REGION='aws region'-e AWS_ACCESS_KEY_ID='ID GOES HERE' -e AWS_SECRET_ACCESS_KEY='KEY GOES HERE'</code></pre><p>If all of this is working as expected, you can go to ECS in AWS and create your task definition.  It will provide you commands to push your image to ECR. </p><p>Maybe I'll add some screenshots here.</p><p>After that you might find you have some extra docker images and containers to clean up locally. The following commands should help.  Consult the docker documentation for more information. <a href=\"https://docs.docker.com/engine/reference/commandline/rmi/\">https://docs.docker.com/engine/reference/commandline/rmi/</a></p><pre><code>for i in ```docker images | grep '&lt;none&gt;'| awk '{ print $3 }'```; do docker rmi -f $i; done\nfor i in `docker container ls --all | awk '{ print $1 }'`; do docker container rm $i; done</code></pre>","url":"https://hackersandslackers.com/my-first-dockerfile/","uuid":"ddb6164b-8bb7-4a8f-b301-ac20261658eb","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b8f30761fc1fc7d92b5c4b4"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736a9","title":"Connect to your Google Cloud Compute Engine","slug":"connect-to-your-google-cloud-eompute-engine","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/gcp_instance@2x.jpg","excerpt":"Configuring SSH and file transfers in Google Cloud.","custom_excerpt":"Configuring SSH and file transfers in Google Cloud.","created_at_pretty":"14 July, 2018","published_at_pretty":"05 September, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-07-14T10:10:50.000-04:00","published_at":"2018-09-05T08:00:00.000-04:00","updated_at":"2019-02-02T04:52:29.000-05:00","meta_title":"Configuring SSH and file transfers in Google Cloud | Hackers And Slackers","meta_description":"Now that you've joined the Google Cloud club, you may have found yourself asking the inevitable: \"how do I connect to my damn instance?\"","og_description":"Now that you've joined the Google Cloud club, you may have found yourself asking the inevitable: \"how do I connect to my damn instance?\"","og_image":"https://hackersandslackers.com/content/images/2018/07/gcp_instance@2x.jpg","og_title":"Connect to your Google Cloud Compute Engine","twitter_description":"Now that you've joined the Google Cloud club, you may have found yourself asking the inevitable: \"how do I connect to my damn instance?\"","twitter_image":"https://hackersandslackers.com/content/images/2018/07/gcp_instance@2x.jpg","twitter_title":"Connect to your Google Cloud Compute Engine","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"}],"plaintext":"So you've taken a leap and decided to host your VPS on Google Cloud: let me be\nthe first to congratulate you on joining the clearly superior cloud platform of\nour modern era. I would apologize for being so openly opinionated, but so far\nI've only stated objective facts.\n\nNow that you've joined the club, you may have found yourself asking the\ninevitable: \"how do I connect to my damn instance?\"  If you're like me, you're\nprobably not the kind of person who enjoys this as their main solution:\n\nGoogle Cloud's in-browser terminal.Luckily for us, there are a few ways to\ninteract with your Compute Engine. Let's take a look at all of them.\n\nSet up the gcloud CLI\nIn order to SSH natively, we need to install the gcloud CLI  on our machine. Mac\nusers can download this here\n[https://cloud.google.com/sdk/docs/quickstart-macos], and Windows users can\ndownload from here [https://cloud.google.com/sdk/docs/quickstart-windows].\nClicking the downloaded file will extract the package. With your package\nextracted, run the install script install.sh  (or install.bat  for Windows) to\nstart the installation:\n\n$ ~/Downloads/google-cloud-sdk/install.sh\nWelcome to the Google Cloud SDK!\n\nTo help improve the quality of this product, we collect anonymized usage data\nand anonymized stacktraces when crashes are encountered; additional information\nis available at <https://cloud.google.com/sdk/usage-statistics>. You may choose\nto opt out of this collection now (by choosing 'N' at the below prompt), or at\nany time in the future by running the following command:\n\n    gcloud config set disable_usage_reporting true\n\nDo you want to help improve the Google Cloud SDK (Y/n)?\n\n\nContinuing the script will list the 'components' gcloud can install on your\nlocal machine, where each component is a Google Cloud product:\n\nYour current Cloud SDK version is: 214.0.0\nThe latest available version is: 214.0.0\n\n┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n│                                                  Components                                                 │\n├───────────────┬──────────────────────────────────────────────────────┬──────────────────────────┬───────────┤\n│     Status    │                         Name                         │            ID            │    Size   │\n├───────────────┼──────────────────────────────────────────────────────┼──────────────────────────┼───────────┤\n│ Not Installed │ App Engine Go Extensions                             │ app-engine-go            │ 152.8 MiB │\n│ Not Installed │ Cloud Bigtable Command Line Tool                     │ cbt                      │   6.3 MiB │\n│ Not Installed │ Cloud Bigtable Emulator                              │ bigtable                 │   4.3 MiB │\n│ Not Installed │ Cloud Datalab Command Line Tool                      │ datalab                  │   < 1 MiB │\n│ Not Installed │ Cloud Datastore Emulator                             │ cloud-datastore-emulator │  17.7 MiB │\n│ Not Installed │ Cloud Datastore Emulator (Legacy)                    │ gcd-emulator             │  38.1 MiB │\n│ Not Installed │ Cloud Pub/Sub Emulator                               │ pubsub-emulator          │  33.4 MiB │\n│ Not Installed │ Cloud SQL Proxy                                      │ cloud_sql_proxy          │   2.5 MiB │\n│ Not Installed │ Emulator Reverse Proxy                               │ emulator-reverse-proxy   │  14.5 MiB │\n│ Not Installed │ Google Cloud Build Local Builder                     │ cloud-build-local        │   4.4 MiB │\n│ Not Installed │ Google Container Local Builder                       │ container-builder-local  │   4.4 MiB │\n│ Not Installed │ Google Container Registry's Docker credential helper │ docker-credential-gcr    │   1.8 MiB │\n│ Not Installed │ gcloud Alpha Commands                                │ alpha                    │   < 1 MiB │\n│ Not Installed │ gcloud Beta Commands                                 │ beta                     │   < 1 MiB │\n│ Not Installed │ gcloud app Java Extensions                           │ app-engine-java          │ 118.6 MiB │\n│ Not Installed │ gcloud app PHP Extensions                            │ app-engine-php           │  21.9 MiB │\n│ Not Installed │ gcloud app Python Extensions                         │ app-engine-python        │   6.2 MiB │\n│ Not Installed │ gcloud app Python Extensions (Extra Libraries)       │ app-engine-python-extras │  28.5 MiB │\n│ Not Installed │ kubectl                                              │ kubectl                  │   < 1 MiB │\n│ Installed     │ BigQuery Command Line Tool                           │ bq                       │   < 1 MiB │\n│ Installed     │ Cloud SDK Core Libraries                             │ core                     │   8.3 MiB │\n│ Installed     │ Cloud Storage Command Line Tool                      │ gsutil                   │   3.6 MiB │\n└───────────────┴──────────────────────────────────────────────────────┴──────────────────────────┴───────────┘\nTo install or remove components at your current SDK version [214.0.0], run:\n  $ gcloud components install COMPONENT_ID\n  $ gcloud components remove COMPONENT_ID\n\nTo update your SDK installation to the latest version [214.0.0], run:\n  $ gcloud components update\n\n\nModify profile to update your $PATH and enable shell command\ncompletion?\n\nDo you want to continue (Y/n)?\n\n\nOnce installed, run gcloud init  in your terminal. This will prompt you to\nlogin:\n\nTo continue, you must log in. Would you like to log in (Y/n)?\n\n\nPressing 'Y' will prompt a simple browser window from which you can authenticate\nwith Google by simply selecting your Google account, as though we were using any\nother app with Google OAuth authentication. That's correct: you don't even need\nto go through the trouble of typing a password, assuming you've logged in to\nyour Google account before (I'm guessing you have).\n\n2ez authentication.Next, the terminal will prompt to specify which of your\nprojects to use. Select the project which contains your instance by entering the\nnumber seen in the resulting list:\n\nPick cloud project to use:\n [1] [my-project-1]\n [2] [my-project-2]\n ...\n Please enter your numeric choice:\n\n\nNow you're in the clear to go nuts with the gcloud  CLI:\n\ngcloud has now been configured!\nYou can use [gcloud config] to change more gcloud settings.\n\nYour active configuration is: [default]\n\n\nSSH via a Native Terminal\nUgh, so now we need to go through the process of creating public and private\nkeys etc to SSH into our instance, right? Wrong: gcloud  is so mo effin' dope\nthat there's a one-line command which will actually do this for you:\n\n$ gcloud compute config-ssh\n\nYou should now be able to use ssh/scp with your instances.\nFor example, try running:\n\n$ ssh instancename.region-b.projectname-173869\n\n\nBut there's no way it's that easy, right?\n\n$ gcloud compute ssh instancename\nEnter passphrase for key '/Users/username/.ssh/google_compute_engine':\n\nWelcome to Ubuntu 16.04.4 LTS (GNU/Linux 4.15.0-1018-gcp x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/advantage\n\n  Get cloud support with Ubuntu Advantage Cloud Guest:\n    http://www.ubuntu.com/business/services/cloud\n\n30 packages can be updated.\n0 updates are security updates.\n\n\nIt really is that easy. For as long as you use your local machine, you will only\never need to used the command gcloud compute ssh instancename  to connect to\nyour instance.\n\nGet and Put Files\nYou might be thinking that the next order of business would be to config SFTP in\norder to manage files on your instance. Believe it or not, there's a simpler\nway.\n\nDownloading Files from your Instance\ngcloud  comes with a built-in tool to download and upload files to your instance\nvia the CLI. To download files from your server, check out this one-liner:\n\ngcloud compute scp [LOCAL_FILE_PATH] [INSTANCE_NAME]:~/path/to/file/on/server\n\n\nUploading Files to your Instance\nThe same command can be reversed to upload as well:\n\ngcloud compute scp --recurse [INSTANCE_NAME]:[REMOTE_DIR] [LOCAL_DIR]\n\n\nOther Methods\nWhen we begin to look into other methods of interacting with our Computer Engine\ninstance, the general youth of GCP becomes apparent.\n\nAt the time of writing, Google's own documentation lacks information on how to\nconnect via SFTP, as the only mention of SFTP is this broken anchor link. Google\nalso provides a RDP  Chrome add-on\n[https://chrome.google.com/webstore/detail/chrome-rdp-for-google-clo/mpbbnannobiobpnfblimoapbephgifkm/] \n specifically for connecting to Compute instances, but my own attempts have\nshown this to be broken as well:\n\nWhy can't I click on you?!?!Despite these setbacks, the combination of SSH and\ngetting/putting files should be more than enough to satisfy anybody's needs for\nnow. Google Cloud Platform is only getting better with time, and is doing so at\na pace which scare other providers.","html":"<p>So you've taken a leap and decided to host your VPS on Google Cloud: let me be the first to congratulate you on joining the clearly superior cloud platform of our modern era. I would apologize for being so openly opinionated, but so far I've only stated objective facts.</p><p>Now that you've joined the club, you may have found yourself asking the inevitable: \"<em>how do I connect to my damn instance?\"</em> If you're like me, you're probably not the kind of person who enjoys this as their main solution:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ssh.gif\" class=\"kg-image\"><figcaption>Google Cloud's in-browser terminal.</figcaption></figure><p>Luckily for us, there are a few ways to interact with your Compute Engine. Let's take a look at all of them.</p><h2 id=\"set-up-the-gcloud-cli\">Set up the gcloud CLI</h2><p>In order to SSH natively, we need to install the <strong>gcloud CLI</strong> on our machine. Mac users can download this <a href=\"https://cloud.google.com/sdk/docs/quickstart-macos\">here</a>, and Windows users can download from <a href=\"https://cloud.google.com/sdk/docs/quickstart-windows\">here</a>. Clicking the downloaded file will extract the package. With your package extracted, run the install script <code>install.sh</code> (or <code>install.bat</code> for Windows) to start the installation:</p><pre><code class=\"language-bash\">$ ~/Downloads/google-cloud-sdk/install.sh\nWelcome to the Google Cloud SDK!\n\nTo help improve the quality of this product, we collect anonymized usage data\nand anonymized stacktraces when crashes are encountered; additional information\nis available at &lt;https://cloud.google.com/sdk/usage-statistics&gt;. You may choose\nto opt out of this collection now (by choosing 'N' at the below prompt), or at\nany time in the future by running the following command:\n\n    gcloud config set disable_usage_reporting true\n\nDo you want to help improve the Google Cloud SDK (Y/n)?\n</code></pre>\n<p>Continuing the script will list the 'components' gcloud can install on your local machine, where each component is a Google Cloud product:</p><pre><code class=\"language-bash\">Your current Cloud SDK version is: 214.0.0\nThe latest available version is: 214.0.0\n\n┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n│                                                  Components                                                 │\n├───────────────┬──────────────────────────────────────────────────────┬──────────────────────────┬───────────┤\n│     Status    │                         Name                         │            ID            │    Size   │\n├───────────────┼──────────────────────────────────────────────────────┼──────────────────────────┼───────────┤\n│ Not Installed │ App Engine Go Extensions                             │ app-engine-go            │ 152.8 MiB │\n│ Not Installed │ Cloud Bigtable Command Line Tool                     │ cbt                      │   6.3 MiB │\n│ Not Installed │ Cloud Bigtable Emulator                              │ bigtable                 │   4.3 MiB │\n│ Not Installed │ Cloud Datalab Command Line Tool                      │ datalab                  │   &lt; 1 MiB │\n│ Not Installed │ Cloud Datastore Emulator                             │ cloud-datastore-emulator │  17.7 MiB │\n│ Not Installed │ Cloud Datastore Emulator (Legacy)                    │ gcd-emulator             │  38.1 MiB │\n│ Not Installed │ Cloud Pub/Sub Emulator                               │ pubsub-emulator          │  33.4 MiB │\n│ Not Installed │ Cloud SQL Proxy                                      │ cloud_sql_proxy          │   2.5 MiB │\n│ Not Installed │ Emulator Reverse Proxy                               │ emulator-reverse-proxy   │  14.5 MiB │\n│ Not Installed │ Google Cloud Build Local Builder                     │ cloud-build-local        │   4.4 MiB │\n│ Not Installed │ Google Container Local Builder                       │ container-builder-local  │   4.4 MiB │\n│ Not Installed │ Google Container Registry's Docker credential helper │ docker-credential-gcr    │   1.8 MiB │\n│ Not Installed │ gcloud Alpha Commands                                │ alpha                    │   &lt; 1 MiB │\n│ Not Installed │ gcloud Beta Commands                                 │ beta                     │   &lt; 1 MiB │\n│ Not Installed │ gcloud app Java Extensions                           │ app-engine-java          │ 118.6 MiB │\n│ Not Installed │ gcloud app PHP Extensions                            │ app-engine-php           │  21.9 MiB │\n│ Not Installed │ gcloud app Python Extensions                         │ app-engine-python        │   6.2 MiB │\n│ Not Installed │ gcloud app Python Extensions (Extra Libraries)       │ app-engine-python-extras │  28.5 MiB │\n│ Not Installed │ kubectl                                              │ kubectl                  │   &lt; 1 MiB │\n│ Installed     │ BigQuery Command Line Tool                           │ bq                       │   &lt; 1 MiB │\n│ Installed     │ Cloud SDK Core Libraries                             │ core                     │   8.3 MiB │\n│ Installed     │ Cloud Storage Command Line Tool                      │ gsutil                   │   3.6 MiB │\n└───────────────┴──────────────────────────────────────────────────────┴──────────────────────────┴───────────┘\nTo install or remove components at your current SDK version [214.0.0], run:\n  $ gcloud components install COMPONENT_ID\n  $ gcloud components remove COMPONENT_ID\n\nTo update your SDK installation to the latest version [214.0.0], run:\n  $ gcloud components update\n\n\nModify profile to update your $PATH and enable shell command\ncompletion?\n\nDo you want to continue (Y/n)?\n</code></pre>\n<p>Once installed, run <code>gcloud init</code> in your terminal. This will prompt you to login:</p><pre><code class=\"language-bash\">To continue, you must log in. Would you like to log in (Y/n)?\n</code></pre>\n<p>Pressing 'Y' will prompt a simple browser window from which you can authenticate with Google by simply selecting your Google account, as though we were using any other app with Google OAuth authentication. That's correct: you don't even need to go through the trouble of typing a password, assuming you've logged in to your Google account before (I'm guessing you have).</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-09-04-at-3.36.26-PM.png\" class=\"kg-image\"><figcaption>2ez authentication.</figcaption></figure><p>Next, the terminal will prompt to specify which of your projects to use. Select the project which contains your instance by entering the number seen in the resulting list:</p><pre><code class=\"language-bash\">Pick cloud project to use:\n [1] [my-project-1]\n [2] [my-project-2]\n ...\n Please enter your numeric choice:\n</code></pre>\n<p>Now you're in the clear to go nuts with the <strong>gcloud</strong> CLI:</p><pre><code class=\"language-bash\">gcloud has now been configured!\nYou can use [gcloud config] to change more gcloud settings.\n\nYour active configuration is: [default]\n</code></pre>\n<h2 id=\"ssh-via-a-native-terminal\">SSH via a Native Terminal</h2><p>Ugh, so now we need to go through the process of creating public and private keys etc to SSH into our instance, right? Wrong: <strong>gcloud</strong> is so mo effin' dope that there's a one-line command which will actually do this for you:</p><pre><code class=\"language-bash\">$ gcloud compute config-ssh\n\nYou should now be able to use ssh/scp with your instances.\nFor example, try running:\n\n$ ssh instancename.region-b.projectname-173869\n</code></pre>\n<p>But there's no way it's that easy, right?</p><pre><code class=\"language-bash\">$ gcloud compute ssh instancename\nEnter passphrase for key '/Users/username/.ssh/google_compute_engine':\n\nWelcome to Ubuntu 16.04.4 LTS (GNU/Linux 4.15.0-1018-gcp x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/advantage\n\n  Get cloud support with Ubuntu Advantage Cloud Guest:\n    http://www.ubuntu.com/business/services/cloud\n\n30 packages can be updated.\n0 updates are security updates.\n</code></pre>\n<p>It really is that easy. For as long as you use your local machine, you will only ever need to used the command <code>gcloud compute ssh instancename</code> to connect to your instance.</p><h2 id=\"get-and-put-files\">Get and Put Files</h2><p>You might be thinking that the next order of business would be to config SFTP in order to manage files on your instance. Believe it or not, there's a simpler way.</p><h3 id=\"downloading-files-from-your-instance\">Downloading Files from your Instance</h3><p><strong>gcloud</strong> comes with a built-in tool to download and upload files to your instance via the CLI. To download files from your server, check out this one-liner:</p><pre><code class=\"language-bash\">gcloud compute scp [LOCAL_FILE_PATH] [INSTANCE_NAME]:~/path/to/file/on/server\n</code></pre>\n<h3 id=\"uploading-files-to-your-instance\">Uploading Files to your Instance</h3><p>The same command can be reversed to upload as well:</p><pre><code class=\"language-bash\">gcloud compute scp --recurse [INSTANCE_NAME]:[REMOTE_DIR] [LOCAL_DIR]\n</code></pre>\n<h2 id=\"other-methods\">Other Methods</h2><p>When we begin to look into other methods of interacting with our Computer Engine instance, the general youth of GCP becomes apparent.</p><p>At the time of writing, Google's own documentation lacks information on how to connect via <strong>SFTP, </strong>as the only mention of SFTP is this <a href=\"https://cloud.google.com/compute/docs/instances/transfer-files#filebrowser\">broken anchor link</a>. Google also provides a <strong>RDP</strong> <a href=\"https://chrome.google.com/webstore/detail/chrome-rdp-for-google-clo/mpbbnannobiobpnfblimoapbephgifkm/\">Chrome add-on</a> specifically for connecting to Compute instances, but my own attempts have shown this to be broken as well:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/rdp.png\" class=\"kg-image\"><figcaption>Why can't I click on you?!?!</figcaption></figure><p>Despite these setbacks, the combination of SSH and getting/putting files should be more than enough to satisfy anybody's needs for now. Google Cloud Platform is only getting better with time, and is doing so at a pace which scare other providers.</p>","url":"https://hackersandslackers.com/connect-to-your-google-cloud-eompute-engine/","uuid":"774f9ff4-8fe2-4951-b240-5de2f80bc266","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b4a046a1c20005e9422c102"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ca","title":"PostgreSQL Cloud Database on Google Cloud","slug":"cloud-sql-postgres-on-gcp","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/postgres4.jpg","excerpt":"Deep Dive into Cloud SQL and its out-of-the-box API.","custom_excerpt":"Deep Dive into Cloud SQL and its out-of-the-box API.","created_at_pretty":"09 August, 2018","published_at_pretty":"10 August, 2018","updated_at_pretty":"28 February, 2019","created_at":"2018-08-09T12:49:05.000-04:00","published_at":"2018-08-10T05:52:00.000-04:00","updated_at":"2019-02-27T23:37:34.000-05:00","meta_title":"Cloud-Hosted Postgres on Google Cloud | Hackers and Slackers","meta_description":"A sexy relational database on the hottest cloud provider on the market is hard to resist. Especially when it comes with a REST API.","og_description":"A sexy relational database on the hottest cloud provider on the market is hard to resist. Especially when it comes with a REST API.\n\n#Postgres #GoogleCloud #Databases","og_image":"https://hackersandslackers.com/content/images/2019/02/postgres4.jpg","og_title":"Cloud SQL Postgres on GCP","twitter_description":"A sexy relational database on the hottest cloud provider on the market is hard to resist. Especially when it comes with a REST API.\n\n#Postgres #GoogleCloud #Databases\n\n","twitter_image":"https://hackersandslackers.com/content/images/2019/02/postgres4.jpg","twitter_title":"Cloud SQL Postgres on GCP","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"PostgreSQL","slug":"postgresql","description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","feature_image":null,"meta_description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","meta_title":"Working with PostgreSQL | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"}],"plaintext":"Well folks, I have a confession to make. I've been maintaining an affair with\ntwo lovers. That's right; they're none other than PostgreSQL, and Google Cloud.\nWhile such polygamy may be shunned by the masses, I believe that somehow, some\nway, we can just make this ménage à trois work. What entices me about Cloud SQL\nis the existence of the Cloud SQL API\n[https://cloud.google.com/sql/docs/postgres/admin-api/]  , which generates\npredictable REST endpoints for presumably reading and writing to your database.\nPlease allow a moment of silence for the old workflow of API Gateways and Lambda\nfunctions. RIP.\n\nWe’ll get to APIs eventually, but for now we have one glaring obstacle: creating\nour DB, and connecting to it in a way vaguely resembles something secure*.\n\nNote: today may or may not be opposite day.Creating Our Cloud Database\nHit up the Cloud SQL [https://console.cloud.google.com/sql/]  section of your\nconsole to get this party started. Database creation on GCP is surprisingly\neasy.\n\nThat's pretty much it tbh.Databases Gone Wild: Postgres Exposed\nThere are plenty of correct ways to connect to your Postgres database correctly\nand securely. You can set up SSL for an IP\n[https://cloud.google.com/sql/docs/postgres/connect-admin-ip], connect using a\nproxy [https://cloud.google.com/sql/docs/postgres/connect-admin-proxy], or even\nvia internal cloud functions\n[https://cloud.google.com/sql/docs/postgres/connect-cloud-functions]. You may\nwant to consider doing one of those things. I'll be doing this a different way,\nbecause I'd rather get my useless data on a hackable public database than\nrewrite Google tutorials:\n\nDo as I say, not as I do.This is where you can feel free to go ahead and\npopulate data into your DB via whichever GUI you'd prefer. It'll be easier to\nsee which API calls work if there's actual data involved.\n\nPick whichever overpriced client suits you best!Enabling the API\nAs always with GCP, we need to explicitly activate the API for SQL; that way,\nthey can charge us money forever, long after we've forgotten this tutorial. We\ncan do this here\n[https://console.cloud.google.com/flows/enableapi?apiid=sqladmin]. Are you\nstarting to feel excited? I know I am; just think, all those API calls right\naround the corner, coming from a real SQL database. Wow. \n\nIn the overall process, we've made it here: the part where we run into OAuth2:\n\nRefresh tokens? Scopes? Uh oh.I'll admit it took me a good amount of time to\ndecrypt the information which failed to conveyed here. After clicking into every\nrelated link and failing at attempts to hit the API via Postman, the bad vibes\nstarted kicking in. What if this isn't the dream after all? To spare you the\nprocess, let me introduce you to a very useful GCP tool.\n\nGoogle API Explorer\nGoogle's API explorer is a GUI for playing with any API, connected to any of\nyour services. This is a cool way to preview what the exact scope of an API is\nbefore you sign up for it. Better yet, you can use placeholder User_IDs  and \nUser_Secrets  since this is basically just a sandbox.\n\nInteractive API learning tools beat reading documentation any day.After\nselecting an 'endpoint' and specifying some details like your project and\ndatabase instance, you can immediately see (theoretical) results of what the\nlive API can do. This is very useful, but I'm afraid this is where things get\ndark.\n\nHello Darkness My Old Friend\nYou may have noticed a lot of similar words or phrases popping up in these\nendpoints. Words such as \"admin\"  and \"list\", while lacking phrases such as \n\"show me my god damn data\". Google's Cloud SQL API  is NOT, in fact, an API to\ninteract with your data, but rather an admin API which enables you to do things\nprobably better suited for, you know, admin consoles.\n\nAs a big fan of GCP, this is but one of a number of growing pains I've\nexperienced with the platform so far. For instance, this entire blog along with\nits VPC has temporary deleted today, because apparently the phrases \"remove my\nproject from Firebase\"  and \"delete my project along with everything I love\" are\nsentimentally similar enough to leave that language vague and awkward.\n\nWhere Do We Go From Here?\nTo reiterate, the problem we were originally looking to solve was to find a\nservice which could (after what, 30 years?) make relational database reading and\nwriting trivial, especially in the case of apps which are simply themes without\na configurable backend, such as this blog.\n\nMongoDB Atlas  is an organizational mess which can't even describe their own\nproduct. Firebase  has yet to implement an import feature, so unless you feel\nlike writing loops to write to an experimental NoSQL database (I don't), we're\nstill kind of screwed. I know there are guys like Dreamfactory out there, but\nthese services are the sketchy ones who email you every day just for looking at\na trial. Also, anything related to Oracle or running on Oracle products (by\nchoice) sucks. There, I said it. Java developers will probably be too bust with\ngarbage collection and getting sued to argue with me anyway.\n\nAll that said, it feels like the \"Backend as a service\" thing is looming over\nthe horizon. There just doesn't seem to be anybody who's executed this\neffectively yet.\n\nUPDATE:  As it turns out, there is a service out there that accomplishes\neverything we hoped to achieve in Google cloud, and it is called Apisentris\n[https://apisentris.com/]. It's awesome, it's free, and the guy behind it is a\nchill dude.","html":"<p>Well folks, I have a confession to make. I've been maintaining an affair with two lovers. That's right; they're none other than PostgreSQL, and Google Cloud. While such polygamy may be shunned by the masses, I believe that somehow, some way, we can just make this ménage à trois work. What entices me about Cloud SQL is the existence of the <a href=\"https://cloud.google.com/sql/docs/postgres/admin-api/\">Cloud SQL API</a> , which generates predictable REST endpoints for presumably reading and writing to your database. Please allow a moment of silence for the old workflow of API Gateways and Lambda functions. RIP.</p><p>We’ll get to APIs eventually, but for now we have one glaring obstacle: creating our DB, and connecting to it in a way vaguely resembles something secure*.</p><span style=\"color: #669ab5; font-style: italic; font-size: 15px; float: right;\">Note: today may or may not be opposite day.</span><h2 id=\"creating-our-cloud-database\">Creating Our Cloud Database</h2><p>Hit up the <a href=\"https://console.cloud.google.com/sql/\">Cloud SQL</a> section of your console to get this party started. Database creation on GCP is surprisingly easy.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/setuppostgres.png\" class=\"kg-image\"><figcaption>That's pretty much it tbh.</figcaption></figure><h2 id=\"databases-gone-wild-postgres-exposed\">Databases Gone Wild: Postgres Exposed  </h2><p>There are plenty of <em>correct </em>ways to connect to your Postgres database correctly and securely. You can <a href=\"https://cloud.google.com/sql/docs/postgres/connect-admin-ip\">set up SSL for an IP</a>, connect <a href=\"https://cloud.google.com/sql/docs/postgres/connect-admin-proxy\">using a proxy</a>, or even via internal <a href=\"https://cloud.google.com/sql/docs/postgres/connect-cloud-functions\">cloud functions</a>. You may want to consider doing one of those things. I'll be doing this a different way, because I'd rather get my useless data on a hackable public database than rewrite Google tutorials:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/public.png\" class=\"kg-image\"><figcaption>Do as I say, not as I do.</figcaption></figure><p>This is where you can feel free to go ahead and populate data into your DB via whichever GUI you'd prefer. It'll be easier to see which API calls work if there's actual data involved.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-08-10-at-4.15.22-AM.png\" class=\"kg-image\"><figcaption>Pick whichever overpriced client suits you best!</figcaption></figure><h2 id=\"enabling-the-api\">Enabling the API</h2><p>As always with GCP, we need to explicitly activate the API for SQL; that way, they can charge us money forever, long after we've forgotten this tutorial. We can do this <a href=\"https://console.cloud.google.com/flows/enableapi?apiid=sqladmin\">here</a>. Are you starting to feel excited? I know I am; just think, all those API calls right around the corner, coming from a real SQL database. Wow. </p><p>In the overall process, we've made it <em>here</em>: the part where we run into OAuth2:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-08-10-at-4.21.55-AM.png\" class=\"kg-image\"><figcaption>Refresh tokens? Scopes? Uh oh.</figcaption></figure><p>I'll admit it took me a good amount of time to decrypt the information which failed to conveyed here. After clicking into every related link and failing at attempts to hit the API via Postman, the bad vibes started kicking in. What if this isn't the dream after all? To spare you the process, let me introduce you to a very useful GCP tool.</p><h2 id=\"google-api-explorer\">Google API Explorer</h2><p>Google's API explorer is a GUI for playing with any API, connected to any of your services. This is a cool way to preview what the exact scope of an API is before you sign up for it. Better yet, you can use placeholder <em>User_IDs</em> and <em>User_Secrets</em> since this is basically just a sandbox.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sandbox.gif\" class=\"kg-image\"><figcaption>Interactive API learning tools beat reading documentation any day.</figcaption></figure><p>After selecting an 'endpoint' and specifying some details like your project and database instance, you can immediately see (theoretical) results of what the live API can do. This is very useful, but I'm afraid this is where things get dark.</p><h3 id=\"hello-darkness-my-old-friend\">Hello Darkness My Old Friend</h3><p>You may have noticed a lot of similar words or phrases popping up in these endpoints. Words such as <em>\"admin\"</em> and \"<em>list\"</em>, while lacking phrases such as <em>\"show me my god damn data\". </em>Google's <strong>Cloud SQL API</strong> is NOT, in fact, an API to interact with your data, but rather an <em>admin </em>API which enables you to do things probably better suited for, you know, admin consoles.</p><p>As a big fan of GCP, this is but one of a number of growing pains I've experienced with the platform so far. For instance, this entire blog along with its VPC has temporary deleted today, because apparently the phrases <em>\"remove my project from Firebase\"</em> and <em>\"delete my project along with everything I love\" </em>are sentimentally similar enough to leave that language vague and awkward.</p><h2 id=\"where-do-we-go-from-here\">Where Do We Go From Here?</h2><p>To reiterate, the problem we were originally looking to solve was to find a service which could (after what, 30 years?) make relational database reading and writing trivial, especially in the case of apps which are simply themes without a configurable backend, such as this blog.</p><p><em>MongoDB Atlas</em> is an organizational mess which can't even describe their own product. <em>Firebase</em> has yet to implement an import feature, so unless you feel like writing loops to write to an experimental NoSQL database (I don't), we're still kind of screwed. I know there are guys like <em>Dreamfactory </em>out there, but these services are the sketchy ones who email you every day just for looking at a trial. Also, anything related to Oracle or running on Oracle products (by choice) sucks. There, I said it. Java developers will probably be too bust with garbage collection and getting sued to argue with me anyway.</p><p>All that said, it feels like the \"Backend as a service\" thing is looming over the horizon. There just doesn't seem to be anybody who's executed this effectively yet.</p><p><strong>UPDATE:</strong> As it turns out, there is a service out there that accomplishes everything we hoped to achieve in Google cloud, and it is called <a href=\"https://apisentris.com/\">Apisentris</a>. It's awesome, it's free, and the guy behind it is a chill dude.</p>","url":"https://hackersandslackers.com/cloud-sql-postgres-on-gcp/","uuid":"76daacf1-55b4-4ede-b21d-29fd727e1d50","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b6c70819dcd9d3270b58635"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c7","title":"Hacking Tableau to Handle ETL Workflows","slug":"turning-tableau-into-an-etl-tool-using-the-rest-api","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/fucktableau@2x.jpg","excerpt":"Weaponizing APIs against tyrannical software.","custom_excerpt":"Weaponizing APIs against tyrannical software.","created_at_pretty":"01 August, 2018","published_at_pretty":"03 August, 2018","updated_at_pretty":"28 February, 2019","created_at":"2018-08-01T08:49:36.000-04:00","published_at":"2018-08-03T08:57:00.000-04:00","updated_at":"2019-02-28T03:18:22.000-05:00","meta_title":"Hacking Tableau to Handle ETL Workflows | Hackers and Slackers","meta_description":"The presence of ETL as an acronym is a perfect reflection of where we are in data engineering's growth trajectory. ","og_description":"The presence of ETL as an acronym is a perfect reflection of where we are in data engineering's growth trajectory. The lack of effective Extract, Transform, and Load workflow products tell us a couple things: we have too many data sources (whether they be APIs or private data sets), and the raw data is virtually unusable until cleaned.","og_image":"https://hackersandslackers.com/content/images/2018/08/fucktableau@2x.jpg","og_title":"Hacking Tableau to Handle ETL Workflows","twitter_description":"The lack of effective Extract, Transform, and Load workflow products tell us a couple things: we have too many data sources, and the raw data is virtually unusable until cleaned.","twitter_image":"https://hackersandslackers.com/content/images/2018/08/fucktableau@2x.jpg","twitter_title":"Hacking Tableau to Handle ETL Workflows","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Hacking Tableau Server","slug":"hacking-tableau-server","description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauseries-2.jpg","meta_description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","meta_title":"Hacking Tableau Server","visibility":"internal"}],"plaintext":"Before we get into the specifics of how to sadistically abuse Tableau, let's\nclear the air: there's something about inaccessible, expensive, proprietary\nenterprise software that tends to put me in a touchy mood. As we know, B2B\nsoftware pricing has nothing to do with code quality or even value-add, but\nrather the tendency of businesses to create time-based urgencies without\nwarning; the kinds of urgencies which may be solved by, say, a tool of sorts.\n\nMy first interaction with Tableau actually took place after I had committed\nmyself to the cult of Python's Pandas library and all that comes with it.\nTableau does little to hide the fact that it is a GUI for data manipulation and\nSQL queries; in most cases, the calculation syntax is exactly the same. From my\nperspective, Tableau could be a tool to save time: instead of rewriting\nvariations of the same scripts over and over, I could use Tableau to do these\ntasks visually for both speed and transparency's sake. It was a win-win for\ntrivial tasks, except for one: the ability to write back to a database. You'd\nthink I wouldn't think that far ahead before purchasing my own Tableau server\nand license, conveniently billed upfront annually.\n\nThe Rise of ETL\nThe presence of ETL as an acronym is a perfect reflection of where we are in\ndata engineering's growth trajectory. The lack of effective Extract, Transform,\nand Load  workflow products tell us a couple things: we have too many data\nsources (whether they be APIs or private data sets), and the raw data is\nvirtually unusable until cleaned. This process could be relatively trivial with\nthe right software. There are plenty of contenders to make this process simple,\nand I'd like to express in unadulterated astonishment that they are all  failing\nmiserably  at solving this task effectively, mostly thanks to poor decision\nmaking and human error alone.\n\nThe ETL Market\nAs it stands, Parabola.io  tops my list of ETL products. Parabola hits the nail\non the head when it comes to UI and ease of use. This begs the question: why,\nthen, are their latest releases focused on support for extraction to garbage\nproducts like Smartsheet? Currently the only extract location which is actually\na database  is MySQL. As much as I want Parabola to succeed, nothing has\nimproved if our workflow still involves manually setting up a third party DB\nwith a schema which perfectly matches our output.\n\nGoogle Cloud is doing its best to somehow tie separate products together such as\n Dataprep  and Bigquery. We'll see how that goes- there's no mention of data\nextraction from APIs in this flow just yet. We might be waiting for some time\nfor Google's perfect answer to mature.\n\nGithub Labs supposedly just announced recent efforts to tackle this space as\nwell with the upcoming Melatano\n[https://about.gitlab.com/2018/08/01/hey-data-teams-we-are-working-on-a-tool-just-for-you/]\n. Hopefully they have their heads on straight.\n\nAnyway, since the world has failed us, we'll just exploit a Tableau backdoor to\ndo this while humanity catches up.\n\nTableau's Rest API\nAs hard as Tableau tries to obfuscate anything and everything, their REST API\ngets us exactly what we want after a bit of red tape. We need to run 3 API\ncalls:\n\n * POST /api/[api-version]/auth/signin: Generate a token so we can actually use\n   the API\n * GET /api/3.0/sites/[site-id]/views:  List all view metadata in a Tableau\n   \"site.\"\n * GET /api/3.0/sites/[site-id]/views/[view-id]/data: Receive a comma\n   delimitated response of the content of your target view\n\nWhat R U Token about\nTo receive our token, we'll use basic auth to hit this simple endpoint via POST:\n \n\nPOST http://mywebsite/api/3.0/auth/signin\n\n\nThe response will come in the form of XML and give us two critical items: our \ntoken, and our site ID:\n\nClearly a user-friendly experience.List Views by Site\nNext up we're GETing the following endpoint:\n\nhttp://mywebsite/api/3.0/sites/543fc0-4123572-483276-9345d8c-96005d532b2fb33/views\n\n\nNote that Tableau asks for the site ID from the previous response to be part of\nthe URL string.\n\nWe'll also need to set headers, so do that.\n\nX-Tableau-Auth: SPMJsdfgHIDUFihdwPqf-5k8GCZJA|sXhFBHzzqksB6K567fsQvtCfTtakqrJLuQ6Cf\n\n\nThe motherload of views.Reap your Reward\nPick the notebook ID you're looking to extract data from. Chose wisely. Your\ntime now. Enter that view into the final endpoint URL:\n\nhttp://mysite/api/3.0/sites/983445c0-4172-4876-9d8c-96005db2gfdgdfb33/views/c0357db9-71b1-4besdfgd1-a14e-5a5f7a36d410/data\n\n\nWhoa mama.Well, Well, Well.\nSo now you know how to generate a Tableau REST API token at will. You also know\nall your view IDs, and how to extract the data from any of those views in a\nfriendly CSV format which happens to play nice with databases. There's a Pandas\nscript waiting to be written here somewhere.\n\nAt this point, you know have all the tools you need to automate the systematic\npillaging of your Tableau Server data. Take a brief moment to remember the days\nwhen Tableau would wave their flags through the countryside as a sign of\ntaunting warfare. They've collected your company's checks and gave you iFrames\nin return.\n\nGo onwards my brethren. For one chance, discover the lands of Plot.ly and D3 as\nFree Men. They may take our paychecks, but they will never take our data.","html":"<p>Before we get into the specifics of how to sadistically abuse Tableau, let's clear the air: there's something about inaccessible, expensive, proprietary enterprise software that tends to put me in a touchy mood. As we know, B2B software pricing has nothing to do with code quality or even value-add, but rather the tendency of businesses to create time-based urgencies without warning; the kinds of urgencies which may be solved by, say, a tool of sorts.</p><p>My first interaction with Tableau actually took place after I had committed myself to the cult of Python's Pandas library and all that comes with it. Tableau does little to hide the fact that it is a GUI for data manipulation and SQL queries; in most cases, the calculation syntax is exactly the same. From my perspective, Tableau could be a tool to save time: instead of rewriting variations of the same scripts over and over, I could use Tableau to do these tasks visually for both speed and transparency's sake. It was a win-win for trivial tasks, except for one: the ability to write back to a database. You'd think I wouldn't think that far ahead before purchasing my own Tableau server and license, conveniently billed upfront annually.</p><h2 id=\"the-rise-of-etl\">The Rise of ETL</h2><p>The presence of ETL as an acronym is a perfect reflection of where we are in data engineering's growth trajectory. The lack of effective <strong>Extract, Transform, and Load</strong> workflow products tell us a couple things: we have too many data sources (whether they be APIs or private data sets), and the raw data is virtually unusable until cleaned. This process could be relatively trivial with the right software. There are plenty of contenders to make this process simple, and I'd like to express in unadulterated astonishment that they are all<strong> failing miserably</strong> at solving this task effectively, mostly thanks to poor decision making and human error alone.</p><h3 id=\"the-etl-market\">The ETL Market</h3><p>As it stands, <a href=\"Parabola.io\">Parabola.io</a> tops my list of ETL products. Parabola hits the nail on the head when it comes to UI and ease of use. This begs the question: why, then, are their latest releases focused on support for extraction to garbage products like <strong>Smartsheet</strong>? Currently the only extract location which is <em>actually a database</em> is MySQL. As much as I want Parabola to succeed, nothing has improved if our workflow still involves manually setting up a third party DB with a schema which perfectly matches our output.</p><p>Google Cloud is doing its best to somehow tie separate products together such as <strong>Dataprep</strong> and <strong>Bigquery</strong>. We'll see how that goes- there's no mention of data extraction from APIs in this flow just yet. We might be waiting for some time for Google's perfect answer to mature.</p><p>Github Labs supposedly just announced recent efforts to tackle this space as well with the upcoming <a href=\"https://about.gitlab.com/2018/08/01/hey-data-teams-we-are-working-on-a-tool-just-for-you/\">Melatano</a>. Hopefully they have their heads on straight.</p><p>Anyway, since the world has failed us, we'll just exploit a Tableau backdoor to do this while humanity catches up.</p><h2 id=\"tableau-s-rest-api\">Tableau's Rest API</h2><p>As hard as Tableau tries to obfuscate anything and everything, their REST API gets us exactly what we want after a bit of red tape. We need to run 3 API calls:</p><ul><li><strong>POST /api/[<em>api-version]</em>/auth/signin</strong>: Generate a token so we can actually use the API</li><li><strong>GET /api/3.0/sites/[site-id]/views</strong>:<strong> </strong>List all view metadata in a Tableau \"site.\"</li><li><strong>GET /api/3.0/sites/[site-id]/views/[view-id]/data</strong>: Receive a comma delimitated response of the content of your target view</li></ul><h3 id=\"what-r-u-token-about\">What R U Token about</h3><p>To receive our token, we'll use basic auth to hit this simple endpoint via POST: </p><pre><code class=\"language-shell\">POST http://mywebsite/api/3.0/auth/signin\n</code></pre>\n<p>The response will come in the form of XML and give us two critical items: our <strong>token</strong>, and our <strong>site ID</strong>:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-08-03-at-7.50.59-AM.png\" class=\"kg-image\"><figcaption>Clearly a user-friendly experience.</figcaption></figure><h3 id=\"list-views-by-site\">List Views by Site</h3><p>Next up we're GETing the following endpoint:</p><pre><code class=\"language-shell\">http://mywebsite/api/3.0/sites/543fc0-4123572-483276-9345d8c-96005d532b2fb33/views\n</code></pre>\n<p>Note that Tableau asks for the <strong>site ID </strong>from the previous response to be part of the URL string.</p><p>We'll also need to set headers, so do that.</p><pre><code class=\"language-shell\">X-Tableau-Auth: SPMJsdfgHIDUFihdwPqf-5k8GCZJA|sXhFBHzzqksB6K567fsQvtCfTtakqrJLuQ6Cf\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-08-03-at-7.57.47-AM.png\" class=\"kg-image\"><figcaption>The motherload of views.</figcaption></figure><h3 id=\"reap-your-reward\">Reap your Reward</h3><p>Pick the notebook ID you're looking to extract data from. Chose wisely. Your time now. Enter that view into the final endpoint URL:</p><pre><code class=\"language-shell\">http://mysite/api/3.0/sites/983445c0-4172-4876-9d8c-96005db2gfdgdfb33/views/c0357db9-71b1-4besdfgd1-a14e-5a5f7a36d410/data\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-08-03-at-8.01.24-AM.png\" class=\"kg-image\"><figcaption>Whoa mama.</figcaption></figure><h2 id=\"well-well-well-\">Well, Well, Well.</h2><p>So now you know how to generate a Tableau REST API token at will. You also know all your view IDs, and how to extract the data from any of those views in a friendly CSV format which happens to play nice with databases. There's a Pandas script waiting to be written here somewhere.</p><p>At this point, you know have all the tools you need to automate the systematic pillaging of your Tableau Server data. Take a brief moment to remember the days when Tableau would wave their flags through the countryside as a sign of taunting warfare. They've collected your company's checks and gave you iFrames in return.</p><p>Go onwards my brethren. For one chance, discover the lands of Plot.ly and D3 as Free Men. They may take our paychecks, but they will <strong>never </strong>take our data.</p>","url":"https://hackersandslackers.com/turning-tableau-into-an-etl-tool-using-the-rest-api/","uuid":"7b86dd9c-7d93-4518-8f3a-b593a6cdb7f0","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b61ac60d2852c0dc51d9217"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c5","title":"Hacking Your Tableau Linux Server","slug":"hacking-linux-tableau-server","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/hacktableau@2x.jpg","excerpt":"Cracking Tableau's master Postgres account.","custom_excerpt":"Cracking Tableau's master Postgres account.","created_at_pretty":"26 July, 2018","published_at_pretty":"26 July, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-07-26T03:17:59.000-04:00","published_at":"2018-07-26T05:55:50.000-04:00","updated_at":"2019-02-02T04:23:43.000-05:00","meta_title":"Cracking Tableau's master Postgres account | Hackers And Slackers","meta_description":"BI tools are great for understanding preexisting data, but they don't allow us to go much further. Your data is with them, and it's not going anywhere else.","og_description":"BI tools are great for understanding preexisting data, they don't go much further. Your data is with them, and it's not going anywhere else.","og_image":"https://hackersandslackers.com/content/images/2018/07/hacktableau@2x.jpg","og_title":"Hacking Your Tableau Linux Server","twitter_description":"BI tools are great for understanding preexisting data, they don't go much further. Your data is with them, and it's not going anywhere else.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/hacktableau@2x.jpg","twitter_title":"Hacking Your Tableau Linux Server","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#Hacking Tableau Server","slug":"hacking-tableau-server","description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauseries-2.jpg","meta_description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","meta_title":"Hacking Tableau Server","visibility":"internal"}],"plaintext":"Let's say you're a Data Scientist. Well, maybe not a data scientist- I mean,\nthose online data analysis courses were definitely worth it, and you'd made it\nthis far without being quizzed on Bayesian linear regression. So maybe you're an\nanalyst or something, but whatever:  you use Tableau, So you must be a\nScientist™.\n\nI've admitted a few times in the past to have purchased a personal Tableau\nServer license in my more ignorant years (aka a few months ago). While BI tools\nare great for understanding preexisting data, they don't allow us to go much\nfurther. This is is entirely by design. Sure, you can clean and slice your data\nand put it into a cute iFrame dashboard, but Tableau explicitly makes one thing\nexplicitly clear in their product design choices: your data is with them, and\nit's not going anywhere else. Today we're going to take a step towards changing\nthat.\n\nProprietary Product Design: Crimes Against Customers\nTableau has explicit hierarchies for information, but let's start with \nworkbooks.  Workbooks are basically spreadsheets, or in other words,  \ncollections of SQL query outputs against a data source (or multiple data\nsources) via a clean UI. The resulting tabular data is referred to as views. An\nExcel user might equate these to \"sheets\", but a SQL user understands that these\nfunction more like a materialized view of sorts. One would think the tables we\ncreate (from our own data) inherently belongs to us, but it doesn't. Not until\nyou get clever.\n\nI realize Tableau maybe be at the top of the market for its niche.... so the\nthings I'm claiming may seem a little farfetched. Why am I so convinced that\nTableau wants to lock your data? Stay with me here, and let me count the ways.\n\nCommon Courtesy API Visibility\nCommon knowledge suggest that visible APIs attracts development talent. The more\nintelligent people are exposed to your product, the more like they are to\ncontribute. What happens if we check out the API response calls in our browser\nwhen viewing  Worksheet on Tableau Server?\n\nLet's just agree this is all useless.While this level of unnecessary paranoia on\nTableau's part is distasteful, let's not forget that we're dealing with a\nproduct archaic enough to preview Windows server support over Linux. The\nnarrative begins to make sense.\n\nPostgres Hide and Seek\nTableau Server is running a Postgres database; really nothing magical happening\nhere. Well, other than the database has been renamed, protected, and obfuscated\nin a way that even the server owner would struggle with. The default commands to\ninteract with PostgreSQL are hidden from server admins altogether.\n\n$ psql postgres -u toddbirchard -p\nThe program 'psql' is currently not installed. To run 'psql' please ask your administrator to install the package 'postgresql-client-common'\n\n-------------------\n\n$ sudo -u postgres psql postgres\nsudo: unknown user: postgres\nsudo: unable to initialize policy plugin\n\n-------------------\n\n$ sudo -u toddbirchard psql postgres\nsudo: psql: command not found\n\n-------------------\n\n$ psql\npsql: could not connect to server: No such file or directory\n        Is the server running locally and accepting\n        connections on Unix domain socket \"/var/run/postgresql/.s.PGSQL.5432\"?\n\n-------------------\n\n$ pgsql\nNo command 'pgsql' found, did you mean:\n Command 'psql' from package 'postgresql-client-common' (main)\npgsql: command not found\n\n\nWhat if we do a search?\n\n$ locate postgresql\n\n/etc/postgresql-common\n/etc/postgresql-common/user_clusters\n/opt/tableau-postgresql-odbc_9.5.3_amd64.deb\n/opt/tableau/tableau_driver/postgresql-odbc\n/opt/tableau/tableau_driver/postgresql-odbc/psqlodbcw.so\n/opt/tableau/tableau_server/packages/bin.20181.18.0510.1418/repo-jars/postgresql-9.4.1209.jar\n/opt/tableau/tableau_server/packages/clientfileservice.20181.18.0510.1418/postgresql-9.4.1208.jar\n/opt/tableau/tableau_server/packages/lib.20181.18.0510.1418/postgresql-9.4.1208.jar\n/opt/tableau/tableau_server/packages/lib.20181.18.0510.1418/postgresql-9.4.1209.jar\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/_int.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/adminpack.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/ascii_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/auth_delay.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/auto_explain.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/autoinc.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/btree_gin.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/btree_gist.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/chkpass.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/citext.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/cube.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/cyrillic_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dblink.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_int.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_snowball.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_xsyn.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/earthdistance.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc2004_sjis2004.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_cn_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_jp_and_sjis.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_kr_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_tw_and_big5.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/file_fdw.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/fuzzystrmatch.so\n\n\n...And so forth. There are over a thousand results. Postgres is definitely up\nand running, Tableau just hates you. Unfortunately for Tableau, this drove me to\nhate them back.\n\nEnter TSM: The Linux Tableau CLI\nOn Linux exclusively, TSM is intended to be your one tool to configure Tableau\nServer. It's a fine tool, but it just so happens to omit critical information\nand capabilities that somebody who owns their data  might want to know. At first\nglance, it seems innocent and helpful:\n\nCommand\n Explanation\n tsm configuration [parameters]\n -- Set customization for Tableau Server.\n tsm customize [parameters] -- Set customization for Tableau Server.\n tsm data-access [parameters]\n -- Category of commands related to data-access.\n tsm help | [category]\n -- Help for tsm commands\n .tsm initialize [parameters]\n -- Initialize Tableau Server\n tsm jobs [parameters]\n -- Category of commands related to async jobs.\n tsm licenses [parameters]\n -- Category of commands related to licensing.\n tsm login [parameters] -- Sign in to the TSM agent\n tsm logout -- Sign out from the TSM agent\n tsm maintenance [parameters]\n -- Category of commands related to maintenance.\n tsm pending-changes [parameters]\n -- Category of commands for pending changes.\n tsm register [parameters]\n -- Register the product\n tsm reset [parameters]\n -- Clears the initial admin user so you can enter a new one. Once reset is\ncompleted you will need to use the tabcmd initialuser command to create a new\ninitial user before remote users can sign in again\n tsm restart [parameters]\n -- Restart Tableau Server\n tsm security [parameters]\n -- Category of commands related to security configuration\n tsm settings [parameters]\n -- Category of commands related to configuration and topology settings\n tsm sites [parameters]\n -- Category of commands related to site import and export\n tsm start [parameters]\n -- Start Tableau Server\n tsm status [parameters]\n -- View Tableau Server status\n tsm stop [parameters]\n -- Stop Tableau Server\n tsm topology [parameters] -- Category of commands related to server topology\n tsm user-identity-store [parameters]\n -- Category of commands related to user-identity-store\n tsm version -- Displays version information.\n The Red Herring\nTableau owns Google results, period. Any search query containing the word\n\"Tableau\" is dominated with pages of content Tableau would prefer  you abide by,\nand of these things is the creation of a readonly  user to access the Postgres\ndatabase. The catch here is that the readonly  user can't read all tables at\nall: there are certain tables reserved specifically for a Postgres tableau\n\"Superuser\", which is utterly and entirely undocumented on Linux.  For all I\nknow, I my be the first to publish an article of this sort, but let's hope not.\n\nFirst, let's see which users exist on Postgres using TSM:\n\n$ tsm data-access repository-access list\n\nUser       Access\nTableau    true\nReadonly   true\n\n\nThere's that Readonly user we talked about: feel free to play around with that\nuser to create meaningless insights if you so please. On the other hand we have\na Tableau  user, which happens to be a Postgres superuser. If you don't feel\ncomfortable accessing Superuser privileges, I suggest you leave now. This is \nHackers And Slackers,  and we don't fuck around; especially when software to the\ntune of 1 thousand dollars hides our data from us.\n\nOperation Shock and Awe\nThere's a little command called tsm configuration  which lets you set some cute\nvariables for your server. The documentation is here\n[https://onlinehelp.tableau.com/current/server-linux/en-us/cli_configuration-set_tsm.htm]\n, but there's just one piece missing, and it's the one we need.\n\nTableau may be our Postgres Superuser, but what would its password possibly be?\nThis isn't documented anywhere. Consider this my gift to you:\n\n$ tsm configuration get -k pgsql.adminpassword\n145v756270d3467bv3140af5f01v5c7e4976bcee\n\n\nCould it be? Did Tableau intentionally prevent users from access PostgreSQL\ndirectly from command line and hide an undocumented password? Yes, it does all\nof those things. It's time to fuck shit up.\n\nClaim Ownership\nWe've made it this far. The bullet is in the chamber. Go ahead and take what is\nrightfully yours.\n\ntsm data-access repository-access enable --repository-username Tableau\n--repository-password 145v756270d3467bv3140af5f01v5c7e4976bcee\n\n\nJust make sure port 8060 is open on your VPC and you're in. Considering that\nthere are zero search results for accomplishing this on Linux, it looks like\nit's just you and me now. One of us may likely go mad with power and turn on one\nanother. That is the way of the Sith. Welcome.\n\nUnspeakable treasures lie within.Moving on Up\nFeel free to cruise the workgroup  database for now and wreck havoc. As fun as\nthis has been, I have another trick up my sleeve. You've spent a lot of time\nbuilding Worksheets and views; what if you could programmatically sync to an\nexternal database and autogenerate a schema for these views, updated on a\nscheduler, to source data for products you're building?\n\nThats sounds a lot like what a useful product would do. Stick around, and next\ntime we'll be beating Tableau down for everything its worth.","html":"<p>Let's say you're a Data Scientist. Well, maybe not a <em>data scientist- </em>I mean, those online data analysis courses were definitely worth it, and you'd made it this far without being quizzed on Bayesian linear regression. So maybe you're an analyst or something, but whatever:  you use Tableau, So you must be a Scientist™.</p><p>I've admitted a few times in the past to have purchased a personal Tableau Server license in my more ignorant years (aka a few months ago). While BI tools are great for understanding preexisting data, they don't allow us to go much further. This is is entirely by design. Sure, you can clean and slice your data and put it into a cute iFrame dashboard, but Tableau explicitly makes one thing explicitly clear in their product design choices: your data is with them, and it's not going anywhere else. Today we're going to take a step towards changing that.</p><h2 id=\"proprietary-product-design-crimes-against-customers\">Proprietary Product Design: Crimes Against Customers</h2><p>Tableau has explicit hierarchies for information, but let's start with <strong>workbooks.</strong> Workbooks are basically spreadsheets, or in other words,<strong> </strong>collections of SQL query outputs against a data source (or multiple data sources) via a clean UI. The resulting tabular data is referred to as <strong>views</strong>. An Excel user might equate these to \"sheets\", but a SQL user understands that these function more like a materialized view of sorts. One would think the tables we create (from our own data) inherently belongs to us, but it doesn't. Not until you get clever.</p><p>I realize Tableau maybe be at the top of the market for its niche.... so the things I'm claiming may seem a little farfetched. Why am I so convinced that Tableau wants to lock your data? Stay with me here, and let me count the ways.</p><h2 id=\"common-courtesy-api-visibility\">Common Courtesy API Visibility</h2><p>Common knowledge suggest that visible APIs attracts development talent. The more intelligent people are exposed to your product, the more like they are to contribute. What happens if we check out the API response calls in our browser when viewing  Worksheet on Tableau Server?</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ezgif.com-gif-maker.gif\" class=\"kg-image\"><figcaption>Let's just agree this is all useless.</figcaption></figure><p>While this level of unnecessary paranoia on Tableau's part is distasteful, let's not forget that we're dealing with a product archaic enough to preview Windows server support over Linux. The narrative begins to make sense.</p><h3 id=\"postgres-hide-and-seek\">Postgres Hide and Seek</h3><p>Tableau Server is running a Postgres database; really nothing magical happening here. Well, other than the database has been renamed, protected, and obfuscated in a way that even the server owner would struggle with. The default commands to interact with PostgreSQL are hidden from server admins altogether.</p><pre><code class=\"language-bash\">$ psql postgres -u toddbirchard -p\nThe program 'psql' is currently not installed. To run 'psql' please ask your administrator to install the package 'postgresql-client-common'\n\n-------------------\n\n$ sudo -u postgres psql postgres\nsudo: unknown user: postgres\nsudo: unable to initialize policy plugin\n\n-------------------\n\n$ sudo -u toddbirchard psql postgres\nsudo: psql: command not found\n\n-------------------\n\n$ psql\npsql: could not connect to server: No such file or directory\n        Is the server running locally and accepting\n        connections on Unix domain socket &quot;/var/run/postgresql/.s.PGSQL.5432&quot;?\n\n-------------------\n\n$ pgsql\nNo command 'pgsql' found, did you mean:\n Command 'psql' from package 'postgresql-client-common' (main)\npgsql: command not found\n</code></pre>\n<p>What if we do a search?</p><pre><code class=\"language-bash\">$ locate postgresql\n\n/etc/postgresql-common\n/etc/postgresql-common/user_clusters\n/opt/tableau-postgresql-odbc_9.5.3_amd64.deb\n/opt/tableau/tableau_driver/postgresql-odbc\n/opt/tableau/tableau_driver/postgresql-odbc/psqlodbcw.so\n/opt/tableau/tableau_server/packages/bin.20181.18.0510.1418/repo-jars/postgresql-9.4.1209.jar\n/opt/tableau/tableau_server/packages/clientfileservice.20181.18.0510.1418/postgresql-9.4.1208.jar\n/opt/tableau/tableau_server/packages/lib.20181.18.0510.1418/postgresql-9.4.1208.jar\n/opt/tableau/tableau_server/packages/lib.20181.18.0510.1418/postgresql-9.4.1209.jar\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/_int.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/adminpack.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/ascii_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/auth_delay.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/auto_explain.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/autoinc.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/btree_gin.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/btree_gist.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/chkpass.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/citext.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/cube.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/cyrillic_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dblink.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_int.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_snowball.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/dict_xsyn.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/earthdistance.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc2004_sjis2004.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_cn_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_jp_and_sjis.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_kr_and_mic.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/euc_tw_and_big5.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/file_fdw.so\n/opt/tableau/tableau_server/packages/pgsql.20181.18.0510.1418/lib/postgresql/fuzzystrmatch.so\n</code></pre>\n<p>...And so forth. There are over a thousand results. Postgres is definitely up and running, Tableau just hates you. Unfortunately for Tableau, this drove me to hate them back.</p><h2 id=\"enter-tsm-the-linux-tableau-cli\">Enter TSM: The Linux Tableau CLI</h2><p>On Linux exclusively, TSM is intended to be your one tool to configure Tableau Server. It's a fine tool, but it just so happens to omit critical information and capabilities that somebody who <em>owns their data</em> might want to know. At first glance, it seems innocent and helpful:</p><style>\n    td{\n        min-width: 224px;\n            text-align: left;\n    padding: 10px 20px !important;\n            line-height: 1.3;\n        text-align: left !important;\n    }\n    </style>\n\n<table style=\"cellpadding=\" 10px\"=\"\">\n  <thead>\n    <th>Command</th>\n    <th>Explanation</th>\n  </thead>\n  <tbody>\n    <tr>\n      <td>tsm configuration [parameters]</td>\n      <td>-- Set customization for Tableau Server.</td>\n    </tr>\n    <tr>\n      <td>tsm customize [parameters] </td>\n      <td>-- Set customization for Tableau Server.</td>\n    </tr>\n    <tr>\n      <td>tsm data-access [parameters]</td>\n      <td>-- Category of commands related to data-access.</td>\n    </tr>\n    <tr>\n      <td>tsm help  | [category]</td>\n      <td>-- Help for tsm commands</td>\n    </tr>\n    <tr>\n      <td>.tsm initialize [parameters]</td>\n      <td>-- Initialize Tableau Server</td>\n    </tr>\n    <tr>\n      <td>tsm jobs [parameters]</td>\n      <td> -- Category of commands related to async jobs.</td>\n    </tr>\n    <tr>\n      <td>tsm licenses [parameters]</td>\n      <td>-- Category of commands related to licensing.</td>\n    </tr>\n    <tr>\n      <td>tsm login [parameters] </td>\n      <td>-- Sign in to the TSM agent</td>\n    </tr>\n    <tr>\n      <td>tsm logout </td>\n      <td>-- Sign out from the TSM agent</td>\n    </tr>\n    <tr>\n      <td>tsm maintenance  [parameters]</td>\n      <td>-- Category of commands related to maintenance.</td>\n    </tr>\n    <tr>\n      <td>tsm pending-changes [parameters]</td>\n      <td>-- Category of commands for pending changes.</td>\n    </tr>\n    <tr>\n      <td>tsm register [parameters]</td>\n      <td>-- Register the product</td>\n    </tr>\n    <tr>\n      <td>tsm reset [parameters]</td>\n      <td>-- Clears the initial admin user so you can enter a new one. Once reset is completed you will need to use the tabcmd initialuser command to create a new initial user before remote users can sign in again</td>\n    </tr>\n    <tr>\n      <td>tsm restart [parameters]</td>\n      <td>-- Restart Tableau Server</td>\n    </tr>\n    <tr>\n      <td>tsm security [parameters]</td>\n      <td>-- Category of commands related to security configuration</td>\n    </tr>\n    <tr>\n      <td>tsm settings [parameters]</td>\n      <td>-- Category of commands related to configuration and topology settings</td>\n    </tr>\n    <tr>\n      <td>tsm sites [parameters]</td>\n      <td>-- Category of commands related to site import and export</td>\n    </tr>\n    <tr>\n      <td>tsm start [parameters]</td>\n      <td>-- Start Tableau Server</td>\n    </tr>\n    <tr>\n      <td>tsm status [parameters]</td>\n      <td>-- View Tableau Server status</td>\n    </tr>\n    <tr>\n      <td>tsm stop [parameters]</td>\n      <td>-- Stop Tableau Server</td>\n    </tr>\n    <tr>\n      <td>tsm topology  [parameters] </td>\n      <td>-- Category of commands related to server topology</td>\n    </tr>\n    <tr>\n      <td>tsm user-identity-store [parameters]</td>\n      <td>-- Category of commands related to user-identity-store</td>\n    </tr>\n    <tr>\n      <td>tsm version </td>\n      <td>-- Displays version information.</td>\n    </tr>\n  </tbody>\n</table>\n<!-- DivTable.com -->\n<h2 id=\"the-red-herring\">The Red Herring</h2><p>Tableau owns Google results, period. Any search query containing the word \"Tableau\" is dominated with pages of content Tableau would <em>prefer</em> you abide by, and of these things is the creation of a <em>readonly</em> user to access the Postgres database. The catch here is that the <strong>readonly</strong> user can't read all tables at all: there are certain tables reserved specifically for a Postgres tableau \"Superuser\", which is <em>utterly and entirely undocumented on Linux.</em> For all I know, I my be the first to publish an article of this sort, but let's hope not.</p><p>First, let's see which users exist on Postgres using TSM:</p><pre><code class=\"language-bash\">$ tsm data-access repository-access list\n\nUser       Access\nTableau    true\nReadonly   true\n</code></pre>\n<p>There's that Readonly user we talked about: feel free to play around with that user to create meaningless insights if you so please. On the other hand we have a <strong>Tableau</strong> user, which happens to be a Postgres superuser. If you don't feel comfortable accessing Superuser privileges, I suggest you leave now. This is <strong>Hackers And Slackers,</strong> and we don't fuck around; especially when software to the tune of 1 thousand dollars hides our data from us.</p><h2 id=\"operation-shock-and-awe\">Operation Shock and Awe</h2><p>There's a little command called <code>tsm configuration</code> which lets you set some cute variables for your server. The documentation is <a href=\"https://onlinehelp.tableau.com/current/server-linux/en-us/cli_configuration-set_tsm.htm\">here</a>, but there's just one piece missing, and it's the one we need.</p><p><strong>Tableau </strong>may be our Postgres Superuser, but what would its password possibly be? This isn't documented anywhere. Consider this my gift to you:</p><pre><code class=\"language-bash\">$ tsm configuration get -k pgsql.adminpassword\n145v756270d3467bv3140af5f01v5c7e4976bcee\n</code></pre>\n<p>Could it be? Did Tableau intentionally prevent users from access PostgreSQL directly from command line and hide an undocumented password? Yes, it does all of those things. It's time to fuck shit up.</p><h2 id=\"claim-ownership\">Claim Ownership</h2><p>We've made it this far. The bullet is in the chamber. Go ahead and take what is rightfully yours.</p><pre><code class=\"language-bash\">tsm data-access repository-access enable --repository-username Tableau\n--repository-password 145v756270d3467bv3140af5f01v5c7e4976bcee\n</code></pre>\n<p>Just make sure port 8060 is open on your VPC and you're in. Considering that there are zero search results for accomplishing this on Linux, it looks like it's just you and me now. One of us may likely go mad with power and turn on one another. That is the way of the Sith. Welcome.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/winner.png\" class=\"kg-image\"><figcaption>Unspeakable treasures lie within.</figcaption></figure><h2 id=\"moving-on-up\">Moving on Up</h2><p>Feel free to cruise the <strong>workgroup</strong> database for now and wreck havoc. As fun as this has been, I have another trick up my sleeve. You've spent a lot of time building Worksheets and views; what if you could programmatically sync to an external database and autogenerate a schema for these views, updated on a scheduler, to source data for products you're building?</p><p>Thats sounds a lot like what a useful product would do. Stick around, and next time we'll be beating Tableau down for everything its worth. </p>","url":"https://hackersandslackers.com/hacking-linux-tableau-server/","uuid":"4bcb1c4b-bbe2-428c-b7ee-fa7adc751973","page":false,"codeinjection_foot":"<script>\n    hljs.configure({languages:['bash']});\n</script>","codeinjection_head":"","comment_id":"5b5975a75c6b8259b902b66a"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736aa","title":"Create a VPS with Google Cloud: Introducing Compute Engine","slug":"setting-up-dns-with-google-cloud-platform","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","excerpt":"Spin up a VPS and configure DNS with relative ease.","custom_excerpt":"Spin up a VPS and configure DNS with relative ease.","created_at_pretty":"14 July, 2018","published_at_pretty":"14 July, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-07-14T10:28:34.000-04:00","published_at":"2018-07-14T14:55:03.000-04:00","updated_at":"2019-02-14T02:29:40.000-05:00","meta_title":"Google Cloud Platform: Creating a VPS | Hackers and Slackers","meta_description":"Google Cloud Platform is a compelling choice for respectable enterprises, particularly those with a sense of style and curiosity.","og_description":"The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity just yet. Let's set up a server to see what the hype is about. Today'll we'll be creating a standard Linux instance and walking through the steps to configure an existing DNS for said instance.","og_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","og_title":"Create a VPS with Google Cloud: Compute Engine","twitter_description":"The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity just yet. Let's set up a server to see what the hype is about. Today'll we'll be creating a standard Linux instance and walking through the steps to configure an existing DNS for said instance.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","twitter_title":"Create a VPS with Google Cloud: Compute Engine","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"}],"plaintext":"For the last few weeks I've been enamored with Google's cloud platform, aptly\nnamed Google Cloud Platform. GCP contains the things you might expect from a\nyoung player in the 'screw AWS' space: much of what exists on AWS has an\nequivalent on GPC, but certain subtleties exist, such as the lack of Python\nserverless functions and so forth. That said, GCP makes up for any shortcomings\nby leveraging services exclusive to Google.\n\nIn my opinion, GCP is the first contender in the market to package enterprise\ncloud computing in a satisfying way. It's clear GCP has assigned UI and Product\nManagement resources to their platform, where Amazon clearly did not. while not\nwithout its shortcomings, it's obvious Google has chosen usability as a key\ndifferentiator from AWS.\n\nAside from the UI, GCP offers plenty of fun functionality such as their cloud\nlauncher. This is the equivalent of one-click deploys for cool stuff, whether\nthey be services to add to your VPC, Google APIs, Datasets, or what have you.\nThe ease of plug-and-play these plug-and-play services make GCP a compelling\nchoice for a respectable enterprise which hasn't lost the gift of curiosity.\n\nIt's like product hunt... on crack.The best way to get a feel for what value a\nproduct has would be use it, of course. In the interest of becoming familiar\nwith Google Cloud, we'll execute the most basic task of setting up a VPS to\ndeploy code to. This practice will end up touching on many of GCP's core\nservices which will allow us to grasp the basic offerings of the product, as\nwell as its strengths and weakness.\n\nDoes in Fact Compute \nGCP cutely names their server's Compute Engines,  which are at least more\ntolerable than, say, EC2 instances. I'm just going to call them servers because\nI'm not the type of person who orders a \"tall\" at Starbucks.\n\nCreate a \"project\" in Google Cloud, and you'll immediately land at a dashboard.\nAll Google's services are tucked away in the left-hand menu. Open that bad boy\nup and find Compute Engine.\n\nShhh, it's thinking.Select create. As opposed to the preset choices of VPCS you might be used to,\nGoogle allows us to customize our VPS to our exact technical specifications on a\nsliding scale. Want 96 processing cores, but only a single GB of RAM? No\nproblem, if that's what you're into. Weirdo.\n\nAs well as picking between the usual Linux distributions, Compute Engine also\nallows customers to select their number of GPUs, as well as the generation of\nIntel CPU their instance will run on.\n\nDat customization thoWe want traffic to hit this instance, so make sure you\ncheck Allow HTTP  traffic  and Allow HTTPS traffic  before continuing. Once your\ninstance is created, you should immediately able to SSH into your server via\nGCP's browser client.\n\nThe App Engine\nGCP is not without its own fair share of arbitrary product classifications. DNS\nrecords and hosts are contained within the App Engine  service of the platform.\nFind the App Engine service in the left hand navigation, and scroll down to the \nsettings  link:\n\nAllllll the way at the bottom.Here's we'll be able to see a \"custom domains\" tab\nwhich allows us to point a domain we've purchased from a service like Namecheap \n or what-have-you to Google Cloud. I'll personally be walking though this\nexample by directing a pointless domain called memegenerator.io  I purchased on\nNamecheap for no good reason.\n\nWhen you add a custom domain via this screen, you'll immediately be asked to\nverify ownership over the domain via the familiar Google Webmaster tool, which\nyou'll be redirected to automatically.\n\nBack to Your Registrar\nChances are you've dealt with verification via Google webmaster before, but this\ntime we've only given the option to do this via DNS. Select your registrar in\nthe dropdown in order to reveal a Google-generated record used to verify your\ndomain. \n\nPlease don't tell me you use GoDaddy.The resulting value will need to be added\nas a .txt record before we can actually point your domain to Google's servers.\n\nIf you're using Namecheap like I am, log in to your dashboard and find your\ndomain by clicking \"manage domain\". Make sure you're under the \"advanced DNS\"\ntab:\n\nEven if you're not using Namecheap, this shouldn't be much different.Delete all\nexisting records. Then create a TXT record (with @ as the host) and input the\nvalue that Google provided you earlier. Now, when you return to the webmaster\ntool, clicking verify tool should  pick up on this change. \n\nIf the webmaster tool does not pick up on this verification right away, don't\npanic. This happens fairly often - just frantically keep making sure everything\nis set up correctly while mashing the verify button.Navigate back to the Custom\nDomains tab in GCP and continue the process- you should see that your domain is\nverified. You'll be prompted to enter any subdomains you'd GCP to pick up on\nhere. Wrap that up and save.\n\n\n\nMake it Rain with Records\nOh, we're far from over buddy. We need to go back to update our A and AAAA\nrecords, now that Google as bestowed that privilege upon us. You should see a\ntable such as the one below:\n\nType\n Data\n Alias\n A\n 216.239.32.21\n A\n 216.239.34.21\n A\n 216.239.36.21\n A\n 216.239.38.21\n AAAA\n 2001:4860:4802:32::15\n AAAA\n 2001:4860:4802:34::15\n AAAA\n 2001:4860:4802:36::15\n AAAA\n 2001:4860:4802:38::15\n CNAME\n ghs.googlehosted.com\n www\n Copy that into your registrar's custom DNS records. Have fun with that.\n\nCloud DNS\nYou may have noticed that we haven't actually specified our Nameservers yet.\nNobody said this was going to be fun; if it were, we probably wouldn't need this\ntutorial. In the GCP search bar, search for Cloud DNS. Create a Zone, and leave\nDNSSEC off.\n\n\n\nBefore we do this next part, I'd like to interject and mention that you did a\nspectacular job of creating all those records and pasting all those values\nearlier. Considering you seem to have a knack for this, it probably won't hurt\nto know that we need to go back into our registrar a third time to paste some\nvalues. You got this. \n\nGoogle's nameservers have now been generated and exposed to you so we can \nactually  point our domain to something meaningful now. You should have 4\nnameservers like the following:\n\nName\n Type\n TTL\n Data\n memegenerator.io.\n NS\n 21600\n ns-cloud-b1.googledomains.com.\n ns-cloud-b2.googledomains.com.\n ns-cloud-b3.googledomains.com.\n ns-cloud-b4.googledomains.com.\n Assign a Static IP\nOkay, we're officially done messing around with our registrar. In the GCP search\nbar, search for External IP addresses.  From there, click the \"Reserve static\nAddress\" button at the top of the screen. This will prompt you with a short\nform: the only important field to fill out here is the \"Attached to\"  dropdown,\nwhich denotes which server instance the IP will be assigned to.\n\nCompute Engine Instance Settings\nShit, is there even more? OK, we're almost done here. Go to your Compute Engine\ninstance you set up earlier. Click \"Edit\". Scroll to the Network Interface \nsection and map the Static IP we created from earlier. Also, go ahead and enter\nyour PTR record:\n\nWhen will it end... please send help.FINAL CHAPTER: Firewall Settings\nLook, I just want to say you're all doing a great job so far. All of you. We're\nall a team here; let's stick together and see this through. Search for Firewall\nRules  and selected Create a Firewall Rule. Name it whatever you want.\n\n * Targets  - This will be where our traffic routes. We want to route to our\n   instance, which is a specified service account.\n * Target service account  - Referring to the above, this is where we select the\n   computer instance we want to hit.\n * Target service account  scope  - Select \"in this project\".\n * Source Filter - Once again, select specified service account.\n * Source service account  scope - Select \"in this project\"\n * Source service account  - This is where we say where the traffic is coming\n   from. It's coming from the App engine, as this is where we specified our DNS.\n * For IPs  and ports, well, do what you want. It's your server. \n\nGet at it\nWell, there you have it. Hopefully by now the domain you've painstaking\nconfigured now points to your server, so you can go ahead and configure your\nwebserver settings or whatever it is you do.\n\nAlright fine, so GCP isn't completely free of its own redundancies. As much as I\nlove to hate on AWS, it seems almost inevitable at this point that any\nenterprise cloud service will maintain a certain level of obscure processes.\nThis is great for flexibility when scaling, but let's be honest: if these\nplatforms were easy to use, who would pay for the certifications?\n\nCheekiness aside, I've become a strong fan of GCP. Google seems to have hit a\nmiddle ground between being user-friendly and powerful, which fills a niché\nwe'll realize was desperately needed. For a fair review of the platform itself,\nI find myself agreeing mostly with this stranger from the internet: \nhttps://www.deps.co/blog/google-cloud-platform-good-bad-ugly/","html":"<p>For the last few weeks I've been enamored with Google's cloud platform, aptly named Google Cloud Platform. GCP contains the things you might expect from a young player in the 'screw AWS' space: much of what exists on AWS has an equivalent on GPC, but certain subtleties exist, such as the lack of Python serverless functions and so forth. That said, GCP makes up for any shortcomings by leveraging services exclusive to Google.</p><p>In my opinion, GCP is the first contender in the market to package enterprise cloud computing in a satisfying way. It's clear GCP has assigned UI and Product Management resources to their platform, where Amazon clearly did not. while not without its shortcomings, it's obvious Google has chosen usability as a key differentiator from AWS.</p><p>Aside from the UI, GCP offers plenty of fun functionality such as their cloud launcher. This is the equivalent of one-click deploys for cool stuff, whether they be services to add to your VPC, Google APIs, Datasets, or what have you. The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-07-14_10-36-02.gif\" class=\"kg-image\"><figcaption>It's like product hunt... on crack.</figcaption></figure><p>The best way to get a feel for what value a product has would be use it, of course. In the interest of becoming familiar with Google Cloud, we'll execute the most basic task of setting up a VPS to deploy code to. This practice will end up touching on many of GCP's core services which will allow us to grasp the basic offerings of the product, as well as its strengths and weakness.</p><h2 id=\"does-in-fact-compute\">Does in Fact Compute </h2><p>GCP cutely names their server's <em>Compute Engines,</em> which are at least more tolerable than, say, EC2 instances. I'm just going to call them servers because I'm not the type of person who orders a \"tall\" at Starbucks.</p><p>Create a \"project\" in Google Cloud, and you'll immediately land at a dashboard. All Google's services are tucked away in the left-hand menu. Open that bad boy up and find Compute Engine.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-07-14_10-44-14.gif\" class=\"kg-image\"><figcaption>Shhh, it's thinking.</figcaption></figure><p>Select <em>create</em>. As opposed to the preset choices of VPCS you might be used to, Google allows us to customize our VPS to our exact technical specifications on a sliding scale. Want 96 processing cores, but only a single GB of RAM? No problem, if that's what you're into. Weirdo.</p><p>As well as picking between the usual Linux distributions, Compute Engine also allows customers to select their number of GPUs, as well as the generation of Intel CPU their instance will run on.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-10.48.02-AM.png\" class=\"kg-image\"><figcaption>Dat customization tho</figcaption></figure><p>We want traffic to hit this instance, so make sure you check <strong>Allow HTTP</strong> <strong>traffic</strong> and <strong>Allow HTTPS traffic</strong> before continuing. Once your instance is created, you should immediately able to SSH into your server via GCP's browser client.</p><h2 id=\"the-app-engine\">The App Engine</h2><p>GCP is not without its own fair share of arbitrary product classifications. DNS records and hosts are contained within the <strong>App Engine</strong> service of the platform. Find the App Engine service in the left hand navigation, and scroll down to the <em>settings</em> link:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-10.58.19-AM.png\" class=\"kg-image\"><figcaption>Allllll the way at the bottom.</figcaption></figure><p>Here's we'll be able to see a \"custom domains\" tab which allows us to point a domain we've purchased from a service like <strong>Namecheap</strong><em> </em>or what-have-you to Google Cloud. I'll personally be walking though this example by directing a pointless domain called <em>memegenerator.io</em> I purchased on Namecheap for no good reason.</p><p>When you add a custom domain via this screen, you'll immediately be asked to verify ownership over the domain via the familiar Google Webmaster tool, which you'll be redirected to automatically.</p><h2 id=\"back-to-your-registrar\">Back to Your Registrar</h2><p>Chances are you've dealt with verification via Google webmaster before, but this time we've only given the option to do this via DNS. Select your registrar in the dropdown in order to reveal a Google-generated record used to verify your domain. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.04.07-AM.png\" class=\"kg-image\"><figcaption>Please don't tell me you use GoDaddy.</figcaption></figure><p>The resulting value will need to be added as a .txt record before we can actually point your domain to Google's servers.</p><p>If you're using Namecheap like I am, log in to your dashboard and find your domain by clicking \"manage domain\". Make sure you're under the \"advanced DNS\" tab:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.08.58-AM.png\" class=\"kg-image\"><figcaption>Even if you're not using Namecheap, this shouldn't be much different.</figcaption></figure><p>Delete all existing records. Then create a TXT record (with @ as the host) and input the value that Google provided you earlier. Now, when you return to the webmaster tool, clicking verify tool <em>should</em> pick up on this change. </p><div class=\"protip\">\nIf the webmaster tool does not pick up on this verification right away, don't panic. This happens fairly often - just frantically keep making sure everything is set up correctly while mashing the verify button.\n</div><p>Navigate back to the Custom Domains tab in GCP and continue the process- you should see that your domain is verified. You'll be prompted to enter any subdomains you'd GCP to pick up on here. Wrap that up and save.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.13.27-AM.png\" class=\"kg-image\"></figure><p></p><h2 id=\"make-it-rain-with-records\">Make it Rain with Records</h2><p>Oh, we're far from over buddy. We need to go back to update our A and AAAA records, now that Google as bestowed that privilege upon us. You should see a table such as the one below:</p><div class=\"tablecontainer\">\n<table>\n  <thead>\n    <tr>\n      <th>Type</th>\n      <th>Data</th>\n      <th>Alias</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>A</td>\n      <td>216.239.32.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.34.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.36.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.38.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:32::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:34::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:36::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:38::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>CNAME</td>\n      <td>ghs.googlehosted.com</td>\n      <td>www</td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Copy that into your registrar's custom DNS records. Have fun with that.</p><h2 id=\"cloud-dns\">Cloud DNS</h2><p>You may have noticed that we haven't actually specified our Nameservers yet. Nobody said this was going to be fun; if it were, we probably wouldn't need this tutorial. In the GCP search bar, search for <em>Cloud DNS</em>. Create a Zone, and leave DNSSEC off.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.25.33-AM.png\" class=\"kg-image\"></figure><p></p><p>Before we do this next part, I'd like to interject and mention that you did a spectacular job of creating all those records and pasting all those values earlier. Considering you seem to have a knack for this, it probably won't hurt to know that we need to go back into our registrar a third time to paste some values. You got this. </p><p>Google's nameservers have now been generated and exposed to you so we can <em>actually</em> point our domain to something meaningful now. You should have 4 nameservers like the following:</p><table>\n  <thead>\n    <tr>\n      <th>Name</th>\n      <th>Type</th>\n      <th>TTL</th>\n      <th>Data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>memegenerator.io.</td>\n      <td>NS</td>\n      <td>21600</td>\n      <td>ns-cloud-b1.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b2.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b3.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b4.googledomains.com.</td>\n    </tr>\n  </tbody>\n</table><h2 id=\"assign-a-static-ip\">Assign a Static IP</h2><p>Okay, we're officially done messing around with our registrar. In the GCP search bar, search for <strong>External IP addresses.</strong> From there, click the \"Reserve static Address\" button at the top of the screen. This will prompt you with a short form: the only important field to fill out here is the <em>\"Attached to\"</em> dropdown, which denotes which server instance the IP will be assigned to.</p><h2 id=\"compute-engine-instance-settings\">Compute Engine Instance Settings</h2><p>Shit, is there even more? OK, we're almost done here. Go to your Compute Engine instance you set up earlier. Click \"Edit\". Scroll to the <em>Network Interface</em> section and map the Static IP we created from earlier. Also, go ahead and enter your PTR record:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.47.24-AM.png\" class=\"kg-image\"><figcaption>When will it end... please send help.</figcaption></figure><h2 id=\"final-chapter-firewall-settings\">FINAL CHAPTER: Firewall Settings</h2><p>Look, I just want to say you're all doing a great job so far. All of you. We're all a team here; let's stick together and see this through. Search for <strong>Firewall Rules</strong> and selected <em>Create a Firewall Rule. </em>Name it whatever you want.</p><ul><li><strong>Targets</strong> - This will be where our traffic routes. We want to route to our instance, which is a <em>specified service account.</em></li><li><strong>Target service account</strong> - Referring to the above, this is where we select the computer instance we want to hit.</li><li><strong>Target service account</strong> <strong>scope</strong> - Select \"in this project\".</li><li><strong>Source Filter </strong>- Once again, select <em>specified service account.</em></li><li><strong>Source service account</strong> <strong>scope </strong>- Select \"in this project\"</li><li><strong>Source service account</strong> - This is where we say where the traffic is coming from. It's coming from the <em>App engine</em>, as this is where we specified our DNS.</li><li>For <strong>IPs</strong> and <strong>ports, </strong>well, do what you want. It's your server. </li></ul><h2 id=\"get-at-it\">Get at it</h2><p>Well, there you have it. Hopefully by now the domain you've painstaking configured now points to your server, so you can go ahead and configure your webserver settings or whatever it is you do.</p><p>Alright fine, so GCP isn't completely free of its own redundancies. As much as I love to hate on AWS, it seems almost inevitable at this point that any enterprise cloud service will maintain a certain level of obscure processes. This is great for flexibility when scaling, but let's be honest: if these platforms were easy to use, who would pay for the certifications?</p><p>Cheekiness aside, I've become a strong fan of GCP. Google seems to have hit a middle ground between being user-friendly and powerful, which fills a niché we'll realize was desperately needed. For a fair review of the platform itself, I find myself agreeing mostly with this stranger from the internet: <a href=\"https://www.deps.co/blog/google-cloud-platform-good-bad-ugly/\">https://www.deps.co/blog/google-cloud-platform-good-bad-ugly/</a></p>","url":"https://hackersandslackers.com/setting-up-dns-with-google-cloud-platform/","uuid":"ed22ae1a-b636-48dd-8502-141ae08fa9d9","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b4a08921c20005e9422c108"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736a0","title":"Weekend Worker #2 - Cert Renewals","slug":"renewing-certs","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/encrypt3@2x.jpg","excerpt":"Renewing LetsEncrypt Certs with Certbot.","custom_excerpt":"Renewing LetsEncrypt Certs with Certbot.","created_at_pretty":"09 July, 2018","published_at_pretty":"09 July, 2018","updated_at_pretty":"19 September, 2018","created_at":"2018-07-08T20:25:30.000-04:00","published_at":"2018-07-08T20:33:37.000-04:00","updated_at":"2018-09-19T02:56:32.000-04:00","meta_title":"Weekend Worker #2 - Cert Renewals | Hackers and Slackers","meta_description":"LetsEncrypt for the awesome temporary free SSL Certs they offer. In the last use I became familiar with and implemented the use of certbot. ","og_description":"LetsEncrypt for the awesome temporary free SSL Certs they offer. In the last use I became familiar with and implemented the use of certbot. ","og_image":"https://hackersandslackers.com/content/images/2018/07/encrypt3@2x.jpg","og_title":"Weekend Worker #2 - Cert Renewals","twitter_description":"LetsEncrypt for the awesome temporary free SSL Certs they offer. In the last use I became familiar with and implemented the use of certbot. ","twitter_image":"https://hackersandslackers.com/content/images/2018/07/encrypt3@2x.jpg","twitter_title":"Weekend Worker 2: Cert Renewals | Hackers and Slackers","authors":[{"name":"Ryan Rosado","slug":"xodz","bio":"World renowned DJ who got his start from being famous on the internet. Averages 3 headshots per second in daily life and pays for all and essentials in bitcoin.","profile_image":"https://hackersandslackers.com/content/images/2019/03/ryan2.jpg","twitter":"@Zawdz","facebook":null,"website":"http://twitch.tv/xodz/videos/all"}],"primary_author":{"name":"Ryan Rosado","slug":"xodz","bio":"World renowned DJ who got his start from being famous on the internet. Averages 3 headshots per second in daily life and pays for all and essentials in bitcoin.","profile_image":"https://hackersandslackers.com/content/images/2019/03/ryan2.jpg","twitter":"@Zawdz","facebook":null,"website":"http://twitch.tv/xodz/videos/all"},"primary_tag":{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},"tags":[{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"}],"plaintext":"It's Sunday and you know what that means... time to catch up on work outside of\nwork. \n\nI recently used LetsEncrypt for the awesome temporary free SSL Certs they offer.\nIn the last use I became familiar with and implemented the use of certbot\n[https://dedisource.com/docs/display/Public/What+is+Certbot]. \n\nI did not go so far as to automate certbot\n[https://dedisource.com/docs/display/Public/What+is+Certbot]  to check for and\nupdate near-expiring certs. But this is coming up soon...\n\nHowever, it's come time to renew so I've had to reteach myself how to do it,\ngrasping for all logs in 'history' over a few different machines, I was able to\neasily re-do it once more and this time - document Renewing LetsEncrypt Certs\nwith Certbot\n[https://dedisource.com/docs/display/Public/Renewing+LetsEncrypt+Certs+with+Certbot]\n.","html":"<p>It's Sunday and you know what that means... time to catch up on work outside of work. </p><p>I recently used LetsEncrypt for the awesome temporary free SSL Certs they offer. In the last use I became familiar with and implemented the use of <a href=\"https://dedisource.com/docs/display/Public/What+is+Certbot\">certbot</a>. </p><p>I did not go so far as to automate <a href=\"https://dedisource.com/docs/display/Public/What+is+Certbot\">certbot</a> to check for and update near-expiring certs. But this is coming up soon...</p><p>However, it's come time to renew so I've had to reteach myself how to do it, grasping for all logs in 'history' over a few different machines, I was able to easily re-do it once more and this time - document <a href=\"https://dedisource.com/docs/display/Public/Renewing+LetsEncrypt+Certs+with+Certbot\">Renewing LetsEncrypt Certs with Certbot</a>.</p>","url":"https://hackersandslackers.com/renewing-certs/","uuid":"0b6e2064-d1b0-4b92-93c1-4741899bb502","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b42ab7a2d99b9040e300f7e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673685","title":"Weekend Worker #1","slug":"weekend-worker-1","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/06/xodz@2x.jpg","excerpt":"Implementing an automatic backup system.","custom_excerpt":"Implementing an automatic backup system.","created_at_pretty":"24 June, 2018","published_at_pretty":"24 June, 2018","updated_at_pretty":"25 July, 2018","created_at":"2018-06-24T11:13:12.000-04:00","published_at":"2018-06-24T11:57:06.000-04:00","updated_at":"2018-07-24T22:06:03.000-04:00","meta_title":"Weekend Worker #1 | Hackers and Slackers","meta_description":"Implementing an automatic backup system","og_description":"Implementing an automatic backup system","og_image":"https://hackersandslackers.com/content/images/2018/06/xodz@2x.jpg","og_title":"Weekend Worker #1","twitter_description":"Implementing an automatic backup system","twitter_image":"https://hackersandslackers.com/content/images/2018/06/xodz@2x.jpg","twitter_title":"Weekend Worker #1","authors":[{"name":"Ryan Rosado","slug":"xodz","bio":"World renowned DJ who got his start from being famous on the internet. Averages 3 headshots per second in daily life and pays for all and essentials in bitcoin.","profile_image":"https://hackersandslackers.com/content/images/2019/03/ryan2.jpg","twitter":"@Zawdz","facebook":null,"website":"http://twitch.tv/xodz/videos/all"}],"primary_author":{"name":"Ryan Rosado","slug":"xodz","bio":"World renowned DJ who got his start from being famous on the internet. Averages 3 headshots per second in daily life and pays for all and essentials in bitcoin.","profile_image":"https://hackersandslackers.com/content/images/2019/03/ryan2.jpg","twitter":"@Zawdz","facebook":null,"website":"http://twitch.tv/xodz/videos/all"},"primary_tag":{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},"tags":[{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"}],"plaintext":"Hello and Welcome, this is the first installment of \"Weekend Worker\" series.\n\nToday as a Weekend Worker i'll be implementing an automatic backup system to\nbackup each individual client website.\n\nWe'll be using the following technologies:\n\n * Linux cron job\n * Bash\n * Ansible\n * Docker\n * AWS ECS\n * VNC server\n\nAnd we'll setup our dev environment on our home Windows desktop with the\nfollowing tools:\n\n * Ansible for Windows (to launch dev tests)\n * Visual Studio Code (for editing and pushing updates)\n * Git (so our remote prod server can grab the code updates)\n * VNCviewer (to access prod remotely)\n * Bitbucket (for source control)\n\nPreparing the Env:\n\nDownload Visual Studio Code\nDownload Git Bash from git-scm\nUse terminal window within Visual Studio Code, travel to repository location and\ninitiate git & pull from master. (not within scope of this document)\nat same location, we need Ansible-playbook to work so we will get Ansible for\nWindows.\n\nOn second thought, we won't install Ansible for Windows. We will just run the\nAnsible-playbook on our remote system - after we push and pull the updates from\nsource control. We can use the --check flag or dev inventory for testing.\n\nStarting the Work:\nCurrently, my client's websites exist within a docker container per website.\n\nThe plan is to have a cron job to run an ansible-playbook which will create a\nDocker Image out of each customer's Docker Container. The Docker Image will be\npushed to AWS ECS Docker Registry regularly.\n\nWe will have a loop in our Ansible scripts so the backup is individually applied\nto each item (website) in our Inventory file.\n\nCron will run the bash script to initiate the ansible-playbook run.\n\nFirst we will follow this document to allow Ansible to prepare our connectivity\nand authenticate with AWS ECS\nhttps://dedisource.com/docs/display/Public/Ansible+amazon-ecr-credential-helper+module\n\nThen, we will need to convert these steps to Ansible script actions using the\nAnsible Command module\nhttps://dedisource.com/docs/display/Public/Backup+container+to+registry\n\nLastly, when we have the Ansible Scripts working to Enable Connection to ECS\n[https://dedisource.com/docs/display/Public/Enable+Connection+to+AWS+ECS], \nPackage Docker Container to Image\n[https://dedisource.com/docs/display/Public/Package+Docker+Container+to+Image],\nTag Image and Push to AWS ECS registry\n[https://dedisource.com/docs/display/Public/Tag+Image+and+Push+to+AWS+ECS+registry]\n\nWe will Set Cron Job for Shell Script\n[https://dedisource.com/docs/display/Public/Cron+Job+for+Shell+Script]  to run\nonce per day. We will have the Bash Shell Script to Launch Ansible Playbook\n[https://dedisource.com/docs/display/Public/Bash+Shell+Script+to+Launch+Ansible+Playbook]\n\nAnd that will about do it for us today.\n\nThanks","html":"<p>Hello and Welcome, this is the first installment of &quot;Weekend Worker&quot; series.</p>\n<p>Today as a Weekend Worker i'll be implementing an automatic backup system to backup each individual client website.</p>\n<p>We'll be using the following technologies:</p>\n<ul>\n<li>Linux cron job</li>\n<li>Bash</li>\n<li>Ansible</li>\n<li>Docker</li>\n<li>AWS ECS</li>\n<li>VNC server</li>\n</ul>\n<p>And we'll setup our dev environment on our home Windows desktop with the following tools:</p>\n<ul>\n<li>Ansible for Windows (to launch dev tests)</li>\n<li>Visual Studio Code (for editing and pushing updates)</li>\n<li>Git (so our remote prod server can grab the code updates)</li>\n<li>VNCviewer (to access prod remotely)</li>\n<li>Bitbucket (for source control)</li>\n</ul>\n<p>Preparing the Env:</p>\n<p>Download Visual Studio Code<br>\nDownload Git Bash from git-scm<br>\nUse terminal window within Visual Studio Code, travel to repository location and initiate git &amp; pull from master. (not within scope of this document)<br>\nat same location, we need Ansible-playbook to work so we will get Ansible for Windows.</p>\n<p>On second thought, we won't install Ansible for Windows. We will just run the Ansible-playbook on our remote system - after we push and pull the updates from source control. We can use the --check flag or dev inventory for testing.</p>\n<p>Starting the Work:<br>\nCurrently, my client's websites exist within a docker container per website.</p>\n<p>The plan is to have a cron job to run an ansible-playbook which will create a Docker Image out of each customer's Docker Container. The Docker Image will be pushed to AWS ECS Docker Registry regularly.</p>\n<p>We will have a loop in our Ansible scripts so the backup is individually applied to each item (website) in our Inventory file.</p>\n<p>Cron will run the bash script to initiate the ansible-playbook run.</p>\n<p>First we will follow this document to allow Ansible to prepare our connectivity and authenticate with AWS ECS<br>\n<a href=\"https://dedisource.com/docs/display/Public/Ansible+amazon-ecr-credential-helper+module\">https://dedisource.com/docs/display/Public/Ansible+amazon-ecr-credential-helper+module</a></p>\n<p>Then, we will need to convert these steps to Ansible script actions using the Ansible Command module<br>\n<a href=\"https://dedisource.com/docs/display/Public/Backup+container+to+registry\">https://dedisource.com/docs/display/Public/Backup+container+to+registry</a></p>\n<p>Lastly, when we have the Ansible Scripts working to <a href=\"https://dedisource.com/docs/display/Public/Enable+Connection+to+AWS+ECS\">Enable Connection to ECS</a>, <a href=\"https://dedisource.com/docs/display/Public/Package+Docker+Container+to+Image\">Package Docker Container to Image</a>,<br>\n<a href=\"https://dedisource.com/docs/display/Public/Tag+Image+and+Push+to+AWS+ECS+registry\">Tag Image and Push to AWS ECS registry</a></p>\n<p>We will <a href=\"https://dedisource.com/docs/display/Public/Cron+Job+for+Shell+Script\">Set Cron Job for Shell Script</a> to run once per day. We will have the <a href=\"https://dedisource.com/docs/display/Public/Bash+Shell+Script+to+Launch+Ansible+Playbook\">Bash Shell Script to Launch Ansible Playbook</a></p>\n<p>And that will about do it for us today.</p>\n<p>Thanks</p>\n","url":"https://hackersandslackers.com/weekend-worker-1/","uuid":"008bc16f-28fa-4825-bb9f-5d77a5be63df","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b2fb5085e55265a190ee2ae"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867366f","title":"AWS Adventures: Why Can't I SSH Into My Damn EC2 Instance?","slug":"aws-adventures-why-cant-i-ssh-into-my-damn-ec2-instance","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/06/ec2@2x.jpg","excerpt":"Watch as I struggle with the cloud!  My pain, your gain!","custom_excerpt":"Watch as I struggle with the cloud!  My pain, your gain!","created_at_pretty":"06 June, 2018","published_at_pretty":"06 June, 2018","updated_at_pretty":"25 July, 2018","created_at":"2018-06-06T19:27:37.000-04:00","published_at":"2018-06-06T19:41:47.000-04:00","updated_at":"2018-07-24T22:06:03.000-04:00","meta_title":"AWS Adventures: Why Can't I SSH Into My Damn EC2 Instance? | Hackers and Slackers","meta_description":"Watch as I struggle with the cloud!  My pain, your gain!","og_description":"Watch as I struggle with the cloud!  My pain, your gain!","og_image":"https://hackersandslackers.com/content/images/2018/06/ec2@2x.jpg","og_title":"AWS Adventures: Why Can't I SSH Into My Damn EC2 Instance?","twitter_description":"Watch as I struggle with the cloud!  My pain, your gain!","twitter_image":"https://hackersandslackers.com/content/images/2018/06/ec2@2x.jpg","twitter_title":"AWS Adventures: Why Can't I SSH Into My Damn EC2 Instance?","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"}],"plaintext":"Sometimes I find myself responsible for setting up and maintaining my own\ninfrastructure for doing data stuff. In light of this, I've taken it upon myself\nto learn more about AWS in order for this experience to be less terrifying. I've\nbeen following a course on Udemy for the AWS Solutions Architect Certification.\nSo far, so good.\n\nCut to the EC2 section. Has you spin up a little EC2 instance and SSH into it. I\nwould find myself SSHing in, then after a few minutes my connection would be\nreset and then any further attempts would be met with a Resource temporarily\nunavailable.\n\nI googled around. Lots of stuff that didn't work. I logged into a client's\nconsole that I had access to, tried to see if there were any settings that were\ndifferent from mine. What on Earth did I mess with? I first made an AWS account\nin 2012, and go into phases of messing with my personal account and forgetting\nit exists. I must have hit some kind of \"Make it so every server you launch is\nunreachable and useless\" button at some point, then forgotten where this button\nwas.\n\nIt's a tough little jungle. There's numerous different versions of security on\nAWS. Then, finally, I noticed an angel on StackOverflow posted that you should\ncheck to see whether you have a public DNS address. Turns out I didn't! \nhttps://stackoverflow.com/questions/20941704/ec2-instance-has-no-public-dns\n\n 1. Go to console.aws.amazon.com\n 2. Go To Services -> VPC\n 3. Open Your VPCs\n 4. select your VPC connected to your EC2 and\n 5. select Actions => Edit DNS Hostnames ---> Change DNS hostnames: to YES\n\nAaand it worked!\n\nHow did it get like this? I deleted and re-made the VPC numerous times, so it\nwas off by default for some reason. When did I mess with this? Why did I mess\nwith this? Why did it work at all instead of blocking me from the beginning? Who\nknows!\n\nP.S. Digging the \"code journal\" style of tech talk, among other reasons because\nI know I'm not going to accidentally plagiarize some tutorial I've read.\n\nUPDATE:\nJust tried to log back in with my settings from before, and wouldnchaknowit, it\nsuddenly started being wacky again! Exact same problems too - can log in for a\nbit shortly after the instance starts, then connection reset, then temporarily\nunavailable.\n\nI decided to look at the System Logs (accessible from Actions -> Instance\nSettings -> Get System Log). I noticed that it was blank. And when logs showed\nup, coincidentally my connection was reset again! The last line of the system\nlog was ip-172-30-0-53 login:. A clue, mayhaps! Maybe it has something to do\nwith the little intranet it was logged into!\n\nFrantic googling. Eventually, I discover that when I created my account, there\nwas a system called \"EC2 Classic\" in place (it presumably was not called this at\nthe time). They eventually added the VPC feature (short and sweet: VPC stands\nfor either \"Volatile Psionic Cloak\" or \"Virtual Private Cloud\", and is one of\nthe several terms that mean \"a place where your VMs run\" (each one has its own\nsubtle idiosyncracies. I will be bitching about them again, I promise you.) Why\ndoesn't this text editor do paren-highlighting? (print-str \"I love lisp\")  Eh,\nlet's say this is enough.)\n\nSooo, VPCs put a spanner in the works of how EC2 classic worked. If you made\nyour AWS account after VPC was introduced, you had to do stuff with VPC.\nHowever, if your account was old enough that you had access to EC2 Classic, they\nlet you use both systems so as not to nuke old infrastructure you might have\nhad. Note that whether you were \"VPC Only\" or \"VPC And EC2 Classic\" is something\nthat's flagged at the account level.\n\nI think it MIGHT have been okay, but while trying to log in, I deleted the VPC\nthat was present cuz I read that it'd spawn a new one that was set to default\noptions. Now, this did happen, except that the one I deleted was my \"Default\nVPC\". I do not fully understand the signifigance of this, but it seems to be\nwhat was getting in my way. So, simple - just make a new Default VPC! However,\nif you have an \"EC2 And VPC\" account, you cannot make a new Default VPC (for\nreasons that are mysterious to me).\n\nRemember when I said \"VPC and EC2 Classic\" status was at the account level?\nUnfortunately, that means you need to contact AWS support in order to change it.\nIf you've ever used normal Amazon customer support, you're probably accustomed\nto it being pretty good - you just open a chat window, say your stuff didn't\narrive, then they overnight the missing delivery. AWS support (if you're not\npaying extra money) is not like that. I put in the request on Wednesday night,\nand I've had several rounds of confirming \"Yes, I want you to do this\", each\nwith at least a day-long turn-around. It is now Sunday, and I got a message from\nyesterday saying that my account is finally in the process of being moved over.\nHopefully it all goes off without a hitch, but we'll see!","html":"<p>Sometimes I find myself responsible for setting up and maintaining my own infrastructure for doing data stuff.  In light of this, I've taken it upon myself to learn more about AWS in order for this experience to be less terrifying.  I've been following a course on Udemy for the AWS Solutions Architect Certification.  So far, so good.</p>\n<p>Cut to the EC2 section.  Has you spin up a little EC2 instance and SSH into it.  I would find myself SSHing in, then after a few minutes my connection would be reset and then any further attempts would be met with a <code>Resource temporarily unavailable</code>.</p>\n<p>I googled around.  Lots of stuff that didn't work.  I logged into a client's console that I had access to, tried to see if there were any settings that were different from mine.  What on Earth did I mess with?  I first made an AWS account in 2012, and go into phases of messing with my personal account and forgetting it exists.  I must have hit some kind of &quot;Make it so every server you launch is unreachable and useless&quot; button at some point, then forgotten where this button was.</p>\n<p>It's a tough little jungle.  There's numerous different versions of security on AWS.  Then, finally, I noticed an angel on StackOverflow posted that you should check to see whether you have a public DNS address.  Turns out I didn't!  <a href=\"https://stackoverflow.com/questions/20941704/ec2-instance-has-no-public-dns\">https://stackoverflow.com/questions/20941704/ec2-instance-has-no-public-dns</a></p>\n<ol>\n<li>Go to console.aws.amazon.com</li>\n<li>Go To Services -&gt; VPC</li>\n<li>Open Your VPCs</li>\n<li>select your VPC connected to your EC2 and</li>\n<li>select Actions =&gt; Edit DNS Hostnames ---&gt; Change DNS hostnames: to YES</li>\n</ol>\n<p>Aaand it worked!</p>\n<p>How did it get like this?  I deleted and re-made the VPC numerous times, so it was off by default for some reason.  When did I mess with this?  Why did I mess with this?  Why did it work at all instead of blocking me from the beginning?  Who knows!</p>\n<p>P.S. Digging the &quot;code journal&quot; style of tech talk, among other reasons because I know I'm not going to accidentally plagiarize some tutorial I've read.</p>\n<p>UPDATE:<br>\nJust tried to log back in with my settings from before, and wouldnchaknowit, it suddenly started being wacky again!  Exact same problems too - can log in for a bit shortly after the instance starts, then connection reset, then temporarily unavailable.</p>\n<p>I decided to look at the System Logs (accessible from Actions -&gt; Instance Settings -&gt; Get System Log).  I noticed that it was blank.  And when logs showed up, coincidentally my connection was reset again!  The last line of the system log was <code>ip-172-30-0-53 login:</code>.  A clue, mayhaps!  Maybe it has something to do with the little intranet it was logged into!</p>\n<p>Frantic googling.  Eventually, I discover that when I created my account, there was a system called &quot;EC2 Classic&quot; in place (it presumably was not called this at the time).  They eventually added the VPC feature (short and sweet: VPC stands for either &quot;Volatile Psionic Cloak&quot; or &quot;Virtual Private Cloud&quot;, and is one of the several terms that mean &quot;a place where your VMs run&quot; (each one has its own subtle idiosyncracies.  I will be bitching about them again, I promise you.)  Why doesn't this text editor do paren-highlighting?  <code>(print-str &quot;I love lisp&quot;)</code> Eh, let's say this is enough.)</p>\n<p>Sooo, VPCs put a spanner in the works of how EC2 classic worked.  If you made your AWS account after VPC was introduced, you had to do stuff with VPC.  However, if your account was old enough that you had access to EC2 Classic, they let you use both systems so as not to nuke old infrastructure you might have had.  Note that whether you were &quot;VPC Only&quot; or &quot;VPC And EC2 Classic&quot; is something that's flagged at the account level.</p>\n<p>I think it MIGHT have been okay, but while trying to log in, I deleted the VPC that was present cuz I read that it'd spawn a new one that was set to default options.  Now, this did happen, except that the one I deleted was my &quot;Default VPC&quot;.  I do not fully understand the signifigance of this, but it seems to be what was getting in my way.  So, simple - just make a new Default VPC!  However, if you have an &quot;EC2 And VPC&quot; account, you cannot make a new Default VPC (for reasons that are mysterious to me).</p>\n<p>Remember when I said &quot;VPC and EC2 Classic&quot; status was at the account level?  Unfortunately, that means you need to contact AWS support in order to change it.  If you've ever used normal Amazon customer support, you're probably accustomed to it being pretty good - you just open a chat window, say your stuff didn't arrive, then they overnight the missing delivery.  AWS support (if you're not paying extra money) is not like that.  I put in the request on Wednesday night, and I've had several rounds of confirming &quot;Yes, I want you to do this&quot;, each with at least a day-long turn-around.  It is now Sunday, and I got a message from yesterday saying that my account is finally in the process of being moved over.  Hopefully it all goes off without a hitch, but we'll see!</p>\n","url":"https://hackersandslackers.com/aws-adventures-why-cant-i-ssh-into-my-damn-ec2-instance/","uuid":"62262c95-6926-4f0c-96c7-cb4269f40a43","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b186de91e7fe93906b2e8f7"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867364d","title":"Preparing your AWS Project to Build an API","slug":"building-an-api-using-aws","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/awsapi-1-3.jpg","excerpt":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","custom_excerpt":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","created_at_pretty":"06 May, 2018","published_at_pretty":"06 May, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-05-06T07:30:47.000-04:00","published_at":"2018-05-06T08:58:41.000-04:00","updated_at":"2019-03-28T08:54:39.000-04:00","meta_title":"Preparing your AWS Project to Build an API | Hackers and Slackers","meta_description":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","og_description":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","og_image":"https://hackersandslackers.com/content/images/2019/03/awsapi-1-3.jpg","og_title":"Preparing your AWS Project to Build an API | Hackers and Slackers","twitter_description":"Get your AWS instance configured, and become familiar with the services needed to build APIs.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/awsapi-1-2.jpg","twitter_title":"Preparing your AWS Project to Build an API | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},"tags":[{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"#Creating APIs in AWS","slug":"create-an-aws-api","description":"Create a REST API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pythonlambda.jpg","meta_description":"Create an API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","meta_title":"Create a REST API in AWS","visibility":"internal"}],"plaintext":"There comes a surreal moment in nearly every profession in which perspective\nviolently forces itself into our self-awareness. People with cooler jobs\nprobably have that moment when they save their first patient or launch their\nfirst rocket. For me, the idea of building an API was this moment in software\ndevelopment. All those past black boxes which spat out results your life\ndepended on: we can make those now.\n\nFeel free to remain unfazed by this as I'm sure most are... for those of us who\ncan't remember how they became an \"engineer\" in the first place, API design\nfeels like reaching a final frontier. Granted, this may happen at least 20 more\ntimes in your software career, so don’t pause too long now.\n\nIf you managed to catch the tutorial on setting up RDS on AWS\n[https://hackersandslackers.com/setting-up-mysql-on-aws/], you're already a step\nahead. We're going to make our way through this slowly, which is probably a good\nidea even if you've done this before. There are so many pitfalls and nuances in\nAWS's architecture that I'm not even sure I fully understand what's happening,\neven when everything works.\n\nQuick Overview\nHere are the services we'll be using to hook this baby up:\n\n *   RDS:  Amazon's cloud-hosted relational databases. These databases come\n   preconfigured with an endpoint, which can be made accessible to other AWS\n   services or even to external manipulation. \n *   Lambda:  Snippets of code which can be invoked without setting up a web\n   server (hence: \"serverless\"). Lambda functions are intended to serve simple,\n   specific functions (such as serving as the logic for an endpoint, for\n   instance). Lambda functions play well with other AWS services: we'll be using\n   this as the glue between our API and interacting with the Database.\n *   API Gateway:  Amazon's visual editor for creating an API. API Gateway\n   allows developers to architect the structure and logic of APIs without having\n   to worry about setting up routes via code.\n *   IAM:  Amazon's headache of a user & permissions manager. IAM is needed to\n   specify exactly with AWS services have access to other services, which users\n   are permitted to interact with your API, etc. \n\nGameplan\nSo here's the deal. Our RDS  database will be where all the data we provide and\nreceive will live. Lambda  functions will be the snippets of code actually\ninteracting with information from the database; all of our queries will be done\nthrough Lambda. API Gateway  will control the \"design\" of the API, as in the\nstructure of endpoints, their respective methods, and how all these should\ninteract with Lambda.\n\nIt sounds simple enough, but the devil is in the details. And trust me, there\nare a lot of details.\n\nSetting the Correct Role Permissions\nUsually, I'd say we should jump into the fun stuff and deal with the details\nwhen we get to them. I won't let you steer down that road with AWS... let's\navoid smashing our heads on keyboards where possible and kick things off slow.\n\nIf you were to attempt to create a Lambda function off the bat, the first prompt\nto appear would demand a \"role\" to be specified. Roles are one of the types of\npermission packages (?) we mentioned earlier. Roles limit exactly which services\nyour Lambda function can interact with off the bat. Start with the wrong role,\nand you won't be able to do much of anything.\n\nHead over the IAM console\n[https://console.aws.amazon.com/iam/home?region=us-east-1#/home]  to set up an\nappropriate role:\n\nWhat a God-awful way to handle permissions.Let's pause for a moment to take this\nall in. You'll see we have users, groups, roles, policies and a whole bunch of\nother garbage. Policies can be attached to roles. Policies can also be attached\nto users, and also attached to groups. Users can be in groups. Wait, so what if\na user has a bunch of policies, but then joins a group with a bunch of policies?\nWhat even is a \"policy\"? These are the real questions. The short answer is none\nof it makes sense; it's just extra job security for those who make it work.\n\nClick on \"Roles\" in the sidebar. Create a role. Select \"Lambda\" and click next.\n\nThis interface only seems to get worse.Ok cool. The role  we're creating is basically just going to be a collection of\npermissions we can attached directly to the role. Go ahead and attach these:\n\n * AmazonVPCFullAccess\n * AmazonAPIGatewayInvokeFullAccess\n * AmazonRDSFullAccess\n * AWSLambdaFullAccess\n * CloudWatchLogsFullAccess\n\nSave the role, and remember what you name it. You'll need it.\n\nGetting Started with Lambda Functions\nGo back to the Lambda console. It's game time. We're going to create a function\nfrom scratch (sadly, I haven't found any of the blueprints to be very useful\njust yet).\n\nIgnore Amazon's silly Blueprints.Under “runtime”, you’ll need to pick which\nprogramming language we’ll be writing our function in. I’m doing Python 3\nbecause I don’t mess with semicolons, ya dig. Most people seem to stick with\nNode, which makes sense: Node is much faster at runtime, especially when you\nconsider that AWS runs Node natively. The choice is your preference.\n\nAha, see the “Role” dropdown? This is what I warned you about. Select the role\nyou just created earlier from existing roles.\n\nLambda Function Editor\nWelcome to Lambda's web UIBehold, the Lambda visual editor. That tree you're\nseeing is a representation of the integration this function will handle. The\ncurrent function is the box top-middle, the trigger is on the left, and the list\nof potential AWS services we can touch is on the right; these were automatically\npopulated by that role I forced you to create. You're welcome.\n\nNOTE:  The entire interface below this section depends on which service you've\nclicked in the tree. It's not the most intuitive at first. I have my Lambda\nfunction selected, so that's the interface I can interact with below.\n\nInline Code Editor\nWe can create Lambdas directly in the browser, or by uploading souce via zip\nfile.Real quick, we need to go over what each field here does. The dropdown\ncurrently set to \"edit code inline\" can be expanded, which gives you the option\nto upload a zip file of source code. THIS WILL DELETE ALL PREEXISTING WORK. \nThey don't tell you that, hah. Ha hah. I recommend doing everything offline to\nbe uploaded later - this needs to be done with python packages anyway.\n\nHandler  specifies which function should be called upon initialization.\n\"lambda_function\" is referring to the function, so \"handler\" here specifies that\nthe function handler within lambda_function.py  is what will get called upon\nexecution.\n\nOur Lambda’s VPC Settings\nScroll down until you hit this pretty little gem:\n\nAWS is filled with complicated network concepts, and zero attempts to explain\nthem.We need to specify the VPC this function will interact with. If you created\nan RDS already, go ahead select the VPC you created. Add a bunch of subnets\n(whichever ones). Finally, select a security group. Remember that the\npermissions of this group determine whether or not your VPC is allowed to speak\nto this function. If you're struggling with this, check out the AWS MySQL post\nagain. I'm not going to link it twice in one post, sorry. I have self-respect\nyou know.\n\nThat's Enough For Now\nThere's a lot to take in when playing around in AWS. The combination of\ngibberish terminology and horrible documentation doesn't exactly make for solid\nuser experience. If you're new to AWS and any of this seems frustrating, know\nit's supposed to be. Amazon owns you, and they hate you. Kind of like God.\n\nI'd suggest messing around the interface, and maybe even check out API Gateway a\nbit to get a feel for how that stuff looks. They set you up with a cute demo to\nmake you think it's going to be easy, so maybe you'll enjoy that. Next time,\nwe're going to crank out some Lambdas.","html":"<p>There comes a surreal moment in nearly every profession in which perspective violently forces itself into our self-awareness. People with cooler jobs probably have that moment when they save their first patient or launch their first rocket. For me, the idea of building an API was this moment in software development. All those past black boxes which spat out results your life depended on: we can make those now.</p><p>Feel free to remain unfazed by this as I'm sure most are... for those of us who can't remember how they became an \"engineer\" in the first place, API design feels like reaching a final frontier. Granted, this may happen at least 20 more times in your software career, so don’t pause too long now.</p><p>If you managed to catch the tutorial on <a href=\"https://hackersandslackers.com/setting-up-mysql-on-aws/\">setting up RDS on AWS</a>, you're already a step ahead. We're going to make our way through this slowly, which is probably a good idea even if you've done this before. There are so many pitfalls and nuances in AWS's architecture that I'm not even sure I fully understand what's happening, even when everything works.</p><h2 id=\"quick-overview\">Quick Overview</h2><p>Here are the services we'll be using to hook this baby up:</p><ul><li> <strong>RDS:</strong> Amazon's cloud-hosted relational databases. These databases come preconfigured with an endpoint, which can be made accessible to other AWS services or even to external manipulation. </li><li> <strong>Lambda:</strong> Snippets of code which can be invoked without setting up a web server (hence: \"<em>serverless</em>\"). Lambda functions are intended to serve simple, specific functions (such as serving as the logic for an endpoint, for instance). Lambda functions play well with other AWS services: we'll be using this as the glue between our API and interacting with the Database.</li><li> <strong>API Gateway:</strong> Amazon's visual editor for creating an API. API Gateway allows developers to architect the structure and logic of APIs without having to worry about setting up routes via code.</li><li> <strong>IAM:</strong> Amazon's headache of a user &amp; permissions manager. IAM is needed to specify exactly with AWS services have access to other services, which users are permitted to interact with your API, etc. </li></ul><h3 id=\"gameplan\">Gameplan</h3><p>So here's the deal. Our <strong>RDS</strong> database will be where all the data we provide and receive will live. <strong>Lambda</strong> functions will be the snippets of code actually interacting with information from the database; all of our queries will be done through Lambda. <strong>API Gateway</strong> will control the \"design\" of the API, as in the structure of endpoints, their respective methods, and how all these should interact with Lambda.</p><p>It sounds simple enough, but the devil is in the details. And trust me, there are a lot of details.</p><h2 id=\"setting-the-correct-role-permissions\">Setting the Correct Role Permissions</h2><p>Usually, I'd say we should jump into the fun stuff and deal with the details when we get to them. I won't let you steer down that road with AWS... let's avoid smashing our heads on keyboards where possible and kick things off slow.</p><p>If you were to attempt to create a Lambda function off the bat, the first prompt to appear would demand a \"<strong>role</strong>\" to be specified. Roles are one of the types of permission packages (?) we mentioned earlier. Roles limit exactly which services your Lambda function can interact with off the bat. Start with the wrong role, and you won't be able to do much of anything.</p><p>Head over the <a href=\"https://console.aws.amazon.com/iam/home?region=us-east-1#/home\">IAM console</a> to set up an appropriate role:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.06.13.png\" class=\"kg-image\" alt=\"Screenshot-2018-05-06-08.06.13\"><figcaption>What a God-awful way to handle permissions.</figcaption></figure><!--kg-card-end: image--><p>Let's pause for a moment to take this all in. You'll see we have users, groups, roles, policies and a whole bunch of other garbage. Policies can be attached to roles. Policies can also be attached to users, and also attached to groups. Users can be in groups. Wait, so what if a user has a bunch of policies, but then joins a group with a bunch of policies? What even is a \"policy\"? These are the real questions. The short answer is none of it makes sense; it's just extra job security for those who make it work.</p><p>Click on \"Roles\" in the sidebar. Create a role. Select \"Lambda\" and click <em>next</em>.</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.18.21.png\" class=\"kg-image\" alt=\"Screenshot-2018-05-06-08.18.21\"><figcaption>This interface only seems to get worse.</figcaption></figure><!--kg-card-end: image--><p>Ok cool. The <strong>role</strong> we're creating is basically just going to be a collection of permissions we can attached directly to the role. Go ahead and attach these:</p><ul><li>AmazonVPCFullAccess</li><li>AmazonAPIGatewayInvokeFullAccess</li><li>AmazonRDSFullAccess</li><li>AWSLambdaFullAccess</li><li>CloudWatchLogsFullAccess</li></ul><p>Save the role, and remember what you name it. You'll need it.</p><h2 id=\"getting-started-with-lambda-functions\">Getting Started with Lambda Functions</h2><p>Go back to the Lambda console. It's game time. We're going to create a function from scratch (sadly, I haven't found any of the blueprints to be very useful just yet).</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.25.16.png\" class=\"kg-image\" alt=\"Lambda\"><figcaption>Ignore Amazon's silly Blueprints.</figcaption></figure><!--kg-card-end: image--><p>Under “runtime”, you’ll need to pick which programming language we’ll be writing our function in. I’m doing Python 3 because I don’t mess with semicolons, ya dig. Most people seem to stick with Node, which makes sense: Node is much faster at runtime, especially when you consider that AWS runs Node natively. The choice is your preference.</p><p>Aha, see the “Role” dropdown? This is what I warned you about. Select the role you just created earlier from existing roles.</p><h3 id=\"lambda-function-editor\">Lambda Function Editor</h3><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screenshot-2018-05-06-08.30.00.png\" class=\"kg-image\"><figcaption>Welcome to Lambda's web UI</figcaption></figure><!--kg-card-end: image--><p>Behold, the Lambda visual editor. That tree you're seeing is a representation of the integration this function will handle. The current function is the box top-middle, the trigger is on the left, and the list of potential AWS services we can touch is on the right; these were automatically populated by that role I forced you to create. You're welcome.</p><p><strong>NOTE:</strong> The entire interface below this section depends on which service you've clicked in the tree. It's not the most intuitive at first. I have my Lambda function selected, so that's the interface I can interact with below.</p><h3 id=\"inline-code-editor\">Inline Code Editor</h3><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.35.20.png\" class=\"kg-image\" alt=\"Function code\"><figcaption>We can create Lambdas directly in the browser, or by uploading souce via zip file.</figcaption></figure><!--kg-card-end: image--><p>Real quick, we need to go over what each field here does. The dropdown currently set to \"edit code inline\" can be expanded, which gives you the option to upload a zip file of source code. <em>THIS WILL DELETE ALL PREEXISTING WORK.</em> They don't tell you that, hah. Ha hah. I recommend doing everything offline to be uploaded later - this needs to be done with python packages anyway.</p><p><strong>Handler</strong> specifies which function should be called upon initialization. \"lambda_function\" is referring to the function, so \"handler\" here specifies that the function handler within <code>lambda_function.py</code> is what will get called upon execution.</p><h3 id=\"our-lambda-s-vpc-settings\">Our Lambda’s VPC Settings</h3><p>Scroll down until you hit this pretty little gem:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-08.41.02.png\" class=\"kg-image\" alt=\"VPC\"><figcaption>AWS is filled with complicated network concepts, and zero attempts to explain them.</figcaption></figure><!--kg-card-end: image--><p>We need to specify the VPC this function will interact with. If you created an RDS already, go ahead select the VPC you created. Add a bunch of subnets (whichever ones). Finally, select a <em>security group</em>. Remember that the permissions of this group determine whether or not your VPC is allowed to speak to this function. If you're struggling with this, check out the AWS MySQL post again. I'm not going to link it twice in one post, sorry. I have self-respect you know.</p><h2 id=\"that-s-enough-for-now\">That's Enough For Now</h2><p>There's a lot to take in when playing around in AWS. The combination of gibberish terminology and horrible documentation doesn't exactly make for solid user experience. If you're new to AWS and any of this seems frustrating, know it's supposed to be. Amazon owns you, and they hate you. Kind of like God.</p><p>I'd suggest messing around the interface, and maybe even check out API Gateway a bit to get a feel for how that stuff looks. They set you up with a cute demo to make you think it's going to be easy, so maybe you'll enjoy that. Next time, we're going to crank out some Lambdas.</p>","url":"https://hackersandslackers.com/building-an-api-using-aws/","uuid":"45101fbc-527b-432b-994e-31d855e76aff","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5aeee767926f095edfccda8e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673648","title":"MySQL on the Cloud with AWS RDS","slug":"setting-up-mysql-on-aws","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/04/aws_mysql@2x.jpg","excerpt":"Spinning up a standalone MySQL Database with Amazon.","custom_excerpt":"Spinning up a standalone MySQL Database with Amazon.","created_at_pretty":"30 April, 2018","published_at_pretty":"01 May, 2018","updated_at_pretty":"27 November, 2018","created_at":"2018-04-29T23:12:26.000-04:00","published_at":"2018-04-30T20:14:57.000-04:00","updated_at":"2018-11-27T03:54:21.000-05:00","meta_title":"Setting up MySQL on AWS | Hackers and Slackers","meta_description":"Spinning up a standalone MySQL Database with Amazon","og_description":"Spinning up a standalone MySQL Database with Amazon","og_image":"https://hackersandslackers.com/content/images/2018/04/aws_mysql@2x.jpg","og_title":"Setting up MySQL on AWS","twitter_description":"Spinning up a standalone MySQL Database with Amazon","twitter_image":"https://hackersandslackers.com/content/images/2018/04/aws_mysql@2x.jpg","twitter_title":"Setting up MySQL on AWS","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"#Working with MySQL","slug":"working-with-mysql","description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysql1_o-1.jpg","meta_description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","meta_title":"Working with MySQL","visibility":"internal"}],"plaintext":"Last time we became familiar with the handiwork of setting up MySQL locally,\nnavigating databases via command line, and exposing your database to external\naccess. While badass, it has come to my attention that most people don't bother\ndoing things this way. Unless you're getting deep into some heavy architecture,\nmost people opt to use cloud services such as AWS to set up databases which are\nintended to be interacted with by multiple services.\n\nA perfect example is one we ran into over the weekend while working on this very\nblog. We're running a Ghost instance, which is respectably complex\nproduction-ready app. For a bunch of guys just looking to make some stupid blog\nwidgets, it became obvious that reverse engineering the undocumented inner\nworkings of an open source node app was a rabbit hole of complexity.\n\nHosting on AWS\nIn our case, AWS is useful for enforcing separation of concerns. Instead of\nbuilding new logic into a live app, we can build that logic elsewhere in a way\nthat's reusable across multiple apps.\n\nThe end goal here is simply to read/write to a database. That said, there's\nstill a fair amount of complexity involved. We'll need to leverage the following\nAWS services:\n\n * RDS (Relational Database Service): A cloud hosted database\n * API Gateway: An interface for building APIs\n * Lambda: The necessary serverless connector between RDS and Gateway\n * IAM: Amazon's god-awful user and policy manager\n\nFor now, all we're going to worry about is RDS.\n\nData is the New Kale is the New Money is the new Bitcoin Oil Gold ETFs\nHead to the AWS console and create a new RDS instance. Once prompted, go with\nMySQL:\n\nAs though some of these are real options. Please.Stick with MySQL Production  on the next screen.\n\nDo everything in production. AlwaysConfiguration Settings\nThis is where we set our configurations. You'll notice immediately how\nconvoluted AWS tends to be with their naming conventions. I personally hate how\nintentionally unintuitive all of AWS tends to be (what the hell is a \ndb.t2.medium)? This sort of absurdity is just something we need to deal with\nforever. Amazon is technically outside the realm of enforceable Monopoly laws,\nand there's no reason to believe their reign of mediocre products and talking\nrobots is ever going to end.\n\n * License: Select general-public-license\n * Version: Choose whichever, just don't do an old one\n * Instance class: Most of these instances are huge and unnecessary. Go with\n   something small: I would also advise looking at the pricing plan.\n * Multi AZ: Create a replica.\n * Storage type: General.\n * Allocated storage: Feel free to allocate more for latency.\n * Publicly Accessible: True.\n\nGod I love configuring esoteric shit.Once configuration is complete, it takes a\ngood amount of time for the database to be created. While we wait, let's move on\nto creating to a user to access this. We can do this with IAM: another AWS\nproduct with an even more terrible interface.\n\nAccess\nFair warning: user roles and permissions are the worst part of AWS. I could\nwrite an entire series on how deep this mess of a scheme goes, but quite\nhonestly I still barely understand what I'm doing most of the time.\n\nCreating a User\nCreate a new user that will access the database. Go to the Users panel  and\ncreate a user:\n\nModifying permission policies\nPermissions works by \"attaching\" existing \"policies\" to users, groups, etc. AWS\nhas some default policies that we can leverage for our purposes, so this should\nluckily be somewhat straightforward.\n\nPolicies can also be combined so that users have multiple policies across AWS\nproducts.\n\nNative Client\nOnce your DB pops up in AWS, we're going to need to get you a GUI to modify your\nDB. Don't even try to be a hotshot by setting up all your tables via command\nline. It sucks, it's slower, and nobody is impressed. Don't bother downloading\nthe AWS CLI either. Do not pass GO. Do not collect 500 dollars.\n\nIn case you need to install MySQL locally, an OSX download can be found here.\nCome to think of it, that step was probably unnecessary. I'm not sure why I did\nthat.\n\nI settled on Sequel Pro [https://www.sequelpro.com/]  as a client. It's good\nenough, and their logo looks like pancakes. That's really the only metric I\nneeded tbh.\n\nTo connect to your database, you'll need to retrieve the endpoint and port\nnumber from your RDS console:\n\nConnect to that ish:\n\nHopefully everything went well! If not, I'm sure the problem will be a quick and\neasy fix. Surely it won't involve mindlessly swapping permissions for an entire\nday. You defintely won't somehow end up corrupting your .bash_profile, making\nPython invisible to your OS, and effectively destroying your computer. Only an\nidiot would do something like that. Yesterday evening.\n\nGo ahead and get accustomed to the UI of Sequel Pro - it's pretty\nstraightforward, and ten thousand million times less effort than creating tables\nvia terminal. Create columns under the \"structure\" tab - the terminology should\nimmediately seem familiar if you've been following the series until this point.\n\nProtip: Issues with Security Groups\nIf you're running into an issue connecting to your DB externally, I happened to\nrun in to a nice little issue the other day with security groups. RDS instances\nlimit what kinds of connections they accept via \"security groups.\" This is yet\nanother layer of AWS security hassle where you'll need to specify which hosts\nare permitted to access your DB, by type of connection, port range, etc.\n\nIf you'd like to get this over with as soon as possible, this configuration will\nopen you up to the entire world:\n\nHappy Trails\nNext time we're going to sink deeper into this rabbit hole by exploring the\nwonderful world of serverless functions. Setting up AWS Lambda will allow us to\nconfigure endpoints which will allow us to read and write data to our brand new\ntable in the sky.\n\nWe'll still need to get into API Gateway after that, but let's not think about\nthat just yet. Let's not address the absurd amount of time and effort we're\nabout to spend just to make a god damn widget that shows Github commits.","html":"<p>Last time we became familiar with the handiwork of setting up MySQL locally, navigating databases via command line, and exposing your database to external access. While badass, it has come to my attention that most people don't bother doing things this way. Unless you're getting deep into some heavy architecture, most people opt to use cloud services such as AWS to set up databases which are intended to be interacted with by multiple services.</p><p>A perfect example is one we ran into over the weekend while working on this very blog. We're running a Ghost instance, which is respectably complex production-ready app. For a bunch of guys just looking to make some stupid blog widgets, it became obvious that reverse engineering the undocumented inner workings of an open source node app was a rabbit hole of complexity.</p><h2 id=\"hosting-on-aws\">Hosting on AWS</h2><p>In our case, AWS is useful for enforcing separation of concerns. Instead of building new logic into a live app, we can build that logic elsewhere in a way that's reusable across multiple apps.</p><p>The end goal here is simply to read/write to a database. That said, there's still a fair amount of complexity involved. We'll need to leverage the following AWS services:</p><ul><li>RDS (Relational Database Service): A cloud hosted database</li><li>API Gateway: An interface for building APIs</li><li>Lambda: The necessary serverless connector between RDS and Gateway</li><li>IAM: Amazon's god-awful user and policy manager</li></ul><p>For now, all we're going to worry about is RDS.</p><h2 id=\"data-is-the-new-kale-is-the-new-money-is-the-new-bitcoin-oil-gold-etfs\">Data is the New Kale is the New Money is the new Bitcoin Oil Gold ETFs</h2><p>Head to the AWS console and create a new RDS instance. Once prompted, go with MySQL:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-04-30-19.59.13.png\" class=\"kg-image\" alt=\"Database Type\"><figcaption>As though some of these are real options. Please.</figcaption></figure><p>Stick with <strong>MySQL Production</strong> on the next screen.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-04-30-19.59.22.png\" class=\"kg-image\" alt=\"Use case\"><figcaption>Do everything in production. Always</figcaption></figure><h3 id=\"configuration-settings\">Configuration Settings</h3><p>This is where we set our configurations. You'll notice immediately how convoluted AWS tends to be with their naming conventions. I personally hate how intentionally unintuitive all of AWS tends to be (what the hell is a <em>db.t2.medium</em>)? This sort of absurdity is just something we need to deal with forever. Amazon is technically outside the realm of enforceable Monopoly laws, and there's no reason to believe their reign of mediocre products and talking robots is ever going to end.</p><ul><li><strong>License</strong>: Select <em>general-public-license</em></li><li><strong>Version</strong>: Choose whichever, just don't do an old one</li><li><strong>Instance class</strong>: Most of these instances are huge and unnecessary. Go with something small: I would also advise looking at the pricing plan.</li><li><strong>Multi AZ</strong>: Create a replica.</li><li><strong>Storage type</strong>: General.</li><li><strong>Allocated storage</strong>: Feel free to allocate more for latency.</li><li><strong>Publicly Accessible</strong>: True.</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-04-30-19.59.46.png\" class=\"kg-image\" alt=\"Configuration\"><figcaption>God I love configuring esoteric shit.</figcaption></figure><p>Once configuration is complete, it takes a good amount of time for the database to be created. While we wait, let's move on to creating to a user to access this. We can do this with IAM: another AWS product with an even more terrible interface.</p><h2 id=\"access\">Access</h2><p>Fair warning: user roles and permissions are the worst part of AWS. I could write an entire series on how deep this mess of a scheme goes, but quite honestly I still barely understand what I'm doing most of the time.</p><h3 id=\"creating-a-user\">Creating a User</h3><p>Create a new user that will access the database. Go to the <a href=\"https://console.aws.amazon.com/iam/home?region=us-east-1#/users\">Users panel</a> and create a user:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/04/Screenshot-2018-04-30-19.37.20.png\" class=\"kg-image\" alt=\"Users\"></figure><h3 id=\"modifying-permission-policies\">Modifying permission policies</h3><p>Permissions works by \"attaching\" existing \"policies\" to users, groups, etc. AWS has some default policies that we can leverage for our purposes, so this should luckily be somewhat straightforward.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/04/Screenshot-2018-04-30-19.39.15.png\" class=\"kg-image\" alt=\"Permissions\"></figure><p>Policies can also be combined so that users have multiple policies across AWS products.</p><h2 id=\"native-client\">Native Client</h2><p>Once your DB pops up in AWS, we're going to need to get you a GUI to modify your DB. Don't even try to be a hotshot by setting up all your tables via command line. It sucks, it's slower, and nobody is impressed. Don't bother downloading the AWS CLI either. Do not pass GO. Do not collect 500 dollars.</p><p>In case you need to install MySQL locally, an OSX download can be found <a href=\"https://dev.mysql.com/downloads/mysql/5.5.html#macosx-dmg\">here</a>. Come to think of it, that step was probably unnecessary. I'm not sure why I did that.</p><p>I settled on <a href=\"https://www.sequelpro.com/\">Sequel Pro</a> as a client. It's good enough, and their logo looks like pancakes. That's really the only metric I needed tbh.</p><p>To connect to your database, you'll need to retrieve the endpoint and port number from your RDS console:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/04/Screenshot-2018-04-30-19.51.44.png\" class=\"kg-image\" alt=\"Endpoint\"></figure><p>Connect to that ish:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/04/Screenshot-2018-04-30-19.51.28.png\" class=\"kg-image\" alt=\"Sequel Pro\"></figure><p>Hopefully everything went well! If not, I'm sure the problem will be a quick and easy fix. Surely it won't involve mindlessly swapping permissions for an entire day. You defintely won't somehow end up corrupting your .bash_profile, making Python invisible to your OS, and effectively destroying your computer. Only an idiot would do something like that. Yesterday evening.</p><p>Go ahead and get accustomed to the UI of Sequel Pro - it's pretty straightforward, and ten thousand million times less effort than creating tables via terminal. Create columns under the \"structure\" tab - the terminology should immediately seem familiar if you've been following the series until this point.</p><h2 id=\"protip-issues-with-security-groups\">Protip: Issues with Security Groups</h2><p>If you're running into an issue connecting to your DB externally, I happened to run in to a nice little issue the other day with security groups. RDS instances limit what kinds of connections they accept via \"security groups.\" This is yet another layer of AWS security hassle where you'll need to specify which hosts are permitted to access your DB, by type of connection, port range, etc.</p><p>If you'd like to get this over with as soon as possible, this configuration will open you up to the entire world:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-06-07.15.26.png\" class=\"kg-image\" alt=\"Security Groups\"></figure><h2 id=\"happy-trails\">Happy Trails</h2><p>Next time we're going to sink deeper into this rabbit hole by exploring the wonderful world of serverless functions. Setting up AWS Lambda will allow us to configure endpoints which will allow us to read and write data to our brand new table in the sky.</p><p>We'll still need to get into API Gateway after that, but let's not think about that just yet. Let's not address the absurd amount of time and effort we're about to spend just to make a god damn widget that shows Github commits.</p>","url":"https://hackersandslackers.com/setting-up-mysql-on-aws/","uuid":"bf9a9804-206a-4556-ade4-b7cbdd896ecc","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5ae6899aed09bd1cb7110e51"}}]}},"pageContext":{"slug":"devops","limit":12,"skip":12,"numberOfPages":3,"humanPageNumber":2,"prevPageNumber":1,"nextPageNumber":3,"previousPagePath":"/tag/devops/","nextPagePath":"/tag/devops/page/3/"}}