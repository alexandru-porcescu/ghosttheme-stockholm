{"data":{"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c80bd2c48278b7063d89718","title":"Lynx Roundup, March 8th","slug":"lynx-roundup-march-8th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/139.jpg","excerpt":"Great white shark genome! Window functions in Pandas & SQL!  Useful linear algebra slides!","custom_excerpt":"Great white shark genome! Window functions in Pandas & SQL!  Useful linear algebra slides!","created_at_pretty":"07 March, 2019","published_at_pretty":"08 March, 2019","updated_at_pretty":"08 March, 2019","created_at":"2019-03-07T01:41:48.000-05:00","published_at":"2019-03-08T07:00:00.000-05:00","updated_at":"2019-03-08T10:55:45.000-05:00","meta_title":"Lynx Roundup, March 8th | Hackers and Slackers","meta_description":"Great white shark genome! Window functions in Pandas & SQL!  Useful linear algebra slides!","og_description":"Great white shark genome! Window functions in Pandas & SQL!  Useful linear algebra slides!","og_image":"https://hackersandslackers.com/content/images/2019/03/139.jpg","og_title":"Lynx Roundup, March 8th","twitter_description":"Great white shark genome! Window functions in Pandas & SQL!  Useful linear algebra slides!","twitter_image":"https://hackersandslackers.com/content/images/2019/03/139.jpg","twitter_title":"Lynx Roundup, March 8th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"\n\nhttps://functional.works-hub.com/learn/isomorphism-and-embedding-886ab\n\nhttps://github.com/vinta/awesome-python\n\nhttps://www.wired.com/story/dun-dun-duun-duuun-the-great-white-shark-genome-is-here/\n\nhttps://www.phmsociety.org/sites/phmsociety.org/files/phm_submission/2016/ijphm_16_020.pdf\n\nhttps://medium.com/jbennetcodes/how-to-get-rid-of-loops-and-use-window-functions-in-pandas-or-spark-sql-907f274850e4\n\nhttps://github.com/rasbt/stat479-deep-learning-ss19/blob/master/L04_linalg-dl/L04_linalg-dl_slides.pdf\n\nhttps://hbr.org/2019/01/the-hard-truth-about-innovative-cultures","html":"<p></p><p><a href=\"https://functional.works-hub.com/learn/isomorphism-and-embedding-886ab\">https://functional.works-hub.com/learn/isomorphism-and-embedding-886ab</a></p><p><a href=\"https://github.com/vinta/awesome-python\">https://github.com/vinta/awesome-python</a></p><p><a href=\"https://www.wired.com/story/dun-dun-duun-duuun-the-great-white-shark-genome-is-here/\">https://www.wired.com/story/dun-dun-duun-duuun-the-great-white-shark-genome-is-here/</a></p><p><a href=\"https://www.phmsociety.org/sites/phmsociety.org/files/phm_submission/2016/ijphm_16_020.pdf\">https://www.phmsociety.org/sites/phmsociety.org/files/phm_submission/2016/ijphm_16_020.pdf</a></p><p><a href=\"https://medium.com/jbennetcodes/how-to-get-rid-of-loops-and-use-window-functions-in-pandas-or-spark-sql-907f274850e4\">https://medium.com/jbennetcodes/how-to-get-rid-of-loops-and-use-window-functions-in-pandas-or-spark-sql-907f274850e4</a></p><p><a href=\"https://github.com/rasbt/stat479-deep-learning-ss19/blob/master/L04_linalg-dl/L04_linalg-dl_slides.pdf\">https://github.com/rasbt/stat479-deep-learning-ss19/blob/master/L04_linalg-dl/L04_linalg-dl_slides.pdf</a></p><p><a href=\"https://hbr.org/2019/01/the-hard-truth-about-innovative-cultures\">https://hbr.org/2019/01/the-hard-truth-about-innovative-cultures</a></p>","url":"https://hackersandslackers.com/lynx-roundup-march-8th/","uuid":"cfe83f32-3425-49c2-abaf-59e74128e38c","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c80bd2c48278b7063d89718"}},{"node":{"id":"Ghost__Post__5c806baf199621174e904b03","title":"Writing Your First GraphQL Query","slug":"writing-your-first-graphql-queries","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/graphql-1-3.jpg","excerpt":"Begin to structure complex queries against your GraphQL API.","custom_excerpt":"Begin to structure complex queries against your GraphQL API.","created_at_pretty":"07 March, 2019","published_at_pretty":"07 March, 2019","updated_at_pretty":"28 March, 2019","created_at":"2019-03-06T19:54:07.000-05:00","published_at":"2019-03-07T10:37:00.000-05:00","updated_at":"2019-03-28T11:01:59.000-04:00","meta_title":"Writing Your First GraphQL Queries | Hackers and Slackers","meta_description":"Structure your first GraphQL Queries and begin to build a client.","og_description":"Structure your first GraphQL Queries and begin to build a client.","og_image":"https://hackersandslackers.com/content/images/2019/03/graphql-1-3.jpg","og_title":"Writing Your First GraphQL Queries","twitter_description":"Structure your first GraphQL Queries and begin to build a client.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/graphql-1-2.jpg","twitter_title":"Writing Your First GraphQL Queries","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"GraphQL","slug":"graphql","description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","feature_image":null,"meta_description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","meta_title":"Build a GraphQL API | Hackers and Slackers","visibility":"public"},"tags":[{"name":"GraphQL","slug":"graphql","description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","feature_image":null,"meta_description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","meta_title":"Build a GraphQL API | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#GraphQL Hype","slug":"graphql-hype","description":"Learn GraphQL syntax and see the reasons why the future of APIs is here to stay. We walk through everything from server/client setup to intricate tricks.","feature_image":"https://hackersandslackers.com/content/images/2019/03/graphqlseries.jpg","meta_description":"Learn GraphQL syntax and see the reasons why the future of APIs is here to stay. We walk through everything from server/client setup to intricate tricks.","meta_title":"GraphQL Hype","visibility":"internal"}],"plaintext":"In our last run-in with GraphQL, we used Prisma  to assist in setting up a\nGraphQL server\n[https://hackersandslackers.com/easily-build-graphql-apis-with-prisma/]. This\neffectively gave us an endpoint to work with for making GraphQL requests against\nthe database we specified when getting started. If you're still in the business\nof setting up a GraphQL server, there are plenty of alternative services to\nPrisma you could explore. Apollo [https://www.apollographql.com/]  is perhaps\nthe most popular. A different approach could be to use GraphCMS\n[https://graphcms.com/]: a headless CMS for building GraphQL models with a\nbeautiful interface.\n\nWith our first models are created and deployed, we’re now able to explore\nGraphQL hands-on. Prisma (and just about any other service) gives us the luxury\nof a “playground” interface, where we can write all sorts of nonsensical and\notherwise dangerous shit. This is our opportunity to get comfortable before\nunleashing our ignorance upon the world in a production environment. To guide\nus, I’ll be using my own example of creating models, importing dummy data, and\nhow to write the queries to fetch said data.\n\nOur Example Model\nIn my case, I created a model for one of my favorite things: JIRA issues. I'll\nbe creating a Kanban widget using the data we play with here down the line, so\nthis is a real live use-case we'll be working with.\n\nHere are the contents of my datamodel.prisma  file:\n\ntype jiraissue {\n  id: ID! @unique,\n  key: String! @unique,\n  assignee: String,\n  summary: String,\n  status: String!,\n  priority: String,\n  issuetype: String,\n  epic_name: String,\n  updated: DateTime,\n  rank: Int,\n  timestamp: Int,\n  project: String\n}\n\nYou'll notice we have a good number of datatypes here, as well as two unique\nkeys. In case this point has been missed before, the exclamation marks in our\nmodel denote a required field.\n\nDeploying this model results in the following PostgreSQL query:\n\nCREATE TABLE \"default$default\".\"jiraissues\" (\n    \"id\" varchar(25) NOT NULL,\n    \"key\" text NOT NULL,\n    \"assignee\" text,\n    \"summary\" text,\n    \"status\" text NOT NULL,\n    \"priority\" text,\n    \"issuetype\" text,\n    \"epic_name\" text,\n    \"updated\" timestamp(3),\n    \"rank\" int4,\n    \"timestamp\" int4,\n    \"project\" text,\n    \"updatedAt\" timestamp(3) NOT NULL,\n    \"createdAt\" timestamp(3) NOT NULL,\n    PRIMARY KEY (\"id\")\n);\n\n\nLooks like everything lines up! The only caveat are the updatedAt  and createdAt \n fields: Prisma adds these to every database table for us.\n\nHere's a sample of the data I added by connecting to my database and importing a\nCSV:\n\nid\n key\n assignee\n summary\n status\n priority\n issuetype\n epic_name\n updated\n rank\n timestamp\n project\n updatedAt\n createdAt\n 430\n HACK-769\n Todd Birchard\n Fix projects dropdown\n Done\n Medium\n Bug\n Projects Page\n 2019-02-15 00:00:00\n 3\n 1550224412\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 465\n HACK-782\n Todd Birchard\n Lynx: on mobile, instead of full link, show domainname.com/...\n To Do\n Low\n Task\n Widgets\n 2019-02-15 00:00:00\n 4\n 1550223282\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 472\n HACK-774\n Todd Birchard\n New Widget: Next/Previous article in series\n To Do\n High\n Task\n Widgets\n 2019-02-14 00:00:00\n 2\n 1550194799\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 464\n HACK-778\n Todd Birchard\n HLJS: set indentation level\n Backlog\n Medium\n Task\n Code snippets\n 2019-02-14 00:00:00\n 3\n 1550194791\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 481\n HACK-555\n Todd Birchard\n Minify Babel\n Backlog\n Medium\n Task\n Optimization\n 2019-02-14 00:00:00\n 3\n 1550194782\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 432\n HACK-777\n Todd Birchard\n Redesign footer to be informative; link-heavy\n Done\n Medium\n Task\n Creative\n 2019-02-14 00:00:00\n 2\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 433\n HACK-779\n Todd Birchard\n Changeover from cloudinary to DO\n Done\n Highest\n Task\n Urgent\n 2019-02-14 00:00:00\n 0\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 428\n HACK-775\n Todd Birchard\n Update issuetype icons\n To Do\n Low\n Data & Analytics\n Projects Page\n 2019-02-14 00:00:00\n 3\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 374\n HACK-710\n Todd Birchard\n Implement auto text synopsis for Lynx posts\n Done\n High\n Task\n Lynx\n 2019-02-14 00:00:00\n 1\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 185\n HACK-395\n Todd Birchard\n Create fallback image for posts with no image\n To Do\n Low\n Task\n Page Templates\n 2019-02-14 00:00:00\n 3\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n A Few Things About GraphQL Queries\nBefore going any further, let's touch on a few concepts that are easy to stumble\nover.\n\nFirstly, a  GraphQL API only has a single endpoint. It makes sense: the logic of\nGraphQL API hits sit with the person creating the queries. That said, we've all\nbeen building REST APIs long enough to have this slip past us; I caught myself\nthinking through how to separate which endpoints I wanted before remembering\nthat's entirely not how this works.\n\nIt's import to understand that GraphQL is designed to be explicit. A significant\nadvantage of GraphQL is that we can be sure only to return the information which\nis essential to us.  For applications looking to optimize system resources (such\nas mobile apps), avoiding massive payloads is a feature, not a bug. This\nexplains many of the design decisions which went into designing GraphQL, as\nyou'll see it's intentionally difficult (but possible) to create a \"get all\nrecords\" query.\n\nLastly, GraphQL allows us to create queries in both shorthand and long-form  \nformats.  We'll take a look at both, starting with shorthand.\n\nGraphQL Shorthand Queries\nShorthand queries are an excellent place to start for beginners like us just\ntrying to get some data out of our database.\n\nThe structure of such a query looks like this:\n\n{\n  [model_name]s {\n    [desired_field_name_1]\n    [desired_field_name_2]\n    [desired_field_name_3]\n  }\n}\n\nUsing our example, our model_name  in this case would be jiraissue made plural, \nresulting in jiraissues. This is an important thing to note: when creating\nmodels, we should name them as a single entity, as things get confusing very\nfast otherwise. I initially made the mistake of naming my model jiraissues,\nwhich would then drive me to query jiraissueses. That was a fun little trip.\n\nWithin the brackets of our model, we must explicitly specify which fields (aka\ndatabase columns) we'd like returned with our query. Here's a full example of a\nshorthand query:\n\n{\n  jiraissues {\n    key\n    summary\n    epic_name\n  }\n}\n\n\nCheck out what this results in when entered in our \"playground\":\n\nQuery on the left, results on the right.Just like that, we have liftoff!\n\nThe \"Where\" Clause\nAs mentioned earlier, a major point of GraphQL is to return only the data which\nis necessary. Thus, we should almost always make queries with a where clause.\nThus, we can extend our simple query as such:\n\n{\n  jiraissueses(where: {status: \"Backlog\"}) {\n    key\n    summary\n    epic_name\n    status\n  }\n}\n\n\nAnd here's the result:\n\nFiltering results \"where\" certain criteria are met.Adding to Our Query\nJust like SQL or MongoDB queries, we can add more to our query to get more\nspecific:\n\n{\n  jiraissues(where: {status: \"Backlog\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC,  first: 6) \n  {\n    key\n    summary\n    epic_name\n    status\n    updated\n  }\n}\n\n\nHere, we've expanded our filter to work on two  fields: now our query will only\nreturn issues which match our criteria for both status  and project. \n\nWe've also added a few other things to our query. With orderBy, we can set the\norder in which records will be returned to us by field, either in ascending\n(ASC) or descending (DESC) order. first  imposes a limit on our results, giving\nus the first 6 which meet our criteria. Alternatively, last  would give us the\nopposite.\n\nThere are plenty of more parameters we could add here. For example:\n\n * [fieldname]_contains: Filters results where the string field contains a\n   substring.\n * [fieldname]_in: Checks a list to return records where the value of the field\n   matches any substring in a provided list.\n * [fieldname]_starts_with: An expression to check for values that start with a\n   provided substring.\n * [fieldname]_ends_with: Similar to the above, only for ending with a\n   substring.\n\nNot only are there more to add to this list, but each as an accompanying reverse\nstatement which would return the opposite. For example, [fieldname]_not_contains \n is the opposite of [fieldname]_contains.\n\nGraphQL Longform Queries\nWhat we've seen so far is already pretty powerful, but we're far from seeing\njust how far GraphQL can go. \n\nTo demonstrate what a more complicated query is capable of, let's use out Kanban\nboard example. Our board is going to have 4 columns representing 4 statuses: \nBacklog, To Do, In Progress, and Done.  Check out how we can receive all of this\nwith a single query:\n\nquery KanbanJiraIssues {\n  backlog: jiraissues(where: {status: \"Backlog\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  todo: jiraissues(where: {status: \"To Do\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  inprogress: jiraissues(where: {status: \"In Progress\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  done: jiraissues(where: {status: \"Done\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n}\n\n\nUnlike our shorthand queries, we begin this query with the syntax query\n[your_query_name]. You can name your query anything you'd like.\n\nWithin that query, we can perform multiple individual queries which we too give\ndisplay names. In whole, the structure looks like this:\\\n\nquery [your_query_name] {\n  [subquery_name]: [model_name]s(where: {[your_criteria]}){\n    [desired_field_name_1]\n    [desired_field_name_2]\n    [desired_field_name_3]\n  }\n}\n\n\nCheck out the result:\n\nNow THAT's a query.This format has helped us accomplish something previously\nimpossible with REST APIs: we've used a single endpoint to give us exactly  the\ninformation we need while omitting the information we don't.\n\nPassing Variables Into Queries\nAs you can see, queries can get lengthy pretty quick. It would suck if we had to\nwrite the entirety of the query above every time we wanted to hit an API.\nLuckily, we don't don't have to: that's where GraphQL variables come in.\n\nVariables allow us to use the structure of a GraphQL query repeatedly, while\nproviding different values where we see fit. That means if we have a\nparticularly complicated query structure that we'd like to repurpose, we can\npass dynamic values into said query. This is where things start to get really\npowerful.\n\nLet's assume that finding JIRA issues by epic link  is a common task we'll have\nto deal with. This is how we'd pass a dynamic value for epic_link:\n\nquery JiraIssuesByEpicName($epic_name: String) {\n  jiraissues(where: {epic_name: $epic_name}) {\n    key\n    summary\n    epic_name\n    status\n    updated\n    project\n    priority\n    issuetype\n    timestamp\n  }\n}\n\n$epic_name  is the name of our variable, which we set in the object we pass to\nthe query. That object looks like this:\n\n{\n  \"epic_name\": \"SEO\"\n}\n\nSo what we're saying on line 1  is that we're passing a variable named \n$epic_name, and that variable will be a String. When $epic_name  appears again\non line 2, the variable is interpreted as its value, which is \"SEO\".\n\nLuckily, our playground has a place specifically for setting variables which get\npassed to our queries. Here's how it all looks:\n\nHeavy breathing intensifies.Unlimited Power?\nWhile GraphQL's syntax looks clean and simple at first glance, it's easy to see\nhow quickly simple queries evolve into complex behemoths. It's no coincidence\nthat all GraphQL services come with a playground. It's hard to imagine how\nanybody could internalize GraphQL syntax without trial and error, and we're only\ngetting started.\n\nSo far we've only queried existing data; we haven't even begun to touch on\nmutations yet. Catch us next time when we start modifying data and get ourselves\ninto a whole lot of trouble.","html":"<p>In our last run-in with GraphQL, we used <strong>Prisma</strong> to assist in <a href=\"https://hackersandslackers.com/easily-build-graphql-apis-with-prisma/\">setting up a GraphQL server</a>. This effectively gave us an endpoint to work with for making GraphQL requests against the database we specified when getting started. If you're still in the business of setting up a GraphQL server, there are plenty of alternative services to Prisma you could explore. <a href=\"https://www.apollographql.com/\"><strong>Apollo</strong></a> is perhaps the most popular. A different approach could be to use <a href=\"https://graphcms.com/\"><strong>GraphCMS</strong></a>: a headless CMS for building GraphQL models with a beautiful interface.</p><p>With our first models are created and deployed, we’re now able to explore GraphQL hands-on. Prisma (and just about any other service) gives us the luxury of a “playground” interface, where we can write all sorts of nonsensical and otherwise dangerous shit. This is our opportunity to get comfortable before unleashing our ignorance upon the world in a production environment. To guide us, I’ll be using my own example of creating models, importing dummy data, and how to write the queries to fetch said data.</p><h2 id=\"our-example-model\">Our Example Model</h2><p>In my case, I created a model for one of my favorite things: JIRA issues. I'll be creating a Kanban widget using the data we play with here down the line, so this is a real live use-case we'll be working with.</p><p>Here are the contents of my <code>datamodel.prisma</code> file:</p><!--kg-card-begin: code--><pre><code>type jiraissue {\n  id: ID! @unique,\n  key: String! @unique,\n  assignee: String,\n  summary: String,\n  status: String!,\n  priority: String,\n  issuetype: String,\n  epic_name: String,\n  updated: DateTime,\n  rank: Int,\n  timestamp: Int,\n  project: String\n}</code></pre><!--kg-card-end: code--><p>You'll notice we have a good number of datatypes here, as well as two unique keys. In case this point has been missed before, the exclamation marks in our model denote a required field.</p><p>Deploying this model results in the following PostgreSQL query:</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">CREATE TABLE &quot;default$default&quot;.&quot;jiraissues&quot; (\n    &quot;id&quot; varchar(25) NOT NULL,\n    &quot;key&quot; text NOT NULL,\n    &quot;assignee&quot; text,\n    &quot;summary&quot; text,\n    &quot;status&quot; text NOT NULL,\n    &quot;priority&quot; text,\n    &quot;issuetype&quot; text,\n    &quot;epic_name&quot; text,\n    &quot;updated&quot; timestamp(3),\n    &quot;rank&quot; int4,\n    &quot;timestamp&quot; int4,\n    &quot;project&quot; text,\n    &quot;updatedAt&quot; timestamp(3) NOT NULL,\n    &quot;createdAt&quot; timestamp(3) NOT NULL,\n    PRIMARY KEY (&quot;id&quot;)\n);\n</code></pre>\n<!--kg-card-end: markdown--><p>Looks like everything lines up! The only caveat are the <code>updatedAt</code> and <code>createdAt</code> fields: Prisma adds these to every database table for us.</p><p>Here's a sample of the data I added by connecting to my database and importing a CSV:</p><!--kg-card-begin: html--><div class=\"tableContainer\">\n<table>\n    <thead>\n       <tr>\n             <th>id</th>\n             <th>key</th>\n             <th>assignee</th>\n             <th>summary</th>\n             <th>status</th>\n             <th>priority</th>\n             <th>issuetype</th>\n             <th>epic_name</th>\n             <th>updated</th>\n             <th>rank</th>\n             <th>timestamp</th>\n             <th>project</th>\n             <th>updatedAt</th>\n             <th>createdAt</th>\n         </tr>\n    </thead>\n    <tbody>\n       <tr>\n              <td>430</td>\n              <td>HACK-769</td>\n              <td>Todd Birchard</td>\n              <td>Fix projects dropdown</td>\n              <td>Done</td>\n              <td>Medium</td>\n              <td>Bug</td>\n              <td>Projects Page</td>\n              <td>2019-02-15 00:00:00</td>\n              <td>3</td>\n              <td>1550224412</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>465</td>\n              <td>HACK-782</td>\n              <td>Todd Birchard</td>\n              <td>Lynx: on mobile, instead of full link, show domainname.com/...</td>\n              <td>To Do</td>\n              <td>Low</td>\n              <td>Task</td>\n              <td>Widgets</td>\n              <td>2019-02-15 00:00:00</td>\n              <td>4</td>\n              <td>1550223282</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>472</td>\n              <td>HACK-774</td>\n              <td>Todd Birchard</td>\n              <td>New Widget: Next/Previous article in series</td>\n              <td>To Do</td>\n              <td>High</td>\n              <td>Task</td>\n              <td>Widgets</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>2</td>\n              <td>1550194799</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>464</td>\n              <td>HACK-778</td>\n              <td>Todd Birchard</td>\n              <td>HLJS: set indentation level</td>\n              <td>Backlog</td>\n              <td>Medium</td>\n              <td>Task</td>\n              <td>Code snippets</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>3</td>\n              <td>1550194791</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>481</td>\n              <td>HACK-555</td>\n              <td>Todd Birchard</td>\n              <td>Minify Babel</td>\n              <td>Backlog</td>\n              <td>Medium</td>\n              <td>Task</td>\n              <td>Optimization</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>3</td>\n              <td>1550194782</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>432</td>\n              <td>HACK-777</td>\n              <td>Todd Birchard</td>\n              <td>Redesign footer to be informative; link-heavy</td>\n              <td>Done</td>\n              <td>Medium</td>\n              <td>Task</td>\n              <td>Creative</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>2</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>433</td>\n              <td>HACK-779</td>\n              <td>Todd Birchard</td>\n              <td>Changeover from cloudinary to DO</td>\n              <td>Done</td>\n              <td>Highest</td>\n              <td>Task</td>\n              <td>Urgent</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>0</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>428</td>\n              <td>HACK-775</td>\n              <td>Todd Birchard</td>\n              <td>Update issuetype icons</td>\n              <td>To Do</td>\n              <td>Low</td>\n              <td>Data & Analytics</td>\n              <td>Projects Page</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>3</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>374</td>\n              <td>HACK-710</td>\n              <td>Todd Birchard</td>\n              <td>Implement auto text synopsis for Lynx posts</td>\n              <td>Done</td>\n              <td>High</td>\n              <td>Task</td>\n              <td>Lynx</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>1</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>185</td>\n              <td>HACK-395</td>\n              <td>Todd Birchard</td>\n              <td>Create fallback image for posts with no image</td>\n              <td>To Do</td>\n              <td>Low</td>\n              <td>Task</td>\n              <td>Page Templates</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>3</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n    </tbody>\n   </table>\n</div><!--kg-card-end: html--><h2 id=\"a-few-things-about-graphql-queries\">A Few Things About GraphQL Queries</h2><p>Before going any further, let's touch on a few concepts that are easy to stumble over.</p><p>Firstly, a<strong> GraphQL API only has a single endpoint</strong>. It makes sense: the logic of GraphQL API hits sit with the person creating the queries. That said, we've all been building REST APIs long enough to have this slip past us; I caught myself thinking through how to separate which endpoints I wanted before remembering that's entirely not how this works.</p><p>It's import to understand that <strong>GraphQL is designed to be explicit</strong>. A significant advantage of GraphQL is that we can be sure <em>only to return the information which is essential to us.</em> For applications looking to optimize system resources (such as mobile apps), avoiding massive payloads is a feature, not a bug. This explains many of the design decisions which went into designing GraphQL, as you'll see it's intentionally difficult (but possible) to create a \"get all records\" query.</p><p>Lastly, GraphQL allows us to <strong>create queries in both shorthand and long-form</strong> <strong>formats</strong>.<strong> </strong>We'll take a look at both, starting with shorthand.</p><h2 id=\"graphql-shorthand-queries\">GraphQL Shorthand Queries</h2><p>Shorthand queries are an excellent place to start for beginners like us just trying to get some data out of our database.</p><p>The structure of such a query looks like this:</p><!--kg-card-begin: code--><pre><code>{\n  [model_name]s {\n    [desired_field_name_1]\n    [desired_field_name_2]\n    [desired_field_name_3]\n  }\n}</code></pre><!--kg-card-end: code--><p>Using our example, our <strong>model_name</strong> in this case would be <strong>jiraissue </strong><em>made plural,</em> resulting in <strong>jiraissues</strong>. This is an important thing to note: when creating models, we should name them as a single entity, as things get confusing very fast otherwise. I initially made the mistake of naming my model <strong>jiraissues</strong>, which would then drive me to query <strong>jiraissueses</strong>. That was a fun little trip.</p><p>Within the brackets of our model, we must explicitly specify which fields (aka database columns) we'd like returned with our query. Here's a full example of a shorthand query:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">{\n  jiraissues {\n    key\n    summary\n    epic_name\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Check out what this results in when entered in our \"playground\":</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-06-at-8.50.53-PM.png\" class=\"kg-image\"><figcaption>Query on the left, results on the right.</figcaption></figure><!--kg-card-end: image--><p>Just like that, we have liftoff!</p><h3 id=\"the-where-clause\">The \"Where\" Clause</h3><p>As mentioned earlier, a major point of GraphQL is to return only the data which is necessary. Thus, we should almost always make queries with a <em>where </em>clause. Thus, we can extend our simple query as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">{\n  jiraissueses(where: {status: &quot;Backlog&quot;}) {\n    key\n    summary\n    epic_name\n    status\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>And here's the result:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-06-at-9.21.23-PM.png\" class=\"kg-image\"><figcaption>Filtering results \"where\" certain criteria are met.</figcaption></figure><!--kg-card-end: image--><h3 id=\"adding-to-our-query\">Adding to Our Query</h3><p>Just like SQL or MongoDB queries, we can add more to our query to get more specific:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">{\n  jiraissues(where: {status: &quot;Backlog&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC,  first: 6) \n  {\n    key\n    summary\n    epic_name\n    status\n    updated\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Here, we've expanded our filter to work on <em>two</em> fields: now our query will only return issues which match our criteria for both <code>status</code> and <code>project</code>. </p><p>We've also added a few other things to our query. With <code>orderBy</code>, we can set the order in which records will be returned to us by field, either in ascending (ASC) or descending (DESC) order. <code>first</code> imposes a limit on our results, giving us the first 6 which meet our criteria. Alternatively, <code>last</code> would give us the opposite.</p><p>There are plenty of more parameters we could add here. For example:</p><ul><li><code>[fieldname]_contains</code>: Filters results where the string field contains a substring.</li><li><code>[fieldname]_in</code>: Checks a list to return records where the value of the field matches any substring in a provided list.</li><li><code>[fieldname]_starts_with</code>: An expression to check for values that start with a provided substring.</li><li><code>[fieldname]_ends_with</code>: Similar to the above, only for ending with a substring.</li></ul><p>Not only are there more to add to this list, but each as an accompanying reverse statement which would return the opposite. For example, <code>[fieldname]_not_contains</code> is the opposite of <code>[fieldname]_contains</code>.</p><h2 id=\"graphql-longform-queries\">GraphQL Longform Queries</h2><p>What we've seen so far is already pretty powerful, but we're far from seeing just how far GraphQL can go. </p><p>To demonstrate what a more complicated query is capable of, let's use out Kanban board example. Our board is going to have 4 columns representing 4 statuses: <strong>Backlog, To Do, In Progress, </strong>and <strong>Done.</strong> Check out how we can receive all of this with a single query:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">query KanbanJiraIssues {\n  backlog: jiraissues(where: {status: &quot;Backlog&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  todo: jiraissues(where: {status: &quot;To Do&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  inprogress: jiraissues(where: {status: &quot;In Progress&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  done: jiraissues(where: {status: &quot;Done&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Unlike our shorthand queries, we begin this query with the syntax <code>query [your_query_name]</code>. You can name your query anything you'd like.</p><p>Within that query, we can perform multiple individual queries which we too give display names. In whole, the structure looks like this:\\</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">query [your_query_name] {\n  [subquery_name]: [model_name]s(where: {[your_criteria]}){\n    [desired_field_name_1]\n    [desired_field_name_2]\n    [desired_field_name_3]\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Check out the result:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-06-at-11.22.29-PM.png\" class=\"kg-image\"><figcaption>Now THAT's a query.</figcaption></figure><!--kg-card-end: image--><p>This format has helped us accomplish something previously impossible with REST APIs: we've used a single endpoint to give us <em>exactly</em> the information we need while omitting the information we don't.</p><h2 id=\"passing-variables-into-queries\">Passing Variables Into Queries</h2><p>As you can see, queries can get lengthy pretty quick. It would suck if we had to write the entirety of the query above every time we wanted to hit an API. Luckily, we don't don't have to: that's where GraphQL <em>variables </em>come in.</p><p>Variables allow us to use the structure of a GraphQL query repeatedly, while providing different values where we see fit. That means if we have a particularly complicated query structure that we'd like to repurpose, we can pass dynamic values into said query. This is where things start to get really powerful.</p><p>Let's assume that finding JIRA issues by <em>epic link</em> is a common task we'll have to deal with. This is how we'd pass a dynamic value for <strong>epic_link:</strong></p><!--kg-card-begin: code--><pre><code>query JiraIssuesByEpicName($epic_name: String) {\n  jiraissues(where: {epic_name: $epic_name}) {\n    key\n    summary\n    epic_name\n    status\n    updated\n    project\n    priority\n    issuetype\n    timestamp\n  }\n}</code></pre><!--kg-card-end: code--><p><code>$epic_name</code> is the name of our variable, which we set in the object we pass to the query. That object looks like this:</p><!--kg-card-begin: code--><pre><code>{\n  \"epic_name\": \"SEO\"\n}</code></pre><!--kg-card-end: code--><p>So what we're saying on <strong>line 1</strong> is that we're passing a variable named <code>$epic_name</code>, and that variable will be a <code>String</code>. When <code>$epic_name</code> appears again on <strong>line 2</strong>, the variable is interpreted as its value, which is \"SEO\".</p><p>Luckily, our playground has a place specifically for setting variables which get passed to our queries. Here's how it all looks:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/graphql-variables.png\" class=\"kg-image\"><figcaption>Heavy breathing intensifies.</figcaption></figure><!--kg-card-end: image--><h3 id=\"unlimited-power\">Unlimited Power?</h3><p>While GraphQL's syntax looks clean and simple at first glance, it's easy to see how quickly simple queries evolve into complex behemoths. It's no coincidence that all GraphQL services come with a playground. It's hard to imagine how anybody could internalize GraphQL syntax without trial and error, and we're only getting started.</p><p>So far we've only queried existing data; we haven't even begun to touch on mutations yet. Catch us next time when we start modifying data and get ourselves into a whole lot of trouble.</p>","url":"https://hackersandslackers.com/writing-your-first-graphql-queries/","uuid":"4019e61f-0f68-4921-99d4-5085864f9143","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c806baf199621174e904b03"}},{"node":{"id":"Ghost__Post__5c80bc6448278b7063d89709","title":"Lynx Roundup, March 7th","slug":"lynx-roundup-march-7th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/119.jpg","excerpt":"Stacks & Queues in Python!  Awesome online stats textbook!  Ethic for public sector data scientists!","custom_excerpt":"Stacks & Queues in Python!  Awesome online stats textbook!  Ethic for public sector data scientists!","created_at_pretty":"07 March, 2019","published_at_pretty":"07 March, 2019","updated_at_pretty":"07 March, 2019","created_at":"2019-03-07T01:38:28.000-05:00","published_at":"2019-03-07T10:37:00.000-05:00","updated_at":"2019-03-07T15:56:45.000-05:00","meta_title":"Lynx Roundup, March 7th | Hackers and Slackers","meta_description":"Stacks & Queues in Python!  Awesome online stats textbook!  Ethic for public sector data scientists!","og_description":"Stacks & Queues in Python!  Awesome online stats textbook!  Ethic for public sector data scientists!","og_image":"https://hackersandslackers.com/content/images/2019/03/119.jpg","og_title":"Lynx Roundup, March 7th","twitter_description":"Stacks & Queues in Python!  Awesome online stats textbook!  Ethic for public sector data scientists!","twitter_image":"https://hackersandslackers.com/content/images/2019/03/119.jpg","twitter_title":"Lynx Roundup, March 7th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"\n\nhttps://www.statlect.com/\n\nhttps://theintercept.com/2019/02/02/shoshana-zuboff-age-of-surveillance-capitalism/\n\nhttps://stackabuse.com/stacks-and-queues-in-python/\n\nhttps://twitter.com/realpython/status/1099459999259156480\n\nhttps://datasciencetexts.com/\n\nhttps://www.reddit.com/r/statistics/comments/aqqjox/is_anova_dead/\n\nhttps://urbanspatial.github.io/AlgorithmicFairness_ACodebasedPrimerForPublicSectorDataScientists/","html":"<p></p><p><a href=\"https://www.statlect.com/\">https://www.statlect.com/</a></p><p><a href=\"https://theintercept.com/2019/02/02/shoshana-zuboff-age-of-surveillance-capitalism/\">https://theintercept.com/2019/02/02/shoshana-zuboff-age-of-surveillance-capitalism/</a></p><p><a href=\"https://stackabuse.com/stacks-and-queues-in-python/\">https://stackabuse.com/stacks-and-queues-in-python/</a></p><p><a href=\"https://twitter.com/realpython/status/1099459999259156480\">https://twitter.com/realpython/status/1099459999259156480</a></p><p><a href=\"https://datasciencetexts.com/\">https://datasciencetexts.com/</a></p><p><a href=\"https://www.reddit.com/r/statistics/comments/aqqjox/is_anova_dead/\">https://www.reddit.com/r/statistics/comments/aqqjox/is_anova_dead/</a></p><p><a href=\"https://urbanspatial.github.io/AlgorithmicFairness_ACodebasedPrimerForPublicSectorDataScientists/\">https://urbanspatial.github.io/AlgorithmicFairness_ACodebasedPrimerForPublicSectorDataScientists/</a></p>","url":"https://hackersandslackers.com/lynx-roundup-march-7th/","uuid":"88af45d1-d496-4427-a06d-900ef1d83824","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c80bc6448278b7063d89709"}},{"node":{"id":"Ghost__Post__5c663cadc2209e663b5e5ae9","title":"Lynx Roundup, March 3rd","slug":"lynx-roundup-march-3rd","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/147.jpg","excerpt":"Inside the Apollo Guidance Computer!  Linear Operators in Python!  Disruption-Tolerant Networking from NASA!","custom_excerpt":"Inside the Apollo Guidance Computer!  Linear Operators in Python!  Disruption-Tolerant Networking from NASA!","created_at_pretty":"15 February, 2019","published_at_pretty":"03 March, 2019","updated_at_pretty":"03 March, 2019","created_at":"2019-02-14T23:14:37.000-05:00","published_at":"2019-03-03T14:12:00.000-05:00","updated_at":"2019-03-03T14:55:12.000-05:00","meta_title":"Lynx Roundup, March 3rd | Hackers and Slackers","meta_description":"Inside the Apollo Guidance Computer!  Linear Operators in Python!  Disruption-Tolerant Networking from NASA!","og_description":"Inside the Apollo Guidance Computer!  Linear Operators in Python!  Disruption-Tolerant Networking from NASA!","og_image":"https://hackersandslackers.com/content/images/2019/03/147.jpg","og_title":"Lynx Roundup, March 3rd | Hackers and Slackers","twitter_description":"Inside the Apollo Guidance Computer!  Linear Operators in Python!  Disruption-Tolerant Networking from NASA!","twitter_image":"https://hackersandslackers.com/content/images/2019/03/147.jpg","twitter_title":"Lynx Roundup, March 3rd | Hackers and Slackers","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"\n\nhttp://www.righto.com/2019/01/inside-apollo-guidance-computers-core.html\n\nhttps://towardsdatascience.com/making-sense-of-startup-valuations-with-data-science-1dededaf18bb\n\nhttps://www.nasa.gov/content/dtn\n\nhttps://www.reddit.com/r/ProgrammerHumor/comments/aouyj1/when_you_program_python_for_a_year_and_realize/\n\nhttps://github.com/equinor/pylops\n\n> 15 Trending Data Science GitHub Repositories you can not miss in 2017\n[https://www.analyticsvidhya.com/blog/2017/12/15-data-science-repositories-github-2017/]\nhttps://juxt.pro/blog/posts/react-hooks-raw.html","html":"<p></p><p><a href=\"http://www.righto.com/2019/01/inside-apollo-guidance-computers-core.html\">http://www.righto.com/2019/01/inside-apollo-guidance-computers-core.html</a></p><p><a href=\"https://towardsdatascience.com/making-sense-of-startup-valuations-with-data-science-1dededaf18bb\">https://towardsdatascience.com/making-sense-of-startup-valuations-with-data-science-1dededaf18bb</a></p><p><a href=\"https://www.nasa.gov/content/dtn\">https://www.nasa.gov/content/dtn</a></p><p><a href=\"https://www.reddit.com/r/ProgrammerHumor/comments/aouyj1/when_you_program_python_for_a_year_and_realize/\">https://www.reddit.com/r/ProgrammerHumor/comments/aouyj1/when_you_program_python_for_a_year_and_realize/</a></p><p><a href=\"https://github.com/equinor/pylops\">https://github.com/equinor/pylops</a></p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"wp-embedded-content\"><a href=\"https://www.analyticsvidhya.com/blog/2017/12/15-data-science-repositories-github-2017/\">15 Trending Data Science GitHub Repositories you can not miss in 2017</a></blockquote>\n<script type=\"text/javascript\">\n<!--//--><![CDATA[//><!--\n\t\t!function(a,b){\"use strict\";function c(){if(!e){e=!0;var a,c,d,f,g=-1!==navigator.appVersion.indexOf(\"MSIE 10\"),h=!!navigator.userAgent.match(/Trident.*rv:11\\./),i=b.querySelectorAll(\"iframe.wp-embedded-content\");for(c=0;c<i.length;c++){if(d=i[c],!d.getAttribute(\"data-secret\"))f=Math.random().toString(36).substr(2,10),d.src+=\"#?secret=\"+f,d.setAttribute(\"data-secret\",f);if(g||h)a=d.cloneNode(!0),a.removeAttribute(\"security\"),d.parentNode.replaceChild(a,d)}}}var d=!1,e=!1;if(b.querySelector)if(a.addEventListener)d=!0;if(a.wp=a.wp||{},!a.wp.receiveEmbedMessage)if(a.wp.receiveEmbedMessage=function(c){var d=c.data;if(d)if(d.secret||d.message||d.value)if(!/[^a-zA-Z0-9]/.test(d.secret)){var e,f,g,h,i,j=b.querySelectorAll('iframe[data-secret=\"'+d.secret+'\"]'),k=b.querySelectorAll('blockquote[data-secret=\"'+d.secret+'\"]');for(e=0;e<k.length;e++)k[e].style.display=\"none\";for(e=0;e<j.length;e++)if(f=j[e],c.source===f.contentWindow){if(f.removeAttribute(\"style\"),\"height\"===d.message){if(g=parseInt(d.value,10),g>1e3)g=1e3;else if(~~g<200)g=200;f.height=g}if(\"link\"===d.message)if(h=b.createElement(\"a\"),i=b.createElement(\"a\"),h.href=f.getAttribute(\"src\"),i.href=d.value,i.host===h.host)if(b.activeElement===f)a.top.location.href=d.value}else;}},d)a.addEventListener(\"message\",a.wp.receiveEmbedMessage,!1),b.addEventListener(\"DOMContentLoaded\",c,!1),a.addEventListener(\"load\",c,!1)}(window,document);\n//--><!]]>\n</script><iframe sandbox=\"allow-scripts\" security=\"restricted\" src=\"https://www.analyticsvidhya.com/blog/2017/12/15-data-science-repositories-github-2017/embed/\" width=\"600\" height=\"338\" title=\"&#8220;15 Trending Data Science GitHub Repositories you can not miss in 2017&#8221; &#8212; Analytics Vidhya\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" class=\"wp-embedded-content\"></iframe></figure><p><a href=\"https://juxt.pro/blog/posts/react-hooks-raw.html\">https://juxt.pro/blog/posts/react-hooks-raw.html</a></p>","url":"https://hackersandslackers.com/lynx-roundup-march-3rd/","uuid":"f821a75a-3e7c-450b-8499-7d71ff7076c6","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c663cadc2209e663b5e5ae9"}},{"node":{"id":"Ghost__Post__5c663c07c2209e663b5e5add","title":"Lynx Roundup, March 2nd","slug":"lynx-roundup-march-2nd","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/148.jpg","excerpt":"People ignore good advice from AI!  Word embeddings!  Visualizing latencies!","custom_excerpt":"People ignore good advice from AI!  Word embeddings!  Visualizing latencies!","created_at_pretty":"15 February, 2019","published_at_pretty":"02 March, 2019","updated_at_pretty":"05 March, 2019","created_at":"2019-02-14T23:11:51.000-05:00","published_at":"2019-03-02T05:30:00.000-05:00","updated_at":"2019-03-04T21:42:03.000-05:00","meta_title":"Lynx Roundup, March 2nd | Hackers and Slackers","meta_description":"People ignore good advice from AI!  Word embeddings!  Visualizing latencies!","og_description":"People ignore good advice from AI!  Word embeddings!  Visualizing latencies!","og_image":"https://hackersandslackers.com/content/images/2019/03/148.jpg","og_title":"Lynx Roundup, March 2nd | Hackers and Slackers","twitter_description":"People ignore good advice from AI!  Word embeddings!  Visualizing latencies!","twitter_image":"https://hackersandslackers.com/content/images/2019/03/148.jpg","twitter_title":"Lynx Roundup, March 2nd | Hackers and Slackers","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"\n\nhttps://www.arl.army.mil/www/default.cfm?article=3360\n\nhttps://www.gameworkersunite.org/get-involved\n\nhttps://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html\n\nhttp://www.1-9-9-1.com/\n\nhttps://lilianweng.github.io/lil-log/2017/10/15/learning-word-embedding.html\n\nhttps://www.reddit.com/r/learnpython/comments/ajds8s/classes_vs_functions_when_to_use_which_and_why/\n\nhttps://www.openfaas.com/blog/digitalocean-one-click/","html":"<p></p><p><a href=\"https://www.arl.army.mil/www/default.cfm\">https://www.arl.army.mil/www/default.cfm</a>?article=3360</p><p><a href=\"https://www.gameworkersunite.org/get-involved\">https://www.gameworkersunite.org/get-involved</a></p><p><a href=\"https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html\">https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html</a></p><p><a href=\"http://www.1-9-9-1.com/\">http://www.1-9-9-1.com/</a></p><p><a href=\"https://lilianweng.github.io/lil-log/2017/10/15/learning-word-embedding.html\">https://lilianweng.github.io/lil-log/2017/10/15/learning-word-embedding.html</a></p><p><a href=\"https://www.reddit.com/r/learnpython/comments/ajds8s/classes_vs_functions_when_to_use_which_and_why/\">https://www.reddit.com/r/learnpython/comments/ajds8s/classes_vs_functions_when_to_use_which_and_why/</a></p><p><a href=\"https://www.openfaas.com/blog/digitalocean-one-click/\">https://www.openfaas.com/blog/digitalocean-one-click/</a></p>","url":"https://hackersandslackers.com/lynx-roundup-march-2nd/","uuid":"4082d3e9-bebd-493e-8d78-5844ea4624a8","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c663c07c2209e663b5e5add"}},{"node":{"id":"Ghost__Post__5c79b0070fa2b110f256e320","title":"Running Jupyter Notebooks on a Ubuntu Server","slug":"running-jupyter-notebooks-on-a-ubuntu-server","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/jupyter.jpg","excerpt":"Configuring a VPS from scratch to host Jupyter notebooks with Anaconda.","custom_excerpt":"Configuring a VPS from scratch to host Jupyter notebooks with Anaconda.","created_at_pretty":"01 March, 2019","published_at_pretty":"02 March, 2019","updated_at_pretty":"14 April, 2019","created_at":"2019-03-01T17:19:51.000-05:00","published_at":"2019-03-01T21:15:40.000-05:00","updated_at":"2019-04-14T12:27:20.000-04:00","meta_title":"Running Jupyter Notebooks on a Ubuntu Server | Hackers and Slackers","meta_description":"Configuring a VPS from scratch to host Jupyter notebooks with Anaconda.","og_description":"Configuring a VPS from scratch to host Jupyter notebooks with Anaconda.","og_image":"https://hackersandslackers.com/content/images/2019/03/jupyter.jpg","og_title":"Running Jupyter Notebooks on a Ubuntu Server","twitter_description":"Configuring a VPS from scratch to host Jupyter notebooks with Anaconda.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/jupyter.jpg","twitter_title":"Running Jupyter Notebooks on a Ubuntu Server","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"}],"plaintext":"It dawned on me the other day that for a publication which regularly uses and\ntalks about Jupyter notebooks [https://jupyter.org/], we’ve never actually taken\nthe time to explain what they are or how to start using them. No matter where\nyou may have been in your career, first exposure to Jupyter and the IPython\n[https://ipython.org/]  shell is often a confusingly magical experience. Writing\nprograms line-by-line and receiving feedback in real-time feels more like\npainting oil on canvas and programming. I suppose we can finally chalk up a win\nfor dynamically typed languages.\n\nThere are a couple of barriers for practical devs to overcome before using\nJupyter, the most obvious being hardware costs. If you’re utilizing a full \nAnaconda  installation, chances are you’re not the type of person to mess\naround. Real machine learning algorithms take real resources, and real resources\ntake real money. A few vendors have popped up here are offering managed\ncloud-hosted notebooks for this reason. For those of us who bothered to do the\nmath, it turns out most of these services are more expensive than spinning up a\ndedicated VPS.\n\nData scientists with impressive machines have no problem running notebooks\nlocally for most use cases. While that’s fine and good for scientists, this\nsetup is problematic for those of us with commitments to Python outside of\nnotebooks. Upon installation, Anaconda barges into your system’s ~/.bash_profile\n, shouts “I am the captain now,”  and crowns itself as your system’s default\nPython path. Conda and Pip have some trouble getting along, so for those of us\nwho build Python applications and use notebooks, it's best to keep these things\nisolated.\n\nSetting Up a VPS\nWe're going to spin up a barebones Ubuntu 18.04 instance from scratch. I opted\nfor DigitalOcean  in my case, both for simplicity and the fact that I'm\nincredibly broke. Depending on how broke you may or may not be, this is where\nyou'll have to make a judgment call for your system resources:\n\nMy kind sir, I would like to order the most exquisite almost-cheapest Droplet on\nthe menuSSH into that bad boy. You know what to do next:\n\n$ sudo apt update\n$ sudo apt upgrade -y\n\n\nWith that out of the way, next we'll grab the latest version of Python:\n\n$ sudo apt install python3-pip python3-dev\n$ sudo -H pip3 install --upgrade pip\n\n\nFinally, we'll open port 8888 for good measure, since this is the port Jupyter\nruns on:\n\n$ sudo ufw enable\n$ sudo ufw allow 8888\n$ sudo ufw allow 22\n$ sudo ufw status\n\n\nTo                         Action      From\n--                         ------      ----\nOpenSSH                    ALLOW       Anywhere\n8888                       ALLOW       Anywhere\n\n\nCreate a New User\nAs always, we should create a Linux user besides root to do just about anything:\n\n$ adduser myuser\n\nAdding user `myuser' ...\nAdding new group `myuser' (1001) ...\nAdding new user `myuser' (1001) with group `myuser' ...\nCreating home directory `/home/myuser' ...\nCopying files from `/etc/skel' ...\nEnter new UNIX password:\nRetype new UNIX password:\npasswd: password updated successfully\nChanging the user information for myuser\nEnter the new value, or press ENTER for the default\n        Full Name []: My User\n        Room Number []: 420\n        Work Phone []: 555-1738\n        Home Phone []: derrrr\n        Other []: i like turtles\nIs the information correct? [Y/n] y\n\n\nThen, add them to the sudoers  group:\n\n$ usermod -aG sudo myuser\n\n\nLog in as the user:\n\n$ su - myuser\nTo run a command as administrator (user \"root\"), use \"sudo <command>\".\nSee \"man sudo_root\" for details.\n\n\nInstall The Latest Anaconda Distribution\nAnaconda comes with all the fantastic Data Science Python packages we'll need\nfor our notebook. To find the latest distribution, check here: \nhttps://www.anaconda.com/download/. We'll install this to a /tmp  folder:\n\ncd /tmp\ncurl -O https://repo.anaconda.com/archive/Anaconda3-2018.12-Linux-x86_64.sh\n\n\nOnce downloaded, begin the installation:\n\n$ sh Anaconda3-2018.12-Linux-x86_64.sh\n\n\nComplete the resulting prompts:\n\nWelcome to Anaconda3 2018.12\n\nIn order to continue the installation process, please review the license\nagreement.\nPlease, press ENTER to continue\n>>>\n\n\nGet ready for the wall of text....\n\n===================================\n\nCopyright 2015, Anaconda, Inc.\n\nAll rights reserved under the 3-clause BSD License:\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\n.......\n\n\nDo you accept the license terms? [yes|no]\n\n\nThis kicks off a rather lengthy install process. Afterward, you'll be prompted\nto add Conda to your startup script. Say yes:\n\ninstallation finished.\nDo you wish the installer to prepend the Anaconda3 install location\nto PATH in your /home/myuser/.bashrc ? [yes|no]\n\n\nThe final part of the installation will ask if you'd like to install VS Code.\nDecline this offer because Microsoft sucks.\n\nFinally, reload your /.bashrc file to get apply Conda's changes:\n\n$ source ~/.bashrc\n\n\nSetting Up Conda Environments\nConda installations can be isolated to separate environments similarly to how we\nwould  with Virtualenv. Unlike Virtualenv, however, Conda environments can be\nactivated from anywhere (not just in the directory containing the environment).\nCreate and activate a Conda env:\n\n$ conda create --name myenv python=3\n$ conda activate myenv\n\n\nCongrats, you're now in an active Conda environment!\n\nStarting Up Jupyter\nMake sure you're in a directory you'd like to be running Jupyter in. Entering \njupyter notebook  in this directory should result in the following:\n\n(jupyter_env) myuser@jupyter:~$ jupyter notebook\n[I 21:23:21.198 NotebookApp] Writing notebook server cookie secret to /run/user/1001/jupyter/notebook_cookie_secret\n[I 21:23:21.361 NotebookApp] Serving notebooks from local directory: /home/myuser/jupyter\n[I 21:23:21.361 NotebookApp] The Jupyter Notebook is running at:\n[I 21:23:21.361 NotebookApp] http://localhost:8888/?token=1fefa6ab49a498a3f37c959404f7baf16b9a2eda3eaa6d72\n[I 21:23:21.361 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n[W 21:23:21.361 NotebookApp] No web browser found: could not locate runnable browser.\n[C 21:23:21.361 NotebookApp]\n\n    Copy/paste this URL into your browser when you connect for the first time,\n    to login with a token:\n        http://localhost:8888/?token=1u2grit856t5yig5f37tf5iu5y4gfi73tfty5hf\n\n\nThis next part is tricky. To run our notebook, we need to reconnect to our VPS\nvia an SSH tunnel. Close the terminal and reconnect to your server with the\nfollowing format:\n\nssh -L 8888:localhost:8888 myuser@your_server_ip\n\n\nIndeed, localhost  is intended to stay the same, but your_server_ip  is to be\nreplaced with the address of your server.\n\nWith that done, let's try this one more time. Remember to reactivate your Conda\nenvironment first!\n\n$ jupyter notebook\n\n\nThis time around, the links which appear in the terminal should work!\n\nWE DID ITBONUS ROUND: Theme Your Notebooks\nIf ugly interfaces bother you as much as they bother me, I highly recommend\ntaking a look at the jupyter-themes package on Github\n[https://github.com/dunovank/jupyter-themes]. This package allows you to\ncustomize the look and feel of your notebook, either as simple as activating a\nstyle, or as complex as setting your margin width. I highly recommend checking\nout the available themes to spice up your notebook!","html":"<p>It dawned on me the other day that for a publication which regularly uses and talks about <a href=\"https://jupyter.org/\">Jupyter notebooks</a>, we’ve never actually taken the time to explain what they are or how to start using them. No matter where you may have been in your career, first exposure to Jupyter and the <a href=\"https://ipython.org/\">IPython</a> shell is often a confusingly magical experience. Writing programs line-by-line and receiving feedback in real-time feels more like painting oil on canvas and programming. I suppose we can finally chalk up a win for dynamically typed languages.</p><p>There are a couple of barriers for practical devs to overcome before using Jupyter, the most obvious being hardware costs. If you’re utilizing a full <strong>Anaconda</strong> installation, chances are you’re not the type of person to mess around. Real machine learning algorithms take real resources, and real resources take real money. A few vendors have popped up here are offering managed cloud-hosted notebooks for this reason. For those of us who bothered to do the math, it turns out most of these services are more expensive than spinning up a dedicated VPS.</p><p>Data scientists with impressive machines have no problem running notebooks locally for most use cases. While that’s fine and good for scientists, this setup is problematic for those of us with commitments to Python outside of notebooks. Upon installation, Anaconda barges into your system’s <code>~/.bash_profile</code>, shouts <strong><em>“I am the captain now,”</em></strong> and crowns itself as your system’s default Python path. Conda and Pip have some trouble getting along, so for those of us who build Python applications and use notebooks, it's best to keep these things isolated.</p><h2 id=\"setting-up-a-vps\">Setting Up a VPS</h2><p>We're going to spin up a barebones Ubuntu 18.04 instance from scratch. I opted for <strong>DigitalOcean</strong> in my case, both for simplicity and the fact that I'm incredibly broke. Depending on how broke you may or may not be, this is where you'll have to make a judgment call for your system resources:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/digitaloceanvps.png\" class=\"kg-image\"><figcaption>My kind sir, I would like to order the most exquisite almost-cheapest Droplet on the menu</figcaption></figure><!--kg-card-end: image--><p>SSH into that bad boy. You know what to do next:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ sudo apt update\n$ sudo apt upgrade -y\n</code></pre>\n<!--kg-card-end: markdown--><p>With that out of the way, next we'll grab the latest version of Python:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ sudo apt install python3-pip python3-dev\n$ sudo -H pip3 install --upgrade pip\n</code></pre>\n<!--kg-card-end: markdown--><p>Finally, we'll open port 8888 for good measure, since this is the port Jupyter runs on:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ sudo ufw enable\n$ sudo ufw allow 8888\n$ sudo ufw allow 22\n$ sudo ufw status\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">To                         Action      From\n--                         ------      ----\nOpenSSH                    ALLOW       Anywhere\n8888                       ALLOW       Anywhere\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"create-a-new-user\">Create a New User</h3><p>As always, we should create a Linux user besides root to do just about anything:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ adduser myuser\n\nAdding user `myuser' ...\nAdding new group `myuser' (1001) ...\nAdding new user `myuser' (1001) with group `myuser' ...\nCreating home directory `/home/myuser' ...\nCopying files from `/etc/skel' ...\nEnter new UNIX password:\nRetype new UNIX password:\npasswd: password updated successfully\nChanging the user information for myuser\nEnter the new value, or press ENTER for the default\n        Full Name []: My User\n        Room Number []: 420\n        Work Phone []: 555-1738\n        Home Phone []: derrrr\n        Other []: i like turtles\nIs the information correct? [Y/n] y\n</code></pre>\n<!--kg-card-end: markdown--><p>Then, add them to the <strong>sudoers</strong> group:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ usermod -aG sudo myuser\n</code></pre>\n<!--kg-card-end: markdown--><p>Log in as the user:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ su - myuser\nTo run a command as administrator (user &quot;root&quot;), use &quot;sudo &lt;command&gt;&quot;.\nSee &quot;man sudo_root&quot; for details.\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"install-the-latest-anaconda-distribution\">Install The Latest Anaconda Distribution</h3><p>Anaconda comes with all the fantastic Data Science Python packages we'll need for our notebook. To find the latest distribution, check here: <a href=\"https://www.anaconda.com/download/\">https://www.anaconda.com/download/</a>. We'll install this to a <code>/tmp</code> folder:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">cd /tmp\ncurl -O https://repo.anaconda.com/archive/Anaconda3-2018.12-Linux-x86_64.sh\n</code></pre>\n<!--kg-card-end: markdown--><p>Once downloaded, begin the installation:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ sh Anaconda3-2018.12-Linux-x86_64.sh\n</code></pre>\n<!--kg-card-end: markdown--><p>Complete the resulting prompts:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">Welcome to Anaconda3 2018.12\n\nIn order to continue the installation process, please review the license\nagreement.\nPlease, press ENTER to continue\n&gt;&gt;&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>Get ready for the wall of text....</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">===================================\n\nCopyright 2015, Anaconda, Inc.\n\nAll rights reserved under the 3-clause BSD License:\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\n.......\n\n\nDo you accept the license terms? [yes|no]\n</code></pre>\n<!--kg-card-end: markdown--><p>This kicks off a rather lengthy install process. Afterward, you'll be prompted to add Conda to your startup script. Say <strong>yes</strong>:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">installation finished.\nDo you wish the installer to prepend the Anaconda3 install location\nto PATH in your /home/myuser/.bashrc ? [yes|no]\n</code></pre>\n<!--kg-card-end: markdown--><p>The final part of the installation will ask if you'd like to install VS Code. Decline this offer because Microsoft sucks.</p><p>Finally, reload your <strong>/.bashrc </strong>file to get apply Conda's changes:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ source ~/.bashrc\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"setting-up-conda-environments\">Setting Up Conda Environments</h3><p>Conda installations can be isolated to separate environments similarly to how we would  with Virtualenv. Unlike Virtualenv, however, Conda environments can be activated from anywhere (not just in the directory containing the environment). Create and activate a Conda env:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ conda create --name myenv python=3\n$ conda activate myenv\n</code></pre>\n<!--kg-card-end: markdown--><p>Congrats, you're now in an active Conda environment!</p><h3 id=\"starting-up-jupyter\">Starting Up Jupyter</h3><p>Make sure you're in a directory you'd like to be running Jupyter in. Entering <code>jupyter notebook</code> in this directory should result in the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">(jupyter_env) myuser@jupyter:~$ jupyter notebook\n[I 21:23:21.198 NotebookApp] Writing notebook server cookie secret to /run/user/1001/jupyter/notebook_cookie_secret\n[I 21:23:21.361 NotebookApp] Serving notebooks from local directory: /home/myuser/jupyter\n[I 21:23:21.361 NotebookApp] The Jupyter Notebook is running at:\n[I 21:23:21.361 NotebookApp] http://localhost:8888/?token=1fefa6ab49a498a3f37c959404f7baf16b9a2eda3eaa6d72\n[I 21:23:21.361 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n[W 21:23:21.361 NotebookApp] No web browser found: could not locate runnable browser.\n[C 21:23:21.361 NotebookApp]\n\n    Copy/paste this URL into your browser when you connect for the first time,\n    to login with a token:\n        http://localhost:8888/?token=1u2grit856t5yig5f37tf5iu5y4gfi73tfty5hf\n</code></pre>\n<!--kg-card-end: markdown--><p>This next part is tricky. To run our notebook, we need to reconnect to our VPS via an SSH tunnel. Close the terminal and reconnect to your server with the following format:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">ssh -L 8888:localhost:8888 myuser@your_server_ip\n</code></pre>\n<!--kg-card-end: markdown--><p>Indeed, <code>localhost</code> is intended to stay the same, but <code>your_server_ip</code> is to be replaced with the address of your server.</p><p>With that done, let's try this one more time. Remember to reactivate your Conda environment first!</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ jupyter notebook\n</code></pre>\n<!--kg-card-end: markdown--><p>This time around, the links which appear in the terminal should work!</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-01-at-7.01.42-PM.png\" class=\"kg-image\"><figcaption>WE DID IT</figcaption></figure><!--kg-card-end: image--><h2 id=\"bonus-round-theme-your-notebooks\">BONUS ROUND: Theme Your Notebooks</h2><p>If ugly interfaces bother you as much as they bother me, I highly recommend taking a look at the <a href=\"https://github.com/dunovank/jupyter-themes\">jupyter-themes package on Github</a>. This package allows you to customize the look and feel of your notebook, either as simple as activating a style, or as complex as setting your margin width. I highly recommend checking out the available themes to spice up your notebook!</p><!--kg-card-begin: gallery--><figure class=\"kg-card kg-gallery-card kg-width-wide\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://hackersandslackers.com/content/images/2019/03/gruvbox-dark-python.png\" width=\"1013\" height=\"903\"></div><div class=\"kg-gallery-image\"><img src=\"https://hackersandslackers.com/content/images/2019/03/grade3_table.png\" width=\"1293\" height=\"809\"></div><div class=\"kg-gallery-image\"><img src=\"https://hackersandslackers.com/content/images/2019/03/jtplotDark_reach.png\" width=\"8400\" height=\"3600\"></div></div><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://hackersandslackers.com/content/images/2019/03/oceans16_code_headers.png\" width=\"1293\" height=\"808\"></div><div class=\"kg-gallery-image\"><img src=\"https://hackersandslackers.com/content/images/2019/03/onedork_code_headers.png\" width=\"1293\" height=\"808\"></div></div><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"https://hackersandslackers.com/content/images/2019/03/solarized-dark_iruby.png\" width=\"951\" height=\"498\"></div><div class=\"kg-gallery-image\"><img src=\"https://hackersandslackers.com/content/images/2019/03/chesterish_code_headers.png\" width=\"1293\" height=\"808\"></div></div></div></figure><!--kg-card-end: gallery-->","url":"https://hackersandslackers.com/running-jupyter-notebooks-on-a-ubuntu-server/","uuid":"0cfc9046-2e28-46a2-9f95-8851a9aea770","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c79b0070fa2b110f256e320"}},{"node":{"id":"Ghost__Post__5c663adcc2209e663b5e5ac7","title":"Lynx Roundup, February 28th","slug":"lynx-roundup-february-28th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/144.jpg","excerpt":"Data science books!  SQL for Data Scientists!  Example of Formal Verification in a Distributed System!","custom_excerpt":"Data science books!  SQL for Data Scientists!  Example of Formal Verification in a Distributed System!","created_at_pretty":"15 February, 2019","published_at_pretty":"01 March, 2019","updated_at_pretty":"01 March, 2019","created_at":"2019-02-14T23:06:52.000-05:00","published_at":"2019-03-01T14:20:00.000-05:00","updated_at":"2019-03-01T14:20:34.000-05:00","meta_title":"Lynx Roundup, February 28th | Hackers and Slackers","meta_description":"Data science books!  SQL for Data Scientists!  Example of Formal Verification in a Distributed System!","og_description":"Data science books!  SQL for Data Scientists!  Example of Formal Verification in a Distributed System!","og_image":"https://hackersandslackers.com/content/images/2019/03/144.jpg","og_title":"Lynx Roundup, February 28th","twitter_description":"Data science books!  SQL for Data Scientists!  Example of Formal Verification in a Distributed System!","twitter_image":"https://hackersandslackers.com/content/images/2019/03/144.jpg","twitter_title":"Lynx Roundup, February 28th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"\n\nhttps://www.forbes.com/sites/quora/2018/01/24/when-is-haskell-more-useful-than-r-or-python-in-data-science/\n\nhttps://datasciencetexts.com/\n\nhttps://jack-vanlightly.com/blog/2019/1/27/building-a-simple-distributed-system-formal-verification\n\nhttp://pbpython.com/excel-diff-pandas-update.html\n\nhttps://phys.org/news/2019-01-metallic-wood-strength-titanium-density.html\n\nhttps://stackabuse.com/understanding-recursive-functions-with-python/\n\nhttps://kanoki.org/2019/02/02/learn-sql-for-data-science/","html":"<p></p><p><a href=\"https://www.forbes.com/sites/quora/2018/01/24/when-is-haskell-more-useful-than-r-or-python-in-data-science/\">https://www.forbes.com/sites/quora/2018/01/24/when-is-haskell-more-useful-than-r-or-python-in-data-science/</a></p><p><a href=\"https://datasciencetexts.com/\">https://datasciencetexts.com/</a></p><p><a href=\"https://jack-vanlightly.com/blog/2019/1/27/building-a-simple-distributed-system-formal-verification\">https://jack-vanlightly.com/blog/2019/1/27/building-a-simple-distributed-system-formal-verification</a></p><p><a href=\"http://pbpython.com/excel-diff-pandas-update.html\">http://pbpython.com/excel-diff-pandas-update.html</a></p><p><a href=\"https://phys.org/news/2019-01-metallic-wood-strength-titanium-density.html\">https://phys.org/news/2019-01-metallic-wood-strength-titanium-density.html</a></p><p><a href=\"https://stackabuse.com/understanding-recursive-functions-with-python/\">https://stackabuse.com/understanding-recursive-functions-with-python/</a></p><p><a href=\"https://kanoki.org/2019/02/02/learn-sql-for-data-science/\">https://kanoki.org/2019/02/02/learn-sql-for-data-science/</a></p>","url":"https://hackersandslackers.com/lynx-roundup-february-28th/","uuid":"ad03128b-08ca-4f93-aa64-3f7f9d22d765","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c663adcc2209e663b5e5ac7"}},{"node":{"id":"Ghost__Post__5c663a7bc2209e663b5e5abc","title":"Lynx Roundup, February 27th","slug":"lynx-roundup-february-27th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/143@2x.jpg","excerpt":"Graphing your hiccups!  Patterns of database normalization!  A guide to Agda!","custom_excerpt":"Graphing your hiccups!  Patterns of database normalization!  A guide to Agda!","created_at_pretty":"15 February, 2019","published_at_pretty":"01 March, 2019","updated_at_pretty":"01 March, 2019","created_at":"2019-02-14T23:05:15.000-05:00","published_at":"2019-03-01T14:19:00.000-05:00","updated_at":"2019-03-01T14:19:20.000-05:00","meta_title":"Lynx Roundup, February 27th | Hackers and Slackers","meta_description":"Graphing your hiccups!  Patterns of database normalization!  A guide to Agda!","og_description":"Graphing your hiccups!  Patterns of database normalization!  A guide to Agda!","og_image":"https://hackersandslackers.com/content/images/2019/03/143@2x.jpg","og_title":"Lynx Roundup, February 27th","twitter_description":"Graphing your hiccups!  Patterns of database normalization!  A guide to Agda!","twitter_image":"https://hackersandslackers.com/content/images/2019/03/143@2x.jpg","twitter_title":"Lynx Roundup, February 27th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"\n\nhttp://www.cs.toronto.edu/~jianzhao/papers/matrixwave.pdf\n\nhttps://medium.com/@gajus/lessons-learned-scaling-postgresql-database-to-1-2bn-records-month-edc5449b3067\n\nhttps://www.reddit.com/r/dataisbeautiful/comments/aotbmd/i_got_a_case_of_the_hiccups_last_night_so_i/\n\nhttps://plfa.github.io/\n\nhttps://www.reddit.com/r/Database/comments/ag9lby/help_understanding_normalization/\n\nhttps://phys.org/news/2019-02-reverse-cool-future.html\n\nhttp://cci.esa.int/data","html":"<p></p><p><a href=\"http://www.cs.toronto.edu/~jianzhao/papers/matrixwave.pdf\">http://www.cs.toronto.edu/~jianzhao/papers/matrixwave.pdf</a></p><p><a href=\"https://medium.com/@gajus/lessons-learned-scaling-postgresql-database-to-1-2bn-records-month-edc5449b3067\">https://medium.com/@gajus/lessons-learned-scaling-postgresql-database-to-1-2bn-records-month-edc5449b3067</a></p><p><a href=\"https://www.reddit.com/r/dataisbeautiful/comments/aotbmd/i_got_a_case_of_the_hiccups_last_night_so_i/\">https://www.reddit.com/r/dataisbeautiful/comments/aotbmd/i_got_a_case_of_the_hiccups_last_night_so_i/</a></p><p><a href=\"https://plfa.github.io/\">https://plfa.github.io/</a></p><p><a href=\"https://www.reddit.com/r/Database/comments/ag9lby/help_understanding_normalization/\">https://www.reddit.com/r/Database/comments/ag9lby/help_understanding_normalization/</a></p><p><a href=\"https://phys.org/news/2019-02-reverse-cool-future.html\">https://phys.org/news/2019-02-reverse-cool-future.html</a></p><p><a href=\"http://cci.esa.int/data\">http://cci.esa.int/data</a></p>","url":"https://hackersandslackers.com/lynx-roundup-february-27th/","uuid":"2fbc8ca8-015a-4a9c-bdbb-f137f1848240","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c663a7bc2209e663b5e5abc"}},{"node":{"id":"Ghost__Post__5c663b95c2209e663b5e5ad2","title":"Lynx Roundup, March 1st","slug":"lynx-roundup-march-1st","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/145-1.jpg","excerpt":"Stacks & Queues in Python!  Learning Spark!  Kotlin for Pythonistas!","custom_excerpt":"Stacks & Queues in Python!  Learning Spark!  Kotlin for Pythonistas!","created_at_pretty":"15 February, 2019","published_at_pretty":"01 March, 2019","updated_at_pretty":"01 March, 2019","created_at":"2019-02-14T23:09:57.000-05:00","published_at":"2019-03-01T07:00:00.000-05:00","updated_at":"2019-03-01T14:47:15.000-05:00","meta_title":"Lynx Roundup, March 1st | Hackers and Slackers","meta_description":"Stacks & Queues in Python!  Learning Spark!  Kotlin for Pythonistas!","og_description":"Stacks & Queues in Python!  Learning Spark!  Kotlin for Pythonistas!","og_image":"https://hackersandslackers.com/content/images/2019/03/145-1.jpg","og_title":"Lynx Roundup, March 1st","twitter_description":"Stacks & Queues in Python!  Learning Spark!  Kotlin for Pythonistas!","twitter_image":"https://hackersandslackers.com/content/images/2019/03/145-1.jpg","twitter_title":"Lynx Roundup, March 1st","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"\n\nhttps://stackabuse.com/stacks-and-queues-in-python/\n\nhttps://github.com/NtesEyes/pylane\n\nhttps://www.reddit.com/r/datascience/comments/ajio6o/learn_spark/\n\nhttps://mymodernmet.com/history-of-the-alphabet-usefulcharts/\n\nhttps://www.reddit.com/r/Database/comments/al8rop/why_exactly_area_manytomany_relationships_bad/\n\nhttps://towardsdatascience.com/back-to-the-metal-top-3-programming-language-to-develop-big-data-frameworks-in-2019-69a44a36a842\n\nhttps://khan.github.io/kotlin-for-python-developers/","html":"<p></p><p><a href=\"https://stackabuse.com/stacks-and-queues-in-python/\">https://stackabuse.com/stacks-and-queues-in-python/</a></p><p><a href=\"https://github.com/NtesEyes/pylane\">https://github.com/NtesEyes/pylane</a></p><p><a href=\"https://www.reddit.com/r/datascience/comments/ajio6o/learn_spark/\">https://www.reddit.com/r/datascience/comments/ajio6o/learn_spark/</a></p><p><a href=\"https://mymodernmet.com/history-of-the-alphabet-usefulcharts/\">https://mymodernmet.com/history-of-the-alphabet-usefulcharts/</a></p><p><a href=\"https://www.reddit.com/r/Database/comments/al8rop/why_exactly_area_manytomany_relationships_bad/\">https://www.reddit.com/r/Database/comments/al8rop/why_exactly_area_manytomany_relationships_bad/</a></p><p><a href=\"https://towardsdatascience.com/back-to-the-metal-top-3-programming-language-to-develop-big-data-frameworks-in-2019-69a44a36a842\">https://towardsdatascience.com/back-to-the-metal-top-3-programming-language-to-develop-big-data-frameworks-in-2019-69a44a36a842</a></p><p><a href=\"https://khan.github.io/kotlin-for-python-developers/\">https://khan.github.io/kotlin-for-python-developers/</a></p>","url":"https://hackersandslackers.com/lynx-roundup-march-1st/","uuid":"c2ad29e1-50bd-4fc6-8a7a-d17bcc2f4a45","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c663b95c2209e663b5e5ad2"}},{"node":{"id":"Ghost__Post__5c17ddd4418434084a873d2a","title":"Drawing Mapbox Route Objects via the Directions API","slug":"mapbox-draw-route-objects","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/mapboxroutes.jpg","excerpt":"Using the Mapbox Directions API to visually draw routes.","custom_excerpt":"Using the Mapbox Directions API to visually draw routes.","created_at_pretty":"17 December, 2018","published_at_pretty":"28 February, 2019","updated_at_pretty":"03 March, 2019","created_at":"2018-12-17T12:33:08.000-05:00","published_at":"2019-02-28T09:15:52.000-05:00","updated_at":"2019-03-03T16:21:52.000-05:00","meta_title":"Draw Route Objects with Mapbox Directions API | Hackers and Slackers","meta_description":"Using the Mapbox Directions API to visually draw routes.","og_description":"Using the Mapbox Directions API to visually draw routes.","og_image":"https://hackersandslackers.com/content/images/2019/02/mapboxroutes.jpg","og_title":"Drawing Route Objects with Mapbox Directions API","twitter_description":"Using the Mapbox Directions API to visually draw routes.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/mapboxroutes.jpg","twitter_title":"Drawing Route Objects with Mapbox Directions API","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"#Mapping Data with Mapbox","slug":"mapping-data-with-mapbox","description":"A full exploration into Mapbox: the sweetheart of geovisualization amongst data scientists. Learn the core product or see why the API rivals Google Maps.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mapbox.jpg","meta_description":"A full exploration into Mapbox: the sweetheart of geovisualization amongst data scientists. Learn the core product or see why the API rivals Google Maps.","meta_title":"Mapping Data with Mapbox","visibility":"internal"}],"plaintext":"If you've been here before, you probably already know our affinity for Mapbox \nand the visualization tools it provides data scientists and analysts. In the\npast, we've covered encoding location data from raw addresses\n[https://hackersandslackers.com/preparing-data-for-mapbox-geocoding/], as well\nas an exploration of Mapbox Studio\n[https://hackersandslackers.com/map-data-visualization-with-mapbox/]  for those\ngetting acquainted with the tool. Today we're going a step further: drawing\ndirections on a map.\n\nIt sounds simple enough: we already know how to geocode addresses, so all we\nneed to do is literally go from point A to point B. That said, things always\ntend to get tricky, and if you've never worked with GeoJSON\n[http://geojson.org/]  before, you're in for a treat.\n\nLoad Up Some Data\nI'm going to assume you have a DataFrame ready containing these columns:\n\n * origin_longitude\n * origin_latitude\n * destination_longitude\n * destination_latitude\n * Name/description of this route \n\nIf you want to play along, there are plenty of free datasets out there to play\nwith - I sourced some information from BigQuery while I was testing things out.\n\nimport os\nimport pandas as pd\nimport requests\nimport json\n\nroutes_df = pd.read_csv('datasources/routes.csv').head(10)\ntoken = os.environ.get('mapbox_token')\n\n\nSo far so good- all we've done is load our data, and save our Mapbox token from\nan environment variable.\n\nMapbox Directions Endpoint\nNext, we're going to use Mapbox's Directions API\n[https://docs.mapbox.com/api/navigation/#directions]  to return a route for us.\nThe anatomy of a GET call to receive directions looks like this:\n\nhttps://api.mapbox.com/directions/v5/mapbox/{{method_of_transportation}}/{{origin_longitude}},{{origin_latitude}};{{destination_longitude}},{{destination_latitude}}\n\nPARAMS:\naccess_token={{your_mapbox_access_token}}\ngeometries=geojson\n\n\n * method_of_transportation refers to one of the three methods that Mapbox\n   offers for creating routes: driving-traffic, driving, walking, and cycling.\n   Note that there is currently no way to draw route objects which follow public\n   transit: this is perhaps Mapbox's biggest downfall at the moment.\n   Nevertheless, if this is something you need, data can be imported from Google\n   maps to be used with Mapbox.\n * access_token  can be either your public token (visible upon login at\n   mapbox.com) or a generated secret token.\n * geometries  accepts the method by which to draw the object. This can be \n   GeoJSON,  polyline, or polyline6. Let's stick with GeoJSON.\n\nConstructing API Requests\nLet's construct a request per row in our DataFrame. By using Pandas' apply, we\nfire a function per row to do just that:\n\nimport os\nimport pandas as pd\nimport requests\nimport json\n\nroutes_df = pd.read_csv('datasources/routes.csv').head(10)\ntoken = os.environ.get('mapbox_token')\n\ndef create_route_json(row):\n    \"\"\"Get route JSON.\"\"\"\n    base_url = 'https://api.mapbox.com/directions/v5/mapbox/driving/'\n    url = base_url + str(row['home_longitude']) + \\\n        ',' + str(row['home_latitude']) + \\\n        ';' + str(row['destination_longitude']) + \\\n        ',' + str(row['destination_latitude'])\n    params = {\n        'geometries': 'geojson',\n        'access_token': token\n    }\n    req = requests.get(url, params=params)\n    route_json = req.json()['routes'][0]\n    # Now what?\n\n\nroutes_df.apply(create_route_json, axis=1)\n\n\nHere's where things get a little tricky. You see, GeoJSON abides by a strict\nformat. It looks something like this:\n\n{\n  \"type\": \"Feature\",\n  \"geometry\": {\n    \"coordinates\": [\n      [ -73.985897, 40.748133 ], [ -73.985046, 40.747773 ], \n      [ -73.984579, 40.748431 ], [ -73.973437, 40.743885 ],\n      [ -73.972844, 40.744452 ], [ -73.970728, 40.743885 ], \n      [ -73.970611, 40.735137 ], [ -73.9714, 40.733734 ],\n      [ -73.973503, 40.732341 ], [ -73.969823, 40.729864 ], \n      [ -73.969243, 40.727535 ], [ -73.975074, 40.711418 ],\n      [ -73.976603, 40.710276 ], [ -73.978077, 40.710587 ], \n      [ -73.979462, 40.70932 ], [ -73.992664, 40.708145 ],\n      [ -73.996237, 40.707307 ], [ -74.001135, 40.704086 ], \n      [ -74.0055, 40.70243 ], [ -74.006778, 40.703628 ],\n      [ -74.009173, 40.702484 ], [ -74.010637, 40.70371 ], \n      [ -74.014535, 40.703624 ], [ -74.014665, 40.704034 ],\n      [ -74.017057, 40.703259 ]\n    ],\n    \"type\": \"LineString\"\n  },\n  \"legs\": [{\n      \"summary\": \"\",\n      \"weight\": 3873.3,\n      \"duration\": 3873.3,\n      \"steps\": [],\n      \"distance\": 9660.2\n  }],\n  \"weight_name\": \"duration\",\n  \"weight\": 3873.3,\n  \"duration\": 3873.3,\n  \"distance\": 9660.2,\n  \"properties\": {\n    \"name\": \"Empire State\"\n  }\n}\n\n\nFor the sake of being difficult, the Mapbox Directions API doesn't return\nresponses in exactly this format. Instead, their response looks like this:\n\n{\n  \"routes\": [{\n    \"geometry\": {\n      \"coordinates\": [\n        [-73.985897, 40.748133],\n        [-73.985046, 40.747773],\n        [-73.984579, 40.748431],\n        [-73.973437, 40.743885],\n        [-73.972844, 40.744452],\n        [-73.970728, 40.743885],\n        [-73.970611, 40.735137],\n        [-73.9714, 40.733734],\n        [-73.973503, 40.732341],\n        [-73.969823, 40.729864],\n        [-73.969243, 40.727535],\n        [-73.975074, 40.711418],\n        [-73.976603, 40.710276],\n        [-73.978077, 40.710587],\n        [-73.979462, 40.70932],\n        [-73.992664, 40.708145],\n        [-73.996237, 40.707307],\n        [-74.001135, 40.704086],\n        [-74.0055, 40.70243],\n        [-74.006778, 40.703628],\n        [-74.009173, 40.702484],\n        [-74.010637, 40.70371],\n        [-74.014535, 40.703624],\n        [-74.014665, 40.704034],\n        [-74.017057, 40.703259]\n      ],\n      \"type\": \"LineString\"\n    },\n    \"legs\": [{\n      \"summary\": \"\",\n      \"weight\": 3873.3,\n      \"duration\": 3873.3,\n      \"steps\": [],\n      \"distance\": 9660.2\n    }],\n    \"weight_name\": \"duration\",\n    \"weight\": 3873.3,\n    \"duration\": 3873.3,\n    \"distance\": 9660.2\n  }],\n  \"waypoints\": [{\n      \"distance\": 34.00158252003884,\n      \"name\": \"West 33rd Street\",\n      \"location\": [\n        -73.985897,\n        40.748133\n      ]\n    },\n    {\n      \"distance\": 6.627227256764976,\n      \"name\": \"\",\n      \"location\": [\n        -74.017057,\n        40.703259\n      ]\n    }\n  ],\n  \"code\": \"Ok\",\n  \"uuid\": \"cjsomodyl025642o6f1jsddx6\"\n}\n\n\nThe format isn't too  far off, but it's different enough to not work. \n\nFormatting GeoJSON Correctly\nWe need to write a function to take the response Mapbox has given us and\ntransform it into a usable GeoJSON format:\n\nimport os\nimport pandas as pd\nimport requests\nimport json\n\nroutes_df = pd.read_csv('datasources/routes.csv').head(10)\ntoken = os.environ.get('mapbox_token')\n\n\ndef create_route_geojson(route_json, name):\n    \"\"\"Properly formats GeoJson for Mapbox visualization.\"\"\"\n    routes_dict = {\n        \"type\": \"Feature\",\n        \"geometry\": {\n            \"type\": \"LineString\"\n        },\n        \"weight_name\": \"duration\",\n        \"weight\": 718.9,\n        \"duration\": 0,\n        \"distance\": 0,\n        \"properties\": {\n            \"name\": \"\"\n        }\n    }\n    routes_dict['geometry']['coordinates'] = route_json['geometry']['coordinates']\n    routes_dict['legs'] = route_json['legs']\n    routes_dict['duration'] = route_json['legs'][0]['duration']\n    routes_dict['distance'] = route_json['legs'][0]['distance']\n    routes_dict['properties']['name'] = name\n    with open('dataoutput/' + name + '.json', 'w') as f:\n        json.dump(routes_dict, \n                  f, \n                  sort_keys=True, \n                  indent=4, \n                  ensure_ascii=False)\n        \n\ndef create_walking_route(row):\n    \"\"\"Get route JSON.\"\"\"\n    base_url = 'https://api.mapbox.com/directions/v5/mapbox/driving/'\n    url = base_url + str(row['home_longitude']) + \\\n        ',' + str(row['home_latitude']) + \\\n        ';' + str(row['destination_longitude']) + \\\n        ',' + str(row['destination_latitude'])\n    params = {\n        'geometries': 'geojson',\n        'access_token': token\n    }\n    req = requests.get(url, params=params)\n    route_json = req.json()['routes'][0]\n    create_route_geojson(route_json, str(int(row['route_id'])))\n\n\nroutes_df.apply(create_walking_route, axis=1)\n\n\nIt's not pretty, but it's reliable: we explicitly create the JSON structure we\nneed with routes_dict, and modify it with the API responses coming back from\nMapbox. Of course, we're still doing this one at a time, for every row in our\nDataFrame.\n\nYou'll notice I save each JSON file locally for now. In the future, we'll write\na script to automate the process of uploading our GeoJSON objects and adding\nthem to the proper Tilesets, but right now I just want to see that our work paid\noff!\n\nBy using Mapbox studio, we can see the result of our first route:\n\nA \"Driving\" Route from the Empire State Building to Battery Park.Aha! Would you\nlook at that- Mapbox knew to take the FDR drive. That's some promising stuff.\n\nDrawing Routes En Masse\nNaturally, this is only the tip of the iceberg: of the DataFrame of information\nwe loaded up, we've so far only viewed a single result. If anything in data is\nworth doing, it must be done thousands of times systematically without fail.\nLuckily, Mapbox provides us with the tools to do this: from lending us an S3\nbucket, to modifying datasets via the API, there's nothing to fear.\n\nTune in next time when do more... stuff!","html":"<p>If you've been here before, you probably already know our affinity for <strong>Mapbox</strong> and the visualization tools it provides data scientists and analysts. In the past, we've covered <a href=\"https://hackersandslackers.com/preparing-data-for-mapbox-geocoding/\">encoding location data from raw addresses</a>, as well as an <a href=\"https://hackersandslackers.com/map-data-visualization-with-mapbox/\">exploration of Mapbox Studio</a> for those getting acquainted with the tool. Today we're going a step further: drawing directions on a map.</p><p>It sounds simple enough: we already know how to geocode addresses, so all we need to do is literally go from point A to point B. That said, things always tend to get tricky, and if you've never worked with <a href=\"http://geojson.org/\">GeoJSON</a> before, you're in for a treat.</p><h2 id=\"load-up-some-data\">Load Up Some Data</h2><p>I'm going to assume you have a DataFrame ready containing these columns:</p><ul><li>origin_longitude</li><li>origin_latitude</li><li>destination_longitude</li><li>destination_latitude</li><li>Name/description of this route </li></ul><p>If you want to play along, there are plenty of free datasets out there to play with - I sourced some information from <strong>BigQuery </strong>while I was testing things out.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nimport pandas as pd\nimport requests\nimport json\n\nroutes_df = pd.read_csv('datasources/routes.csv').head(10)\ntoken = os.environ.get('mapbox_token')\n</code></pre>\n<!--kg-card-end: markdown--><p>So far so good- all we've done is load our data, and save our Mapbox token from an environment variable.</p><h2 id=\"mapbox-directions-endpoint\">Mapbox Directions Endpoint</h2><p>Next, we're going to use Mapbox's <a href=\"https://docs.mapbox.com/api/navigation/#directions\">Directions API</a> to return a route for us. The anatomy of a GET call to receive directions looks like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">https://api.mapbox.com/directions/v5/mapbox/{{method_of_transportation}}/{{origin_longitude}},{{origin_latitude}};{{destination_longitude}},{{destination_latitude}}\n\nPARAMS:\naccess_token={{your_mapbox_access_token}}\ngeometries=geojson\n</code></pre>\n<!--kg-card-end: markdown--><ul><li><strong>method_of_transportation </strong>refers to one of the three methods that Mapbox offers for creating routes: <em>driving-traffic</em>, <em>driving</em>, <em>walking</em>, and <em>cycling</em>. Note that there is currently no way to draw route objects which follow public transit: this is perhaps Mapbox's biggest downfall at the moment. Nevertheless, if this is something you need, data can be imported from Google maps to be used with Mapbox.</li><li><strong>access_token</strong> can be either your public token (visible upon login at mapbox.com) or a generated secret token.</li><li><strong>geometries</strong> accepts the method by which to draw the object. This can be <em>GeoJSON,</em> <em>polyline, </em>or <em>polyline6. </em>Let's stick with GeoJSON.</li></ul><h2 id=\"constructing-api-requests\">Constructing API Requests</h2><p>Let's construct a request per row in our DataFrame. By using Pandas' apply, we fire a function per row to do just that:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nimport pandas as pd\nimport requests\nimport json\n\nroutes_df = pd.read_csv('datasources/routes.csv').head(10)\ntoken = os.environ.get('mapbox_token')\n\ndef create_route_json(row):\n    &quot;&quot;&quot;Get route JSON.&quot;&quot;&quot;\n    base_url = 'https://api.mapbox.com/directions/v5/mapbox/driving/'\n    url = base_url + str(row['home_longitude']) + \\\n        ',' + str(row['home_latitude']) + \\\n        ';' + str(row['destination_longitude']) + \\\n        ',' + str(row['destination_latitude'])\n    params = {\n        'geometries': 'geojson',\n        'access_token': token\n    }\n    req = requests.get(url, params=params)\n    route_json = req.json()['routes'][0]\n    # Now what?\n\n\nroutes_df.apply(create_route_json, axis=1)\n</code></pre>\n<!--kg-card-end: markdown--><p>Here's where things get a little tricky. You see, GeoJSON abides by a strict format. It looks something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-json\">{\n  &quot;type&quot;: &quot;Feature&quot;,\n  &quot;geometry&quot;: {\n    &quot;coordinates&quot;: [\n      [ -73.985897, 40.748133 ], [ -73.985046, 40.747773 ], \n      [ -73.984579, 40.748431 ], [ -73.973437, 40.743885 ],\n      [ -73.972844, 40.744452 ], [ -73.970728, 40.743885 ], \n      [ -73.970611, 40.735137 ], [ -73.9714, 40.733734 ],\n      [ -73.973503, 40.732341 ], [ -73.969823, 40.729864 ], \n      [ -73.969243, 40.727535 ], [ -73.975074, 40.711418 ],\n      [ -73.976603, 40.710276 ], [ -73.978077, 40.710587 ], \n      [ -73.979462, 40.70932 ], [ -73.992664, 40.708145 ],\n      [ -73.996237, 40.707307 ], [ -74.001135, 40.704086 ], \n      [ -74.0055, 40.70243 ], [ -74.006778, 40.703628 ],\n      [ -74.009173, 40.702484 ], [ -74.010637, 40.70371 ], \n      [ -74.014535, 40.703624 ], [ -74.014665, 40.704034 ],\n      [ -74.017057, 40.703259 ]\n    ],\n    &quot;type&quot;: &quot;LineString&quot;\n  },\n  &quot;legs&quot;: [{\n      &quot;summary&quot;: &quot;&quot;,\n      &quot;weight&quot;: 3873.3,\n      &quot;duration&quot;: 3873.3,\n      &quot;steps&quot;: [],\n      &quot;distance&quot;: 9660.2\n  }],\n  &quot;weight_name&quot;: &quot;duration&quot;,\n  &quot;weight&quot;: 3873.3,\n  &quot;duration&quot;: 3873.3,\n  &quot;distance&quot;: 9660.2,\n  &quot;properties&quot;: {\n    &quot;name&quot;: &quot;Empire State&quot;\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>For the sake of being difficult, the Mapbox Directions API doesn't return responses in exactly this format. Instead, their response looks like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-json\">{\n  &quot;routes&quot;: [{\n    &quot;geometry&quot;: {\n      &quot;coordinates&quot;: [\n        [-73.985897, 40.748133],\n        [-73.985046, 40.747773],\n        [-73.984579, 40.748431],\n        [-73.973437, 40.743885],\n        [-73.972844, 40.744452],\n        [-73.970728, 40.743885],\n        [-73.970611, 40.735137],\n        [-73.9714, 40.733734],\n        [-73.973503, 40.732341],\n        [-73.969823, 40.729864],\n        [-73.969243, 40.727535],\n        [-73.975074, 40.711418],\n        [-73.976603, 40.710276],\n        [-73.978077, 40.710587],\n        [-73.979462, 40.70932],\n        [-73.992664, 40.708145],\n        [-73.996237, 40.707307],\n        [-74.001135, 40.704086],\n        [-74.0055, 40.70243],\n        [-74.006778, 40.703628],\n        [-74.009173, 40.702484],\n        [-74.010637, 40.70371],\n        [-74.014535, 40.703624],\n        [-74.014665, 40.704034],\n        [-74.017057, 40.703259]\n      ],\n      &quot;type&quot;: &quot;LineString&quot;\n    },\n    &quot;legs&quot;: [{\n      &quot;summary&quot;: &quot;&quot;,\n      &quot;weight&quot;: 3873.3,\n      &quot;duration&quot;: 3873.3,\n      &quot;steps&quot;: [],\n      &quot;distance&quot;: 9660.2\n    }],\n    &quot;weight_name&quot;: &quot;duration&quot;,\n    &quot;weight&quot;: 3873.3,\n    &quot;duration&quot;: 3873.3,\n    &quot;distance&quot;: 9660.2\n  }],\n  &quot;waypoints&quot;: [{\n      &quot;distance&quot;: 34.00158252003884,\n      &quot;name&quot;: &quot;West 33rd Street&quot;,\n      &quot;location&quot;: [\n        -73.985897,\n        40.748133\n      ]\n    },\n    {\n      &quot;distance&quot;: 6.627227256764976,\n      &quot;name&quot;: &quot;&quot;,\n      &quot;location&quot;: [\n        -74.017057,\n        40.703259\n      ]\n    }\n  ],\n  &quot;code&quot;: &quot;Ok&quot;,\n  &quot;uuid&quot;: &quot;cjsomodyl025642o6f1jsddx6&quot;\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>The format isn't <em>too</em> far off, but it's different enough to not work. </p><h2 id=\"formatting-geojson-correctly\">Formatting GeoJSON Correctly</h2><p>We need to write a function to take the response Mapbox has given us and transform it into a usable GeoJSON format:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nimport pandas as pd\nimport requests\nimport json\n\nroutes_df = pd.read_csv('datasources/routes.csv').head(10)\ntoken = os.environ.get('mapbox_token')\n\n\ndef create_route_geojson(route_json, name):\n    &quot;&quot;&quot;Properly formats GeoJson for Mapbox visualization.&quot;&quot;&quot;\n    routes_dict = {\n        &quot;type&quot;: &quot;Feature&quot;,\n        &quot;geometry&quot;: {\n            &quot;type&quot;: &quot;LineString&quot;\n        },\n        &quot;weight_name&quot;: &quot;duration&quot;,\n        &quot;weight&quot;: 718.9,\n        &quot;duration&quot;: 0,\n        &quot;distance&quot;: 0,\n        &quot;properties&quot;: {\n            &quot;name&quot;: &quot;&quot;\n        }\n    }\n    routes_dict['geometry']['coordinates'] = route_json['geometry']['coordinates']\n    routes_dict['legs'] = route_json['legs']\n    routes_dict['duration'] = route_json['legs'][0]['duration']\n    routes_dict['distance'] = route_json['legs'][0]['distance']\n    routes_dict['properties']['name'] = name\n    with open('dataoutput/' + name + '.json', 'w') as f:\n        json.dump(routes_dict, \n                  f, \n                  sort_keys=True, \n                  indent=4, \n                  ensure_ascii=False)\n        \n\ndef create_walking_route(row):\n    &quot;&quot;&quot;Get route JSON.&quot;&quot;&quot;\n    base_url = 'https://api.mapbox.com/directions/v5/mapbox/driving/'\n    url = base_url + str(row['home_longitude']) + \\\n        ',' + str(row['home_latitude']) + \\\n        ';' + str(row['destination_longitude']) + \\\n        ',' + str(row['destination_latitude'])\n    params = {\n        'geometries': 'geojson',\n        'access_token': token\n    }\n    req = requests.get(url, params=params)\n    route_json = req.json()['routes'][0]\n    create_route_geojson(route_json, str(int(row['route_id'])))\n\n\nroutes_df.apply(create_walking_route, axis=1)\n</code></pre>\n<!--kg-card-end: markdown--><p>It's not pretty, but it's reliable: we explicitly create the JSON structure we need with <code>routes_dict</code>, and modify it with the API responses coming back from Mapbox. Of course, we're still doing this one at a time, for every row in our DataFrame.</p><p>You'll notice I save each JSON file locally for now. In the future, we'll write a script to automate the process of uploading our GeoJSON objects and adding them to the proper Tilesets, but right now I just want to see that our work paid off!</p><p>By using Mapbox studio, we can see the result of our first route:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2019-02-28-at-8.05.21-AM.png\" class=\"kg-image\"><figcaption>A \"Driving\" Route from the Empire State Building to Battery Park.</figcaption></figure><!--kg-card-end: image--><p>Aha! Would you look at that- Mapbox knew to take the FDR drive. That's some promising stuff.</p><h3 id=\"drawing-routes-en-masse\">Drawing Routes En Masse</h3><p>Naturally, this is only the tip of the iceberg: of the DataFrame of information we loaded up, we've so far only viewed a single result. If anything in data is worth doing, it must be done thousands of times systematically without fail. Luckily, Mapbox provides us with the tools to do this: from lending us an S3 bucket, to modifying datasets via the API, there's nothing to fear.</p><p>Tune in next time when do more... stuff!</p>","url":"https://hackersandslackers.com/mapbox-draw-route-objects/","uuid":"ef0a4639-8818-475b-9a25-6a20b13c1ecf","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c17ddd4418434084a873d2a"}},{"node":{"id":"Ghost__Post__5c663a28c2209e663b5e5ab2","title":"Lynx Roundup, February 26th","slug":"lynx-roundup-february-26th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/142.jpg","excerpt":"Minimally Sufficient Pandas!  Dependent Types in Python!  Symbolic & Imperative APIs in TensorFlow!","custom_excerpt":"Minimally Sufficient Pandas!  Dependent Types in Python!  Symbolic & Imperative APIs in TensorFlow!","created_at_pretty":"15 February, 2019","published_at_pretty":"26 February, 2019","updated_at_pretty":"28 February, 2019","created_at":"2019-02-14T23:03:52.000-05:00","published_at":"2019-02-26T07:00:00.000-05:00","updated_at":"2019-02-27T22:45:40.000-05:00","meta_title":"Lynx Roundup, February 26th | Hackers and Slackers","meta_description":"Minimally Sufficient Pandas!  Dependent Types in Python!  Symbolic & Imperative APIs in TensorFlow!","og_description":"Minimally Sufficient Pandas!  Dependent Types in Python!  Symbolic & Imperative APIs in TensorFlow!","og_image":"https://hackersandslackers.com/content/images/2019/02/142.jpg","og_title":"Lynx Roundup, February 26th","twitter_description":"Minimally Sufficient Pandas!  Dependent Types in Python!  Symbolic & Imperative APIs in TensorFlow!","twitter_image":"https://hackersandslackers.com/content/images/2019/02/142.jpg","twitter_title":"Lynx Roundup, February 26th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"\n\nhttps://medium.com/dunder-data/minimally-sufficient-pandas-a8e67f2a2428\n\nhttps://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021\n\nhttps://eng.uber.com/aresdb/\n\nhttps://github.com/pybee/briefcase\n\nhttps://dev.to/wemake-services/simple-dependent-types-in-python-4e14\n\nhttps://www.searchenginejournal.com/python-seo-data-reference-guide/287927/#close\n\nhttps://phys.org/news/2019-02-scientists-magnet.html","html":"<p></p><p><a href=\"https://medium.com/dunder-data/minimally-sufficient-pandas-a8e67f2a2428\">https://medium.com/dunder-data/minimally-sufficient-pandas-a8e67f2a2428</a></p><p><a href=\"https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021\">https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021</a></p><p><a href=\"https://eng.uber.com/aresdb/\">https://eng.uber.com/aresdb/</a></p><p><a href=\"https://github.com/pybee/briefcase\">https://github.com/pybee/briefcase</a></p><p><a href=\"https://dev.to/wemake-services/simple-dependent-types-in-python-4e14\">https://dev.to/wemake-services/simple-dependent-types-in-python-4e14</a></p><p><a href=\"https://www.searchenginejournal.com/python-seo-data-reference-guide/287927/#close\">https://www.searchenginejournal.com/python-seo-data-reference-guide/287927/#close</a></p><p><a href=\"https://phys.org/news/2019-02-scientists-magnet.html\">https://phys.org/news/2019-02-scientists-magnet.html</a></p>","url":"https://hackersandslackers.com/lynx-roundup-february-26th/","uuid":"21409c82-4e00-4d12-a36b-a2fd11a49d97","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c663a28c2209e663b5e5ab2"}},{"node":{"id":"Ghost__Post__5c654ed3eab17b74dbf2d2b0","title":"Welcome to SQL 3: Building Relations and Combining Data Sets","slug":"welcome-to-sql-3-building-relationships-and-combining-data","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/SQLpt3@2x.jpg","excerpt":"This week we look at the fun side of SQL where we JOIN tables and create UNIONs.","custom_excerpt":"This week we look at the fun side of SQL where we JOIN tables and create UNIONs.","created_at_pretty":"14 February, 2019","published_at_pretty":"26 February, 2019","updated_at_pretty":"10 April, 2019","created_at":"2019-02-14T06:19:47.000-05:00","published_at":"2019-02-25T20:11:28.000-05:00","updated_at":"2019-04-10T10:16:10.000-04:00","meta_title":"Relationships and Combining Data in SQL | Hackers and Slackers","meta_description":"This week we look at the fun side of SQL. Get the low-down on how to JOIN tables and create UNIONs.","og_description":"This week we look at the fun side of SQL. Get the low-down on how to JOIN tables and create UNIONs.","og_image":"https://hackersandslackers.com/content/images/2019/02/SQLpt3@2x.jpg","og_title":"Welcome to SQL 3: Building Relationships and Combining Data","twitter_description":"This week we look at the fun side of SQL. Get the low-down on how to JOIN tables and create UNIONs.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/SQLpt3@2x.jpg","twitter_title":"Welcome to SQL 3: Building Relationships and Combining Data","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},{"name":"PostgreSQL","slug":"postgresql","description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","feature_image":null,"meta_description":"Our preferred relational database of choice which deserves more love. Learn the advantages that PostgreSQL provides over closed-source competitors.","meta_title":"Working with PostgreSQL | Hackers and Slackers","visibility":"public"},{"name":"#Welcome to SQL","slug":"welcome-to-sql","description":"If you feel like you’re late to the data party, we all are. The party has been going strong since the 70s: brush up on SQL syntax the old-fashioned way.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/welcometosqlseries.jpg","meta_description":"If you feel like you’re late to the data party, we all are. The party has been going strong since the 70s: brush up on SQL syntax the old-fashioned way.","meta_title":"Welcome to SQL","visibility":"internal"}],"plaintext":"If you've felt a bit distance or estranged from SQL so far in the series, never\nfear: we're about to discover the magic of what makes relational databases so...\n relational.  Turn down the lights and put on your favorite Marvin Gaye track;\nwe're about to make connections on a whole other level.\n\nI find that existing attempts to explain Database relations (JOINs in\nparticular) have been an utter failure in illustrating these concepts. The Venn\nDiagrams we're all accustomed to seeing mean nothing to somebody who has never\nseen a JOIN occur, and even then, do they really  describe what's happening? I'd\nlove to toss together some quick animations as an alternative, but chances are\nI'll settle for something mediocre like the rest of us.\n\nRelational Databases in Action\nAs much as we've covered SQL so far, we still haven't had \"the talk.\" Oh God no,\nnot that  talk; I meant the obligatory \nexample-of-how-two-tables-might-relate-to-one-another  talk. This talk is a bit\nless awkward, but it definitely won't prepare you for the finer things in life.\nJust kidding, data is  the finer part of life. Or at least it is in mine. Let's\nnot linger on that too long.\n\nLet's look at the most common scenario used to illustrate data relationships:\nthe customers  vs. orders  predicament. Let's say we decided to open up an \nOrganic Vegan Paleo Keto Kale Voltron 5000  health-food marketplace to cater to\na high-end clientele: pretentious rich assholes. It just so happens that the\n\"rich asshole\" market is very receptive to best practices in customer relations,\nso we start a CRM to track our best customers. This record-keeping helps us\npretend to remember the names and personalities of our clientele:\n\nCustomers Table\nid\n first_name\n last_name\n email\n gender\n state\n phone\n 653466635\n Timothea\n Crat\n tcrat0@bandcamp.com\n Female\n Washington\n 206-220-3752\n 418540868\n Kettie\n Fuggle\n kfuggle1@cafepress.com\n Female\n California\n 661-793-1372\n 857532654\n Boonie\n Sommerland\n bsommerland2@soundcloud.com\n Male\n North Carolina\n 919-299-0715\n 563295938-4\n Red\n Seldon\n rseldon3@addthis.com\n Male\n Indiana\n 765-880-7420\n 024844147\n Marika\n Gallatly\n mgallatly4@loc.gov\n Female\n New York\n 718-126-1462\n 900992907\n Sharlene\n McMaster\n smcmaster5@gmpg.org\n Female\n Nevada\n 775-376-0931\n 329211747-X\n Grover\n Okey\n gokey6@weather.com\n Male\n Texas\n 915-913-0625\n 656608031\n Farly\n Pluck\n fpluck7@buzzfeed.com\n Male\n Texas\n 432-670-8809\n 906380018\n Sumner\n Pickerell\n spickerellb@bloglovin.com\n Male\n Colorado\n 719-239-5042\n On the other hand, we need to keep track of inventory and items sold. Since\nwe're already swiping credit cards and getting all this personal customer data,\nwhy not associate purchases to loyal customers? Thus, we have a list of\ntransactions which looks something as such:\n\nOrders Table\nitem_id\n customer_id\n item_purchased\n first_name\n last_name\n amount\n date_purchased\n 82565290-530d-4272-9c8b-38dc0bc7426a\n 653466635\n Creme De Menthe Green\n Timothea\n Crat\n $8.57\n 5/13/18\n 9cfa5f5c-6a9c-4400-8f0f-f8262a787cd0\n 653466635\n Veal Inside - Provimi\n Timothea\n Crat\n $5.77\n 3/3/18\n 5dea0cce-c6be-4f35-91f6-0c6a1a8b8f11\n 656608031\n Arizona - Plum Green Tea\n Grover\n Okey\n $1.72\n 9/6/18\n b4813421-12e8-479b-a3b6-3d1c4c539625\n 656608031\n Beer - Fruli\n Grover\n Okey\n $4.05\n 10/1/18\n 4e7c8548-340f-4e89-a7f1-95173dcc6e53\n 656608031\n Boogies\n Grover\n Okey\n $1.97\n 12/17/18\n 65261e94-494d-48cc-8d5a-642ae6921600\n 656608031\n Cup - 3.5oz; Foam\n Grover\n Okey\n $1.84\n 11/28/18\n 1bfdca0f-d54a-4845-bbf5-982813ab4a65\n 656608031\n Arizona - Green Tea\n Grover\n Gauford\n $0.22\n 5/23/18\n d20d7add-bad4-4559-8896-d4f6d05aa3dd\n 906380018\n Lemonade - Strawberry; 591 Ml\n Sumner\n Tortoishell\n $7.98\n 10/11/18\n 12134510-bc6c-4bd7-b733-b549a61edaa3\n 906380018\n Pasta - Cappellini; Dry\n Sumner\n Wash\n $0.31\n 11/13/18\n 80f1957c-df4d-40dc-b9c4-2c3939dd0865\n 906380018\n Remy Red Berry Infusion\n Sumner\n Pisculli\n $1.25\n 12/31/18\n a75f7593-3312-43e4-a604-43405f02efdd\n 906380018\n Veal - Slab Bacon\n Sumner\n Janaszewski\n $9.80\n 3/9/18\n c6ef1f55-f35d-4618-8de7-36f59ea6653a\n 906380018-5\n Beans - Black Bean; Dry\n Sumner\n Piegrome\n $1.36\n 12/11/18\n c5b87ee3-da94-41b1-973a-ef544a3ffb6f\n 906380018\n Calypso - Strawberry Lemonade\n Sumner\n Piegrome\n $7.71\n 2/21/19\n e383c58b-d8da-40ac-afd6-7ee629dc95c6\n 656608031\n Basil - Primerba; Paste\n Mohammed\n Reed\n $2.77\n 10/21/18\n d88ccd5b-0acb-4144-aceb-c4b4b46d3b17\n 656608031\n Cheese - Fontina\n Mohammed\n Reed\n $4.24\n 7/14/18\n 659df773-719c-447e-a1a9-4577dc9c6885\n 656608031\n Cotton Wet Mop 16 Oz\n Jock\n Skittles\n $8.44\n 1/24/19\n ff52e91e-4a49-4a52-b9a5-ddc0b9316429\n 656608031\n Pastry - Trippleberry Muffin - Mini\n Jock\n Skittles\n $9.77\n 11/17/18\n 86f8ad6a-c04c-4714-8f39-01c28dcbb3cb\n 656608031\n Bread - Olive\n Jock\n Skittles\n $4.51\n 1/10/19\n e7a66b71-86ff-4700-ac57-71291e6997b0\n 656608031\n Wine - White; Riesling; Semi - Dry\n Farly\n Pluck\n $4.23\n 4/15/18\n c448db87-1246-494a-bae4-dceb8ee8a7ae\n 656608031\n Melon - Honey Dew\n Farly\n Pluck\n $1.00\n 9/10/18\n 725c171a-452d-45ef-9f23-73ef20109b90\n 656608031\n Sugar - Invert\n Farly\n Pluck\n $9.04\n 3/24/18\n 849f9140-1469-4e23-a1de-83533af5fb88\n 656608031\n Yokaline\n Farly\n Pluck\n $3.21\n 12/31/18\n 2ea79a6b-bfec-4a08-9457-04128f3b37a9\n 656608031\n Cake - Bande Of Fruit\n Farly\n Pluck\n $1.57\n 5/20/18\n Naturally, customers buy more than one item; they buy a lot. Especially that \nFarly Pluck guy at the bottom- quite the unfortunate auto-generated name.\n\nAs standalone tables, the customers  and orders  tables each serve at least one\nstraightforward purpose on their own. The Customers  table helps us with\nconsumer demographic analysis, whereas the Orders  table makes sure we’re making\nmoney and aren't getting robbed. While important, neither of the functions are\nparticularly revolutionary: this basic level of record keeping has been at the\ncore of nearly every business since the 70s. \n\nThe ability to combine data enables us to gain far more significant insights. We\ncan reward loyal customers, cater to the needs of individuals based on their\npreferences, and perhaps even sell the personal data of where and when Mr. Pluck\nhas been every Tuesday and Thursday for the past 4 months to the highest bidding\ndata broker (hint: he's at our store).\n\nThanks to relational databases, we are neither limited to single monolithic\ntables nor are we shackled by the constraints of the tables we set up front.\nAssociating data is trivial, as long as we have a means by which to associate it\nby. Below is a visualization of matching a foreign key  in our orders table to a\n primary key  in our Customers  table:\n\nAn Order's Foreign Key References a customer's IDThe above illustrates what\nwe've already brushed on a bit: Foreign Key association. Primary and foreign\nkeys are essential to describing relations between the tables, and in performing\nSQL joins. Without further adieu, let's join some data.\n\nJoining Sets of Data\nTo “join” multiple sets of data is to consolidate multiple tables into one. \n\nThe manner of this consolidation is determined by which of the four methods of\njoining tables we use: inner joins, right joins, left joins, and outer joins \n(left and right joins are kind of the same, but whatever). Regardless of the\ntype of join, all joins have the following in common:\n\n * Row comparison: we look for rows where the values of a column in Table A \n   match the values of a column in Table B.\n * Consolidation of columns: The purpose of any join is to come away with a\n   table containing columns from both  tables. \n\nLEFT & RIGHT JOINs\nLEFT  and RIGHT  joins cover a myriad of use cases. With a bit of creativity,\nleft/right joins can help solve problems we may not have expected. The terms \"\nleft\" and \"right\" refer to the table we'd like to join on when reading from\nleft-to-right. When joining tables via LEFT JOIN, the first  table in our query\nwill be the \"left\" table. Alternatively, a RIGHT JOIN  refers to the last \ntable. \n\nWhen we say \"table to join on,\" we're specifying which table's key values will\nbe the \"authority\" for our merge. In a LEFT MERGE, all  of the records in Table\nA will survive the merge:\n\n * For rows which have a match in Table B, these rows will be 'extended' to\n   include the data in Table B. This means the new columns being added to Table\n   A  from  Table B  will contain data for all rows where an association has\n   been made.\n * For rows which exist in Table A  but do NOT have a match in Table B, these\n   rows are unaffected: they will contain the same data as before the join, with\n   values in the new columns left blank.\n * Keys which exist in Table B  but do NOT exist in Table A  will be discarded.\n   The purpose of these joins is to enrich the data of the primary table.\n\nBelow is an example of an actual left join I use to power the Kanban board\nmodule on our \"Projects\" page. The left table is a table of JIRA issues, and the\nright table is a collection of issue-based customizations, such as custom icons\nand colors for issue types. Take a look at how this data is associated, and what\nmakes it into the final table:\n\nKeys on the left table determine which rows stay or go.The structure of a LEFT JOIN  query looks as such:\n\nSELECT \n  table_1.*, table_2.*\nFROM\n  t1\n    LEFT JOIN\n  t2 ON t1.column_name = t2.column_name;\n\n\nHere's an example with actual values:\n\nSELECT first_name, last_name, order_date, order_amount\nFROM customers c\nLEFT JOIN orders o\nON c.customer_id = o.customer_id;\n\n\nCompare this to a RIGHT JOIN:\n\nSELECT first_name, last_name, order_date, order_amount \nFROM customers c RIGHT JOIN orders o \nON c.customer_id = o.customer_id;\n\n\nINNER JOIN (or CROSS JOIN)\nInner joins are the most conservative method for joining sets of data. Unlike \nLEFT  or RIGHT  joins, there is no authoritative table in an inner join:  only\nrows which contain a match in all  tables will survive the join. All other rows\nwill be ignored:\n\nSELECT table_1.column_name(s), table_2.column_name(s), \nFROM table1\nINNER JOIN table2\nON table1.column_name = table2.column_name;\n\n\nBecause inner joins will only act on rows which match in all affected tables, an\ninner join will typically contain the most \"complete\" data set (highest number\nof columns satisfied with values), but will contain the fewest number of rows. \n\nOUTER JOINs\nOuter joins  actually come in a few different flavors. Generally speaking, outer\njoins maximize the amount of data which will survive after the join is\nperformed. \n\nLEFT (OR RIGHT) OUTER JOIN\nAt first glance, you might look at the results of a left/right outer  join and\nmistake them to exactly the same as their pure left/right join counterparts.\nWell, you actually wouldn't be mistaken at all! That's right, I was lying:\nthere's essentially no difference between types of joins (thus our time\nmentioning them has been worthless).\n\nFULL OUTER JOIN\nIn a full outer join, all  columns and rows will be joined into the resulting\noutput, regardless of whether or not the rows matched on our specified key. Why\ndo we specify a key at all, you ask? Matching rows on a key still  combines rows\nwhich are similar to all involved tables (if there are truly no rows with common\nground during a merge, you should ask yourself why you're merging two unrelated\nsets of data in the first place).\n\nThe result is kind of a mess. I'm going to borrow an illustration from the \nPandas  documentation here:\n\nSource: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\nWhile Column B appears to be left somewhat intact, take a look at what's\nhappening around it: columns labeled A_x and A_y  have been generated as a\nresult of the join. The outer join has created a table where every possible\ncombination of values for the keys in column B exists. Thus, the number of rows\nin our new table is effectively length of Table A  *  length of Table B.\n\nI personally rarely use outer joins, but that's just me.\n\nSELECT column_name(s)\nFROM table1\nFULL OUTER JOIN table2\nON table1.column_name = table2.column_name;\n\n\nScenario: Create a New Table from Multiple JOINs\nSo far we've only looked at examples of two tables being joined at once. In\nfact, we can merge as many tables as we want, all at once! Going back to the\nJIRA example, here is the actual query I use to create the final table which\npowers a custom Kanban board:\n\nCREATE TABLE jira\nAS\nSELECT\n  jira_issues.*,\n  jira_issuetypes.issuetype_url,\n  jira_issuetypes.issuetype_color,\n  jira_epiccolors.epic_color\nFROM\n  jira_issues\n  LEFT JOIN jira_issuetypes ON jira_issues.issuetype = jira_issuetypes.issuetype\n  LEFT JOIN jira_epiccolors ON jira_issues.epic_name = jira_epiccolors.epic_name;\n\n\nIf you're using PostgreSQL, views are a great way to save the results of a join\nwithout adding additional tables. Instead of using CREATE TABLE, try using \nCREATE VIEW:CREATE VIEW jira\nAS SELECT\n  jira_issues.*,\n  jira_issuetypes.issuetype_url,\n  jira_issuetypes.issuetype_color,\n  jira_epiccolors.epic_color\nFROM\n  jira_issues\n  LEFT JOIN jira_issuetypes ON jira_issues.issuetype = jira_issuetypes.issuetype\n  LEFT JOIN jira_epiccolors ON jira_issues.epic_name = jira_epiccolors.epic_name;\n\nUnions & Union All\nA good way to think about JOINs is extending our dataset horizontally. A UNION,\nthen, is a way of combining data vertically. Unions  combine data sets with the\nsame structure: they simply create a table with rows from both tables. UNION \noperators can combine the result-set of two or more SELECT statements, as long\nas:\n\n * Each SELECT statement within UNION must have the same number of columns.\n * The columns must also have similar data types.\n * The columns in each SELECT statement must also be in the same order.\n\nUNION\nSELECT column_name(s) FROM table1\nUNION\nSELECT column_name(s) FROM table2;\n\n\nUNION (with WHERE)\nWe can also add logic to unions via where  statements:\n\nSELECT City, Country FROM Customers\nWHERE Country='Germany'\nUNION\nSELECT City, Country FROM Suppliers\nWHERE Country='Germany'\nORDER BY City;\n\n\nUNION ALL\nAn interesting distinction is the presence of UNION  versus UNION ALL. Of the\ntwo, UNION  is the more \"intelligent\" operation: if identical rows exist in both\nSELECT queries, a UNION  will know to only give us one row to avoid duplicates.\nOn the other hand, UNION ALL  does  return duplicates: this results in a faster\nquery and could be useful for those who want to know what is in both SELECT \nstatements:\n\nSELECT column_name(s) FROM table1\nUNION ALL\nSELECT column_name(s) FROM table2;\n\n\nUNION ALL (with WHERE)\nJust like UNION, we can add logic to union all via where  statements:\n\nSELECT City, Country FROM Customers\nWHERE Country='Germany'\nUNION ALL\nSELECT City, Country FROM Suppliers\nWHERE Country='Germany'\nORDER BY City;\n\n\nMore SQL Ahead\nI hope that visualizing the way which JOINs  and UNIONs  work can help to reduce\nfriction for SQL new-comers. I find it difficult to believe that human beings\ncan fully grasp these concepts without seeing them happen first-hand, which begs\nthe question: why would anybody explore something so poorly explained, without\nknowing the benefits?\n\nIf you find these guides useful, feel welcome to holler at me to keep them\ncoming. We still have more SQL ahead in our series: stay tuned for when we\nexplore aggregate values and more!","html":"<p>If you've felt a bit distance or estranged from SQL so far in the series, never fear: we're about to discover the magic of what makes relational databases so... <em>relational.</em> Turn down the lights and put on your favorite Marvin Gaye track; we're about to make connections on a whole other level.</p><p>I find that existing attempts to explain Database relations (JOINs in particular) have been an utter failure in illustrating these concepts. The Venn Diagrams we're all accustomed to seeing mean nothing to somebody who has never seen a JOIN occur, and even then, do they <em>really</em> describe what's happening? I'd love to toss together some quick animations as an alternative, but chances are I'll settle for something mediocre like the rest of us.</p><h2 id=\"relational-databases-in-action\">Relational Databases in Action</h2><p>As much as we've covered SQL so far, we still haven't had \"the talk.\" Oh God no, not <em>that</em> talk; I meant the obligatory <em>example-of-how-two-tables-might-relate-to-one-another</em> talk. This talk is a bit less awkward, but it definitely won't prepare you for the finer things in life. Just kidding, data <em>is</em> the finer part of life. Or at least it is in mine. Let's not linger on that too long.</p><p>Let's look at the most common scenario used to illustrate data relationships: the <strong>customers</strong> vs. <strong>orders</strong> predicament. Let's say we decided to open up an <strong>Organic Vegan Paleo Keto Kale Voltron 5000</strong> health-food marketplace to cater to a high-end clientele: pretentious rich assholes. It just so happens that the \"rich asshole\" market is very receptive to best practices in customer relations, so we start a CRM to track our best customers. This record-keeping helps us pretend to remember the names and personalities of our clientele:</p><h3 id=\"customers-table\">Customers Table</h3><!--kg-card-begin: html--><style>\n    .table1 td {\n        padding: 15px;\n    display: table-cell;\n    text-align: left;\n    vertical-align: middle;\n    font-size: 0.8em;\n    text-align: center;\n    line-height: 1.2;\n    font-size: .75em;\n    }\n    \n    \n    .table1 td:nth-of-type(4) {\n        max-width: 80px;\n    }\n    .table1 td:last-of-type{\n        min-width: 100px;\n    }\n    \n        \n</style>\n\n<div class=\"tableContainer\">\n<table class=\"table1\">\n\t<thead>\n       <tr>\n              <th>id</th>\n              <th>first_name</th>\n              <th>last_name</th>\n              <th>email</th>\n              <th>gender</th>\n              <th>state</th>\n              <th>phone</th>\n          </tr>\n    </thead>\n    <tbody>\n       <tr>\n              <td>653466635</td>\n              <td>Timothea</td>\n              <td>Crat</td>\n              <td>tcrat0@bandcamp.com</td>\n              <td>Female</td>\n              <td>Washington</td>\n              <td>206-220-3752</td>\n          </tr>\n       <tr>\n              <td>418540868</td>\n              <td>Kettie</td>\n              <td>Fuggle</td>\n              <td>kfuggle1@cafepress.com</td>\n              <td>Female</td>\n              <td>California</td>\n              <td>661-793-1372</td>\n          </tr>\n       <tr>\n              <td>857532654</td>\n              <td>Boonie</td>\n              <td>Sommerland</td>\n              <td>bsommerland2@soundcloud.com</td>\n              <td>Male</td>\n              <td>North Carolina</td>\n              <td>919-299-0715</td>\n          </tr>\n       <tr>\n              <td>563295938-4</td>\n              <td>Red</td>\n              <td>Seldon</td>\n              <td>rseldon3@addthis.com</td>\n              <td>Male</td>\n              <td>Indiana</td>\n              <td>765-880-7420</td>\n          </tr>\n       <tr>\n              <td>024844147</td>\n              <td>Marika</td>\n              <td>Gallatly</td>\n              <td>mgallatly4@loc.gov</td>\n              <td>Female</td>\n              <td>New York</td>\n              <td>718-126-1462</td>\n          </tr>\n       <tr>\n              <td>900992907</td>\n              <td>Sharlene</td>\n              <td>McMaster</td>\n              <td>smcmaster5@gmpg.org</td>\n              <td>Female</td>\n              <td>Nevada</td>\n              <td>775-376-0931</td>\n          </tr>\n       <tr>\n              <td>329211747-X</td>\n              <td>Grover</td>\n              <td>Okey</td>\n              <td>gokey6@weather.com</td>\n              <td>Male</td>\n              <td>Texas</td>\n              <td>915-913-0625</td>\n          </tr>\n       <tr>\n              <td>656608031</td>\n              <td>Farly</td>\n              <td>Pluck</td>\n              <td>fpluck7@buzzfeed.com</td>\n              <td>Male</td>\n              <td>Texas</td>\n              <td>432-670-8809</td>\n          </tr>\n        <tr>\n              <td>906380018</td>\n              <td>Sumner</td>\n              <td>Pickerell</td>\n              <td>spickerellb@bloglovin.com</td>\n              <td>Male</td>\n              <td>Colorado</td>\n              <td>719-239-5042</td>\n          </tr>\n    </tbody>\n   </table>\n</div><!--kg-card-end: html--><p>On the other hand, we need to keep track of inventory and items sold. Since we're already swiping credit cards and getting all this personal customer data, why not associate purchases to loyal customers? Thus, we have a list of transactions which looks something as such:</p><h3 id=\"orders-table\">Orders Table</h3><!--kg-card-begin: html--><style>\n    .table2 td {\n      padding: 10px 15px;\n    }\n    \n    .table2 tr td:first-of-type {\n        min-width: 100px !important;\n    white-space: nowrap;\n    text-overflow: ellipsis;\n    max-width: 100px;\n    }\n    \n    .table2 tr td:nth-of-type(2) {\n        min-width: 85px !important;\n    }\n</style>\n\n\n<div class=\"tableContainer\">\n   <table class=\"table2\">\n          <thead>\n       <tr>\n              <th>item_id</th>\n              <th>customer_id</th>\n              <th>item_purchased</th>\n              <th>first_name</th>\n              <th>last_name</th>\n              <th>amount</th>\n              <th>date_purchased</th>\n          </tr>\n       </thead>\n       <tbody>\n       <tr>\n              <td>82565290-530d-4272-9c8b-38dc0bc7426a</td>\n              <td>653466635</td>\n              <td>Creme De Menthe Green</td>\n              <td>Timothea</td>\n              <td>Crat</td>\n              <td>$8.57</td>\n              <td>5/13/18</td>\n          </tr>\n       <tr>\n              <td>9cfa5f5c-6a9c-4400-8f0f-f8262a787cd0</td>\n              <td>653466635</td>\n              <td>Veal Inside - Provimi</td>\n              <td>Timothea</td>\n              <td>Crat</td>\n              <td>$5.77</td>\n              <td>3/3/18</td>\n          </tr>\n       <tr>\n              <td>5dea0cce-c6be-4f35-91f6-0c6a1a8b8f11</td>\n              <td>656608031</td>\n              <td>Arizona - Plum Green Tea</td>\n              <td>Grover</td>\n              <td>Okey</td>\n              <td>$1.72</td>\n              <td>9/6/18</td>\n          </tr>\n       <tr>\n              <td>b4813421-12e8-479b-a3b6-3d1c4c539625</td>\n              <td>656608031</td>\n              <td>Beer - Fruli</td>\n              <td>Grover</td>\n              <td>Okey</td>\n              <td>$4.05</td>\n              <td>10/1/18</td>\n          </tr>\n       <tr>\n              <td>4e7c8548-340f-4e89-a7f1-95173dcc6e53</td>\n              <td>656608031</td>\n              <td>Boogies</td>\n              <td>Grover</td>\n              <td>Okey</td>\n              <td>$1.97</td>\n              <td>12/17/18</td>\n          </tr>\n       <tr>\n              <td>65261e94-494d-48cc-8d5a-642ae6921600</td>\n              <td>656608031</td>\n              <td>Cup - 3.5oz; Foam</td>\n              <td>Grover</td>\n              <td>Okey</td>\n              <td>$1.84</td>\n              <td>11/28/18</td>\n          </tr>\n       <tr>\n              <td>1bfdca0f-d54a-4845-bbf5-982813ab4a65</td>\n              <td>656608031</td>\n              <td>Arizona - Green Tea</td>\n              <td>Grover</td>\n              <td>Gauford</td>\n              <td>$0.22</td>\n              <td>5/23/18</td>\n          </tr>\n       <tr>\n              <td>d20d7add-bad4-4559-8896-d4f6d05aa3dd</td>\n              <td>906380018</td>\n              <td>Lemonade - Strawberry; 591 Ml</td>\n              <td>Sumner</td>\n              <td>Tortoishell</td>\n              <td>$7.98</td>\n              <td>10/11/18</td>\n          </tr>\n       <tr>\n              <td>12134510-bc6c-4bd7-b733-b549a61edaa3</td>\n              <td>906380018</td>\n              <td>Pasta - Cappellini; Dry</td>\n              <td>Sumner</td>\n              <td>Wash</td>\n              <td>$0.31</td>\n              <td>11/13/18</td>\n          </tr>\n       <tr>\n              <td>80f1957c-df4d-40dc-b9c4-2c3939dd0865</td>\n              <td>906380018</td>\n              <td>Remy Red Berry Infusion</td>\n              <td>Sumner</td>\n              <td>Pisculli</td>\n              <td>$1.25</td>\n              <td>12/31/18</td>\n          </tr>\n       <tr>\n              <td>a75f7593-3312-43e4-a604-43405f02efdd</td>\n              <td>906380018</td>\n              <td>Veal - Slab Bacon</td>\n              <td>Sumner</td>\n              <td>Janaszewski</td>\n              <td>$9.80</td>\n              <td>3/9/18</td>\n          </tr>\n       <tr>\n              <td>c6ef1f55-f35d-4618-8de7-36f59ea6653a</td>\n              <td>906380018-5</td>\n              <td>Beans - Black Bean; Dry</td>\n              <td>Sumner</td>\n              <td>Piegrome</td>\n              <td>$1.36</td>\n              <td>12/11/18</td>\n          </tr>\n       <tr>\n              <td>c5b87ee3-da94-41b1-973a-ef544a3ffb6f</td>\n              <td>906380018</td>\n              <td>Calypso - Strawberry Lemonade</td>\n              <td>Sumner</td>\n              <td>Piegrome</td>\n              <td>$7.71</td>\n              <td>2/21/19</td>\n          </tr>\n       <tr>\n              <td>e383c58b-d8da-40ac-afd6-7ee629dc95c6</td>\n              <td>656608031</td>\n              <td>Basil - Primerba; Paste</td>\n              <td>Mohammed</td>\n              <td>Reed</td>\n              <td>$2.77</td>\n              <td>10/21/18</td>\n          </tr>\n       <tr>\n              <td>d88ccd5b-0acb-4144-aceb-c4b4b46d3b17</td>\n              <td>656608031</td>\n              <td>Cheese - Fontina</td>\n              <td>Mohammed</td>\n              <td>Reed</td>\n              <td>$4.24</td>\n              <td>7/14/18</td>\n          </tr>\n       <tr>\n              <td>659df773-719c-447e-a1a9-4577dc9c6885</td>\n              <td>656608031</td>\n              <td>Cotton Wet Mop 16 Oz</td>\n              <td>Jock</td>\n              <td>Skittles</td>\n              <td>$8.44</td>\n              <td>1/24/19</td>\n          </tr>\n       <tr>\n              <td>ff52e91e-4a49-4a52-b9a5-ddc0b9316429</td>\n              <td>656608031</td>\n              <td>Pastry - Trippleberry Muffin - Mini</td>\n              <td>Jock</td>\n              <td>Skittles</td>\n              <td>$9.77</td>\n              <td>11/17/18</td>\n          </tr>\n       <tr>\n              <td>86f8ad6a-c04c-4714-8f39-01c28dcbb3cb</td>\n              <td>656608031</td>\n              <td>Bread - Olive</td>\n              <td>Jock</td>\n              <td>Skittles</td>\n              <td>$4.51</td>\n              <td>1/10/19</td>\n          </tr>\n\t\t\t<tr>\n\n              <td>e7a66b71-86ff-4700-ac57-71291e6997b0</td>\n              <td>656608031</td>\n              <td>Wine - White; Riesling; Semi - Dry</td>\n              <td>Farly</td>\n              <td>Pluck</td>\n              <td>$4.23</td>\n              <td>4/15/18</td>\n          </tr>\n       <tr>\n              <td>c448db87-1246-494a-bae4-dceb8ee8a7ae</td>\n              <td>656608031</td>\n              <td>Melon - Honey Dew</td>\n              <td>Farly</td>\n              <td>Pluck</td>\n              <td>$1.00</td>\n              <td>9/10/18</td>\n          </tr>\n       <tr>\n              <td>725c171a-452d-45ef-9f23-73ef20109b90</td>\n              <td>656608031</td>\n              <td>Sugar - Invert</td>\n              <td>Farly</td>\n              <td>Pluck</td>\n              <td>$9.04</td>\n              <td>3/24/18</td>\n          </tr>\n       <tr>\n              <td>849f9140-1469-4e23-a1de-83533af5fb88</td>\n              <td>656608031</td>\n              <td>Yokaline</td>\n              <td>Farly</td>\n              <td>Pluck</td>\n              <td>$3.21</td>\n              <td>12/31/18</td>\n          </tr>\n       <tr>\n              <td>2ea79a6b-bfec-4a08-9457-04128f3b37a9</td>\n              <td>656608031</td>\n              <td>Cake - Bande Of Fruit</td>\n              <td>Farly</td>\n              <td>Pluck</td>\n              <td>$1.57</td>\n              <td>5/20/18</td>\n          </tr>\n       </tbody>\n   </table>\n</div><!--kg-card-end: html--><p>Naturally, customers buy more than one item; they buy a <em>lot. </em>Especially that <strong>Farly Pluck </strong>guy at the bottom- quite the unfortunate auto-generated name.</p><p>As standalone tables, the <strong>customers</strong> and <strong>orders</strong> tables each serve at least one straightforward purpose on their own. The <strong>Customers</strong> table helps us with consumer demographic analysis, whereas the <strong>Orders</strong> table makes sure we’re making money and aren't getting robbed. While important, neither of the functions are particularly revolutionary: this basic level of record keeping has been at the core of nearly every business since the 70s. </p><p>The ability to combine data enables us to gain far more significant insights. We can reward loyal customers, cater to the needs of individuals based on their preferences, and perhaps even sell the personal data of where and when Mr. Pluck has been every Tuesday and Thursday for the past 4 months to the highest bidding data broker (hint: he's at our store).</p><p>Thanks to relational databases, we are neither limited to single monolithic tables nor are we shackled by the constraints of the tables we set up front. Associating data is trivial, as long as we have a <em>means by which to associate it by</em>. Below is a visualization of matching a <strong>foreign key</strong> in our orders table to a <strong>primary key</strong> in our <strong>Customers</strong> table:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackers.nyc3.digitaloceanspaces.com/posts/2019/02/orders4.gif\" class=\"kg-image\"><figcaption>An Order's Foreign Key References a customer's ID</figcaption></figure><!--kg-card-end: image--><p>The above illustrates what we've already brushed on a bit: Foreign Key association. Primary and foreign keys are essential to describing relations between the tables, and in performing SQL joins. Without further adieu, let's join some data.</p><h2 id=\"joining-sets-of-data\">Joining Sets of Data</h2><p>To “join” multiple sets of data is to consolidate multiple tables into one. </p><p>The manner of this consolidation is determined by which of the four methods of joining tables we use: <strong>inner joins</strong>, <strong>right joins</strong>, <strong>left joins</strong>, and <strong>outer joins</strong> (left and right joins are kind of the same, but whatever). Regardless of the type of <em>join</em>, all joins have the following in common:</p><ul><li>Row comparison: we look for rows where the values of a column in <strong>Table A</strong> match the values of a column in <strong>Table B</strong>.</li><li>Consolidation of columns: The purpose of any join is to come away with a table containing columns from <em>both</em> tables. </li></ul><h3 id=\"left-right-joins\">LEFT &amp; RIGHT JOINs</h3><p><code>LEFT</code> and <code>RIGHT</code> joins cover a myriad of use cases. With a bit of creativity, left/right joins can help solve problems we may not have expected. The terms \"<strong>left</strong>\" and \"<strong>right</strong>\" refer to the table we'd like to join on when reading from left-to-right. When joining tables via <code>LEFT JOIN</code>, the <em>first</em> table in our query will be the \"left\" table. Alternatively, a <code>RIGHT JOIN</code> refers to the <em>last</em> table. </p><p>When we say \"table to join on,\" we're specifying which table's key values will be the \"authority\" for our merge. In a <code>LEFT MERGE</code>, <em>all</em> of the records in <strong>Table A </strong>will survive the merge:</p><ul><li>For rows which have a match in <strong>Table B</strong>, these rows will be 'extended' to include the data in <strong>Table B</strong>. This means the new columns being added to <strong>Table A</strong> from<strong> Table B</strong> will contain data for all rows where an association has been made.</li><li>For rows which exist in <strong>Table A</strong> but do NOT have a match in <strong>Table B</strong>, these rows are unaffected: they will contain the same data as before the join, with values in the new columns left blank.</li><li>Keys which exist in <strong>Table B</strong> but do NOT exist in <strong>Table A</strong> will be discarded. The purpose of these joins is to enrich the data of the primary table.</li></ul><p>Below is an example of an actual left join I use to power the Kanban board module on our \"Projects\" page. The left table is a table of JIRA issues, and the right table is a collection of issue-based customizations, such as custom icons and colors for issue types. Take a look at how this data is associated, and what makes it into the final table:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackers.nyc3.digitaloceanspaces.com/posts/2019/02/tables15.gif\" class=\"kg-image\"><figcaption>Keys on the left table determine which rows stay or go.</figcaption></figure><!--kg-card-end: image--><p>The structure of a <code>LEFT JOIN</code> query looks as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">SELECT \n  table_1.*, table_2.*\nFROM\n  t1\n    LEFT JOIN\n  t2 ON t1.column_name = t2.column_name;\n</code></pre>\n<!--kg-card-end: markdown--><p>Here's an example with actual values:</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">SELECT first_name, last_name, order_date, order_amount\nFROM customers c\nLEFT JOIN orders o\nON c.customer_id = o.customer_id;\n</code></pre>\n<!--kg-card-end: markdown--><p>Compare this to a <strong>RIGHT JOIN:</strong></p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">SELECT first_name, last_name, order_date, order_amount \nFROM customers c RIGHT JOIN orders o \nON c.customer_id = o.customer_id;\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"inner-join-or-cross-join-\">INNER JOIN (or CROSS JOIN)</h3><p>Inner joins are the most conservative method for joining sets of data. Unlike <code>LEFT</code> or <code>RIGHT</code> joins, there is no authoritative table in an <strong>inner join:</strong> only rows which contain a match in <em>all</em> tables will survive the join. All other rows will be ignored:</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">SELECT table_1.column_name(s), table_2.column_name(s), \nFROM table1\nINNER JOIN table2\nON table1.column_name = table2.column_name;\n</code></pre>\n<!--kg-card-end: markdown--><p>Because inner joins will only act on rows which match in all affected tables, an inner join will typically contain the most \"complete\" data set (highest number of columns satisfied with values), but will contain the fewest number of rows. </p><h2 id=\"outer-joins\">OUTER JOINs</h2><p><strong>Outer joins</strong> actually come in a few different flavors. Generally speaking, outer joins maximize the amount of data which will survive after the join is performed. </p><h3 id=\"left-or-right-outer-join\">LEFT (OR RIGHT) OUTER JOIN</h3><p>At first glance, you might look at the results of a left/right <em>outer</em> join and mistake them to exactly the same as their pure left/right join counterparts. Well, you actually wouldn't be mistaken at all! That's right, I was lying: there's essentially no difference between types of joins (thus our time mentioning them has been worthless).</p><h3 id=\"full-outer-join\">FULL OUTER JOIN</h3><p>In a <strong>full outer join</strong>, <em>all</em> columns and rows will be joined into the resulting output, regardless of whether or not the rows matched on our specified key. Why do we specify a key at all, you ask? Matching rows on a key <em>still</em> combines rows which are similar to all involved tables (if there are truly no rows with common ground during a merge, you should ask yourself why you're merging two unrelated sets of data in the first place).</p><p>The result is kind of a mess. I'm going to borrow an illustration from the <strong>Pandas</strong> documentation here:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackers.nyc3.digitaloceanspaces.com/posts/2019/02/merging_merge_on_key_dup.png\" class=\"kg-image\"><figcaption>Source: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html</figcaption></figure><!--kg-card-end: image--><p>While Column B appears to be left somewhat intact, take a look at what's happening around it: columns labeled <strong>A_x </strong>and <strong>A_y</strong> have been generated as a result of the join. The outer join has created a table where every possible combination of values for the keys in column B exists. Thus, the number of rows in our new table is effectively <strong><em>length of Table A</em> </strong>*<strong> <em>length of Table B</em>.</strong></p><p>I personally rarely use <strong>outer joins</strong>, but that's just me.</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">SELECT column_name(s)\nFROM table1\nFULL OUTER JOIN table2\nON table1.column_name = table2.column_name;\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"scenario-create-a-new-table-from-multiple-joins\">Scenario: Create a New Table from Multiple JOINs</h2><p>So far we've only looked at examples of two tables being joined at once. In fact, we can merge as many tables as we want, all at once! Going back to the JIRA example, here is the actual query I use to create the final table which powers a custom Kanban board:</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">CREATE TABLE jira\nAS\nSELECT\n  jira_issues.*,\n  jira_issuetypes.issuetype_url,\n  jira_issuetypes.issuetype_color,\n  jira_epiccolors.epic_color\nFROM\n  jira_issues\n  LEFT JOIN jira_issuetypes ON jira_issues.issuetype = jira_issuetypes.issuetype\n  LEFT JOIN jira_epiccolors ON jira_issues.epic_name = jira_epiccolors.epic_name;\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><div class=\"protip\">\n    If you're using PostgreSQL, views are a great way to save the results of a join without adding additional tables. Instead of using <code>CREATE TABLE</code>, try using <code>CREATE VIEW</code>:\n<pre><code>CREATE VIEW jira\nAS SELECT\n  jira_issues.*,\n  jira_issuetypes.issuetype_url,\n  jira_issuetypes.issuetype_color,\n  jira_epiccolors.epic_color\nFROM\n  jira_issues\n  LEFT JOIN jira_issuetypes ON jira_issues.issuetype = jira_issuetypes.issuetype\n  LEFT JOIN jira_epiccolors ON jira_issues.epic_name = jira_epiccolors.epic_name;</code></pre>\n</div><!--kg-card-end: markdown--><h2 id=\"unions-union-all\">Unions &amp; Union All</h2><p>A good way to think about <code>JOIN</code>s is extending our dataset <em>horizontally</em>. A <code>UNION</code>, then, is a way of combining data <em>vertically. </em><strong>Unions</strong><em> </em>combine data sets with the same structure: they simply create a table with rows from both tables. <code>UNION</code> operators can combine the result-set of two or more SELECT statements, as long as:</p><ul><li>Each SELECT statement within UNION must have the same number of columns.</li><li>The columns must also have similar data types.</li><li>The columns in each SELECT statement must also be in the same order.</li></ul><h3 id=\"union\">UNION</h3><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">SELECT column_name(s) FROM table1\nUNION\nSELECT column_name(s) FROM table2;\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"union-with-where-\">UNION (with WHERE)</h3><p>We can also add logic to <strong>unions </strong>via <strong>where</strong><em> </em>statements:</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">SELECT City, Country FROM Customers\nWHERE Country='Germany'\nUNION\nSELECT City, Country FROM Suppliers\nWHERE Country='Germany'\nORDER BY City;\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"union-all\">UNION ALL</h3><p>An interesting distinction is the presence of <code>UNION</code> versus <code>UNION ALL</code>. Of the two, <code>UNION</code> is the more \"intelligent\" operation: if identical rows exist in both SELECT <code>queries</code>, a <code>UNION</code> will know to only give us one row to avoid duplicates. On the other hand, <code>UNION ALL</code> <em>does</em> return duplicates: this results in a faster query and could be useful for those who want to know what is in both <code>SELECT</code> statements:</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">SELECT column_name(s) FROM table1\nUNION ALL\nSELECT column_name(s) FROM table2;\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"union-all-with-where-\">UNION ALL (with WHERE)</h3><p>Just like <code>UNION</code>, we can add logic to <strong>union all </strong>via <strong>where</strong><em> </em>statements:</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">SELECT City, Country FROM Customers\nWHERE Country='Germany'\nUNION ALL\nSELECT City, Country FROM Suppliers\nWHERE Country='Germany'\nORDER BY City;\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"more-sql-ahead\">More SQL Ahead</h2><p>I hope that visualizing the way which <strong>JOINs</strong> and <strong>UNIONs</strong> work can help to reduce friction for SQL new-comers. I find it difficult to believe that human beings can fully grasp these concepts without seeing them happen first-hand, which begs the question: why would anybody explore something so poorly explained, without knowing the benefits?</p><p>If you find these guides useful, feel welcome to holler at me to keep them coming. We still have more SQL ahead in our series: stay tuned for when we explore aggregate values and more!</p>","url":"https://hackersandslackers.com/welcome-to-sql-3-building-relationships-and-combining-data/","uuid":"5e222417-19b5-49a7-aa64-fbe042891f00","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c654ed3eab17b74dbf2d2b0"}}]}},"pageContext":{"pageNumber":3,"humanPageNumber":4,"skip":36,"limit":12,"numberOfPages":33,"previousPagePath":"/page/3","nextPagePath":"/page/5"}}