{"data":{"ghostTag":{"slug":"software-development","name":"Software Development","visibility":"public","feature_image":null,"description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","meta_description":"General software development principals and tools. Receive insights applicable to building any application."},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c779ffbc380a221de39c7cf","title":"Using Flask-Login to Handle User Accounts","slug":"authenticating-users-with-flask-login","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/flasklogin.jpg","excerpt":"Add user authentication to your Flask app with Flask-Login","custom_excerpt":"Add user authentication to your Flask app with Flask-Login","created_at_pretty":"28 February, 2019","published_at_pretty":"04 April, 2019","updated_at_pretty":"07 April, 2019","created_at":"2019-02-28T03:46:51.000-05:00","published_at":"2019-04-04T18:36:51.000-04:00","updated_at":"2019-04-07T14:15:17.000-04:00","meta_title":"Authenticating Users With Flask-Login | Hackers and Slackers","meta_description":"Adding user authentication to your Flask app with the Flask-Login Python library. Manage user creation, log-ins, signups, and application security.","og_description":"Adding user authentication to your Flask app with the Flask-Login Python library. Manage user creation, log-ins, signups, and application security.","og_image":"https://hackersandslackers.com/content/images/2019/04/flasklogin-2.jpg","og_title":"Authenticating Users With Flask-Login","twitter_description":"Adding user authentication to your Flask app with the Flask-Login Python library. Manage user creation, log-ins, signups, and application security.","twitter_image":"https://hackersandslackers.com/content/images/2019/04/flasklogin-1.jpg","twitter_title":"Authenticating Users With Flask-Login","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"We’ve covered a lot of Flask goodness in this series thus far. We fully\nunderstand how to structure a sensible application; we can serve up complex\npage\ntemplates\n[https://hackersandslackers.com/powerful-page-templates-in-flask-with-jinja/],\nand have dived into interacting with databases using Flask-SQLAlchemy\n[https://hackersandslackers.com/manage-database-models-with-flask-sqlalchemy/].\nFor our next challenge, we’re going to need all  of the knowledge we've acquired\nthus far and much, much more. Welcome to the Super Bowl of Flask development.\nThis. Is. Flask-Login.\n\nFlask-Login [https://flask-login.readthedocs.io/en/latest/]  is a dope library\nwhich handles all aspects of user management, including vital nuances you might\nnot expect. Some noteworthy features include securing parts of our app behind\nlogin walls, encrypting passwords, and handling sessions. Moreover, It plays\nnicely with other Flask libraries we’re already familiar with: Flask-SQLAlchemy\n[https://hackersandslackers.com/manage-database-models-with-flask-sqlalchemy/] \nto create and fetch accounts, and Flask-WTForms\n[https://hackersandslackers.com/guide-to-building-forms-in-flask/]  for handling\nintelligent sign-up & log-in forms. This tutorial assumes you have some working\nknowledge of these things.\n\nFlask-Login is shockingly quite easy to use after the initial learning curve...\nbut therein lies the catch. Perhaps I’m not the only one to have noticed, but\nmost Flask-related documentation tends to be, well, God-awful. The community is\nriddled with helplessly outdated information; if you ever come across flask.ext \nin a tutorial, it is inherently worthless to anybody developing in 2019. To make\nmatters worse, official Flask-Login documentation contains some artifacts which\nare just plain wrong. The documentation contradicts itself (I’ll show you what I\nmean), and offers little to no code examples to speak of. My only hope is that I\nmight save somebody the endless headaches I’ve experienced myself.\n\nStructuring Our Application\nLet’s start with installing dependencies. This should give you an idea of what\nyou’re in for:\n\n$ pip3 install flask flask-login flask-sqlalchemy psycopg2-binary python-dotenv\n\n\nSweet. Let’s take this one step at a time, starting with our project file\nstructure:\n\nflasklogin-tutorial\n├── /login_tutorial\n│   ├── __init__.py\n│   ├── auth.py\n│   ├── forms.py\n│   ├── models.py\n│   ├── routes.py\n│   ├── /static\n│   │   ├── /dist\n│   │   │   ├── /css\n│   │   │   │   ├── account.css\n│   │   │   │   └── dashboard.css\n│   │   │   └── /js\n│   │   │       └── main.min.js\n│   │   └── /src\n│   │       ├── /js\n│   │       │   └── main.js\n│   │       └── /less\n│   │           ├── account.less\n│   │           ├── dashboard.less\n│   │           └── vars.less\n│   └── /templates\n│       ├── dashboard.html\n│       ├── layout.html\n│       ├── login.html\n│       ├── meta.html\n│       ├── scripts.html\n│       └── signup.html\n├── config.py\n├── requirements.txt\n├── setup.py\n├── start.sh\n└── wsgi.py\n\n\nOf course, I wouldn't be a gentleman unless I revealed my config.py  as well:\n\nimport os\n\n\nclass Config:\n    \"\"\"Set Flask configuration vars from .env file.\"\"\"\n\n    # General Config\n    SECRET_KEY = os.environ.get('SECRET_KEY')\n    FLASK_APP = os.environ.get('FLASK_APP')\n    FLASK_ENV = os.environ.get('FLASK_ENV')\n    FLASK_DEBUG = os.environ.get('FLASK_DEBUG')\n\n    # Database\n    SQLALCHEMY_DATABASE_URI = os.environ.get('SQLALCHEMY_DATABASE_URI')\n    SQLALCHEMY_TRACK_MODIFICATIONS = os.environ.get('SQLALCHEMY_TRACK_MODIFICATIONS')\n\n\nThe configuration values live in a .env  file, a practice I highly encourage. Of\nthese configuration variables, SECRET_KEY  is where we should turn our\nattention. SECRET_KEY is the equivalent of a password used to secure our app; it\nshould be as long, nonsensical, and impossible-to-remember as humanly possible.\nSeriously: having your secret key compromised is the equivalent of feeding\ngremlins after midnight.\n\nInitializing Flask-Login\nWith a standard \"application factory\" app, setting up Flask-Login is no\ndifferent from other Flask plugins (or whatever they're called now). This makes\nsetting up easy; all we need to do is make sure Flask-Login  is initialized in \n__init__.py  along with the rest of our plugins:\n\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_login import LoginManager\n\n\ndb = SQLAlchemy()\nlogin_manager = LoginManager()\n\n\ndef create_app():\n    \"\"\"Construct the core application.\"\"\"\n    app = Flask(__name__, instance_relative_config=False)\n\n    # Application Configuration\n    app.config.from_object('config.Config')\n\n    # Initialize Plugins\n    db.init_app(app)\n    login_manager.init_app(app)\n\n    with app.app_context():\n        # Import parts of our application\n        from . import routes\n        from . import login\n        app.register_blueprint(routes.main_bp)\n        app.register_blueprint(login.login_bp)\n\n        # Initialize Global db\n        db.create_all()\n\n        return app\n\n\nIn the above example, we're using the minimal number of plug-ins to get logins\nworking: Flask-SQLAlchemy  and Flask-Login.\n\nTo keep our sanity, we're going to separate our login routes from our main\napplication routes and logic. This is why we register a Blueprint called auth_bp\n, imported from a file called auth.py. Our “main” application (AKA anything that\nisn’t logging in) will instead live in routes.py, in a Blueprint called main_bp.\nWe'll come back to these in a moment\n\nCreating a User Model\nWe'll save our User  model in models.py. There are a few things to keep in mind\nwhen creating models compatible with Flask-Login- the most important being the\nutilization of UserMixin  from the flask_login  library. When we inherit our\nclass from UserMixin,  our model is immediately extended to include all the\nmethods necessary for Flask-Login to work. This is by far the easiest way of\ncreating a User model. I won't bother getting into details of what these methods\ndo, because if you simply begin your class with class User(UserMixin, db.Model):\n, you genuinely don't need to understand any of it:\n\nfrom . import db\nfrom flask_login import UserMixin\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\n\nclass User(UserMixin, db.Model):\n    \"\"\"Model for user accounts.\"\"\"\n\n    __tablename__ = 'flasklogin-users'\n\n    id = db.Column(db.Integer,\n                   primary_key=True,\n                   )\n    name = db.Column(db.String,\n                     nullable=False,\n                     unique=False)\n    email = db.Column(db.String(40),\n                      unique=True,\n                      nullable=False\n                      )\n    password = db.Column(db.String(200),\n                         primary_key=False,\n                         unique=False,\n                         nullable=False\n                         )\n    website = db.Column(db.String(60),\n                        index=False,\n                        unique=False,\n                        nullable=True\n                        )\n    created_on = db.Column(db.DateTime,\n                           index=False,\n                           unique=False,\n                           nullable=True\n                           )\n    last_login = db.Column(db.DateTime,\n                           index=False,\n                           unique=False,\n                           nullable=True\n                           )\n\n    def set_password(self, password):\n        \"\"\"Create hashed password.\"\"\"\n        self.password = generate_password_hash(password, method='sha256')\n\n    def check_password(self, password):\n        \"\"\"Check hashed password.\"\"\"\n        return check_password_hash(self.password, password)\n\n    def __repr__(self):\n        return '<User {}>'.format(self.username)\n\n\nThe set_password  and check_password  methods don't necessarily need to live\ninside our User model, but it's nice to keep related logic bundled together and\nout of our routes.\n\nYou may notice that our password field explicitly allows 200 characters: this is\nbecause our database will be storing hashed passwords. Thus, even if a user's\npassword is 8 characters long, the string in our database will look much\ndifferent.\n\nCreating Log-in and Sign-up Forms\nIf you're well versed in WTForms, our form logic in forms.py  probably looks as\nyou'd expect. Of course, the constraints we set here are to handle front-end\nvalidation only:\n\nfrom wtforms import Form, StringField, PasswordField, validators, SubmitField\nfrom wtforms.validators import ValidationError, DataRequired, Email, EqualTo, Length, Optional\n\n\nclass SignupForm(Form):\n    \"\"\"User Signup Form.\"\"\"\n\n    name = StringField('Name',\n                        validators=[DataRequired(message=('Enter a fake name or something.'))])\n    email = StringField('Email',\n                        validators=[Length(min=6, message=('Please enter a valid email address.')),\n                                    Email(message=('Please enter a valid email address.')),\n                                    DataRequired(message=('Please enter a valid email address.'))])\n    password = PasswordField('Password',\n                             validators=[DataRequired(message='Please enter a password.'),\n                                         Length(min=6, message=('Please select a stronger password.')),\n                                         EqualTo('confirm', message='Passwords must match')])\n    confirm = PasswordField('Confirm Your Password',)\n    website = StringField('Website',\n                          validators=[Optional()])\n    submit = SubmitField('Register')\n\n\nclass LoginForm(Form):\n    \"\"\"User Login Form.\"\"\"\n\n    email = StringField('Email', validators=[DataRequired('Please enter a valid email address.'),\n                                             Email('Please enter a valid email address.')])\n    password = PasswordField('Password', validators=[DataRequired('Uhh, your password tho?')])\n    submit = SubmitField('Log In')\n\n\nWith those out of the way, let's look at how we implement these on the Jinja\nside.\n\nsignup.html\n{% extends \"layout.html\" %}\n\n{% block pagestyles %}\n    <link href=\"{{ url_for('static', filename='dist/css/account.css') }}\" rel=\"stylesheet\" type=\"text/css\">\n{% endblock %}\n\n{% block content %}\n  <div class=\"formwrapper\">\n    <form method=post>\n      <div class=\"logo\">\n        <img src=\"{{ url_for('static', filename='dist/img/logo.png') }}\">\n      </div>\n      {% for message in get_flashed_messages() %}\n        <div class=\"alert alert-warning\">\n            <button type=\"button\" class=\"close\" data-dismiss=\"alert\">&times;</button>\n            {{ message }}\n        </div>\n      {% endfor %}\n      <h1>Sign Up</h1>\n      <div class=\"name\">\n        {{ form.name.label }}\n        {{ form.name(placeholder='John Smith') }}\n        {% if form.name.errors %}\n          <ul class=\"errors\">\n            {% for error in form.email.errors %}<li>{{ error }}</li>{% endfor %}\n          </ul>\n        {% endif %}\n      </div>\n      <div class=\"email\">\n        {{ form.email.label }}\n        {{ form.email(placeholder='youremail@example.com') }}\n        {% if form.email.errors %}\n          <ul class=\"errors\">\n            {% for error in form.email.errors %}<li>{{ error }}</li>{% endfor %}\n          </ul>\n        {% endif %}\n      </div>\n      <div class=\"password\">\n        {{ form.password.label }}\n        {{ form.password }}\n        {% if form.password.errors %}\n          <ul class=\"errors\">\n            {% for error in form.password.errors %}<li>{{ error }}</li>{% endfor %}\n          </ul>\n        {% endif %}\n      </div>\n      <div class=\"confirm\">\n        {{ form.confirm.label }}\n        {{ form.confirm }}\n        {% if form.confirm.errors %}\n          <ul class=\"errors\">\n            {% for error in form.confirm.errors %}<li>{{ error }}</li>{% endfor %}\n          </ul>\n        {% endif %}\n      </div>\n      <div class=\"website\">\n        {{ form.website.label }}\n        {{ form.website(placeholder='http://example.com') }}\n      </div>\n      <div class=\"submitbutton\">\n        <input id=\"submit\" type=\"submit\" value=\"Submit\">\n      </div>\n    </form>\n    <div class=\"loginsignup\">\n      <span>Already have an account? <a href=\"{{ url_for('auth_bp.login_page') }}\">Log in.</a><span>\n    </div>\n  </div>\n{% endblock %}\n\n\n\nlogin.py\n{% extends \"layout.html\" %}\n\n{% block pagestyles %}\n  <link href=\"{{ url_for('static', filename='dist/css/account.css') }}\" rel=\"stylesheet\" type=\"text/css\">\n{% endblock %}\n\n{% block content %}\n  <div class=\"formwrapper\">\n    <form method=post>\n      <div class=\"logo\">\n        <img src=\"{{ url_for('static', filename='dist/img/logo.png') }}\">\n      </div>\n      {% for message in get_flashed_messages() %}\n        <div class=\"alert alert-warning\">\n            <button type=\"button\" class=\"close\" data-dismiss=\"alert\">&times;</button>\n            {{ message }}\n        </div>\n      {% endfor %}\n      <h1>Log In</h1>\n      <div class=\"email\">\n         {{ form.email.label }}\n         {{ form.email(placeholder='youremail@example.com') }}\n         {% if form.email.errors %}\n           <ul class=\"errors\">\n             {% for error in form.email.errors %}<li>{{ error }}</li>{% endfor %}\n           </ul>\n         {% endif %}\n      </div>\n      <div class=\"password\">\n        {{ form.password.label }}\n        {{ form.password }}\n        {% if form.email.errors %}\n          <ul class=\"errors\">\n            {% for error in form.password.errors %}<li>{{ error }}</li>{% endfor %}\n          </ul>\n        {% endif %}\n      </div>\n      <div class=\"submitbutton\">\n        <input id=\"submit\" type=\"submit\" value=\"Submit\">\n      </div>\n      <div class=\"loginsignup\">\n        <span>Don't have an account? <a href=\"{{ url_for('auth_bp.signup_page') }}\">Sign up.</a><span>\n        </div>\n    </form>\n  </div>\n{% endblock %}\n\n\n\nExcellent: the stage is set to start kicking some ass.\n\nCreating Our Login Routes\nLet us turn our attention to the heart of the logic we'll be writing in auth.py:\n\nimport os\nfrom flask import redirect, render_template, flash, Blueprint, request, session, url_for\nfrom flask_login import login_required, logout_user, current_user, login_user\nfrom flask import current_app as app\nfrom werkzeug.security import generate_password_hash, check_password_hash\nfrom .forms import LoginForm, SignupForm\nfrom .models import db, User\nfrom . import login_manager\n\n\n# Blueprint Configuration\nauth_bp = Blueprint('auth_bp', __name__,\n                    template_folder='templates',\n                    static_folder='static')\nassets = Environment(app)\n\n\n@auth_bp.route('/login', methods=['GET', 'POST'])\ndef login_page():\n    \"\"\"User login page.\"\"\"\n    # Bypass Login screen if user is logged in\n    if current_user.is_authenticated:\n        return redirect(url_for('main_bp.dashboard'))\n    login_form = LoginForm(request.form)\n    # POST: Create user and redirect them to the app\n    if request.method == 'POST':\n        ...\n    # GET: Serve Log-in page\n    return render_template('login.html',\n                           form=LoginForm(),\n                           title='Log in | Flask-Login Tutorial.',\n                           template='login-page',\n                           body=\"Log in with your User account.\")\n\n\n@auth_bp.route('/signup', methods=['GET', 'POST'])\ndef signup_page():\n    \"\"\"User sign-up page.\"\"\"\n    signup_form = SignupForm(request.form)\n    # POST: Sign user in\n    if request.method == 'POST':\n        ...\n    # GET: Serve Sign-up page\n    return render_template('/signup.html',\n                           title='Create an Account | Flask-Login Tutorial.',\n                           form=SignupForm(),\n                           template='signup-page',\n                           body=\"Sign up for a user account.\")\n\n\nHere we find two separate skeleton routes for Sign up  and Log in. Without the\nauthentication logic added quite yet, these routes look almost identical thus\nfar.\n\nEach time a user visits a page in your app, the corresponding route is sent a \nrequest  object. This object contains contextual information about the request\nmade by the user, such as the type of request (GET or POST), any form data which\nwas submitted, etc. We leverage this to see whether the user is just arriving at\nthe page for the first time (a GET request), or if they're attempting to sign in\n(a POST request). The fairly clever takeaway here is that our login pages verify\nusers by making POST requests to themselves: this allows us to keep all logic\nrelated to logging in or signing up in a single route.\n\nSigning Up\nWe're able to validate the submitted form by importing the SignupForm  class and\npassing request.form  as the form in question. if signup_form.validate()  checks\nthe information submitted by the user against all the form's validators. If any\nof the validators are not met, the user is redirected back to the signup form\nwith error messages present.\n\nAssuming that our user isn't inept, we can move on with our logic. First, we\nneed to make sure a user with the provided email doesn't already exist:\n\n...\n\n@auth_bp.route('/signup', methods=['GET', 'POST'])\ndef signup_page():\n    \"\"\"User sign-up page.\"\"\"\n    signup_form = SignupForm(request.form)\n    # POST: Sign user in\n    if request.method == 'POST':\n        if signup_form.validate():\n            # Get Form Fields\n            name = request.form.get('name')\n            email = request.form.get('email')\n            password = request.form.get('password')\n            website = request.form.get('website')\n            existing_user = User.query.filter_by(email=email).first()\n            if existing_user is None:\n                user = User(name=name,\n                            email=email,\n                            password=generate_password_hash(password, method='sha256'),\n                            website=website)\n                db.session.add(user)\n                db.session.commit()\n                login_user(user)\n                return redirect(url_for('main_bp.dashboard'))\n            flash('A user already exists with that email address.')\n            return redirect(url_for('auth_bp.signup_page'))\n    # GET: Serve Sign-up page\n    return render_template('/signup.html',\n                           title='Create an Account | Flask-Login Tutorial.',\n                           form=SignupForm(),\n                           template='signup-page',\n                           body=\"Sign up for a user account.\")\n\n\nIf existing_user is None, we're all clear to actually clear to create a new user\nrecord. We create an instance of our User model via user = User(...). We then\nadd the user via standard SQLAlchemy syntax and finally use the imported method \nlogin_user()  to log the user in.\n\nIf everything goes well, the user will finally be redirected to the main\napplication, which is handled by return redirect(url_for('main_bp.dashboard')):\n\nA successful user log in.And here's what will happen if we log out and try to\nsign up with the same information:\n\nAttempting to sign up with an existing emailLogging In\nMoving on to our login route:\n\n@auth_bp.route('/login', methods=['GET', 'POST'])\ndef login_page():\n    \"\"\"User login page.\"\"\"\n    # Bypass Login screen if user is logged in\n    if current_user.is_authenticated:\n        return redirect(url_for('main_bp.dashboard'))\n    login_form = LoginForm(request.form)\n    # POST: Create user and redirect them to the app\n    if request.method == 'POST':\n        if login_form.validate():\n            # Get Form Fields\n            email = request.form.get('email')\n            password = request.form.get('password')\n            # Validate Login Attempt\n            user = User.query.filter_by(email=email).first()\n            if user:\n                if user.check_password(password=password):\n                    login_user(user)\n                    next = request.args.get('next')\n                    return redirect(next or url_for('main_bp.dashboard'))\n        flash('Invalid username/password combination')\n        return redirect(url_for('auth_bp.login_page'))\n    # GET: Serve Log-in page\n    return render_template('login.html',\n                           form=LoginForm(),\n                           title='Log in | Flask-Login Tutorial.',\n                           template='login-page',\n                           body=\"Log in with your User account.\")\n\n\nThis should mostly look the same! our logic is identical up until the point\nwhere we check to see if the user exists. This time, a match results in success\nas opposed to a failure. Continuing, we then use user.check_password()  to check\nthe hashed password we created earlier with user.generate_password_hash(). Both\nof these methods handle the encrypting and decrypting of passwords on their own\n(based on that SECRET_KEY we created earlier) to ensure that nobody (not even\nus) has any business looking at user passwords.\n\nAs with last time, a successful login ends in login_user(user). Our redirect\nlogic is little more sophisticated this time around: instead of always sending\nthe user back to the dashboard, we check for next, which is a parameter stored\nin the query string of the current user. If the user attempted to access our app\nbefore logging in, next  would equal the page they had attempted to reach: this\nallows us wall-off our app from unauthorized users, and then drop users off at\nthe page they attempted to reach before they logged in:\n\nA successful log inIMPORTANT: Login Helpers\nBefore your app can work like the above, we need to finish auth.py  by providing\na few more routes:\n\n@auth_bp.route(\"/logout\")\n@login_required\ndef logout_page():\n    \"\"\"User log-out logic.\"\"\"\n    logout_user()\n    return redirect(url_for('auth_bp.login_page'))\n\n\n@login_manager.user_loader\ndef load_user(user_id):\n    \"\"\"Check if user is logged-in on every page load.\"\"\"\n    if user_id is not None:\n        return User.query.get(user_id)\n    return None\n\n\n@login_manager.unauthorized_handler\ndef unauthorized():\n    \"\"\"Redirect unauthorized users to Login page.\"\"\"\n    flash('You must be logged in to view that page.')\n    return redirect(url_for('auth_bp.login_page'))\n\n\nOur first route, logout_page, handles the logic of users logging out. This will\nsimply end the user's session and redirect them to the login screen.\n\nload_user  is critical for making our app work: before every page load, our app\nmust verify whether or not the user is logged in (or still  logged in after time\nhas elapsed). user_loader  loads users by their unique ID. If a user is\nreturned, this signifies a logged-out user. Otherwise, when None  is returned,\nthe user is logged out.\n\nLastly, we have the unauthorized  route, which uses the unauthorized_handler \ndecorator for dealing with unauthorized users. Any time a user attempts to hit\nour app and is unauthorized, this route will fire.\n\nThe Last Piece: routes.py\nThe last thing we'll cover is how to protect parts of our app from unauthorized\nusers. Here's what we have in routes.py:\n\nimport os\nfrom flask import Blueprint, render_template\nfrom flask_assets import Environment, Bundle\nfrom flask_login import current_user\nfrom flask import current_app as app\nfrom .models import User\nfrom flask_login import login_required\n\n\n# Blueprint Configuration\nmain_bp = Blueprint('main_bp', __name__,\n                    template_folder='templates',\n                    static_folder='static')\nassets = Environment(app)\n\n\n@main_bp.route('/', methods=['GET'])\n@login_required\ndef dashboard():\n    \"\"\"Serve logged in Dashboard.\"\"\"\n    return render_template('dashboard.html',\n                           title='Flask-Login Tutorial.',\n                           template='dashboard-template',\n                           current_user=current_user,\n                           body=\"You are now logged in!\")\n\n\nThe magic here is all contained within the @login_required  decorator. When this\ndecorator is present on a route, the following things happen:\n\n * The @login_manager.user_loader  route we created determines whether or not\n   the user is authorized to view the page (logged in). If the user is logged\n   in, they'll be permitted to view the page.\n * If the user is not logged in, the user will be redirected as per the logic in\n   the route decorated with @login_manager.unauthorized_handler.\n * The name of the route the user attempted to access will be stored in the URL\n   as ?url=[name-of-route]. This what allows next  to work.\n\nThere You Have It\nIf you've made it this far, I commend you for your courage. To reward your\naccomplishments, I've published the source code for this tutorial on Github\n[https://github.com/toddbirchard/flasklogin-tutorial]  for your reference.\nGodspeed, brave adventurer.","html":"<p>We’ve covered a lot of Flask goodness in this series thus far. We fully understand how to structure a sensible application; we can serve up <a href=\"https://hackersandslackers.com/powerful-page-templates-in-flask-with-jinja/\"><strong>complex page templates</strong></a>, and have dived into <a href=\"https://hackersandslackers.com/manage-database-models-with-flask-sqlalchemy/\"><strong>interacting with databases using Flask-SQLAlchemy</strong></a>. For our next challenge, we’re going to need <em>all</em> of the knowledge we've acquired thus far and much, much more. Welcome to the Super Bowl of Flask development. This. Is. Flask-Login.</p><p><a href=\"https://flask-login.readthedocs.io/en/latest/\"><strong>Flask-Login</strong></a> is a dope library which handles all aspects of user management, including vital nuances you might not expect. Some noteworthy features include securing parts of our app behind login walls, encrypting passwords, and handling sessions. Moreover, It plays nicely with other Flask libraries we’re already familiar with: <a href=\"https://hackersandslackers.com/manage-database-models-with-flask-sqlalchemy/\"><strong>Flask-SQLAlchemy</strong></a> to create and fetch accounts, and <a href=\"https://hackersandslackers.com/guide-to-building-forms-in-flask/\"><strong>Flask-WTForms</strong></a> for handling intelligent sign-up &amp; log-in forms. This tutorial assumes you have <em>some </em>working knowledge of these things.</p><p>Flask-Login is shockingly quite easy to use after the initial learning curve... but therein lies the catch. Perhaps I’m not the only one to have noticed, but most Flask-related documentation tends to be, well, God-awful. The community is riddled with helplessly outdated information; if you ever come across <code>flask.ext</code> in a tutorial, it is inherently worthless to anybody developing in 2019. To make matters worse, official Flask-Login documentation contains some artifacts which are just plain wrong. The documentation contradicts itself (I’ll show you what I mean), and offers little to no code examples to speak of. My only hope is that I might save somebody the endless headaches I’ve experienced myself.</p><h2 id=\"structuring-our-application\"><strong>Structuring Our Application</strong></h2><p>Let’s start with installing dependencies. This should give you an idea of what you’re in for:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ pip3 install flask flask-login flask-sqlalchemy psycopg2-binary python-dotenv\n</code></pre>\n<!--kg-card-end: markdown--><p>Sweet. Let’s take this one step at a time, starting with our project file structure:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">flasklogin-tutorial\n├── /login_tutorial\n│   ├── __init__.py\n│   ├── auth.py\n│   ├── forms.py\n│   ├── models.py\n│   ├── routes.py\n│   ├── /static\n│   │   ├── /dist\n│   │   │   ├── /css\n│   │   │   │   ├── account.css\n│   │   │   │   └── dashboard.css\n│   │   │   └── /js\n│   │   │       └── main.min.js\n│   │   └── /src\n│   │       ├── /js\n│   │       │   └── main.js\n│   │       └── /less\n│   │           ├── account.less\n│   │           ├── dashboard.less\n│   │           └── vars.less\n│   └── /templates\n│       ├── dashboard.html\n│       ├── layout.html\n│       ├── login.html\n│       ├── meta.html\n│       ├── scripts.html\n│       └── signup.html\n├── config.py\n├── requirements.txt\n├── setup.py\n├── start.sh\n└── wsgi.py\n</code></pre>\n<!--kg-card-end: markdown--><p>Of course, I wouldn't be a gentleman unless I revealed my <strong>config.py</strong> as well:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\n\n\nclass Config:\n    &quot;&quot;&quot;Set Flask configuration vars from .env file.&quot;&quot;&quot;\n\n    # General Config\n    SECRET_KEY = os.environ.get('SECRET_KEY')\n    FLASK_APP = os.environ.get('FLASK_APP')\n    FLASK_ENV = os.environ.get('FLASK_ENV')\n    FLASK_DEBUG = os.environ.get('FLASK_DEBUG')\n\n    # Database\n    SQLALCHEMY_DATABASE_URI = os.environ.get('SQLALCHEMY_DATABASE_URI')\n    SQLALCHEMY_TRACK_MODIFICATIONS = os.environ.get('SQLALCHEMY_TRACK_MODIFICATIONS')\n</code></pre>\n<!--kg-card-end: markdown--><p>The configuration values live in a <code>.env</code> file, a practice I highly encourage. Of these configuration variables, <strong>SECRET_KEY</strong> is where we should turn our attention. SECRET_KEY is the equivalent of a password used to secure our app; it should be as long, nonsensical, and impossible-to-remember as humanly possible. Seriously: having your secret key compromised is the equivalent of feeding gremlins after midnight.</p><h2 id=\"initializing-flask-login\">Initializing Flask-Login</h2><p>With a standard \"application factory\" app, setting up Flask-Login is no different from other Flask plugins (or whatever they're called now). This makes setting up easy; all we need to do is make sure <strong>Flask-Login</strong> is initialized in <code>__init__.py</code> along with the rest of our plugins:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_login import LoginManager\n\n\ndb = SQLAlchemy()\nlogin_manager = LoginManager()\n\n\ndef create_app():\n    &quot;&quot;&quot;Construct the core application.&quot;&quot;&quot;\n    app = Flask(__name__, instance_relative_config=False)\n\n    # Application Configuration\n    app.config.from_object('config.Config')\n\n    # Initialize Plugins\n    db.init_app(app)\n    login_manager.init_app(app)\n\n    with app.app_context():\n        # Import parts of our application\n        from . import routes\n        from . import login\n        app.register_blueprint(routes.main_bp)\n        app.register_blueprint(login.login_bp)\n\n        # Initialize Global db\n        db.create_all()\n\n        return app\n</code></pre>\n<!--kg-card-end: markdown--><p>In the above example, we're using the minimal number of plug-ins to get logins working: <strong>Flask-SQLAlchemy</strong> and <strong>Flask-Login</strong>.</p><p>To keep our sanity, we're going to separate our login routes from our main application routes and logic. This is why we register a Blueprint called <strong>auth_bp</strong>, imported from a file called <code>auth.py</code>. Our “main” application (AKA anything that isn’t logging in) will instead live in <code>routes.py</code>, in a Blueprint called <strong>main_bp</strong>. We'll come back to these in a moment</p><h2 id=\"creating-a-user-model\">Creating a User Model</h2><p>We'll save our <strong>User</strong> model in <code>models.py</code>. There are a few things to keep in mind when creating models compatible with Flask-Login- the most important being the utilization of <code>UserMixin</code> from the <code>flask_login</code> library. When we inherit our class from <strong>UserMixin,</strong> our model is immediately extended to include all the methods necessary for Flask-Login to work. This is by far the easiest way of creating a User model. I won't bother getting into details of what these methods do, because if you simply begin your class with <code>class User(UserMixin, db.Model):</code>, you genuinely don't need to understand any of it:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from . import db\nfrom flask_login import UserMixin\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\n\nclass User(UserMixin, db.Model):\n    &quot;&quot;&quot;Model for user accounts.&quot;&quot;&quot;\n\n    __tablename__ = 'flasklogin-users'\n\n    id = db.Column(db.Integer,\n                   primary_key=True,\n                   )\n    name = db.Column(db.String,\n                     nullable=False,\n                     unique=False)\n    email = db.Column(db.String(40),\n                      unique=True,\n                      nullable=False\n                      )\n    password = db.Column(db.String(200),\n                         primary_key=False,\n                         unique=False,\n                         nullable=False\n                         )\n    website = db.Column(db.String(60),\n                        index=False,\n                        unique=False,\n                        nullable=True\n                        )\n    created_on = db.Column(db.DateTime,\n                           index=False,\n                           unique=False,\n                           nullable=True\n                           )\n    last_login = db.Column(db.DateTime,\n                           index=False,\n                           unique=False,\n                           nullable=True\n                           )\n\n    def set_password(self, password):\n        &quot;&quot;&quot;Create hashed password.&quot;&quot;&quot;\n        self.password = generate_password_hash(password, method='sha256')\n\n    def check_password(self, password):\n        &quot;&quot;&quot;Check hashed password.&quot;&quot;&quot;\n        return check_password_hash(self.password, password)\n\n    def __repr__(self):\n        return '&lt;User {}&gt;'.format(self.username)\n</code></pre>\n<!--kg-card-end: markdown--><p>The <code>set_password</code> and <code>check_password</code> methods don't necessarily need to live inside our User model, but it's nice to keep related logic bundled together and out of our routes.</p><p>You may notice that our password field explicitly allows 200 characters: this is because our database will be storing hashed passwords. Thus, even if a user's password is 8 characters long, the string in our database will look much different.</p><h2 id=\"creating-log-in-and-sign-up-forms\">Creating Log-in and Sign-up Forms</h2><p>If you're well versed in <strong>WTForms</strong>, our form logic in <strong>forms.py</strong> probably looks as you'd expect. Of course, the constraints we set here are to handle front-end validation only:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from wtforms import Form, StringField, PasswordField, validators, SubmitField\nfrom wtforms.validators import ValidationError, DataRequired, Email, EqualTo, Length, Optional\n\n\nclass SignupForm(Form):\n    &quot;&quot;&quot;User Signup Form.&quot;&quot;&quot;\n\n    name = StringField('Name',\n                        validators=[DataRequired(message=('Enter a fake name or something.'))])\n    email = StringField('Email',\n                        validators=[Length(min=6, message=('Please enter a valid email address.')),\n                                    Email(message=('Please enter a valid email address.')),\n                                    DataRequired(message=('Please enter a valid email address.'))])\n    password = PasswordField('Password',\n                             validators=[DataRequired(message='Please enter a password.'),\n                                         Length(min=6, message=('Please select a stronger password.')),\n                                         EqualTo('confirm', message='Passwords must match')])\n    confirm = PasswordField('Confirm Your Password',)\n    website = StringField('Website',\n                          validators=[Optional()])\n    submit = SubmitField('Register')\n\n\nclass LoginForm(Form):\n    &quot;&quot;&quot;User Login Form.&quot;&quot;&quot;\n\n    email = StringField('Email', validators=[DataRequired('Please enter a valid email address.'),\n                                             Email('Please enter a valid email address.')])\n    password = PasswordField('Password', validators=[DataRequired('Uhh, your password tho?')])\n    submit = SubmitField('Log In')\n</code></pre>\n<!--kg-card-end: markdown--><p>With those out of the way, let's look at how we implement these on the Jinja side.</p><h3 id=\"signup-html\">signup.html</h3><!--kg-card-begin: markdown--><pre><code class=\"language-html\">{% extends &quot;layout.html&quot; %}\n\n{% block pagestyles %}\n    &lt;link href=&quot;{{ url_for('static', filename='dist/css/account.css') }}&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt;\n{% endblock %}\n\n{% block content %}\n  &lt;div class=&quot;formwrapper&quot;&gt;\n    &lt;form method=post&gt;\n      &lt;div class=&quot;logo&quot;&gt;\n        &lt;img src=&quot;{{ url_for('static', filename='dist/img/logo.png') }}&quot;&gt;\n      &lt;/div&gt;\n      {% for message in get_flashed_messages() %}\n        &lt;div class=&quot;alert alert-warning&quot;&gt;\n            &lt;button type=&quot;button&quot; class=&quot;close&quot; data-dismiss=&quot;alert&quot;&gt;&amp;times;&lt;/button&gt;\n            {{ message }}\n        &lt;/div&gt;\n      {% endfor %}\n      &lt;h1&gt;Sign Up&lt;/h1&gt;\n      &lt;div class=&quot;name&quot;&gt;\n        {{ form.name.label }}\n        {{ form.name(placeholder='John Smith') }}\n        {% if form.name.errors %}\n          &lt;ul class=&quot;errors&quot;&gt;\n            {% for error in form.email.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}\n          &lt;/ul&gt;\n        {% endif %}\n      &lt;/div&gt;\n      &lt;div class=&quot;email&quot;&gt;\n        {{ form.email.label }}\n        {{ form.email(placeholder='youremail@example.com') }}\n        {% if form.email.errors %}\n          &lt;ul class=&quot;errors&quot;&gt;\n            {% for error in form.email.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}\n          &lt;/ul&gt;\n        {% endif %}\n      &lt;/div&gt;\n      &lt;div class=&quot;password&quot;&gt;\n        {{ form.password.label }}\n        {{ form.password }}\n        {% if form.password.errors %}\n          &lt;ul class=&quot;errors&quot;&gt;\n            {% for error in form.password.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}\n          &lt;/ul&gt;\n        {% endif %}\n      &lt;/div&gt;\n      &lt;div class=&quot;confirm&quot;&gt;\n        {{ form.confirm.label }}\n        {{ form.confirm }}\n        {% if form.confirm.errors %}\n          &lt;ul class=&quot;errors&quot;&gt;\n            {% for error in form.confirm.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}\n          &lt;/ul&gt;\n        {% endif %}\n      &lt;/div&gt;\n      &lt;div class=&quot;website&quot;&gt;\n        {{ form.website.label }}\n        {{ form.website(placeholder='http://example.com') }}\n      &lt;/div&gt;\n      &lt;div class=&quot;submitbutton&quot;&gt;\n        &lt;input id=&quot;submit&quot; type=&quot;submit&quot; value=&quot;Submit&quot;&gt;\n      &lt;/div&gt;\n    &lt;/form&gt;\n    &lt;div class=&quot;loginsignup&quot;&gt;\n      &lt;span&gt;Already have an account? &lt;a href=&quot;{{ url_for('auth_bp.login_page') }}&quot;&gt;Log in.&lt;/a&gt;&lt;span&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n{% endblock %}\n\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"login-py\">login.py</h3><!--kg-card-begin: markdown--><pre><code class=\"language-html\">{% extends &quot;layout.html&quot; %}\n\n{% block pagestyles %}\n  &lt;link href=&quot;{{ url_for('static', filename='dist/css/account.css') }}&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt;\n{% endblock %}\n\n{% block content %}\n  &lt;div class=&quot;formwrapper&quot;&gt;\n    &lt;form method=post&gt;\n      &lt;div class=&quot;logo&quot;&gt;\n        &lt;img src=&quot;{{ url_for('static', filename='dist/img/logo.png') }}&quot;&gt;\n      &lt;/div&gt;\n      {% for message in get_flashed_messages() %}\n        &lt;div class=&quot;alert alert-warning&quot;&gt;\n            &lt;button type=&quot;button&quot; class=&quot;close&quot; data-dismiss=&quot;alert&quot;&gt;&amp;times;&lt;/button&gt;\n            {{ message }}\n        &lt;/div&gt;\n      {% endfor %}\n      &lt;h1&gt;Log In&lt;/h1&gt;\n      &lt;div class=&quot;email&quot;&gt;\n         {{ form.email.label }}\n         {{ form.email(placeholder='youremail@example.com') }}\n         {% if form.email.errors %}\n           &lt;ul class=&quot;errors&quot;&gt;\n             {% for error in form.email.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}\n           &lt;/ul&gt;\n         {% endif %}\n      &lt;/div&gt;\n      &lt;div class=&quot;password&quot;&gt;\n        {{ form.password.label }}\n        {{ form.password }}\n        {% if form.email.errors %}\n          &lt;ul class=&quot;errors&quot;&gt;\n            {% for error in form.password.errors %}&lt;li&gt;{{ error }}&lt;/li&gt;{% endfor %}\n          &lt;/ul&gt;\n        {% endif %}\n      &lt;/div&gt;\n      &lt;div class=&quot;submitbutton&quot;&gt;\n        &lt;input id=&quot;submit&quot; type=&quot;submit&quot; value=&quot;Submit&quot;&gt;\n      &lt;/div&gt;\n      &lt;div class=&quot;loginsignup&quot;&gt;\n        &lt;span&gt;Don't have an account? &lt;a href=&quot;{{ url_for('auth_bp.signup_page') }}&quot;&gt;Sign up.&lt;/a&gt;&lt;span&gt;\n        &lt;/div&gt;\n    &lt;/form&gt;\n  &lt;/div&gt;\n{% endblock %}\n\n</code></pre>\n<!--kg-card-end: markdown--><p>Excellent: the stage is set to start kicking some ass.</p><h2 id=\"creating-our-login-routes\">Creating Our Login Routes</h2><p>Let us turn our attention to the heart of the logic we'll be writing in <strong>auth.py</strong>:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nfrom flask import redirect, render_template, flash, Blueprint, request, session, url_for\nfrom flask_login import login_required, logout_user, current_user, login_user\nfrom flask import current_app as app\nfrom werkzeug.security import generate_password_hash, check_password_hash\nfrom .forms import LoginForm, SignupForm\nfrom .models import db, User\nfrom . import login_manager\n\n\n# Blueprint Configuration\nauth_bp = Blueprint('auth_bp', __name__,\n                    template_folder='templates',\n                    static_folder='static')\nassets = Environment(app)\n\n\n@auth_bp.route('/login', methods=['GET', 'POST'])\ndef login_page():\n    &quot;&quot;&quot;User login page.&quot;&quot;&quot;\n    # Bypass Login screen if user is logged in\n    if current_user.is_authenticated:\n        return redirect(url_for('main_bp.dashboard'))\n    login_form = LoginForm(request.form)\n    # POST: Create user and redirect them to the app\n    if request.method == 'POST':\n        ...\n    # GET: Serve Log-in page\n    return render_template('login.html',\n                           form=LoginForm(),\n                           title='Log in | Flask-Login Tutorial.',\n                           template='login-page',\n                           body=&quot;Log in with your User account.&quot;)\n\n\n@auth_bp.route('/signup', methods=['GET', 'POST'])\ndef signup_page():\n    &quot;&quot;&quot;User sign-up page.&quot;&quot;&quot;\n    signup_form = SignupForm(request.form)\n    # POST: Sign user in\n    if request.method == 'POST':\n        ...\n    # GET: Serve Sign-up page\n    return render_template('/signup.html',\n                           title='Create an Account | Flask-Login Tutorial.',\n                           form=SignupForm(),\n                           template='signup-page',\n                           body=&quot;Sign up for a user account.&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>Here we find two separate skeleton routes for <strong>Sign up</strong> and <strong>Log in</strong>. Without the authentication logic added quite yet, these routes look almost identical thus far.</p><p>Each time a user visits a page in your app, the corresponding route is sent a <code>request</code> object. This object contains contextual information about the request made by the user, such as the type of request (GET or POST), any form data which was submitted, etc. We leverage this to see whether the user is just arriving at the page for the first time (a GET request), or if they're attempting to sign in (a POST request). The fairly clever takeaway here is that our login pages verify users by making POST requests to themselves: this allows us to keep all logic related to logging in or signing up in a single route.</p><h3 id=\"signing-up\">Signing Up</h3><p>We're able to validate the submitted form by importing the <code>SignupForm</code> class and passing <code>request.form</code> as the form in question. <code>if signup_form.validate()</code> checks the information submitted by the user against all the form's validators. If any of the validators are not met, the user is redirected back to the signup form with error messages present.</p><p>Assuming that our user isn't inept, we can move on with our logic. First, we need to make sure a user with the provided email doesn't already exist:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">...\n\n@auth_bp.route('/signup', methods=['GET', 'POST'])\ndef signup_page():\n    &quot;&quot;&quot;User sign-up page.&quot;&quot;&quot;\n    signup_form = SignupForm(request.form)\n    # POST: Sign user in\n    if request.method == 'POST':\n        if signup_form.validate():\n            # Get Form Fields\n            name = request.form.get('name')\n            email = request.form.get('email')\n            password = request.form.get('password')\n            website = request.form.get('website')\n            existing_user = User.query.filter_by(email=email).first()\n            if existing_user is None:\n                user = User(name=name,\n                            email=email,\n                            password=generate_password_hash(password, method='sha256'),\n                            website=website)\n                db.session.add(user)\n                db.session.commit()\n                login_user(user)\n                return redirect(url_for('main_bp.dashboard'))\n            flash('A user already exists with that email address.')\n            return redirect(url_for('auth_bp.signup_page'))\n    # GET: Serve Sign-up page\n    return render_template('/signup.html',\n                           title='Create an Account | Flask-Login Tutorial.',\n                           form=SignupForm(),\n                           template='signup-page',\n                           body=&quot;Sign up for a user account.&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>If <code>existing_user is None</code>, we're all clear to actually clear to create a new user record. We create an instance of our User model via <code>user = User(...)</code>. We then add the user via standard SQLAlchemy syntax and finally use the imported method <code>login_user()</code> to log the user in.</p><p>If everything goes well, the user will finally be redirected to the main application, which is handled by <code>return redirect(url_for('main_bp.dashboard'))</code>:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/04/signup.gif\" class=\"kg-image\"><figcaption>A successful user log in.</figcaption></figure><!--kg-card-end: image--><p>And here's what will happen if we log out and try to sign up with the same information:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/04/signupfailed.gif\" class=\"kg-image\"><figcaption>Attempting to sign up with an existing email</figcaption></figure><!--kg-card-end: image--><h3 id=\"logging-in\">Logging In</h3><p>Moving on to our login route:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">@auth_bp.route('/login', methods=['GET', 'POST'])\ndef login_page():\n    &quot;&quot;&quot;User login page.&quot;&quot;&quot;\n    # Bypass Login screen if user is logged in\n    if current_user.is_authenticated:\n        return redirect(url_for('main_bp.dashboard'))\n    login_form = LoginForm(request.form)\n    # POST: Create user and redirect them to the app\n    if request.method == 'POST':\n        if login_form.validate():\n            # Get Form Fields\n            email = request.form.get('email')\n            password = request.form.get('password')\n            # Validate Login Attempt\n            user = User.query.filter_by(email=email).first()\n            if user:\n                if user.check_password(password=password):\n                    login_user(user)\n                    next = request.args.get('next')\n                    return redirect(next or url_for('main_bp.dashboard'))\n        flash('Invalid username/password combination')\n        return redirect(url_for('auth_bp.login_page'))\n    # GET: Serve Log-in page\n    return render_template('login.html',\n                           form=LoginForm(),\n                           title='Log in | Flask-Login Tutorial.',\n                           template='login-page',\n                           body=&quot;Log in with your User account.&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>This should mostly look the same! our logic is identical up until the point where we check to see if the user exists. This time, a match results in success as opposed to a failure. Continuing, we then use <code>user.check_password()</code> to check the hashed password we created earlier with <code>user.generate_password_hash()</code>. Both of these methods handle the encrypting and decrypting of passwords on their own (based on that SECRET_KEY we created earlier) to ensure that nobody (not even us) has any business looking at user passwords.</p><p>As with last time, a successful login ends in <code>login_user(user)</code>. Our redirect logic is little more sophisticated this time around: instead of always sending the user back to the dashboard, we check for <code>next</code>, which is a parameter stored in the query string of the current user. If the user attempted to access our app before logging in, <code>next</code> would equal the page they had attempted to reach: this allows us wall-off our app from unauthorized users, and then drop users off at the page they attempted to reach before they logged in:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/04/login.gif\" class=\"kg-image\"><figcaption>A successful log in</figcaption></figure><!--kg-card-end: image--><h3 id=\"important-login-helpers\">IMPORTANT: Login Helpers</h3><p>Before your app can work like the above, we need to finish <strong>auth.py</strong> by providing a few more routes:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">@auth_bp.route(&quot;/logout&quot;)\n@login_required\ndef logout_page():\n    &quot;&quot;&quot;User log-out logic.&quot;&quot;&quot;\n    logout_user()\n    return redirect(url_for('auth_bp.login_page'))\n\n\n@login_manager.user_loader\ndef load_user(user_id):\n    &quot;&quot;&quot;Check if user is logged-in on every page load.&quot;&quot;&quot;\n    if user_id is not None:\n        return User.query.get(user_id)\n    return None\n\n\n@login_manager.unauthorized_handler\ndef unauthorized():\n    &quot;&quot;&quot;Redirect unauthorized users to Login page.&quot;&quot;&quot;\n    flash('You must be logged in to view that page.')\n    return redirect(url_for('auth_bp.login_page'))\n</code></pre>\n<!--kg-card-end: markdown--><p>Our first route, <code>logout_page</code>, handles the logic of users logging out. This will simply end the user's session and redirect them to the login screen.</p><p><code>load_user</code> is critical for making our app work: before every page load, our app must verify whether or not the user is logged in (or <em>still</em> logged in after time has elapsed). <code>user_loader</code> loads users by their unique ID. If a user is returned, this signifies a logged-out user. Otherwise, when <code>None</code> is returned, the user is logged out.</p><p>Lastly, we have the <code>unauthorized</code> route, which uses the <code>unauthorized_handler</code> decorator for dealing with unauthorized users. Any time a user attempts to hit our app and is unauthorized, this route will fire.</p><h2 id=\"the-last-piece-routes-py\">The Last Piece: routes.py</h2><p>The last thing we'll cover is how to protect parts of our app from unauthorized users. Here's what we have in <strong>routes.py</strong>:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nfrom flask import Blueprint, render_template\nfrom flask_assets import Environment, Bundle\nfrom flask_login import current_user\nfrom flask import current_app as app\nfrom .models import User\nfrom flask_login import login_required\n\n\n# Blueprint Configuration\nmain_bp = Blueprint('main_bp', __name__,\n                    template_folder='templates',\n                    static_folder='static')\nassets = Environment(app)\n\n\n@main_bp.route('/', methods=['GET'])\n@login_required\ndef dashboard():\n    &quot;&quot;&quot;Serve logged in Dashboard.&quot;&quot;&quot;\n    return render_template('dashboard.html',\n                           title='Flask-Login Tutorial.',\n                           template='dashboard-template',\n                           current_user=current_user,\n                           body=&quot;You are now logged in!&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>The magic here is all contained within the <code>@login_required</code> decorator. When this decorator is present on a route, the following things happen:</p><ul><li>The <code>@login_manager.user_loader</code> route we created determines whether or not the user is authorized to view the page (logged in). If the user is logged in, they'll be permitted to view the page.</li><li>If the user is not logged in, the user will be redirected as per the logic in the route decorated with <code>@login_manager.unauthorized_handler</code>.</li><li>The name of the route the user attempted to access will be stored in the URL as <code>?url=[name-of-route]</code>. This what allows <code>next</code> to work.</li></ul><h3 id=\"there-you-have-it\">There You Have It</h3><p>If you've made it this far, I commend you for your courage. To reward your accomplishments, I've published the <a href=\"https://github.com/toddbirchard/flasklogin-tutorial\">source code for this tutorial on Github</a> for your reference. Godspeed, brave adventurer.</p>","url":"https://hackersandslackers.com/authenticating-users-with-flask-login/","uuid":"23a82e0a-31e7-49ea-8cc1-fecdd466bcfd","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c779ffbc380a221de39c7cf"}},{"node":{"id":"Ghost__Post__5c82cfe75af763016e85082e","title":"Working With GraphQL Fragments and Mutations","slug":"creating-updating-and-deleting-data-via-graphql-mutations","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/graphql-mutations-1-3.jpg","excerpt":"Make your GraphQL queries more dynamic with Fragments, plus get started with Mutations.","custom_excerpt":"Make your GraphQL queries more dynamic with Fragments, plus get started with Mutations.","created_at_pretty":"08 March, 2019","published_at_pretty":"19 March, 2019","updated_at_pretty":"20 March, 2019","created_at":"2019-03-08T15:26:15.000-05:00","published_at":"2019-03-19T16:34:38.000-04:00","updated_at":"2019-03-20T18:39:27.000-04:00","meta_title":"Working With GraphQL Fragments and Mutations | Hackers and Slackers","meta_description":"Make your GraphQL queries more dynamic with Fragments, plus get started with Mutations.","og_description":"Make your GraphQL queries more dynamic with Fragments, plus get started with Mutations.","og_image":"https://hackersandslackers.com/content/images/2019/03/graphql-mutations-1-3.jpg","og_title":"Working With GraphQL Fragments and Mutations","twitter_description":"Make your GraphQL queries more dynamic with Fragments, plus get started with Mutations.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/graphql-mutations-1-2.jpg","twitter_title":"Working With GraphQL Fragments and Mutations","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"GraphQL","slug":"graphql","description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","feature_image":null,"meta_description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","meta_title":"Build a GraphQL API | Hackers and Slackers","visibility":"public"},"tags":[{"name":"GraphQL","slug":"graphql","description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","feature_image":null,"meta_description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","meta_title":"Build a GraphQL API | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#GraphQL Hype","slug":"graphql-hype","description":"Learn GraphQL syntax and see the reasons why the future of APIs is here to stay. We walk through everything from server/client setup to intricate tricks.","feature_image":"https://hackersandslackers.com/content/images/2019/03/graphqlseries.jpg","meta_description":"Learn GraphQL syntax and see the reasons why the future of APIs is here to stay. We walk through everything from server/client setup to intricate tricks.","meta_title":"GraphQL Hype","visibility":"internal"}],"plaintext":"Last week we encountered a genuine scenario when working with GraphQL clients.\nWhen building real applications consuming data via GraphQL, we usually don't\nknow precisely the query we're going to want to run at runtime. Imagine a user\ncruising through your application, setting preferences, and arriving at core\npieces of functionality under a content which is specific only to them. Say\nwe're building a GrubHub knockoff (we hate profits and love entering\nimpenetrable parts of the market, it's not that uncommon really.) At its core,\nthe information we're serving will always be restaurants; we'll always want to\nreturn things like the restaurant address, name, rating, etc. Because we want\nour app to be intelligent, this means that circumstances in which User 1  makes\na query are vastly different than User 2. Aside from the obvious facts (residing\nin different locales), perhaps there's more metadata we can leverage from User 1\n's longterm app usage, versus User 2  who is a total noob to our knockoff app.\n\nYet, the information we're serving will always be restaurants. There's a core\nquery being reused at the heart of our requests: we need to be dynamic enough to\naccount for the fact that User 1  has checked off 13 different cuisines and\nstrict delivery time windows, whereas User 2  doesn't give a shit. User 2  just\nwants pizza.\n\nThis is where GraphQL Fragments  come in to play. We've already seen how we can\npass variables through our queries to receive contextual data: the next step is\ncreating blocks of reusable code which may never change, which become the\nfoundational building blocks of all future queries.\n\nWhen to Use Fragments\nBack to our JIRA example, I demonstrated precisely the sort of thing one should\nnever do: making more than one GraphQL request to serve a single purpose.\n\nTo recap, we're pulling in JIRA issues to a Kanban board. Our board has 4\ncolumns: one per \"status.\" Here's a god-awful way of hardcoding a query like\nthat:\n\nquery JiraIssuesByStatus($project: String, $status: String) {\n\tbacklog: jiraIssues(where: {project: $project, status: $status}, orderBy: updated_DESC, first: 6) {\n\tkey\n    summary\n    epic_color\n    epic_name\n    status\n    priority_rank\n    priority_url\n    issuetype_name\n    issuetype_url\n    assignee_name\n    assignee_url \n   }\n  todo: jiraIssues(where: {project: $project, status: $status}, orderBy: updated_DESC, first: 6) {\n\tkey\n    summary\n    epic_color\n    epic_name\n    status\n    priority_rank\n    priority_url\n    issuetype_name\n    issuetype_url\n    assignee_name\n    assignee_url \n   }\n  progress: jiraIssues(where: {project: $project, status: $status}, orderBy: updated_DESC, first: 6) {\n\tkey\n    summary\n    epic_color\n    epic_name\n    status\n    priority_rank\n    priority_url\n    issuetype_name\n    issuetype_url\n    assignee_name\n    assignee_url \n   }\n  done: jiraIssues(where: {project: $project, status: $status}, orderBy: updated_DESC, first: 6) {\n\tkey\n    summary\n    epic_color\n    epic_name\n    status\n    priority_rank\n    priority_url\n    issuetype_name\n    issuetype_url\n    assignee_name\n    assignee_url \n   }\n }\n\nSeems like a lot of repetition, yeah? What if we could define chunks of queries\nto be reused to simplify things?\n\n# Write your query or mutation here\nfragment JiraFields on jiraIssue {\n  key\n  summary\n  epic_color\n  epic_name\n  status\n  priority_rank\n  priority_url\n  issuetype_name\n  issuetype_url\n  assignee_name\n  assignee_url \n}\n\nquery JiraIssuesViaFragments($project: String) {\n  backlog: jiraIssues(where: {status: \"Backlog\", project: $project}, orderBy: updated_DESC, first: 6) {\n    ...JiraFields\n  }\n  todo: jiraIssues(where: {status: \"To Do\", project: $project}, orderBy: updated_DESC, first: 6) {\n    ...JiraFields\n  }\n  progress: jiraIssues(where: {status: \"In Progress\", project: $project}, orderBy: updated_DESC, first: 6) {\n    ...JiraFields\n  }\n  done: jiraIssues(where: {status: \"Done\", project: $project}, orderBy: updated_DESC, first: 6) {\n    ...JiraFields\n  }\n}\n\nProgress! Instead of reiterating the fields we want to query for each time, we\nset these once.  We do this by creating a fragment  named JiraFields  (naming\nconventions for fragments are totally up to you- these don't relate to\nanything). To make this easier to visualize, let's just look at the parts:\n\nfragment [GivenNameToYourFragment] on [DatamodelToQuery(SINGULAR)] {\n  [fields] \n}\n\nTake note of [nameOfDatamodelToQuery(SINGULAR)]. Our fragment will refer to data\nmodel in the singular syntax  - this is important.\n\nOur New Query Using a Fragment\nAgain, let's simply what we're looking at:\n\nquery [GivenNameToYourQuery]($project: String) {\n  [subsetName]: [DatamodelToQuery(PLURAL)](where: {status: \"Backlog\", project: $project}) {\n    ...[GivenNameToYourFragment]\n  }\n}\n\n * [subsetName]  is the name of the embedded JSON object to be returned in the\n   response. The naming is up to us.\n * [DatamodelToQuery(PLURAL)]  contrasts the singular data model we specified in\n   our fragment.\n * Finally, ...[GivenNameToYourFragment]  is the syntax for dumping a fragment\n   into a query. Yes, the ...  is intentional.\n\nHere's how we managed to get on:\n\nNow we're talkin'.Implementing On The Client Side\nWith the big picture in hand, this is still all theoretical until we have some\nreal code making real dynamic queries. So which GraphQL client tools should we\nuse?!?! Sweet baby Jesus have mercy, I wish I had a straight answer.\n\nAs we all know, Apollo [https://github.com/apollographql/apollo-client]  is\ncrushing the game with their seemingly endless libraries doing... a lot of\nsimilar stuff? Then there's Prisma\n[https://www.prisma.io/docs/prisma-client/basic-data-access/reading-data-JAVASCRIPT-rsc2/]\n, the new hotshot looking to make a buck. But what about this repo\n[https://github.com/smooth-code/fraql]? It seems totally fine, but why won't it\nfreakin work?! And what about this Lokka [https://github.com/kadirahq/lokka] \nthing? Also, apparently you can just use node-fetch\n[https://www.apollographql.com/docs/react/advanced/fragments.html#fragment-matcher] \n anyway?\n\nFor somebody looking for simplicity, this gets very frustrating. Most clients\nare immediately concerned with integrating with React as fast as possible\n(totally understandable), but a small-town country boy like me just wants to\nstart with simple. I'm just trying to write a god damn tutorial!\n\nAnyway. The GraphQL ecosystem is was it is: we'd be foolish to think anything\nrelated to JavaScript could be cohesive or straightforward. Instead of wrestling\nwith that reality, now's as good a time as ever to move on to the part of\nGraphQL we've failed to speak of: modifying data.\n\nGraphQL Mutation Cheatsheet\nAny form of creating, changing, or deleting data in GraphQL falls under the\numbrella of mutations. The structure is similar to queries, except that we take\ndata in (presumably through variables) and spit out whichever fields you'd like\nto see as a result of that.\n\nCreating Records\nA functioning \"create\" mutation with the resulting response:\n\nSimple enough.And the mutation itself, just in case anybody is copy/pasting out\nthere:\n\nmutation CreateJiraIssue($key: String!, $summary: String!, $status: String!) {\n  createjiraissues(data: {key: $key, status: $status, summary: $summary}) {\n    key\n    status\n    summary\n  }\n}\n\nUpdating Records\nWe can update records (aka nodes) by specifying the target node using where: {},\nand the data to be updated within data: {}\n\nSyntax is just like creating nodes, but with an added where:{} statement.mutation UpdateJIRAIssue($summary: String, $status: String) {\n  updatejiraIssue(data: {status: $status, summary: $summary}, where:{key: \"HACK-10\"}) {\n    key\n    status\n    summary\n    project\n    issuetype_name\n    epic_name\n  }\n}\n\nDeleting Records\nYou can even specify which fields you want returned from the node you're in the\nact of ruthlessly murdering! \n\nAnd with its final breath, the node shouted out \"Hack-9999, Backlog, Test issue\nwith GraphQL\" to please its master once last time.mutation DeleteJiraIssue ($key: String!){\n    deletejiraissues(where: {key: $key}){\n    key\n    status\n    summary\n  }\n}\n\nEnough For Now\nHopefully, I'm not the only one to have bee deceived by the simplicity of\nGraphQL's syntax at first glance. The minimalism of GraphQL queries and\nmutations would lead one to believe that they're simple to understand right off\nthe bat. The problem with that logic is the syntax is so  simplistic, that\nthere's hardly any way of telling what nearly identical queries or mutations\nmight do from one character to the next. Even in JSON, the combination of \nexplicit quotations, key:value relationships, and  comma-separation  affords us\na lot of inferred knowledge we take for granted.\n\nI'm not saying GraphQL is wrong, or painstakingly difficult to pick up, as much\nas it can easily be frustrating to newcomers (and rightfully so). As long as\npeople keep reading, I'll keep posting, so let's chip away at this thing week by\nweek.","html":"<p>Last week we encountered a genuine scenario when working with GraphQL clients. When building real applications consuming data via GraphQL, we usually don't know precisely the query we're going to want to run at runtime. Imagine a user cruising through your application, setting preferences, and arriving at core pieces of functionality under a content which is specific only to them. Say we're building a GrubHub knockoff (we hate profits and love entering impenetrable parts of the market, it's not that uncommon really.) At its core, the information we're serving will always be restaurants; we'll always want to return things like the restaurant address, name, rating, etc. Because we want our app to be intelligent, this means that circumstances in which <strong>User 1</strong> makes a query are vastly different than <strong>User 2</strong>. Aside from the obvious facts (residing in different locales), perhaps there's more metadata we can leverage from <strong>User 1</strong>'s longterm app usage, versus <strong>User 2</strong> who is a total noob to our knockoff app.</p><p>Yet, <em>the information we're serving will always be restaurants</em>. There's a core query being reused at the heart of our requests: we need to be dynamic enough to account for the fact that <strong>User 1</strong> has checked off 13 different cuisines and strict delivery time windows, whereas <strong>User 2</strong> doesn't give a shit. <strong>User 2</strong> just wants pizza.</p><p>This is where GraphQL <em><strong>Fragments</strong></em> come in to play. We've already seen how we can pass variables through our queries to receive contextual data: the next step is creating blocks of reusable code which may never change, which become the foundational building blocks of all future queries.</p><h2 id=\"when-to-use-fragments\">When to Use Fragments</h2><p>Back to our JIRA example, I demonstrated precisely the sort of thing one should never do: making more than one GraphQL request to serve a single purpose.</p><p>To recap, we're pulling in JIRA issues to a Kanban board. Our board has 4 columns: one per \"status.\" Here's a god-awful way of hardcoding a query like that:</p><!--kg-card-begin: code--><pre><code>query JiraIssuesByStatus($project: String, $status: String) {\n\tbacklog: jiraIssues(where: {project: $project, status: $status}, orderBy: updated_DESC, first: 6) {\n\tkey\n    summary\n    epic_color\n    epic_name\n    status\n    priority_rank\n    priority_url\n    issuetype_name\n    issuetype_url\n    assignee_name\n    assignee_url \n   }\n  todo: jiraIssues(where: {project: $project, status: $status}, orderBy: updated_DESC, first: 6) {\n\tkey\n    summary\n    epic_color\n    epic_name\n    status\n    priority_rank\n    priority_url\n    issuetype_name\n    issuetype_url\n    assignee_name\n    assignee_url \n   }\n  progress: jiraIssues(where: {project: $project, status: $status}, orderBy: updated_DESC, first: 6) {\n\tkey\n    summary\n    epic_color\n    epic_name\n    status\n    priority_rank\n    priority_url\n    issuetype_name\n    issuetype_url\n    assignee_name\n    assignee_url \n   }\n  done: jiraIssues(where: {project: $project, status: $status}, orderBy: updated_DESC, first: 6) {\n\tkey\n    summary\n    epic_color\n    epic_name\n    status\n    priority_rank\n    priority_url\n    issuetype_name\n    issuetype_url\n    assignee_name\n    assignee_url \n   }\n }</code></pre><!--kg-card-end: code--><p>Seems like a lot of repetition, yeah? What if we could define chunks of queries to be reused to simplify things?</p><!--kg-card-begin: code--><pre><code># Write your query or mutation here\nfragment JiraFields on jiraIssue {\n  key\n  summary\n  epic_color\n  epic_name\n  status\n  priority_rank\n  priority_url\n  issuetype_name\n  issuetype_url\n  assignee_name\n  assignee_url \n}\n\nquery JiraIssuesViaFragments($project: String) {\n  backlog: jiraIssues(where: {status: \"Backlog\", project: $project}, orderBy: updated_DESC, first: 6) {\n    ...JiraFields\n  }\n  todo: jiraIssues(where: {status: \"To Do\", project: $project}, orderBy: updated_DESC, first: 6) {\n    ...JiraFields\n  }\n  progress: jiraIssues(where: {status: \"In Progress\", project: $project}, orderBy: updated_DESC, first: 6) {\n    ...JiraFields\n  }\n  done: jiraIssues(where: {status: \"Done\", project: $project}, orderBy: updated_DESC, first: 6) {\n    ...JiraFields\n  }\n}</code></pre><!--kg-card-end: code--><p>Progress! Instead of reiterating the fields we want to query for each time, we set these <em>once.</em> We do this by creating a <code>fragment</code> named <strong>JiraFields</strong> (naming conventions for fragments are totally up to you- these don't relate to anything). To make this easier to visualize, let's just look at the parts:</p><!--kg-card-begin: code--><pre><code>fragment [GivenNameToYourFragment] on [DatamodelToQuery(SINGULAR)] {\n  [fields] \n}</code></pre><!--kg-card-end: code--><p>Take note of <code>[nameOfDatamodelToQuery(SINGULAR)]</code>. Our fragment will refer to data model in the singular syntax  - this is important.</p><h3 id=\"our-new-query-using-a-fragment\">Our New Query Using a Fragment</h3><p>Again, let's simply what we're looking at:</p><!--kg-card-begin: code--><pre><code>query [GivenNameToYourQuery]($project: String) {\n  [subsetName]: [DatamodelToQuery(PLURAL)](where: {status: \"Backlog\", project: $project}) {\n    ...[GivenNameToYourFragment]\n  }\n}</code></pre><!--kg-card-end: code--><ul><li><code>[subsetName]</code> is the name of the embedded JSON object to be returned in the response. The naming is up to us.</li><li><code>[DatamodelToQuery(PLURAL)]</code> contrasts the singular data model we specified in our fragment.</li><li>Finally, <code>...[GivenNameToYourFragment]</code> is the syntax for dumping a fragment into a query. Yes, the <code>...</code> is intentional.</li></ul><p>Here's how we managed to get on:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-18-at-8.15.19-AM.png\" class=\"kg-image\"><figcaption>Now we're talkin'.</figcaption></figure><!--kg-card-end: image--><h2 id=\"implementing-on-the-client-side\">Implementing On The Client Side</h2><p>With the big picture in hand, this is still all theoretical until we have some real code making real dynamic queries. So which GraphQL client tools should we use?!?! Sweet baby Jesus have mercy, I wish I had a straight answer.</p><p>As we all know, <a href=\"https://github.com/apollographql/apollo-client\"><strong>Apollo</strong></a> is crushing the game with their seemingly endless libraries doing... a lot of similar stuff? Then there's <strong><a href=\"https://www.prisma.io/docs/prisma-client/basic-data-access/reading-data-JAVASCRIPT-rsc2/\">Prisma</a></strong>, the new hotshot looking to make a buck. But what about <a href=\"https://github.com/smooth-code/fraql\"><strong>this repo</strong></a>? It seems totally fine, but why won't it freakin work?! And what about this <strong><a href=\"https://github.com/kadirahq/lokka\">Lokka</a></strong> thing? Also, <a href=\"https://www.apollographql.com/docs/react/advanced/fragments.html#fragment-matcher\">apparently you can just use <strong>node-fetch</strong></a> anyway?</p><p>For somebody looking for simplicity, this gets very frustrating. Most clients are immediately concerned with integrating with React as fast as possible (totally understandable), but a small-town country boy like me just wants to start with simple. I'm just trying to write a god damn tutorial!</p><p>Anyway. The GraphQL ecosystem is was it is: we'd be foolish to think anything related to JavaScript could be cohesive or straightforward. Instead of wrestling with that reality, now's as good a time as ever to move on to the part of GraphQL we've failed to speak of: modifying data.</p><h2 id=\"graphql-mutation-cheatsheet\">GraphQL Mutation Cheatsheet</h2><p>Any form of creating, changing, or deleting data in GraphQL falls under the umbrella of mutations. The structure is similar to queries, except that we take data in (presumably through variables) and spit out whichever fields you'd like to see as a result of that.</p><h3 id=\"creating-records\">Creating Records</h3><p>A functioning \"create\" mutation with the resulting response:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-08-at-4.02.41-PM.png\" class=\"kg-image\"><figcaption>Simple enough.</figcaption></figure><!--kg-card-end: image--><p>And the mutation itself, just in case anybody is copy/pasting out there:</p><!--kg-card-begin: code--><pre><code>mutation CreateJiraIssue($key: String!, $summary: String!, $status: String!) {\n  createjiraissues(data: {key: $key, status: $status, summary: $summary}) {\n    key\n    status\n    summary\n  }\n}</code></pre><!--kg-card-end: code--><h3 id=\"updating-records\">Updating Records</h3><p>We can update records (aka nodes) by specifying the target node using <code>where: {}</code>, and the data to be updated within <code>data: {}</code></p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-19-at-1.23.28-PM.png\" class=\"kg-image\"><figcaption>Syntax is just like creating nodes, but with an added where:{} statement.</figcaption></figure><!--kg-card-end: image--><!--kg-card-begin: code--><pre><code>mutation UpdateJIRAIssue($summary: String, $status: String) {\n  updatejiraIssue(data: {status: $status, summary: $summary}, where:{key: \"HACK-10\"}) {\n    key\n    status\n    summary\n    project\n    issuetype_name\n    epic_name\n  }\n}</code></pre><!--kg-card-end: code--><h3 id=\"deleting-records\">Deleting Records</h3><p>You can even specify which fields you want returned from the node you're in the act of ruthlessly murdering! </p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-08-at-4.02.20-PM.png\" class=\"kg-image\"><figcaption>And with its final breath, the node shouted out \"Hack-9999, Backlog, Test issue with GraphQL\" to please its master once last time.</figcaption></figure><!--kg-card-end: image--><!--kg-card-begin: code--><pre><code>mutation DeleteJiraIssue ($key: String!){\n    deletejiraissues(where: {key: $key}){\n    key\n    status\n    summary\n  }\n}</code></pre><!--kg-card-end: code--><h3 id=\"enough-for-now\">Enough For Now</h3><p>Hopefully, I'm not the only one to have bee deceived by the simplicity of GraphQL's syntax at first glance. The minimalism of GraphQL queries and mutations would lead one to believe that they're simple to understand right off the bat. The problem with that logic is the syntax is <em>so</em> simplistic, that there's hardly any way of telling what nearly identical queries or mutations might do from one character to the next. Even in JSON, the combination of <strong>explicit quotations</strong>, <strong>key:value relationships</strong>, and<strong> comma-separation</strong> affords us a lot of inferred knowledge we take for granted.</p><p>I'm not saying GraphQL is wrong, or painstakingly difficult to pick up, as much as it can easily be frustrating to newcomers (and rightfully so). As long as people keep reading, I'll keep posting, so let's chip away at this thing week by week.</p><p></p>","url":"https://hackersandslackers.com/creating-updating-and-deleting-data-via-graphql-mutations/","uuid":"a042692b-1812-49a1-a2fb-c0bd97973edf","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c82cfe75af763016e85082e"}},{"node":{"id":"Ghost__Post__5c85a8da181da30210ceca9d","title":"Serve Docker Containers With A Custom Domain and SSL","slug":"serve-docker-containers-with-custom-dns-and-ssl","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/caddy.jpg","excerpt":"Do even less work to deploy your Docker apps to production.","custom_excerpt":"Do even less work to deploy your Docker apps to production.","created_at_pretty":"11 March, 2019","published_at_pretty":"11 March, 2019","updated_at_pretty":"09 April, 2019","created_at":"2019-03-10T20:16:26.000-04:00","published_at":"2019-03-11T06:15:00.000-04:00","updated_at":"2019-04-09T15:05:49.000-04:00","meta_title":"Serve Docker Containers With A Domain and SSL | Hackers and Slackers","meta_description":"Do even less work to deploy your Docker apps to production. Caddy is a Fast, cross-platform HTTP/2 web server with automatic SSL.","og_description":"Do even less work to deploy your Docker apps to production. Caddy is a Fast, cross-platform HTTP/2 web server with automatic SSL.","og_image":"https://hackersandslackers.com/content/images/2019/03/caddy.jpg","og_title":"Serve Docker Containers With A Custom Domain and SSL","twitter_description":"Do even less work to deploy your Docker apps to production. Caddy is a Fast, cross-platform HTTP/2 web server with automatic SSL.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/caddy.jpg","twitter_title":"Serve Docker Containers With A Custom Domain and SSL","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},"tags":[{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"The past few years of software development and architecture has witnessed\nmultiple revolutions. The rise of containers, unruly package management\necosystems, and one-click-deployments holds an unspoken narrative: most people\nprobably don’t care about how  things work beneath the top layer. Sure,\nadvancements in application infrastructure has undoubtedly made our lives\neasier. I suppose I find this lack of curiosity and unwillingness to dig deeper\ninto the innards, an unrelatable trait. Yet I digress.\n\nI’ve never found web server configurations to be particularly difficult, but\napparently most consider this enough of a nuisance to make something even easier\nto use. That’s where I came across Caddy [https://caddyserver.com/].\n\nCaddy  is a web server and free SSL service in which most of the actual work\nhappens via their download GUI [https://caddyserver.com/download]. It’s great.\nEven though I never expected us to reach a place where apt install nginx  and \napt install certbot  is considered too much of a burden, it only took a few\nminutes of wrestling with a Docker container running on a VPS that I realized\nthere was a better way.\n\nServe Anything With Caddy\nIn my particular example, the Docker container I was running produced an API\nendpoint. For some reason, this service forcefully insists that this endpoint is\nyour machine’s localhost, or it simply won’t work. While scoffing at vanity URLs\nfor APIs is fine, what isn’t  fine is you can’t assign an SSL certificate to an\nIP address. That means whichever app consuming your API will fail because your\napp surely has a cert of its own, and HTTPS > HTTP  API calls just aren’t gonna\nhappen.\n\nCaddy trivializes SSL certs to the point where you might not notice you’ve\nacquired one. Any host specified in a Caddyfile  immediately receives an SSL\ncert, but we'll get to that in a moment.\n\nCaddy’s download page is like a shopping cart for which things you might want\nyour web server to do. Proxies, CORS, you name it: just put it in the (free)\nshopping cart:\n\nSoon we won't even have to write code at all!Selecting your platform, plugins, and license  will provide you with a\nconvenient one-liner which downloads your exact package, unpacks, and installs\nit on your machine. For example, a Caddy installation for Linux with no bells or\nwhistles looks like this:\n\ncurl https://getcaddy.com | bash\n\n\nThis will install Caddy, which leaves only some trivial configuration before\nyou're up and running.\n\nConfiguring Your Caddyfile\nCaddy is configured via what is simply named Caddyfile, a file which can\nconveniently live in your project folder, as opposed to a distant land called \n/etc/nginx/sites-enabled. Go ahead and create your Caddy file.\n\nThe first line in our Caddyfile config is both simple and magic. It contains\nmerely the domain you’re intending to listen on, such something like \nhackersandslackers.com.  No matter what else happens in your config, the mere\nexistence of this line will generate an SSL cert for you when you run caddy.\n\nYou can serve content via any method that Nginx  or Apache  can, albeit much\neasier. A few examples:\n\n * root path/to/project  points your DNS to serve HTTP out a root folder.\n * websocket path/to/socket command  will serve an application via the specified\n   websocket.\n * rewrite [/original/folder/path] [/new/folder/path]  will reroute internal\n   requests made to origin A to origin B,\n\nThe point I’m trying to make here is that no matter what your desired\nconfiguration might be, it’s dead simple and likely won’t exceed more than 5\nlines.\n\nServing Our Docker Container via Proxy\nIf you’re using Node, chances are you’re going for a proxy configuration. In my\ncase I had no choice: I somehow needed to interact with an HTTP  url, while also\npassing the authentication headers necessary to make the app work. Luckily, this\nis trivial:\n\nexample.com\n\nproxy example.com proxy example.com localhost:4466/my_api/prod {\n transparent\n} \n\nerrors proxieserrors.log\n\nYes, really. Our proxy  block simply creates a proxy from  example.com, and\nserves localhost:4466/my_api/prod.\n\ntransparent  is a magic phrase which passes through all our headers to the\ntarget. It's shorthand for the following:\n\nheader_upstream Host {host}\nheader_upstream X-Real-IP {remote}\nheader_upstream X-Forwarded-For {remote}\nheader_upstream X-Forwarded-Port {server_port}\nheader_upstream X-Forwarded-Proto {scheme}\n\nDespite our Docker app requiring an authentication token to work hitting \nexample.com  will still result in a working endpoint thanks to the headers we're\npushing upstream.\n\nI even went the extra mile to include errors proxieserrors.log  as a way to log\nerrors. I didn't even need to. I only even got two errors total: Caddy works\nobnoxiously well.\n\nIn case you need anything more, I’d recommend reading the documentation\n[https://caddyserver.com/docs/proxy]. Even then, this basically summarizes the\nthings you can potentially configure:\n\nproxy from to... {\n\tpolicy name [value]\n\tfail_timeout duration\n\tmax_fails integer\n\tmax_conns in≈teger\n\ttry_duration duration\n\ttry_interval duration\n\thealth_check path\n\thealth_check_port port\n\thealth_check_interval interval_duration\n\thealth_check_timeout timeout_duration\n\tfallback_delay delay_duration\n\theader_upstream name value\n\theader_downstream name value\n\tkeepalive number\n\ttimeout duration\n\twithout prefix\n\texcept ignored_paths...\n\tupstream to\n\tca_certificates certs...\n\tinsecure_skip_verify\n\tpreset\n}\n\nRun Caddy And Never Worry About It Again\nSaving your Caddyfile  and running $ caddy  will issue your cert, and run Caddy\nas a process. This will result in a dialogue letting  you know that Caddy is\nlistening on both ports 80  and 443.\n\nCaddy won’t run as a background process by default. To do this, simply use the\ncommand $ nohup caddy &  and you're good to go.","html":"<p>The past few years of software development and architecture has witnessed multiple revolutions. The rise of containers, unruly package management ecosystems, and one-click-deployments holds an unspoken narrative: most people probably don’t care about <em>how</em> things work beneath the top layer. Sure, advancements in application infrastructure has undoubtedly made our lives easier. I suppose I find this lack of curiosity and unwillingness to dig deeper into the innards, an unrelatable trait. Yet I digress.</p><p>I’ve never found web server configurations to be particularly difficult, but apparently most consider this enough of a nuisance to make something even easier to use. That’s where I came across <a href=\"https://caddyserver.com/\" rel=\"noopener\">Caddy</a>.</p><p><strong>Caddy</strong> is a web server and free SSL service in which most of the actual work happens via their <a href=\"https://caddyserver.com/download\" rel=\"noopener\">download GUI</a>. It’s great. Even though I never expected us to reach a place where <code>apt install nginx</code> and <code>apt install certbot</code> is considered too much of a burden, it only took a few minutes of wrestling with a Docker container running on a VPS that I realized there was a better way.</p><h2 id=\"serve-anything-with-caddy\">Serve Anything With Caddy</h2><p>In my particular example, the Docker container I was running produced an API endpoint. For some reason, this service forcefully insists that this endpoint is your machine’s <em>localhost</em>, or it simply won’t work. While scoffing at vanity URLs for APIs is fine, what <em>isn’t</em> fine is <em>you can’t assign an SSL certificate to an IP address. </em>That means whichever app consuming your API will fail because your app <em>surely </em>has a cert of its own, and <strong>HTTPS &gt; HTTP</strong> API calls just aren’t gonna happen.</p><p>Caddy trivializes SSL certs to the point where you might not notice you’ve acquired one. Any host specified in a <code>Caddyfile</code> immediately receives an SSL cert, but we'll get to that in a moment.</p><p>Caddy’s download page is like a shopping cart for which things you might want your web server to do. Proxies, CORS, you name it: just put it in the (free) shopping cart:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/caddy-download.png\" class=\"kg-image\"><figcaption>Soon we won't even have to write code at all!</figcaption></figure><!--kg-card-end: image--><p>Selecting your <strong>platform</strong>, <strong>plugins</strong>, and <strong>license</strong> will provide you with a convenient one-liner which downloads your exact package, unpacks, and installs it on your machine. For example, a Caddy installation for Linux with no bells or whistles looks like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">curl https://getcaddy.com | bash\n</code></pre>\n<!--kg-card-end: markdown--><p>This will install Caddy, which leaves only some trivial configuration before you're up and running.</p><h2 id=\"configuring-your-caddyfile\">Configuring Your Caddyfile</h2><p>Caddy is configured via what is simply named <code>Caddyfile</code>, a file which can conveniently live in your project folder, as opposed to a distant land called <code>/etc/nginx/sites-enabled</code>. Go ahead and create your Caddy file.</p><p>The first line in our Caddyfile config is both simple and magic. It contains merely the domain you’re intending to listen on, such something like <em>hackersandslackers.com.</em> No matter what else happens in your config, the mere existence of this line will generate an SSL cert for you when you run caddy.</p><p>You can serve content via any method that <strong>Nginx</strong> or <strong>Apache</strong> can, albeit much easier. A few examples:</p><ul><li><code>root path/to/project</code> points your DNS to serve HTTP out a root folder.</li><li><code>websocket path/to/socket command</code> will serve an application via the specified websocket.</li><li><code>rewrite [/original/folder/path] [/new/folder/path]</code> will reroute internal requests made to origin A to origin B,</li></ul><p>The point I’m trying to make here is that no matter what your desired configuration might be, it’s dead simple and likely won’t exceed more than 5 lines.</p><h2 id=\"serving-our-docker-container-via-proxy\">Serving Our Docker Container via Proxy</h2><p>If you’re using Node, chances are you’re going for a proxy configuration. In my case I had no choice: I somehow needed to interact with an <strong>HTTP</strong> url, while also passing the authentication headers necessary to make the app work. Luckily, this is trivial:</p><!--kg-card-begin: code--><pre><code>example.com\n\nproxy example.com proxy example.com localhost:4466/my_api/prod {\n transparent\n} \n\nerrors proxieserrors.log</code></pre><!--kg-card-end: code--><p>Yes, really. Our <code>proxy</code> block simply creates a proxy <em>from</em> <code>example.com</code>, and serves <code>localhost:4466/my_api/prod</code>.</p><p><code>transparent</code> is a magic phrase which passes through all our headers to the target. It's shorthand for the following:</p><!--kg-card-begin: code--><pre><code>header_upstream Host {host}\nheader_upstream X-Real-IP {remote}\nheader_upstream X-Forwarded-For {remote}\nheader_upstream X-Forwarded-Port {server_port}\nheader_upstream X-Forwarded-Proto {scheme}</code></pre><!--kg-card-end: code--><p>Despite our Docker app requiring an authentication token to work hitting <code>example.com</code> will still result in a working endpoint thanks to the headers we're pushing upstream.</p><p>I even went the extra mile to include <code>errors proxieserrors.log</code> as a way to log errors. I didn't even need to. I only even got two errors total: Caddy works obnoxiously well.</p><p>In case you need anything more, I’d recommend reading <a href=\"https://caddyserver.com/docs/proxy\" rel=\"noopener\">the documentation</a>. Even then, this basically summarizes the things you can potentially configure:</p><!--kg-card-begin: code--><pre><code>proxy from to... {\n\tpolicy name [value]\n\tfail_timeout duration\n\tmax_fails integer\n\tmax_conns in≈teger\n\ttry_duration duration\n\ttry_interval duration\n\thealth_check path\n\thealth_check_port port\n\thealth_check_interval interval_duration\n\thealth_check_timeout timeout_duration\n\tfallback_delay delay_duration\n\theader_upstream name value\n\theader_downstream name value\n\tkeepalive number\n\ttimeout duration\n\twithout prefix\n\texcept ignored_paths...\n\tupstream to\n\tca_certificates certs...\n\tinsecure_skip_verify\n\tpreset\n}</code></pre><!--kg-card-end: code--><h2 id=\"run-caddy-and-never-worry-about-it-again\">Run Caddy And Never Worry About It Again</h2><p>Saving your <code>Caddyfile</code> and running <code>$ caddy</code> will issue your cert, and run Caddy as a process. This will result in a dialogue letting  you know that Caddy is listening on both ports <code>80</code> and <code>443</code>.</p><p>Caddy won’t run as a background process by default. To do this, simply use the command <code>$ nohup caddy &amp;</code> and you're good to go.</p>","url":"https://hackersandslackers.com/serve-docker-containers-with-custom-dns-and-ssl/","uuid":"5b609f96-d76d-4b8b-943e-d470ee414d97","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c85a8da181da30210ceca9d"}},{"node":{"id":"Ghost__Post__5c838ee05af763016e85085b","title":"Building a Client For Your GraphQL API","slug":"interacting-with-your-graphql-api","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/graphqlclient.jpg","excerpt":"Now that we have an understanding of GraphQL queries and API setup, it's time to get that data.","custom_excerpt":"Now that we have an understanding of GraphQL queries and API setup, it's time to get that data.","created_at_pretty":"09 March, 2019","published_at_pretty":"09 March, 2019","updated_at_pretty":"18 March, 2019","created_at":"2019-03-09T05:01:04.000-05:00","published_at":"2019-03-09T15:43:14.000-05:00","updated_at":"2019-03-18T03:10:39.000-04:00","meta_title":"Building a Client For Your GraphQL API | Hackers and Slackers","meta_description":"Now that we have an understanding of GraphQL queries and API setup, it's time to get that data.","og_description":"Now that we have an understanding of GraphQL queries and API setup, it's time to get that data.","og_image":"https://hackersandslackers.com/content/images/2019/03/graphqlclient.jpg","og_title":"Building a Client For Your GraphQL API","twitter_description":"Now that we have an understanding of GraphQL queries and API setup, it's time to get that data.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/graphqlclient.jpg","twitter_title":"Building a Client For Your GraphQL API","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"GraphQL","slug":"graphql","description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","feature_image":null,"meta_description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","meta_title":"Build a GraphQL API | Hackers and Slackers","visibility":"public"},"tags":[{"name":"GraphQL","slug":"graphql","description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","feature_image":null,"meta_description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","meta_title":"Build a GraphQL API | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"#GraphQL Hype","slug":"graphql-hype","description":"Learn GraphQL syntax and see the reasons why the future of APIs is here to stay. We walk through everything from server/client setup to intricate tricks.","feature_image":"https://hackersandslackers.com/content/images/2019/03/graphqlseries.jpg","meta_description":"Learn GraphQL syntax and see the reasons why the future of APIs is here to stay. We walk through everything from server/client setup to intricate tricks.","meta_title":"GraphQL Hype","visibility":"internal"}],"plaintext":"If you had the pleasure of joining us last time, we had just completed a crash\ncourse in structuring GraphQL Queries\n[https://hackersandslackers.com/writing-your-first-graphql-queries/]. As much we\nall love studying abstract queries within the confines of a playground\nenvironment, the only real way to learn anything to overzealously attempt to\nbuild something way out of our skill level. Thus, we're going to shift gears and\nactually make something  with all the dry technical knowledge we've accumulated\nso far. Hooray!\n\nData Gone Wild: Exposing Your GraphQL Endpoint\nIf you're following along with Prisma as your GraphQL service, the endpoint for\nyour API defaults to [your_ip_address]:4466. What's more, you've probably\nnoticed it is publicly accessible. THIS IS VERY BAD.  Your server has full\nread/write access to whichever database you configured with it... if anybody\nfinds your endpoint hanging out in a Github commit somewhere, you've just lost\nyour database and everything in it. You're pretty much Equifax, and you should\nfeel bad.\n\nPrisma has a straightforward solution. While SSHed into\nwherever-you-set-up-your-server, check out the prisma.yaml  file which was\ngenerated as a result of when we first started getting set up. You know, this\ndirectory:\n\nmy-prisma\n├── datamodel.prisma\n├── docker-compose.yml\n├── generated\n│   └── prisma-client\n│       ├── index.ts\n│       └── prisma-schema.ts\n└── prisma.yml\n\n\nprisma.yaml  seems inglorious, but that's because it's hiding a secret; or\nshould I say, it's not  hiding a secret! Hah! You know, like, credentials. For\nconnecting to your API. Anyway. Add one more line to your prisma.yaml  file\nwhich defines a secret, like this:\n\nendpoint: http://localhost:4466\ndatamodel: datamodel.prisma\nsecret: HIIHGUTFTUY$VK$G$YI&TUYCUY$DT$\n\ngenerate:\n  - generator: typescript-client\n    output: ./generated/prisma-client/\n\n\nWith your secret stashed away safely, the Prisma CLI can now use this secret to\ncreate an authentication token: that  will be the value you need to actually\nconnect to your Prisma server remotely.\n\nType prisma token  in your project directory to get the work of art:\n\n$ prisma token\neyJhbGciOiJIUzI1NiIsInUYGFUJGSFKHFGSJFKSFJKSFGJdfSwiaWF0IjoxNTUyMTYwMDQ5LCJleHAiOjE1NTI3NjQ4NDl9.xrubUg_dRc93bqqR4f6jGt-KvQRS2Xq6lRi0a0uw-C0\n\n\nNice; believe it or not, that was the \"hard\" part.\n\nEXTRA CREDIT: Assign a DNS Record and Apply a Security Certificate\nIf really want to, you could already query against your insecure IP address and\nstart receiving some information. That said, making HTTP  requests as such from \nHTTPS  origins will fail. Not only that, but you kind of look shitty for not\neven bothering to name your API, much less apply a free SSL certificate. For the\neasiest possible way to do this, see our post on using Caddy as an HTTP server\n[https://hackersandslackers.com/serve-docker-containers-with-custom-dns-and-ssl/]\n.\n\nBuilding a Javascript Client to Consume Our API\nWith our API nice and secure, we can start hitting this baby from wherever we\nwant... as long as it's a Node app. We'll start by requiring two packages:\n\nconst { GraphQLClient } = require('graphql-request')\nconst { dotenv } = require('dotenv').config()\n\n\nGraphQLClient  is the magic behind our client- it's everything. It also happens\nto be very similar to existing npm  libraries for making requests, such as \nnode-fetch [https://hackersandslackers.com/making-api-requests-with-nodejs/].\n\nWe'll also leverage the dotenv  library to make sure our API endpoint  and \nBearer token  stay out of source code. Try not to be Equifax whenever possible. \ndotenv  allows us to load sensitive values from a .env  file. Just in case you\nneed a refresher, that file should look like this:\n\nNODE_ENV=Production\nENDPOINT=https://yourapiendpoint.com\nAUTH=Bearer eyJhbGciOBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHGUYFIERIBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHZl-UGnMrOk3w\n\nInitialize The GraphQL Client\nI like to set up a one-time client for our API that we can go back and reuse if\nneed be. After pulling the API endpoint and token from our .env  file, setting\nup the client is easy:\n\nconst { GraphQLClient } = require('graphql-request')\nconst { dotenv } = require('dotenv').config()\n\nconst endpoint = process.env.ENDPOINT;\nconst token = process.env.AUTH;\n\n// Initialize GraphQL Client\nconst client = new GraphQLClient(endpoint, {\n  headers: {\n    Authorization: token\n  }\n});\n\n\nEMERGENCY MEETING: EVERYBODY HUDDLE UP\nOh I'm sorry, were you focusing on development? Unfortunately for you, I spent 8\nyears as a product manager, and I love  stopping everything suddenly to call\nemergency meetings.\n\nReal talk though, let's think back to the JIRA Kanban board example we've been\nusing for the last two posts. If you recall, we're going to write a query that\npopulates a 4-column Kanban board. The board represents a project (in this case,\n Hackers and Slackers) and each column represents a status  of ticket, like\nthis:\n\nconst statuses = ['Backlog', 'To Do', 'In Progress', 'Done'];\n\n\nWe've previously established that GraphQL queries are friendly to drop-in\nvariables. Let's use this to build some logic into our client, as opposed to\nhardcoding a massive query, which is really just the same 4 queries stitched\ntogether. Here's what a query to populate a single JIRA column looks like:\n\n// Structured query\nconst query = `\n    query JiraIssuesByStatus($project: String, $status: String) {\n         jiraIssues(where: {project: $project, status: $status}, \n         orderBy: timestamp_DESC, \n         first: 6) {\n            key\n            summary\n            epic\n            status\n            project\n            priority\n            issuetype\n            timestamp\n            }\n         }\n       `\n\nWe're passing both the project  and the issue status  as variables to our query.\nWe can make things a bit dynamic here by looping through our statuses and\nexecuting this query four times: each time resulting in a callback filling the\nappropriate columns with JIRA issues.\n\nThis approach is certainly less clunky and more dynamic than a hardcoded query.\nThat said, this still  isn't the best solution. Remember: the strength of\nGraphQL is the ability to get obscene amounts of data across complex\nrelationships in a single call. The best approach here would probably be to\nbuild the query string itself dynamically using fragments,  which we'll review\nin the next post.Game On: Our Client in Action\nconst { GraphQLClient } = require('graphql-request')\nconst { dotenv } = require('dotenv').config()\n\nconst endpoint = process.env.ENDPOINT;\nconst token = process.env.AUTH;\n\n// Initialize GraphQL Client\nconst client = new GraphQLClient(endpoint, {\n  headers: {\n    Authorization: token\n  }\n});\n\n// Structured query\nconst query = `\n   query JiraIssuesByStatus($project: String, $status: String) {\n      jiraIssues(where: {project: $project, status: $status}, orderBy: timestamp_DESC, first: 6) {\n         key\n         summary\n         epic\n         status\n         project\n         priority\n         issuetype\n         timestamp\n        }\n      }\n    `;\n\n// All Possible Issue Statuses\nconst statuses = ['Backlog', 'To Do', 'In Progress', 'Done'];\n\n// Execute a query per issue status\nfor(var i = 0; i < statuses.length; i++){\n  var variables = {\n    project: \"Hackers and Slackers\",\n    status: statuses[i]\n  }\n\n  client.request(query, variables).then((data) => {\n    console.log(data)\n  }).catch(err => {\n    console.log(err.response.errors) // GraphQL response errors\n    console.log(err.response.data) // Response data if available\n  });\n}\n\n\nWorks like a charm. We only had one endpoint, only had to set one header, and\ndidn't spend any time reading through hundreds of pages of documentation to\nfigure out which combination of REST API endpoint, parameters, and methods\nactually get us what we want. It's almost as if we're writing SQL now, except...\nit looks a lot more like... NoSQL. Thanks for the inspiration, MongoDB! Hope\nthat whole selling-open-source-software  thing works out.\n\nOh, and of course, here were the results of my query:\n\n{ jiraIssues:\n   [ { priority: 'Medium',\n       timestamp: 1550194791,\n       project: 'Hackers and Slackers',\n       key: 'HACK-778',\n       epic: 'Code snippets',\n       status: 'Backlog',\n       issuetype: 'Task',\n       summary: 'HLJS: set indentation level' },\n     { priority: 'Medium',\n       timestamp: 1550194782,\n\n       project: 'Hackers and Slackers',\n       key: 'HACK-555',\n       epic: 'Optimization',\n       status: 'Backlog',\n       issuetype: 'Task',\n       summary: 'Minify Babel' },\n     { priority: 'Medium',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-785',\n       epic: 'New Post',\n       status: 'Backlog',\n       issuetype: 'Task',\n       summary: 'Unix commands for data' },\n     { priority: 'Medium',\n       timestamp: 1550016000,\n       project: 'Hackers and Slackers',\n       key: 'HACK-251',\n       epic: 'New Post',\n       status: 'Backlog',\n       issuetype: 'Content',\n       summary: 'Using Ghost\\'s content filtering' },\n     { priority: 'Medium',\n       timestamp: 1550016000,\n       project: 'Hackers and Slackers',\n       key: 'HACK-302',\n       epic: 'Widgets',\n       status: 'Backlog',\n       issuetype: 'Integration',\n       summary: 'Discord channel signups ' },\n     { priority: 'Low',\n       timestamp: 1550016000,\n       project: 'Hackers and Slackers',\n       key: 'HACK-336',\n       epic: 'New Post',\n       status: 'Backlog',\n       issuetype: 'Content',\n       summary: 'Linux: Configuring your server to send SMTP emails' } ] }\n{ jiraIssues:\n   [ { priority: 'Medium',\n       timestamp: 1550224412,\n       project: 'Hackers and Slackers',\n       key: 'HACK-769',\n       epic: 'Projects Page',\n       status: 'Done',\n       issuetype: 'Bug',\n       summary: 'Fix projects dropdown' },\n     { priority: 'High',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-710',\n       epic: 'Lynx',\n       status: 'Done',\n       issuetype: 'Task',\n       summary: 'Implement auto text synopsis for Lynx posts' },\n     { priority: 'Medium',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-777',\n       epic: 'Creative',\n       status: 'Done',\n       issuetype: 'Task',\n       summary: 'Redesign footer to be informative; link-heavy' },\n     { priority: 'Highest',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-779',\n       epic: 'Urgent',\n       status: 'Done',\n       issuetype: 'Task',\n       summary: 'Changeover from cloudinary to DO' },\n     { priority: 'Medium',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-780',\n       epic: 'Creative',\n       status: 'Done',\n       issuetype: 'Task',\n       summary: 'Make mobile post title bold' },\n     { priority: 'High',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-781',\n       epic: 'Urgent',\n       status: 'Done',\n       issuetype: 'Bug',\n       summary: 'This post consistently doesn’t work on mobile' } ] }\n{ jiraIssues:\n   [ { priority: 'Low',\n       timestamp: 1550223282,\n       project: 'Hackers and Slackers',\n       key: 'HACK-782',\n       epic: 'Widgets',\n       status: 'To Do',\n       issuetype: 'Task',\n       summary:\n        'Lynx: on mobile, instead of full link, show domainname.com/...' },\n     { priority: 'High',\n       timestamp: 1550194799,\n       project: 'Hackers and Slackers',\n       key: 'HACK-774',\n       epic: 'Widgets',\n       status: 'To Do',\n       issuetype: 'Task',\n       summary: 'New Widget: Next/Previous article in series' },\n     { priority: 'Low',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-395',\n       epic: 'Page Templates',\n       status: 'To Do',\n       issuetype: 'Task',\n       summary: 'Create fallback image for posts with no image' },\n     { priority: 'High',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-756',\n       epic: 'Newsletter',\n       status: 'To Do',\n       issuetype: 'Major Functionality',\n       summary: 'Automate newsletter' },\n     { priority: 'Low',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-775',\n       epic: 'Projects Page',\n       status: 'To Do',\n       issuetype: 'Data & Analytics',\n       summary: 'Update issuetype icons' },\n     { priority: 'Lowest',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-776',\n       epic: 'Projects Page',\n       status: 'To Do',\n       issuetype: 'Task',\n       summary: 'Add fork icon to repos' } ] }\n{ jiraIssues:\n   [ { priority: 'High',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-784',\n       epic: 'New Post',\n       status: 'In Progress',\n       issuetype: 'Content',\n       summary: 'Welcome to SQL part1' } ] }\n\n\nBefore we say \"GG, 2ez, 1v1 me,\" know that we're  only getting started \nuncovering what GraphQL can do. It's not all just creating and deleting records\neither; we're talking full-on database JOIN equivalent type shit here. Stick\naround folks, the bandwagon's just getting warmed up.","html":"<p>If you had the pleasure of joining us last time, we had just completed a <a href=\"https://hackersandslackers.com/writing-your-first-graphql-queries/\">crash course in structuring GraphQL Queries</a>. As much we all love studying abstract queries within the confines of a playground environment, the only real way to learn anything to overzealously attempt to build something way out of our skill level. Thus, we're going to shift gears and actually <em>make something</em> with all the dry technical knowledge we've accumulated so far. Hooray!</p><h2 id=\"data-gone-wild-exposing-your-graphql-endpoint\">Data Gone Wild: Exposing Your GraphQL Endpoint</h2><p>If you're following along with Prisma as your GraphQL service, the endpoint for your API defaults to <code>[your_ip_address]:4466</code>. What's more, you've probably noticed it is publicly accessible. <strong>THIS IS VERY BAD.</strong> Your server has full read/write access to whichever database you configured with it... if anybody finds your endpoint hanging out in a Github commit somewhere, you've just lost your database and everything in it. You're pretty much Equifax, and you should feel bad.</p><p>Prisma has a straightforward solution. While SSHed into wherever-you-set-up-your-server, check out the <code>prisma.yaml</code> file which was generated as a result of when we first started getting set up. You know, this directory:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">my-prisma\n├── datamodel.prisma\n├── docker-compose.yml\n├── generated\n│   └── prisma-client\n│       ├── index.ts\n│       └── prisma-schema.ts\n└── prisma.yml\n</code></pre>\n<!--kg-card-end: markdown--><p><code>prisma.yaml</code> seems inglorious, but that's because it's hiding a secret; or should I say, it's <em>not</em> hiding a secret! Hah! You know, like, credentials. For connecting to your API. Anyway. Add one more line to your <code>prisma.yaml</code> file which defines a <code>secret</code>, like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-yaml\">endpoint: http://localhost:4466\ndatamodel: datamodel.prisma\nsecret: HIIHGUTFTUY$VK$G$YI&amp;TUYCUY$DT$\n\ngenerate:\n  - generator: typescript-client\n    output: ./generated/prisma-client/\n</code></pre>\n<!--kg-card-end: markdown--><p>With your secret stashed away safely, the <strong>Prisma CLI </strong>can now use this secret to create an authentication token: <em>that</em> will be the value you need to actually connect to your Prisma server remotely.</p><p>Type <code>prisma token</code> in your project directory to get the work of art:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ prisma token\neyJhbGciOiJIUzI1NiIsInUYGFUJGSFKHFGSJFKSFJKSFGJdfSwiaWF0IjoxNTUyMTYwMDQ5LCJleHAiOjE1NTI3NjQ4NDl9.xrubUg_dRc93bqqR4f6jGt-KvQRS2Xq6lRi0a0uw-C0\n</code></pre>\n<!--kg-card-end: markdown--><p>Nice; believe it or not, that was the \"hard\" part.</p><h3 id=\"extra-credit-assign-a-dns-record-and-apply-a-security-certificate\">EXTRA CREDIT: Assign a DNS Record and Apply a Security Certificate</h3><p>If really want to, you could already query against your insecure IP address and start receiving some information. That said, making <strong>HTTP</strong> requests as such from <strong>HTTPS</strong> origins will fail. Not only that, but you kind of look shitty for not even bothering to name your API, much less apply a free SSL certificate. For the easiest possible way to do this, see our post on <a href=\"https://hackersandslackers.com/serve-docker-containers-with-custom-dns-and-ssl/\">using Caddy as an HTTP server</a>.</p><h2 id=\"building-a-javascript-client-to-consume-our-api\">Building a Javascript Client to Consume Our API</h2><p>With our API nice and secure, we can start hitting this baby from wherever we want... as long as it's a Node app. We'll start by requiring two packages:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">const { GraphQLClient } = require('graphql-request')\nconst { dotenv } = require('dotenv').config()\n</code></pre>\n<!--kg-card-end: markdown--><p><code>GraphQLClient</code> is the magic behind our client- it's everything. It also happens to be very similar to existing <strong>npm</strong> libraries for making requests, such as <a href=\"https://hackersandslackers.com/making-api-requests-with-nodejs/\">node-fetch</a>.</p><p>We'll also leverage the <code>dotenv</code> library to make sure our <strong>API endpoint</strong> and <strong>Bearer token</strong> stay out of source code. Try not to be Equifax whenever possible. <code>dotenv</code> allows us to load sensitive values from a <code>.env</code> file. Just in case you need a refresher, that file should look like this:</p><!--kg-card-begin: code--><pre><code>NODE_ENV=Production\nENDPOINT=https://yourapiendpoint.com\nAUTH=Bearer eyJhbGciOBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHGUYFIERIBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHBLAHZl-UGnMrOk3w</code></pre><!--kg-card-end: code--><h3 id=\"initialize-the-graphql-client\">Initialize The GraphQL Client</h3><p>I like to set up a one-time client for our API that we can go back and reuse if need be. After pulling the API endpoint and token from our <code>.env</code> file, setting up the client is easy:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">const { GraphQLClient } = require('graphql-request')\nconst { dotenv } = require('dotenv').config()\n\nconst endpoint = process.env.ENDPOINT;\nconst token = process.env.AUTH;\n\n// Initialize GraphQL Client\nconst client = new GraphQLClient(endpoint, {\n  headers: {\n    Authorization: token\n  }\n});\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"emergency-meeting-everybody-huddle-up\">EMERGENCY MEETING: EVERYBODY HUDDLE UP</h2><p>Oh I'm sorry, were you focusing on development? Unfortunately for you, I spent 8 years as a product manager, and I <em>love</em> stopping everything suddenly to call emergency meetings.</p><p>Real talk though, let's think back to the JIRA Kanban board example we've been using for the last two posts. If you recall, we're going to write a query that populates a 4-column Kanban board. The board represents a <em>project </em>(in this case, <strong>Hackers and Slackers</strong>) and each column represents a <em>status</em> of ticket, like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">const statuses = ['Backlog', 'To Do', 'In Progress', 'Done'];\n</code></pre>\n<!--kg-card-end: markdown--><p>We've previously established that GraphQL queries are friendly to drop-in variables. Let's use this to build some logic into our client, as opposed to hardcoding a massive query, which is really just the same 4 queries stitched together. Here's what a query to populate a single JIRA column looks like:</p><!--kg-card-begin: code--><pre><code>// Structured query\nconst query = `\n    query JiraIssuesByStatus($project: String, $status: String) {\n         jiraIssues(where: {project: $project, status: $status}, \n         orderBy: timestamp_DESC, \n         first: 6) {\n            key\n            summary\n            epic\n            status\n            project\n            priority\n            issuetype\n            timestamp\n            }\n         }\n       `</code></pre><!--kg-card-end: code--><p>We're passing both the <em>project</em> and the <em>issue status</em> as variables to our query. We can make things a bit dynamic here by looping through our statuses and executing this query four times: each time resulting in a callback filling the appropriate columns with JIRA issues.</p><!--kg-card-begin: html--><div class=\"protip\">\nThis approach is certainly less clunky and more dynamic than a hardcoded query. That said, this <i>still</i> isn't the best solution. Remember: the strength of GraphQL is the ability to get obscene amounts of data across complex relationships in a single call. The best approach here would probably be to build the query string itself dynamically using <strong>fragments,</strong> which we'll review in the next post.\n</div><!--kg-card-end: html--><h2 id=\"game-on-our-client-in-action\">Game On: Our Client in Action</h2><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">const { GraphQLClient } = require('graphql-request')\nconst { dotenv } = require('dotenv').config()\n\nconst endpoint = process.env.ENDPOINT;\nconst token = process.env.AUTH;\n\n// Initialize GraphQL Client\nconst client = new GraphQLClient(endpoint, {\n  headers: {\n    Authorization: token\n  }\n});\n\n// Structured query\nconst query = `\n   query JiraIssuesByStatus($project: String, $status: String) {\n      jiraIssues(where: {project: $project, status: $status}, orderBy: timestamp_DESC, first: 6) {\n         key\n         summary\n         epic\n         status\n         project\n         priority\n         issuetype\n         timestamp\n        }\n      }\n    `;\n\n// All Possible Issue Statuses\nconst statuses = ['Backlog', 'To Do', 'In Progress', 'Done'];\n\n// Execute a query per issue status\nfor(var i = 0; i &lt; statuses.length; i++){\n  var variables = {\n    project: &quot;Hackers and Slackers&quot;,\n    status: statuses[i]\n  }\n\n  client.request(query, variables).then((data) =&gt; {\n    console.log(data)\n  }).catch(err =&gt; {\n    console.log(err.response.errors) // GraphQL response errors\n    console.log(err.response.data) // Response data if available\n  });\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Works like a charm. We only had one endpoint, only had to set one header, and didn't spend any time reading through hundreds of pages of documentation to figure out which combination of REST API endpoint, parameters, and methods actually get us what we want. It's almost as if we're writing SQL now, except... it looks a lot more like... NoSQL. Thanks for the inspiration, <strong>MongoDB</strong>! Hope that whole <em>selling-open-source-software</em> thing works out.</p><p>Oh, and of course, here were the results of my query:</p><!--kg-card-begin: markdown--><pre><code class=\"language-json\">{ jiraIssues:\n   [ { priority: 'Medium',\n       timestamp: 1550194791,\n       project: 'Hackers and Slackers',\n       key: 'HACK-778',\n       epic: 'Code snippets',\n       status: 'Backlog',\n       issuetype: 'Task',\n       summary: 'HLJS: set indentation level' },\n     { priority: 'Medium',\n       timestamp: 1550194782,\n\n       project: 'Hackers and Slackers',\n       key: 'HACK-555',\n       epic: 'Optimization',\n       status: 'Backlog',\n       issuetype: 'Task',\n       summary: 'Minify Babel' },\n     { priority: 'Medium',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-785',\n       epic: 'New Post',\n       status: 'Backlog',\n       issuetype: 'Task',\n       summary: 'Unix commands for data' },\n     { priority: 'Medium',\n       timestamp: 1550016000,\n       project: 'Hackers and Slackers',\n       key: 'HACK-251',\n       epic: 'New Post',\n       status: 'Backlog',\n       issuetype: 'Content',\n       summary: 'Using Ghost\\'s content filtering' },\n     { priority: 'Medium',\n       timestamp: 1550016000,\n       project: 'Hackers and Slackers',\n       key: 'HACK-302',\n       epic: 'Widgets',\n       status: 'Backlog',\n       issuetype: 'Integration',\n       summary: 'Discord channel signups ' },\n     { priority: 'Low',\n       timestamp: 1550016000,\n       project: 'Hackers and Slackers',\n       key: 'HACK-336',\n       epic: 'New Post',\n       status: 'Backlog',\n       issuetype: 'Content',\n       summary: 'Linux: Configuring your server to send SMTP emails' } ] }\n{ jiraIssues:\n   [ { priority: 'Medium',\n       timestamp: 1550224412,\n       project: 'Hackers and Slackers',\n       key: 'HACK-769',\n       epic: 'Projects Page',\n       status: 'Done',\n       issuetype: 'Bug',\n       summary: 'Fix projects dropdown' },\n     { priority: 'High',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-710',\n       epic: 'Lynx',\n       status: 'Done',\n       issuetype: 'Task',\n       summary: 'Implement auto text synopsis for Lynx posts' },\n     { priority: 'Medium',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-777',\n       epic: 'Creative',\n       status: 'Done',\n       issuetype: 'Task',\n       summary: 'Redesign footer to be informative; link-heavy' },\n     { priority: 'Highest',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-779',\n       epic: 'Urgent',\n       status: 'Done',\n       issuetype: 'Task',\n       summary: 'Changeover from cloudinary to DO' },\n     { priority: 'Medium',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-780',\n       epic: 'Creative',\n       status: 'Done',\n       issuetype: 'Task',\n       summary: 'Make mobile post title bold' },\n     { priority: 'High',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-781',\n       epic: 'Urgent',\n       status: 'Done',\n       issuetype: 'Bug',\n       summary: 'This post consistently doesn’t work on mobile' } ] }\n{ jiraIssues:\n   [ { priority: 'Low',\n       timestamp: 1550223282,\n       project: 'Hackers and Slackers',\n       key: 'HACK-782',\n       epic: 'Widgets',\n       status: 'To Do',\n       issuetype: 'Task',\n       summary:\n        'Lynx: on mobile, instead of full link, show domainname.com/...' },\n     { priority: 'High',\n       timestamp: 1550194799,\n       project: 'Hackers and Slackers',\n       key: 'HACK-774',\n       epic: 'Widgets',\n       status: 'To Do',\n       issuetype: 'Task',\n       summary: 'New Widget: Next/Previous article in series' },\n     { priority: 'Low',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-395',\n       epic: 'Page Templates',\n       status: 'To Do',\n       issuetype: 'Task',\n       summary: 'Create fallback image for posts with no image' },\n     { priority: 'High',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-756',\n       epic: 'Newsletter',\n       status: 'To Do',\n       issuetype: 'Major Functionality',\n       summary: 'Automate newsletter' },\n     { priority: 'Low',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-775',\n       epic: 'Projects Page',\n       status: 'To Do',\n       issuetype: 'Data &amp; Analytics',\n       summary: 'Update issuetype icons' },\n     { priority: 'Lowest',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-776',\n       epic: 'Projects Page',\n       status: 'To Do',\n       issuetype: 'Task',\n       summary: 'Add fork icon to repos' } ] }\n{ jiraIssues:\n   [ { priority: 'High',\n       timestamp: 1550102400,\n       project: 'Hackers and Slackers',\n       key: 'HACK-784',\n       epic: 'New Post',\n       status: 'In Progress',\n       issuetype: 'Content',\n       summary: 'Welcome to SQL part1' } ] }\n</code></pre>\n<!--kg-card-end: markdown--><p>Before we say \"GG, 2ez, 1v1 me,\" know that we're<em> only getting started</em> uncovering what GraphQL can do. It's not all just creating and deleting records either; we're talking full-on database JOIN equivalent type shit here. Stick around folks, the bandwagon's just getting warmed up.</p>","url":"https://hackersandslackers.com/interacting-with-your-graphql-api/","uuid":"34fef193-6a56-4754-a329-3d34571fcd15","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c838ee05af763016e85085b"}},{"node":{"id":"Ghost__Post__5c806baf199621174e904b03","title":"Writing Your First GraphQL Query","slug":"writing-your-first-graphql-queries","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/graphql-1-3.jpg","excerpt":"Begin to structure complex queries against your GraphQL API.","custom_excerpt":"Begin to structure complex queries against your GraphQL API.","created_at_pretty":"07 March, 2019","published_at_pretty":"07 March, 2019","updated_at_pretty":"28 March, 2019","created_at":"2019-03-06T19:54:07.000-05:00","published_at":"2019-03-07T10:37:00.000-05:00","updated_at":"2019-03-28T11:01:59.000-04:00","meta_title":"Writing Your First GraphQL Queries | Hackers and Slackers","meta_description":"Structure your first GraphQL Queries and begin to build a client.","og_description":"Structure your first GraphQL Queries and begin to build a client.","og_image":"https://hackersandslackers.com/content/images/2019/03/graphql-1-3.jpg","og_title":"Writing Your First GraphQL Queries","twitter_description":"Structure your first GraphQL Queries and begin to build a client.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/graphql-1-2.jpg","twitter_title":"Writing Your First GraphQL Queries","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"GraphQL","slug":"graphql","description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","feature_image":null,"meta_description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","meta_title":"Build a GraphQL API | Hackers and Slackers","visibility":"public"},"tags":[{"name":"GraphQL","slug":"graphql","description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","feature_image":null,"meta_description":"Ditch REST endpoints and build APIs that make sense with your workflow. Get started with Prisma or Apollo toolkits, and join the GraphQL bandwagon.","meta_title":"Build a GraphQL API | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#GraphQL Hype","slug":"graphql-hype","description":"Learn GraphQL syntax and see the reasons why the future of APIs is here to stay. We walk through everything from server/client setup to intricate tricks.","feature_image":"https://hackersandslackers.com/content/images/2019/03/graphqlseries.jpg","meta_description":"Learn GraphQL syntax and see the reasons why the future of APIs is here to stay. We walk through everything from server/client setup to intricate tricks.","meta_title":"GraphQL Hype","visibility":"internal"}],"plaintext":"In our last run-in with GraphQL, we used Prisma  to assist in setting up a\nGraphQL server\n[https://hackersandslackers.com/easily-build-graphql-apis-with-prisma/]. This\neffectively gave us an endpoint to work with for making GraphQL requests against\nthe database we specified when getting started. If you're still in the business\nof setting up a GraphQL server, there are plenty of alternative services to\nPrisma you could explore. Apollo [https://www.apollographql.com/]  is perhaps\nthe most popular. A different approach could be to use GraphCMS\n[https://graphcms.com/]: a headless CMS for building GraphQL models with a\nbeautiful interface.\n\nWith our first models are created and deployed, we’re now able to explore\nGraphQL hands-on. Prisma (and just about any other service) gives us the luxury\nof a “playground” interface, where we can write all sorts of nonsensical and\notherwise dangerous shit. This is our opportunity to get comfortable before\nunleashing our ignorance upon the world in a production environment. To guide\nus, I’ll be using my own example of creating models, importing dummy data, and\nhow to write the queries to fetch said data.\n\nOur Example Model\nIn my case, I created a model for one of my favorite things: JIRA issues. I'll\nbe creating a Kanban widget using the data we play with here down the line, so\nthis is a real live use-case we'll be working with.\n\nHere are the contents of my datamodel.prisma  file:\n\ntype jiraissue {\n  id: ID! @unique,\n  key: String! @unique,\n  assignee: String,\n  summary: String,\n  status: String!,\n  priority: String,\n  issuetype: String,\n  epic_name: String,\n  updated: DateTime,\n  rank: Int,\n  timestamp: Int,\n  project: String\n}\n\nYou'll notice we have a good number of datatypes here, as well as two unique\nkeys. In case this point has been missed before, the exclamation marks in our\nmodel denote a required field.\n\nDeploying this model results in the following PostgreSQL query:\n\nCREATE TABLE \"default$default\".\"jiraissues\" (\n    \"id\" varchar(25) NOT NULL,\n    \"key\" text NOT NULL,\n    \"assignee\" text,\n    \"summary\" text,\n    \"status\" text NOT NULL,\n    \"priority\" text,\n    \"issuetype\" text,\n    \"epic_name\" text,\n    \"updated\" timestamp(3),\n    \"rank\" int4,\n    \"timestamp\" int4,\n    \"project\" text,\n    \"updatedAt\" timestamp(3) NOT NULL,\n    \"createdAt\" timestamp(3) NOT NULL,\n    PRIMARY KEY (\"id\")\n);\n\n\nLooks like everything lines up! The only caveat are the updatedAt  and createdAt \n fields: Prisma adds these to every database table for us.\n\nHere's a sample of the data I added by connecting to my database and importing a\nCSV:\n\nid\n key\n assignee\n summary\n status\n priority\n issuetype\n epic_name\n updated\n rank\n timestamp\n project\n updatedAt\n createdAt\n 430\n HACK-769\n Todd Birchard\n Fix projects dropdown\n Done\n Medium\n Bug\n Projects Page\n 2019-02-15 00:00:00\n 3\n 1550224412\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 465\n HACK-782\n Todd Birchard\n Lynx: on mobile, instead of full link, show domainname.com/...\n To Do\n Low\n Task\n Widgets\n 2019-02-15 00:00:00\n 4\n 1550223282\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 472\n HACK-774\n Todd Birchard\n New Widget: Next/Previous article in series\n To Do\n High\n Task\n Widgets\n 2019-02-14 00:00:00\n 2\n 1550194799\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 464\n HACK-778\n Todd Birchard\n HLJS: set indentation level\n Backlog\n Medium\n Task\n Code snippets\n 2019-02-14 00:00:00\n 3\n 1550194791\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 481\n HACK-555\n Todd Birchard\n Minify Babel\n Backlog\n Medium\n Task\n Optimization\n 2019-02-14 00:00:00\n 3\n 1550194782\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 432\n HACK-777\n Todd Birchard\n Redesign footer to be informative; link-heavy\n Done\n Medium\n Task\n Creative\n 2019-02-14 00:00:00\n 2\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 433\n HACK-779\n Todd Birchard\n Changeover from cloudinary to DO\n Done\n Highest\n Task\n Urgent\n 2019-02-14 00:00:00\n 0\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 428\n HACK-775\n Todd Birchard\n Update issuetype icons\n To Do\n Low\n Data & Analytics\n Projects Page\n 2019-02-14 00:00:00\n 3\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 374\n HACK-710\n Todd Birchard\n Implement auto text synopsis for Lynx posts\n Done\n High\n Task\n Lynx\n 2019-02-14 00:00:00\n 1\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n 185\n HACK-395\n Todd Birchard\n Create fallback image for posts with no image\n To Do\n Low\n Task\n Page Templates\n 2019-02-14 00:00:00\n 3\n 1550102400\n Hackers and Slackers\n 2019-03-02 15:43:59.419\n 2019-03-02 15:43:59.419\n A Few Things About GraphQL Queries\nBefore going any further, let's touch on a few concepts that are easy to stumble\nover.\n\nFirstly, a  GraphQL API only has a single endpoint. It makes sense: the logic of\nGraphQL API hits sit with the person creating the queries. That said, we've all\nbeen building REST APIs long enough to have this slip past us; I caught myself\nthinking through how to separate which endpoints I wanted before remembering\nthat's entirely not how this works.\n\nIt's import to understand that GraphQL is designed to be explicit. A significant\nadvantage of GraphQL is that we can be sure only to return the information which\nis essential to us.  For applications looking to optimize system resources (such\nas mobile apps), avoiding massive payloads is a feature, not a bug. This\nexplains many of the design decisions which went into designing GraphQL, as\nyou'll see it's intentionally difficult (but possible) to create a \"get all\nrecords\" query.\n\nLastly, GraphQL allows us to create queries in both shorthand and long-form  \nformats.  We'll take a look at both, starting with shorthand.\n\nGraphQL Shorthand Queries\nShorthand queries are an excellent place to start for beginners like us just\ntrying to get some data out of our database.\n\nThe structure of such a query looks like this:\n\n{\n  [model_name]s {\n    [desired_field_name_1]\n    [desired_field_name_2]\n    [desired_field_name_3]\n  }\n}\n\nUsing our example, our model_name  in this case would be jiraissue made plural, \nresulting in jiraissues. This is an important thing to note: when creating\nmodels, we should name them as a single entity, as things get confusing very\nfast otherwise. I initially made the mistake of naming my model jiraissues,\nwhich would then drive me to query jiraissueses. That was a fun little trip.\n\nWithin the brackets of our model, we must explicitly specify which fields (aka\ndatabase columns) we'd like returned with our query. Here's a full example of a\nshorthand query:\n\n{\n  jiraissues {\n    key\n    summary\n    epic_name\n  }\n}\n\n\nCheck out what this results in when entered in our \"playground\":\n\nQuery on the left, results on the right.Just like that, we have liftoff!\n\nThe \"Where\" Clause\nAs mentioned earlier, a major point of GraphQL is to return only the data which\nis necessary. Thus, we should almost always make queries with a where clause.\nThus, we can extend our simple query as such:\n\n{\n  jiraissueses(where: {status: \"Backlog\"}) {\n    key\n    summary\n    epic_name\n    status\n  }\n}\n\n\nAnd here's the result:\n\nFiltering results \"where\" certain criteria are met.Adding to Our Query\nJust like SQL or MongoDB queries, we can add more to our query to get more\nspecific:\n\n{\n  jiraissues(where: {status: \"Backlog\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC,  first: 6) \n  {\n    key\n    summary\n    epic_name\n    status\n    updated\n  }\n}\n\n\nHere, we've expanded our filter to work on two  fields: now our query will only\nreturn issues which match our criteria for both status  and project. \n\nWe've also added a few other things to our query. With orderBy, we can set the\norder in which records will be returned to us by field, either in ascending\n(ASC) or descending (DESC) order. first  imposes a limit on our results, giving\nus the first 6 which meet our criteria. Alternatively, last  would give us the\nopposite.\n\nThere are plenty of more parameters we could add here. For example:\n\n * [fieldname]_contains: Filters results where the string field contains a\n   substring.\n * [fieldname]_in: Checks a list to return records where the value of the field\n   matches any substring in a provided list.\n * [fieldname]_starts_with: An expression to check for values that start with a\n   provided substring.\n * [fieldname]_ends_with: Similar to the above, only for ending with a\n   substring.\n\nNot only are there more to add to this list, but each as an accompanying reverse\nstatement which would return the opposite. For example, [fieldname]_not_contains \n is the opposite of [fieldname]_contains.\n\nGraphQL Longform Queries\nWhat we've seen so far is already pretty powerful, but we're far from seeing\njust how far GraphQL can go. \n\nTo demonstrate what a more complicated query is capable of, let's use out Kanban\nboard example. Our board is going to have 4 columns representing 4 statuses: \nBacklog, To Do, In Progress, and Done.  Check out how we can receive all of this\nwith a single query:\n\nquery KanbanJiraIssues {\n  backlog: jiraissues(where: {status: \"Backlog\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  todo: jiraissues(where: {status: \"To Do\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  inprogress: jiraissues(where: {status: \"In Progress\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  done: jiraissues(where: {status: \"Done\", project: \"Hackers and Slackers\"}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n}\n\n\nUnlike our shorthand queries, we begin this query with the syntax query\n[your_query_name]. You can name your query anything you'd like.\n\nWithin that query, we can perform multiple individual queries which we too give\ndisplay names. In whole, the structure looks like this:\\\n\nquery [your_query_name] {\n  [subquery_name]: [model_name]s(where: {[your_criteria]}){\n    [desired_field_name_1]\n    [desired_field_name_2]\n    [desired_field_name_3]\n  }\n}\n\n\nCheck out the result:\n\nNow THAT's a query.This format has helped us accomplish something previously\nimpossible with REST APIs: we've used a single endpoint to give us exactly  the\ninformation we need while omitting the information we don't.\n\nPassing Variables Into Queries\nAs you can see, queries can get lengthy pretty quick. It would suck if we had to\nwrite the entirety of the query above every time we wanted to hit an API.\nLuckily, we don't don't have to: that's where GraphQL variables come in.\n\nVariables allow us to use the structure of a GraphQL query repeatedly, while\nproviding different values where we see fit. That means if we have a\nparticularly complicated query structure that we'd like to repurpose, we can\npass dynamic values into said query. This is where things start to get really\npowerful.\n\nLet's assume that finding JIRA issues by epic link  is a common task we'll have\nto deal with. This is how we'd pass a dynamic value for epic_link:\n\nquery JiraIssuesByEpicName($epic_name: String) {\n  jiraissues(where: {epic_name: $epic_name}) {\n    key\n    summary\n    epic_name\n    status\n    updated\n    project\n    priority\n    issuetype\n    timestamp\n  }\n}\n\n$epic_name  is the name of our variable, which we set in the object we pass to\nthe query. That object looks like this:\n\n{\n  \"epic_name\": \"SEO\"\n}\n\nSo what we're saying on line 1  is that we're passing a variable named \n$epic_name, and that variable will be a String. When $epic_name  appears again\non line 2, the variable is interpreted as its value, which is \"SEO\".\n\nLuckily, our playground has a place specifically for setting variables which get\npassed to our queries. Here's how it all looks:\n\nHeavy breathing intensifies.Unlimited Power?\nWhile GraphQL's syntax looks clean and simple at first glance, it's easy to see\nhow quickly simple queries evolve into complex behemoths. It's no coincidence\nthat all GraphQL services come with a playground. It's hard to imagine how\nanybody could internalize GraphQL syntax without trial and error, and we're only\ngetting started.\n\nSo far we've only queried existing data; we haven't even begun to touch on\nmutations yet. Catch us next time when we start modifying data and get ourselves\ninto a whole lot of trouble.","html":"<p>In our last run-in with GraphQL, we used <strong>Prisma</strong> to assist in <a href=\"https://hackersandslackers.com/easily-build-graphql-apis-with-prisma/\">setting up a GraphQL server</a>. This effectively gave us an endpoint to work with for making GraphQL requests against the database we specified when getting started. If you're still in the business of setting up a GraphQL server, there are plenty of alternative services to Prisma you could explore. <a href=\"https://www.apollographql.com/\"><strong>Apollo</strong></a> is perhaps the most popular. A different approach could be to use <a href=\"https://graphcms.com/\"><strong>GraphCMS</strong></a>: a headless CMS for building GraphQL models with a beautiful interface.</p><p>With our first models are created and deployed, we’re now able to explore GraphQL hands-on. Prisma (and just about any other service) gives us the luxury of a “playground” interface, where we can write all sorts of nonsensical and otherwise dangerous shit. This is our opportunity to get comfortable before unleashing our ignorance upon the world in a production environment. To guide us, I’ll be using my own example of creating models, importing dummy data, and how to write the queries to fetch said data.</p><h2 id=\"our-example-model\">Our Example Model</h2><p>In my case, I created a model for one of my favorite things: JIRA issues. I'll be creating a Kanban widget using the data we play with here down the line, so this is a real live use-case we'll be working with.</p><p>Here are the contents of my <code>datamodel.prisma</code> file:</p><!--kg-card-begin: code--><pre><code>type jiraissue {\n  id: ID! @unique,\n  key: String! @unique,\n  assignee: String,\n  summary: String,\n  status: String!,\n  priority: String,\n  issuetype: String,\n  epic_name: String,\n  updated: DateTime,\n  rank: Int,\n  timestamp: Int,\n  project: String\n}</code></pre><!--kg-card-end: code--><p>You'll notice we have a good number of datatypes here, as well as two unique keys. In case this point has been missed before, the exclamation marks in our model denote a required field.</p><p>Deploying this model results in the following PostgreSQL query:</p><!--kg-card-begin: markdown--><pre><code class=\"language-sql\">CREATE TABLE &quot;default$default&quot;.&quot;jiraissues&quot; (\n    &quot;id&quot; varchar(25) NOT NULL,\n    &quot;key&quot; text NOT NULL,\n    &quot;assignee&quot; text,\n    &quot;summary&quot; text,\n    &quot;status&quot; text NOT NULL,\n    &quot;priority&quot; text,\n    &quot;issuetype&quot; text,\n    &quot;epic_name&quot; text,\n    &quot;updated&quot; timestamp(3),\n    &quot;rank&quot; int4,\n    &quot;timestamp&quot; int4,\n    &quot;project&quot; text,\n    &quot;updatedAt&quot; timestamp(3) NOT NULL,\n    &quot;createdAt&quot; timestamp(3) NOT NULL,\n    PRIMARY KEY (&quot;id&quot;)\n);\n</code></pre>\n<!--kg-card-end: markdown--><p>Looks like everything lines up! The only caveat are the <code>updatedAt</code> and <code>createdAt</code> fields: Prisma adds these to every database table for us.</p><p>Here's a sample of the data I added by connecting to my database and importing a CSV:</p><!--kg-card-begin: html--><div class=\"tableContainer\">\n<table>\n    <thead>\n       <tr>\n             <th>id</th>\n             <th>key</th>\n             <th>assignee</th>\n             <th>summary</th>\n             <th>status</th>\n             <th>priority</th>\n             <th>issuetype</th>\n             <th>epic_name</th>\n             <th>updated</th>\n             <th>rank</th>\n             <th>timestamp</th>\n             <th>project</th>\n             <th>updatedAt</th>\n             <th>createdAt</th>\n         </tr>\n    </thead>\n    <tbody>\n       <tr>\n              <td>430</td>\n              <td>HACK-769</td>\n              <td>Todd Birchard</td>\n              <td>Fix projects dropdown</td>\n              <td>Done</td>\n              <td>Medium</td>\n              <td>Bug</td>\n              <td>Projects Page</td>\n              <td>2019-02-15 00:00:00</td>\n              <td>3</td>\n              <td>1550224412</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>465</td>\n              <td>HACK-782</td>\n              <td>Todd Birchard</td>\n              <td>Lynx: on mobile, instead of full link, show domainname.com/...</td>\n              <td>To Do</td>\n              <td>Low</td>\n              <td>Task</td>\n              <td>Widgets</td>\n              <td>2019-02-15 00:00:00</td>\n              <td>4</td>\n              <td>1550223282</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>472</td>\n              <td>HACK-774</td>\n              <td>Todd Birchard</td>\n              <td>New Widget: Next/Previous article in series</td>\n              <td>To Do</td>\n              <td>High</td>\n              <td>Task</td>\n              <td>Widgets</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>2</td>\n              <td>1550194799</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>464</td>\n              <td>HACK-778</td>\n              <td>Todd Birchard</td>\n              <td>HLJS: set indentation level</td>\n              <td>Backlog</td>\n              <td>Medium</td>\n              <td>Task</td>\n              <td>Code snippets</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>3</td>\n              <td>1550194791</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>481</td>\n              <td>HACK-555</td>\n              <td>Todd Birchard</td>\n              <td>Minify Babel</td>\n              <td>Backlog</td>\n              <td>Medium</td>\n              <td>Task</td>\n              <td>Optimization</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>3</td>\n              <td>1550194782</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>432</td>\n              <td>HACK-777</td>\n              <td>Todd Birchard</td>\n              <td>Redesign footer to be informative; link-heavy</td>\n              <td>Done</td>\n              <td>Medium</td>\n              <td>Task</td>\n              <td>Creative</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>2</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>433</td>\n              <td>HACK-779</td>\n              <td>Todd Birchard</td>\n              <td>Changeover from cloudinary to DO</td>\n              <td>Done</td>\n              <td>Highest</td>\n              <td>Task</td>\n              <td>Urgent</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>0</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>428</td>\n              <td>HACK-775</td>\n              <td>Todd Birchard</td>\n              <td>Update issuetype icons</td>\n              <td>To Do</td>\n              <td>Low</td>\n              <td>Data & Analytics</td>\n              <td>Projects Page</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>3</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>374</td>\n              <td>HACK-710</td>\n              <td>Todd Birchard</td>\n              <td>Implement auto text synopsis for Lynx posts</td>\n              <td>Done</td>\n              <td>High</td>\n              <td>Task</td>\n              <td>Lynx</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>1</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n       <tr>\n              <td>185</td>\n              <td>HACK-395</td>\n              <td>Todd Birchard</td>\n              <td>Create fallback image for posts with no image</td>\n              <td>To Do</td>\n              <td>Low</td>\n              <td>Task</td>\n              <td>Page Templates</td>\n              <td>2019-02-14 00:00:00</td>\n              <td>3</td>\n              <td>1550102400</td>\n              <td>Hackers and Slackers</td>\n              <td>2019-03-02 15:43:59.419</td>\n              <td>2019-03-02 15:43:59.419</td>\n          </tr>\n    </tbody>\n   </table>\n</div><!--kg-card-end: html--><h2 id=\"a-few-things-about-graphql-queries\">A Few Things About GraphQL Queries</h2><p>Before going any further, let's touch on a few concepts that are easy to stumble over.</p><p>Firstly, a<strong> GraphQL API only has a single endpoint</strong>. It makes sense: the logic of GraphQL API hits sit with the person creating the queries. That said, we've all been building REST APIs long enough to have this slip past us; I caught myself thinking through how to separate which endpoints I wanted before remembering that's entirely not how this works.</p><p>It's import to understand that <strong>GraphQL is designed to be explicit</strong>. A significant advantage of GraphQL is that we can be sure <em>only to return the information which is essential to us.</em> For applications looking to optimize system resources (such as mobile apps), avoiding massive payloads is a feature, not a bug. This explains many of the design decisions which went into designing GraphQL, as you'll see it's intentionally difficult (but possible) to create a \"get all records\" query.</p><p>Lastly, GraphQL allows us to <strong>create queries in both shorthand and long-form</strong> <strong>formats</strong>.<strong> </strong>We'll take a look at both, starting with shorthand.</p><h2 id=\"graphql-shorthand-queries\">GraphQL Shorthand Queries</h2><p>Shorthand queries are an excellent place to start for beginners like us just trying to get some data out of our database.</p><p>The structure of such a query looks like this:</p><!--kg-card-begin: code--><pre><code>{\n  [model_name]s {\n    [desired_field_name_1]\n    [desired_field_name_2]\n    [desired_field_name_3]\n  }\n}</code></pre><!--kg-card-end: code--><p>Using our example, our <strong>model_name</strong> in this case would be <strong>jiraissue </strong><em>made plural,</em> resulting in <strong>jiraissues</strong>. This is an important thing to note: when creating models, we should name them as a single entity, as things get confusing very fast otherwise. I initially made the mistake of naming my model <strong>jiraissues</strong>, which would then drive me to query <strong>jiraissueses</strong>. That was a fun little trip.</p><p>Within the brackets of our model, we must explicitly specify which fields (aka database columns) we'd like returned with our query. Here's a full example of a shorthand query:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">{\n  jiraissues {\n    key\n    summary\n    epic_name\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Check out what this results in when entered in our \"playground\":</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-06-at-8.50.53-PM.png\" class=\"kg-image\"><figcaption>Query on the left, results on the right.</figcaption></figure><!--kg-card-end: image--><p>Just like that, we have liftoff!</p><h3 id=\"the-where-clause\">The \"Where\" Clause</h3><p>As mentioned earlier, a major point of GraphQL is to return only the data which is necessary. Thus, we should almost always make queries with a <em>where </em>clause. Thus, we can extend our simple query as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">{\n  jiraissueses(where: {status: &quot;Backlog&quot;}) {\n    key\n    summary\n    epic_name\n    status\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>And here's the result:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-06-at-9.21.23-PM.png\" class=\"kg-image\"><figcaption>Filtering results \"where\" certain criteria are met.</figcaption></figure><!--kg-card-end: image--><h3 id=\"adding-to-our-query\">Adding to Our Query</h3><p>Just like SQL or MongoDB queries, we can add more to our query to get more specific:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">{\n  jiraissues(where: {status: &quot;Backlog&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC,  first: 6) \n  {\n    key\n    summary\n    epic_name\n    status\n    updated\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Here, we've expanded our filter to work on <em>two</em> fields: now our query will only return issues which match our criteria for both <code>status</code> and <code>project</code>. </p><p>We've also added a few other things to our query. With <code>orderBy</code>, we can set the order in which records will be returned to us by field, either in ascending (ASC) or descending (DESC) order. <code>first</code> imposes a limit on our results, giving us the first 6 which meet our criteria. Alternatively, <code>last</code> would give us the opposite.</p><p>There are plenty of more parameters we could add here. For example:</p><ul><li><code>[fieldname]_contains</code>: Filters results where the string field contains a substring.</li><li><code>[fieldname]_in</code>: Checks a list to return records where the value of the field matches any substring in a provided list.</li><li><code>[fieldname]_starts_with</code>: An expression to check for values that start with a provided substring.</li><li><code>[fieldname]_ends_with</code>: Similar to the above, only for ending with a substring.</li></ul><p>Not only are there more to add to this list, but each as an accompanying reverse statement which would return the opposite. For example, <code>[fieldname]_not_contains</code> is the opposite of <code>[fieldname]_contains</code>.</p><h2 id=\"graphql-longform-queries\">GraphQL Longform Queries</h2><p>What we've seen so far is already pretty powerful, but we're far from seeing just how far GraphQL can go. </p><p>To demonstrate what a more complicated query is capable of, let's use out Kanban board example. Our board is going to have 4 columns representing 4 statuses: <strong>Backlog, To Do, In Progress, </strong>and <strong>Done.</strong> Check out how we can receive all of this with a single query:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">query KanbanJiraIssues {\n  backlog: jiraissues(where: {status: &quot;Backlog&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  todo: jiraissues(where: {status: &quot;To Do&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  inprogress: jiraissues(where: {status: &quot;In Progress&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n  done: jiraissues(where: {status: &quot;Done&quot;, project: &quot;Hackers and Slackers&quot;}, orderBy: updated_DESC, first: 6){\n    key\n    status\n    summary\n    assignee\n    priority\n    issuetype\n    epic_name\n    updated\n    rank\n    timestamp\n    project\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Unlike our shorthand queries, we begin this query with the syntax <code>query [your_query_name]</code>. You can name your query anything you'd like.</p><p>Within that query, we can perform multiple individual queries which we too give display names. In whole, the structure looks like this:\\</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">query [your_query_name] {\n  [subquery_name]: [model_name]s(where: {[your_criteria]}){\n    [desired_field_name_1]\n    [desired_field_name_2]\n    [desired_field_name_3]\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Check out the result:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-06-at-11.22.29-PM.png\" class=\"kg-image\"><figcaption>Now THAT's a query.</figcaption></figure><!--kg-card-end: image--><p>This format has helped us accomplish something previously impossible with REST APIs: we've used a single endpoint to give us <em>exactly</em> the information we need while omitting the information we don't.</p><h2 id=\"passing-variables-into-queries\">Passing Variables Into Queries</h2><p>As you can see, queries can get lengthy pretty quick. It would suck if we had to write the entirety of the query above every time we wanted to hit an API. Luckily, we don't don't have to: that's where GraphQL <em>variables </em>come in.</p><p>Variables allow us to use the structure of a GraphQL query repeatedly, while providing different values where we see fit. That means if we have a particularly complicated query structure that we'd like to repurpose, we can pass dynamic values into said query. This is where things start to get really powerful.</p><p>Let's assume that finding JIRA issues by <em>epic link</em> is a common task we'll have to deal with. This is how we'd pass a dynamic value for <strong>epic_link:</strong></p><!--kg-card-begin: code--><pre><code>query JiraIssuesByEpicName($epic_name: String) {\n  jiraissues(where: {epic_name: $epic_name}) {\n    key\n    summary\n    epic_name\n    status\n    updated\n    project\n    priority\n    issuetype\n    timestamp\n  }\n}</code></pre><!--kg-card-end: code--><p><code>$epic_name</code> is the name of our variable, which we set in the object we pass to the query. That object looks like this:</p><!--kg-card-begin: code--><pre><code>{\n  \"epic_name\": \"SEO\"\n}</code></pre><!--kg-card-end: code--><p>So what we're saying on <strong>line 1</strong> is that we're passing a variable named <code>$epic_name</code>, and that variable will be a <code>String</code>. When <code>$epic_name</code> appears again on <strong>line 2</strong>, the variable is interpreted as its value, which is \"SEO\".</p><p>Luckily, our playground has a place specifically for setting variables which get passed to our queries. Here's how it all looks:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/graphql-variables.png\" class=\"kg-image\"><figcaption>Heavy breathing intensifies.</figcaption></figure><!--kg-card-end: image--><h3 id=\"unlimited-power\">Unlimited Power?</h3><p>While GraphQL's syntax looks clean and simple at first glance, it's easy to see how quickly simple queries evolve into complex behemoths. It's no coincidence that all GraphQL services come with a playground. It's hard to imagine how anybody could internalize GraphQL syntax without trial and error, and we're only getting started.</p><p>So far we've only queried existing data; we haven't even begun to touch on mutations yet. Catch us next time when we start modifying data and get ourselves into a whole lot of trouble.</p>","url":"https://hackersandslackers.com/writing-your-first-graphql-queries/","uuid":"4019e61f-0f68-4921-99d4-5085864f9143","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c806baf199621174e904b03"}},{"node":{"id":"Ghost__Post__5c5a3e362c71af62216fd45e","title":"Manage Database Models with Flask-SQLAlchemy","slug":"manage-database-models-with-flask-sqlalchemy","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-sqlalchemy2.jpg","excerpt":"Connect your Flask app to a database using Flask-SQLAlchemy.","custom_excerpt":"Connect your Flask app to a database using Flask-SQLAlchemy.","created_at_pretty":"06 February, 2019","published_at_pretty":"06 February, 2019","updated_at_pretty":"03 April, 2019","created_at":"2019-02-05T20:53:58.000-05:00","published_at":"2019-02-06T08:00:00.000-05:00","updated_at":"2019-04-03T11:38:02.000-04:00","meta_title":"Manage Database Models with Flask-SQLAlchemy | Hackers and Slackers","meta_description":"Connect your Flask application to a database using the Flask-SQLAlchemy library. The most important Flask library you'll ever use.","og_description":"Connect your Flask application to a database using the Flask-SQLAlchemy library. The most important Flask library you'll ever use.","og_image":"https://hackersandslackers.com/content/images/2019/03/flask-sqlalchemy2.jpg","og_title":"Manage Database Models with Flask-SQLAlchemy | Hackers and Slackers","twitter_description":"Connect your Flask application to a database using the Flask-SQLAlchemy library. The most important Flask library you'll ever use.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/flask-sqlalchemy2.jpg","twitter_title":"Manage Database Models with Flask-SQLAlchemy | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"By now you're surely familiar with the benefits of Python's core SQLAlchemy\nlibrary\n[https://hackersandslackers.com/pythonic-database-management-with-sqlalchemy/]:\nthe all-in-one solution for basically anything database related. Like most major\nPython libraries, SQLAlchemy has been ported into a version specifically\ncompatible with Flask, aptly named Flask-SQLAlchemy.\n\nSimilar to the core SQLAlchemy package, Flask-SQLAlchemy provides an ORM for us\nto modify application data by easily creating defined models. Regardless of what\nyour database of choice might be, Flask-SQLAlchemy will ensure that the models\nwe create in Python will translate to the syntax of our chosen database. Given\nthe ease-of-use and one-size-fits-all  nature of Flask-SQLAlchemy, it's no\nwonder that the library has been the de facto database library of choice for\nFlask since the very beginning (seriously, is there even another option?)\n\nConfiguring Flask-SQLAlchemy For Your Application\nThere are a few essential configuration variables we need to set upfront before\ninteracting with our database. As is standard, we'll be using a class defined in\n config.py  to handle our Flask config:\n\nimport os\n\n\nclass Config:\n    \"\"\"Set Flask configuration vars from .env file.\"\"\"\n    \n    # General\n    TESTING = os.environ[\"TESTING\"]\n    FLASK_DEBUG = os.environ[\"FLASK_DEBUG\"]\n\n    # Database\n    SQLALCHEMY_DATABASE_URI = os.environ.get(\"SQLALCHEMY_DATABASE_URI\")\n    SQLALCHEMY_TRACK_MODIFICATIONS = os.environ.get(\"SQLALCHEMY_TRACK_MODIFICATIONS\")\n\n\nLet's break these down:\n\n * SQLALCHEMY_DATABASE_URI: the connection string we need to connect to our\n   database. This follows the standard convention: \n   [db_type]+[db_connector]://[username]:[password]@[host]:[port]/[db_name]\n * SQLALCHEMY_ECHO: When set to 'True', Flask-SQLAlchemy will log all database\n   activity to Python's stderr for debugging purposes.\n * SQLALCHEMY_TRACK_MODIFICATIONS: Honestly, I just always set this to 'False,'\n   otherwise an obnoxious warning appears every time you run your app reminding\n   you that this option takes a lot of system resources.\n\nThose are the big ones we should worry about. If you're into some next-level\ndatabase shit, there are a few other pro-mode configuration variables which you\ncan find here [http://flask-sqlalchemy.pocoo.org/2.3/config/].\n\nBy using the exact naming conventions for the variables above, simply having\nthem in our config file will automatically configure our database connections\nfor us. We will never have to create engines, sessions, or connections.\nInitiating Flask-SQLAlchemy With Our App\nAs always, we're going to use the Flask Application Factory method\n[https://hackersandslackers.com/structuring-your-flask-app/]  for initiating our\napp. If you're unfamiliar with the term, you're going to find this tutorial to\nbe confusing and pretty much useless.\n\nThe most basic __init__.py  file for Flask applications using Flask-SQLAlchemy\nshould look like this:\n\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\n\ndb = SQLAlchemy()\n\n\ndef create_app():\n    \"\"\"Construct the core application.\"\"\"\n    app = Flask(__name__, instance_relative_config=False)\n    db.init_app(app)\n    app.config.from_object('config.Config')\n\n    with app.app_context():\n        # Imports\n        from . import routes\n        \n        # Create tables for our models\n        db.create_all()\n\n        return app\n\n\nNote the presence of db  and its location: this our database object being set as\na global  variable outside of create_app(). Inside of create_app(), on the other\nhand, contains the line db.init_app(app). Even though we've set our db object\nglobally, this means nothing until we initialize it after creating our\napplication. We accomplish this by calling init_app()  within create_app(), and\npassing our app as the parameter. Within the actual 'application context' is\nwhere we'll call create_all(), which we'll cover in a bit.\n\nIf that last paragraph sounded like total gibberish to you, you are not alone. \nThe Flask Application Factory is perhaps one of the most odd and poorly\nexplained concepts in Python software development- my best advice is to not\nbecome frustrated, take the copy + paste code above, and blindly accept the\nspoon-fed nonsense enough times until it becomes second nature. That's what I\ndid, and even as I worked through this tutorial, I still  came across obnoxious\nquirks that caught me off-guard.\n\nTake note of import we make inside of the application context called routes.\nThis is one of two files we haven't written just yet: once we create them, our\napplication file structure will look something like this:\n\nmy-app\n├── /application\n│   ├── __init__.py\n│   ├── routes.py\n│   ├── models.py\n├── .env\n├── config.py\n└── wsgi.py\n\n\nCreating Database Models\nCreate a models.py  file in our application directory. Here we'll import the db \nobject that we created in __init__.py. Now we can create database models by\ndefining classes in this file.\n\nA common example would be to start with a User  model. The first variable we\ncreate is __tablename__, which will correspond to the name of the SQL table new\nusers will be saved. Each additional variable we create within this model class\nwill correspond a column in the database:\n\nfrom . import db\n\n\nclass User(db.Model):\n    \"\"\"Model for user accounts.\"\"\"\n\n    __tablename__ = 'users'\n    id = db.Column(db.Integer,\n                   primary_key=True\n                   )\n    username = db.Column(db.String(64),\n                         index=False,\n                         unique=True,\n                         nullable=False\n                         )\n    email = db.Column(db.String(80),\n                      index=True,\n                      unique=True,\n                      nullable=False\n                      )\n    created = db.Column(db.DateTime,\n                        index=False,\n                        unique=False,\n                        nullable=False\n                        )\n    bio = db.Column(db.Text,\n                    index=False,\n                    unique=False,\n                    nullable=True\n                    )\n    admin = db.Column(db.Boolean,\n                      index=False,\n                      unique=False,\n                      nullable=False\n                      )\n    \n    def __repr__(self):\n        return '<User {}>'.format(self.username)\n\n\nEach \"column\" accepts the following attributes:\n\n * Data Type:  Accepts one of the following: String(size), Text, DateTime, Float\n   , Boolean, PickleType, or LargeBinary.\n * primary_key: Whether or not the column should serve as the primary key.\n * unique: Whether or not to enforce unique values for the column.\n * nullable: Denotes required fields.\n\nWith our first model created, you're already way closer to interacting with your\ndatabase than you might think.\n\nCreating Our First Entry\nLet's create a user in our routes.py  file.\n\nfrom flask import request, render_template, make_response\nfrom datetime import datetime as dt\nfrom flask import current_app as app\nfrom .models import db, User\n\n\n@app.route('/', methods=['GET'])\ndef entry():\n    \"\"\"Endpoint to create a user.\"\"\"\n    new_user = User(username='myuser',\n                    email='myuser@example.com',\n                    created=dt.now(),\n                    bio=\"In West Philadelphia born and raised, on the playground is where I spent most of my days\",\n                    admin=False\n                    )\n    db.session.add(new_user)\n    db.session.commit()\n    return make_response(\"User created!\")\n\n\nCheck out how easy this is! All it takes to create a user is create an instance\nof the User  class from models.py, add it to our session via \ndb.session.add(new_user), and commit the changes with db.session.commit()! Let's\nsee what happens when we run this app:\n\nUser Created!\n\n\nThat's what we like to see! If we access our database at this point, we can see\nthat this exact record was created in our users  table.\n\nQuerying Our New Data\nCreating information is dope, but how can we confirm it exists? I've added a few\nthings to routes.py  to show us what's up:\n\nfrom flask import request, render_template\nfrom datetime import datetime as dt\nfrom flask import current_app as app\nfrom .models import db, User\n\n\n@app.route('/', methods=['GET'])\ndef entry():\n    \"\"\"Endpoint to create a user.\"\"\"\n    new_user = User(username='myuser',\n                    email='myuser@example.com',\n                    created=dt.now(),\n                    bio=\"In West Philadelphia born and raised, on the playground is where I spent most of my days\",\n                    admin=False\n                    )\n    db.session.add(new_user)\n    db.session.commit()\n    users = User.query.all()\n    return render_template('users.html', users=users, title=\"Show Users\")\n\n\n  The statement User.query.all()  will return all instances of User  in our\ndatabase. I created a Jinja template to show us all records nicely:\n\n{% extends \"layout.html\" %}\n\n{% block content %}\n  {% for user in users %}\n    <ul id=\"user.username\">\n      <li>Username: {{ user.username }}</li>\n      <li>Email: {{ user.email }}</li>\n      <li>Created: {{ user.created }}</li>\n      <li>Bio: {{ user.bio }}</li>\n      <li>Admin: {{ user.admin }}</li>\n    </ul>\n  {% endfor %}\n{% endblock %}\n\n\nThus, our app gives us:\n\nWe have liftoff!So we can get a single user, but what about a whole table full\nof users? Well, all we need to do is keep changing the username and email\naddress (our unique keys, to avoid a clash) when firing up the app, and each\ntime it runs, it'll create a new user. Here's what comes back after running the\napp a few times with different values:\n\nI Can't Believe It's Not Error Messages.™Here, Take All My Stuff\nSure, Flask-SQLAlchemy is great once you get going, but as we've already seen\n\"getting set up\" isn't always a walk in the park. This is one of those things\nthat always seems to be wrong no matter how many times you've done it from\nmemory.\n\nAs a parting gift, I've put the source for this tutorial up on Github\n[https://github.com/toddbirchard/flasksqlalchemy-tutorial]  for you to treasure\nand enjoy. No seriously, take it. Get it away from me. I'm done with Flask for\ntoday. I need to go play some Rocket League.\n\nPS: Add me on PSN","html":"<p>By now you're surely familiar with the benefits of Python's <a href=\"https://hackersandslackers.com/pythonic-database-management-with-sqlalchemy/\">core SQLAlchemy library</a>: the all-in-one solution for basically anything database related. Like most major Python libraries, SQLAlchemy has been ported into a version specifically compatible with Flask, aptly named <strong>Flask-SQLAlchemy</strong>.</p><p>Similar to the core SQLAlchemy package, Flask-SQLAlchemy provides an ORM for us to modify application data by easily creating defined models. Regardless of what your database of choice might be, Flask-SQLAlchemy will ensure that the models we create in Python will translate to the syntax of our chosen database. Given the ease-of-use and one-size-fits-all  nature of Flask-SQLAlchemy, it's no wonder that the library has been the de facto database library of choice for Flask since the very beginning (seriously, is there even another option?)</p><h2 id=\"configuring-flask-sqlalchemy-for-your-application\">Configuring Flask-SQLAlchemy For Your Application</h2><p>There are a few essential configuration variables we need to set upfront before interacting with our database. As is standard, we'll be using a class defined in <code>config.py</code> to handle our Flask config:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\n\n\nclass Config:\n    &quot;&quot;&quot;Set Flask configuration vars from .env file.&quot;&quot;&quot;\n    \n    # General\n    TESTING = os.environ[&quot;TESTING&quot;]\n    FLASK_DEBUG = os.environ[&quot;FLASK_DEBUG&quot;]\n\n    # Database\n    SQLALCHEMY_DATABASE_URI = os.environ.get(&quot;SQLALCHEMY_DATABASE_URI&quot;)\n    SQLALCHEMY_TRACK_MODIFICATIONS = os.environ.get(&quot;SQLALCHEMY_TRACK_MODIFICATIONS&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>Let's break these down:</p><ul><li><code>SQLALCHEMY_DATABASE_URI</code>: the connection string we need to connect to our database. This follows the standard convention: <code>[db_type]+[db_connector]://[username]:[password]@[host]:[port]/[db_name]</code></li><li><code>SQLALCHEMY_ECHO</code>: When set to 'True', Flask-SQLAlchemy will log all database activity to Python's stderr for debugging purposes.</li><li><code>SQLALCHEMY_TRACK_MODIFICATIONS</code>: Honestly, I just always set this to 'False,' otherwise an obnoxious warning appears every time you run your app reminding you that this option takes a lot of system resources.</li></ul><p>Those are the big ones we should worry about. If you're into some next-level database shit, there are a few other pro-mode configuration variables which you can find <a href=\"http://flask-sqlalchemy.pocoo.org/2.3/config/\">here</a>.</p><!--kg-card-begin: html--><div class=\"protip\">By using the exact naming conventions for the variables above, simply having them in our config file will automatically configure our database connections for us. We will never have to create engines, sessions, or connections.</div><!--kg-card-end: html--><h2 id=\"initiating-flask-sqlalchemy-with-our-app\">Initiating Flask-SQLAlchemy With Our App</h2><p>As always, we're going to use the <a href=\"https://hackersandslackers.com/structuring-your-flask-app/\">Flask Application Factory method</a> for initiating our app. If you're unfamiliar with the term, you're going to find this tutorial to be confusing and pretty much useless.</p><p>The most basic <code>__init__.py</code> file for Flask applications using Flask-SQLAlchemy should look like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\n\ndb = SQLAlchemy()\n\n\ndef create_app():\n    &quot;&quot;&quot;Construct the core application.&quot;&quot;&quot;\n    app = Flask(__name__, instance_relative_config=False)\n    db.init_app(app)\n    app.config.from_object('config.Config')\n\n    with app.app_context():\n        # Imports\n        from . import routes\n        \n        # Create tables for our models\n        db.create_all()\n\n        return app\n</code></pre>\n<!--kg-card-end: markdown--><p>Note the presence of <code>db</code> and its location: this our database object being set as a <em>global</em> variable outside of <code>create_app()</code>. Inside of <code>create_app()</code>, on the other hand, contains the line <code>db.init_app(app)</code>. Even though we've set our db object globally, this means nothing until we initialize it after creating our application. We accomplish this by calling <code>init_app()</code> within <code>create_app()</code>, and passing our app as the parameter. Within the actual 'application context' is where we'll call <code>create_all()</code>, which we'll cover in a bit.</p><p>If that last paragraph sounded like total gibberish to you, <em>you are not alone.</em> The Flask Application Factory is perhaps one of the most odd and poorly explained concepts in Python software development- my best advice is to not become frustrated, take the copy + paste code above, and blindly accept the spoon-fed nonsense enough times until it becomes second nature. That's what I did, and even as I worked through this tutorial, I <em>still</em> came across obnoxious quirks that caught me off-guard.</p><p>Take note of import we make inside of the application context called <strong>routes</strong>. This is one of two files we haven't written just yet: once we create them, our application file structure will look something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">my-app\n├── /application\n│   ├── __init__.py\n│   ├── routes.py\n│   ├── models.py\n├── .env\n├── config.py\n└── wsgi.py\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"creating-database-models\">Creating Database Models</h2><p>Create a <code>models.py</code> file in our application directory. Here we'll import the <code>db</code> object that we created in <code>__init__.py</code>. Now we can create database models by defining classes in this file.</p><p>A common example would be to start with a <strong>User</strong> model. The first variable we create is <code>__tablename__</code>, which will correspond to the name of the SQL table new users will be saved. Each additional variable we create within this model class will correspond a column in the database:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from . import db\n\n\nclass User(db.Model):\n    &quot;&quot;&quot;Model for user accounts.&quot;&quot;&quot;\n\n    __tablename__ = 'users'\n    id = db.Column(db.Integer,\n                   primary_key=True\n                   )\n    username = db.Column(db.String(64),\n                         index=False,\n                         unique=True,\n                         nullable=False\n                         )\n    email = db.Column(db.String(80),\n                      index=True,\n                      unique=True,\n                      nullable=False\n                      )\n    created = db.Column(db.DateTime,\n                        index=False,\n                        unique=False,\n                        nullable=False\n                        )\n    bio = db.Column(db.Text,\n                    index=False,\n                    unique=False,\n                    nullable=True\n                    )\n    admin = db.Column(db.Boolean,\n                      index=False,\n                      unique=False,\n                      nullable=False\n                      )\n    \n    def __repr__(self):\n        return '&lt;User {}&gt;'.format(self.username)\n</code></pre>\n<!--kg-card-end: markdown--><p>Each \"column\" accepts the following attributes:</p><ul><li><strong>Data Type:</strong> Accepts one of the following: <code>String(size)</code>, <code>Text</code>, <code>DateTime</code>, <code>Float</code>, <code>Boolean</code>, <code>PickleType</code>, or <code>LargeBinary</code>.</li><li><strong>primary_key</strong>: Whether or not the column should serve as the primary key.</li><li><strong>unique</strong>: Whether or not to enforce unique values for the column.</li><li><strong>nullable: </strong>Denotes required fields.</li></ul><p>With our first model created, you're already way closer to interacting with your database than you might think.</p><h2 id=\"creating-our-first-entry\">Creating Our First Entry</h2><p>Let's create a user in our <code>routes.py</code> file.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import request, render_template, make_response\nfrom datetime import datetime as dt\nfrom flask import current_app as app\nfrom .models import db, User\n\n\n@app.route('/', methods=['GET'])\ndef entry():\n    &quot;&quot;&quot;Endpoint to create a user.&quot;&quot;&quot;\n    new_user = User(username='myuser',\n                    email='myuser@example.com',\n                    created=dt.now(),\n                    bio=&quot;In West Philadelphia born and raised, on the playground is where I spent most of my days&quot;,\n                    admin=False\n                    )\n    db.session.add(new_user)\n    db.session.commit()\n    return make_response(&quot;User created!&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>Check out how easy this is! All it takes to create a user is create an instance of the <code>User</code> class from <code>models.py</code>, add it to our session via <code>db.session.add(new_user)</code>, and commit the changes with <code>db.session.commit()</code>! Let's see what happens when we run this app:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">User Created!\n</code></pre>\n<!--kg-card-end: markdown--><p>That's what we like to see! If we access our database at this point, we can see that this exact record was created in our <em>users</em> table.</p><h2 id=\"querying-our-new-data\">Querying Our New Data</h2><p>Creating information is dope, but how can we confirm it exists? I've added a few things to <code>routes.py</code> to show us what's up:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import request, render_template\nfrom datetime import datetime as dt\nfrom flask import current_app as app\nfrom .models import db, User\n\n\n@app.route('/', methods=['GET'])\ndef entry():\n    &quot;&quot;&quot;Endpoint to create a user.&quot;&quot;&quot;\n    new_user = User(username='myuser',\n                    email='myuser@example.com',\n                    created=dt.now(),\n                    bio=&quot;In West Philadelphia born and raised, on the playground is where I spent most of my days&quot;,\n                    admin=False\n                    )\n    db.session.add(new_user)\n    db.session.commit()\n    users = User.query.all()\n    return render_template('users.html', users=users, title=&quot;Show Users&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p> The statement <code>User.query.all()</code> will return all instances of <code>User</code> in our database. I created a Jinja template to show us all records nicely:</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">{% extends &quot;layout.html&quot; %}\n\n{% block content %}\n  {% for user in users %}\n    &lt;ul id=&quot;user.username&quot;&gt;\n      &lt;li&gt;Username: {{ user.username }}&lt;/li&gt;\n      &lt;li&gt;Email: {{ user.email }}&lt;/li&gt;\n      &lt;li&gt;Created: {{ user.created }}&lt;/li&gt;\n      &lt;li&gt;Bio: {{ user.bio }}&lt;/li&gt;\n      &lt;li&gt;Admin: {{ user.admin }}&lt;/li&gt;\n    &lt;/ul&gt;\n  {% endfor %}\n{% endblock %}\n</code></pre>\n<!--kg-card-end: markdown--><p>Thus, our app gives us:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/04/flasksqlalchemy-test.png\" class=\"kg-image\"><figcaption>We have liftoff!</figcaption></figure><!--kg-card-end: image--><p>So we can get a single user, but what about a whole table full of users? Well, all we need to do is keep changing the username and email address (our unique keys, to avoid a clash) when firing up the app, and each time it runs, it'll create a new user. Here's what comes back after running the app a few times with different values:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2019-02-06-at-12.39.07-AM.png\" class=\"kg-image\"><figcaption>I Can't Believe It's Not Error Messages.<b>™</b></figcaption></figure><!--kg-card-end: image--><h3 id=\"here-take-all-my-stuff\">Here, Take All My Stuff</h3><p>Sure, Flask-SQLAlchemy is great once you get going, but as we've already seen \"getting set up\" isn't always a walk in the park. This is one of those things that always seems to be wrong no matter how many times you've done it from memory.</p><p>As a parting gift, I've put the source for this tutorial up <a href=\"https://github.com/toddbirchard/flasksqlalchemy-tutorial\">on Github</a> for you to treasure and enjoy. No seriously, take it. Get it away from me. I'm done with Flask for today. I need to go play some Rocket League.</p><!--kg-card-begin: html--><span style=\"color: #a7a7a7;font-style: italic;font-size:.9em;\">PS: Add me on PSN</span><!--kg-card-end: html-->","url":"https://hackersandslackers.com/manage-database-models-with-flask-sqlalchemy/","uuid":"e9fdcb15-3289-472f-8892-2e01cdaced9d","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c5a3e362c71af62216fd45e"}},{"node":{"id":"Ghost__Post__5c34086694d3e847951adf3e","title":"Poetically Packaging Your Python Project","slug":"poetic-python-project-packaging","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/01/poetry4@2x.jpg","excerpt":"Manage your projects with Poetry to handle dependencies, envs, packaging, etc.","custom_excerpt":"Manage your projects with Poetry to handle dependencies, envs, packaging, etc.","created_at_pretty":"08 January, 2019","published_at_pretty":"08 January, 2019","updated_at_pretty":"09 April, 2019","created_at":"2019-01-07T21:18:14.000-05:00","published_at":"2019-01-08T10:16:00.000-05:00","updated_at":"2019-04-09T17:59:40.000-04:00","meta_title":"Poetically Packaging Your Python Project | Hackers and Slackers","meta_description":"Manage your projects with Poetry: a dependency manager and project packager all in one. Handle your environment and project data in a single file.","og_description":"Manage your projects with Poetry to handle dependencies, envs, packaging, etc.","og_image":"https://hackersandslackers.com/content/images/2019/01/poetry4@2x.jpg","og_title":"Poetically Packaging Your Python Project","twitter_description":"Manage your projects with Poetry to handle dependencies, envs, packaging, etc.","twitter_image":"https://hackersandslackers.com/content/images/2019/01/poetry4@2x.jpg","twitter_title":"Poetically Packaging Your Python Project","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"It wasn't long ago that we Hackers were singing the praises of Pipenv\n[https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/]\n: Python's seemingly superior dependency manager at the time. While we hold much\nlove in hearts, sometimes there is love to go around. We just so happen to be\nfair weather fans, which reminds me: what has Pipenv done for me lately?\n\nAs you've probably guessed (considering its a piece of software), nothing much.\nWell, there was that time when pip upgraded from v.18  to v.18.1, which broke\nPipenv entirely with almost minimal acknowledgment (for all I know this might\nstill be broken). As our lives seemed to fade, a miracle emerged from the ashes:\na young, smart, attractive alternative to Pipenv that's been whispering in my\near, and promising the world. Her name is Poetry [https://poetry.eustace.io/].\n\nWhat Light Through Yonder GitHub Breaks?\nPoetry stems from the genuine frustration that comes with not only managing\nenvironments and dependencies in Python, but the fact that even solving this\nproblem (albeit poorly) still doesn't solve the related tasks needing\nfulfillment when creating respectable Python projects. Consider Node's \npackage.json: a single file which contains a project's metadata, prod\ndependencies, dev dependencies, contact information, etc. Instead, Python\nprojects usually come with the following:\n\nSetup.py\nIf you've never bothered to publish a package to PyPI before, there's a decent\nchance you may not be very familiar with some of the nuances that come with \nsetup.py  or why you'd bother creating one. This is a losing mentality: we\nshould assume that most (or some) of the things we build might become useful\nenough to distribute some day.\n\nThus, we get this monstrosity:\n\nfrom setuptools import setup, find_packages, tests_require, packages, name\n\nwith open(\"README\", 'r') as f:\n    long_description = f.read()\n\nsetup = (\n    name='Fake Project',\n    version='1.0',\n    description='A fake project used for example purposes.',\n    long_description=long_description,\n    author='Todd Birchard',\n    author_email='todd@hackersandslackers.com',\n    maintainer='Some Loser',\n    maintainer_email='some.loser@example.com,\n    url=\"https://github.com/toddbirchard/fake-project\",\n    license='MIT',\n    include_package_data=True,\n    package_dir={'application'}\n    packages=['distutils', 'modules'],\n    tests_require=[\"pytest\"],\n    cmdclass={\"pytest\": PyTest},\n    classifiers=[\n          'Development Status :: 2 - Beta',\n          'Environment :: Console',\n          'Environment :: Web Environment',\n          'Intended Audience :: End Users/Desktop',\n          'Intended Audience :: Developers',\n          'Intended Audience :: System Administrators',\n          'License :: OSI Approved :: Python Software Foundation License',\n          'Operating System :: MacOS :: MacOS X',\n          'Operating System :: Microsoft :: Windows',\n          'Operating System :: POSIX',\n          'Programming Language :: Python',\n          'Topic :: Communications :: Email',\n          'Topic :: Office/Business',\n          'Topic :: Software Development :: Bug Tracking',\n          ],\n)\n\n\nMany of the metadata fields are rather self-explanatory. But what about the\nfields related to package dependencies, such as package_dir or packages? Wasn't\nthis already handled in our Pipfile? On top of that, we need to specify then the\ntest suite we're using via tests_require  and cmdclass? Short answer: pretty\nmuch.\n\nSetup.cfg\nThe real joke with setup.py  is that it needs its own configuration file: yes, a\nconfiguration file for your configuration file. setup.cfg, as the name\nsuggestions, sets even more granular configurations for the things mentioned in \nsetup.py, such as how pytest  should be handled, etc. Let's not get into it, but\nhere's an example:\n\n[coverage:run]\nomit = */test/*\n\n[flake8]\nexclude = *.egg*,.env,.git,.tox,_*,build*,dist*,venv*,python2/,python3/\nignore = E261,W503\nmax-line-length = 121\n\n[tool:pytest]\nminversion = 3.2\naddopts =\n  # --fulltrace\n  # -n auto\n  --cov-config=setup.cfg\n  --cov=httplib2\n  --noconftest\n  --showlocals\n  --strict\n  --tb=short\n  --timeout=17\n  --verbose\n  -ra\n\n\nPipfile and Pipfile.lock\nIf you have been using Pipenv, you'll recognize these files as being responsible\nfor setting your Python version and dependencies. But wait- didn't we also need\nto specify dependencies in setup.py?  Yes, we did. There is no God, but if there\nwere, he'd probably hate you. Here's all the work you'd need to do creating an\nacceptable Pipfile:\n\n[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\nFlask-SQLAlchemy = \"*\"\npsycopg2 = \"*\"\npsycopg2-binary = \"*\"\nrequests = \"*\"\nconfigparser=\"*\"\nmapbox=\"*\"\nflask=\"*\"\npandas=\"*\"\nFlask-Assets=\"*\"\nlibsass=\"*\"\njsmin=\"*\"\ndash_core_components=\"*\"\ndash-table=\"*\"\ndash_html_components=\"*\"\ndash=\"*\"\nflask-session=\"*\"\nflask-redis=\"*\"\ngunicorn=\"*\"\npytest-flask=\"*\"\n\n\n[dev-packages]\n\n[requires]\npython_version = \"3.7.1\"\n\n\n\nBut wait, there's more!\n\nRequirements.txt\nBecause the Pipfile format has not been adopted as a standard for dependency\nmanagement, we still  need to create a requirements.txt file if we want to\ndeploy our application to respectable hosts such as Google App Engine  or\nwhat-have-you. So now we have this ugly son of a bitch from the stone age to\ndeal with as well:\n\natomicwrites==1.2.1\nattrs==18.2.0\nboto3==1.9.75\nbotocore==1.12.75\nCacheControl==0.12.5\ncertifi==2018.11.29\nchardet==3.0.4\nClick==7.0\nconfigparser==3.5.0\ndash==0.35.1\ndash-core-components==0.42.0\ndash-html-components==0.13.4\ndash-renderer==0.16.1\ndash-table==3.1.11\ndecorator==4.3.0\ndocutils==0.14\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Compress==1.4.0\nFlask-Redis==0.3.0\nFlask-Session==0.3.1\nFlask-SQLAlchemy==2.3.2\ngunicorn==19.9.0\nidna==2.8\nipython-genutils==0.2.0\niso3166==0.9\nitsdangerous==1.1.0\nJinja2==2.10\njmespath==0.9.3\njsmin==2.2.2\njsonschema==2.6.0\njupyter-core==4.4.0\nlibsass==0.17.0\nmapbox==0.17.2\nMarkupSafe==1.1.0\nmore-itertools==5.0.0\nmsgpack==0.6.0\nnbformat==4.4.0\nnumpy==1.15.4\npandas==0.23.4\nplotly==3.5.0\npluggy==0.8.0\npolyline==1.3.2\npsycopg2==2.7.6.1\npsycopg2-binary==2.7.6.1\npy==1.7.0\npytest==4.1.0\npytest-flask==0.14.0\npython-dateutil==2.7.5\npytz==2018.9\nredis==3.0.1\nrequests==2.21.0\nretrying==1.3.3\ns3transfer==0.1.13\nsix==1.12.0\nSQLAlchemy==1.2.15\ntraitlets==4.3.2\nuritemplate==3.0.0\nurllib3==1.24.1\nwebassets==0.12.1\nWerkzeug==0.14.1\n\n\nMANIFEST.in\nYES, THERE'S MORE. If you're not bothered by now, please leave this blog\nimmediately. The job market is ripe for neckbeards who take pleasure in\nunnecessary complexity. Until the robots take over, this blog is for humans.\n\nAnyway, there's an entire file dedicated to including files in your project\nwhich aren't code. We're entering comically ridiculous territory:\n\ninclude README.rst\ninclude docs/*.txt\ninclude funniest/data.json\n\n\nIt's a Bird! It's a Plane! Its... A Single, Sophisticated Config File?\nI hope you're thoroughly pissed off after looking back at all the things we've\nlet slide by year after year, telling ourselves that this patchwork of standards\nis just fine. Cue our hero: the creator of Poetry:\n\n> Packaging systems and dependency management in Python are rather convoluted and\nhard to understand for newcomers. Even for seasoned developers it might be\ncumbersome at times to create all files needed in a Python project: setup.py,\nrequirements.txt, setup.cfg, MANIFEST.in  and the newly added Pipfile. So I\nwanted a tool that would limit everything to a single configuration file to do:\ndependency management, packaging and publishing.\nOh God yes, but HOW?!?!\n\nIntroducing pyproject.toml\nPoetry is built around a single configuration dubbed pyproject.toml  which has\nbecome an accepted standard in the Python community\n[https://www.python.org/dev/peps/pep-0518/]  by way of PEP 518.  With the weight\nof the Python development community itself, it's safe to say this isn't another\nfad and is worth using.\n\nHere's an example .toml file from the Poetry Github repository\n[https://github.com/sdispater/poetry]:\n\n[tool.poetry]\nname = \"my-package\"\nversion = \"0.1.0\"\ndescription = \"The description of the package\"\n\nlicense = \"MIT\"\n\nauthors = [\n    \"Sébastien Eustace <sebastien@eustace.io>\"\n]\n\nreadme = 'README.md'  # Markdown files are supported\n\nrepository = \"https://github.com/sdispater/poetry\"\nhomepage = \"https://github.com/sdispater/poetry\"\n\nkeywords = ['packaging', 'poetry']\n\n[tool.poetry.dependencies]\npython = \"~2.7 || ^3.2\"  # Compatible python versions must be declared here\ntoml = \"^0.9\"\n# Dependencies with extras\nrequests = { version = \"^2.13\", extras = [ \"security\" ] }\n# Python specific dependencies with prereleases allowed\npathlib2 = { version = \"^2.2\", python = \"~2.7\", allows-prereleases = true }\n# Git dependencies\ncleo = { git = \"https://github.com/sdispater/cleo.git\", branch = \"master\" }\n\n# Optional dependencies (extras)\npendulum = { version = \"^1.4\", optional = true }\n\n[tool.poetry.dev-dependencies]\npytest = \"^3.0\"\npytest-cov = \"^2.4\"\n\n[tool.poetry.scripts]\nmy-script = 'my_package:main'\n\n\nIn addition to covering the scope of all previously mentioned files, using \npyproject.toml  with Poetry also covers:\n\n * Auto-populating the exclude  section from values found in .gitignore\n * The addition of a keywords  section to be included with the resulting PyPi\n   package\n * Support for version numbers using any syntax, such as wildcard (*)  or carrot\n   (^1.0.0)  syntax\n * Auto-detection for virtual environments, thus a global install that can be\n   used within envs\n\nCreating Poetic Art\nAre we all fired up yet? Right: let's change our workflow forever.\n\nInstallation\n  To install Poetry on OSX, use the following:\n\n$ curl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python\n\n\nThis will create an addition to your ~/.bash_profile. Restart your terminal and\nverify the installation:\n\n$ poetry --version\nPoetry 0.12.10\n\n\nCreating a New Python Project\nNavigate to whichever file path you'd like your new project to call home. To get\nstarted, all we need next is the following command:\n\npoetry new my-package\n\n\nReady for a breath of fresh air? This command generates a basic project\nstructure for you- something that's been missing from Python for a long time\nwhen compared to similar generators for Node or otherwise. The resulting project\nstructure looks as such:\n\nmy-package\n├── pyproject.toml\n├── README.rst\n├── my_package\n│   └── __init__.py\n└── tests\n    ├── __init__.py\n    └── test_my_package\n\n\nOf the beautiful things happening here, the only one we haven't touched on yet\nis Poetry's built-in integration with pytest. Oh, happy day!\n\nAlternative Interactive Installation Method\nIf you'd prefer a bit more handholding, feel free to use poetry init  in an\nempty directory (or a directory without the existing .toml  file) to be walked\nthrough the creation process:\n\n$ poetry init\n\nThis command will guide you through creating your pyproject.toml config.\n\nPackage name [my-package]: Great Package\nVersion [0.1.0]:\nDescription []: Great package for great people.\nAuthor [Todd Birchard <todd@hackersandslackers.com>, n to skip]:\nLicense []: MIT\nCompatible Python versions [^2.7]: ^3.7\n\nWould you like to define your dependencies (require) interactively? (yes/no) [yes] no\n\n\n\nWould you like to define your dev dependencies (require-dev) interactively (yes/no) [yes] no\n\nGenerated file\n\n[tool.poetry]\nname = \"Great Package\"\nversion = \"0.1.0\"\ndescription = \"Great package for great people.\"\nauthors = [\"Todd Birchard <todd@hackersandslackers.com>\"]\nlicense = \"MIT\"\n\n[tool.poetry.dependencies]\npython = \"^3.7\"\n\n[tool.poetry.dev-dependencies]\n\n[build-system]\nrequires = [\"poetry>=0.12\"]\nbuild-backend = \"poetry.masonry.api\"\n\n\nDo you confirm generation? (yes/no) [yes] yes\n\n\nManaging Dependencies in pyproject.toml\nIf you're familiar with Pipfiles, pyproject.toml handles dependencies the same\nway. Just remember that poetry install  installs your listed dependencies, and \npoetry update  will update dependencies in poetry.lock to their latest versions.\n\nCarry on my Wayward Son\nI could spend all day copy-pasting general usage from the Poetry Github page,\nbut I think my work here is done. Do yourself a favor and  take a look at the\nGithub repo [https://github.com/sdispater/poetry]  to make your life easier\nforever. Or at least until the next replacement solution comes along.","html":"<p>It wasn't long ago that we Hackers were <a href=\"https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/\">singing the praises of Pipenv</a>: Python's seemingly superior dependency manager at the time. While we hold much love in hearts, sometimes there is love to go around. We just so happen to be fair weather fans, which reminds me: what has Pipenv done for me <em>lately</em>?</p><p>As you've probably guessed (considering its a piece of software), nothing much. Well, there was that time when pip upgraded from <code>v.18</code> to <code>v.18.1</code>, which broke Pipenv entirely with almost minimal acknowledgment (for all I know this might still be broken). As our lives seemed to fade, a miracle emerged from the ashes: a young, smart, attractive alternative to Pipenv that's been whispering in my ear, and promising the world. Her name is <a href=\"https://poetry.eustace.io/\"><strong>Poetry</strong></a>.</p><h2 id=\"what-light-through-yonder-github-breaks\">What Light Through Yonder GitHub Breaks?</h2><p>Poetry stems from the genuine frustration that comes with not only managing environments and dependencies in Python, but the fact that even solving this problem (albeit poorly) still doesn't solve the related tasks needing fulfillment when creating respectable Python projects. Consider Node's <code>package.json</code>: a single file which contains a project's metadata, prod dependencies, dev dependencies, contact information, etc. Instead, Python projects usually come with the following:</p><h3 id=\"setup-py\">Setup.py</h3><p>If you've never bothered to publish a package to PyPI before, there's a decent chance you may not be very familiar with some of the nuances that come with <code>setup.py</code> or why you'd bother creating one. This is a losing mentality: we should assume that most (or some) of the things we build might become useful enough to distribute some day.</p><p>Thus, we get this monstrosity:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from setuptools import setup, find_packages, tests_require, packages, name\n\nwith open(&quot;README&quot;, 'r') as f:\n    long_description = f.read()\n\nsetup = (\n    name='Fake Project',\n    version='1.0',\n    description='A fake project used for example purposes.',\n    long_description=long_description,\n    author='Todd Birchard',\n    author_email='todd@hackersandslackers.com',\n    maintainer='Some Loser',\n    maintainer_email='some.loser@example.com,\n    url=&quot;https://github.com/toddbirchard/fake-project&quot;,\n    license='MIT',\n    include_package_data=True,\n    package_dir={'application'}\n    packages=['distutils', 'modules'],\n    tests_require=[&quot;pytest&quot;],\n    cmdclass={&quot;pytest&quot;: PyTest},\n    classifiers=[\n          'Development Status :: 2 - Beta',\n          'Environment :: Console',\n          'Environment :: Web Environment',\n          'Intended Audience :: End Users/Desktop',\n          'Intended Audience :: Developers',\n          'Intended Audience :: System Administrators',\n          'License :: OSI Approved :: Python Software Foundation License',\n          'Operating System :: MacOS :: MacOS X',\n          'Operating System :: Microsoft :: Windows',\n          'Operating System :: POSIX',\n          'Programming Language :: Python',\n          'Topic :: Communications :: Email',\n          'Topic :: Office/Business',\n          'Topic :: Software Development :: Bug Tracking',\n          ],\n)\n</code></pre>\n<!--kg-card-end: markdown--><p>Many of the metadata fields are rather self-explanatory. But what about the fields related to package dependencies, such as package_dir or packages? Wasn't this already handled in our Pipfile? On top of that, we need to specify then the test suite we're using via <strong>tests_require</strong> and <strong>cmdclass</strong>? Short answer: pretty much.</p><h3 id=\"setup-cfg\">Setup.cfg</h3><p>The real joke with <code>setup.py</code> is that it needs its own configuration file: yes, a configuration file for your configuration file. <code>setup.cfg</code>, as the name suggestions, sets even more granular configurations for the things mentioned in <code>setup.py</code>, such as how <strong>pytest</strong> should be handled, etc. Let's not get into it, but here's an example:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">[coverage:run]\nomit = */test/*\n\n[flake8]\nexclude = *.egg*,.env,.git,.tox,_*,build*,dist*,venv*,python2/,python3/\nignore = E261,W503\nmax-line-length = 121\n\n[tool:pytest]\nminversion = 3.2\naddopts =\n  # --fulltrace\n  # -n auto\n  --cov-config=setup.cfg\n  --cov=httplib2\n  --noconftest\n  --showlocals\n  --strict\n  --tb=short\n  --timeout=17\n  --verbose\n  -ra\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"pipfile-and-pipfile-lock\">Pipfile and Pipfile.lock</h3><p>If you have been using Pipenv, you'll recognize these files as being responsible for setting your Python version and dependencies. <em>But wait- didn't we also need to specify dependencies in setup.py?</em> Yes, we did. There is no God, but if there were, he'd probably hate you. Here's all the work you'd need to do creating an acceptable Pipfile:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">[[source]]\nurl = &quot;https://pypi.org/simple&quot;\nverify_ssl = true\nname = &quot;pypi&quot;\n\n[packages]\nFlask-SQLAlchemy = &quot;*&quot;\npsycopg2 = &quot;*&quot;\npsycopg2-binary = &quot;*&quot;\nrequests = &quot;*&quot;\nconfigparser=&quot;*&quot;\nmapbox=&quot;*&quot;\nflask=&quot;*&quot;\npandas=&quot;*&quot;\nFlask-Assets=&quot;*&quot;\nlibsass=&quot;*&quot;\njsmin=&quot;*&quot;\ndash_core_components=&quot;*&quot;\ndash-table=&quot;*&quot;\ndash_html_components=&quot;*&quot;\ndash=&quot;*&quot;\nflask-session=&quot;*&quot;\nflask-redis=&quot;*&quot;\ngunicorn=&quot;*&quot;\npytest-flask=&quot;*&quot;\n\n\n[dev-packages]\n\n[requires]\npython_version = &quot;3.7.1&quot;\n\n</code></pre>\n<!--kg-card-end: markdown--><p>But wait, there's more!</p><h3 id=\"requirements-txt\">Requirements.txt</h3><p>Because the Pipfile format has not been adopted as a standard for dependency management, we <em>still</em> need to create a requirements.txt file if we want to deploy our application to respectable hosts such as <strong>Google App Engine</strong> or what-have-you. So now we have this ugly son of a bitch from the stone age to deal with as well:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">atomicwrites==1.2.1\nattrs==18.2.0\nboto3==1.9.75\nbotocore==1.12.75\nCacheControl==0.12.5\ncertifi==2018.11.29\nchardet==3.0.4\nClick==7.0\nconfigparser==3.5.0\ndash==0.35.1\ndash-core-components==0.42.0\ndash-html-components==0.13.4\ndash-renderer==0.16.1\ndash-table==3.1.11\ndecorator==4.3.0\ndocutils==0.14\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Compress==1.4.0\nFlask-Redis==0.3.0\nFlask-Session==0.3.1\nFlask-SQLAlchemy==2.3.2\ngunicorn==19.9.0\nidna==2.8\nipython-genutils==0.2.0\niso3166==0.9\nitsdangerous==1.1.0\nJinja2==2.10\njmespath==0.9.3\njsmin==2.2.2\njsonschema==2.6.0\njupyter-core==4.4.0\nlibsass==0.17.0\nmapbox==0.17.2\nMarkupSafe==1.1.0\nmore-itertools==5.0.0\nmsgpack==0.6.0\nnbformat==4.4.0\nnumpy==1.15.4\npandas==0.23.4\nplotly==3.5.0\npluggy==0.8.0\npolyline==1.3.2\npsycopg2==2.7.6.1\npsycopg2-binary==2.7.6.1\npy==1.7.0\npytest==4.1.0\npytest-flask==0.14.0\npython-dateutil==2.7.5\npytz==2018.9\nredis==3.0.1\nrequests==2.21.0\nretrying==1.3.3\ns3transfer==0.1.13\nsix==1.12.0\nSQLAlchemy==1.2.15\ntraitlets==4.3.2\nuritemplate==3.0.0\nurllib3==1.24.1\nwebassets==0.12.1\nWerkzeug==0.14.1\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"manifest-in\">MANIFEST.in</h3><p>YES, THERE'S MORE. If you're not bothered by now, please leave this blog immediately. The job market is ripe for neckbeards who take pleasure in unnecessary complexity. Until the robots take over, this blog is for humans.</p><p>Anyway, there's an entire file dedicated to including files in your project which aren't code. We're entering comically ridiculous territory:</p><!--kg-card-begin: markdown--><pre><code class=\"language-ini\">include README.rst\ninclude docs/*.txt\ninclude funniest/data.json\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"it-s-a-bird-it-s-a-plane-its-a-single-sophisticated-config-file\">It's a Bird! It's a Plane! Its... A Single, Sophisticated Config File?</h2><p>I hope you're thoroughly pissed off after looking back at all the things we've let slide by year after year, telling ourselves that this patchwork of standards is just fine. Cue our hero: the creator of Poetry:</p><blockquote>Packaging systems and dependency management in Python are rather convoluted and hard to understand for newcomers. Even for seasoned developers it might be cumbersome at times to create all files needed in a Python project: <code>setup.py</code>,<code>requirements.txt</code>, <code>setup.cfg</code>, <code>MANIFEST.in</code> and the newly added <code>Pipfile</code>. So I wanted a tool that would limit everything to a single configuration file to do: dependency management, packaging and publishing.</blockquote><p>Oh God yes, but HOW?!?!</p><h3 id=\"introducing-pyproject-toml\">Introducing pyproject.toml</h3><p>Poetry is built around a single configuration dubbed <code>pyproject.toml</code> which has become an <a href=\"https://www.python.org/dev/peps/pep-0518/\">accepted standard in the Python community</a> by way of <strong>PEP 518.</strong> With the weight of the Python development community itself, it's safe to say this isn't another fad and is worth using.</p><p>Here's an example <strong>.toml </strong>file from the <a href=\"https://github.com/sdispater/poetry\">Poetry Github repository</a>:</p><!--kg-card-begin: markdown--><pre><code class=\"language-toml\">[tool.poetry]\nname = &quot;my-package&quot;\nversion = &quot;0.1.0&quot;\ndescription = &quot;The description of the package&quot;\n\nlicense = &quot;MIT&quot;\n\nauthors = [\n    &quot;Sébastien Eustace &lt;sebastien@eustace.io&gt;&quot;\n]\n\nreadme = 'README.md'  # Markdown files are supported\n\nrepository = &quot;https://github.com/sdispater/poetry&quot;\nhomepage = &quot;https://github.com/sdispater/poetry&quot;\n\nkeywords = ['packaging', 'poetry']\n\n[tool.poetry.dependencies]\npython = &quot;~2.7 || ^3.2&quot;  # Compatible python versions must be declared here\ntoml = &quot;^0.9&quot;\n# Dependencies with extras\nrequests = { version = &quot;^2.13&quot;, extras = [ &quot;security&quot; ] }\n# Python specific dependencies with prereleases allowed\npathlib2 = { version = &quot;^2.2&quot;, python = &quot;~2.7&quot;, allows-prereleases = true }\n# Git dependencies\ncleo = { git = &quot;https://github.com/sdispater/cleo.git&quot;, branch = &quot;master&quot; }\n\n# Optional dependencies (extras)\npendulum = { version = &quot;^1.4&quot;, optional = true }\n\n[tool.poetry.dev-dependencies]\npytest = &quot;^3.0&quot;\npytest-cov = &quot;^2.4&quot;\n\n[tool.poetry.scripts]\nmy-script = 'my_package:main'\n</code></pre>\n<!--kg-card-end: markdown--><p>In addition to covering the scope of all previously mentioned files, using <strong>pyproject.toml</strong> with Poetry also covers:</p><ul><li>Auto-populating the <strong>exclude</strong> section from values found in <code>.gitignore</code></li><li>The addition of a <strong>keywords</strong> section to be included with the resulting PyPi package</li><li>Support for version numbers using any syntax, such as <strong>wildcard (*)</strong> or <strong>carrot (^1.0.0)</strong> syntax</li><li>Auto-detection for virtual environments, thus a global install that can be used within envs</li></ul><h2 id=\"creating-poetic-art\">Creating Poetic Art</h2><p>Are we all fired up yet? Right: let's change our workflow forever.</p><h3 id=\"installation\">Installation</h3><p> To install Poetry on OSX, use the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ curl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python\n</code></pre>\n<!--kg-card-end: markdown--><p>This will create an addition to your <code>~/.bash_profile</code>. Restart your terminal and verify the installation:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ poetry --version\nPoetry 0.12.10\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"creating-a-new-python-project\">Creating a New Python Project</h3><p>Navigate to whichever file path you'd like your new project to call home. To get started, all we need next is the following command:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">poetry new my-package\n</code></pre>\n<!--kg-card-end: markdown--><p>Ready for a breath of fresh air? This command generates a basic project structure for you- something that's been missing from Python for a long time when compared to similar generators for Node or otherwise. The resulting project structure looks as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">my-package\n├── pyproject.toml\n├── README.rst\n├── my_package\n│   └── __init__.py\n└── tests\n    ├── __init__.py\n    └── test_my_package\n</code></pre>\n<!--kg-card-end: markdown--><p>Of the beautiful things happening here, the only one we haven't touched on yet is Poetry's built-in integration with <strong>pytest</strong>. Oh, happy day!</p><h4 id=\"alternative-interactive-installation-method\">Alternative Interactive Installation Method</h4><p>If you'd prefer a bit more handholding, feel free to use <code>poetry init</code> in an empty directory (or a directory without the existing <strong>.toml</strong> file) to be walked through the creation process:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ poetry init\n\nThis command will guide you through creating your pyproject.toml config.\n\nPackage name [my-package]: Great Package\nVersion [0.1.0]:\nDescription []: Great package for great people.\nAuthor [Todd Birchard &lt;todd@hackersandslackers.com&gt;, n to skip]:\nLicense []: MIT\nCompatible Python versions [^2.7]: ^3.7\n\nWould you like to define your dependencies (require) interactively? (yes/no) [yes] no\n\n\n\nWould you like to define your dev dependencies (require-dev) interactively (yes/no) [yes] no\n\nGenerated file\n\n[tool.poetry]\nname = &quot;Great Package&quot;\nversion = &quot;0.1.0&quot;\ndescription = &quot;Great package for great people.&quot;\nauthors = [&quot;Todd Birchard &lt;todd@hackersandslackers.com&gt;&quot;]\nlicense = &quot;MIT&quot;\n\n[tool.poetry.dependencies]\npython = &quot;^3.7&quot;\n\n[tool.poetry.dev-dependencies]\n\n[build-system]\nrequires = [&quot;poetry&gt;=0.12&quot;]\nbuild-backend = &quot;poetry.masonry.api&quot;\n\n\nDo you confirm generation? (yes/no) [yes] yes\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"managing-dependencies-in-pyproject-toml\">Managing Dependencies in pyproject.toml</h2><p>If you're familiar with Pipfiles, pyproject.toml handles dependencies the same way. Just remember that <code>poetry install</code> installs your listed dependencies, and <code>poetry update</code> will update dependencies in <em>poetry.lock </em>to their latest versions.</p><h3 id=\"carry-on-my-wayward-son\">Carry on my Wayward Son</h3><p>I could spend all day copy-pasting general usage from the Poetry Github page, but I think my work here is done. Do yourself a favor and<a href=\"https://github.com/sdispater/poetry\"> take a look at the Github repo</a> to make your life easier forever. Or at least until the next replacement solution comes along.</p>","url":"https://hackersandslackers.com/poetic-python-project-packaging/","uuid":"10ddf06a-b12f-40b4-9849-2b057d3fe2f4","page":false,"codeinjection_foot":null,"codeinjection_head":"<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@glorious/demo/dist/gdemo.min.css\">\n<script src=\"https://cdn.jsdelivr.net/npm/@glorious/demo/dist/gdemo.min.js\"></script>\n","comment_id":"5c34086694d3e847951adf3e"}},{"node":{"id":"Ghost__Post__5c307c9493bed0776a0a3d80","title":"Using Redis to Store Information in Python Applications","slug":"using-redis-with-python","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/redis-1-2.jpg","excerpt":"A temporary data store for everything from session variables to chat queues.","custom_excerpt":"A temporary data store for everything from session variables to chat queues.","created_at_pretty":"05 January, 2019","published_at_pretty":"05 January, 2019","updated_at_pretty":"28 March, 2019","created_at":"2019-01-05T04:44:52.000-05:00","published_at":"2019-01-05T08:21:00.000-05:00","updated_at":"2019-03-28T05:41:12.000-04:00","meta_title":"Using Redis to Store Information in Python Apps | Hackers and Slackers","meta_description":"Take the guesswork out of storing values in memory: use Redis in your Python stack to have full control over session variables.","og_description":"Take the guesswork out of storing values in memory: use Redis in your Python stack to have full control over session variables.","og_image":"https://hackersandslackers.com/content/images/2019/03/redis-1-2.jpg","og_title":"Using Redis to Store Information in Python Applications","twitter_description":"Take the guesswork out of storing values in memory: use Redis in your Python stack to have full control over session variables.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/redis-1-1.jpg","twitter_title":"Using Redis to Store Information in Python Applications","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"We’re hacking into the new year here at Hackers and Slackers, and in the\nprocess, we’ve received plenty of new gifts to play with. Nevermind how Santa\nmanages to fit physically non-existent SaaS products under the Christmas tree.\nWe ask for abstract enterprise software every year, and this time we happened to\nget a little red box.\n\nIf you've never personally used Redis, the name probably sounds familiar as\nyou've been bombarded with obscure technology brand names in places like the\nHeroku marketplace, or your unacceptably nerdy Twitter account (I assure you,\nmine is worse). So what is Redis, you ask? Well, it's a NoSQL datasto- wait,\nwhere are you... NO! Don't leave! It's not like THAT, I swear!\n\nWhat Redis is and When to Use It\nRedis stores information in the familiar key/value pair format, but the term\n‘NoSQL’ is more of a technicality than an indicator of use cases synonymous with\nNoSQL databases of the past. Redis looks the part for the very purpose it\nserves: a box that you fill with crap which may or may not be important down the\nline. It’s the perfect place to put a Starbucks gift card or the clothes you’ve\nalready worn which aren’t quite ready to be washed yet.\n\nAll Users go to Heaven: Cloud Storage for User Sessions\nPerhaps the most common use case is a glorified session cache. Similar to the\nway users might store temporary app information in cookies, Redis holds on to\ninformation which is fleeting. The difference is we now own this information\ninside our very own box, thus the Redis motto: “your box, your rules.”* \n\n* I made this up: it holds zero truth.Because temporary user information is in\nour hands as opposed to a fickle browser, we can decide just how  temporary our\n“cache” is, having it persist across sessions or even devices. While local\nmemory storage may as well be a place for throwaway information, and databases\nfor persistent or eternal information, Redis is somewhere in between. As users\ninteract and the information they create within our app evolves, we may choose\nat any point to promote information stored in Redis to a database, or perhaps\nhave it stick around a little while longer. They’ll be thrilled to see their\nshopping cart still filled with the stupid things they almost bought while they\nwere drunk yesterday.\n\nWhen Variables are on a Bagel, You can Have Variables Any Time \nIn other words, Redis is great for solving the need of globally accessible\nvariables throughout an entire application, on a per-user basis. Users who\naccidentally quit your app, move to a new context, or merely use your app for\nlonger than your QA team are easier to manage when their temporary information\nis in a safe and global environment. Compare this to saving a user’s Pac-Man\nscore to a global variable:  the moment an app like Pac-Man crashes or restarts,\nthat session is gone forever. Thus dies another three-letter app obscenity\nbelonging to a leaderboard.\n\nSpeaking of Leaderboards...\nRedis is great at counting in increments. This is probably made evident by the\nfact that it is a computer, and these are the things computers do. Something\nelse that’s made great by counting: queues! Cues of tasks, notifications, chats,\ndisappearing naked photos, etc: all of these things are ideally suited for our\nred box.\n\nGetting a Red Box of Your Own\nPlaying around with a cloud-hosted Redis box will cost you maybe 5 bucks\n(monthly if you forget to cancel). Redis is open source so there are plenty of\nvendors to choose from with little differentiation between them. I’ll consider\nrecommending whichever vendor offers to bribe me the most, but in the meantime\nI’ll leave the window shopping to you.\n\nSetting up Redis should feel like setting up a cloud SQL database, except\nsmaller and cuter. You’ll be able to pick adorable features for your box of\npossibly-but-not-surely-worthless stuff, such as hosted region, etc. Once you're\nset up you should have a host URL for reaching your instance:\n\nredis-1738.c62.us-east-1-4.ec2.cloud.fakeredisprovider.com:42069\n\nNow we’re cooking with gas.\n\nUsing the redis-py Python Library\nThe main Python Redis library is typed as redis, as in pip install Redis. The\neasiest way to connect in any case is via a URI connection string, like such:\n\nr = redis.Redis( url='rediss://:password@hostname:port/0')\n\n\nNote the unique structure of the URI above:\n\n * rediss://: precedes all Redis URIs; NOTE THE TRAILING COLON.\n * password  comes next, with the interesting choice to bypass usernames.\n * hostname  is the instance's URL... almost always a thinly veiled repurposed\n   EC2 instance. That's right, we're being sold simple open source software\n   hosted on AWS. Don't think about it.\n * port is your preferred port of call after pillaging British trade ships. Just\n   making sure you're still here.\n * /database brings up the rear, which is the name of your database.\n\nAs with regular databases, other connection methods exist such as via SSL\ncertificates, etc.\n\nStoring and Getting Values\nThis is your bread and butter for interacting with Redis:\n\n * .set():  Set a key/value pair by either overwriting or creating a new value\n * .get():  Retrieve a value by naming the associated key\n * hmget():  Accepts a variable number of keys, and will return values for each\n   if they exist\n * hmset():  Set multiple values to a single key.\n * hgetall():  Get all values for a key where a key has been assigned multiple\n   values.\n\nIt’s important to note that Redis by default returns bytes as opposed to\nstrings. As a result, it is important to remember the encoding/decoding of\nvalues in order to retrieve them properly. For example:\n\n# Setting a Value\nr.set('uri', str(app.config['SQLALCHEMY_DATABASE_URI']).encode('utf-8'))\n\n# Getting a Value\nr.get('uri').decode('utf-8')\n\n\nIf you happen to be remotely sane, you probably don't want to deal with encoding\nand decoding values over and again. Luckily we can ensure that responses are\nalways decoded for us by setting the decode_responses  parameter to True  when\nsetting up our Redis instance:\n\nredis.StrictRedis(host=\"localhost\", port=6379, charset=\"utf-8\", decode_responses=True)\n\n\nThe redis-py documentation [https://redis-py.readthedocs.io/en/latest/] \nactually goes wayyy deeper than the 5 methods listed above. If you ever somehow\nmanage to cover all of it, I have many questions about the type of person you\nare.\n\nMore Redis Libraries for Python\nIf the above encoding/decoding seems annoying, you aren’t the first. That’s why\nlibraries like Redisworks [https://github.com/seperman/redisworks]  exist.\nRedisworks allows for the seamless exchange of Python data types to and from\nRedis. Want to shove a Python dict down your box’s throat? Go ahead! You won’t\neven have to think about it very hard. There are plenty of similar libraries all\naimed to make sad lives easier.\n\nWant more? How about Asyncio’s very own asynchronous Redis library\n[https://asyncio-redis.readthedocs.io/en/latest/]?  Or how about the similar \naioredis [aioredis.readthedocs.org], another Asyncio Redis plug-in, which also\nincludes pure Python parsing, clustering support, and things I don’t even\nunderstand! There are truly more Python libraries for Redis\n[https://redis.io/clients#python]  than you could need.\n\nFinally, how could we ever forget Flask-Redis? We’ve already covered this\n[https://hackersandslackers.com/demystifying-flasks-application-context/], but\nis easily the first and last Redis library any Flask developer will use.\n\nYour Box, Your Treasure, Your World™\nNow that we’ve uncovered this niche between cached data and stored data, the\npossibilities are endless. The world is your oyster full of things which you may\nor may not choose to shove in your box.\n\nOk, fine. Perhaps this whole concept feels like a bit of an obscure niche hardly\nworthy of the words on this page. Just remember that feeling when the time comes\nthat you too need a little red cube, and it will be waiting with love and\ncompassion. A companion cube, if you will.","html":"<p>We’re hacking into the new year here at Hackers and Slackers, and in the process, we’ve received plenty of new gifts to play with. Nevermind how Santa manages to fit physically non-existent SaaS products under the Christmas tree. We ask for abstract enterprise software every year, and this time we happened to get a little red box.</p><p>If you've never personally used Redis, the name probably sounds familiar as you've been bombarded with obscure technology brand names in places like the Heroku marketplace, or your unacceptably nerdy Twitter account (I assure you, mine is worse). So what is Redis, you ask? Well, it's a NoSQL datasto- wait, where are you... NO! Don't leave! It's not like THAT, I swear!</p><h2 id=\"what-redis-is-and-when-to-use-it\">What Redis is and When to Use It</h2><p>Redis stores information in the familiar key/value pair format, but the term ‘NoSQL’ is more of a technicality than an indicator of use cases synonymous with NoSQL databases of the past. Redis looks the part for the very purpose it serves: a box that you fill with crap which may or may not be important down the line. It’s the perfect place to put a Starbucks gift card or the clothes you’ve already worn which aren’t quite ready to be washed yet.</p><h3 id=\"all-users-go-to-heaven-cloud-storage-for-user-sessions\">All Users go to Heaven: Cloud Storage for User Sessions</h3><p>Perhaps the most common use case is a glorified <strong>session cache</strong>. Similar to the way users might store temporary app information in cookies, Redis holds on to information which is fleeting. The difference is we now own this information inside our very own box, thus the Redis motto: “<em>your box, your rules</em>.”* </p><!--kg-card-begin: html--><span style=\"color:#9DA0A0;font-style:italic;margin-bottom:30px;display:block;text-align:right;width:100%;\">* I made this up: it holds zero truth.</span><!--kg-card-end: html--><p>Because temporary user information is in our hands as opposed to a fickle browser, we can decide just <em>how</em> temporary our “cache” is, having it persist across sessions or even devices. While local memory storage may as well be a place for throwaway information, and databases for persistent or eternal information, Redis is somewhere in between. As users interact and the information they create within our app evolves, we may choose at any point to promote information stored in Redis to a database, or perhaps have it stick around a little while longer. They’ll be thrilled to see their shopping cart still filled with the stupid things they almost bought while they were drunk yesterday.</p><h3 id=\"when-variables-are-on-a-bagel-you-can-have-variables-any-time\">When Variables are on a Bagel, You can Have Variables Any Time </h3><p>In other words, Redis is great for solving the need of globally accessible variables throughout an entire application, on a per-user basis. Users who accidentally quit your app, move to a new context, or merely use your app for longer than your QA team are easier to manage when their temporary information is in a safe and global environment. Compare this to saving a user’s Pac-Man score to a global variable:  the moment an app like Pac-Man crashes or restarts, that session is gone forever. Thus dies another three-letter app obscenity belonging to a leaderboard.</p><h3 id=\"speaking-of-leaderboards-\">Speaking of Leaderboards...</h3><p>Redis is great at counting in increments. This is probably made evident by the fact that it is a computer, and these are the things computers do. Something else that’s made great by counting: queues! Cues of tasks, notifications, chats, disappearing naked photos, etc: all of these things are ideally suited for our red box.</p><h2 id=\"getting-a-red-box-of-your-own\">Getting a Red Box of Your Own</h2><p>Playing around with a cloud-hosted Redis box will cost you maybe 5 bucks (monthly if you forget to cancel). Redis is open source so there are plenty of vendors to choose from with little differentiation between them. I’ll consider recommending whichever vendor offers to bribe me the most, but in the meantime I’ll leave the window shopping to you.</p><p>Setting up Redis should feel like setting up a cloud SQL database, except smaller and cuter. You’ll be able to pick adorable features for your box of possibly-but-not-surely-worthless stuff, such as hosted region, etc. Once you're set up you should have a host URL for reaching your instance:</p><!--kg-card-begin: code--><pre><code>redis-1738.c62.us-east-1-4.ec2.cloud.fakeredisprovider.com:42069</code></pre><!--kg-card-end: code--><p>Now we’re cooking with gas.</p><h2 id=\"using-the-redis-py-python-library\">Using the redis-py Python Library</h2><p>The main Python Redis library is typed as <code>redis</code>, as in <code>pip install Redis</code>. The easiest way to connect in any case is via a URI connection string, like such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">r = redis.Redis( url='rediss://:password@hostname:port/0')\n</code></pre>\n<!--kg-card-end: markdown--><p>Note the unique structure of the URI above:</p><ul><li><strong>rediss://: </strong>precedes all Redis URIs; <em>NOTE THE TRAILING COLON.</em></li><li><strong>password</strong> comes next, with the interesting choice to bypass usernames.</li><li><strong>hostname</strong> is the instance's URL... almost always a thinly veiled repurposed EC2 instance. That's right, we're being sold simple open source software hosted on AWS. Don't think about it.</li><li><strong>port </strong>is your preferred port of call after pillaging British trade ships. Just making sure you're still here.</li><li><strong>/database </strong>brings up the rear, which is the name of your database.</li></ul><p>As with regular databases, other connection methods exist such as via SSL certificates, etc.</p><h3 id=\"storing-and-getting-values\">Storing and Getting Values</h3><p>This is your bread and butter for interacting with Redis:</p><ul><li><strong>.set():</strong> Set a key/value pair by either overwriting or creating a new value</li><li><strong>.get():</strong> Retrieve a value by naming the associated key</li><li><strong>hmget():</strong> Accepts a variable number of keys, and will return values for each if they exist</li><li><strong>hmset():</strong> Set multiple values to a single key.</li><li><strong>hgetall():</strong> Get all values for a key where a key has been assigned multiple values.</li></ul><p>It’s important to note that Redis by default returns bytes as opposed to strings. As a result, it is important to remember the encoding/decoding of values in order to retrieve them properly. For example:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># Setting a Value\nr.set('uri', str(app.config['SQLALCHEMY_DATABASE_URI']).encode('utf-8'))\n\n# Getting a Value\nr.get('uri').decode('utf-8')\n</code></pre>\n<!--kg-card-end: markdown--><p>If you happen to be remotely sane, you probably don't want to deal with encoding and decoding values over and again. Luckily we can ensure that responses are always decoded for us by setting the <code>decode_responses</code> parameter to <code>True</code> when setting up our Redis instance:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">redis.StrictRedis(host=&quot;localhost&quot;, port=6379, charset=&quot;utf-8&quot;, decode_responses=True)\n</code></pre>\n<!--kg-card-end: markdown--><p>The <a href=\"https://redis-py.readthedocs.io/en/latest/\" rel=\"noopener\"><strong>redis-py</strong> documentation</a> actually goes wayyy deeper than the 5 methods listed above. If you ever somehow manage to cover all of it, I have many questions about the type of person you are.</p><h2 id=\"more-redis-libraries-for-python\">More Redis Libraries for Python</h2><p>If the above encoding/decoding seems annoying, you aren’t the first. That’s why libraries like <a href=\"https://github.com/seperman/redisworks\" rel=\"noopener\"><strong>Redisworks</strong></a> exist. Redisworks allows for the seamless exchange of Python data types to and from Redis. Want to shove a Python dict down your box’s throat? Go ahead! You won’t even have to think about it very hard. There are plenty of similar libraries all aimed to make sad lives easier.</p><p>Want more? How about Asyncio’s very own <a href=\"https://asyncio-redis.readthedocs.io/en/latest/\">asynchronous Redis library</a>?  Or how about the similar <strong><a href=\"aioredis.readthedocs.org\">aioredis</a></strong>, another Asyncio Redis plug-in, which also includes pure Python parsing, clustering support, and things I don’t even understand! There are truly <a href=\"https://redis.io/clients#python\">more Python libraries for Redis</a> than you could need.</p><p>Finally, how could we ever forget <strong>Flask-Redis</strong>? We’ve <a href=\"https://hackersandslackers.com/demystifying-flasks-application-context/\" rel=\"noopener\">already covered this</a>, but is easily the first and last Redis library any Flask developer will use.</p><h2 id=\"your-box-your-treasure-your-world-\">Your Box, Your Treasure, Your World<strong>™</strong></h2><p>Now that we’ve uncovered this niche between cached data and stored data, the possibilities are endless. The world is your oyster full of things which you may or may not choose to shove in your box.</p><p>Ok, fine. Perhaps this whole concept feels like a bit of an obscure niche hardly worthy of the words on this page. Just remember that feeling when the time comes that you too need a little red cube, and it will be waiting with love and compassion. A companion cube, if you will.</p>","url":"https://hackersandslackers.com/using-redis-with-python/","uuid":"fcf41325-f7d3-4f3f-b43f-8609e5dc6b07","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c307c9493bed0776a0a3d80"}},{"node":{"id":"Ghost__Post__5c1af93bffe54a660c58b85a","title":"Cracking Full Control Over Plot.ly Dash","slug":"gaining-full-control-over-plotly-dash","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/Dash@2x.jpg","excerpt":"Build apps with Plot.ly Dash on your own terms","custom_excerpt":"Build apps with Plot.ly Dash on your own terms","created_at_pretty":"20 December, 2018","published_at_pretty":"20 December, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-12-19T21:06:51.000-05:00","published_at":"2018-12-20T14:58:00.000-05:00","updated_at":"2019-03-28T05:19:31.000-04:00","meta_title":"Cracking Full Control Over Plot.ly Dash | Hackers and Slackers","meta_description":"Build apps with Plot.ly Dash on your own terms. Extend Flask functionality with Dash, not the other way around.","og_description":"Build apps with Plot.ly Dash on your own terms. Extend Flask functionality with Dash, not the other way around.","og_image":"https://hackersandslackers.com/content/images/2018/12/Dash@2x.jpg","og_title":"Cracking Full Control Over Plot.ly Dash","twitter_description":"Build apps with Plot.ly Dash on your own terms. Extend Flask functionality with Dash, not the other way around.","twitter_image":"https://hackersandslackers.com/content/images/2018/12/Dash@2x.jpg","twitter_title":"Cracking Full Control Over Plot.ly Dash","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Plotly","slug":"plotly","description":"Get intimate with a staple product in data visualization. Create charts with Plot.ly's core product, or become a pro with Plot.ly Dash.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Dash.jpg","meta_description":"Get intimate with a staple product in data visualization. Create charts with Plot.ly's core product, or become a pro with Plot.ly Dash.","meta_title":"Plotly for Data Visualization | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Plotly","slug":"plotly","description":"Get intimate with a staple product in data visualization. Create charts with Plot.ly's core product, or become a pro with Plot.ly Dash.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Dash.jpg","meta_description":"Get intimate with a staple product in data visualization. Create charts with Plot.ly's core product, or become a pro with Plot.ly Dash.","meta_title":"Plotly for Data Visualization | Hackers and Slackers","visibility":"public"},{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Data Vis","slug":"datavis","description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Primarily focused on programmatic visualization as opposed to Business Intelligence software.","feature_image":null,"meta_description":"Visualize your data with charting tools like Matplotlib, Plotly, D3, Chart.js, Muze, Seaborn, and countless others. Focused on programmatic visualization.","meta_title":"Data Visualization | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Using Plotly Dash Like a Pro","slug":"plotly-dash","description":"Push the limits of Plot.ly Dash to create data-driven applications with ease. Take on Python, Pandas, Flask, and Data Visualization all at once.","feature_image":"https://hackersandslackers.com/content/images/2019/03/Dash.jpg","meta_description":"Push the limits of Plot.ly Dash to create data-driven applications with ease. Take on Python, Pandas, Flask, and Data Visualization all at once.","meta_title":"Using Plotly Dash Like a Pro","visibility":"internal"}],"plaintext":"Ahh, Plot.ly [http://plot.ly/]; typing that name into a post headline triggers\nan emotional cocktail of pride and embarrassment. Over the years Plotly has been\nat the core of some of the most influential products I’ve worked on: a\nhodgepodge of Fintech and humanitarian clients, all of which are still proudly\nwaving their charts and dashboards around the world. Yet, my mind is boggled by\na simple question: what the hell  took us so long to write our first post about\nPlotly? We've been operating Hackers and Slackers for over a full year now...\ndid I seriously write a  post about JQuery\n[https://hackersandslackers.com/making-ajax-calls-with-jquery/]  in that time\nbefore reaching this point?\n\nMuch has changed in the last year or so for our friends in Montreal. Number 1 in\nmy book is the price reduction of their core product: from 300 dollars  to zero.\nI paid the 300 dollars. We really need to get a “donate” button around here. \n\nA close second is undoubtedly the introduction of Plot.ly Dash\n[https://plot.ly/products/dash/]. Dash  tickles a sentiment which has danced\nthrough many young and helplessly naïve Pythonistas' minds: what if we could\nwrite only  in Python, like, forever?  As awful of an idea it is to start\nGoogling Python-to-frontend code interpreters (they exist; I checked), Plotly's\nDash does a shockingly good job of breathing life into that romantic fantasy of\ncommitting to Python forever.\n\nBut we're not here to deliver a recycled 'What is Plotly?'  synopsis. We're not\neven interested in the obligatory 'How to Get Started Using This\nAlready-Well-Documented-Technology' post. Plotly deserves better than that.\nInstead, we're coming hot out of the gate swinging: we're going to show you how\nto beat Plotly down, break it, and make it bend to your will. Welcome to a\nmagical edition of Hacking Plotly. It must be Christmas, folks.\n\nLet's Make a Plotly + Flask Lovechild from Hell\nLike almost every single advancement to come out of Python-geared architecture\nthis year, Dash has a little secret: it's gotten here with a little help from\nFlask. Alright, perhaps more than a little: Dash actually extends Flask. Sounds\nsensible, and perhaps even exciting at first; its almost as though every crush\nyou've ever had decided it be best to simply put their differences aside to\nstart a group chat with you in the interest of making your sexual well-being an\nequal team effort out of sheer love. As you've already guessed, life doesn't\nwork like that.\n\nDash hijacks Flask from the beginning, starting with the way we instantiate the\napp. Any code monkey who has laid eyes upon a wsgi.py file can tell you\nsomething is up before you can even say app = dash.Dash(__name__). Check out the\nrecommended startup boilerplate:\n\nfrom dash import Dash\nimport dash_core_components as dcc\nimport dash_html_components as html\n\nexternal_stylesheets = ['https://codepen.io/fgdsgfhgfh/pen/IHvjvb.css']\n\napp = Dash(__name__, external_stylesheets=external_stylesheets)\n\napp.layout = html.Div(\n        id='example-div-element'\n        )\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n\n\nIf you were to attempt to take this boilerplate and attempt to add core Flask\nlogic, such as authentication with Flask-Login, generating assets with \nFlask-Assets, or just creating a global database, where would you start? Plotly\ncleverly suggests reserving the app  namespace for your app- the very same that\nwe would do with Flask. Yet if we attempt to modify the app  object the same as\nwe would with Flask, nothing will work: Dash has declared an ecosystem, and\nnowhere in that ecosystem are you invited to add custom Flask application logic\nout of the box.\n\nDash does what it was intended to do very well: building dashboard-based\napplications. The issue is that applications which can only display data  aren't\nentirely useful as end products. What if we wanted to create a fully-featured\napp, where data visualization was simply a feature  of said app?\n\nCreating a Fully-Featured App (Where Data Vis is Simply a Feature of Said App)\nA common \"workaround\" you'll find in the community is passing Flask to Dash as\nthe underlying \"server\", something like this:\n\nfrom flask import Flask\nfrom dash import Dash\nimport dash_core_components as dcc\nimport dash_html_components as html\n\nserver = Flask(__name__)\napp = dash.Dash(__name__, server=server, url_base_pathname='/path')\napp.layout = html.Div(id='example-div-element')\n\n@server.route(\"/dash\")\ndef MyDashApp():\n    return app.index()\n\n\nMake no mistake: this method sucks. Sure, you've regained the ability to create\nroutes here and there, but let's not forget:\n\n * Your app will always start on a Dash-served page: if anything, we'd want our\n   start page to be something we have full control over to then dive into the\n   Dash components.\n * Access to globally available Flask plugins are still unavailable in this\n   method. Notice how we never set an application context?\n * Your ability to style your application with static assets and styles is\n   completely out of your hands.\n * Container architecture built on Flask, such as Google App Engine, won't play\n   nicely when we start something that isn't Flask. So there's a good chance\n   that playing by the rules means losing the ability to deploy.\n\nIf we want to do these things, we cannot start our app as an instance of Dash\nand attempt to work around it. Instead, we must create a Flask app, and put Dash\nin its place as an app embedded in our  app. This gives us full control over\nwhen users can enter the Dash interface, and even within that interface, we can\nstill manage database connections or user sessions as we see fit. Welcome to the\nbig leagues.\n\nTurning the Tables: Dash Inside Flask\nFirst things first, let's get our wsgi.py  file back. Pretty much any hosted\nPython application expects this, so please: enough with the app.py  nonsense.\n\nfrom plotly_flask_tutorial import create_app\n\napp = create_app()\n\nif __name__ == \"__main__\":\n    app.run(host='0.0.0.0', debug=True)\n\n\nLook familiar? Not only do we get Flask back, but we get our entire application\nfactory and all that it includes. Take a look at application/__init__.py:\n\nfrom flask import Flask\nfrom . import dash_view\n\n\ndef create_app():\n    \"\"\"Construct the core application.\"\"\"\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n    dash_app = dash_view.Add_Dash(app)\n\n    with app.app_context():\n        # Construct the core application\n        from . import routes\n        app.register_blueprint(routes.main_bp)\n\n        return app\n\n\nIt's almost as though nothing changed! In fact, the only line we have regarding\nDash here is dash_app = plotly_dash_views.Add_Dash(app). \n\nWe import dash_view  at the start of __init.py__. What is this, you might ask?\nIt's actually a file which contains our Dash app! Dash apps typically like to\nhave a single .py  file per view, which turns out to work great for us. Let's\nlook at why this works by checking dash_view.py:\n\nimport glob\nfrom dash import Dash\nimport dash_table\nimport dash_core_components as dcc\nimport dash_html_components as html\nimport pandas as pd\n\n\ndef Add_Dash(server):\n    \"\"\"Plot.ly Dash view which populates the screen with loaded DataFrames.\"\"\"\n    external_stylesheets = ['https://hackers.nyc3.cdn.digitaloceanspaces.com/css/plotly-flask-tutorial.css']\n    dash_app = Dash(server=server,\n                    external_stylesheets=external_stylesheets,\n                    routes_pathname_prefix='/dash_view/')\n\n    # Create Dash Layout\n    dash_app.layout = html.Div(\n        id='dash-container'\n      )\n\n    return dash_app.server\n\n\nWe pass our Flask instance to Add_Dash  as a parameter called server. Unlike the\nprevious examples, it's actually server  running the show this time, with Dash\npiggybacking as a module. This is our most important line of code:\n\ndash_app = Dash(server=server, routes_pathname_prefix='/dash_view/')\n\n\nDash doesn't handle routes like Flask does (or at all, really). That's fine! We\nstart dash_app  with URL prefix, which means the Dash logic here is confined to\nthat single page. This means we can build a sprawling Flask app with hundreds of\nfeatures and views, and oh yeah, if we want a Dash view, we can just create a\nfile for that to chill on its own, not touching anything else.\n\nNow you're thinking with portals™.\n\nWhat Our App Looks Like\nIf you're following along, it would probably help to have a top-level view of\nwhat's going on so far:\n\nplotlydash-flask-tutorial\n├── /plotly_flask_tutorial\n│   ├── __init__.py\n│   ├── dash_view.py\n│   ├── routes.py\n│   ├── /data\n│   │   ├── chicago_taxis.csv\n│   │   ├── citibike_trips.csv\n│   │   ├── cities.csv\n│   │   └── pocket.csv\n│   ├── /static\n│   │   ├── dist\n│   │   │   └── css\n│   │   │       └── plotly-flask-tutorial.css\n│   │   ├── js\n│   │   │   └── main.js\n│   │   └── less\n│   │       ├── global.less\n│   │       ├── header.less\n│   │       └── table.less\n│   ├── /templates\n│   │   ├── index.html\n│   │   └── nav.html\n│   └── /data\n│       ├── chicago_taxis.csv\n│       ├── citibike_trips.csv\n│       ├── cities.csv\n│       └── pocket.csv\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── config.py\n├── requirements.txt\n├── setup.py\n├── start.sh\n└── wsgi.py\n\n\nWe're storing our app within a directory called plotly_flask_tutorial. In that\ndirectory, we have our typical Flask stuff (/templates, /static, etc) as well as\ntwo notable files: routes.py  and dash_view.py.\n\nroutes.py\nroutes.py  can contain anything we want. Our application will default to serving\na Flask page, not  a Dash page, so our routes can be an entire standalone\napplication. Here's what I tossed in there: \n\nimport os\nfrom flask import Blueprint, render_template\nfrom flask_assets import Environment, Bundle\nfrom flask import current_app as app\nimport lesscpy\n\nmain_bp = Blueprint('main_bp', __name__,\n                    template_folder='templates',\n                    static_folder='static')\nassets = Environment(app)\nEnvironment.auto_build = True\nEnvironment.debug = False\nless_bundle = Bundle('less/*.less',\n                     filters='less,cssmin',\n                     output='dist/css/plotly-flask-tutorial.css.css',\n                     extra={'rel': 'stylesheet/less'})\njs_bundle = Bundle('js/*.js',\n                   filters='jsmin',\n                   output='dist/js/main.js')\nassets.register('less_all', less_bundle)\nassets.register('js_all', js_bundle)\nless_bundle.build(force=True)\njs_bundle.build()\n\n\n# Landing Page\n@main_bp.route('/', methods=['GET'])\ndef home():\n    return render_template('index.html',\n                           title='Plotly Flask Tutorial.',\n                           template='home-template',\n                           body=\"This is an example homepage, served with Flask.\")\n\n\nAll this is doing is serving up index.html.\n\ndash_view.py\ndash_view.py  is the Dash app we have living within  our Flask app. But how does\nFlask know which url to serve our application at? Wasn't it missing from \nroutes.py? Indeed it was, good fellow! Because we set routes_pathname_prefix, we\n don't need  to create a route for dash_view.py: it will always be served\nwhenever we navigate to 127.0.01/dash_view. Thus, we can create a navigation\ntemplate like this:\n\n<nav>\n  <a href=\"/\"><i class=\"fas fa-home\"></i> Home</a>\n  <a href=\"/dash_view/\"><i class=\"fas fa-chart-line\"></i> Embdedded Plotly Dash</a>\n</nav>\n\n\nCreating Something Useful\nHere's a fun little thing I was able to do with Dash, while in the context of\nrunning under a Flask app. In our file dash_view.py, I have the app look at a\nfolder of extracted datasets (called  /data). For each dataset, I use Pandas to\ngenerate a preview, and Dash's \"data table\" component to render said previews in\nour Dash app. This lets us quickly cruise through the data an app depends on\nwith a cool interface:\n\nA bit rough around the edges, but you get the point.If you're hungry for some\nsource code to get started building your own Plotly Dash views, here's the\nsource I used to create the page above:\n\nimport glob\nfrom pathlib import Path, PurePath\nfrom dash import Dash\nimport dash_table\nimport dash_core_components as dcc\nimport dash_html_components as html\nimport pandas as pd\n\np = Path('.')\n\n\ndef Add_Dash(server):\n    \"\"\"Plot.ly Dash view which populates the screen with loaded DataFrames.\"\"\"\n    external_stylesheets = ['https://hackers.nyc3.cdn.digitaloceanspaces.com/css/plotly-flask-tutorial.css',\n                            'https://fonts.googleapis.com/css?family=Lato',\n                   'https://use.fontawesome.com/releases/v5.8.1/css/all.css']\n    dash_app = Dash(server=server,\n                    external_stylesheets=external_stylesheets,\n                    routes_pathname_prefix='/dash_view/')\n\n    # Override the underlying HTML template\n    dash_app.index_string = '''<!DOCTYPE html>\n        <html>\n            <head>\n                {%metas%}\n                <title>{%title%}</title>\n                {%favicon%}\n                {%css%}\n            </head>\n            <body>\n                <nav>\n                  <a href=\"/\"><i class=\"fas fa-home\"></i> Home</a>\n                  <a href=\"/dash_view/\"><i class=\"fas fa-chart-line\"></i> Embdedded Plotly Dash</a>\n                </nav>\n                {%app_entry%}\n                <footer>\n                    {%config%}\n                    {%scripts%}\n                    {%renderer%}\n                </footer>\n            </body>\n        </html>'''\n\n    # Create Dash Layout comprised of Data Tables\n    dash_app.layout = html.Div(\n        children=get_datasets(),\n        id='flex-container'\n      )\n\n    return dash_app.server\n\n\ndef get_datasets():\n    \"\"\"Returns previews of all CSVs saved in /data directory.\"\"\"\n    data_filepath = list(p.glob('plotly_flask_tutorial/data/*.csv'))\n    arr = ['This is an example Plot.ly Dash App.']\n    for index, csv in enumerate(data_filepath):\n        print(PurePath(csv))\n        df = pd.read_csv(data_filepath[index]).head(10)\n        table_preview = dash_table.DataTable(\n            id='table_' + str(index),\n            columns=[{\"name\": i, \"id\": i} for i in df.columns],\n            data=df.to_dict(\"rows\"),\n            sorting=True,\n        )\n        arr.append(table_preview)\n    return arr\n\n\nI've gone ahead and uploaded the source code for this working example up on\nGithub [https://github.com/toddbirchard/plotlydash-flask-tutorial]. Please steal\nit: it's all yours.\n\nNeedless to say, there's way more cool shit we can accomplish with Plotly Dash.\nStick around long enough, and chances are we'll cover all of them.","html":"<p>Ahh, <a href=\"http://plot.ly/\"><strong>Plot.ly</strong></a>; typing that name into a post headline triggers an emotional cocktail of pride and embarrassment. Over the years Plotly has been at the core of some of the most influential products I’ve worked on: a hodgepodge of Fintech and humanitarian clients, all of which are still proudly waving their charts and dashboards around the world. Yet, my mind is boggled by a simple question: what the <em>hell</em> took us so long to write our first post about Plotly? We've been operating Hackers and Slackers for over a full year now... did I seriously write a<a href=\"https://hackersandslackers.com/making-ajax-calls-with-jquery/\"> post about JQuery</a> in that time before reaching this point?</p><p>Much has changed in the last year or so for our friends in Montreal. Number 1 in my book is the price reduction of their core product: from <em><strong>300 dollars</strong></em> to <em><strong>zero</strong></em>. I paid the 300 dollars. We really need to get a “donate” button around here. </p><p>A close second is undoubtedly the introduction of <strong><a href=\"https://plot.ly/products/dash/\">Plot.ly Dash</a></strong>. <strong>Dash</strong> tickles a sentiment which has danced through many young and helplessly naïve Pythonistas' minds: <em>what if we could write </em><strong><em>only</em></strong><em> in Python, like, </em><strong><em>forever</em></strong><em>?</em> As awful of an idea it is to start Googling Python-to-frontend code interpreters (they exist; I checked), Plotly's Dash does a shockingly good job of breathing life into that romantic fantasy of committing to Python forever.</p><p>But we're not here to deliver a recycled 'W<em>hat is Plotly?'</em> synopsis. We're not even interested in the obligatory '<em>How to Get Started Using This Already-Well-Documented-Technology' </em>post<em>. </em>Plotly deserves better than that. Instead, we're coming hot out of the gate swinging: we're going to show you how to beat Plotly down, break it, and make it bend to your will. Welcome to a magical edition of Hacking Plotly. It must be Christmas, folks.</p><h2 id=\"let-s-make-a-plotly-flask-lovechild-from-hell\">Let's Make a Plotly + Flask Lovechild from Hell</h2><p>Like almost every single advancement to come out of Python-geared architecture this year, Dash has a little secret: it's gotten here with a little help from Flask. Alright, perhaps more than a little: Dash actually extends Flask. Sounds sensible, and perhaps even exciting at first; its almost as though every crush you've ever had decided it be best to simply put their differences aside to start a group chat with you in the interest of making your sexual well-being an equal team effort out of sheer love. As you've already guessed, life doesn't work like that.</p><p>Dash hijacks Flask from the beginning, starting with the way we instantiate the app. Any code monkey who has laid eyes upon a <strong>wsgi.py </strong>file can tell you something is up before you can even say <code>app = dash.Dash(__name__)</code>. Check out the recommended startup boilerplate:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from dash import Dash\nimport dash_core_components as dcc\nimport dash_html_components as html\n\nexternal_stylesheets = ['https://codepen.io/fgdsgfhgfh/pen/IHvjvb.css']\n\napp = Dash(__name__, external_stylesheets=external_stylesheets)\n\napp.layout = html.Div(\n        id='example-div-element'\n        )\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre>\n<!--kg-card-end: markdown--><p>If you were to attempt to take this boilerplate and attempt to add core Flask logic, such as authentication with <code>Flask-Login</code>, generating assets with <code>Flask-Assets</code>, or just creating a global database, where would you start? Plotly cleverly suggests reserving the <code>app</code> namespace for your app- the very same that we would do with Flask. Yet if we attempt to modify the <code>app</code> object the same as we would with Flask, nothing will work: Dash has declared an ecosystem, and nowhere in that ecosystem are you invited to add custom Flask application logic out of the box.</p><p>Dash does what it was intended to do very well: building dashboard-based applications. The issue is that applications which can <em>only display data</em> aren't entirely useful as end products. What if we wanted to create a fully-featured app, where data visualization was simply a <em>feature</em> of said app?</p><h2 id=\"creating-a-fully-featured-app-where-data-vis-is-simply-a-feature-of-said-app-\">Creating a Fully-Featured App (Where Data Vis is Simply a Feature of Said App)</h2><p>A common \"workaround\" you'll find in the community is passing Flask to Dash as the underlying \"server\", something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask\nfrom dash import Dash\nimport dash_core_components as dcc\nimport dash_html_components as html\n\nserver = Flask(__name__)\napp = dash.Dash(__name__, server=server, url_base_pathname='/path')\napp.layout = html.Div(id='example-div-element')\n\n@server.route(&quot;/dash&quot;)\ndef MyDashApp():\n    return app.index()\n</code></pre>\n<!--kg-card-end: markdown--><p>Make no mistake: this method <em>sucks. </em>Sure, you've regained the ability to create routes here and there, but let's not forget:</p><ul><li>Your app will always start on a Dash-served page: if anything, we'd want our start page to be something we have full control over to then dive into the Dash components.</li><li>Access to globally available Flask plugins are still unavailable in this method. Notice how we never set an application context?</li><li>Your ability to style your application with static assets and styles is completely out of your hands.</li><li>Container architecture built on Flask, such as Google App Engine, won't play nicely when we start something that isn't Flask. So there's a good chance that playing by the rules means losing the ability to deploy.</li></ul><p>If we want to do these things, we cannot start our app as an instance of Dash and attempt to work around it. Instead, we must create a Flask app, and put Dash in its place as an app embedded in <em>our</em> app. This gives us full control over when users can enter the Dash interface, and even within that interface, we can still manage database connections or user sessions as we see fit. Welcome to the big leagues.</p><h2 id=\"turning-the-tables-dash-inside-flask\">Turning the Tables: Dash Inside Flask</h2><p>First things first, let's get our <strong>wsgi.py</strong> file back. Pretty much any hosted Python application expects this, so please: enough with the <strong>app.py</strong> nonsense.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from plotly_flask_tutorial import create_app\n\napp = create_app()\n\nif __name__ == &quot;__main__&quot;:\n    app.run(host='0.0.0.0', debug=True)\n</code></pre>\n<!--kg-card-end: markdown--><p>Look familiar? Not only do we get Flask back, but we get our entire application factory and all that it includes. Take a look at <code>application/__init__.py</code><em>:</em></p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from flask import Flask\nfrom . import dash_view\n\n\ndef create_app():\n    &quot;&quot;&quot;Construct the core application.&quot;&quot;&quot;\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n    dash_app = dash_view.Add_Dash(app)\n\n    with app.app_context():\n        # Construct the core application\n        from . import routes\n        app.register_blueprint(routes.main_bp)\n\n        return app\n</code></pre>\n<!--kg-card-end: markdown--><p>It's almost as though nothing changed! In fact, the only line we have regarding Dash here is <code>dash_app = plotly_dash_views.Add_Dash(app)</code>. </p><p>We import <code>dash_view</code> at the start of <code>__init.py__</code>. What is this, you might ask? It's actually a file which contains our Dash app! Dash apps typically like to have a single <em>.py</em> file per view, which turns out to work great for us. Let's look at why this works by checking <code>dash_view.py</code>:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import glob\nfrom dash import Dash\nimport dash_table\nimport dash_core_components as dcc\nimport dash_html_components as html\nimport pandas as pd\n\n\ndef Add_Dash(server):\n    &quot;&quot;&quot;Plot.ly Dash view which populates the screen with loaded DataFrames.&quot;&quot;&quot;\n    external_stylesheets = ['https://hackers.nyc3.cdn.digitaloceanspaces.com/css/plotly-flask-tutorial.css']\n    dash_app = Dash(server=server,\n                    external_stylesheets=external_stylesheets,\n                    routes_pathname_prefix='/dash_view/')\n\n    # Create Dash Layout\n    dash_app.layout = html.Div(\n        id='dash-container'\n      )\n\n    return dash_app.server\n</code></pre>\n<!--kg-card-end: markdown--><p>We pass our Flask instance to <code>Add_Dash</code> as a parameter called <em>server. </em>Unlike the previous examples, it's actually <em>server</em> running the show this time, with Dash piggybacking as a module. This is our most important line of code:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">dash_app = Dash(server=server, routes_pathname_prefix='/dash_view/')\n</code></pre>\n<!--kg-card-end: markdown--><p>Dash doesn't handle routes like Flask does (or at all, really). That's fine! We start <code>dash_app</code> with URL prefix, which means the Dash logic here is confined to that single page. This means we can build a sprawling Flask app with hundreds of features and views, and oh yeah, if we want a Dash view, we can just create a file for that to chill on its own, not touching anything else.</p><p>Now you're thinking with portals<strong>™.</strong></p><h2 id=\"what-our-app-looks-like\">What Our App Looks Like</h2><p>If you're following along, it would probably help to have a top-level view of what's going on so far:</p><!--kg-card-begin: markdown--><pre><code>plotlydash-flask-tutorial\n├── /plotly_flask_tutorial\n│   ├── __init__.py\n│   ├── dash_view.py\n│   ├── routes.py\n│   ├── /data\n│   │   ├── chicago_taxis.csv\n│   │   ├── citibike_trips.csv\n│   │   ├── cities.csv\n│   │   └── pocket.csv\n│   ├── /static\n│   │   ├── dist\n│   │   │   └── css\n│   │   │       └── plotly-flask-tutorial.css\n│   │   ├── js\n│   │   │   └── main.js\n│   │   └── less\n│   │       ├── global.less\n│   │       ├── header.less\n│   │       └── table.less\n│   ├── /templates\n│   │   ├── index.html\n│   │   └── nav.html\n│   └── /data\n│       ├── chicago_taxis.csv\n│       ├── citibike_trips.csv\n│       ├── cities.csv\n│       └── pocket.csv\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── config.py\n├── requirements.txt\n├── setup.py\n├── start.sh\n└── wsgi.py\n</code></pre>\n<!--kg-card-end: markdown--><p>We're storing our app within a directory called <code>plotly_flask_tutorial</code>. In that directory, we have our typical Flask stuff (<strong>/templates</strong>, <strong>/static</strong>, etc) as well as two notable files: <code>routes.py</code> and <code>dash_view.py</code>.</p><h3 id=\"routes-py\">routes.py</h3><p><code>routes.py</code> can contain anything we want. Our application will default to serving a Flask page, <em>not</em> a Dash page, so our routes can be an entire standalone application. Here's what I tossed in there: </p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nfrom flask import Blueprint, render_template\nfrom flask_assets import Environment, Bundle\nfrom flask import current_app as app\nimport lesscpy\n\nmain_bp = Blueprint('main_bp', __name__,\n                    template_folder='templates',\n                    static_folder='static')\nassets = Environment(app)\nEnvironment.auto_build = True\nEnvironment.debug = False\nless_bundle = Bundle('less/*.less',\n                     filters='less,cssmin',\n                     output='dist/css/plotly-flask-tutorial.css.css',\n                     extra={'rel': 'stylesheet/less'})\njs_bundle = Bundle('js/*.js',\n                   filters='jsmin',\n                   output='dist/js/main.js')\nassets.register('less_all', less_bundle)\nassets.register('js_all', js_bundle)\nless_bundle.build(force=True)\njs_bundle.build()\n\n\n# Landing Page\n@main_bp.route('/', methods=['GET'])\ndef home():\n    return render_template('index.html',\n                           title='Plotly Flask Tutorial.',\n                           template='home-template',\n                           body=&quot;This is an example homepage, served with Flask.&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>All this is doing is serving up <code>index.html</code>.</p><h3 id=\"dash_view-py\">dash_view.py</h3><p><code>dash_view.py</code> is the Dash app we have living <em>within</em> our Flask app. But how does Flask know which url to serve our application at? Wasn't it missing from <code>routes.py</code>? Indeed it was, good fellow! Because we set <strong>routes_pathname_prefix</strong>, we <em>don't need</em> to create a route for <code>dash_view.py</code>: it will always be served whenever we navigate to <code>127.0.01/dash_view</code>. Thus, we can create a navigation template like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-html\">&lt;nav&gt;\n  &lt;a href=&quot;/&quot;&gt;&lt;i class=&quot;fas fa-home&quot;&gt;&lt;/i&gt; Home&lt;/a&gt;\n  &lt;a href=&quot;/dash_view/&quot;&gt;&lt;i class=&quot;fas fa-chart-line&quot;&gt;&lt;/i&gt; Embdedded Plotly Dash&lt;/a&gt;\n&lt;/nav&gt;\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"creating-something-useful\">Creating Something Useful</h2><p>Here's a fun little thing I was able to do with Dash, while in the context of running under a Flask app. In our file <code>dash_view.py</code>, I have the app look at a folder of extracted datasets (called<em> /data</em>). For each dataset, I use Pandas to generate a preview, and Dash's \"data table\" component to render said previews in our Dash app. This lets us quickly cruise through the data an app depends on with a cool interface:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/dataframes.gif\" class=\"kg-image\"><figcaption>A bit rough around the edges, but you get the point.</figcaption></figure><!--kg-card-end: image--><p>If you're hungry for some source code to get started building your own Plotly Dash views, here's the source I used to create the page above:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import glob\nfrom pathlib import Path, PurePath\nfrom dash import Dash\nimport dash_table\nimport dash_core_components as dcc\nimport dash_html_components as html\nimport pandas as pd\n\np = Path('.')\n\n\ndef Add_Dash(server):\n    &quot;&quot;&quot;Plot.ly Dash view which populates the screen with loaded DataFrames.&quot;&quot;&quot;\n    external_stylesheets = ['https://hackers.nyc3.cdn.digitaloceanspaces.com/css/plotly-flask-tutorial.css',\n                            'https://fonts.googleapis.com/css?family=Lato',\n                   'https://use.fontawesome.com/releases/v5.8.1/css/all.css']\n    dash_app = Dash(server=server,\n                    external_stylesheets=external_stylesheets,\n                    routes_pathname_prefix='/dash_view/')\n\n    # Override the underlying HTML template\n    dash_app.index_string = '''&lt;!DOCTYPE html&gt;\n        &lt;html&gt;\n            &lt;head&gt;\n                {%metas%}\n                &lt;title&gt;{%title%}&lt;/title&gt;\n                {%favicon%}\n                {%css%}\n            &lt;/head&gt;\n            &lt;body&gt;\n                &lt;nav&gt;\n                  &lt;a href=&quot;/&quot;&gt;&lt;i class=&quot;fas fa-home&quot;&gt;&lt;/i&gt; Home&lt;/a&gt;\n                  &lt;a href=&quot;/dash_view/&quot;&gt;&lt;i class=&quot;fas fa-chart-line&quot;&gt;&lt;/i&gt; Embdedded Plotly Dash&lt;/a&gt;\n                &lt;/nav&gt;\n                {%app_entry%}\n                &lt;footer&gt;\n                    {%config%}\n                    {%scripts%}\n                    {%renderer%}\n                &lt;/footer&gt;\n            &lt;/body&gt;\n        &lt;/html&gt;'''\n\n    # Create Dash Layout comprised of Data Tables\n    dash_app.layout = html.Div(\n        children=get_datasets(),\n        id='flex-container'\n      )\n\n    return dash_app.server\n\n\ndef get_datasets():\n    &quot;&quot;&quot;Returns previews of all CSVs saved in /data directory.&quot;&quot;&quot;\n    data_filepath = list(p.glob('plotly_flask_tutorial/data/*.csv'))\n    arr = ['This is an example Plot.ly Dash App.']\n    for index, csv in enumerate(data_filepath):\n        print(PurePath(csv))\n        df = pd.read_csv(data_filepath[index]).head(10)\n        table_preview = dash_table.DataTable(\n            id='table_' + str(index),\n            columns=[{&quot;name&quot;: i, &quot;id&quot;: i} for i in df.columns],\n            data=df.to_dict(&quot;rows&quot;),\n            sorting=True,\n        )\n        arr.append(table_preview)\n    return arr\n</code></pre>\n<!--kg-card-end: markdown--><p>I've gone ahead and uploaded the source code for this working example up <a href=\"https://github.com/toddbirchard/plotlydash-flask-tutorial\">on Github</a>. Please steal it: it's all yours.</p><p>Needless to say, there's way more cool shit we can accomplish with Plotly Dash. Stick around long enough, and chances are we'll cover all of them.</p>","url":"https://hackersandslackers.com/gaining-full-control-over-plotly-dash/","uuid":"535768b9-34b6-4a80-b5fa-b69b50cf3a68","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c1af93bffe54a660c58b85a"}},{"node":{"id":"Ghost__Post__5c192cdba632c8240cad3869","title":"Globally Accessible Variables in Flask: Demystifying the 'Application Context'","slug":"demystifying-flasks-application-context","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/flask_factory-2.jpg","excerpt":"Breaking down the nuances of the ‘app context’ in Flask's Application Factory.","custom_excerpt":"Breaking down the nuances of the ‘app context’ in Flask's Application Factory.","created_at_pretty":"18 December, 2018","published_at_pretty":"19 December, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-12-18T12:22:35.000-05:00","published_at":"2018-12-19T08:00:00.000-05:00","updated_at":"2019-04-09T23:49:27.000-04:00","meta_title":"Demystifying Flask's Application Context | Hackers and Slackers","meta_description":"A guide breaking down the cryptic nuances of Flask's 'Application Context.' Putting an end to \"RuntimeError: working outside of application context\".","og_description":"A guide breaking down the cryptic nuances of Flask's 'Application Context.' Putting an end to \"RuntimeError: working outside of application context\".","og_image":"https://hackersandslackers.com/content/images/2019/04/flask_factory-2-2.jpg","og_title":"Demystifying Flask's Application Context","twitter_description":"A guide breaking down the cryptic nuances of Flask's 'Application Context.' Putting an end to \"RuntimeError: working outside of application context\".","twitter_image":"https://hackersandslackers.com/content/images/2019/04/flask_factory-2-1.jpg","twitter_title":"Demystifying Flask's Application Context","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"A 'skill' that's always fascinated me is just how long some engineers can make\nit in their career while carrying glaringly obvious gaps in their knowledge of\nthe systems they use every day. To my surprise, I've turned corners where I\nmyself have been that engineer all along, and there's perhaps no better example\nof this then the time I've spent with Flask.\n\nWARNING! Highly opinionated statement incoming: Flask is everything a framework\nshould be. That is to say, it isn't really  a framework a fully-fledged\nframework at all. Sure, the term microframework might seem like a cute PR term,\nbut that doesn't negate the fact that there's something about Flask that's\ndifferent. When I write apps in Flask,  I feel as though I'm writing apps in \nPython.  On the other hand, when I write apps in Django,  I feel like I'm just\nwriting apps in Django.  A disciplined programmer might feel that overly\nstructured frameworks damper creativity and they're probably right: these are\nthe backbones of businesses, thus it makes sense to keep people from deviating\nfrom the norm. \n\nThe upside of Flask is also its downside: there's nearly an infinite number of\nways to solve a single problem. Every Stackoverflow regular has their own\npreference, and sometimes, just none of them seem... right. The problem is\ncompounded by some of the phrasing coming from Flask's documentation itself.\nFlask touts the importance of structuring apps with factories and Blueprints,\nwhile simultaneously expressing the power behind the application context.  What\nyou'll notice over time is that in Flask's own examples, these two 'very\nimportant things' never both appear at the same time: that's because they're\nsimply incompatible with one another.  This is a highly understated\ncontradiction of philosophies.\n\nCommunication Breakdown?\nHere's Flask's take on Application factories\n[http://flask.pocoo.org/docs/1.0/patterns/appfactories/]:\n\n> If you are already using packages and blueprints for your application (Modular\nApplications with Blueprints) there are a couple of really nice ways to further\nimprove the experience. A common pattern is creating the application object when\nthe blueprint is imported.\n\n\nAnd here's their description of the Application context\n[http://flask.pocoo.org/docs/1.0/appcontext/]:\n\n> The application context keeps track of the application-level data during a\nrequest, CLI command, or other activity. Rather than passing the application\naround to each function, the current_app and g proxies are accessed instead.\n\n\nConsidering g  is intended to stand for \"global\" it seems safe from the previous\nstatements that setting attributes of g  can be accessed globally within an\napplication... but they can't. This is where we backpedal and get into messy\nterritory:\n\n> However, importing the app instance within the modules in your project is prone\nto circular import issues. When using the app factory pattern or writing\nreusable blueprints or extensions there won’t be an app instance to import at\nall.\n\nFlask solves this issue with the application context. Rather than referring to\nan app directly, you use the the current_app  proxy, which points to the\napplication handling the current activity.\n\n\nOkay, fine. So if I instantiate an application factory with app.app_context(): \n(which is the only sensible way to create a factory at all)  I should be able to\nregister blueprints within that context, and reference the app context, correct?\n\nI could be crazy but this never seems to work  within blueprints. Whether they\nexist as peer modules or submodules, the words 'from application import\ncurrent_app as app' always seems to result in the same \"missing application\ncontext\" error. Conveniently it seems, all working examples of the application\ncontext seem to be when the Flask developers opt to serve single-file app\nexamples. This stranger from Stackoverflow\n[https://stackoverflow.com/questions/50233118/access-to-flask-global-variables-in-blueprint-apps] \n clears things up a bit:\n\n> This happens because the data are lost when the context (with app.app_context())\nends (doc).\nInside the context, everything is ok :\n\nfrom flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n   print(g.my_db)\n\nthis prints 'database ok'\n\n\nBut outside, you cannot access the attribute:\n\nfrom flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n\nprint(g.my_db)\n\n\nthis throws RuntimeError: Working outside of application context\n\neven if you create a new context:\n\nfrom flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n\nwith app.app_context():\n   print(g.my_db)\n\n\nthis throws AttributeError: '_AppCtxGlobals' object has no attribute 'my_db'\n\n\nAlas, here I am. Doomed writing posts to fill in the blanks of documentation\nleft behind by others. \n\nFlask Sessions: The REAL Slim Shady\nFlask-Session  is the MVP when it comes sharing temporary information across\nmodularized parts of our program. In fact, it's a bit odd this isn't encouraged\nmore-so than g. But whatever. We're here to heal.\n\nSessions  can handled in a number of different ways besides cookies. Take a look\nat the choices we have for storing session-based values in an instance of Flask:\n\nSESSION_TYPE\n Specifies which type of session interface to\nuse. Built-in session types:\n\n * null: NullSessionInterface (default)\n * redis: RedisSessionInterface\n * memcached: MemcachedSessionInterface\n * filesystem: FileSystemSessionInterface\n * mongodb: MongoDBSessionInterface\n * sqlalchemy: SqlAlchemySessionInterface\n\nSESSION_PERMANENT\n Whether use permanent session or not, default\nto be True\n SESSION_USE_SIGNER\n Whether sign the session cookie sid or not,\nif set to True, you have to set\n flask.Flask.secret_key\n[http://flask.pocoo.org/docs/api/#flask.Flask.secret_key], default to be\n False\n SESSION_KEY_PREFIX\n A prefix that is added before all session keys.\nThis makes it possible to use the same backend\nstorage server for different apps, default\n“session:”\n SESSION_REDIS\n A redis.Redis  instance, default connect to\n 127.0.0.1:6379\n SESSION_MEMCACHED\n A memcache.Client  instance, default connect\nto 127.0.0.1:11211\n SESSION_FILE_DIR\n The directory where session files are stored.\nDefault to use flask_session  directory under\ncurrent working directory.\n SESSION_FILE_THRESHOLD\n The maximum number of items the session stores\nbefore it starts deleting some, default 500\n SESSION_FILE_MODE\n The file mode wanted for the session files,\ndefault 0600\n SESSION_MONGODB\n A pymongo.MongoClient  instance, default\nconnect to 127.0.0.1:27017\n SESSION_MONGODB_DB\n The MongoDB database you want to use, default\n“flask_session”\n SESSION_MONGODB_COLLECT\n The MongoDB collection you want to use, default\n“sessions”\n SESSION_SQLALCHEMY\n A flask.ext.sqlalchemy.SQLAlchemy  instance\nwhose database connection URI is configured\nusing the SQLALCHEMY_DATABASE_URI  parameter\n SESSION_SQLALCHEMY_TABLE\n The name of the SQL table you want to use,\ndefault “sessions”\n Using Redis For Cached Session Information\nFor the sake of trying something different, I've opted to pick up a tiny Redis\ninstance from redislabs [https://redislabs.com/]. I can't help myself but\nwasting money on new services to play with; after all, check out how cool this\nlittle red box looks:\n\nRedis Enterprise: A Unique Primary Database\nPerfomance at Scale\n * 50M ops/sec,\n    Symmetric shared–nothing architecture ensures no performance overheads while\n   scaling, auto-sharding and re-balancing\n    Enhanced connection management, pipeline execution and request scheduling\n    \n\nBuilt-in high performance search\n * High performance, real-time indexing with items available for search within\n   1ms\n * Predictable high performance querying while maintaining concurrent loads of\n   indexing and querying\n * Highly scalable across multiple nodes to billions of items per second \n\nFailsafe high availability\n * Cross-rack/zone/datacenter/geo replication\n * Instant auto-failover in single digit second\n * Zero impact on throughput and latency during cluster operations such as\n   scaling, upgrades, re-sharding and rebalancing\n * Out-of-the box support for backup, restore and DR\n\nActive-active geo distribution\n * Reads/Writes in multiple geo regions to the same dataset\n * Local latencies, global availability\n * Built-in conflict resolution for simple and complex data types\n * Based on revolutionary CRDT academic research\n\nBuilt-in persistence\n * Enhanced storage engine for parallel access to any persistent storage\n * Multiple options for enhanced data persistence\n * Reliable persistence configurations on both master and slave shards with zero\n   performance impact\n\nMulti-model\n * Graph, JSON, Machine Learning and Bloom filter modules set industry standards\n   for high performance\n * Multi-shard coordination\n * Extensibility with custom modules\n\nIntelligent tiered access to memory\n * Up to 80% lower infrastructure costs by running Redis on Flash\n * Automatic management of data tiering between RAM & Flash with no code changes\n * Supports all new persistent memory technologies\n\nFlexible deployment options\n * Hybrid clusters can span on-prem infrastructure and multiple clouds\n * Most efficient use of resources with maximized core usage, multi-tenancy,\n   re-sharding and re-balancing to avoid noisy neighbors in every environment\n\nPerfomance at Scale\n Built-in persistence\n Failsafe high availability\n Active-active geo distribution\n Built-in high performance search\n Multi-model\n Intelligent tiered access to memory\n \n(RAM and Flash)\n Flexible deployment options\n \n(cloud, on-prem, hybrid)\n Fast\nPerformance at scale\n Built-in high performance search\n Reliable\nBuilt-in persistence\n Failsafe high availability\n Active-active geo distribution\n Flexible\nMulti-model\n Flexible deployment options (cloud, hybrid, on-prem)\n Intelligent tiered access to memory (ram and flash)\n (Why am I not getting paid for this? Why did I take the time to even make that\nmodule?)Redis  is NoSQL datastore written in C intended to temporarily hold data in\nmemory for users as they blaze mindlessly through your site. Other use cases\ninclude serving as the foundation for real-time chat apps via the\npublish/subscribe messaging paradigm; popular amongst stupid chat or dating apps\nslowly destroying our abilities as human beings to interact face-to-face.\nPowerful stuff.\n\nStructuring init.py Correctly\nConsider this to be the guide to Flask Application factories I wish I had months\nago. A healthy application factory should:\n\n * Derive all app configuration values from a class or environment variables.\n * Allow Database interactions to occur at any point within the app.\n * Pass values globally outside of the application context.\n\nThis does all of those things:\n\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_session import Session\nfrom flask_redis import FlaskRedis\n\n# Globally accessible libraries\ndb = SQLAlchemy()\nr = FlaskRedis()\n\n\ndef create_app():\n    \"\"\"Initialize the core application.\"\"\"\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n\n    with app.app_context():\n        # Set global session variables\n        r.set('endpoint', str(app.config['ENDPOINT']).encode('utf-8'))\n        r.set('post_query', str(app.config['POST_QUERY']).encode('utf-8'))\n        \n        # Initialize Global Libraries\n        redis_store.init_app(app)\n        db.init_app(app)\n\n        # Include our Routes\n        from . import routes\n\n        return app\n\n\nThe order of operations here is critical.\n\nBefore we do anything related to the app itself, we create instances of \nflask_sqlalchemy  and flask_redis. This will be initialized with our app once we\nactually have one created.\n\nThe first two lines of create_app()  should be no surprise: we're just creating\nour Flask app, and stating that it should be configured using a class called \nConfig  in a file named config.py.\n\napp = Flask(__name__, instance_relative_config=False)\napp.config.from_object('config.Config')\n\n\nMoving down the function comes the moment of truth: creating the app context. \nWhat happens in the app context stays in the app context... except for our sick\nnew Redis setup. By using the Redis .set()  method, we can assign key/value\npairs  for Redis hang on to, such as values from our app config which might be\nneeded elsewhere in our app: r.set('endpoint',\nstr(app.config['ENDPOINT']).encode('utf-8')).\n\nRedis stores information as bytes by default, thus attempting to pass values\nsuch as strings will result in the infamous `b'leading letter b'` phenomenon. Be\nsure to encode your values as utf-8 when using set(), and decode when using\nget().Making Redis Globally Available\nThe next part is important: we need to 'initialize' the services we want to use\nglobally (such as database access or Redis) by using init_app(). This must \nhappen inside the application context, with the parameter being app. This is our\nway of achieving singularity into inter-dimensional travel, thus breaking out of\nthe dreaded application context long after it dies.\n\nLet's Access Some Variables, Baby\nThe moment of truth: will this actually work? Or am I actually a filthy liar\nflooding the internet with more uselessly outdated Flask advice? Let's see:\n\n# routes.py\n\nfrom flask import current_app as app\nfrom flask import make_response\nimport json\nfrom . import models\nfrom . import r\n\nheaders = { 'Access-Control-Allow-Headers': 'Content-Type' }\n\n\n@app.route('/', methods=['GET', 'POST'])\ndef entry():\n    readers = models.Readers.query.filter_by(username='john').all()\n    print(readers)\n    print(r.get('uri').decode('utf-8'))\n    return make_response(str('readers'), 200, headers)\n\n\nEureka! This worthless entry-point prints two things: the value we assigned to\nour Redis block, and all records in our database of people named John:\n\n>> [<User john>]\n>> https://us1-hackersandslackers-543.cloudfunctions.net/link-endpoint?url=\n\n\nAs simple and stupid as it seems, developing an app to this point while\nunderstanding why it works  is a victory for any developer. I complain about\nthis nearly every post, but the fact of the matter is that the heroes who build\nmuch of today's technologies commonly fail to explain their own art in\nunderstandable terms. It's an understandable phenomenon resulting from isolated\nspurts of genius, perhaps, but it damages the growth of companies and humanity\nalike.\n\nSo I guess this is my calling: writing documentation for other people's\naccomplishments. \"Marginally less confusing than 4 open Stackoverflow tabs.\" \nThat's what I hope to have engraved on my gravestone.\n\nMerry Christmas.","html":"<p>A 'skill' that's always fascinated me is just how long some engineers can make it in their career while carrying glaringly obvious gaps in their knowledge of the systems they use every day. To my surprise, I've turned corners where I myself have been that engineer all along, and there's perhaps no better example of this then the time I've spent with Flask.</p><p><strong>WARNING! Highly opinionated statement incoming</strong>: Flask is everything a framework should be. That is to say, it <em>isn't really</em> a framework a fully-fledged framework at all. Sure, the term <em>microframework </em>might seem like a cute PR term, but that doesn't negate the fact that there's something about Flask that's different. When I write apps in <strong>Flask,</strong> I feel as though I'm writing apps in <strong>Python.</strong> On the other hand, when I write apps in <strong>Django,</strong> I feel like I'm just writing apps in <strong>Django.</strong> A disciplined programmer might feel that overly structured frameworks damper creativity and they're probably right: these are the backbones of businesses, thus it makes sense to keep people from deviating from the norm. </p><p>The upside of Flask is also its downside: there's nearly an infinite number of ways to solve a single problem. Every Stackoverflow regular has their own preference, and sometimes, just none of them seem... <em>right. </em>The problem is compounded by some of the phrasing coming from Flask's documentation itself. Flask touts the importance of structuring apps with factories and Blueprints, while simultaneously expressing the power behind the <strong><em>application context.</em></strong> What you'll notice over time is that in Flask's own examples, these two 'very important things' never both appear at the same time: that's because they're simply <em>incompatible with one another.</em> This is a highly understated contradiction of philosophies.</p><h2 id=\"communication-breakdown\">Communication Breakdown?</h2><p>Here's <a href=\"http://flask.pocoo.org/docs/1.0/patterns/appfactories/\">Flask's take on Application factories</a>:</p><blockquote>\n<p>If you are already using packages and blueprints for your application (Modular Applications with Blueprints) there are a couple of really nice ways to further improve the experience. A common pattern is creating the application object when the blueprint is imported.</p>\n</blockquote>\n<p>And here's their <a href=\"http://flask.pocoo.org/docs/1.0/appcontext/\">description of the Application context</a>:</p><blockquote>\n<p>The application context keeps track of the application-level data during a request, CLI command, or other activity. Rather than passing the application around to each function, the current_app and g proxies are accessed instead.</p>\n</blockquote>\n<p>Considering <code>g</code> is intended to stand for \"global\" it seems safe from the previous statements that setting attributes of <code>g</code> can be accessed globally within an application... but they can't. This is where we backpedal and get into messy territory:</p><blockquote>\n<p>However, importing the app instance within the modules in your project is prone to circular import issues. When using the app factory pattern or writing reusable blueprints or extensions there won’t be an app instance to import at all.</p>\n<p>Flask solves this issue with the application context. Rather than referring to an app directly, you use the the <strong>current_app</strong> proxy, which points to the application handling the current activity.</p>\n</blockquote>\n<p>Okay, fine. So if I instantiate an application factory with <code>app.app_context():</code> (which is the only sensible way to create a factory at all)  I should be able to register blueprints within that context, and reference the app context, correct?</p><p>I could be crazy but this <em>never seems to work</em> within blueprints. Whether they exist as peer modules or submodules, the words 'from application import current_app as app' always seems to result in the same \"missing application context\" error. Conveniently it seems, all working examples of the application context seem to be when the Flask developers opt to serve single-file app examples. This <a href=\"https://stackoverflow.com/questions/50233118/access-to-flask-global-variables-in-blueprint-apps\">stranger from Stackoverflow</a> clears things up a bit:</p><blockquote>\n<p>This happens because the data are lost when the context (with app.app_context()) ends (doc).<br>\nInside the context, everything is ok :</p>\n<pre><code class=\"language-python\">from flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n   print(g.my_db)\n\nthis prints 'database ok'\n</code></pre>\n<p>But outside, you cannot access the attribute:</p>\n<pre><code class=\"language-python\">from flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n\nprint(g.my_db)\n</code></pre>\n<p>this throws RuntimeError: Working outside of application context</p>\n<p>even if you create a new context:</p>\n<pre><code class=\"language-python\">from flask import Flask, g\napp = Flask(__name__)\nwith app.app_context():\n   g.my_db = 'database ok'\n\nwith app.app_context():\n   print(g.my_db)\n</code></pre>\n<p>this throws AttributeError: '_AppCtxGlobals' object has no attribute 'my_db'</p>\n</blockquote>\n<p>Alas, here I am. Doomed writing posts to fill in the blanks of documentation left behind by others. </p><h2 id=\"flask-sessions-the-real-slim-shady\">Flask Sessions: The REAL Slim Shady</h2><p><code>Flask-Session</code> is the MVP when it comes sharing temporary information across modularized parts of our program. In fact, it's a bit odd this isn't encouraged more-so than <code>g</code>. But whatever. We're here to heal.</p><p><strong>Sessions</strong> can handled in a number of different ways besides cookies. Take a look at the choices we have for storing session-based values in an instance of Flask:</p><style>\n    tr td:first-child{\n    text-align: left;\n    text-align: top;\n    }\n    \n    tr td:first-child {\n    text-align: left;\n    text-align: top;\n    font-weight: 500;\n    background: #646c82 !important;\n    color: white;\n    border-bottom: 1px solid #747d92;\n    max-width: 70px;\n}\n    \n    table td {\n        font-size:.9em;\n    }\n    \n    td {\n       text-align: left;\n        font-size:.9em;\n        \n    }\n   \n    \n    tr td:nth-of-type(2){\n        font-weight: 100;\n            padding: 20px;\n    }\n    @media (max-width: 800px) {\n        \n        tr td {\n    \t\tpadding: 10px 0;\n        }\n        \n        tbody {\n            margin-left: 0 !important;\n        }\n        \n      tr td:first-child {\n       width: 100%;\n       white-space: nowrap;\n    padding: 10px 0 !important;\n    text-overflow: ellipsis;\n          max-width: none;\n    }\n        \n        tr:first-child td{\n       \t    min-width: 300px;\n            max-width: -webkit-fill-available !important;\n        }\n        \n        th {\n            \n        }\n        \n        tr {\n            padding: 0px !important;\n            overflow-x: hidden;\n        }\n        \n        td {\n            line-height:1.5;\n        }\n        \n        td:nth-of-type(2) {\n            width: 100%;\n            padding: 20px !important;\n        }\n        \n        tr td:nth-of-type(2){\n        font-weight: 100;\n        padding: 15px !important;\n    \t}\n    }\n    \n        \n</style>\n\n<div class=\"tableContainer\">\n  <table>\n  <tbody valign=\"top\">\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_TYPE</span></td>\n      <td>\n        <p class=\"first\">Specifies which type of session interface to\n          use. Built-in session types:</p>\n        <ul class=\"last simple\">\n          <li><strong>null</strong>: NullSessionInterface (default)</li>\n          <li><strong>redis</strong>: RedisSessionInterface</li>\n          <li><strong>memcached</strong>: MemcachedSessionInterface</li>\n          <li><strong>filesystem</strong>: FileSystemSessionInterface</li>\n          <li><strong>mongodb</strong>: MongoDBSessionInterface</li>\n          <li><strong>sqlalchemy</strong>: SqlAlchemySessionInterface</li>\n        </ul>\n      </td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_PERMANENT</span></td>\n      <td>Whether use permanent session or not, default\n        to be <span class=\"pre\">True</span></td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_USE_SIGNER</span></td>\n      <td>Whether sign the session cookie sid or not,\n        if set to <span class=\"pre\">True</span>, you have to set\n        <a class=\"reference external\" href=\"http://flask.pocoo.org/docs/api/#flask.Flask.secret_key\" title=\"(in Flask v0.12-dev)\"><tt class=\"xref py py-attr docutils literal\"><span class=\"pre\">flask.Flask.secret_key</span></tt></a>, default to be\n        <span class=\"pre\">False</span></td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_KEY_PREFIX</span></td>\n      <td>A prefix that is added before all session keys.\n        This makes it possible to use the same backend\n        storage server for different apps, default\n        “session:”</td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_REDIS</span></td>\n      <td>A <span class=\"pre\">redis.Redis</span> instance, default connect to\n        <span class=\"pre\">127.0.0.1:6379</span></td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_MEMCACHED</span></td>\n      <td>A <span class=\"pre\">memcache.Client</span> instance, default connect\n        to <span class=\"pre\">127.0.0.1:11211</span></td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_FILE_DIR</span></td>\n      <td>The directory where session files are stored.\n        Default to use <cite>flask_session</cite> directory under\n        current working directory.</td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_FILE_THRESHOLD</span></td>\n      <td>The maximum number of items the session stores\n        before it starts deleting some, default 500</td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_FILE_MODE</span></td>\n      <td>The file mode wanted for the session files,\n        default 0600</td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_MONGODB</span></td>\n      <td>A <span class=\"pre\">pymongo.MongoClient</span> instance, default\n        connect to <span class=\"pre\">127.0.0.1:27017</span></td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_MONGODB_DB</span></td>\n      <td>The MongoDB database you want to use, default\n        “flask_session”</td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_MONGODB_COLLECT</span></td>\n      <td>The MongoDB collection you want to use, default\n        “sessions”</td>\n    </tr>\n    <tr class=\"row-odd\">\n      <td><span class=\"pre\">SESSION_SQLALCHEMY</span></td>\n      <td>A <span class=\"pre\">flask.ext.sqlalchemy.SQLAlchemy</span> instance\n        whose database connection URI is configured\n        using the <span class=\"pre\">SQLALCHEMY_DATABASE_URI</span> parameter</td>\n    </tr>\n    <tr class=\"row-even\">\n      <td><span class=\"pre\">SESSION_SQLALCHEMY_TABLE</span></td>\n      <td>The name of the SQL table you want to use,\n        default “sessions”</td>\n    </tr>\n  </tbody>\n    </table>\n</div>\n<h3 id=\"using-redis-for-cached-session-information\">Using Redis For Cached Session Information</h3><p>For the sake of trying something different, I've opted to pick up a tiny Redis instance from <a href=\"https://redislabs.com/\"><strong>redislabs</strong></a>. I can't help myself but wasting money on new services to play with; after all, check out how cool this little red box looks:</p>\n<!-- Strengths -->\n<div id=\"unique\">\n  <!-- Headline -->\n  <h2>Redis Enterprise: A Unique Primary Database</h2>\n  <div class=\"item-scale item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-performance-reverse.svg\">\n    <h3>Perfomance at Scale</h3>\n    <ul>\n      <li>50M ops/sec,\n        <1ms 26=\"\" latency,=\"\" with=\"\" only=\"\" cloud=\"\" instances<=\"\" li=\"\"> <li>Symmetric shared–nothing architecture ensures no performance overheads while scaling, auto-sharding and re-balancing</li>\n      <li>Enhanced connection management, pipeline execution and request scheduling</li>\n    </1ms></li></ul>\n  </div>\n  <div class=\"item-search item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-search-reverse.svg\">\n    <h3>Built-in high performance search</h3>\n    <ul>\n      <li>High performance, real-time indexing with items available for search within 1ms</li>\n      <li>Predictable high performance querying while maintaining concurrent loads of indexing and querying</li>\n      <li>Highly scalable across multiple nodes to billions of items per second </li>\n    </ul>\n  </div>\n  <div class=\"item-fail item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-fail-reverse.svg\" class=\"popup-image\">\n    <h3>Failsafe high availability</h3>\n    <ul>\n      <li>Cross-rack/zone/datacenter/geo replication</li>\n      <li>Instant auto-failover in single digit second</li>\n      <li>Zero impact on throughput and latency during cluster operations such as scaling, upgrades, re-sharding and rebalancing</li>\n      <li>Out-of-the box support for backup, restore and DR</li>\n    </ul>\n  </div>\n  <div class=\"item-geo item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-geo-reverse.svg\" class=\"popup-image\">\n    <h3>Active-active geo distribution</h3>\n    <ul>\n      <li>Reads/Writes in multiple geo regions to the same dataset</li>\n      <li>Local latencies, global availability</li>\n      <li>Built-in conflict resolution for simple and complex data types</li>\n      <li>Based on revolutionary CRDT academic research</li>\n    </ul>\n  </div>\n  <div class=\"item-persist item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-persist-reverse.svg\" class=\"popup-image\">\n    <h3>Built-in persistence</h3>\n    <ul>\n      <li>Enhanced storage engine for parallel access to any persistent storage</li>\n      <li>Multiple options for enhanced data persistence</li>\n      <li>Reliable persistence configurations on both master and slave shards with zero performance impact</li>\n    </ul>\n  </div>\n  <div class=\"item-multi item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-multi-reverse.svg\" class=\"popup-image\">\n    <h3>Multi-model</h3>\n    <ul>\n      <li>Graph, JSON, Machine Learning and Bloom filter modules set industry standards for high performance</li>\n      <li>Multi-shard coordination</li>\n      <li>Extensibility with custom modules</li>\n    </ul>\n  </div>\n  <div class=\"item-tiered item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-tiered-reverse.svg\" class=\"popup-image\">\n    <h3>Intelligent tiered access to memory</h3>\n    <ul>\n      <li>Up to 80% lower infrastructure costs by running Redis on Flash</li>\n      <li>Automatic management of data tiering between RAM &amp; Flash with no code changes</li>\n      <li>Supports all new persistent memory technologies</li>\n    </ul>\n  </div>\n  <div class=\"item-deploy item hidden\">\n    <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-deploy-reverse.svg\" class=\"popup-image\">\n    <h3>Flexible deployment options</h3>\n    <ul>\n      <li>Hybrid clusters can span on-prem infrastructure and multiple clouds</li>\n      <li>Most efficient use of resources with maximized core usage, multi-tenancy, re-sharding and re-balancing to avoid noisy neighbors in every environment</li>\n    </ul>\n  </div>\n  <!-- Categories -->\n  <!-- Desktop Grid -->\n  <div class=\"strengths\">\n    <!-- Grid - Row -->\n\n    <div class=\"main-flex\">\n      <div class=\"columns medium-4 left parent\">\n        <div class=\"columns feature item-fast scale\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Perfomance at Scale\n          </div>\n        </div>\n\n        <div class=\"columns feature item-durable persistence\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Built-in persistence\n          </div>\n        </div>\n\n        <div class=\"columns feature item-durable failsafe\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Failsafe high availability\n          </div>\n        </div>\n\n        <div class=\"columns feature item-durable geo\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Active-active geo distribution\n          </div>\n        </div>\n\n      </div>\n      <div class=\"columns medium-4 center parent\">\n        <div class=\"redis red-strengths\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/redis-e-logo.svg\" alt=\"Redis Labs\">\n        </div>\n      </div>\n      <div class=\"columns medium-4 right parent\">\n        <div class=\"columns feature right item-fast search\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Built-in high performance search\n          </div>\n        </div>\n\n        <div class=\"columns feature item-flex multi\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Multi-model\n          </div>\n        </div>\n\n        <div class=\"columns feature item-flex vert tiered\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Intelligent tiered access to memory\n            <br>(RAM and Flash)\n          </div>\n        </div>\n\n        <div class=\"columns feature item-flex vert deploy\">\n          <div class=\"img\">\n          </div>\n          <div class=\"text\">\n            Flexible deployment options\n            <br>(cloud, on-prem, hybrid)\n          </div>\n        </div>\n\n\n      </div>\n\n    </div>\n\n    <!-- Grid - Redis Logo-->\n\n  </div>\n  <!-- End Desktop Grid -->\n\n\n\n  <div class=\"grid-container mobile-grid\">\n    <div class=\"redis-mobile red-strengths\">\n      <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/redis-e-logo.svg\" alt=\"Redis Labs\">\n    </div>\n    <!-- Column 1 -->\n    <div class=\"mobile-flex\">\n      <div class=\"columns small-12 medium-4\">\n        <h3>Fast</h3>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-performance.svg\">\n          <span class=\"text short\">\n            Performance at scale\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-search.svg\">\n          <span class=\"text med\">\n            Built-in high performance search\n          </span>\n        </div>\n      </div>\n      <!-- End Column 1 -->\n      <!-- Column 2 -->\n      <div class=\"columns small-12 medium-4\">\n        <h3>Reliable</h3>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-persist.svg\">\n          <span class=\"text short\">\n            Built-in persistence\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-fail.svg\">\n          <span class=\"text short med\">\n            Failsafe high availability\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-geo.svg\">\n          <span class=\"text med\">\n            Active-active geo distribution\n          </span>\n        </div>\n      </div>\n      <!-- End Column 2 -->\n      <!-- Column 3 -->\n      <div class=\"columns small-12 medium-4\">\n        <h3>Flexible</h3>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-multi.svg\">\n          <span class=\"text short\">\n            Multi-model\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-deploy.svg\">\n          <span class=\"text long\">\n            Flexible deployment options <span class=\"small\">(cloud, hybrid, on-prem)</span>\n          </span>\n        </div>\n        <div class=\"columns\">\n          <img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/ico-front-tiered.svg\">\n          <span class=\"text long\">\n            Intelligent tiered access to memory <span class=\"small\">(ram and flash)</span>\n          </span>\n        </div>\n      </div>\n    </div>\n    <!-- End Column 3 -->\n  </div>\n</div>\n<span style=\"color: #969696;\n    text-align: center;\n    display: block;\n    font-weight: 100;\n    font-style: italic;\n    margin-bottom: 30px;\n    font-size: .9em;\">(Why am I not getting paid for this? Why did I take the time to even make that module?)</span><p><strong>Redis</strong> is NoSQL datastore written in C intended to temporarily hold data in memory for users as they blaze mindlessly through your site. Other use cases include serving as the foundation for real-time chat apps via the publish/subscribe messaging paradigm; popular amongst stupid chat or dating apps slowly destroying our abilities as human beings to interact face-to-face. Powerful stuff.</p><h2 id=\"structuring-init-py-correctly\">Structuring <strong>init</strong>.py Correctly</h2><p>Consider this to be the guide to Flask Application factories I wish I had months ago. A healthy application factory should:</p><ul><li>Derive all app configuration values from a class or environment variables.</li><li>Allow Database interactions to occur at any point within the app.</li><li>Pass values globally outside of the application context.</li></ul><p>This does all of those things:</p><pre><code class=\"language-python\">from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_session import Session\nfrom flask_redis import FlaskRedis\n\n# Globally accessible libraries\ndb = SQLAlchemy()\nr = FlaskRedis()\n\n\ndef create_app():\n    &quot;&quot;&quot;Initialize the core application.&quot;&quot;&quot;\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n\n    with app.app_context():\n        # Set global session variables\n        r.set('endpoint', str(app.config['ENDPOINT']).encode('utf-8'))\n        r.set('post_query', str(app.config['POST_QUERY']).encode('utf-8'))\n        \n        # Initialize Global Libraries\n        redis_store.init_app(app)\n        db.init_app(app)\n\n        # Include our Routes\n        from . import routes\n\n        return app\n</code></pre>\n<p>The order of operations here is critical.</p><p>Before we do anything related to the app itself, we create instances of <code>flask_sqlalchemy</code> and <code>flask_redis</code>. This will be initialized with our app once we actually have one created.</p><p>The first two lines of <code>create_app()</code> should be no surprise: we're just creating our Flask app, and stating that it should be configured using a class called <strong>Config</strong> in a file named <strong>config.py.</strong></p><pre><code class=\"language-python\">app = Flask(__name__, instance_relative_config=False)\napp.config.from_object('config.Config')\n</code></pre>\n<p>Moving down the function comes the moment of truth: <strong>creating the app context.</strong> What happens in the app context stays in the app context... except for our sick new Redis setup. By using the Redis <code>.set()</code> method, we can assign <em>key/value pairs</em> for Redis hang on to, such as values from our app config which might be needed elsewhere in our app: <code>r.set('endpoint', str(app.config['ENDPOINT']).encode('utf-8'))</code>.</p><div class=\"protip\">\n    Redis stores information as bytes by default, thus attempting to pass values such as strings will result in the infamous `b'leading letter b'` phenomenon. Be sure to encode your values as utf-8 when using set(), and decode when using get().\n</div><h3 id=\"making-redis-globally-available\">Making Redis Globally Available</h3><p>The next part is important: we need to 'initialize' the services we want to use globally (such as database access or Redis) by using <code>init_app()</code>. This <em>must </em>happen inside the application context, with the parameter being <code>app</code>. This is our way of achieving singularity into inter-dimensional travel, thus breaking out of the dreaded application context long after it dies.</p><h2 id=\"let-s-access-some-variables-baby\">Let's Access Some Variables, Baby</h2><p>The moment of truth: will this actually work? Or am I actually a filthy liar flooding the internet with more uselessly outdated Flask advice? Let's see:</p><pre><code class=\"language-python\"># routes.py\n\nfrom flask import current_app as app\nfrom flask import make_response\nimport json\nfrom . import models\nfrom . import r\n\nheaders = { 'Access-Control-Allow-Headers': 'Content-Type' }\n\n\n@app.route('/', methods=['GET', 'POST'])\ndef entry():\n    readers = models.Readers.query.filter_by(username='john').all()\n    print(readers)\n    print(r.get('uri').decode('utf-8'))\n    return make_response(str('readers'), 200, headers)\n</code></pre>\n<p>Eureka! This worthless entry-point prints two things: the value we assigned to our Redis block, and all records in our database of people named John:</p><pre><code class=\"language-bash\">&gt;&gt; [&lt;User john&gt;]\n&gt;&gt; https://us1-hackersandslackers-543.cloudfunctions.net/link-endpoint?url=\n</code></pre>\n<p>As simple and stupid as it seems, developing an app to this point <em>while understanding why it works</em> is a victory for any developer. I complain about this nearly every post, but the fact of the matter is that the heroes who build much of today's technologies commonly fail to explain their own art in understandable terms. It's an understandable phenomenon resulting from isolated spurts of genius, perhaps, but it damages the growth of companies and humanity alike.</p><p>So I guess this is my calling: writing documentation for other people's accomplishments. <strong>\"Marginally less confusing than 4 open Stackoverflow tabs.\"</strong> That's what I hope to have engraved on my gravestone.</p><p>Merry Christmas.</p>","url":"https://hackersandslackers.com/demystifying-flasks-application-context/","uuid":"ede882df-a696-43ef-a392-9430d98a961e","page":false,"codeinjection_foot":"<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/autoNumeric.min.js\"></script>\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/underscore-min.js\"></script>\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/mustache.min.js\"></script>\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/owl.js\"></script>\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/jquery.counterup.min.js\"></script>\n\n\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/foundation.js\"></script>\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/docker.js\"></script>\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/jquery.fancybox.pack.js\"></script>\n<script type=\"text/javascript\" async=\"\" src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/scripts.js\"></script>","codeinjection_head":"<link rel=\"stylesheet\" href=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/redis/redislast2.css\">","comment_id":"5c192cdba632c8240cad3869"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673740","title":"The Many Faces and Filetypes of Python Configs","slug":"simplify-your-python-projects-configuration","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/11/config@2x.jpg","excerpt":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files.","custom_excerpt":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files.","created_at_pretty":"29 November, 2018","published_at_pretty":"29 November, 2018","updated_at_pretty":"27 December, 2018","created_at":"2018-11-29T02:24:13.000-05:00","published_at":"2018-11-29T16:40:26.000-05:00","updated_at":"2018-12-26T23:23:54.000-05:00","meta_title":"Simplify Your Python Project Configuration | Hackers and Slackers","meta_description":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files. Adopt a feel for when certain files or classes fit your needs best.","og_description":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files. Adopt a feel for when certain files or classes fit your needs best.","og_image":"https://hackersandslackers.com/content/images/2018/11/config@2x.jpg","og_title":"The Many Faces and Files of Python Configs","twitter_description":"Cleverly (or uncleverly) configure your Python project using .ini, .yaml, or .env files. Adopt a feel for when certain files or classes fit your needs best.","twitter_image":"https://hackersandslackers.com/content/images/2018/11/config@2x.jpg","twitter_title":"The Many Faces and Files of Python Configs","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"As we cling harder and harder to Dockerfiles, Kubernetes, or any modern\npreconfigured app environment, our dependency on billable boilerplate grows.\nWhether or not that is a problem is a conversation in itself. The longer I keep\nmy projects self-hosted, the more  I'm consumed by the open-ended approaches\npeople take to manage their project configuration variables.\n\nFull disclosure here: this post is probably about as boring as where you see\nthis heading. Today, I'm here to talk about Python Environment and general\nconfiguration variable handling.\n\nPick Your Poison\nSomeday, each and every one of us will die. I'm referring of course to the part\ninside of us that slowly withers away as we're forced to maintain projects we've\nhanded off. We can do our best to avoid these situations by isolating the\nvariables most subject to change in separate, easy-to-edit files for Person\nNumber 2 to pick up on.\n\nOption 1: Project Config via .ini Files\n.ini  files are simple, making them perfect for simple projects- especially\nthose to be handled by others why may not have development backgrounds. These\nare configuration files with a single-level hierarchy:\n\n[GLOBAL]\nPROJECT: Fake Example Project\nREGION: us-east-1\nINPUT_FOLDER: data/zip/\nOUTPUT_FOLDER: data/output/\nTIMEOUT: 200\nMEMORY: 512\n\n[PROD]\nDATABASE = postgresql://loser:weakpassword@localhost:5432/mydatabase\nENDPOINT = https://production.endpoint.example.com\nUSER = PROD_USERNAME\n\n[DEV]\nDATABASE = postgresql://loser:weakpassword@localhost:5432/mydatabase\nENDPOINT = https://dev.endpoint.example.com\nUSER = DEV_USERNAME\n\n\nAnother example, for instance, may be to specify AWS Services:\n\n[S3]\nBUCKET_NAME: public-bucket\nBUCKET_FOLDER: /\n\n[RDS]\nNAME: rds/prod/sensitivedata\nARN: arn:aws:rds:us-east-1:66574567568434896:secret:rds/prod/peopledata-ZvJ3Ys\nREGION: us-east-1\n\n[LAMBDA]\nFUNCTION_NAME: handler\nHANDLER: lambda.handler\nDESCRIPTION: Performs a task every now and then.\nRUNTIME: python3.7\nROLE: lambda_role\nDIST_FOLDER: lambda/dist\n\n[SECRETS]\nSECRET_NAME: rds/prod/totallysecret\nSECRET_ARN: arn:aws:secretsmanager:us-east-1:769979969:secret:rds/prod/stupidproject-5647\n\n\n.ini  files are handled in Python by the configparser  library; this is our way\nof doing something with the essentially static text in these files. Since we're\nkeeping vars separate from app source code, we now need to create a file and a\nclass which exists merely to access these values.\n\nCreating a Python Class to Extract Variables\nInstead of explicitly hardcoding a dump of all variables, we're going to create\na class that provides an easy syntax for accessing variables on demand. Check it\nout:\n\n# config_loader.py\nfrom configparser import SafeConfigParser\nimport os\n\n\nclass Config:\n    \"\"\"Interact with configuration variables.\"\"\"\n\n    configParser = SafeConfigParser()\n    configFilePath = (os.path.join(os.getcwd(), 'config.ini'))\n\n    @classmethod\n    def initialize(cls, newhire_table):\n        \"\"\"Start config by reading config.ini.\"\"\"\n        cls.configParser.read(cls.configFilePath)\n\n    @classmethod\n    def prod(cls, key):\n        \"\"\"Get prod values from config.ini.\"\"\"\n        return cls.configParser.get('PROD', key)\n\n    @classmethod\n    def dev(cls, key):\n        \"\"\"Get dev values from config.ini.\"\"\"\n        return cls.configParser.get('DEV', key)\n\n\nThis simple class goes a long way to simplify grabbing variables. The class\nnever needs to be instantiated, so we can import Config  wherever we please and\nimmediately start pulling values.\n\nTo separate variables by concern, each block in config.ini  receives its own\nclass method. Now retrieving the proper variables is as simple as \nConfig.prod('DATABASE')  will return the URI for a production database. Easy to\nuse, simple to understand.\n\nOption 2: Complex YAML Configurations\nUnless you're developing apps in isolation in an isolated third-world nation or\nunder a dictatorship which blocks internet access, you already know that .yaml \nfiles are all the rage when it comes to storing static values in text files\n(wow, this really is  an obscure topic for a post).\n\nYAML  files provide plenty of upsides to alternative file types. Where .ini \nfiles are simply grouped variables, YAML  provides a hierarchy structure. This\nmakes YAML files much easier to understand and maintain for larger applications,\nas some variables only make sense in the context of being a sub-variable (?).\n\nCheck out what a sample YAML config might look like:\n\n---\n\nappName: appName\nlogLevel: WARN\n\nAWS:\n    Region: us-east-1\n    Resources:\n      EC2: \n        Type: \"AWS::EC2::Instance\"\n        Properties: \n          ImageId: \"ami-0ff8a91507f77f867\"\n          InstanceType: t2.micro\n          KeyName: testkey\n          BlockDeviceMappings:\n            -\n              DeviceName: /dev/sdm\n              Ebs:\n                VolumeType: io1\n                Iops: 200\n                DeleteOnTermination: false\n                VolumeSize: 20\n      Lambda:\n          Type: \"AWS::Lambda::Function\"\n          Properties: \n            Handler: \"index.handler\"\n            Role: \n              Fn::GetAtt: \n                - \"LambdaExecutionRole\"\n                - \"Arn\"\n            Runtime: \"python3.7\"\n            Timeout: 25\n            TracingConfig:\n              Mode: \"Active\"\n\nroutes:\n  admin:\n    url: /admin\n    template: admin.html\n    assets:\n        templates: /templates\n        static: /static\n  dashboard:\n    url: /dashboard\n    template: dashboard.html\n    assets:\n        templates: /templates\n        static: /static\n  account:\n    url: /account\n    template: account.html\n    assets:\n        templates: /templates\n        static: /static\n        \ndatabases:\n  cassandra:\n    host: example.cassandra.db\n    username: user\n    password: password\n  redshift:\n    jdbcURL: jdbc:redshift://<IP>:<PORT>/file?user=username&password=pass\n    tempS3Dir: s3://path/to/redshift/temp/dir/ \n  redis:\n    host: hostname\n    port: port-number\n    auth: authentication\n    db: database\n\n\nThis would read horribly if we tried to fit this in an .ini  file. A more fair\ncomparison would be to JSON  configurations: JSON objects indeed share the same\nhierarchy advantages of YAML, but JSON syntax is prone to errors and unhelpful\nerror messages, thanks to being a brainchild of Old Man JavaScript. YAML doesn't\ncare if you open and close with brackets, use double quotes, or leave a trailing\ncomma. All of these stupid things are why I prefer Python.\n\nParsing YAML in Python\nI recommend the Python Confuse library [https://github.com/sampsyo/confuse]  (a\npackage name that's sure to raise some eyebrows by your company's information\nsecurity team).\n\nConfuse  allows use to interact with YAML files almost identically to how we\nwould with JSON, with the exception that we specify .get()  at the end of\nwalking through the tree hierarchy, like so:\n\nconfig = confuse.Configuration('MyApp', __name__)\n\nconfig['AWS']['Lambda']['Runtime'].get()\n\n\n.get()  can accept a datatype value such as int. Doing so ensures that the value\nwe're getting is actually of the schema we're expecting, which is a neat\nfeature.\n\nValidators\nConfuse's documentation [https://confuse.readthedocs.io/en/latest/]details\nadditional validation methods for values we pull from YAML files. Methods like \nas_filename(), as_number(), and as_str_seq()  do basically what you'd expect\nthem to.\n\nCLI Configuration\nConfuse also gets into the realm of building CLIs, allowing use to use our YAML\nfile to inform arguments which can be passed to a CLI and their potential\nvalues:\n\nconfig = confuse.Configuration('myapp')\nparser = argparse.ArgumentParser()\nparser.add_argument('--foo', help='a parameter')\nargs = parser.parse_args()\nconfig.set_args(args)\nprint(config['foo'].get())\n\n\nThere's plenty of things you can go nuts with here.\n\nOption 3: Using .env Config Files\nLastly, we can leverage the already well-known .env  format to set variables.\nWorking this way is pretty equivalent to working with .ini  files, but we're\nhuman beings so we're stupid and do things like build the same protocols over\nand over. In .env, we get to store beautiful values such as these:\n\nCONFIG_PATH=${HOME}/.config/foo\nDOMAIN=example.org\nEMAIL=admin@${DOMAIN}\n\nTo read these values, we'll be using the python-dotenv library\n[https://github.com/theskumar/python-dotenv]. This gets you started:\n\nfrom dotenv import load_dotenv\nfrom pathlib import Path\n\nload_dotenv(verbose=True)\n\nenv_path = Path('.') / '.env'\nload_dotenv(dotenv_path=env_path)\n\n\nAfter that, it's a matter of setting variables in Python to values you extract\nfrom .env:\n\nimport os\nSECRET_KEY = os.getenv(\"EMAIL\")\nDATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\")\n\n\nSo Yeah, Basically Just Use What You Want\nClearly there are plenty of ways to set environment and project variables in\nPython. We could spend all day investigating the nuances of each and how their\naccompanying Python configuration class should be structured, but we've got apps\nto build. \n\nBesides, I need to go reflect on my life after writing a thousand words about\nloading variables in Python.","html":"<p>As we cling harder and harder to Dockerfiles, Kubernetes, or any modern preconfigured app environment, our dependency on billable boilerplate grows. Whether or not that is a problem is a conversation in itself. The longer I keep my projects self-hosted, the more  I'm consumed by the open-ended approaches people take to manage their project configuration variables.</p><p>Full disclosure here: this post is probably about as boring as where you see this heading. Today, I'm here to talk about Python Environment and general configuration variable handling.</p><h2 id=\"pick-your-poison\">Pick Your Poison</h2><p>Someday, each and every one of us will die. I'm referring of course to the part inside of us that slowly withers away as we're forced to maintain projects we've handed off. We can do our best to avoid these situations by isolating the variables most subject to change in separate, easy-to-edit files for Person Number 2 to pick up on.</p><h2 id=\"option-1-project-config-via-ini-files\">Option 1: Project Config via .ini Files</h2><p><code>.ini</code> files are simple, making them perfect for simple projects- especially those to be handled by others why may not have development backgrounds. These are configuration files with a single-level hierarchy:</p><pre><code class=\"language-ini\">[GLOBAL]\nPROJECT: Fake Example Project\nREGION: us-east-1\nINPUT_FOLDER: data/zip/\nOUTPUT_FOLDER: data/output/\nTIMEOUT: 200\nMEMORY: 512\n\n[PROD]\nDATABASE = postgresql://loser:weakpassword@localhost:5432/mydatabase\nENDPOINT = https://production.endpoint.example.com\nUSER = PROD_USERNAME\n\n[DEV]\nDATABASE = postgresql://loser:weakpassword@localhost:5432/mydatabase\nENDPOINT = https://dev.endpoint.example.com\nUSER = DEV_USERNAME\n</code></pre>\n<p>Another example, for instance, may be to specify AWS Services:</p><pre><code class=\"language-ini\">[S3]\nBUCKET_NAME: public-bucket\nBUCKET_FOLDER: /\n\n[RDS]\nNAME: rds/prod/sensitivedata\nARN: arn:aws:rds:us-east-1:66574567568434896:secret:rds/prod/peopledata-ZvJ3Ys\nREGION: us-east-1\n\n[LAMBDA]\nFUNCTION_NAME: handler\nHANDLER: lambda.handler\nDESCRIPTION: Performs a task every now and then.\nRUNTIME: python3.7\nROLE: lambda_role\nDIST_FOLDER: lambda/dist\n\n[SECRETS]\nSECRET_NAME: rds/prod/totallysecret\nSECRET_ARN: arn:aws:secretsmanager:us-east-1:769979969:secret:rds/prod/stupidproject-5647\n</code></pre>\n<p><code>.ini</code> files are handled in Python by the <strong>configparser</strong> library; this is our way of doing something with the essentially static text in these files. Since we're keeping vars separate from app source code, we now need to create a file and a class which exists merely to access these values.</p><h3 id=\"creating-a-python-class-to-extract-variables\">Creating a Python Class to Extract Variables</h3><p>Instead of explicitly hardcoding a dump of all variables, we're going to create a class that provides an easy syntax for accessing variables on demand. Check it out:</p><pre><code class=\"language-python\"># config_loader.py\nfrom configparser import SafeConfigParser\nimport os\n\n\nclass Config:\n    &quot;&quot;&quot;Interact with configuration variables.&quot;&quot;&quot;\n\n    configParser = SafeConfigParser()\n    configFilePath = (os.path.join(os.getcwd(), 'config.ini'))\n\n    @classmethod\n    def initialize(cls, newhire_table):\n        &quot;&quot;&quot;Start config by reading config.ini.&quot;&quot;&quot;\n        cls.configParser.read(cls.configFilePath)\n\n    @classmethod\n    def prod(cls, key):\n        &quot;&quot;&quot;Get prod values from config.ini.&quot;&quot;&quot;\n        return cls.configParser.get('PROD', key)\n\n    @classmethod\n    def dev(cls, key):\n        &quot;&quot;&quot;Get dev values from config.ini.&quot;&quot;&quot;\n        return cls.configParser.get('DEV', key)\n</code></pre>\n<p>This simple class goes a long way to simplify grabbing variables. The class never needs to be instantiated, so we can <code>import Config</code> wherever we please and immediately start pulling values.</p><p>To separate variables by concern, each block in <code>config.ini</code> receives its own class method. Now retrieving the proper variables is as simple as <code>Config.prod('DATABASE')</code> will return the URI for a production database. Easy to use, simple to understand.</p><h2 id=\"option-2-complex-yaml-configurations\">Option 2: Complex YAML Configurations</h2><p>Unless you're developing apps in isolation in an isolated third-world nation or under a dictatorship which blocks internet access, you already know that <code>.yaml</code> files are all the rage when it comes to storing static values in text files (wow, this really <em>is</em> an obscure topic for a post).</p><p><strong>YAML</strong> files provide plenty of upsides to alternative file types. Where <strong>.ini</strong> files are simply grouped variables, <strong>YAML</strong> provides a hierarchy structure. This makes YAML files much easier to understand and maintain for larger applications, as some variables only make sense in the context of being a sub-variable (?).</p><p>Check out what a sample YAML config might look like:</p><pre><code class=\"language-yaml\">---\n\nappName: appName\nlogLevel: WARN\n\nAWS:\n    Region: us-east-1\n    Resources:\n      EC2: \n        Type: &quot;AWS::EC2::Instance&quot;\n        Properties: \n          ImageId: &quot;ami-0ff8a91507f77f867&quot;\n          InstanceType: t2.micro\n          KeyName: testkey\n          BlockDeviceMappings:\n            -\n              DeviceName: /dev/sdm\n              Ebs:\n                VolumeType: io1\n                Iops: 200\n                DeleteOnTermination: false\n                VolumeSize: 20\n      Lambda:\n          Type: &quot;AWS::Lambda::Function&quot;\n          Properties: \n            Handler: &quot;index.handler&quot;\n            Role: \n              Fn::GetAtt: \n                - &quot;LambdaExecutionRole&quot;\n                - &quot;Arn&quot;\n            Runtime: &quot;python3.7&quot;\n            Timeout: 25\n            TracingConfig:\n              Mode: &quot;Active&quot;\n\nroutes:\n  admin:\n    url: /admin\n    template: admin.html\n    assets:\n        templates: /templates\n        static: /static\n  dashboard:\n    url: /dashboard\n    template: dashboard.html\n    assets:\n        templates: /templates\n        static: /static\n  account:\n    url: /account\n    template: account.html\n    assets:\n        templates: /templates\n        static: /static\n        \ndatabases:\n  cassandra:\n    host: example.cassandra.db\n    username: user\n    password: password\n  redshift:\n    jdbcURL: jdbc:redshift://&lt;IP&gt;:&lt;PORT&gt;/file?user=username&amp;password=pass\n    tempS3Dir: s3://path/to/redshift/temp/dir/ \n  redis:\n    host: hostname\n    port: port-number\n    auth: authentication\n    db: database\n</code></pre>\n<p>This would read horribly if we tried to fit this in an <strong>.ini</strong> file. A more fair comparison would be to <strong>JSON</strong> configurations: JSON objects indeed share the same hierarchy advantages of YAML, but JSON syntax is prone to errors and unhelpful error messages, thanks to being a brainchild of Old Man JavaScript. YAML doesn't care if you open and close with brackets, use double quotes, or leave a trailing comma. All of these stupid things are why I prefer Python.</p><h3 id=\"parsing-yaml-in-python\">Parsing YAML in Python</h3><p>I recommend the <a href=\"https://github.com/sampsyo/confuse\">Python <em>Confuse</em> library</a> (a package name that's sure to raise some eyebrows by your company's information security team).</p><p><strong>Confuse</strong> allows use to interact with YAML files almost identically to how we would with JSON, with the exception that we specify <code>.get()</code> at the end of walking through the tree hierarchy, like so:</p><pre><code class=\"language-python\">config = confuse.Configuration('MyApp', __name__)\n\nconfig['AWS']['Lambda']['Runtime'].get()\n</code></pre>\n<p><strong>.get()</strong> can accept a datatype value such as <em>int. </em>Doing so ensures that the value we're getting is actually of the schema we're expecting, which is a neat feature.</p><h4 id=\"validators\">Validators</h4><p><a href=\"https://confuse.readthedocs.io/en/latest/\">Confuse's documentation </a>details additional validation methods for values we pull from YAML files. Methods like <code>as_filename()</code>, <code>as_number()</code>, and <code>as_str_seq()</code> do basically what you'd expect them to.</p><h4 id=\"cli-configuration\">CLI Configuration</h4><p>Confuse also gets into the realm of building CLIs, allowing use to use our YAML file to inform arguments which can be passed to a CLI and their potential values:</p><pre><code class=\"language-python\">config = confuse.Configuration('myapp')\nparser = argparse.ArgumentParser()\nparser.add_argument('--foo', help='a parameter')\nargs = parser.parse_args()\nconfig.set_args(args)\nprint(config['foo'].get())\n</code></pre>\n<p>There's plenty of things you can go nuts with here.</p><h2 id=\"option-3-using-env-config-files\">Option 3: Using .env Config Files</h2><p>Lastly, we can leverage the already well-known <code>.env</code> format to set variables. Working this way is pretty equivalent to working with <strong>.ini</strong> files, but we're human beings so we're stupid and do things like build the same protocols over and over. In <strong>.env</strong>, we get to store beautiful values such as these:</p><pre><code>CONFIG_PATH=${HOME}/.config/foo\nDOMAIN=example.org\nEMAIL=admin@${DOMAIN}</code></pre><p>To read these values, we'll be using the <a href=\"https://github.com/theskumar/python-dotenv\"><strong>python-dotenv</strong> library</a>. This gets you started:</p><pre><code class=\"language-python\">from dotenv import load_dotenv\nfrom pathlib import Path\n\nload_dotenv(verbose=True)\n\nenv_path = Path('.') / '.env'\nload_dotenv(dotenv_path=env_path)\n</code></pre>\n<p>After that, it's a matter of setting variables in Python to values you extract from <code>.env</code>:</p><pre><code class=\"language-python\">import os\nSECRET_KEY = os.getenv(&quot;EMAIL&quot;)\nDATABASE_PASSWORD = os.getenv(&quot;DATABASE_PASSWORD&quot;)\n</code></pre>\n<h2 id=\"so-yeah-basically-just-use-what-you-want\">So Yeah, Basically Just Use What You Want</h2><p>Clearly there are plenty of ways to set environment and project variables in Python. We could spend all day investigating the nuances of each and how their accompanying Python configuration class should be structured, but we've got apps to build. </p><p>Besides, I need to go reflect on my life after writing a thousand words about loading variables in Python.</p>","url":"https://hackersandslackers.com/simplify-your-python-projects-configuration/","uuid":"48fb64b7-b9f2-4605-ac1f-c1c45ffc5964","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5bff941deae98c3b9d4c25f4"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867373d","title":"MongoDB Cloud: \"Backend as a Service\" with Atlas & Stitch","slug":"mongodb-cloud-backend-as-a-service-with-atlas-and-stitch","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/11/mongodbcloud@2x.jpg","excerpt":"MongoDB's silent transformation from an open-source database to enterprise cloud provider.","custom_excerpt":"MongoDB's silent transformation from an open-source database to enterprise cloud provider.","created_at_pretty":"13 November, 2018","published_at_pretty":"15 November, 2018","updated_at_pretty":"15 February, 2019","created_at":"2018-11-13T16:05:20.000-05:00","published_at":"2018-11-15T08:00:00.000-05:00","updated_at":"2019-02-15T12:49:05.000-05:00","meta_title":"MongoDB Cloud: \"Backend as a Service\" | Hackers and Slackers","meta_description":"Breaking down MongoDB Atlas and MongoDB Stitch to fully assess the capabilities of an unlikely cloud platform.","og_description":"Breaking down MongoDB Atlas and MongoDB Stitch to fully assess the capabilities of an unlikely cloud platform.","og_image":"https://hackersandslackers.com/content/images/2018/11/mongodbcloud@2x.jpg","og_title":"MongoDB Cloud: \"Backend as a Service\" with Atlas And Stitch","twitter_description":"Breaking down MongoDB Atlas and MongoDB Stitch to fully assess the capabilities of an unlikely cloud platform.","twitter_image":"https://hackersandslackers.com/content/images/2018/11/mongodbcloud@2x.jpg","twitter_title":"MongoDB Cloud: \"Backend as a Service\" with Atlas And Stitch","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"Unless you've been living under a rock (or only visit this site via work-related\nGoogle Searches, like most people) you've probably heard me drone on here and\nthere about MongoDB Atlas  and MongoDB Stitch. I even went so far as to hack\ntogether an awful workflow that somehow utilized Tableau as an ETL tool to feed\nJIRA information into Mongo. I'd like to formally apologize for that entire\nseries: I can't imagine there's a single soul on this planet interested in\nlearning about all of those things simultaneously. Such hobbies reserved for\nmasochists with blogging addictions. I apologize. Let's start over.\n\nFirst off, this is not a tutorial on how to use MongoDB: the database. I have\nzero interest cluttering the internet by reiterating what a MEAN stack is for\nthe ten thousandth time, nor will I bore you with core NoSQL concepts you\nalready understand. I'm here to talk about the giant on the horizon we didn't\nsee coming, where MongoDB the database decided to become MongoDB Inc\n[https://en.wikipedia.org/wiki/MongoDB_Inc.]:  the enterprise cloud provider.\nThe same MongoDB that recently purchased mLab\n[https://www.mongodb.com/press/mongodb-strengthens-global-cloud-database-with-acquisition-of-mlab]\n, the other  cloud-hosted solution for Mongo databases. MongoDB the company is\nbold enough to place its bets on building a cloud far  simpler and restricted\nthan either AWS or GCloud. The core of that bet implies that most of us aren't\nexactly building unicorn products as much as we're reinventing the wheel: and\nthey're probably right.\n\nWelcome to our series on MongoDB cloud, where we break down every service\nMongoDB has to offer; one by one.\n\nWhat is MongoDB Cloud, and Does it Exist?\nWhat I refer to as \"MongoDB Cloud\" (which, for some reason, isn't the actual\nname of the suite MongoDB offers) is actually two products:\n\n * MongoDB Atlas: A cloud-hosted MongoDB cluster with a beefy set of features.\n   Real-time dashboards, high-availability, security features,  an awesome\n   desktop client, and a CLI to top it all off.\n * MongoDB Stitch: A group of services designed to interact with Atlas in every\n   conceivable way, including creating endpoints, triggers, user authentication\n   flows, serverless functions, and a UI to handle all of this.\n\nI'm spying on you and every query you make.Atlas as a Standalone Database\nThere are plenty of people who simply want an instance of MongoDB hosted in the\ncloud as-is: just ask the guys at mLab. This was in fact how I got pulled into\nMongo's cloud myself.\n\nMongoDB Atlas has plenty of advantages over a self-hosted instance of Mongo,\nwhich Mongo itself is confident in by offering a free tier\n[https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/]  of Atlas to\nprospective buyers. If you're a company or enterprise, the phrases High\nAvailability, Horizontal Scalability, relatively Higher Performance  will\nprobably be enough for you. But for us hobbyists, why pay for a Mongo cloud\ninstance?\n\nMongo themselves gives this comparison:\n\nOverview\n MongoDB Atlas\n Compose\n ObjectRocket\n Free Tier\n Yes\nStorage: 512 MB\nRAM: Variable\n No\n30-day free trial\n No\n30-day free trial\n Live migration\n Yes\nNo\nNo\nChoice of cloud providers\n AWS, Azure & GCP\n AWS, Softlayer & GCP\nAvailable in 2 regions for each provider\n Rackspace\n Choice of instance configuration\n Yes\n No\nConfiguration based on required storage capacity only. No way to independently\nselect underlying hardware configurations\n No\nConfiguration based on required storage capacity only. No way to independently\nselect underlying hardware configurations\n Availability of latest MongoDB version\n Yes\nNew versions of the database are available on MongoDB Atlas as soon as they are\nreleased\n No\nNew versions typically available 1-2 quarters following database release\nNo\nNew versions typically available 1-2 quarters following database release\nReplica Set Configuration\n Up to 7 replicas\nAll replicas configured as data-bearing nodes\n 3 data-bearing nodes\nOne of the data-bearing nodes is hidden and used for backups only\n 3 data-bearing nodes\nAutomatic Sharding Support\n Yes\nNo\nYes\nData explorer\n Yes\nYes\nNo\nSQL-based BI Connectivity\n Yes\nNo\nNo\nPause and resume clusters\n Yes\nNo\nNo\nDatabase supported in on-premise deployments\n Yes\nMongoDB Enterprise Advanced [/products/mongodb-enterprise-advanced]\n No\nNo\nGlobal writes Low-latency writes from anywhere in the world Yes\n No\n No\n Cross-region replication Distribute data around the world for multi-region\nfault tolerance and local reads Yes\n No\n No\n Monitoring of database health with automated alerting\n Yes\nMongoDB Atlas UI & support for APM platforms (New Relic)\n Yes\nNew Relic\n Yes\nNew Relic\n Continuous backup\n Yes\nBackups maintained\nseconds behind production cluster\n No\nBackups taken with mongodump against hidden replica set member\n No\nBackups taken with mongodump\n Queryable backups\n Yes\nNo\nNo\nAutomated & consistent snapshots of sharded clusters\n Yes\nNot Applicable\nNo support for auto-sharding\n No\nRequires manually coordinating the recovery of mongodumps across shards\n Access control & IP whitelisting\n Yes\nYes\nYes\nAWS VPC Peering\n Yes\nBeta Release\nYes\nAdditional Charge\n Encryption of data in-flight\n Yes\nTLS/SSL as standard\n Yes\nYes\nEncryption of data at-rest\n Yes\nAvailable for AWS deployments; always on with Azure and GCP\n No\nYes\nAvailable only with specific pricing plans and data centers\n LDAP Integration\n Yes\n No\nNo\n Database-level auditing\nTrack DDL, DML, DCL operations\n Yes\n No\nNo\n Bring your own KMS\n Yes\n No\nNo\n Realistically there are probably only a number of items that stand out on the\ncomparison list when we go strictly database-to-database. Freedom over instance\nconfiguration sounds great, but in practice is more similar to putting a cap on\nhow much MongoDB decides to charge you that month (by the way, it's usually a\nlot; keep this mind). Having the Latest Version  seems great, but this can just\nas easily mean breaking production unannounced as much as it means new features.\n\nMongoDB clearly wins over the enterprise space with Continuous & queryable\nbackups, integration with LDAP, and automatic sharding support. Truthfully if\nthis were merely a database-level feature and cost comparison, the decision to\ngo with  MongoDB Atlas  would come down to how much you like their pretty\ndesktop interface:\n\nA perfectly legitimate reason to pay up, imho.So let's say MongoDB Atlas is\nmarginally better than a competitor in the confined realm of \"being a database.\"\nAre Stitch microservices enough to justify keeping your instance with the\nMongoDB team?\n\nService-by-Service Breakdown of Stitch\nStitch is kind of like if AWS exited in an alternative universe, where JSON and\nJavaScript were earth's only technologies. Thinking back to how we create APIs\nin AWS, the status quo almost always involves spinning up a Dynamo  (NoSQL)\ndatabase to put behind Lambda functions, accessible by API Gateway endpoints.\nStitch's core use case revolves around this use-case of end-user-accessing-data,\nwith a number of services dedicated specifically to supporting or improving this\nflow. The closest comparison to Stitch would be GCloud's Firebase. \n\nSo what makes Stitch so special?\n\nService 1: Querying Atlas Securely via Frontend Code\nSomething that cannot be understated is the ability to query Atlas via frontend\nJavascript. We're not passing API keys, Secrets, or any sort of nonsense;\nbecause you're configured things correctly, whitelisted domains can run queries\nof any complexity without ever interacting with an app's backend.  This is not a\ncrazy use case: consider this blog for example, or more so lately, mobile\napplications:\n\n<script src=\"https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js\"></script>\n<script>\n  const client = stitch.Stitch.initializeDefaultAppClient('myapp');\n\n  const db = client.getServiceClient(stitch.RemoteMongoClient.factory, 'mongodb-atlas').db('<DATABASE>');\n\n  client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => \n    db.collection('<COLLECTION>').updateOne({owner_id: client.auth.user.id}, {$set:{number:42}}, {upsert:true})\n  ).then(() => \n    db.collection('<COLLECTION>').find({owner_id: client.auth.user.id}, { limit: 100}).asArray()\n  ).then(docs => {\n      console.log(\"Found docs\", docs)\n      console.log(\"[MongoDB Stitch] Connected to Stitch\")\n  }).catch(err => {\n    console.error(err)\n  });\n</script>\n\n\nThis isn't to say we're allowing any user to query any data all willy-nilly just\nbecause they're on our whitelisted IP: all data stored in Atlas is restricted to\nspecified Users  by defining User Roles. Joe Schmoe can't just inject a query\ninto any presumed database and wreak havoc, because Joe Schmoe can only access\ndata we've permitted his user account to view or write to. What is this \"user\naccount\" you ask? This brings us to the next big feature...\n\nService 2: End-User Account Creation & Management\nStitch will handle user account creation for you without the boilerplate.\nCreating an app with user accounts is a huge pain in the ass. Cheeky phrases\nlike 'Do the OAuth Dance'  can't ever hope to minimize the agonizing repetitive\npain of creating user accounts or managing relationships between users and data\n(can user X  see a comment from user Y?). Stitch allows most of the intolerably\nbenign logic behind these features to be handled via a UI.\n\nIt would be a far cry to say these processes have been \"trivialized\", but the\ntime saved is perhaps just enough to keep a coding hobbyist interested in their\nside projects as opposed to giving up and playing Rocket League.\n\nAs far as the permissions to read comments go... well, here's a self-explanatory\nscreenshot of how Stitch handles read/write document permission in its simplest\nform:\n\nOwners of comments can write their comments. Everybody else reads. Seems simple.\nService 3: Serverless Functions\nStitch functions are akin to AWS Lambda functions, but much easier to configure\nfor cross-service integration (and also limited to JavaScript ECMA 2015 or\nsomething). Functions benefit from the previous two features, in that they too\ncan be triggered from a whitelisted app's frontend, and are governed by a simple\n\"rules\" system, eliminating the need for security group configurations etc.\n\nThis is what calling a function from an app's frontend looks like:\n\n<script>\n    client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user => {\n     client.callFunction(\"numCards\", [\"In Progress\"]).then(results => {\n       $('#progress .count').text(results + ' issues');\n     })\n    });\n</script>\n\n\nFunctions can run any query against Atlas, retrieve values  (such as environment\nvariables), and even call other functions. Functions can also be fired by\ndatabase triggers,  where a change to a collection will prompt an action such as\nan alert.\n\nService 4: HTTP Webhooks\nWebhooks are a fast way to toss up endpoints. Stitch endpoints are agnostic to\none another in that they are one-off URLs to perform single tasks. We could\nnever build a well-designed API using Stitch Webhooks, as we could with API\nGateway; this simply isn't the niche MongoDB is trying to hit (the opposite, in\nfact). \n\nConfiguration for a single Webhook.This form with a mere 6 fields clearly\nillustrates what Stitch intends to do: trivializing the creation of\ntraditionally non-trivial features.\n\nService 5: Storing 'Values' in Stitch\nA \"value\" is equivalent to an environment variable. These can be used to store\nAPI keys, secrets, or whatever. Of course, values are retrieved via functions.\n\nShhh, it's a secret ;)Service 6+: A Bunch of Mostly Bloated Extras\nFinally, Stitch has thrown in a few third-party integrations for good measure.\nSome integrations like S3 Integration could definitely come in handy, but it's\nworth asking why Mongo constantly over advertises their integrations with Github \n and Twilio. We've already established that we can create endpoints which accept\ninformation, and we can make functions which GET  information... so isn't\nanything with an API pretty easy to 'integrate' with?\n\nThis isn't to say the extra services aren't useful, they just seem a bit... odd.\nIt feels a lot like bloating the catalog, but the catalog isn't nearly bloated\nenough where it feels normal (like Heroku add-ons, for example). The choice to\nlaunch Stitch with a handful of barely-useful integrations only comes off as\nmore and more aimless as time passes; as months turn to years and no additions\nor updates are made to service offerings, it's worth questioning what the vision\nhad been for the product in the first place. In my experience, feature sets like\nthese happen when Product Managers are more powerful than they are useful.\n\nThe Breathtaking Climax: Is Stitch Worth It?\nI've been utilizing Stitch to fill in the blanks in development for months now,\nperhaps nearly a year. Each time I find myself working with Stitch or looking at\nthe bill, I can't decide if it's been a Godsend for its nich\u001dé, or an expensive\ntoy with an infuriating lack of accurate documentation.\n\n  Stitch is very much a copy-and-paste-cookie-cutter-code  type of product,\nwhich begs the question of why their tutorials are recklessly outdated;\nsometimes to the point where MongoDB's own tutorial source code doesn't work. \nThere are so many use cases and potential benefits to Stitch, so why is the \nGithub repo [https://github.com/mongodb/stitch-examples]  containing example\ncode snippets so unmaintained, and painfully irrelevant? Lastly, why am I\nselling this product harder than their own internal team?\n\nStitch is a good product with a lot of unfortunate oversight. That said, Google\nFirebase still doesn't even have an \"import data\" feature, so I suppose it's\ntime to dig deep into this vendor lock and write a 5-post series about it before\nSilicon Valley's best and brightest get their shit together enough to actually\ncreate something useful and intuitive for other human beings to use. In the\nmeantime, feel free to steal source from tutorials I'll be posting, because\nthey'll be sure to, you know, actually work.","html":"<p>Unless you've been living under a rock (or only visit this site via work-related Google Searches, like most people) you've probably heard me drone on here and there about <strong>MongoDB Atlas</strong> and <strong>MongoDB Stitch</strong>. I even went so far as to hack together an awful workflow that somehow utilized Tableau as an ETL tool to feed JIRA information into Mongo. I'd like to formally apologize for that entire series: I can't imagine there's a single soul on this planet interested in learning about all of those things simultaneously. Such hobbies reserved for masochists with blogging addictions. I apologize. Let's start over.</p><p>First off, this is not a tutorial on how to use <em>MongoDB: the database</em>. I have zero interest cluttering the internet by reiterating what a MEAN stack is for the ten thousandth time, nor will I bore you with core NoSQL concepts you already understand. I'm here to talk about the giant on the horizon we didn't see coming, where MongoDB the database decided to become <a href=\"https://en.wikipedia.org/wiki/MongoDB_Inc.\"><strong>MongoDB Inc</strong></a><strong>:</strong> the enterprise cloud provider. The same MongoDB that recently purchased <a href=\"https://www.mongodb.com/press/mongodb-strengthens-global-cloud-database-with-acquisition-of-mlab\">mLab</a>, the <em>other</em> cloud-hosted solution for Mongo databases. MongoDB the company is bold enough to place its bets on building a cloud <em>far</em> simpler and restricted than either AWS or GCloud. The core of that bet implies that most of us aren't exactly building unicorn products as much as we're reinventing the wheel: and they're probably right.</p><p>Welcome to our series on MongoDB cloud, where we break down every service MongoDB has to offer; one by one.</p><h2 id=\"what-is-mongodb-cloud-and-does-it-exist\">What is MongoDB Cloud, and Does it Exist?</h2><p>What I refer to as \"MongoDB Cloud\" (which, for some reason, isn't the actual name of the suite MongoDB offers) is actually two products:</p><ul><li><strong>MongoDB Atlas</strong>: A cloud-hosted MongoDB cluster with a beefy set of features. Real-time dashboards, high-availability, security features,  an awesome desktop client, and a CLI to top it all off.</li><li><strong>MongoDB Stitch: </strong>A group of services designed to interact with Atlas in every conceivable way, including creating endpoints, triggers, user authentication flows, serverless functions, and a UI to handle all of this.</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/metrics.gif\" class=\"kg-image\"><figcaption>I'm spying on you and every query you make.</figcaption></figure><h3 id=\"atlas-as-a-standalone-database\">Atlas as a Standalone Database</h3><p>There are plenty of people who simply want an instance of MongoDB hosted in the cloud as-is: just ask the guys at mLab. This was in fact how I got pulled into Mongo's cloud myself.</p><p>MongoDB Atlas has plenty of advantages over a self-hosted instance of Mongo, which Mongo itself is confident in by offering a <a href=\"https://docs.mongodb.com/manual/tutorial/atlas-free-tier-setup/\">free tier</a> of Atlas to prospective buyers. If you're a company or enterprise, the phrases <strong>High Availability</strong>, <strong>Horizontal Scalability, </strong>relatively <strong>Higher Performance</strong> will probably be enough for you. But for us hobbyists, why pay for a Mongo cloud instance?</p><p>Mongo themselves gives this comparison:</p><div class=\"tableContainer\">\n<table class=\"table left\">\n  <thead>\n    <tr>\n      <th>\n        <strong>Overview</strong>\n      </th>\n      <th>\n        <strong>MongoDB Atlas</strong>\n      </th>\n      <th>\n        <strong>Compose</strong>\n      </th>\n      <th>\n        <strong>ObjectRocket</strong>\n      </th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>\n        Free Tier\n      </td>\n      <td>\n        Yes<br><small>Storage: 512 MB<br>RAM: Variable</small>\n      </td>\n      <td>\n        No<br><small>30-day free trial</small>\n      </td>\n      <td>\n        No<br><small>30-day free trial</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Live migration\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Choice of cloud providers\n      </td>\n      <td>\n        AWS, Azure &amp; GCP\n      </td>\n      <td>\n        AWS, Softlayer &amp; GCP<br><small>Available in 2 regions for each provider</small>\n      </td>\n      <td>\n        Rackspace\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Choice of instance configuration\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small>Configuration based on required storage capacity only. No way to independently select underlying hardware configurations</small>\n      </td>\n      <td>\n        No<br><small>Configuration based on required storage capacity only. No way to independently select underlying hardware configurations</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Availability of latest MongoDB version\n      </td>\n      <td>\n        Yes<br><small>New versions of the database are available on MongoDB Atlas as soon as they are released</small>\n      </td>\n      <td>\n        No<br><small>New versions typically available 1-2 quarters following database release<br></small>\n      </td>\n      <td>\n        No<br><small>New versions typically available 1-2 quarters following database release<br></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Replica Set Configuration\n      </td>\n      <td>\n        Up to 7 replicas<br><small>All replicas configured as data-bearing nodes</small>\n      </td>\n      <td>\n        3 data-bearing nodes<br><small>One of the data-bearing nodes is hidden and used for backups only</small>\n      </td>\n      <td>\n        3 data-bearing nodes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Automatic Sharding Support\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Data explorer\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        SQL-based BI Connectivity\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Pause and resume clusters\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Database supported in on-premise deployments\n      </td>\n      <td>\n        Yes<br><small><a href=\"/products/mongodb-enterprise-advanced\">MongoDB Enterprise Advanced</a></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Global writes <small>Low-latency writes from anywhere in the world </small>\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Cross-region replication <small>Distribute data around the world for multi-region fault tolerance and local reads </small>\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No\n      </td>\n      <td>\n        No\n      </td>\n    </tr><tr>\n      <td>\n        Monitoring of database health with automated alerting\n      </td>\n      <td>\n        Yes<br><small>MongoDB Atlas UI &amp; support for APM platforms (New Relic)</small>\n      </td>\n      <td>\n        Yes<br><small>New Relic</small>\n      </td>\n      <td>\n        Yes<br><small>New Relic</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Continuous backup\n      </td>\n      <td>\n        Yes<br><small>Backups maintained<br>seconds behind production cluster</small>\n      </td>\n      <td>\n        No<br><small>Backups taken with mongodump against hidden replica set member</small>\n      </td>\n      <td>\n        No<br><small>Backups taken with mongodump</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Queryable backups\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Automated &amp; consistent snapshots of sharded clusters\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Not Applicable<br><small>No support for auto-sharding</small>\n      </td>\n      <td>\n        No<br><small>Requires manually coordinating the recovery of mongodumps across shards</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Access control &amp; IP whitelisting\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        AWS VPC Peering\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Beta Release<br><small></small>\n      </td>\n      <td>\n        Yes<br><small>Additional Charge</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Encryption of data in-flight\n      </td>\n      <td>\n        Yes<br><small>TLS/SSL as standard</small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n      <td>\n        Yes<br><small></small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Encryption of data at-rest\n      </td>\n      <td>\n        Yes<br><small>Available for AWS deployments; always on with Azure and GCP</small>\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        Yes<br><small>Available only with specific pricing plans and data centers</small>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        LDAP Integration\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Database-level auditing<br><small>Track DDL, DML, DCL operations</small>\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n    <tr>\n      <td>\n        Bring your own KMS\n      </td>\n      <td>\n        Yes\n      </td>\n      <td>\n        No<br><small></small>\n      </td>\n      <td>\n        No\n      </td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Realistically there are probably only a number of items that stand out on the comparison list when we go strictly database-to-database. Freedom over <strong>instance configuration </strong>sounds great, but in practice is more similar to putting a cap on how much MongoDB decides to charge you that month (by the way, it's usually a lot; keep this mind). Having the <strong>Latest Version</strong> seems great, but this can just as easily mean breaking production unannounced as much as it means new features.</p><p>MongoDB clearly wins over the enterprise space with <strong>Continuous &amp; queryable backups</strong>, integration with <strong>LDAP, </strong>and <strong>automatic sharding support. </strong>Truthfully if this were merely a database-level feature and cost comparison, the decision to go with<strong> MongoDB Atlas</strong> would come down to how much you like their pretty desktop interface:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/compass.gif\" class=\"kg-image\"><figcaption>A perfectly legitimate reason to pay up, imho.</figcaption></figure><p>So let's say MongoDB Atlas is marginally better than a competitor in the confined realm of \"being a database.\" Are Stitch microservices enough to justify keeping your instance with the MongoDB team?</p><h2 id=\"service-by-service-breakdown-of-stitch\">Service-by-Service Breakdown of Stitch</h2><p>Stitch is kind of like if AWS exited in an alternative universe, where JSON and JavaScript were earth's only technologies. Thinking back to how we create APIs in AWS, the status quo almost always involves spinning up a <strong>Dynamo</strong> (NoSQL) database to put behind <strong>Lambda </strong>functions, accessible by <strong>API Gateway </strong>endpoints. Stitch's core use case revolves around this use-case of <em>end-user-accessing-data</em>, with a number of services dedicated specifically to supporting or improving this flow. The closest comparison to Stitch would be GCloud's <strong>Firebase</strong>. </p><p>So what makes Stitch so special?</p><h3 id=\"service-1-querying-atlas-securely-via-frontend-code\">Service 1: Querying Atlas Securely via Frontend Code</h3><p>Something that cannot be understated is the ability to query Atlas via frontend Javascript. We're not passing API keys, Secrets, or any sort of nonsense; because you're configured things correctly, whitelisted domains can run queries of any complexity <em>without ever interacting with an app's backend.</em> This is not a crazy use case: consider this blog for example, or more so lately, mobile applications:</p><pre><code class=\"language-javascript\">&lt;script src=&quot;https://s3.amazonaws.com/stitch-sdks/js/bundles/4.0.8/stitch.js&quot;&gt;&lt;/script&gt;\n&lt;script&gt;\n  const client = stitch.Stitch.initializeDefaultAppClient('myapp');\n\n  const db = client.getServiceClient(stitch.RemoteMongoClient.factory, 'mongodb-atlas').db('&lt;DATABASE&gt;');\n\n  client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; \n    db.collection('&lt;COLLECTION&gt;').updateOne({owner_id: client.auth.user.id}, {$set:{number:42}}, {upsert:true})\n  ).then(() =&gt; \n    db.collection('&lt;COLLECTION&gt;').find({owner_id: client.auth.user.id}, { limit: 100}).asArray()\n  ).then(docs =&gt; {\n      console.log(&quot;Found docs&quot;, docs)\n      console.log(&quot;[MongoDB Stitch] Connected to Stitch&quot;)\n  }).catch(err =&gt; {\n    console.error(err)\n  });\n&lt;/script&gt;\n</code></pre>\n<p>This isn't to say we're allowing any user to query any data all willy-nilly just because they're on our whitelisted IP: all data stored in Atlas is restricted to specified <strong>Users</strong> by defining <strong>User Roles. </strong>Joe Schmoe can't just inject a query into any presumed database and wreak havoc, because Joe Schmoe can only access data we've permitted his user account to view or write to. What is this \"user account\" you ask? This brings us to the next big feature...</p><h3 id=\"service-2-end-user-account-creation-management\">Service 2: End-User Account Creation &amp; Management</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-13-at-5.59.03-PM.png\" class=\"kg-image\"><figcaption>Stitch will handle user account creation for you without the boilerplate.</figcaption></figure><p>Creating an app with user accounts is a huge pain in the ass. Cheeky phrases like '<strong>Do the OAuth Dance'</strong> can't ever hope to minimize the agonizing repetitive pain of creating user accounts or managing relationships between users and data (can <em>user X</em> see a comment from <em>user Y</em>?). Stitch allows most of the intolerably benign logic behind these features to be handled via a UI.</p><p>It would be a far cry to say these processes have been \"trivialized\", but the time saved is perhaps just enough to keep a coding hobbyist interested in their side projects as opposed to giving up and playing Rocket League.</p><p>As far as the permissions to read comments go... well, here's a self-explanatory screenshot of how Stitch handles read/write document permission in its simplest form:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-13-at-6.09.25-PM.png\" class=\"kg-image\"><figcaption>Owners of comments can write their comments. Everybody else reads. Seems simple.</figcaption></figure><h3 id=\"service-3-serverless-functions\">Service 3: Serverless Functions</h3><p>Stitch functions are akin to AWS Lambda functions, but much easier to configure for cross-service integration (and also limited to JavaScript ECMA 2015 or something). Functions benefit from the previous two features, in that they too can be triggered from a whitelisted app's frontend, and are governed by a simple \"rules\" system, eliminating the need for security group configurations etc.</p><p>This is what calling a function from an app's frontend looks like:</p><pre><code class=\"language-javascript\">&lt;script&gt;\n    client.auth.loginWithCredential(new stitch.AnonymousCredential()).then(user =&gt; {\n     client.callFunction(&quot;numCards&quot;, [&quot;In Progress&quot;]).then(results =&gt; {\n       $('#progress .count').text(results + ' issues');\n     })\n    });\n&lt;/script&gt;\n</code></pre>\n<p>Functions can run any query against Atlas, retrieve <em>values</em> (such as environment variables), and even call other functions. Functions can also be fired by database <strong>triggers,</strong> where a change to a collection will prompt an action such as an alert.</p><h3 id=\"service-4-http-webhooks\">Service 4: HTTP Webhooks</h3><p>Webhooks are a fast way to toss up endpoints. Stitch endpoints are agnostic to one another in that they are one-off URLs to perform single tasks. We could never build a well-designed API using Stitch Webhooks, as we could with <strong>API Gateway</strong>; this simply isn't the niche MongoDB is trying to hit (the opposite, in fact). </p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-14-at-4.33.27-PM.png\" class=\"kg-image\"><figcaption>Configuration for a single Webhook.</figcaption></figure><p>This form with a mere 6 fields clearly illustrates what Stitch intends to do: trivializing the creation of traditionally non-trivial features.</p><h3 id=\"service-5-storing-values-in-stitch\">Service 5: Storing 'Values' in Stitch</h3><p>A \"value\" is equivalent to an environment variable. These can be used to store API keys, secrets, or whatever. Of course, values are retrieved via functions.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-11-14-at-7.45.28-PM.png\" class=\"kg-image\"><figcaption>Shhh, it's a secret ;)</figcaption></figure><h3 id=\"service-6-a-bunch-of-mostly-bloated-extras\">Service 6+: A Bunch of Mostly Bloated Extras</h3><p>Finally, Stitch has thrown in a few third-party integrations for good measure. Some integrations like <strong>S3 Integration </strong>could definitely come in handy, but it's worth asking why Mongo constantly over advertises their integrations with <strong>Github</strong> and <strong>Twilio</strong>. We've already established that we can create endpoints which accept information, and we can make functions which <em>GET</em> information... so isn't anything with an API pretty easy to 'integrate' with?</p><p>This isn't to say the extra services aren't useful, they just seem a bit... odd. It feels a lot like bloating the catalog, but the catalog isn't nearly bloated enough where it feels normal (like Heroku add-ons, for example). The choice to launch Stitch with a handful of barely-useful integrations only comes off as more and more aimless as time passes; as months turn to years and no additions or updates are made to service offerings, it's worth questioning what the vision had been for the product in the first place. In my experience, feature sets like these happen when Product Managers are more powerful than they are useful.</p><h2 id=\"the-breathtaking-climax-is-stitch-worth-it\">The Breathtaking Climax: Is Stitch Worth It?</h2><p>I've been utilizing Stitch to fill in the blanks in development for months now, perhaps nearly a year. Each time I find myself working with Stitch or looking at the bill, I can't decide if it's been a Godsend for its nich\u001dé, or an expensive toy with an infuriating lack of accurate documentation.</p><p> Stitch is very much a <em>copy-and-paste-cookie-cutter-code</em> type of product, which begs the question of why their tutorials are recklessly outdated; sometimes to the point where MongoDB's own tutorial source code <em>doesn't work. </em>There are so many use cases and potential benefits to Stitch, so why is the <a href=\"https://github.com/mongodb/stitch-examples\">Github repo</a> containing example code snippets so unmaintained, and painfully irrelevant? Lastly, why am I selling this product harder than their own internal team?</p><p>Stitch is a good product with a lot of unfortunate oversight. That said, Google Firebase still doesn't even have an \"import data\" feature, so I suppose it's time to dig deep into this vendor lock and write a 5-post series about it before Silicon Valley's best and brightest get their shit together enough to actually create something useful and intuitive for other human beings to use. In the meantime, feel free to steal source from tutorials I'll be posting, because they'll be sure to, you know, actually work.</p>","url":"https://hackersandslackers.com/mongodb-cloud-backend-as-a-service-with-atlas-and-stitch/","uuid":"5555fa6e-07f0-4f9a-8069-e1e68868e608","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5beb3c900dbec217f3ce801b"}}]}},"pageContext":{"slug":"software-development","limit":12,"skip":0,"numberOfPages":3,"humanPageNumber":1,"prevPageNumber":null,"nextPageNumber":2,"previousPagePath":null,"nextPagePath":"/tag/software-development/page/2/"}}