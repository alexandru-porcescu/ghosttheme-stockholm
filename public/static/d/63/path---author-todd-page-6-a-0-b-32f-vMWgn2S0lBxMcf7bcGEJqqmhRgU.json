{"data":{"ghostAuthor":{"slug":"todd","name":"Todd Birchard","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","cover_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/fox_o_o.jpg","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","location":"New York City","website":"https://toddbirchard.com","twitter":"@ToddRBirchard","facebook":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736aa","title":"Create a VPS with Google Cloud: Introducing Compute Engine","slug":"setting-up-dns-with-google-cloud-platform","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","excerpt":"Spin up a VPS and configure DNS with relative ease.","custom_excerpt":"Spin up a VPS and configure DNS with relative ease.","created_at_pretty":"14 July, 2018","published_at_pretty":"14 July, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-07-14T10:28:34.000-04:00","published_at":"2018-07-14T14:55:03.000-04:00","updated_at":"2019-02-14T02:29:40.000-05:00","meta_title":"Google Cloud Platform: Creating a VPS | Hackers and Slackers","meta_description":"Google Cloud Platform is a compelling choice for respectable enterprises, particularly those with a sense of style and curiosity.","og_description":"The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity just yet. Let's set up a server to see what the hype is about. Today'll we'll be creating a standard Linux instance and walking through the steps to configure an existing DNS for said instance.","og_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","og_title":"Create a VPS with Google Cloud: Compute Engine","twitter_description":"The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity just yet. Let's set up a server to see what the hype is about. Today'll we'll be creating a standard Linux instance and walking through the steps to configure an existing DNS for said instance.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/gcp@2x.jpg","twitter_title":"Create a VPS with Google Cloud: Compute Engine","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Google Cloud","slug":"googlecloud","description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/googleseries2.jpg","meta_description":"Evaluating Google Cloud Platform’s offerings. Get introduced with tutorials, see our vendor comparisons, and endure biased opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#The Rise of Google Cloud","slug":"the-rise-of-google-cloud","description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","feature_image":"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/ADF7E324-9EAD-4F15-8670-AF205E6804EA.png","meta_description":"Build robust serverless architecture on Google Cloud Platform. Learn through tutorials, make comparisons, and hear opinions on GCP as a whole.","meta_title":"The Rise of Google Cloud","visibility":"internal"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"}],"plaintext":"For the last few weeks I've been enamored with Google's cloud platform, aptly\nnamed Google Cloud Platform. GCP contains the things you might expect from a\nyoung player in the 'screw AWS' space: much of what exists on AWS has an\nequivalent on GPC, but certain subtleties exist, such as the lack of Python\nserverless functions and so forth. That said, GCP makes up for any shortcomings\nby leveraging services exclusive to Google.\n\nIn my opinion, GCP is the first contender in the market to package enterprise\ncloud computing in a satisfying way. It's clear GCP has assigned UI and Product\nManagement resources to their platform, where Amazon clearly did not. while not\nwithout its shortcomings, it's obvious Google has chosen usability as a key\ndifferentiator from AWS.\n\nAside from the UI, GCP offers plenty of fun functionality such as their cloud\nlauncher. This is the equivalent of one-click deploys for cool stuff, whether\nthey be services to add to your VPC, Google APIs, Datasets, or what have you.\nThe ease of plug-and-play these plug-and-play services make GCP a compelling\nchoice for a respectable enterprise which hasn't lost the gift of curiosity.\n\nIt's like product hunt... on crack.The best way to get a feel for what value a\nproduct has would be use it, of course. In the interest of becoming familiar\nwith Google Cloud, we'll execute the most basic task of setting up a VPS to\ndeploy code to. This practice will end up touching on many of GCP's core\nservices which will allow us to grasp the basic offerings of the product, as\nwell as its strengths and weakness.\n\nDoes in Fact Compute \nGCP cutely names their server's Compute Engines,  which are at least more\ntolerable than, say, EC2 instances. I'm just going to call them servers because\nI'm not the type of person who orders a \"tall\" at Starbucks.\n\nCreate a \"project\" in Google Cloud, and you'll immediately land at a dashboard.\nAll Google's services are tucked away in the left-hand menu. Open that bad boy\nup and find Compute Engine.\n\nShhh, it's thinking.Select create. As opposed to the preset choices of VPCS you might be used to,\nGoogle allows us to customize our VPS to our exact technical specifications on a\nsliding scale. Want 96 processing cores, but only a single GB of RAM? No\nproblem, if that's what you're into. Weirdo.\n\nAs well as picking between the usual Linux distributions, Compute Engine also\nallows customers to select their number of GPUs, as well as the generation of\nIntel CPU their instance will run on.\n\nDat customization thoWe want traffic to hit this instance, so make sure you\ncheck Allow HTTP  traffic  and Allow HTTPS traffic  before continuing. Once your\ninstance is created, you should immediately able to SSH into your server via\nGCP's browser client.\n\nThe App Engine\nGCP is not without its own fair share of arbitrary product classifications. DNS\nrecords and hosts are contained within the App Engine  service of the platform.\nFind the App Engine service in the left hand navigation, and scroll down to the \nsettings  link:\n\nAllllll the way at the bottom.Here's we'll be able to see a \"custom domains\" tab\nwhich allows us to point a domain we've purchased from a service like Namecheap \n or what-have-you to Google Cloud. I'll personally be walking though this\nexample by directing a pointless domain called memegenerator.io  I purchased on\nNamecheap for no good reason.\n\nWhen you add a custom domain via this screen, you'll immediately be asked to\nverify ownership over the domain via the familiar Google Webmaster tool, which\nyou'll be redirected to automatically.\n\nBack to Your Registrar\nChances are you've dealt with verification via Google webmaster before, but this\ntime we've only given the option to do this via DNS. Select your registrar in\nthe dropdown in order to reveal a Google-generated record used to verify your\ndomain. \n\nPlease don't tell me you use GoDaddy.The resulting value will need to be added\nas a .txt record before we can actually point your domain to Google's servers.\n\nIf you're using Namecheap like I am, log in to your dashboard and find your\ndomain by clicking \"manage domain\". Make sure you're under the \"advanced DNS\"\ntab:\n\nEven if you're not using Namecheap, this shouldn't be much different.Delete all\nexisting records. Then create a TXT record (with @ as the host) and input the\nvalue that Google provided you earlier. Now, when you return to the webmaster\ntool, clicking verify tool should  pick up on this change. \n\nIf the webmaster tool does not pick up on this verification right away, don't\npanic. This happens fairly often - just frantically keep making sure everything\nis set up correctly while mashing the verify button.Navigate back to the Custom\nDomains tab in GCP and continue the process- you should see that your domain is\nverified. You'll be prompted to enter any subdomains you'd GCP to pick up on\nhere. Wrap that up and save.\n\n\n\nMake it Rain with Records\nOh, we're far from over buddy. We need to go back to update our A and AAAA\nrecords, now that Google as bestowed that privilege upon us. You should see a\ntable such as the one below:\n\nType\n Data\n Alias\n A\n 216.239.32.21\n A\n 216.239.34.21\n A\n 216.239.36.21\n A\n 216.239.38.21\n AAAA\n 2001:4860:4802:32::15\n AAAA\n 2001:4860:4802:34::15\n AAAA\n 2001:4860:4802:36::15\n AAAA\n 2001:4860:4802:38::15\n CNAME\n ghs.googlehosted.com\n www\n Copy that into your registrar's custom DNS records. Have fun with that.\n\nCloud DNS\nYou may have noticed that we haven't actually specified our Nameservers yet.\nNobody said this was going to be fun; if it were, we probably wouldn't need this\ntutorial. In the GCP search bar, search for Cloud DNS. Create a Zone, and leave\nDNSSEC off.\n\n\n\nBefore we do this next part, I'd like to interject and mention that you did a\nspectacular job of creating all those records and pasting all those values\nearlier. Considering you seem to have a knack for this, it probably won't hurt\nto know that we need to go back into our registrar a third time to paste some\nvalues. You got this. \n\nGoogle's nameservers have now been generated and exposed to you so we can \nactually  point our domain to something meaningful now. You should have 4\nnameservers like the following:\n\nName\n Type\n TTL\n Data\n memegenerator.io.\n NS\n 21600\n ns-cloud-b1.googledomains.com.\n ns-cloud-b2.googledomains.com.\n ns-cloud-b3.googledomains.com.\n ns-cloud-b4.googledomains.com.\n Assign a Static IP\nOkay, we're officially done messing around with our registrar. In the GCP search\nbar, search for External IP addresses.  From there, click the \"Reserve static\nAddress\" button at the top of the screen. This will prompt you with a short\nform: the only important field to fill out here is the \"Attached to\"  dropdown,\nwhich denotes which server instance the IP will be assigned to.\n\nCompute Engine Instance Settings\nShit, is there even more? OK, we're almost done here. Go to your Compute Engine\ninstance you set up earlier. Click \"Edit\". Scroll to the Network Interface \nsection and map the Static IP we created from earlier. Also, go ahead and enter\nyour PTR record:\n\nWhen will it end... please send help.FINAL CHAPTER: Firewall Settings\nLook, I just want to say you're all doing a great job so far. All of you. We're\nall a team here; let's stick together and see this through. Search for Firewall\nRules  and selected Create a Firewall Rule. Name it whatever you want.\n\n * Targets  - This will be where our traffic routes. We want to route to our\n   instance, which is a specified service account.\n * Target service account  - Referring to the above, this is where we select the\n   computer instance we want to hit.\n * Target service account  scope  - Select \"in this project\".\n * Source Filter - Once again, select specified service account.\n * Source service account  scope - Select \"in this project\"\n * Source service account  - This is where we say where the traffic is coming\n   from. It's coming from the App engine, as this is where we specified our DNS.\n * For IPs  and ports, well, do what you want. It's your server. \n\nGet at it\nWell, there you have it. Hopefully by now the domain you've painstaking\nconfigured now points to your server, so you can go ahead and configure your\nwebserver settings or whatever it is you do.\n\nAlright fine, so GCP isn't completely free of its own redundancies. As much as I\nlove to hate on AWS, it seems almost inevitable at this point that any\nenterprise cloud service will maintain a certain level of obscure processes.\nThis is great for flexibility when scaling, but let's be honest: if these\nplatforms were easy to use, who would pay for the certifications?\n\nCheekiness aside, I've become a strong fan of GCP. Google seems to have hit a\nmiddle ground between being user-friendly and powerful, which fills a niché\nwe'll realize was desperately needed. For a fair review of the platform itself,\nI find myself agreeing mostly with this stranger from the internet: \nhttps://www.deps.co/blog/google-cloud-platform-good-bad-ugly/","html":"<p>For the last few weeks I've been enamored with Google's cloud platform, aptly named Google Cloud Platform. GCP contains the things you might expect from a young player in the 'screw AWS' space: much of what exists on AWS has an equivalent on GPC, but certain subtleties exist, such as the lack of Python serverless functions and so forth. That said, GCP makes up for any shortcomings by leveraging services exclusive to Google.</p><p>In my opinion, GCP is the first contender in the market to package enterprise cloud computing in a satisfying way. It's clear GCP has assigned UI and Product Management resources to their platform, where Amazon clearly did not. while not without its shortcomings, it's obvious Google has chosen usability as a key differentiator from AWS.</p><p>Aside from the UI, GCP offers plenty of fun functionality such as their cloud launcher. This is the equivalent of one-click deploys for cool stuff, whether they be services to add to your VPC, Google APIs, Datasets, or what have you. The ease of plug-and-play these plug-and-play services make GCP a compelling choice for a respectable enterprise which hasn't lost the gift of curiosity.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-07-14_10-36-02.gif\" class=\"kg-image\"><figcaption>It's like product hunt... on crack.</figcaption></figure><p>The best way to get a feel for what value a product has would be use it, of course. In the interest of becoming familiar with Google Cloud, we'll execute the most basic task of setting up a VPS to deploy code to. This practice will end up touching on many of GCP's core services which will allow us to grasp the basic offerings of the product, as well as its strengths and weakness.</p><h2 id=\"does-in-fact-compute\">Does in Fact Compute </h2><p>GCP cutely names their server's <em>Compute Engines,</em> which are at least more tolerable than, say, EC2 instances. I'm just going to call them servers because I'm not the type of person who orders a \"tall\" at Starbucks.</p><p>Create a \"project\" in Google Cloud, and you'll immediately land at a dashboard. All Google's services are tucked away in the left-hand menu. Open that bad boy up and find Compute Engine.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/2018-07-14_10-44-14.gif\" class=\"kg-image\"><figcaption>Shhh, it's thinking.</figcaption></figure><p>Select <em>create</em>. As opposed to the preset choices of VPCS you might be used to, Google allows us to customize our VPS to our exact technical specifications on a sliding scale. Want 96 processing cores, but only a single GB of RAM? No problem, if that's what you're into. Weirdo.</p><p>As well as picking between the usual Linux distributions, Compute Engine also allows customers to select their number of GPUs, as well as the generation of Intel CPU their instance will run on.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-10.48.02-AM.png\" class=\"kg-image\"><figcaption>Dat customization tho</figcaption></figure><p>We want traffic to hit this instance, so make sure you check <strong>Allow HTTP</strong> <strong>traffic</strong> and <strong>Allow HTTPS traffic</strong> before continuing. Once your instance is created, you should immediately able to SSH into your server via GCP's browser client.</p><h2 id=\"the-app-engine\">The App Engine</h2><p>GCP is not without its own fair share of arbitrary product classifications. DNS records and hosts are contained within the <strong>App Engine</strong> service of the platform. Find the App Engine service in the left hand navigation, and scroll down to the <em>settings</em> link:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-10.58.19-AM.png\" class=\"kg-image\"><figcaption>Allllll the way at the bottom.</figcaption></figure><p>Here's we'll be able to see a \"custom domains\" tab which allows us to point a domain we've purchased from a service like <strong>Namecheap</strong><em> </em>or what-have-you to Google Cloud. I'll personally be walking though this example by directing a pointless domain called <em>memegenerator.io</em> I purchased on Namecheap for no good reason.</p><p>When you add a custom domain via this screen, you'll immediately be asked to verify ownership over the domain via the familiar Google Webmaster tool, which you'll be redirected to automatically.</p><h2 id=\"back-to-your-registrar\">Back to Your Registrar</h2><p>Chances are you've dealt with verification via Google webmaster before, but this time we've only given the option to do this via DNS. Select your registrar in the dropdown in order to reveal a Google-generated record used to verify your domain. </p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.04.07-AM.png\" class=\"kg-image\"><figcaption>Please don't tell me you use GoDaddy.</figcaption></figure><p>The resulting value will need to be added as a .txt record before we can actually point your domain to Google's servers.</p><p>If you're using Namecheap like I am, log in to your dashboard and find your domain by clicking \"manage domain\". Make sure you're under the \"advanced DNS\" tab:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.08.58-AM.png\" class=\"kg-image\"><figcaption>Even if you're not using Namecheap, this shouldn't be much different.</figcaption></figure><p>Delete all existing records. Then create a TXT record (with @ as the host) and input the value that Google provided you earlier. Now, when you return to the webmaster tool, clicking verify tool <em>should</em> pick up on this change. </p><div class=\"protip\">\nIf the webmaster tool does not pick up on this verification right away, don't panic. This happens fairly often - just frantically keep making sure everything is set up correctly while mashing the verify button.\n</div><p>Navigate back to the Custom Domains tab in GCP and continue the process- you should see that your domain is verified. You'll be prompted to enter any subdomains you'd GCP to pick up on here. Wrap that up and save.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.13.27-AM.png\" class=\"kg-image\"></figure><p></p><h2 id=\"make-it-rain-with-records\">Make it Rain with Records</h2><p>Oh, we're far from over buddy. We need to go back to update our A and AAAA records, now that Google as bestowed that privilege upon us. You should see a table such as the one below:</p><div class=\"tablecontainer\">\n<table>\n  <thead>\n    <tr>\n      <th>Type</th>\n      <th>Data</th>\n      <th>Alias</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>A</td>\n      <td>216.239.32.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.34.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.36.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>A</td>\n      <td>216.239.38.21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:32::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:34::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:36::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>AAAA</td>\n      <td>2001:4860:4802:38::15</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>CNAME</td>\n      <td>ghs.googlehosted.com</td>\n      <td>www</td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Copy that into your registrar's custom DNS records. Have fun with that.</p><h2 id=\"cloud-dns\">Cloud DNS</h2><p>You may have noticed that we haven't actually specified our Nameservers yet. Nobody said this was going to be fun; if it were, we probably wouldn't need this tutorial. In the GCP search bar, search for <em>Cloud DNS</em>. Create a Zone, and leave DNSSEC off.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.25.33-AM.png\" class=\"kg-image\"></figure><p></p><p>Before we do this next part, I'd like to interject and mention that you did a spectacular job of creating all those records and pasting all those values earlier. Considering you seem to have a knack for this, it probably won't hurt to know that we need to go back into our registrar a third time to paste some values. You got this. </p><p>Google's nameservers have now been generated and exposed to you so we can <em>actually</em> point our domain to something meaningful now. You should have 4 nameservers like the following:</p><table>\n  <thead>\n    <tr>\n      <th>Name</th>\n      <th>Type</th>\n      <th>TTL</th>\n      <th>Data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>memegenerator.io.</td>\n      <td>NS</td>\n      <td>21600</td>\n      <td>ns-cloud-b1.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b2.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b3.googledomains.com.</td>\n    </tr>\n    <tr>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>ns-cloud-b4.googledomains.com.</td>\n    </tr>\n  </tbody>\n</table><h2 id=\"assign-a-static-ip\">Assign a Static IP</h2><p>Okay, we're officially done messing around with our registrar. In the GCP search bar, search for <strong>External IP addresses.</strong> From there, click the \"Reserve static Address\" button at the top of the screen. This will prompt you with a short form: the only important field to fill out here is the <em>\"Attached to\"</em> dropdown, which denotes which server instance the IP will be assigned to.</p><h2 id=\"compute-engine-instance-settings\">Compute Engine Instance Settings</h2><p>Shit, is there even more? OK, we're almost done here. Go to your Compute Engine instance you set up earlier. Click \"Edit\". Scroll to the <em>Network Interface</em> section and map the Static IP we created from earlier. Also, go ahead and enter your PTR record:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-14-at-11.47.24-AM.png\" class=\"kg-image\"><figcaption>When will it end... please send help.</figcaption></figure><h2 id=\"final-chapter-firewall-settings\">FINAL CHAPTER: Firewall Settings</h2><p>Look, I just want to say you're all doing a great job so far. All of you. We're all a team here; let's stick together and see this through. Search for <strong>Firewall Rules</strong> and selected <em>Create a Firewall Rule. </em>Name it whatever you want.</p><ul><li><strong>Targets</strong> - This will be where our traffic routes. We want to route to our instance, which is a <em>specified service account.</em></li><li><strong>Target service account</strong> - Referring to the above, this is where we select the computer instance we want to hit.</li><li><strong>Target service account</strong> <strong>scope</strong> - Select \"in this project\".</li><li><strong>Source Filter </strong>- Once again, select <em>specified service account.</em></li><li><strong>Source service account</strong> <strong>scope </strong>- Select \"in this project\"</li><li><strong>Source service account</strong> - This is where we say where the traffic is coming from. It's coming from the <em>App engine</em>, as this is where we specified our DNS.</li><li>For <strong>IPs</strong> and <strong>ports, </strong>well, do what you want. It's your server. </li></ul><h2 id=\"get-at-it\">Get at it</h2><p>Well, there you have it. Hopefully by now the domain you've painstaking configured now points to your server, so you can go ahead and configure your webserver settings or whatever it is you do.</p><p>Alright fine, so GCP isn't completely free of its own redundancies. As much as I love to hate on AWS, it seems almost inevitable at this point that any enterprise cloud service will maintain a certain level of obscure processes. This is great for flexibility when scaling, but let's be honest: if these platforms were easy to use, who would pay for the certifications?</p><p>Cheekiness aside, I've become a strong fan of GCP. Google seems to have hit a middle ground between being user-friendly and powerful, which fills a niché we'll realize was desperately needed. For a fair review of the platform itself, I find myself agreeing mostly with this stranger from the internet: <a href=\"https://www.deps.co/blog/google-cloud-platform-good-bad-ugly/\">https://www.deps.co/blog/google-cloud-platform-good-bad-ugly/</a></p>","url":"https://hackersandslackers.com/setting-up-dns-with-google-cloud-platform/","uuid":"ed22ae1a-b636-48dd-8502-141ae08fa9d9","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b4a08921c20005e9422c108"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867369f","title":"Creating Your First Flask Application","slug":"creating-your-first-flask-application","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/flask-gettingstarted@2x.jpg","excerpt":"After achieving market dominance, Flask is a Python framework impossible to avoid.","custom_excerpt":"After achieving market dominance, Flask is a Python framework impossible to avoid.","created_at_pretty":"08 July, 2018","published_at_pretty":"08 July, 2018","updated_at_pretty":"21 February, 2019","created_at":"2018-07-08T16:06:24.000-04:00","published_at":"2018-07-08T17:51:42.000-04:00","updated_at":"2019-02-21T17:05:15.000-05:00","meta_title":"Creating Your First Flask Application | Hackers and Slackers","meta_description":"After achieving market dominance, Flask is a Python framework impossible to avoid. Learn the basics of creating a Flask web app or API.","og_description":"After achieving market dominance, Flask is a Python framework impossible to avoid. Learn the basics of creating a Flask web app or API.","og_image":"https://hackersandslackers.com/content/images/2018/07/flask-gettingstarted@2x.jpg","og_title":"Creating Your First Flask Application","twitter_description":"After achieving market dominance, Flask is a Python framework impossible to avoid. Learn the basics of creating a Flask web app or API.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/flask-gettingstarted@2x.jpg","twitter_title":"Creating Your First Flask Application","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"#Building Flask Apps","slug":"building-flask-apps","description":"Python’s fast-growing and flexible microframework. Can handle apps as simple as API endpoints, to monoliths remininiscent of Django.","feature_image":"https://hackersandslackers.com/content/images/2019/03/flask-gettingstarted.jpg","meta_description":"Python’s fastest growing, most flexible, and perhaps most Pythonic framework.","meta_title":"Building Flask Apps","visibility":"internal"}],"plaintext":"Evidence of Flask’s rise to power has been all around us for a couple of years\nnow. Anybody paying close attention to the technology stacks chosen by startups\nhas undoubtedly noticed a flip: at some point, the industry standard flipped\naway from Django entirely. \n\nHuge bets are being placed on Flask across the industry. Plotly’s  famous Dash \nproduct is an extension of Flask which has seen significant success. Even major\ncloud providers, namely Google Cloud, are choosing to default to Flask for\nPython implementations of serverless apps. Google Cloud Functions and Google App\nEngine both ship with Flask running at their core. JetBrains finally put an\nofficial number to this trend with their 2018 Python survey\n[https://www.jetbrains.com/research/python-developers-survey-2018/]: 47%  of\ndevs report using Flask to Django’s 45%. Game: Blouses.\n\nFlask wins market dominence in 2018.Put down the pitchforks: this isn’t a Flask\nvs. Django post, nor are we implying that one framework is superior to the\nother. Both frameworks have their place, with that “place” being in the realm of\npreference.\n\nWhy Flask?\nDeveloping apps in Flask has a much different narrative than when developing in\nmore traditional MVC Frameworks. In the past, the setup of a framework would\neasily take hours: with the assumption that our app needed all the bells and\nwhistles, it was impossible to get a “Hello world!” off the ground without a\nfull understanding of database configurations, static assets, templates, and\nother things our app may not even need. This is especially a concern for the\nPython ecosystem. Few people turn to Python for the sole purpose of building a\nweb app: the vast majority of Python developers are in the field of data\nanalysis without a traditional background in application development. Asking\ndata analysts (who have mostly become accustomed to Jupyter notebooks) to pick\nup all the fundamentals of web development before even getting started is just\nunrealistic.\n\nFlask's setup is merely a copy+paste of the following five lines:\n\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    return \"Hello World!\"\n\n\nThose five lines create a live Flask application. Without any other knowledge\nabout the framework, we can immediately plug in any Python logic we already have\nto change “Hello world!” to match any output imaginable. While it's possible to\ncreate an entire Flask application as a single tiny file, Flask can be as\nextended to be just as powerful and complex as its predecessors. When the author\nof a Flask application deems it necessary, various Flask plugins can be pulled\nin to give us robust application logic. Examples include:\n\n * Flask-SQLAlchemy  for database interaction.\n * Flask-Sessions  for user session management.\n * Flask-Login  to manage user logins.\n * Literally hundreds [https://github.com/humiaozuzu/awesome-flask]  of other\n   libraries.\n\nThis plug-and-play structure makes Flask projects feel more expressive while\nsimultaneously providing simplicity to developers starting from 0. Not only\nthat, but reading somebody else’s source suddenly becomes simple: I know this\napp must do XYZ, because this person has imported XYZ.\n\nDissecting Flask’s “Hello World!”\nLet's go back to our 5-line application to pick apart the specifics:\n\nfrom flask import Flask \napp = Flask(__name__)\n\n\nThe most important part of the Flask Python library is Flask  with a capital “F”\n(as in: from flask import Flask).  This five-letter word creates an object which\nrefers to the entirety of the app itself: when we state app = Flask(__name__),\nwe are creating the variable app  which represents our application. Therefore,\nwhen we configure the variable app,  we’re configuring the way our entire\napplication works. For example, setting app = Flask()  can accept a few\nattributes:\n\nfrom flask import Flask\n\napp = Flask(__name__,\n            instance_relative_config=False,\n            template_folder=\"templates\",\n            static_folder=\"static\"\n            )\n\n\nThis is an example of creating a Flask app with a few specifics: the location of\nour config file, the folder in which we'll store pages templates, and the folder\nin which we'll store frontend assets (JS, CSS, images, etc.).\n\nA Basic Flask Route\nThe primary function of our app is called hello(), which is importantly wrapped\nby Flask's most important decorator: .route(). If you aren't familiar with \ndecorators  in Python, a decorator is a function for us to wrap other functions\nwith. It isn't critically important to know all the details, other than that\nFlask comes with a route decorator which allows us to serve up functions based\non which page of the app the user is loading. By setting @app.route(\"/\"), we are\nspecifying that the function hello()  should fire whenever somebody uses our\napp.\n\nOf course, we can return any value besides \"Hello world!\" if we wanted. Let's\nsay you've already a script which returns the square of a number, plus 9. We\ncould save that logic in a function called squareOfNumberPlusNine(), in a file\ncalled logic.py. Now, our script can look like this:\n\nfrom flask import Flask\nfrom logic import squareOfNumberPlusNine\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    value = squareOfNumberPlusNine(5)\n    return value\n\n\nThis would return 34  as opposed to \"Hello world!\". Without any prior knowledge\nof Python web development, we can already use Flask to plug into logic we've\nwritten and serve up a result.\n\nOther Parts of Flask's Core Library\nWe can import other things from flask  besides Flask. Here are some examples:\n\nServing Raw HTML\nMarkup  allows us to return an HTML page by rendering a string as HTML:\n\nfrom flask import Flask, Markup\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    return Markup(\"<h1>Hello World!</h1>\")\n\n\nServing an HTML Page Template\nreturn_template  will return an HTML page by finding the page in our /templates \nfolder:\n\nfrom flask import Flask, render_template\napp = Flask(__name__, template_folder=\"templates\")\n\n@app.route(\"/\")\ndef hello():\n    return render_template(\"index.html\")\n\n\nServing a JSON Response \nmake_response  is suitable if our application is an API and we'd like to return\na response object:\n\nfrom flask import Flask, make_response\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    headers = {\"Content-Type\": \"application/json\"}\n    return make_response('it worked!', 200, headers=headers)\n\n\nOn the topic of creating APIs with Flask, we can also specify whether the route\nat hand is a POST, GET, or some other method. This is handled easily within the\nroute decorator:\n\nfrom flask import Flask, make_response, request\napp = Flask(__name__)\n\n@app.route(\"/\", methods=['GET'])\ndef hello():\n    if request.method != 'GET':\n        return make_response('Malformed request', 400)\n    headers = {\"Content-Type\": \"application/json\"}\n    return make_response('it worked!', 200, headers=headers)\n\n\nThe above function checks to make sure the user is accessing the endpoint with\nthe correct method first. If they've used the incorrect method, we return an\nerror.\n\nSuccumb to Flask\nEven if you chose to stick to your large Frameworks, it's easy to see why Flask\nis useful as a drop-in solution for many tasks. There are undoubtedly plenty of\nuseful Python scripts which go wasted because the final step of making them\neasily consumable by other people was never completed. Flask is an excellent way\nto achieve this last step, and the best part is: you already know how to use it.","html":"<p>Evidence of Flask’s rise to power has been all around us for a couple of years now. Anybody paying close attention to the technology stacks chosen by startups has undoubtedly noticed a flip: at some point, the industry standard flipped away from Django entirely. </p><p>Huge bets are being placed on Flask across the industry. <strong>Plotly’s</strong> famous <strong>Dash</strong> product is an extension of Flask which has seen significant success. Even major cloud providers, namely <strong>Google Cloud</strong>, are choosing to default to Flask for Python implementations of serverless apps. Google Cloud Functions and Google App Engine both ship with Flask running at their core. JetBrains finally put an official number to this trend with their <a href=\"https://www.jetbrains.com/research/python-developers-survey-2018/\">2018 Python survey</a>: <strong>47%</strong> of devs report using Flask to Django’s <strong>45%</strong>. Game: Blouses.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/Screen-Shot-2019-02-13-at-4.36.00-PM.png\" class=\"kg-image\"><figcaption>Flask wins market dominence in 2018.</figcaption></figure><p>Put down the pitchforks: this isn’t a Flask vs. Django post, nor are we implying that one framework is superior to the other. Both frameworks have their place, with that “place” being in the realm of preference.</p><h2 id=\"why-flask\">Why Flask?</h2><p>Developing apps in Flask has a much different narrative than when developing in more traditional MVC Frameworks. In the past, the setup of a framework would easily take hours: with the assumption that our app needed all the bells and whistles, it was impossible to get a “Hello world!” off the ground without a full understanding of database configurations, static assets, templates, and other things our app may not even need. This is especially a concern for the Python ecosystem. Few people turn to Python for the sole purpose of building a web app: the vast majority of Python developers are in the field of data analysis without a traditional background in application development. Asking data analysts (who have mostly become accustomed to Jupyter notebooks) to pick up all the fundamentals of web development before even getting started is just unrealistic.</p><p>Flask's setup is merely a copy+paste of the following five lines:</p><pre><code class=\"language-python\">from flask import Flask\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    return &quot;Hello World!&quot;\n</code></pre>\n<p>Those five lines create a live Flask application. Without any other knowledge about the framework, we can immediately plug in any Python logic we already have to change “Hello world!” to match any output imaginable. While it's possible to create an entire Flask application as a single tiny file, Flask can be as extended to be just as powerful and complex as its predecessors. When the author of a Flask application deems it necessary, various Flask plugins can be pulled in to give us robust application logic. Examples include:</p><ul><li><strong>Flask-SQLAlchemy</strong> for database interaction.</li><li><strong>Flask-Sessions</strong> for user session management.</li><li><strong>Flask-Login</strong> to manage user logins.</li><li>Literally <a href=\"https://github.com/humiaozuzu/awesome-flask\">hundreds</a> of other libraries.</li></ul><p>This plug-and-play structure makes Flask projects feel more expressive while simultaneously providing simplicity to developers starting from 0. Not only that, but reading somebody else’s source suddenly becomes simple: I know this app must do XYZ, because this person has imported XYZ.</p><h2 id=\"dissecting-flask-s-hello-world-\">Dissecting Flask’s “Hello World!”</h2><p>Let's go back to our 5-line application to pick apart the specifics:</p><pre><code class=\"language-python\">from flask import Flask \napp = Flask(__name__)\n</code></pre>\n<p>The most important part of the Flask Python library is <strong>Flask</strong> with a capital “F” (as in: <code>from flask import Flask</code>).  This five-letter word creates an object which refers to the entirety of the app itself: when we state <code>app = Flask(__name__)</code>, we are creating the variable <strong>app</strong> which represents our application. Therefore, when we configure the variable <strong>app,</strong> we’re configuring the way our entire application works. For example, setting <code>app = Flask()</code> can accept a few attributes:</p><pre><code class=\"language-python\">from flask import Flask\n\napp = Flask(__name__,\n            instance_relative_config=False,\n            template_folder=&quot;templates&quot;,\n            static_folder=&quot;static&quot;\n            )\n</code></pre>\n<p>This is an example of creating a Flask app with a few specifics: the location of our config file, the folder in which we'll store pages templates, and the folder in which we'll store frontend assets (JS, CSS, images, etc.).</p><h3 id=\"a-basic-flask-route\">A Basic Flask Route</h3><p>The primary function of our app is called <code>hello()</code>, which is importantly wrapped by Flask's most important decorator: <code>.route()</code>. If you aren't familiar with <strong>decorators</strong> in Python, a decorator is a function for us to wrap other functions with. It isn't critically important to know all the details, other than that Flask comes with a route decorator which allows us to serve up functions based on which page of the app the user is loading. By setting <code>@app.route(\"/\")</code>, we are specifying that the function <code>hello()</code> should fire whenever somebody uses our app.</p><p>Of course, we can return any value besides \"Hello world!\" if we wanted. Let's say you've already a script which returns the square of a number, plus 9. We could save that logic in a function called <code>squareOfNumberPlusNine()</code>, in a file called <code>logic.py</code>. Now, our script can look like this:</p><pre><code class=\"language-python\">from flask import Flask\nfrom logic import squareOfNumberPlusNine\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    value = squareOfNumberPlusNine(5)\n    return value\n</code></pre>\n<p>This would return <strong>34</strong> as opposed to \"<strong>Hello world!\"</strong>. Without any prior knowledge of Python web development, we can already use Flask to plug into logic we've written and serve up a result.</p><h2 id=\"other-parts-of-flask-s-core-library\">Other Parts of Flask's Core Library</h2><p>We can import other things <code>from flask</code> besides <code>Flask</code>. Here are some examples:</p><h3 id=\"serving-raw-html\">Serving Raw HTML</h3><p><code>Markup</code> allows us to return an HTML page by rendering a string as HTML:</p><pre><code class=\"language-python\">from flask import Flask, Markup\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    return Markup(&quot;&lt;h1&gt;Hello World!&lt;/h1&gt;&quot;)\n</code></pre>\n<h3 id=\"serving-an-html-page-template\">Serving an HTML Page Template</h3><p><code>return_template</code> will return an HTML page by finding the page in our <code>/templates</code> folder:</p><pre><code class=\"language-python\">from flask import Flask, render_template\napp = Flask(__name__, template_folder=&quot;templates&quot;)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    return render_template(&quot;index.html&quot;)\n</code></pre>\n<h3 id=\"serving-a-json-response\">Serving a JSON Response </h3><p><code>make_response</code> is suitable if our application is an API and we'd like to return a response object:</p><pre><code class=\"language-python\">from flask import Flask, make_response\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;)\ndef hello():\n    headers = {&quot;Content-Type&quot;: &quot;application/json&quot;}\n    return make_response('it worked!', 200, headers=headers)\n</code></pre>\n<p>On the topic of creating APIs with Flask, we can also specify whether the route at hand is a POST, GET, or some other method. This is handled easily within the route decorator:</p><pre><code class=\"language-python\">from flask import Flask, make_response, request\napp = Flask(__name__)\n\n@app.route(&quot;/&quot;, methods=['GET'])\ndef hello():\n    if request.method != 'GET':\n        return make_response('Malformed request', 400)\n    headers = {&quot;Content-Type&quot;: &quot;application/json&quot;}\n    return make_response('it worked!', 200, headers=headers)\n</code></pre>\n<p>The above function checks to make sure the user is accessing the endpoint with the correct method first. If they've used the incorrect method, we return an error.</p><h2 id=\"succumb-to-flask\">Succumb to Flask</h2><p>Even if you chose to stick to your large Frameworks, it's easy to see why Flask is useful as a drop-in solution for many tasks. There are undoubtedly plenty of useful Python scripts which go wasted because the final step of making them easily consumable by other people was never completed. Flask is an excellent way to achieve this last step, and the best part is: you already know how to use it.</p>","url":"https://hackersandslackers.com/creating-your-first-flask-application/","uuid":"dac63aa8-2a5d-4d3e-a6b1-cccc5785764c","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b426ec02d99b9040e300f74"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867369d","title":"Extract Massive Amounts of Data from APIs in Python","slug":"extracting-massive-datasets-from-apis","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/usa@2x.jpg","excerpt":"Abusing REST APIs for all they’re worth.","custom_excerpt":"Abusing REST APIs for all they’re worth.","created_at_pretty":"04 July, 2018","published_at_pretty":"04 July, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-07-04T15:24:18.000-04:00","published_at":"2018-07-04T17:26:00.000-04:00","updated_at":"2019-03-28T07:55:05.000-04:00","meta_title":"Extracting Massive Datasets in Python | Hackers and Slackers","meta_description":"The data we need and crave is stashed behind APIs all around us. We have the keys to the world, but that power often comes with a few caveats.","og_description":"The data we need and crave is stashed behind APIs all around us. We have the keys to the world, but that power often comes with a few caveats.","og_image":"https://hackersandslackers.com/content/images/2018/07/usa@2x.jpg","og_title":"Extracting Massive Datasets in Python","twitter_description":"The data we need and crave is stashed behind APIs all around us. We have the keys to the world, but that power often comes with a few caveats.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/usa@2x.jpg","twitter_title":"Extracting Massive Datasets in Python","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"}],"plaintext":"Taxation without representation. Colonialism. Not letting people eat cake. Human\nbeings rightfully meet atrocities with action in an effort to change the worked\nfor the better. Cruelty by mankind justifies revolution, and it is this writer’s\nopinion that API limitations are one such cruelty.\n\nThe data we need and crave is stashed in readily available APIs all around us.\nIt’s as though we have the keys to the world, but that power often comes with a\nfew caveats:\n\n * Your “key” only lasts a couple of hours, and if you want another one, you’ll\n   have to use some other keys to get another key.\n * You can have the ten thousand records you’re looking for, but you can only\n   pull 50 at a time.\n * You won’t know the exact structure of the data you’re getting, but it’ll\n   probably be a JSON hierarchy designed by an 8-year-old.\n\nAll men may be created equal, but APIs are not. In the spirit of this 4th of\nJuly, let us declare independence from repetitive tasks: One Script, under\nPython, for Liberty and Justice for all.\n\nProject Setup\nWe'll split our project up by separation of concern into just a few files:\n\nmyProject\n├── main.py\n├── config.py\n└── token.py\n\n\nMain.py will unsurprisingly hold the core logic of our script.\n\nConfig.py contains variables such as client secrets and endpoints which we can\neasily swap when applying this script to different APIs. For now we'll just keep\nvariables client_id  and client_secret  in there for now.\n\nToken.py  serves the purpose of Token Generation. Let's start there.\n\nThat's the Token \nSince we're assuming worst case scenarios let's focus on atrocity number one:\nAPIs which require expiring tokens. There are some tyrants in this world who\nbelieve that in order to use their API, it is necessary to to first use a client\nID and client secret to generate a Token which quickly becomes useless hours\nlater. In other words, you need to use an API every time you want to use the\nactual API. Fuck that.\n\nimport requests\nfrom config import client_id, client_secret\n\ntoken_url = 'https://api.fakeapi.com/auth/oauth2/v2/token'\n\ndef generateToken():\n    r = requests.post(token_url, auth=(client_id, client_secret), json={\"grant_type\": \"client_credentials\"})\n    bearer_token = r.json()['access_token']\n    print('new token = ', bearer_token)\n    return bearer_token\n\ntoken = generateToken()\n\n\nWe import client_id  and client_secret  from our config file off the bat: most\nservices will grant these things simply by signing up for their API.\n\nMany APIs have an endpoint which specifically serves the purpose of accepting\nthese variables and spitting out a generated token. token_url  is the variable\nwe use to store this endpoint.\n\nOur token  variable invokes our generateToken()  function which stores the\nresulting Token. With this out of the way, we can now call this function every\ntime we use the API, so we never have to worry about expiring tokens.\n\nPandas to the Rescue\nWe've established that we're looking to pull a large set of data, probably\nsomewhere in the range of thousands of records. While JSON is all fine and\ndandy, it probably isn't very useful for human beings to consume a JSON file\nwith thousands of records. \n\nAgain, we have no idea what the nature of the data coming through will look\nlike. I don't really care to manually map values to fields, and I'm guessing you\ndon't either. Pandas can help us out here: by passing the first page of records\nto Pandas, we can generate the resulting keys into columns in a Dataframe. It's\nalmost like having a database-type schema created for you simply by looking at\nthe data coming through:\n\nimport requests\nimport pandas as pd\nimport numpy as np\nimport json\nfrom token import token\n\ndef setKeys():\n    headers = {\"Authorization\":\"Bearer \" + token}\n    r = requests.get(base_url + 'users', headers=headers)\n    dataframe = pd.DataFrame(columns=r.json()['data'][0].keys())\n    return dataframe\n\nrecords_df = setKeys()\n\nWe can now store all data into records_df  moving forward, allowing us to build\na table of results.\n\nNo Nation for Pagination\nAnd here we are, one of the most obnoxious parts of programming: paginated\nresults. We want thousands of records, but we're only allowed 50 at a time. Joy.\n\nWe've already set records_df  earlier as a global variable, so we're going to\nappend every page of results we get to that Dataframe, starting at page #1. The\nfunction getRecords  is going to pull that first page for us.\n\nbase_url = 'https://api.fakeapi.com/api/1/'\n\ndef getRecords():\n    headers = {\"Authorization\": \"Bearer \" + token}\n    r = requests.get(base_url + 'users', headers=headers)\n    nextpage = r.json()['pagination']['next_link']\n    records_df = pd.DataFrame(columns=r.json()['data'][0].keys())\n    if nextpage:\n        getNextPage(nextpage)\n\ngetRecords()\n\n\nLuckily APIs if there are  additional pages of results to a request, most APIs\nwill provide a URL to said page, usually stored in the response as a value. In\nour case, you can see we find this value after making the request: nextpage =\nr.json()['pagination']['next_link']. If this value exists, we make a call to get\nthe next page of results.\n\npage = 1\n\ndef getNextPage(nextpage):\n    global page\n    page = page + 1\n    print('PAGE ', page)\n    headers = {\"Authorization\": \"Bearer \" + token}\n    r = requests.get(nextpage, headers=headers)\n    nextpage = r.json()['pagination']['next_link']\n    records = r.json()['data']\n    for user in records:\n        s  = pd.Series(user,index=user.keys())\n        global records_df\n        records_df.loc[len(records_df)] = s\n    records_df.to_csv('records.csv')\n    if nextpage:\n        getNextPage(nextpage)\n\nOur function getNextPage  hits that next page of results, and appends them to\nthe pandas DataFrame we created earlier. If another page exists after that, the\nfunction runs again, and our page increments by 1. As long as more pages exist,\nthis function will fire again and again until all innocent records are driven\nout of their comfortable native resting place and forced into our contained\ndataset. There's not much more American than that.\n\nThere's More We Can Do\nThis script is fine, but it can optimized to be even more modular to truly be\none-size-fits-all. For instance, some APIs don't tell you the number of pages \nyou should except, but rather the number of records.  In those cases, we'd have\nto divide total number of records by records per page to know how many pages to\nexpect. As much as I want to go into detail about writing loops on the 4th of\nJuly, I don't. At all.\n\nThere are plenty more examples, but this should be enough to get us thinking how\nwe can replace tedious work with machines. That sounds like a flavor that pairs\nperfectly with Bud Light and hotdogs if you ask me.","html":"<p>Taxation without representation. Colonialism. Not letting people eat cake. Human beings rightfully meet atrocities with action in an effort to change the worked for the better. Cruelty by mankind justifies revolution, and it is this writer’s opinion that API limitations are one such cruelty.</p><p>The data we need and crave is stashed in readily available APIs all around us. It’s as though we have the keys to the world, but that power often comes with a few caveats:</p><ul><li>Your “key” only lasts a couple of hours, and if you want another one, you’ll have to use some other keys to get another key.</li><li>You can have the ten thousand records you’re looking for, but you can only pull 50 at a time.</li><li>You won’t know the exact structure of the data you’re getting, but it’ll probably be a JSON hierarchy designed by an 8-year-old.</li></ul><p>All men may be created equal, but APIs are not. In the spirit of this 4th of July, let us declare independence from repetitive tasks: One Script, under Python, for Liberty and Justice for all.</p><h2 id=\"project-setup\">Project Setup</h2><p>We'll split our project up by separation of concern into just a few files:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">myProject\n├── main.py\n├── config.py\n└── token.py\n</code></pre>\n<!--kg-card-end: markdown--><p><strong>Main.py </strong>will unsurprisingly hold the core logic of our script.</p><p><strong>Config.py </strong>contains variables such as client secrets and endpoints which we can easily swap when applying this script to different APIs. For now we'll just keep variables <code>client_id</code> and <code>client_secret</code> in there for now.</p><p><strong>Token.py</strong> serves the purpose of Token Generation. Let's start there.</p><h2 id=\"that-s-the-token\">That's the Token </h2><p>Since we're assuming worst case scenarios let's focus on atrocity number one: APIs which require expiring tokens. There are some tyrants in this world who believe that in order to use their API, it is necessary to to first use a client ID and client secret to generate a Token which quickly becomes useless hours later. In other words, you need to use an API every time you want to use the actual API. Fuck that.</p><!--kg-card-begin: code--><pre><code>import requests\nfrom config import client_id, client_secret\n\ntoken_url = 'https://api.fakeapi.com/auth/oauth2/v2/token'\n\ndef generateToken():\n    r = requests.post(token_url, auth=(client_id, client_secret), json={\"grant_type\": \"client_credentials\"})\n    bearer_token = r.json()['access_token']\n    print('new token = ', bearer_token)\n    return bearer_token\n\ntoken = generateToken()\n</code></pre><!--kg-card-end: code--><p>We import <code>client_id</code> and <code>client_secret</code> from our config file off the bat: most services will grant these things simply by signing up for their API.  </p><p>Many APIs have an endpoint which specifically serves the purpose of accepting these variables and spitting out a generated token. <code>token_url</code> is the variable we use to store this endpoint.</p><p>Our <code>token</code> variable invokes our <code>generateToken()</code> function which stores the resulting Token. With this out of the way, we can now call this function every time we use the API, so we never have to worry about expiring tokens.</p><h2 id=\"pandas-to-the-rescue\">Pandas to the Rescue</h2><p>We've established that we're looking to pull a large set of data, probably somewhere in the range of thousands of records. While JSON is all fine and dandy, it probably isn't very useful for human beings to consume a JSON file with thousands of records. </p><p>Again, we have no idea what the nature of the data coming through will look like. I don't really care to manually map values to fields, and I'm guessing you don't either. Pandas can help us out here: by passing the first page of records to Pandas, we can generate the resulting keys into columns in a Dataframe. It's almost like having a database-type schema created for you simply by looking at the data coming through:</p><!--kg-card-begin: code--><pre><code>import requests\nimport pandas as pd\nimport numpy as np\nimport json\nfrom token import token\n\ndef setKeys():\n    headers = {\"Authorization\":\"Bearer \" + token}\n    r = requests.get(base_url + 'users', headers=headers)\n    dataframe = pd.DataFrame(columns=r.json()['data'][0].keys())\n    return dataframe\n\nrecords_df = setKeys()</code></pre><!--kg-card-end: code--><p>We can now store all data into <code>records_df</code> moving forward, allowing us to build a table of results.</p><h2 id=\"no-nation-for-pagination\">No Nation for Pagination</h2><p>And here we are, one of the most obnoxious parts of programming: paginated results. We want thousands of records, but we're only allowed 50 at a time. Joy.</p><p>We've already set <code>records_df</code> earlier as a global variable, so we're going to append every page of results we get to that Dataframe, starting at page #1. The function <code>getRecords</code> is going to pull that first page for us.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">base_url = 'https://api.fakeapi.com/api/1/'\n\ndef getRecords():\n    headers = {&quot;Authorization&quot;: &quot;Bearer &quot; + token}\n    r = requests.get(base_url + 'users', headers=headers)\n    nextpage = r.json()['pagination']['next_link']\n    records_df = pd.DataFrame(columns=r.json()['data'][0].keys())\n    if nextpage:\n        getNextPage(nextpage)\n\ngetRecords()\n</code></pre>\n<!--kg-card-end: markdown--><p>Luckily APIs if there <em>are</em> additional pages of results to a request, most APIs will provide a URL to said page, usually stored in the response as a value. In our case, you can see we find this value after making the request: <code>nextpage = r.json()['pagination']['next_link']</code>. If this value exists, we make a call to get the next page of results.</p><!--kg-card-begin: code--><pre><code>page = 1\n\ndef getNextPage(nextpage):\n    global page\n    page = page + 1\n    print('PAGE ', page)\n    headers = {\"Authorization\": \"Bearer \" + token}\n    r = requests.get(nextpage, headers=headers)\n    nextpage = r.json()['pagination']['next_link']\n    records = r.json()['data']\n    for user in records:\n        s  = pd.Series(user,index=user.keys())\n        global records_df\n        records_df.loc[len(records_df)] = s\n    records_df.to_csv('records.csv')\n    if nextpage:\n        getNextPage(nextpage)</code></pre><!--kg-card-end: code--><p>Our function <code>getNextPage</code> hits that next page of results, and <em>appends them to the pandas DataFrame </em>we created earlier. If another page exists after that, the function runs again, and our page increments by 1. As long as more pages exist, this function will fire again and again until all innocent records are driven out of their comfortable native resting place and forced into our contained dataset. There's not much more American than that.</p><h2 id=\"there-s-more-we-can-do\">There's More We Can Do</h2><p>This script is fine, but it can optimized to be even more modular to truly be one-size-fits-all. For instance, some APIs don't tell you the number of <em>pages</em> you should except, but rather the number of <em>records.</em> In those cases, we'd have to divide total number of records by records per page to know how many pages to expect. As much as I want to go into detail about writing loops on the 4th of July, I don't. At all.</p><p>There are plenty more examples, but this should be enough to get us thinking how we can replace tedious work with machines. That sounds like a flavor that pairs perfectly with Bud Light and hotdogs if you ask me.</p>","url":"https://hackersandslackers.com/extracting-massive-datasets-from-apis/","uuid":"39a94407-5d5a-4038-a6b6-04fa228ad0f0","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b3d1ee2d0ac8a143588f36e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867368d","title":"Upgrading to Gulp 4.0.0","slug":"upgrading-to-gulp-4","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/06/gulp2@2x.jpg","excerpt":"Upgrading to Gulp 4 and tackling the breaking changes that come with it.","custom_excerpt":"Upgrading to Gulp 4 and tackling the breaking changes that come with it.","created_at_pretty":"27 June, 2018","published_at_pretty":"28 June, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-06-27T11:06:39.000-04:00","published_at":"2018-06-28T07:30:00.000-04:00","updated_at":"2019-04-09T21:11:52.000-04:00","meta_title":"Upgrading to Gulp 4.0.0 | Hackers and Slackers","meta_description":"Upgrading to Gulp 4 and tackling the breaking changes that come with it.","og_description":"Upgrading to Gulp 4 and tackling the breaking changes that come with it.","og_image":"https://hackersandslackers.com/content/images/2018/06/gulp2@2x.jpg","og_title":"Upgrading to Gulp 4.0.0","twitter_description":"Upgrading to Gulp 4 and tackling the breaking changes that come with it.","twitter_image":"https://hackersandslackers.com/content/images/2018/06/gulp2@2x.jpg","twitter_title":"Upgrading to Gulp 4.0.0","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},{"name":"ExpressJS","slug":"expressjs","description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch as a simplistic Express app can evolve into a beautiful monstrosity.","feature_image":null,"meta_description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch a simplistic Express app can evolve into a beautiful monstrosity.","meta_title":"ExpressJS Framework | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"Back in the day we touched on some of the wonderful upsides of implementing Gulp\n[https://hackersandslackers.com/using-gulp-to-make-frontend-tolerable/]  into\nyour workflow. If you have been following along and happened to install the\nlatest version of Gulp, you may has noticed something horrible happen: nothing\nworked. I probably should’ve mentioned that the latest major update to Gulp,\nGulp 4, is actually a breaking update. That's my bad.\n\nStrangely, documentation around upgrading from Gulp 3.X to Gulp 4 seems to be\nlagging way behind this release, with the closest thing to official\ndocumentation being some article a guy posted on Medium a while back.\nInteresting strategy, Gulp team.\n\nWhat's the Big Deal?\nThere are a couple architectural differences with Gulp 4, for the better.\nPreviously Gulp would allows us to hold off on executing tasks until dependent\ntask were completed. If task C were dependent on the completion of tasks both A\nand B, we would represent this as such:\n\ngulp.task('default', ['A', 'B'], function() {etc});\n\ngulp.task('A', ['C'], function() {etc});\ngulp.task('B', ['C'], function() {etc});\n\ngulp.task('C', function() {etc});\n\n\nWhile this was an effective way of handling such a workflow, Gulp has made the\nprocess a bit cleaner and easier to digest with the additions of gulp.parallel \nand gulp.series.\n\nParallel  denotes tasks which should be executed in parallel, aka the same time.\n\nSeries  defines a linear order of how tasks should be executed. Parallels can\nexist inside of series, effectively resulting in a fork of tasks before moving\nto the next task in the series:\n\ngulp.task('A', function() {etc});\ngulp.task('B', function() {etc});\n\ngulp.task('C', function() {etc});\n\ngulp.task('default', gulp.series('C', gulp.parallel('A', 'B'), function() {etc}));\n\n\nIn this case, Task C forks into Tasks A and B before converging on their merry\nway to the rest of the series.\n\nQuick Install\nTo get your hands on this, first uninstall your current versions of Gulp and\nGulp CLI:\n\nnpm uninstall gulp --save-dev\nnpm uninstall gulp -g\n\n\nThen we can go ahead and reinstall Gulp as normal. Feel free to force the\nversion:\n\nnpm install gulp-cli -g\nnpm install gulp@4.0.0 -D\n\n\nExample Gulp File\nEnough with all the jargon, we both know what you came here for. let me just\npost what I see to be the bare minimum Gulpfile for your copy and pasting\npleasure:\n\nvar gulp \t= require('gulp'),\n  \tless \t= require('gulp-less'),\n  \tconcat \t= require('gulp-concat'),\n  \tuglify \t= require('gulp-uglify'),\n  \trename \t= require('gulp-rename'),\n    handlebars = require('gulp-handlebars'),\n    declare = require('gulp-declare'),\n    cleanCSS = require('gulp-clean-css');\n\nvar paths = {\n  styles: {\n    src: 'src/less/*.less',\n    dest: 'assets/css'\n  },\n  scripts: {\n    src: 'src/js/*.js',\n    dest: 'assets/js'\n  },\n  html: {\n    src: 'views/*.hbs',\n    dest: 'assets/'\n  }\n};\n\nfunction styles() {\n  return gulp\n  \t.src(paths.styles.src, {\n      sourcemaps: true\n    })\n\t.pipe(less())\n\t.pipe(rename({\n\t  basename: 'main',\n\t  suffix: '.min'\n\t}))\n.pipe(cleanCSS({debug: true}))\n.pipe(concat('main.min.css'))\n.pipe(gulp.dest(paths.styles.dest));\n}\n\nfunction scripts() {\n  return gulp\n\t.src(paths.scripts.src, {\n\t\tsourcemaps: true\n\t})\n\t.pipe(uglify())\n\t.pipe(concat('main.min.js'))\n\t.pipe(gulp.dest(paths.scripts.dest));\n}\n\nfunction templates(){\n  gulp.src('views/*.hbs')\n    .pipe(handlebars())\n    //.pipe(wrap('Handlebars.template(<%= contents %>)'))\n    .pipe(declare({\n      namespace: 'MyApp.templates',\n      noRedeclare: true, // Avoid duplicate declarations\n    }))\n    .pipe(concat('templates.js'))\n    .pipe(gulp.dest('assets/js/'));\n}\n\nfunction watch() {\n  gulp.watch(paths.scripts.src, scripts);\n  gulp.watch(paths.styles.src, styles);\n}\n\nvar build = gulp.parallel(styles, scripts, templates, watch);\n\ngulp.task(build);\ngulp.task('default', build);\n\n\nNothing crazy here: just the typical concat and minification of source files.\n\nHopefully this helps somebody wondering why their latest Gulp installation broke\ntheir Gulpfile. Perhaps next time we'll dig down deep into the shadows of Gulp\nplugins to reveal secret elite legendary Gulp hacks for 1337 hax0rs only. Or\nnot, we could do whatever honestly.","html":"<p>Back in the day we touched on some of the wonderful upsides of <a href=\"https://hackersandslackers.com/using-gulp-to-make-frontend-tolerable/\">implementing Gulp</a> into your workflow. If you have been following along and happened to install the latest version of Gulp, you may has noticed something horrible happen: <em>nothing worked</em>. I probably should’ve mentioned that the latest major update to Gulp, Gulp 4, is actually a breaking update. That's my bad.</p><p>Strangely, documentation around upgrading from Gulp 3.X to Gulp 4 seems to be lagging way behind this release, with the closest thing to official documentation being some article a guy posted on Medium a while back. Interesting strategy, Gulp team.</p><h2 id=\"what-s-the-big-deal\">What's the Big Deal?</h2><p>There are a couple architectural differences with Gulp 4, for the better. Previously Gulp would allows us to hold off on executing tasks until dependent task were completed. If task C were dependent on the completion of tasks both A and B, we would represent this as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">gulp.task('default', ['A', 'B'], function() {etc});\n\ngulp.task('A', ['C'], function() {etc});\ngulp.task('B', ['C'], function() {etc});\n\ngulp.task('C', function() {etc});\n</code></pre>\n<!--kg-card-end: markdown--><p>While this was an effective way of handling such a workflow, Gulp has made the process a bit cleaner and easier to digest with the additions of <strong>gulp.parallel</strong> and <strong>gulp.series</strong>.</p><p><strong>Parallel</strong> denotes tasks which should be executed in parallel, aka the same time.</p><p><strong>Series</strong> defines a linear order of how tasks should be executed. Parallels can exist inside of series, effectively resulting in a fork of tasks before moving to the next task in the series:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">gulp.task('A', function() {etc});\ngulp.task('B', function() {etc});\n\ngulp.task('C', function() {etc});\n\ngulp.task('default', gulp.series('C', gulp.parallel('A', 'B'), function() {etc}));\n</code></pre>\n<!--kg-card-end: markdown--><p>In this case, Task C forks into Tasks A and B before converging on their merry way to the rest of the series.</p><h2 id=\"quick-install\">Quick Install</h2><p>To get your hands on this, first uninstall your current versions of Gulp and Gulp CLI:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">npm uninstall gulp --save-dev\nnpm uninstall gulp -g\n</code></pre>\n<!--kg-card-end: markdown--><p>Then we can go ahead and reinstall Gulp as normal. Feel free to force the version:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">npm install gulp-cli -g\nnpm install gulp@4.0.0 -D\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"example-gulp-file\">Example Gulp File</h2><p>Enough with all the jargon, we both know what you came here for. let me just post what I see to be the bare minimum Gulpfile for your copy and pasting pleasure:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">var gulp \t= require('gulp'),\n  \tless \t= require('gulp-less'),\n  \tconcat \t= require('gulp-concat'),\n  \tuglify \t= require('gulp-uglify'),\n  \trename \t= require('gulp-rename'),\n    handlebars = require('gulp-handlebars'),\n    declare = require('gulp-declare'),\n    cleanCSS = require('gulp-clean-css');\n\nvar paths = {\n  styles: {\n    src: 'src/less/*.less',\n    dest: 'assets/css'\n  },\n  scripts: {\n    src: 'src/js/*.js',\n    dest: 'assets/js'\n  },\n  html: {\n    src: 'views/*.hbs',\n    dest: 'assets/'\n  }\n};\n\nfunction styles() {\n  return gulp\n  \t.src(paths.styles.src, {\n      sourcemaps: true\n    })\n\t.pipe(less())\n\t.pipe(rename({\n\t  basename: 'main',\n\t  suffix: '.min'\n\t}))\n.pipe(cleanCSS({debug: true}))\n.pipe(concat('main.min.css'))\n.pipe(gulp.dest(paths.styles.dest));\n}\n\nfunction scripts() {\n  return gulp\n\t.src(paths.scripts.src, {\n\t\tsourcemaps: true\n\t})\n\t.pipe(uglify())\n\t.pipe(concat('main.min.js'))\n\t.pipe(gulp.dest(paths.scripts.dest));\n}\n\nfunction templates(){\n  gulp.src('views/*.hbs')\n    .pipe(handlebars())\n    //.pipe(wrap('Handlebars.template(&lt;%= contents %&gt;)'))\n    .pipe(declare({\n      namespace: 'MyApp.templates',\n      noRedeclare: true, // Avoid duplicate declarations\n    }))\n    .pipe(concat('templates.js'))\n    .pipe(gulp.dest('assets/js/'));\n}\n\nfunction watch() {\n  gulp.watch(paths.scripts.src, scripts);\n  gulp.watch(paths.styles.src, styles);\n}\n\nvar build = gulp.parallel(styles, scripts, templates, watch);\n\ngulp.task(build);\ngulp.task('default', build);\n</code></pre>\n<!--kg-card-end: markdown--><p>Nothing crazy here: just the typical concat and minification of source files.</p><p>Hopefully this helps somebody wondering why their latest Gulp installation broke their Gulpfile. Perhaps next time we'll dig down deep into the shadows of Gulp plugins to reveal secret elite legendary Gulp hacks for 1337 hax0rs only. Or not, we could do whatever honestly.</p>","url":"https://hackersandslackers.com/upgrading-to-gulp-4/","uuid":"deb7ac06-d159-4c66-8d8a-11442ffbb395","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b33a7ff1e2df4575e4c101c"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867368c","title":"Building Page Templates in ExpressJS With Handlebars","slug":"handlebars-templating-in-expressjs","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/handlebars.jpg","excerpt":"Building views in NodeJS by incorporating layouts, partials, and everything in between.","custom_excerpt":"Building views in NodeJS by incorporating layouts, partials, and everything in between.","created_at_pretty":"25 June, 2018","published_at_pretty":"26 June, 2018","updated_at_pretty":"05 March, 2019","created_at":"2018-06-25T16:39:57.000-04:00","published_at":"2018-06-26T18:52:57.000-04:00","updated_at":"2019-03-04T21:54:13.000-05:00","meta_title":"Handlebars Templating in ExpressJS | Hackers and Slackers","meta_description":"Building views in NodeJS by incorporating layouts, partials, and everything in between.","og_description":"Building views in NodeJS by incorporating layouts, partials, and everything in between.","og_image":"https://hackersandslackers.com/content/images/2019/03/handlebars.jpg","og_title":"Handlebars Templating in ExpressJS","twitter_description":"Building views in NodeJS by incorporating layouts, partials, and everything in between.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/handlebars.jpg","twitter_title":"Handlebars Templating in ExpressJS","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},{"name":"ExpressJS","slug":"expressjs","description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch as a simplistic Express app can evolve into a beautiful monstrosity.","feature_image":null,"meta_description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch a simplistic Express app can evolve into a beautiful monstrosity.","meta_title":"ExpressJS Framework | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"Writing HTML sucks, thus we should do everything to minimize the time we spend\nwriting it as much as possible.  Thus, we have Handlebars\n[https://handlebarsjs.com/]: a lightweight templating system for Node.\nHandlebars allows us to avoid repetitive code by compiling the final DOM\nstructure of our site via logic, typically compiled by task runners such as\nGrunt or Gulp.\n\nIf you're involved in any sort of Node development, you're probably already\nfamiliar with Handlebars to a degree. I thought I was, but it isn't until we\nneed to start a new project from scratch that we realize that we totally forgot\nthe configuration process we took last time. That's why I'm here.\n\nLet's have a quick refresher on the parts that make up Handlebars\n\n * Layouts  are the most ambiguous high-level layer; these are commonly used to\n   set underlying page metadata as well as general layout (for lack of a better\n   term).\n * Pages  are templates which equate to one type  of page. For example, the\n   'post' page on this site is unique from, say, the homepage. Because all posts\n   share elements with one another, hundreds of posts share this same template.\n * Partials  are snippets which can be shared between pages, such as navigation.\n * A Context  is content which is passed to templates and result in being the\n   page's content\n * Helpers  are the closest we get to logic in Handlebars: these allow us to\n   display or omit content based on conditionals such as if  statements. For\n   example: showing an author's avatar only if they have uploaded an image.\n\nProject Setup\nWe're going to use the Express /views  folder to contain all of our handlebars\ngoodness. Our project should look something like this:\n\nmyapp\n├── bin\n├── build\n├── routes\n├── src\n├── views\n│   ├── layouts/\n│   ├── partials/\n│   └── error.hbs\n│   └── index.hbs\n│   └── login.hbs\n│   └── etc\n└── README.md\n└── app.js\n└── package.json\n\n\nIt's important to distinguish that we've separated our views folder into three\nclassifications for layouts, partials, and pages, where pages occupy the root \n/views  directory. It's important to keep this distinction as our structure\naffects how we serve up these templates.\n\nConfigure that Ish\nInstall handlebars:\n\nnpm install handlebars --save\n\n\nCrack open your app.js  file or whatever it is you call that thing. Require\nhandlebars:\n\nvar hbs = require( 'express-handlebars');\n\n\nNext we'll configure Express to use Handlebars as the view engine, and tell\nExpress where to find these files:\n\n// view engine setup\napp.set('view engine', 'hbs');\n\napp.engine( 'hbs', hbs( {\n  extname: 'hbs',\n  defaultView: 'default',\n  layoutsDir: __dirname + '/views/pages/',\n  partialsDir: __dirname + '/views/partials/'\n}));\n\n\nExpress assumes by default that we're storing our views in the '/views' folder,\nwhich we are. We take this a step further by specifying which subfolders our \npartials  and layouts  are in above. We can save pages  directly in /views.\n\nNotice that we're also setting a default layout. We can override this in our\nroutes if needed, but setting a default layout is useful for loading pages in an\nhtml wrapper container page metadata.\n\nKicks on Route 66\nLet's create our first route in routes/index.js. We're going to load a view\ncalled home  into a layout called default:\n\nvar express = require('express');\nvar router = express.Router();\n\nrouter.get('/', function(req, res, next) {\n  res.render('home', {layout: 'default', template: 'home-template'});\n});\n\n\nThis will render views/home.hbs  into views/layouts/default.hbs, provided are\nviews are set up correctly. We also pass a custom value template  which is\nuser-defined; more on that below.\n\nBasic Usage\nLet's finally take a look at our actual Handlebars views. Here's default.hbs:\n\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"utf-8\" />\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n  <title>Best Website</title>\n  <meta name=\"HandheldFriendly\" content=\"True\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, viewport-fit=cover\" />\n  <link rel=\"stylesheet\" href=\"/css/main.min.css\">\n</head>\n<body class=\"{{template}}\">\n  <div class=\"container\">\n\t  {{{body}}}\n  </div>\n  {{> footer}}\n</body>\n</html>\n\n\nWe have three values here: {{template}}  and {{{body}}}, and {{> footer}}.\n\n{{template}}  is a value with double brackets, thus is expecting linear data. We\npassed template  in our route: this sets the body class to equal home-template \non the chance that we'll want to apply page-specific styles or logic in the\nfuture.\n\n{{{body}}}  is rocking the triple brackets, and is reserved specifically to\nserve this purpose: loading templates into other templates.\n\nLastly we have {{> footer}}. This will load a partial named footer  from \nviews/partials/footer.hbs, provided that we create it. The difference between\nhow {{{body}}}  and {{> footer}}  are being loaded have to do with a general\nworkflow philosophy; pages are the main event and thus are loaded into layouts\nby their command. Partials can be called by pages at will whenever we please.\n\nThere's obviously a lot more to Handlebars- the fun doesn't truly begin until we\npull dynamic values from databases or wherever. We'll get there.","html":"<p>Writing HTML sucks, thus we should do everything to minimize the time we spend writing it as much as possible.  Thus, we have <a href=\"https://handlebarsjs.com/\">Handlebars</a>: a lightweight templating system for Node. Handlebars allows us to avoid repetitive code by compiling the final DOM structure of our site via logic, typically compiled by task runners such as Grunt or Gulp.</p><p>If you're involved in any sort of Node development, you're probably already familiar with Handlebars to a degree. I thought I was, but it isn't until we need to start a new project from scratch that we realize that we totally forgot the configuration process we took last time. That's why I'm here.</p><p>Let's have a quick refresher on the parts that make up Handlebars</p><ul><li><strong>Layouts</strong> are the most ambiguous high-level layer; these are commonly used to set underlying page metadata as well as general layout (for lack of a better term).</li><li><strong>Pages</strong> are templates which equate to one <em>type</em> of page. For example, the 'post' page on this site is unique from, say, the homepage. Because all posts share elements with one another, hundreds of posts share this same template.</li><li><strong>Partials</strong> are snippets which can be shared between pages, such as navigation.</li><li>A <strong>Context</strong> is content which is passed to templates and result in being the page's content</li><li><strong>Helpers</strong> are the closest we get to logic in Handlebars: these allow us to display or omit content based on conditionals such as <em>if</em> statements. For example: showing an author's avatar only if they have uploaded an image.</li></ul><h2 id=\"project-setup\">Project Setup</h2><p>We're going to use the Express <em>/views</em> folder to contain all of our handlebars goodness. Our project should look something like this:</p><pre><code class=\"language-bash\">myapp\n├── bin\n├── build\n├── routes\n├── src\n├── views\n│   ├── layouts/\n│   ├── partials/\n│   └── error.hbs\n│   └── index.hbs\n│   └── login.hbs\n│   └── etc\n└── README.md\n└── app.js\n└── package.json\n</code></pre>\n<p>It's important to distinguish that we've separated our views folder into three classifications for <strong>layouts</strong>, <strong>partials</strong>, and <strong>pages</strong>, where pages occupy the root <code>/views</code> directory. It's important to keep this distinction as our structure affects how we serve up these templates.</p><h2 id=\"configure-that-ish\">Configure that Ish</h2><p>Install handlebars:</p><pre><code class=\"language-bash\">npm install handlebars --save\n</code></pre>\n<p>Crack open your <code>app.js</code> file or whatever it is you call that thing. Require handlebars:</p><pre><code class=\"language-javascript\">var hbs = require( 'express-handlebars');\n</code></pre>\n<p>Next we'll configure Express to use Handlebars as the view engine, and tell Express where to find these files:</p><pre><code class=\"language-javascript\">// view engine setup\napp.set('view engine', 'hbs');\n\napp.engine( 'hbs', hbs( {\n  extname: 'hbs',\n  defaultView: 'default',\n  layoutsDir: __dirname + '/views/pages/',\n  partialsDir: __dirname + '/views/partials/'\n}));\n</code></pre>\n<p>Express assumes by default that we're storing our views in the '/views' folder, which we are. We take this a step further by specifying which subfolders our <strong>partials</strong> and <strong>layouts</strong> are in above. We can save <strong>pages</strong> directly in <code>/views</code>.</p><p>Notice that we're also setting a default layout. We can override this in our routes if needed, but setting a default layout is useful for loading pages in an html wrapper container page metadata.</p><h2 id=\"kicks-on-route-66\">Kicks on Route 66</h2><p>Let's create our first route in <code>routes/index.js</code>. We're going to load a view called <em>home</em> into a layout called <em>default</em>:</p><pre><code class=\"language-javascript\">var express = require('express');\nvar router = express.Router();\n\nrouter.get('/', function(req, res, next) {\n  res.render('home', {layout: 'default', template: 'home-template'});\n});\n</code></pre>\n<p>This will render <code>views/home.hbs</code> into <code>views/layouts/default.hbs</code>, provided are views are set up correctly. We also pass a custom value <strong>template</strong> which is user-defined; more on that below.</p><h2 id=\"basic-usage\">Basic Usage</h2><p>Let's finally take a look at our actual Handlebars views. Here's <strong>default.hbs</strong>:</p><pre><code class=\"language-handlebars\">&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n&lt;head&gt;\n  &lt;meta charset=&quot;utf-8&quot; /&gt;\n  &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n  &lt;title&gt;Best Website&lt;/title&gt;\n  &lt;meta name=&quot;HandheldFriendly&quot; content=&quot;True&quot; /&gt;\n  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, viewport-fit=cover&quot; /&gt;\n  &lt;link rel=&quot;stylesheet&quot; href=&quot;/css/main.min.css&quot;&gt;\n&lt;/head&gt;\n&lt;body class=&quot;{{template}}&quot;&gt;\n  &lt;div class=&quot;container&quot;&gt;\n\t  {{{body}}}\n  &lt;/div&gt;\n  {{&gt; footer}}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n<p>We have three values here: <strong>{{template}}</strong> and <strong>{{{body}}}</strong>, and <strong>{{&gt; footer}}</strong>.</p><p><strong>{{template}}</strong> is a value with double brackets, thus is expecting linear data. We passed <em>template</em> in our route: this sets the body class to equal <em>home-template</em> on the chance that we'll want to apply page-specific styles or logic in the future.</p><p><strong>{{{body}}}</strong> is rocking the triple brackets, and is reserved specifically to serve this purpose: loading templates into other templates.</p><p>Lastly we have <strong>{{&gt; footer}}</strong>. This will load a partial named <em>footer</em> from <code>views/partials/footer.hbs</code>, provided that we create it. The difference between how <code>{{{body}}}</code> and <code>{{&gt; footer}}</code> are being loaded have to do with a general workflow philosophy; pages are the main event and thus are loaded into layouts by their command. Partials can be called by pages at will whenever we please.</p><p>There's obviously a lot more to Handlebars- the fun doesn't truly begin until we pull dynamic values from databases or wherever. We'll get there.</p>","url":"https://hackersandslackers.com/handlebars-templating-in-expressjs/","uuid":"9258a456-aee9-4d91-a36b-b1db735270b7","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b31531d04c0af72fa9a7681"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673683","title":"Read and Write to S3 Buckets via NodeJS","slug":"accessing-private-s3-objects-with-node","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/06/nodes3@2x.jpg","excerpt":"Node’s most popular package interacting with the most popular file store on the world’s most popular cloud.","custom_excerpt":"Node’s most popular package interacting with the most popular file store on the world’s most popular cloud.","created_at_pretty":"21 June, 2018","published_at_pretty":"22 June, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-06-21T19:26:44.000-04:00","published_at":"2018-06-22T07:30:00.000-04:00","updated_at":"2019-03-28T05:25:16.000-04:00","meta_title":"Accessing Private S3 Objects with Node | Hackers and Slackers","meta_description":"Node’s most popular package interacting with the most popular file store on the world’s most popular cloud.","og_description":"Node’s most popular package interacting with the most popular file store on the world’s most popular cloud.","og_image":"https://hackersandslackers.com/content/images/2018/06/nodes3@2x.jpg","og_title":"Accessing Private S3 Objects with Node","twitter_description":"Node’s most popular package interacting with the most popular file store on the world’s most popular cloud.","twitter_image":"https://hackersandslackers.com/content/images/2018/06/nodes3@2x.jpg","twitter_title":"Accessing Private S3 Objects with Node","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"ExpressJS","slug":"expressjs","description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch as a simplistic Express app can evolve into a beautiful monstrosity.","feature_image":null,"meta_description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch a simplistic Express app can evolve into a beautiful monstrosity.","meta_title":"ExpressJS Framework | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"}],"plaintext":"We here at H+S are dedicated to one simple cause: creating posts about oddly\nspecific programming scenarios. Somewhere in the world as sad soul is looking to\nprogrammatically access files from an S3 server while keeping their bucket\nprivate. To that person: we heard you.\n\nThere are plenty of reasons you'd want to access files in S3. For example, let's\nsay you read that post\n[https://hackersandslackers.com/using-pandas-with-aws-lambda/]  about using\nPandas in a Lambda function. Since you're already familiar with PyMySQL\n[https://hackersandslackers.com/using-pymysql/], you may hypothetically be in a\nposition to export data from a DB query to a CSV saved in S3. I bet you can\nguess what I've been doing lately.\n\nConfigure the AWS CLI on your VPS\nThe easiest and safest way to interact with other AWS services on your EC2\ninstance (or VPS of choice) is via the AWS CLI. This is easily installed as a\nglobal Python3 library:\n\n$ pip3 install awscli\n\n\nWith the CLI installed we'll be able to do something truly magical: set our AWS\nconfiguration globally. This means that any time we use interact with a\nmicroservice  (such as S3), the boto3  library will always look to the files\nstored in ~/.aws/  for our keys and secrets, without us specifying.  This\ncritical from a security perspective as it removes all  mentions of credentials\nfrom our codebase: including the location of said secrets.\n\nUse $ aws configure  to kickstart the process:\n\n$ aws configure\n$ AWS Access Key ID [None]: YOURACCESSKEY\n$ AWS Secret Access Key [None]: YOURSECRETKEY\n$ Default region name [None]: us-east-2\n$ Default output format [None]: json\n\n\nThis creates a couple config files for us. If we never need to modify these\nfiles, they can be found here:\n\n$ vim ~/.aws/credentials\n$ vim ~/.aws/config\n\n\nNode Time\nWe'll assume you have an app set up with some basic routing, such as the\nbarebones ExpressJS set up.\n\nIn your app we'll need to add 2 dependencies:\n\n$ npm install --save aws-sdk\n$ npm install --save aws-config\n\n\nNow we'll create a route.\n\nvar awsConfig = require('aws-config');\nvar AWS = require('aws-sdk');\n\nrouter.get('/export', function(req, res, next) {\n    var file = 'df.csv';\n    console.log('Trying to download file', fileKey);\n\n    var s3 = new AWS.S3({});\n\n    var options = {\n        Bucket: 'your-bucket-name',\n        Key: file,\n    };\n\n    s3.getObject(options, function(err, data) {\n      res.attachment(file);\n      res.send(data.Body);\n  });\n});\n\n\nNotice the empty curly brackets in new AWS.S3({}). If we had decided to\nbarbarically hardcode our credentials into our source code, normally those\nvalues would live between those brackets as an object. When the brackets are\nempty, the AWS library automagically knows to look to our AWS credentials file\nfor our access and secret keys. \n\nThis is how you'd do things the wrong way, just in case you wanted to be\nentertained:\n\nvar s3 = new AWS.S3({\n    'AccessKeyID': 'YOURACCESSKEY', \n    'SecretAccessKey': 'YOURSECRETACCESSKEY', \n    'Region': 'YOUR REGION'\n});\n\n\nYeah, that totally won't get committed somewhere by accident. Shake-my-head fam.\n\nThat's pretty much it: this route will prompt a download of the target file upon\nhitting the route. As much as I'm sure we'd all love to sit here and go through\nmore complicated use cases, let's just avoid Callback Hell altogether and enjoy\nthe rest of our day.\n\nHell will have to wait until next time.","html":"<p>We here at H+S are dedicated to one simple cause: creating posts about oddly specific programming scenarios. Somewhere in the world as sad soul is looking to programmatically access files from an S3 server while keeping their bucket private. To that person: we heard you.</p><p>There are plenty of reasons you'd want to access files in S3. For example, let's say you read <a href=\"https://hackersandslackers.com/using-pandas-with-aws-lambda/\">that post</a> about using Pandas in a Lambda function. Since you're already familiar with <a href=\"https://hackersandslackers.com/using-pymysql/\">PyMySQL</a>, you may hypothetically be in a position to export data from a DB query to a CSV saved in S3. I bet you can guess what I've been doing lately.</p><h2 id=\"configure-the-aws-cli-on-your-vps\">Configure the AWS CLI on your VPS</h2><p>The easiest and safest way to interact with other AWS services on your EC2 instance (or VPS of choice) is via the AWS CLI. This is easily installed as a global Python3 library:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ pip3 install awscli\n</code></pre>\n<!--kg-card-end: markdown--><p>With the CLI installed we'll be able to do something truly magical: set our AWS configuration globally. This means that any time we use interact with a microservice  (such as S3), the <strong>boto3</strong> library will always look to the files stored in <code>~/.aws/</code> for our keys and secrets, without us specifying.  This critical from a security perspective as it removes <em>all</em> mentions of credentials from our codebase: including the location of said secrets.</p><p>Use <code>$ aws configure</code> to kickstart the process:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ aws configure\n$ AWS Access Key ID [None]: YOURACCESSKEY\n$ AWS Secret Access Key [None]: YOURSECRETKEY\n$ Default region name [None]: us-east-2\n$ Default output format [None]: json\n</code></pre>\n<!--kg-card-end: markdown--><p>This creates a couple config files for us. If we never need to modify these files, they can be found here:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ vim ~/.aws/credentials\n$ vim ~/.aws/config\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"node-time\">Node Time</h2><p>We'll assume you have an app set up with some basic routing, such as the barebones ExpressJS set up.</p><p>In your app we'll need to add 2 dependencies:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ npm install --save aws-sdk\n$ npm install --save aws-config\n</code></pre>\n<!--kg-card-end: markdown--><p>Now we'll create a route.</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">var awsConfig = require('aws-config');\nvar AWS = require('aws-sdk');\n\nrouter.get('/export', function(req, res, next) {\n    var file = 'df.csv';\n    console.log('Trying to download file', fileKey);\n\n    var s3 = new AWS.S3({});\n\n    var options = {\n        Bucket: 'your-bucket-name',\n        Key: file,\n    };\n\n    s3.getObject(options, function(err, data) {\n      res.attachment(file);\n      res.send(data.Body);\n  });\n});\n</code></pre>\n<!--kg-card-end: markdown--><p>Notice the empty curly brackets in <code>new AWS.S3({})</code>. If we had decided to barbarically hardcode our credentials into our source code, normally those values would live between those brackets as an object. When the brackets are empty, the AWS library automagically knows to look to our AWS credentials file for our access and secret keys. </p><p>This is how you'd do things the <strong><em>wrong </em></strong>way, just in case you wanted to be entertained:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">var s3 = new AWS.S3({\n    'AccessKeyID': 'YOURACCESSKEY', \n    'SecretAccessKey': 'YOURSECRETACCESSKEY', \n    'Region': 'YOUR REGION'\n});\n</code></pre>\n<!--kg-card-end: markdown--><p>Yeah, that totally won't get committed somewhere by accident. Shake-my-head fam.</p><p>That's pretty much it: this route will prompt a download of the target file upon hitting the route. As much as I'm sure we'd all love to sit here and go through more complicated use cases, let's just avoid Callback Hell altogether and enjoy the rest of our day.</p><p>Hell will have to wait until next time.</p>","url":"https://hackersandslackers.com/accessing-private-s3-objects-with-node/","uuid":"210f5e64-7599-43d0-a148-d68373a9d3c4","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b2c34345f0bc81011d7cfc6"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673682","title":"Using Pandas with AWS Lambda Functions","slug":"using-pandas-with-aws-lambda","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/pandas-lambdas-2-3.jpg","excerpt":"Forcefully use the Pandas library in your AWS Lambda functions.","custom_excerpt":"Forcefully use the Pandas library in your AWS Lambda functions.","created_at_pretty":"20 June, 2018","published_at_pretty":"21 June, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-06-20T18:21:31.000-04:00","published_at":"2018-06-21T07:30:00.000-04:00","updated_at":"2019-03-28T08:49:25.000-04:00","meta_title":"Using Pandas with AWS Lambda Functions | Hackers and Slackers","meta_description":"Learn how to forcefully use Python's Pandas library in AWS Lambda functions.","og_description":"Learn how to forcefully use Python's Pandas library in AWS Lambda functions.","og_image":"https://hackersandslackers.com/content/images/2019/03/pandas-lambdas-2-3.jpg","og_title":"Using Pandas with AWS Lambda","twitter_description":"Learn how to forcefully use Python's Pandas library in AWS Lambda functions.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/pandas-lambdas-2-2.jpg","twitter_title":"Using Pandas with AWS Lambda","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#Creating APIs in AWS","slug":"create-an-aws-api","description":"Create a REST API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pythonlambda.jpg","meta_description":"Create an API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","meta_title":"Create a REST API in AWS","visibility":"internal"}],"plaintext":"In one corner we have Pandas: Python's beloved data analysis library. In the\nother, AWS: the unstoppable cloud provider we're obligated to use for all\neternity. We should have known this day would come.\n\nWhile not the prettiest workflow, uploaded Python package dependencies for usage\nin AWS Lambda is typically straightforward. We install the packages locally to a\nvirtual env, package them with our app logic, and upload a neat CSV to Lambda.\nIn some cases this doesn't always work: some packages result in a cryptic error\nmessage with absolutely no helpful instruction. Pandas is one of those packages.\n\nWhy is this? I can't exactly speak to that, but I can speak to how to fix it.\n\nSpin up an EC2 Instance\nCertain Python packages need to be installed and compiled on an EC2 instance in\norder to work properly with AWS microservices. I wish I could say that this fun\nlittle fact is well-documented somewhere in AWS with a perfectly good\nexplanation. It's not, and it doesn't.  It's probably best not to ask questions.\n\nSpin up a free tier EC2 instance, update your system packages, and make sure\nPython3 is installed. Some people theorize that the Python dependency package\nerrors happen when said dependencies are installed via versions of Python which\ndiffer from the version AWS is running. Those people are wrong.  I've already\nwasted the time to debunk this. They are liars.\n\nWith Python installed,  create a virtual environment inside any empty directory:\n\n$ apt-get install virtualenv\n$ virtualenv pandasenv\n$ source pandasenv/bin/activate\n\n\nWith the environment active, install pandas via pip3 install pandas. This will\nsave pandas and all its dependencies to the site-packages  folder our\nenvironment is running from, resulting in a URL such as this: \npandasenv/lib/python3.6/site-packages.\n\nPandas is actually 5 packages total. We're going to add each of these libraries\nto a zip file by installing zip, and adding each folder to the zip file\none-by-one. Finally, we'll apply some liberal permissions to the zip file we\njust created so we can grab it via FTP.\n\n$ cd pandasenv/lib/python3.6/site-packages\n$ apt-get install zip\n$ zip -r pandas_archive.zip pandas\n$ zip -r pandas_archive.zip numpy\n$ zip -r pandas_archive.zip pytz\n$ zip -r pandas_archive.zip six.py\n$ zip -r pandas_archive.zip dateutil\n$ chmod 777 pandas_archive.zip\n\n\nThis should be ready for you to FTP in your instance and grab as a zip file now\n(assuming you want to work locally). Alternatively, we could always copy those\npackages into the directory we'd like to work out of and zip everything once\nwe're done.\n\nUpload Source Code to S3\nAt this point, you should have been able to grab the AWS friendly version of\nPandas which is ready to be included in the final source code which will become\nyour Lambda Function.  You might notice that pandas alone nearly 30Mb: which is\nroughly the file size of countless intelligent people creating their life's\nwork. When Lambda Functions go above this file size, it's best to upload our\nfinal package (with source and dependencies) as a zip file to S3, and link it to\nLambda that way. This is considerably faster than the alternative of uploading\nthe zip to Lambda directly.\n\nBonus Round: Saving Exports\nWhat? You want to save a CSV result of all the cool stuff you're doing in\nPandas? You really are needy.\n\nBecause AWS is invoking the function, any attempt to read_csv()  will be\nworthless to us. To get around this, we can use boto3  to write files to an S3\nbucket instead:\n\nimport pandas as pd\nfrom io import StringIO\nimport boto3\n\ns3 = boto3.client('s3', aws_access_key_id=ACCESSKEY, aws_secret_access_key=SECRETYKEY)\ns3_resource = boto3.resource('s3')\nbucket = 'your_bucket_name'\n\ncsv_buffer = StringIO()\n\nexample_df = pd.DataFrame()\nexample_df.to_csv(csv_buffer)\ns3_resource.Object(bucket, 'export.csv').put(Body=csv_buffer.getvalue())\n\n\nWord of Advice\nThis isn't the prettiest process in the world, but we're somewhat at fault here.\nLambda functions are intended to be small tidbits of logic aimed to serve a\nsingle simple purpose. We just jammed 30Mbs of Python libraries into that simple\npurpose.\n\nThere are alternatives to Pandas that are better suited for usage in Lambda,\nsuch as Toolz  (thanks to Snkia for the heads up). Enjoy your full Pandas\nlibrary for now, but remember to feel bad about what you’ve done for next time.","html":"<p>In one corner we have Pandas: Python's beloved data analysis library. In the other, AWS: the unstoppable cloud provider we're obligated to use for all eternity. We should have known this day would come.</p><p>While not the prettiest workflow, uploaded Python package dependencies for usage in AWS Lambda is typically straightforward. We install the packages locally to a virtual env, package them with our app logic, and upload a neat CSV to Lambda. In some cases this doesn't always work: some packages result in a cryptic error message with absolutely no helpful instruction. Pandas is one of those packages.</p><p>Why is this? I can't exactly speak to that, but I can speak to how to fix it.</p><h2 id=\"spin-up-an-ec2-instance\">Spin up an EC2 Instance</h2><p>Certain Python packages need to be installed and compiled on an EC2 instance in order to work properly with AWS microservices. I wish I could say that this fun little fact is well-documented somewhere in AWS with a perfectly good explanation. It's not, and it doesn't.  It's probably best not to ask questions.</p><p>Spin up a free tier EC2 instance, update your system packages, and make sure Python3 is installed. Some people theorize that the Python dependency package errors happen when said dependencies are installed via versions of Python which differ from the version AWS is running. <em>Those people are wrong.</em> I've already wasted the time to debunk this. They are liars.</p><p>With Python installed,  create a virtual environment inside any empty directory:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ apt-get install virtualenv\n$ virtualenv pandasenv\n$ source pandasenv/bin/activate\n</code></pre>\n<!--kg-card-end: markdown--><p>With the environment active, install pandas via <code>pip3 install pandas</code>. This will save pandas and all its dependencies to the <em>site-packages</em> folder our environment is running from, resulting in a URL such as this: <code>pandasenv/lib/python3.6/site-packages</code>.</p><p>Pandas is actually 5 packages total. We're going to add each of these libraries to a zip file by installing <code>zip</code>, and adding each folder to the zip file one-by-one. Finally, we'll apply some liberal permissions to the zip file we just created so we can grab it via FTP.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">$ cd pandasenv/lib/python3.6/site-packages\n$ apt-get install zip\n$ zip -r pandas_archive.zip pandas\n$ zip -r pandas_archive.zip numpy\n$ zip -r pandas_archive.zip pytz\n$ zip -r pandas_archive.zip six.py\n$ zip -r pandas_archive.zip dateutil\n$ chmod 777 pandas_archive.zip\n</code></pre>\n<!--kg-card-end: markdown--><p>This should be ready for you to FTP in your instance and grab as a zip file now (assuming you want to work locally). Alternatively, we could always copy those packages into the directory we'd like to work out of and zip everything once we're done.</p><h3 id=\"upload-source-code-to-s3\">Upload Source Code to S3</h3><p>At this point, you should have been able to grab the <em>AWS friendly </em>version of Pandas which is ready to be included in the final source code which will become your Lambda Function.  You might notice that pandas alone nearly <em>30Mb</em>: which is roughly the file size of countless intelligent people creating their life's work. When Lambda Functions go above this file size, it's best to upload our final package (with source and dependencies) as a zip file to S3, and link it to Lambda that way. This is considerably faster than the alternative of uploading the zip to Lambda directly.</p><h2 id=\"bonus-round-saving-exports\">Bonus Round: Saving Exports</h2><p>What? You want to save a CSV result of all the cool stuff you're doing in Pandas? You really are needy.</p><p>Because AWS is invoking the function, any attempt to <code>read_csv()</code> will be worthless to us. To get around this, we can use <strong>boto3</strong> to write files to an S3 bucket instead:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\nfrom io import StringIO\nimport boto3\n\ns3 = boto3.client('s3', aws_access_key_id=ACCESSKEY, aws_secret_access_key=SECRETYKEY)\ns3_resource = boto3.resource('s3')\nbucket = 'your_bucket_name'\n\ncsv_buffer = StringIO()\n\nexample_df = pd.DataFrame()\nexample_df.to_csv(csv_buffer)\ns3_resource.Object(bucket, 'export.csv').put(Body=csv_buffer.getvalue())\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"word-of-advice\">Word of Advice</h3><p>This isn't the prettiest process in the world, but we're somewhat at fault here. Lambda functions are intended to be small tidbits of logic aimed to serve a single simple purpose. We just jammed 30Mbs of Python libraries into that simple purpose.</p><p>There are alternatives to Pandas that are better suited for usage in Lambda, such as <em>Toolz</em> (thanks to Snkia for the heads up). Enjoy your full Pandas library for now, but remember to feel bad about what you’ve done for next time.</p>","url":"https://hackersandslackers.com/using-pandas-with-aws-lambda/","uuid":"3d2d6592-5614-4485-b9cd-15d905a28c46","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b2ad36cded32f5af8fd674d"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673680","title":"Working with XML tree data in Python","slug":"dealing-with-xml-in-python","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/06/xml@2x.jpg","excerpt":"Make use of Python's native XML library to walk through and extract data.","custom_excerpt":"Make use of Python's native XML library to walk through and extract data.","created_at_pretty":"19 June, 2018","published_at_pretty":"19 June, 2018","updated_at_pretty":"15 November, 2018","created_at":"2018-06-19T17:38:18.000-04:00","published_at":"2018-06-19T18:54:16.000-04:00","updated_at":"2018-11-15T03:28:07.000-05:00","meta_title":"Dealing with XML in Python | Hackers and Slackers","meta_description":"Make use of Python's native XML library to walk through and extract data.","og_description":"Make use of Python's native XML library to walk through and extract data.","og_image":"https://hackersandslackers.com/content/images/2018/06/xml@2x.jpg","og_title":"Dealing with XML in Python","twitter_description":"Make use of Python's native XML library to walk through and extract data.","twitter_image":"https://hackersandslackers.com/content/images/2018/06/xml@2x.jpg","twitter_title":"Dealing with XML in Python","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"Life is filled with things we don't want to do; you're a developer so you\nprobably understand this to a higher degree than most people. Sometimes we waste\nweeks of our lives thanks to an unreasonable and unknowledgeable stakeholder.\nOther times, we need to deal with XML trees.\n\nAt some point or another you're going to need to work with an API that returns\ninformation in XML format. \"Sure,\" we might think, \"I'll just import the\nstandard Python XML package, pick up some syntax nuances, and be on my way.\"\nThat's what I thought too. Today we're going to look at said library, the XML\nElementTree [https://docs.python.org/3/library/xml.etree.elementtree.html] \nlibrary, and see firsthand why this might not be the case.\n\nAs always, the purpose of this is to hopefully save somebody pain. Feel free to\nstash this in your back pocket until XML becomes a problem for you; I'm doing\nthe same.\n\nIt Can't be That Bad\nLet's tackle a few things upfront to save a couple hours of confusion.\n\nFirst off, you know how you've been dot notation to transverse object trees?\nYeah, we can't do that with XML. If we're looking for the child  of a parent, \nparent.child  simply does not work (no, parent['child'] doesn't work either). I\nhope you like looping through trees.\n\nPrint the value of an item in an XML tree doesn’t show you that item's value,\nnor does it show children of that item. It instead prints <Element\n'{http://www.example.com/servicemodel/resources}ItemName' at 0x7fadcf3f83b8>,\nwhich is like a Python equivalent of Javascript's [object Object] in terms of\nusefulness. We can use .text  to see the text value instead of an XML element;.\nGood luck on the other thing, though.\n\nGoing Green\nLet's get this over with and plant some XML trees. I'm going to assume we're\nworking from an API response here.\n\nimport xml.etree.ElementTree as ET\n\ne = ET.fromstring(response.content)\n\n\nIf we were reading an XML file, we'd have to read the file and explicitly search\nfor the root. Even though this doesn’t pertain to us, we should still be aware\nof this inconsistency to avoid future confusion:\n\ne = ET.parse('data.xml')\nroot = e.getroot()\n\n\nWhen we loop through this tree, we 'll need to be mindful of the 3 ways we can\ninteract with XML data. Let's use this tree as an example:\n\n<beer name=\"Bud Light\">\n    <flavor>Water</flavor>\n    <type>Frat</type>\n    <rank>0</rank>\n</beer>\n<beer name=\"PBR\">\n    <flavor>Urine</flavor>\n    <type>Ironic</type>\n    <rank>1</rank>\n</beer>\n<beer name=\"IPA\">\n    <flavor>Pretentious</flavor>\n    <type>Hipster</type>\n    <rank>2</rank>\n</beer>\n\n\n * item.tag  returns the name of the tag. Running this on the first item would\n   return beer, as well as an associated URI.\n * item.attrib()  returns the attributes of the selected item ({'name': 'Bud\n   Light'})\n * item.text  returns the value of text between the open and close tags, if\n   exists.\n\nFinding Stuff\nThere's a few ways to find the data we need in an XML tree, the most obvious of\nwhich would be searching by index. item[0][1]  works, although I have a feeling\nindex-based searching isn't going to be that useful for you.\n\nThe .find and .findall Methods\nOur library has built in .find  and .findall  methods for us to work through a\ntree (returns wither one or all records, as you might have guessed). We search\nby element name as part of a loop:\n\nfor beer in e.findall('beer'):\n    name = beer.get('name') # equivalent to .attrib() in this case\n    flavor = beer.find('flavor').text\n    print(name, \" is \", flavor)\n    \n    \nBud Light is Water    \nPBR is Urine\nIPA is Pretentious\n\n\nThe .iter() Method\nWe can loop through all occurrences of a n element name by using .iter().\n\nfor beertype in e.findall('beer'):\n    print(beertype)\n    \n Frat\n Ironic\n Hipster\n\n\nUsing Some Sort of God-Awful Loop\nIf you're like me you may just skip reading all the documentation altogether,\nget obscenely frustrated, and create some garbage like this:\n\nfor beer in e:\n    for properties in beer:\n          if item.tag == \"{http://www.example.com/beermodel/resources}Type\":\n               print(type)\n                   \nFrat\nIronic\nHipster\n\n\n\nNow that's pretty awful, but I can't tell you had to live your life. You do you.\n\nIn Conclusion\nLook, XML just sucks: don't use it if you don't have to. If you do, save\nyourself some time by coming back to this page.","html":"<p>Life is filled with things we don't want to do; you're a developer so you probably understand this to a higher degree than most people. Sometimes we waste weeks of our lives thanks to an unreasonable and unknowledgeable stakeholder. Other times, we need to deal with XML trees.</p><p>At some point or another you're going to need to work with an API that returns information in XML format. \"Sure,\" we might think, \"I'll just import the standard Python XML package, pick up some syntax nuances, and be on my way.\" That's what I thought too. Today we're going to look at said library, the <a href=\"https://docs.python.org/3/library/xml.etree.elementtree.html\">XML ElementTree</a> library, and see firsthand why this might not be the case.</p><p>As always, the purpose of this is to hopefully save somebody pain. Feel free to stash this in your back pocket until XML becomes a problem for you; I'm doing the same.</p><h2 id=\"it-can-t-be-that-bad\">It Can't be That Bad</h2><p>Let's tackle a few things upfront to save a couple hours of confusion.</p><p>First off, you know how you've been dot notation to transverse object trees? Yeah, we can't do that with XML. If we're looking for the <em>child</em> of a <em>parent</em>, <strong>parent.child</strong> simply does not work (no, parent['child'] doesn't work either). I hope you like looping through trees.</p><p>Print the value of an item in an XML tree doesn’t show you that item's value, nor does it show children of that item. It instead prints <code>&lt;Element '{http://www.example.com/servicemodel/resources}ItemName' at 0x7fadcf3f83b8&gt;</code>, which is like a Python equivalent of Javascript's [object Object] in terms of usefulness. We can use <strong>.text</strong> to see the text value instead of an XML element;. Good luck on the other thing, though.</p><h2 id=\"going-green\">Going Green</h2><p>Let's get this over with and plant some XML trees. I'm going to assume we're working from an API response here.</p><pre><code class=\"language-python\">import xml.etree.ElementTree as ET\n\ne = ET.fromstring(response.content)\n</code></pre>\n<p>If we were reading an XML file, we'd have to read the file and explicitly search for the root. Even though this doesn’t pertain to us, we should still be aware of this inconsistency to avoid future confusion:</p><pre><code class=\"language-python\">e = ET.parse('data.xml')\nroot = e.getroot()\n</code></pre>\n<p>When we loop through this tree, we 'll need to be mindful of the 3 ways we can interact with XML data. Let's use this tree as an example:</p><pre><code class=\"language-xml\">&lt;beer name=&quot;Bud Light&quot;&gt;\n    &lt;flavor&gt;Water&lt;/flavor&gt;\n    &lt;type&gt;Frat&lt;/type&gt;\n    &lt;rank&gt;0&lt;/rank&gt;\n&lt;/beer&gt;\n&lt;beer name=&quot;PBR&quot;&gt;\n    &lt;flavor&gt;Urine&lt;/flavor&gt;\n    &lt;type&gt;Ironic&lt;/type&gt;\n    &lt;rank&gt;1&lt;/rank&gt;\n&lt;/beer&gt;\n&lt;beer name=&quot;IPA&quot;&gt;\n    &lt;flavor&gt;Pretentious&lt;/flavor&gt;\n    &lt;type&gt;Hipster&lt;/type&gt;\n    &lt;rank&gt;2&lt;/rank&gt;\n&lt;/beer&gt;\n</code></pre>\n<ul><li><strong>item.tag</strong> returns the name of the tag. Running this on the first item would return <em>beer</em>, as well as an associated URI.</li><li><strong>item.attrib()</strong> returns the attributes of the selected item (<em>{'name'</em>: <em>'Bud Light'</em>})</li><li><strong>item.text</strong> returns the value of text between the open and close tags, if exists.</li></ul><h2 id=\"finding-stuff\">Finding Stuff</h2><p>There's a few ways to find the data we need in an XML tree, the most obvious of which would be searching by index. <strong>item[0][1]</strong> works, although I have a feeling index-based searching isn't going to be that useful for you.</p><h3 id=\"the-find-and-findall-methods\">The .find and .findall Methods</h3><p>Our library has built in <strong>.find</strong> and <strong>.findall</strong> methods for us to work through a tree (returns wither one or all records, as you might have guessed). We search by element name as part of a loop:</p><pre><code class=\"language-python\">for beer in e.findall('beer'):\n    name = beer.get('name') # equivalent to .attrib() in this case\n    flavor = beer.find('flavor').text\n    print(name, &quot; is &quot;, flavor)\n    \n    \nBud Light is Water    \nPBR is Urine\nIPA is Pretentious\n</code></pre>\n<h3 id=\"the-iter-method\">The .iter() Method</h3><p>We can loop through all occurrences of a n element name by using <strong>.iter()</strong>.</p><pre><code class=\"language-python\">for beertype in e.findall('beer'):\n    print(beertype)\n    \n Frat\n Ironic\n Hipster\n</code></pre>\n<h3 id=\"using-some-sort-of-god-awful-loop\">Using Some Sort of God-Awful Loop</h3><p>If you're like me you may just skip reading all the documentation altogether, get obscenely frustrated, and create some garbage like this:</p><pre><code class=\"language-python\">for beer in e:\n    for properties in beer:\n          if item.tag == &quot;{http://www.example.com/beermodel/resources}Type&quot;:\n               print(type)\n                   \nFrat\nIronic\nHipster\n\n</code></pre>\n<p>Now that's pretty awful, but I can't tell you had to live your life. You do you.</p><h2 id=\"in-conclusion\">In Conclusion</h2><p>Look, XML just sucks: don't use it if you don't have to. If you do, save yourself some time by coming back to this page.</p>","url":"https://hackersandslackers.com/dealing-with-xml-in-python/","uuid":"c28dd935-2162-4d1e-ac2b-4147ee689094","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b2977caded32f5af8fd673e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673678","title":"Using PyMySQL: Python's MySQL Library","slug":"using-pymysql","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/pymysql-1.jpg","excerpt":"The lightweight Python library for interacting with MySQL.","custom_excerpt":"The lightweight Python library for interacting with MySQL.","created_at_pretty":"15 June, 2018","published_at_pretty":"15 June, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-06-14T20:32:21.000-04:00","published_at":"2018-06-15T16:48:12.000-04:00","updated_at":"2019-04-10T00:43:08.000-04:00","meta_title":"Using PyMySQL: Python's MySQL Library | Hackers and Slackers","meta_description":"Learn to work with PyMySQL: the lightweight Python library for interacting with MySQL.","og_description":"Learn to work with PyMySQL: the lightweight Python library for interacting with MySQL.","og_image":"https://hackersandslackers.com/content/images/2019/04/pymysql-1-2.jpg","og_title":"Using PyMySQL: Python's MySQL Library","twitter_description":"Learn to work with PyMySQL: the lightweight Python library for interacting with MySQL.","twitter_image":"https://hackersandslackers.com/content/images/2019/04/pymysql-1-1.jpg","twitter_title":"Using PyMySQL: Python's MySQL Library","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#Working with MySQL","slug":"working-with-mysql","description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysql1_o-1.jpg","meta_description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","meta_title":"Working with MySQL","visibility":"internal"}],"plaintext":"It's almost Friday night, and the squad at H+S is ready to get cooking. Dim down\nthe lights and slip into something more comfortable as we take you on this 100%\norganic flavor extravaganza. Tonight's menu? A Python MySQL library: PyMySQL\n[https://github.com/PyMySQL/PyMySQL].\n\nPyMySQL is lightweight and perfect for fulfilling MySQL queries. If you want\nbells and whistles, you're probably barking up the wrong tree (and you probably\nshould’ve used a DB other than MySQL in the first place).\n\nWhy write tutorials for technologies we openly trash talk? Out of necessity, of\ncourse! There's nothing wrong with MySQL, most enterprises are married to it in\nsome way. Thus, A great use case for PyMySQL is for usage in AWS lambda when\nworking with large enterprise systems. We'll get to that, but for now let's cook\nup something good.\n\nHeat up the Stove\nTurn on the gas and prep the table to set with your favorite collection of\nplates! That's right, we're talking boilerplate. We knew this was coming; it\nseems like every time you want to do something tangibly cool, we need to get\ninto the business of managing connections and whatnot.\n\nTo ease the pain, I'll share with you a preferred method of handling opening\nconnections with PyMySQL. Here we set a function to separate basic connection\nlogic and error messaging from our app:\n\nimport sys\nimport pymysql\nimport logger\n\nconn = None\n\ndef openConnection():\n    global conn\n    try:\n        if(conn is None):\n            conn = pymysql.connect(rds_host, user=name, passwd=password, db=db_name, connect_timeout=5)\n        elif (not conn.open):\n            conn = pymysql.connect(rds_host, user=name, passwd=password, db=db_name, connect_timeout=5)    \n    except:\n        logger.error(\"ERROR: Unexpected error: Could not connect to MySql instance.\")\n        sys.exit()\n\n\n\nNothing fancy here: we set a global variable conn  to serve as our connection,\nand have some basic logic on how to interact with our database. Running \nopenConnection  will attempt to connect to a MySQL db with supplied credentials,\nor throw an error if something goes horribly wrong.\n\nNow we can keep this separate from the rest of our code. Out of sight, out of\nmind.\n\nMeat and Potatoes\nWith the boring stuff out of the way, let's dig into some goodness. We'll start\noff with a basic use case: selecting all rows from a table:\n\ndef getRecords():\n    try:\n        openConnection()\n        with conn.cursor() as cur:\n            sql = \"SELECT * FROM table\"\n            cur.execute(sql)\n            result = cur.fetchall()\n            print(result)\n            cur.close()\n            conn.close()\n    except Exception as e:\n        print(e)\n    finally:\n        print('Query Successful')\n        \ngetRecords() \n\n\nWe split our function into your standard try/except/finally  breakdown. What\nwe're trying is opening a connection using the function we created earlier, and\nrunning queries against it.\n\nThe preferred syntax in PyMySQL is to keep our query in a single string, as seen\nin our variable sql. With our query ready, we need to execute  the query, fetch \nthe resulting records and print the result. We're sure to close the connection\nonce we're done with executing queries... this is critical to ensure db\nconnections don't stay active.\n\nSimple so far, but we're about to kick it up a notch.\n\nSelecting rows\nYou may have noticed we used .fetchall()  to select all records. This is\nimportant to differentiate from .fetchone(), which simply selects the first\nrecord.\n\nWe can iterate over the rows resulting from .fetchall()  with a simple loop, as\nshown in the example below. Beware: attempting to print the result of \n.fetchall()  will simply result in a single integer, which represents the number\nof rows fetched. If there are instances where we know only one record should be\nreturned, .fetchone()  should be used instead.\n\ndef getRecords(table):\n    try:\n        openConnection()\n        with conn.cursor() as cur:\n            sql = \"SELECT * FROM %s\"\n            cur.execute(sql, table)\n            result = cur.fetchall()\n            for row in result:\n                record = {\n                        'id': row[0],\n                        'name': row[1],\n                        'email': row[2],\n                        'phone': row[3],\n\n                    }\n            cur.close()\n            conn.close()\n    except Exception as e:\n        print(e)\n    finally:\n        print('Query Successful')\n        \ngetRecords('table_name')       \n\n\nWhoa, what's with the %s? This is how we pass arguments into queries in PyMySQL.\nThe PyMySQL guys were kind enough to realize how obnoxious it is to constantly\nbreak strings to pass in variables - in the case of SQL queries, this beyond\nobnoxious and borderline unworkable. Remember that MySQL requires explicit\nquotations around passing string values, so queries such as these become a\nnonsensical jumble of escaped characters.\n\nPyMySQL supports backquotes: the distant cousin of the single quotation mark,\nAKA the diagonal quote thing above the tilde ~ button on your keyboard. You\nknow: `. If there comes a time to set a string within your query use this\nelusive quotation as such: sql = \"SELECT * FROM %s WHERE column_name =\n`somevalue`\"Updating Rows of Data\nArguments can be passed as anything inside a query: they simply appear in the\norder in which they are passed. In the below example, we pass table as an\nargument, as well values we want updated, and the identifier for target rows:\n\ndef getRecords(table, data):\n    try:\n        openConnection()\n        with conn.cursor() as cur:\n            sql = \"UPDATE %s SET date=%s, numsent=%s WHERE email = %s\"\n            cur.execute(sql, (table, data['date_sent'], data['status'], data['email']))\n            conn.commit()\n            cur.close()\n            conn.close()\n    except Exception as e:\n        print(e)\n    finally:\n        print('Query Successful')\n\ndata = {\n    'date_sent': '12/01/2018'\n    'email': 'fakeemail@example.com'\n    'status': 'Confirmed'\n}\ngetRecords('table_name', data)       \n\n\nHeads up:  Note the line conn.commit(). Don't forget that - this is what\nactually commits the update to the database. Forgetting this line and wasting\nhours debugging is somewhat of a rite of passage, but let's just skip all that.\n\nFor Dessert: Usage in AWS Lambda\nIt is my treat to share with you my world famous copy & paste recipe for AWS\nLambda. Here we store all of our db credentials in a separate file called \nrdsconfig.py. We also enable logging to take us through what is happening each\nstep of the way:\n\nimport sys\nimport logging\nimport rds_config\nimport pymysql\n\n#rds settings\nrds_host  = \"rdsName.dfsd834mire.us-west-3.rds.amazonaws.com\"\nname = rds_config.db_username\npassword = rds_config.db_password\ndb_name = rds_config.db_name\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\nconn = None\n\ndef openConnection():\n    global conn\n    try:\n        if(conn is None):\n            conn = pymysql.connect(rds_host, user=name, passwd=password, db=db_name, connect_timeout=10)\n        elif (not conn.open):\n            conn = pymysql.connect(rds_host, user=name, passwd=password, db=db_name, connect_timeout=10)\n    except:\n        logger.error(\"ERROR: Could not connect to MySql instance.\")\n        sys.exit()\n\n\nlogger.info(\"SUCCESS: Connection to RDS mysql instance succeeded\")\n\n\nWe thank you all for joining us in this adventure of tantalizing treats. May\nyour data be clean and your stomachs full.\n\nBon appétit.","html":"<p>It's almost Friday night, and the squad at H+S is ready to get cooking. Dim down the lights and slip into something more comfortable as we take you on this 100% organic flavor extravaganza. Tonight's menu? A Python MySQL library: <a href=\"https://github.com/PyMySQL/PyMySQL\">PyMySQL</a>.</p><p>PyMySQL is lightweight and perfect for fulfilling MySQL queries. If you want bells and whistles, you're probably barking up the wrong tree (and you probably should’ve used a DB other than MySQL in the first place).</p><p>Why write tutorials for technologies we openly trash talk? Out of necessity, of course! There's nothing wrong with MySQL, most enterprises are married to it in some way. Thus, A great use case for PyMySQL is for usage in AWS lambda when working with large enterprise systems. We'll get to that, but for now let's cook up something good.</p><h2 id=\"heat-up-the-stove\">Heat up the Stove</h2><p>Turn on the gas and prep the table to set with your favorite collection of plates! That's right, we're talking boilerplate. We knew this was coming; it seems like every time you want to do something tangibly cool, we need to get into the business of managing connections and whatnot.</p><p>To ease the pain, I'll share with you a preferred method of handling opening connections with PyMySQL. Here we set a function to separate basic connection logic and error messaging from our app:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import sys\nimport pymysql\nimport logger\n\nconn = None\n\ndef openConnection():\n    global conn\n    try:\n        if(conn is None):\n            conn = pymysql.connect(rds_host, user=name, passwd=password, db=db_name, connect_timeout=5)\n        elif (not conn.open):\n            conn = pymysql.connect(rds_host, user=name, passwd=password, db=db_name, connect_timeout=5)    \n    except:\n        logger.error(&quot;ERROR: Unexpected error: Could not connect to MySql instance.&quot;)\n        sys.exit()\n\n</code></pre>\n<!--kg-card-end: markdown--><p>Nothing fancy here: we set a global variable <em>conn</em> to serve as our connection, and have some basic logic on how to interact with our database. Running <em>openConnection</em> will attempt to connect to a MySQL db with supplied credentials, or throw an error if something goes horribly wrong.</p><p>Now we can keep this separate from the rest of our code. Out of sight, out of mind.</p><h2 id=\"meat-and-potatoes\">Meat and Potatoes</h2><p>With the boring stuff out of the way, let's dig into some goodness. We'll start off with a basic use case: selecting all rows from a table:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">def getRecords():\n    try:\n        openConnection()\n        with conn.cursor() as cur:\n            sql = &quot;SELECT * FROM table&quot;\n            cur.execute(sql)\n            result = cur.fetchall()\n            print(result)\n            cur.close()\n            conn.close()\n    except Exception as e:\n        print(e)\n    finally:\n        print('Query Successful')\n        \ngetRecords() \n</code></pre>\n<!--kg-card-end: markdown--><p>We split our function into your standard <em>try/except/finally</em> breakdown. What we're trying is opening a connection using the function we created earlier, and running queries against it.</p><p>The preferred syntax in PyMySQL is to keep our query in a single string, as seen in our variable <em>sql</em>. With our query ready, we need to <em>execute</em> the query, <em>fetch</em> the resulting records and print the result. We're sure to close the connection once we're done with executing queries... this is critical to ensure db connections don't stay active.</p><p>Simple so far, but we're about to kick it up a notch.</p><h3 id=\"selecting-rows\">Selecting rows</h3><p>You may have noticed we used <em>.fetchall()</em> to select all records. This is important to differentiate from <em>.fetchone()</em>, which simply selects the first record.</p><p>We can iterate over the rows resulting from <em>.fetchall()</em> with a simple loop, as shown in the example below. Beware: attempting to print the result of <em>.fetchall()</em> will simply result in a single integer, which represents the number of rows fetched. If there are instances where we know only one record should be returned, <em>.fetchone()</em> should be used instead.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">def getRecords(table):\n    try:\n        openConnection()\n        with conn.cursor() as cur:\n            sql = &quot;SELECT * FROM %s&quot;\n            cur.execute(sql, table)\n            result = cur.fetchall()\n            for row in result:\n                record = {\n                        'id': row[0],\n                        'name': row[1],\n                        'email': row[2],\n                        'phone': row[3],\n\n                    }\n            cur.close()\n            conn.close()\n    except Exception as e:\n        print(e)\n    finally:\n        print('Query Successful')\n        \ngetRecords('table_name')       \n</code></pre>\n<!--kg-card-end: markdown--><p>Whoa, what's with the <em><strong>%s</strong></em>? This is how we pass arguments into queries in PyMySQL. The PyMySQL guys were kind enough to realize how obnoxious it is to constantly break strings to pass in variables - in the case of SQL queries, this beyond obnoxious and borderline unworkable. Remember that MySQL requires explicit quotations around passing string values, so queries such as these become a nonsensical jumble of escaped characters.</p><!--kg-card-begin: html--><div class=\"protip\">\nPyMySQL supports backquotes: the distant cousin of the single quotation mark, AKA the diagonal quote thing above the tilde ~ button on your keyboard. You know: `. If there comes a time to set a string within your query use this elusive quotation as such: <code>sql = \"SELECT * FROM %s WHERE column_name = `somevalue`\"</code>\n</div><!--kg-card-end: html--><h3 id=\"updating-rows-of-data\">Updating Rows of Data</h3><p>Arguments can be passed as anything inside a query: they simply appear in the order in which they are passed. In the below example, we pass table as an argument, as well values we want updated, and the identifier for target rows:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">def getRecords(table, data):\n    try:\n        openConnection()\n        with conn.cursor() as cur:\n            sql = &quot;UPDATE %s SET date=%s, numsent=%s WHERE email = %s&quot;\n            cur.execute(sql, (table, data['date_sent'], data['status'], data['email']))\n            conn.commit()\n            cur.close()\n            conn.close()\n    except Exception as e:\n        print(e)\n    finally:\n        print('Query Successful')\n\ndata = {\n    'date_sent': '12/01/2018'\n    'email': 'fakeemail@example.com'\n    'status': 'Confirmed'\n}\ngetRecords('table_name', data)       \n</code></pre>\n<!--kg-card-end: markdown--><p><strong>Heads up:</strong> Note the line <em>conn.commit()</em>. Don't forget that - this is what actually commits the update to the database. Forgetting this line and wasting hours debugging is somewhat of a rite of passage, but let's just skip all that.</p><h2 id=\"for-dessert-usage-in-aws-lambda\">For Dessert: Usage in AWS Lambda</h2><p>It is my treat to share with you my world famous copy &amp; paste recipe for AWS Lambda. Here we store all of our db credentials in a separate file called <em>rdsconfig.py</em>. We also enable logging to take us through what is happening each step of the way:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import sys\nimport logging\nimport rds_config\nimport pymysql\n\n#rds settings\nrds_host  = &quot;rdsName.dfsd834mire.us-west-3.rds.amazonaws.com&quot;\nname = rds_config.db_username\npassword = rds_config.db_password\ndb_name = rds_config.db_name\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\nconn = None\n\ndef openConnection():\n    global conn\n    try:\n        if(conn is None):\n            conn = pymysql.connect(rds_host, user=name, passwd=password, db=db_name, connect_timeout=10)\n        elif (not conn.open):\n            conn = pymysql.connect(rds_host, user=name, passwd=password, db=db_name, connect_timeout=10)\n    except:\n        logger.error(&quot;ERROR: Could not connect to MySql instance.&quot;)\n        sys.exit()\n\n\nlogger.info(&quot;SUCCESS: Connection to RDS mysql instance succeeded&quot;)\n</code></pre>\n<!--kg-card-end: markdown--><p>We thank you all for joining us in this adventure of tantalizing treats. May your data be clean and your stomachs full.</p><p>Bon appétit.</p>","url":"https://hackersandslackers.com/using-pymysql/","uuid":"cd6baf62-981c-4034-ba29-b67d257acbeb","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b230915f37f772d33bc1eb1"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673660","title":"Using Gulp: Tasks to Make Frontend Tolerable","slug":"using-gulp-to-make-frontend-tolerable","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/gulp-1.jpg","excerpt":"Optimize your frontend code with Gulp: the task runner to make you production-ready.","custom_excerpt":"Optimize your frontend code with Gulp: the task runner to make you production-ready.","created_at_pretty":"30 May, 2018","published_at_pretty":"30 May, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-05-29T23:28:01.000-04:00","published_at":"2018-05-30T12:40:20.000-04:00","updated_at":"2019-03-28T05:58:57.000-04:00","meta_title":"Using Gulp to Make Frontend Tolerable | Hackers and Slackers","meta_description":"Automate tasks for production deployment such as compiling your CSS and JS","og_description":"Optimize your frontend code with Gulp: the task runner to make you production-ready.","og_image":"https://hackersandslackers.com/content/images/2019/03/gulp-1.jpg","og_title":"Using Gulp to Make Frontend Tolerable","twitter_description":"Automate the lame stuff","twitter_image":"https://hackersandslackers.com/content/images/2019/03/gulp-1.jpg","twitter_title":"Using Gulp to Make Frontend Tolerable","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},{"name":"ExpressJS","slug":"expressjs","description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch as a simplistic Express app can evolve into a beautiful monstrosity.","feature_image":null,"meta_description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch a simplistic Express app can evolve into a beautiful monstrosity.","meta_title":"ExpressJS Framework | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"NOTE:  This tutorial was written for Gulp versions <4.0.0. Check out this post\n[https://hackersandslackers.com/upgrading-to-gulp-4/]  for Gulp >4.0.0\n\n\n--------------------------------------------------------------------------------\n\nPerhaps the whole obligatory-Gulp-tutorial on [Some Coding Blog] thing has\nbecome a bit cliché at this point. Haters may do as they will, but I 'll take\nany opportunity to jam as many SEO keywords I can get at this point. You know\nthe ones: Gulp, ExpressJS, NodeJS, or perhaps even React Vue frontend Ubuntu\nframework API social cloud data entrepreneur community. \n\nRegardless, we all need our own copy+paste references from time-to-time, or even\nworse: when we copy/paste our gulpfile.js from project to project and forget\nwhat they actually do. I won't tell anybody.\n\nQuick 101\nNodeJS developers use Gulp to automate necessary processes before moving their\nfrontend code to production. This includes minifying files to make them run\nfaster, and to also make them unreadable to people who would otherwise make fun\nof your mediocre Javascript which you were forced to crank out on a short\ntimeline.\n\nGeneral Workflow\nLet's say you're running a basic Express app. As opposed to developing and\nstoring files in a directory such as /public, Gulp enables us to develop in one\ndirectory, and compile to another. That means we can keep our horrible\nuncompressed and uncompiled  source in a folder such as /src, and output them to\na directory such as /dist, which would be our public-facing output. An Express\nfile structure utilizing this would look something like this:\n\n  |- src/\n      |- js/ \n      |- scss/\n  |- dist/\n      |- js/ \n      |- css/\n      |- img/\n      |- fonts/\n  |- views\n      |- index.hbs\n  |- routes\n      |- index.js\n  |- gulpfile.js\n  |- node_modules/\n  |- package.json\n  |- app.js\n\n\nInstallation\nFirst install the gulp CLI:\n\nnpm install --global gulp-cli\n\n\nNext, enter your project folder and install gulp while saving it as  a project\ndependency.\n\nnpm install --save gulp\n\n\nHow it Works\nGulp doesn't do much on its own; the true magic lies within its vast library of\nplugins. Each individual plugin typically covers a simple task, such as\ncompiling LESS or SASS files, or minifying client-side JavaScript and CSS. The\nlimited scope of plugins entails a bit of setup in our gulpfile to chain said\ntasks together, but it also makes Gulp highly customizable to cater to your\nspecific needs.\n\nThe Gulpfile\nGulp works by invoking a file called gulpfile.js in your main directory, which\nyou'll need to create and set up yourself (sorry). The file is divided into two\nmain parts: requiring (importing) plugins, and defining which tasks to run when\ngulp is invoked. A basic worthless gulpfile might look something like:\n\nvar gulp = require('gulp');\n\ngulp.task('default', function () {\n  console.log('Sup World!');\n});\n\n\nTo make this file useful, we'll need to install more plugins and set up tasks\nfor them.\n\nEssential Plugins\nLet's look at what each one does. Keep in mind there are thousands of Gulp\nplugins, so let's just touch on the big hitters here.\n\nKeep in mind to install any of these plugins, you'll simply need to run the npm\ninstallation in your project directory:\n\nnpm install --save [plugin name]\n\n\ngulp-uglify\nMinifies Javascript or CSS files, and outputs the result into the directory of\nyour choice. This plugin can be reused across filetypes, as we'll demonstrate in\na moment.\n\ngulp-concat\nCombines minified files into a single file. This is essential for browser\nperformance as it reduces the number of http requests being made every time your\npage loads.\n\ngulp-rename\nRenames files (such as those produced by gulp-concat).\n\ngulp-sass / gulp-less\nCompiles your Sass or Less files into CSS and outputs to the directory of your\nchoice.\n\ngulp-minify-css\nMinifies CSS, as you might imagine. This can chained to gulp-sass or gulp-less\nto minify the CSS files those tasks produce.\n\ngulp-autoprefixer\nThank god for this. Autoprefixer finds CSS styles and adds the browser-specific\nequivalents to your CSS, so you don't need to write the same style 10 times for\nevery horrible browser in existence. This means you can write styles such as:\n\nbackground: linear-gradient(to bottom, white, black);\n\n\nAnd have them output as:\n\nbackground: -webkit-gradient(linear, left top, left bottom, from(white), to(black));\nbackground: -webkit-linear-gradient(top, white, black);\nbackground: -o-linear-gradient(top, white, black);\nbackground: linear-gradient(to bottom, white, black);\n\n\ngulp-watch\nAllows Gulp to listen for changes being made to source files, so that it may\nfire an event upon file change, such as:\n\ngulp-livereload\nCompiles the changes made in directories being watched via gulp-watch\nautomatically while you work.\n\nNext Level Pro Shit\nWhile these plugins aren't 'essential', they are really cool and helpful.\n\ngulp-sourcemaps\nAn obnoxious side effect of minifying and concating your files is when it comes\ntime to debug errors on the frontend. Errors occurring at \"line 235\" are pretty\nuseless considering your error codes are referring to the compiled files,\nwithout granting a hint as to where the problematic code may have come from in\nthe first place. gulp-sourcemaps resolves this by adding commenting paths to\nwhich source files your code originated from.\n\ngulp-browser-sync\nBy leveraging BrowserSync [https://browsersync.io/], this plugin immediately\nrefreshes an open browser which links to files just changed by gulp. This means\nyou can code, compile, and see the results in real time. This takes a bit extra\neffort to set up, so be sure to check their documentation\n[https://browsersync.io/docs].\n\ngulp-load-plugins\nNormally when creating our gulpfile, we need to start off by requiring our\nplugins via something like this:\n\nvar gulp = require('gulp'),\n    del = require('del'),\n    concat = require('gulp-concat'),\n    rename = require('gulp-rename'),\n    uglify = require('gulp-uglify'),\n    sass = require('gulp-sass'),\n    watch = require('gulp-watch'),\n    livereload = require('gulp-livereload'),\n    minifyCss = require('gulp-minify-css'),\n    autoprefixer = require('gulp-autoprefixer');\n\n\ngulp-load-plugins  instead checks your package.json for any Gulp plugins and\nimmediately requires them, thus saving you a few precious minutes. The output\ninstead looks like:\n\nvar $ = require('gulp-load-plugins')();\n\n\nBuilding The Gulpfile\nNow that we have all these dope plugins, we can finally build our gulpfile.\nHere's an example (without using gulp-load-plugins  for now):\n\nvar gulp = require('gulp'),\n    del = require('del'),\n    concat = require('gulp-concat'),\n    rename = require('gulp-rename'),\n    uglify = require('gulp-uglify'),\n    sass = require('gulp-sass'),\n    watch = require('gulp-watch'),\n    livereload = require('gulp-livereload'),\n    minifyCss = require('gulp-minify-css'),\n    autoprefixer = require('gulp-autoprefixer');\n\ngulp.task('styles', function() {\n    return gulp.src('src/sass/*.scss')\n        .pipe(sass({outputStyle: 'expanded', unix_newlines: true, linefeed: \"lf\"}).on('error', sass.logError))\n        .pipe(autoprefixer())\n        .pipe(minifyCss({\n            keepSpecialComments: 1\n        }))\n        .pipe(rename(\"theme.min.css\"))\n        .pipe(gulp.dest('./assets/css/'));\n});\n\n\ngulp.task('scripts', function() {\n    return gulp.src(['src/js/plugin/*.js', 'src/js/base.js'])\n        .pipe(uglify())\n        .pipe(concat('theme.min.js'))\n        .pipe(gulp.dest('assets/js'));\n});\n\n\ngulp.task('ghost_config', ['scripts'], function() {\n    return gulp.src(['src/js/config.js', 'assets/js/theme.min.js'])\n        .pipe(concat('theme.min.js'))\n        .pipe(gulp.dest('assets/js'));\n});\n\n\ngulp.task('default', function() {\n    gulp.start('styles', 'scripts', 'ghost_config', 'watch');\n});\n\n\ngulp.task('watch', function() {\n    gulp.watch('src/sass/*.scss', ['styles']);\n    gulp.watch('src/js/*.js', ['scripts', 'ghost_config']);\n    livereload.listen();\n    gulp.watch(['*']).on('change', livereload.changed);\n});\n\n\n\nJust by looking at the file itself, you may be able to dissect what's happening.\nAfter we require our plugins, we define our tasks,  which are essentially\nindividual jobs consisting of one or more gulp plugins depending on how you've\nchained them.\n\nHere's the general terminology to help clear things up:\n\n * gulp.task: Defines a task consisting of one of more plugin actions.\n * gulp.src:  Specifies the folder containing source files.\n * gulp.dest: Defines the folder to output compiled files to.\n * pipe(): Allows multiple events to be chained together in a single task.\n\nWrapping up\nOnce your file is ready to go, simply run the grunt  command in your project\ndirectory. You should see Gulp output the status of each task you've set, as\nwell as any errors which may have occurred.\n\nIn short, just use Gulp. The scientific community has come to a consensus that\nGulp is objectively superior to its counterpart, Grunt. Ask Matt, he's a\nscientist.\n\nPeace fam!","html":"<p><em><strong>NOTE</strong>:  This tutorial was written for Gulp versions &lt;4.0.0. Check out <a href=\"https://hackersandslackers.com/upgrading-to-gulp-4/\">this post</a> for Gulp &gt;4.0.0</em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Perhaps the whole obligatory-Gulp-tutorial on [Some Coding Blog] thing has become a bit cliché at this point. Haters may do as they will, but I 'll take any opportunity to jam as many SEO keywords I can get at this point. You know the ones: Gulp, ExpressJS, NodeJS, or perhaps even React Vue frontend Ubuntu framework API social cloud data entrepreneur community. </p><p>Regardless, we all need our own copy+paste references from time-to-time, or even worse: when we copy/paste our gulpfile.js from project to project and forget what they actually do. I won't tell anybody.</p><h2 id=\"quick-101\">Quick 101</h2><p>NodeJS developers use Gulp to automate necessary processes before moving their frontend code to production. This includes minifying files to make them run faster, and to also make them unreadable to people who would otherwise make fun of your mediocre Javascript which you were forced to crank out on a short timeline.</p><h3 id=\"general-workflow\">General Workflow</h3><p>Let's say you're running a basic Express app. As opposed to developing and storing files in a directory such as /public, Gulp enables us to develop in one directory, and compile to another. That means we can keep our horrible uncompressed and uncompiled  source in a folder such as /src, and output them to a directory such as /dist, which would be our public-facing output. An Express file structure utilizing this would look something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">  |- src/\n      |- js/ \n      |- scss/\n  |- dist/\n      |- js/ \n      |- css/\n      |- img/\n      |- fonts/\n  |- views\n      |- index.hbs\n  |- routes\n      |- index.js\n  |- gulpfile.js\n  |- node_modules/\n  |- package.json\n  |- app.js\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"installation\">Installation</h3><p>First install the gulp CLI:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">npm install --global gulp-cli\n</code></pre>\n<!--kg-card-end: markdown--><p>Next, enter your project folder and install gulp while saving it as  a project dependency.</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">npm install --save gulp\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"how-it-works\">How it Works</h2><p>Gulp doesn't do much on its own; the true magic lies within its vast library of plugins. Each individual plugin typically covers a simple task, such as compiling LESS or SASS files, or minifying client-side JavaScript and CSS. The limited scope of plugins entails a bit of setup in our gulpfile to chain said tasks together, but it also makes Gulp highly customizable to cater to your specific needs.</p><h3 id=\"the-gulpfile\">The Gulpfile</h3><p>Gulp works by invoking a file called gulpfile.js in your main directory, which you'll need to create and set up yourself (sorry). The file is divided into two main parts: requiring (importing) plugins, and defining which tasks to run when gulp is invoked. A basic worthless gulpfile might look something like:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">var gulp = require('gulp');\n\ngulp.task('default', function () {\n  console.log('Sup World!');\n});\n</code></pre>\n<!--kg-card-end: markdown--><p>To make this file useful, we'll need to install more plugins and set up tasks for them.</p><h2 id=\"essential-plugins\">Essential Plugins</h2><p>Let's look at what each one does. Keep in mind there are thousands of Gulp plugins, so let's just touch on the big hitters here.</p><p>Keep in mind to install any of these plugins, you'll simply need to run the npm installation in your project directory:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">npm install --save [plugin name]\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"gulp-uglify\">gulp-uglify</h3><p>Minifies Javascript or CSS files, and outputs the result into the directory of your choice. This plugin can be reused across filetypes, as we'll demonstrate in a moment.</p><h3 id=\"gulp-concat\">gulp-concat</h3><p>Combines minified files into a single file. This is essential for browser performance as it reduces the number of http requests being made every time your page loads.</p><h3 id=\"gulp-rename\">gulp-rename</h3><p>Renames files (such as those produced by gulp-concat).</p><h3 id=\"gulp-sass-gulp-less\">gulp-sass / gulp-less</h3><p>Compiles your Sass or Less files into CSS and outputs to the directory of your choice.</p><h3 id=\"gulp-minify-css\">gulp-minify-css</h3><p>Minifies CSS, as you might imagine. This can chained to gulp-sass or gulp-less to minify the CSS files those tasks produce.</p><h3 id=\"gulp-autoprefixer\">gulp-autoprefixer</h3><p>Thank god for this. Autoprefixer finds CSS styles and adds the browser-specific equivalents to your CSS, so you don't need to write the same style 10 times for every horrible browser in existence. This means you can write styles such as:</p><!--kg-card-begin: markdown--><pre><code class=\"language-css\">background: linear-gradient(to bottom, white, black);\n</code></pre>\n<!--kg-card-end: markdown--><p>And have them output as:</p><!--kg-card-begin: markdown--><pre><code class=\"language-css\">background: -webkit-gradient(linear, left top, left bottom, from(white), to(black));\nbackground: -webkit-linear-gradient(top, white, black);\nbackground: -o-linear-gradient(top, white, black);\nbackground: linear-gradient(to bottom, white, black);\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"gulp-watch\">gulp-watch</h3><p>Allows Gulp to listen for changes being made to source files, so that it may fire an event upon file change, such as:</p><h3 id=\"gulp-livereload\">gulp-livereload</h3><p>Compiles the changes made in directories being watched via gulp-watch automatically while you work.</p><h2 id=\"next-level-pro-shit\">Next Level Pro Shit</h2><p>While these plugins aren't 'essential', they are really cool and helpful.</p><h3 id=\"gulp-sourcemaps\">gulp-sourcemaps</h3><p>An obnoxious side effect of minifying and concating your files is when it comes time to debug errors on the frontend. Errors occurring at \"line 235\" are pretty useless considering your error codes are referring to the compiled files, without granting a hint as to where the problematic code may have come from in the first place. gulp-sourcemaps resolves this by adding commenting paths to which source files your code originated from.</p><h3 id=\"gulp-browser-sync\">gulp-browser-sync</h3><p>By leveraging <a href=\"https://browsersync.io/\">BrowserSync</a>, this plugin immediately refreshes an open browser which links to files just changed by gulp. This means you can code, compile, and see the results in real time. This takes a bit extra effort to set up, so be sure to check their <a href=\"https://browsersync.io/docs\">documentation</a>.</p><h3 id=\"gulp-load-plugins\">gulp-load-plugins</h3><p>Normally when creating our gulpfile, we need to start off by requiring our plugins via something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">var gulp = require('gulp'),\n    del = require('del'),\n    concat = require('gulp-concat'),\n    rename = require('gulp-rename'),\n    uglify = require('gulp-uglify'),\n    sass = require('gulp-sass'),\n    watch = require('gulp-watch'),\n    livereload = require('gulp-livereload'),\n    minifyCss = require('gulp-minify-css'),\n    autoprefixer = require('gulp-autoprefixer');\n</code></pre>\n<!--kg-card-end: markdown--><p><strong>gulp-load-plugins</strong> instead checks your package.json for any Gulp plugins and immediately requires them, thus saving you a few precious minutes. The output instead looks like:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">var $ = require('gulp-load-plugins')();\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"building-the-gulpfile\">Building The Gulpfile</h2><p>Now that we have all these dope plugins, we can finally build our gulpfile. Here's an example (without using <strong>gulp-load-plugins</strong> for now):</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">var gulp = require('gulp'),\n    del = require('del'),\n    concat = require('gulp-concat'),\n    rename = require('gulp-rename'),\n    uglify = require('gulp-uglify'),\n    sass = require('gulp-sass'),\n    watch = require('gulp-watch'),\n    livereload = require('gulp-livereload'),\n    minifyCss = require('gulp-minify-css'),\n    autoprefixer = require('gulp-autoprefixer');\n\ngulp.task('styles', function() {\n    return gulp.src('src/sass/*.scss')\n        .pipe(sass({outputStyle: 'expanded', unix_newlines: true, linefeed: &quot;lf&quot;}).on('error', sass.logError))\n        .pipe(autoprefixer())\n        .pipe(minifyCss({\n            keepSpecialComments: 1\n        }))\n        .pipe(rename(&quot;theme.min.css&quot;))\n        .pipe(gulp.dest('./assets/css/'));\n});\n\n\ngulp.task('scripts', function() {\n    return gulp.src(['src/js/plugin/*.js', 'src/js/base.js'])\n        .pipe(uglify())\n        .pipe(concat('theme.min.js'))\n        .pipe(gulp.dest('assets/js'));\n});\n\n\ngulp.task('ghost_config', ['scripts'], function() {\n    return gulp.src(['src/js/config.js', 'assets/js/theme.min.js'])\n        .pipe(concat('theme.min.js'))\n        .pipe(gulp.dest('assets/js'));\n});\n\n\ngulp.task('default', function() {\n    gulp.start('styles', 'scripts', 'ghost_config', 'watch');\n});\n\n\ngulp.task('watch', function() {\n    gulp.watch('src/sass/*.scss', ['styles']);\n    gulp.watch('src/js/*.js', ['scripts', 'ghost_config']);\n    livereload.listen();\n    gulp.watch(['*']).on('change', livereload.changed);\n});\n\n</code></pre>\n<!--kg-card-end: markdown--><p>Just by looking at the file itself, you may be able to dissect what's happening. After we require our plugins, we define our <em>tasks,</em> which are essentially individual jobs consisting of one or more gulp plugins depending on how you've chained them.</p><p>Here's the general terminology to help clear things up:</p><ul><li><strong>gulp.task</strong>: Defines a task consisting of one of more plugin actions.</li><li><strong>gulp.src</strong>:  Specifies the folder containing source files.</li><li><strong>gulp.dest</strong>: Defines the folder to output compiled files to.</li><li><strong>pipe()</strong>: Allows multiple events to be chained together in a single task.</li></ul><h2 id=\"wrapping-up\">Wrapping up</h2><p>Once your file is ready to go, simply run the <strong>grunt</strong> command in your project directory. You should see Gulp output the status of each task you've set, as well as any errors which may have occurred.</p><p>In short, just use Gulp. The scientific community has come to a consensus that Gulp is objectively superior to its counterpart, Grunt. Ask Matt, he's a scientist.</p><p>Peace fam!</p>","url":"https://hackersandslackers.com/using-gulp-to-make-frontend-tolerable/","uuid":"f0ec0903-cd67-4663-b872-9ecdf9ffc557","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b0e1a41e88ecf2fbeb3f5fa"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867365d","title":"JIRA Analysis in Tableau","slug":"jira-analysis-in-tableau","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/05/tableau3@2x.jpg","excerpt":"Utilizing Tableau Desktop to visualize data pulled from JIRA.","custom_excerpt":"Utilizing Tableau Desktop to visualize data pulled from JIRA.","created_at_pretty":"27 May, 2018","published_at_pretty":"27 May, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-05-27T13:16:31.000-04:00","published_at":"2018-05-27T17:38:37.000-04:00","updated_at":"2019-03-28T05:50:40.000-04:00","meta_title":"JIRA Analysis in Tableau | Hackers and Slackers","meta_description":"Utilizing Tableau Desktop to visualize data pulled from JIRA","og_description":"Utilizing Tableau Desktop to visualize data pulled from JIRA","og_image":"https://hackersandslackers.com/content/images/2018/05/tableau3@2x.jpg","og_title":"JIRA Analysis in Tableau","twitter_description":"Utilizing Tableau Desktop to visualize data pulled from JIRA","twitter_image":"https://hackersandslackers.com/content/images/2018/05/tableau3@2x.jpg","twitter_title":"JIRA Analysis in Tableau","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"}],"plaintext":"Greetings to all my feathered friends upon this fine Memorial Day weekend.\nSeeing as how you're here, it appears as though we have a lot in common. Namely,\nwe've chosen to spend our three-day weekends on the internet, as opposed to\noutside.\n\nI've been meaning to build a  widget for this very blog for quite some time now.\nThe vision is to embed a custom Kanban board, which would pull issues from our\nprivate JIRA instance to be publicly displayed and formatted to our liking. To\nmy knowledge, nobody has bothered to attempt building something like this yet;\nprobably for good reason. There are a few gotchas off the bat: for one, JIRA\ncloud's REST API has introduced a \"bug\" which disallows cross-domain calls.\nFine.\n\nMy frustration with propriety software has come down to this: we're going to use\ntwo highly-protected closed source behemoth products against one another. Here's\nthe plan:\n\n * Pull JIRA issues into Tableau\n * Format the data in a worksheet\n * Output our data to a MongoDB database\n * Build a Kanban widget to display these issues\n * Hack the shit out of both JIRA and Tableau to make this process automated\n\nIf this seems like a convoluted way of achieving a small goal, it absolutely is\n- the goal is just as much to become familiar with these systems as is the end\nprize. There's a lot going on here, so for part 1 let's do a dry run of getting\nour issues from JIRA to MongoDB.\n\nThe Extraction\nPulling all issues from JIRA would normally be a simple API call, but in the\nspirit of learning new things we'll try out JIRA's Tableau connector\n[https://marketplace.atlassian.com/apps/1214641/all-in-one-tableau-connector-for-jira]\n. This essentially enables an endpoint specifically for Tableau to pull JIRA\ndata from. After installing the JIRA add-on, we'll be able to produce a URL for\nTableau to consume via the Web Data Connector source:\n\nThe connector allows us to select the data we're looking to pull from JIRA\nupfront. Keep our scope in mind: we're looking to simply display a \"card\" (think\nTrello for all you noobs out there) per issue, so we're only concerned with the\ninformation we'd need to build that. I've boiled this down to:\n\n * Key\n * Issue Type\n * Summary\n * Description\n * Status\n * Creator\n * Priority\n * Epic link\n * Epic Name\n * Epic Color\n\nThe field selection screen when setting up our connector.Work That Sheet\nWith our data imported, create a new worksheet. If you've used Tableau before\nyou're probably very aware of the default column limit on Worksheets. Before we\ndo anything, go to Analysis  > Table Layout  > Advanced  to increase the max\ncolumns from 6 to whatever, let's say 12.\n\nWARING: super sick advanced Tableau hacks incoming.Drag your data into the\n\"rows\" shelf to get something like this:\n\nOur first look at the data.There are a few problems here we need to clean up.\nFirst, take a look at the \"Epic Color\" column.\n\nEyes as Blue as ghx-label-7\nFor some reason, JIRA finds it appropriate to label its colors this cryptic\n code of ghx-label-#. Go ahead and add this to the long list of shitty decisions\nAtlassian has chosen to pursue.\n\nKeeping our goal in mind, we need \"epic colors\" to add some style and flavor to\nour board. Could we make the board without this? Probably, if you're a quitter.\nI'm going to save you some time here. I went ahead and inspected the epic\nelements in my JIRA instance to extract their hex values. Create a new\ncalculated field and add this query to manually map the label nonsense to actual\nvalues:\n\nIF [Epic Colour] = \"ghx-label-1\"\nTHEN \"#42526E\"\nELSEIF [Epic Colour] = \"ghx-label-2\"\nTHEN \"#FFC400\"\nELSEIF [Epic Colour] = \"ghx-label-3\"\nTHEN \"#FFE380\"\nELSEIF [Epic Colour] = \"ghx-label-4\"\nTHEN \"#4C9AFF\"\nELSEIF [Epic Colour] = \"ghx-label-5\"\nTHEN \"#00C7E6\"\nELSEIF [Epic Colour] = \"ghx-label-6\"\nTHEN \"#79F2C0\"\nELSEIF [Epic Colour] = \"ghx-label-7\"\nTHEN \"#C0B6F2\"\nELSEIF [Epic Colour] = \"ghx-label-8\"\nTHEN \"#998DD9\"\nELSEIF [Epic Colour] = \"ghx-label-9\"\nTHEN \"#FFBDAD\"\nELSEIF [Epic Colour] = \"ghx-label-10\"\nTHEN \"#B3D4FF\"\nELSEIF [Epic Colour] = \"ghx-label-11\"\nTHEN \"#79E2F2\"\nELSEIF [Epic Colour] = \"ghx-label-12\"\nTHEN \"#EBECF0\"\nELSEIF [Epic Colour] = \"ghx-label-13\"\nTHEN \"#57D9A3\"\nELSEIF [Epic Colour] = \"ghx-label-14\"\nTHEN \"#FF8F73\"\nELSEIF [Epic Colour] = \"ghx-label-15\"\nTHEN \"#57D9A3\"\nELSEIF [Epic Colour] = \"ghx-label-16\"\nTHEN \"#57D9A3\"\nELSEIF [Epic Colour] = \"ghx-label-17\"\nTHEN \"#57D9A3\"\nEND\n\nReplace the \"Epic Color\" field with this new calculated field to reveal our next\nproblem.\n\nEpic Lynx\nIf you check out our sheet now, we'll see the proper colors values come through,\nbut they will only be appearing for what seems to be one issue per \"Epic\" in our\nsheet:\n\nFeel free to moan and groan a bit while we realize what's happening. We're\nlooking at a list of issues  here, where epics  are themselves to be considered\nan issue. Therefore, only issues which are epics will have colors: issues which\nare linked  to said epics, however, will not. This is annoying. It took me a bit\nto come up with the following solution, although I'd be curious to hear if\nanybody has a better way of doing this.\n\nGo ahead and create a new worksheet. Add Epic Link  and Epic Color  to the\nsheet, and filter out the null values:\n\nCreating a table to perform a SQL-like JOINSo here's the game plan. Stay with me\non this one: we're going to use this sheet as a new source to perform a join \nwith our original data. Once we join on Epic Link, every issue containing an\nepic link will have the parent color as a field as well.\n\nExport this data as a CSV. Go back to Data Sources, open a new data source, and\nselect the CSV we just created. Create an inner merge and associate by epic\nlink:\n\nCreating JOINs via a UI!Now we're getting somewhere. Go back to the original\nsheet and drag the color field from the new data source on to the shelf:\n\nThe result.Pro move. Calculated.\n\nMondo Bongo\nYou'll notice I switched the order of our rows around to have \"Issue key\" as the\nfirst column. Originally I made the mistake of not doing this, only to realize\nthat Tableau will not export merged cells into a CSV. We need to order our\ncolumns starting with the most unique first to avoid any cell merging.\n\nExport that bad boy.\n\nThis is where we'll import our data into MongoDB. How dope is MongoDB, you ask?\nWell, one feature is the ability to import a CSV into an empty database to\nautomatically create the resulting schema and populate it with your values.\nYeah, it's that sick.\n\nI won't turn this into a MongoDB tutorial. Setting up a MongoDB Atlas cluster is\nsomewhat straightforward, and we can use the MongoDB Compass  client to simply\nimport the CSV we created.\n\nWhat Next?\nAs mentioned, our first take at this is going to be a dry run of building this\nwidget with our initial data import. We'll be building this widget in an\nExpressJS app, so next we'll focus on how to connect our app to MongoDB and\nextract this data.\n\nAfter that, we'll need to find a way to automate this process moving forward.\nFull disclosure: Tableau most definitely will not play nice with this, and I'm\niffy on how possible this is. All I know is I've got a Tableau Server instance\nup and running, and I paid good money for it. Therefore, it is my right to break\nit.\n\nI hope at least one or two people have found this to be helpful or interesting\nthus far. Again, I realize this process is a completely roundabout way of\naccomplishing this task... this is mostly a way for us to learn the ins-and-outs\nof these systems. Perhaps we might even build something special. Just think: if\nwe manage to close the loop on this system, we can leverage a GUI to create apps\nnearly as fast as we can imagine them.","html":"<p>Greetings to all my feathered friends upon this fine Memorial Day weekend. Seeing as how you're here, it appears as though we have a lot in common. Namely, we've chosen to spend our three-day weekends on the internet, as opposed to outside.</p><p>I've been meaning to build a  widget for this very blog for quite some time now. The vision is to embed a custom Kanban board, which would pull issues from our private JIRA instance to be publicly displayed and formatted to our liking. To my knowledge, nobody has bothered to attempt building something like this yet; probably for good reason. There are a few gotchas off the bat: for one, JIRA cloud's REST API has introduced a \"bug\" which disallows cross-domain calls. Fine.</p><p>My frustration with propriety software has come down to this: we're going to use two highly-protected closed source behemoth products against one another. Here's the plan:</p><ul><li>Pull JIRA issues into Tableau</li><li>Format the data in a worksheet</li><li>Output our data to a MongoDB database</li><li>Build a Kanban widget to display these issues</li><li>Hack the shit out of both JIRA and Tableau to make this process automated</li></ul><p>If this seems like a convoluted way of achieving a small goal, it absolutely is - the goal is just as much to become familiar with these systems as is the end prize. There's a lot going on here, so for part 1 let's do a dry run of getting our issues from JIRA to MongoDB.</p><h2 id=\"the-extraction\">The Extraction</h2><p>Pulling all issues from JIRA would normally be a simple API call, but in the spirit of learning new things we'll try out <a href=\"https://marketplace.atlassian.com/apps/1214641/all-in-one-tableau-connector-for-jira\">JIRA's Tableau connector</a>. This essentially enables an endpoint specifically for Tableau to pull JIRA data from. After installing the JIRA add-on, we'll be able to produce a URL for Tableau to consume via the Web Data Connector source:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-27-13.42.11.png\" class=\"kg-image\" alt=\"Connector\"></figure><!--kg-card-end: image--><p>The connector allows us to select the data we're looking to pull from JIRA upfront. Keep our scope in mind: we're looking to simply display a \"card\" (think Trello for all you noobs out there) per issue, so we're only concerned with the information we'd need to build that. I've boiled this down to:</p><ul><li>Key</li><li>Issue Type</li><li>Summary</li><li>Description</li><li>Status</li><li>Creator</li><li>Priority</li><li>Epic link</li><li>Epic Name</li><li>Epic Color</li></ul><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-27-13.52.24.png\" class=\"kg-image\" alt=\"Fields\"><figcaption>The field selection screen when setting up our connector.</figcaption></figure><!--kg-card-end: image--><h2 id=\"work-that-sheet\">Work That Sheet</h2><p>With our data imported, create a new worksheet. If you've used Tableau before you're probably very aware of the default column limit on Worksheets. Before we do anything, go to <strong>Analysis</strong> &gt; <strong>Table Layout</strong> &gt; <strong>Advanced</strong> to increase the max columns from 6 to whatever, let's say 12.</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-27-16.02.46.png\" class=\"kg-image\" alt=\"Increase columns\"><figcaption>WARING: super sick advanced Tableau hacks incoming.</figcaption></figure><!--kg-card-end: image--><p>Drag your data into the \"rows\" shelf to get something like this:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/tableausheet.png\" class=\"kg-image\"><figcaption>Our first look at the data.</figcaption></figure><!--kg-card-end: image--><p>There are a few problems here we need to clean up. First, take a look at the \"Epic Color\" column.</p><h3 id=\"eyes-as-blue-as-ghx-label-7\">Eyes as Blue as ghx-label-7</h3><p>For some reason, JIRA finds it appropriate to label its colors this cryptic  code of <em>ghx-label-#</em>. Go ahead and add this to the long list of shitty decisions Atlassian has chosen to pursue.</p><p>Keeping our goal in mind, we need \"epic colors\" to add some style and flavor to our board. Could we make the board without this? Probably, if you're a quitter. I'm going to save you some time here. I went ahead and inspected the epic elements in my JIRA instance to extract their hex values. Create a new calculated field and add this query to manually map the label nonsense to actual values:</p><!--kg-card-begin: code--><pre><code>IF [Epic Colour] = \"ghx-label-1\"\nTHEN \"#42526E\"\nELSEIF [Epic Colour] = \"ghx-label-2\"\nTHEN \"#FFC400\"\nELSEIF [Epic Colour] = \"ghx-label-3\"\nTHEN \"#FFE380\"\nELSEIF [Epic Colour] = \"ghx-label-4\"\nTHEN \"#4C9AFF\"\nELSEIF [Epic Colour] = \"ghx-label-5\"\nTHEN \"#00C7E6\"\nELSEIF [Epic Colour] = \"ghx-label-6\"\nTHEN \"#79F2C0\"\nELSEIF [Epic Colour] = \"ghx-label-7\"\nTHEN \"#C0B6F2\"\nELSEIF [Epic Colour] = \"ghx-label-8\"\nTHEN \"#998DD9\"\nELSEIF [Epic Colour] = \"ghx-label-9\"\nTHEN \"#FFBDAD\"\nELSEIF [Epic Colour] = \"ghx-label-10\"\nTHEN \"#B3D4FF\"\nELSEIF [Epic Colour] = \"ghx-label-11\"\nTHEN \"#79E2F2\"\nELSEIF [Epic Colour] = \"ghx-label-12\"\nTHEN \"#EBECF0\"\nELSEIF [Epic Colour] = \"ghx-label-13\"\nTHEN \"#57D9A3\"\nELSEIF [Epic Colour] = \"ghx-label-14\"\nTHEN \"#FF8F73\"\nELSEIF [Epic Colour] = \"ghx-label-15\"\nTHEN \"#57D9A3\"\nELSEIF [Epic Colour] = \"ghx-label-16\"\nTHEN \"#57D9A3\"\nELSEIF [Epic Colour] = \"ghx-label-17\"\nTHEN \"#57D9A3\"\nEND</code></pre><!--kg-card-end: code--><p>Replace the \"Epic Color\" field with this new calculated field to reveal our next problem.</p><h3 id=\"epic-lynx\">Epic Lynx</h3><p>If you check out our sheet now, we'll see the proper colors values come through, but they will only be appearing for what seems to be one issue per \"Epic\" in our sheet:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-27-16.18.05.png\" class=\"kg-image\" alt=\"Epic Colors\"></figure><!--kg-card-end: image--><p>Feel free to moan and groan a bit while we realize what's happening. We're looking at a list of <em>issues</em> here, where <em>epics</em> are themselves to be considered an issue. Therefore, only issues which are epics will have colors: issues which are <em>linked</em> to said epics, however, will not. This is annoying. It took me a bit to come up with the following solution, although I'd be curious to hear if anybody has a better way of doing this.</p><p>Go ahead and create a new worksheet. Add <strong>Epic Link</strong> and <strong>Epic Color</strong> to the sheet, and filter out the null values:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-27-16.26.24.png\" class=\"kg-image\" alt=\"Epic Color Sheet\"><figcaption>Creating a table to perform a SQL-like JOIN</figcaption></figure><!--kg-card-end: image--><p>So here's the game plan. Stay with me on this one: we're going to use this sheet as a new source to perform a <strong>join</strong> with our original data. Once we join on <strong>Epic Link</strong>, every issue containing an epic link will have the parent color as a field as well.</p><p>Export this data as a CSV. Go back to Data Sources, open a new data source, and select the CSV we just created. Create an inner merge and associate by epic link:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-27-16.31.36.png\" class=\"kg-image\" alt=\"Merge Inner\"><figcaption>Creating JOINs via a UI!</figcaption></figure><!--kg-card-end: image--><p>Now we're getting somewhere. Go back to the original sheet and drag the color field from the new data source on to the shelf:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-27-16.33.27.png\" class=\"kg-image\" alt=\"Issues with colors\"><figcaption>The result.</figcaption></figure><!--kg-card-end: image--><p>Pro move. Calculated.</p><h2 id=\"mondo-bongo\">Mondo Bongo</h2><p>You'll notice I switched the order of our rows around to have \"Issue key\" as the first column. Originally I made the mistake of not doing this, only to realize that Tableau will not export merged cells into a CSV. We need to order our columns starting with the most unique first to avoid any cell merging.</p><p>Export that bad boy.</p><p>This is where we'll import our data into MongoDB. How dope is MongoDB, you ask? Well, one feature is the ability to import a CSV into an empty database to automatically create the resulting schema and populate it with your values. Yeah, it's that sick.</p><p>I won't turn this into a MongoDB tutorial. Setting up a MongoDB Atlas cluster is somewhat straightforward, and we can use the <strong>MongoDB Compass</strong> client to simply import the CSV we created.</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2018/05/Screenshot-2018-05-27-16.40.19.png\" class=\"kg-image\" alt=\"MongoDB\"></figure><!--kg-card-end: image--><h2 id=\"what-next\">What Next?</h2><p>As mentioned, our first take at this is going to be a dry run of building this widget with our initial data import. We'll be building this widget in an ExpressJS app, so next we'll focus on how to connect our app to MongoDB and extract this data.</p><p>After that, we'll need to find a way to automate this process moving forward. Full disclosure: Tableau most definitely will not play nice with this, and I'm iffy on how possible this is. All I know is I've got a Tableau Server instance up and running, and I paid good money for it. Therefore, it is my right to break it.</p><p>I hope at least one or two people have found this to be helpful or interesting thus far. Again, I realize this process is a completely roundabout way of accomplishing this task... this is mostly a way for us to learn the ins-and-outs of these systems. Perhaps we might even build something special. Just think: if we manage to close the loop on this system, we can leverage a GUI to create apps nearly as fast as we can imagine them.</p>","url":"https://hackersandslackers.com/jira-analysis-in-tableau/","uuid":"e3aebe6d-5ae2-4fca-97f5-b805c77cad60","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b0ae7ef057ed3587f8621b3"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673652","title":"Build Custom Widgets For Your Ghost Blog","slug":"build-custom-widgets-for-your-ghost-blog","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/ghost-1.jpg","excerpt":"Get started customizing your themes with simple widgets.","custom_excerpt":"Get started customizing your themes with simple widgets.","created_at_pretty":"15 May, 2018","published_at_pretty":"15 May, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-05-15T18:53:29.000-04:00","published_at":"2018-05-15T19:27:56.000-04:00","updated_at":"2019-04-09T20:47:59.000-04:00","meta_title":"Build Custom Widgets For Your Ghost Blog | Hackers and Slackers","meta_description":"Learn to build custom widgets for your Ghost blog with Handlebars. Easily implement common widgets such as recent posts, related posts, contributors, etc.","og_description":"Learn to build custom widgets for your Ghost blog with Handlebars. Easily implement common widgets such as recent posts, related posts, contributors, etc.","og_image":"https://hackersandslackers.com/content/images/2019/04/ghost-1-2.jpg","og_title":"Build Custom Widgets For Your Ghost Blog","twitter_description":"Learn to build custom widgets for your Ghost blog with Handlebars. Easily implement common widgets such as recent posts, related posts, contributors, etc.","twitter_image":"https://hackersandslackers.com/content/images/2019/04/ghost-1-1.jpg","twitter_title":"Build Custom Widgets For Your Ghost Blog","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"ExpressJS","slug":"expressjs","description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch as a simplistic Express app can evolve into a beautiful monstrosity.","feature_image":null,"meta_description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch a simplistic Express app can evolve into a beautiful monstrosity.","meta_title":"ExpressJS Framework | Hackers and Slackers","visibility":"public"},"tags":[{"name":"ExpressJS","slug":"expressjs","description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch as a simplistic Express app can evolve into a beautiful monstrosity.","feature_image":null,"meta_description":"A safespace for NodeJS newbies to learn Javascript’s most popular backend framework. Watch a simplistic Express app can evolve into a beautiful monstrosity.","meta_title":"ExpressJS Framework | Hackers and Slackers","visibility":"public"},{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"}],"plaintext":"Here at H+S headquarters, we're pretty into the Ghost blogging platform. It's a\nlot like Wordpress, except without everything that sucks about Wordpress. It's a\nNode app, isn't bloated with widgets, is more secure, smarter, prettier, and so\non. If you're a dev looking to get a quick clean CMS running, Ghost is pretty\nmuch a no-brainer.\n\nWhile the platform has been around for a while, the community is still in its\ninfancy as humanity lags behind the curve, with 80% of all sites victim of\nhacking being Wordpress-based. As such, we consider it our duty to share\nknowledge where possible to expedite the growth of independent blogging.\n\nThis is no means a \"getting started with Ghost\" post - Ghost's own documentation\ncovers that quite well. Instead, we'd like to share the source for some of the\nwidgets we've developed over the years to help your theme along.\n\nBasics of Ghost Theme Development\nThere are actually two stacks we should be conscious of when building Ghost\nthemes: the core Ghost stack, and our theme's stack (yes, they are different... \nkind of).\n\nGhost is built on the following core stack:\n\n * NodeJS\n * ExpressJS\n * Handlebars\n * Grunt\n\nCommon to both Ghost's core stack and a Ghost theme stack is Handlebars. \nHandlebars is a templating system which adds logic to otherwise-static HTML\npages. If you're not quite familiar with Handlebars, check out our quick\ntutorial [https://hackersandslackers.com/handlebars-templating-in-expressjs/] \non how to get the gist of things As long as you're familiar with Express and\nHandlebars, you'll be good to go. You could very well\n\nEverything we're doing today happens at the theme  level, which is your\npresentation layer that can be swapped at any given time. Running on your own\ninstallation, the path should look something like:\n\n/var/www/ghost/content/themes/myTheme/\n\n\nThis is where our development will be taking place.\n\nThe Widgets\nA \"widget\" is simply a Handlebars partial saved in your theme. Unlike your\ntraditional monolithic Blog CMS (such as Wordpress), Ghost's widgets must be\nadded to your theme programmatically (I would argue that this is not a bad\nthing).\n\n1. Recent Posts Widget\nThis is a fairly common widget which displays X number of posts ranked by most\nrecent.\n\n<!-- start widget -->\n{{#get \"posts\" limit=\"3\" filter=\"primary_tag:-#hidden\"}}\n  <div class=\"widget\">\n    <h4 class=\"title\">Recent</h4>\n    <div class=\"content recent-post\">\n      {{#foreach posts}}\n        <div class=\"recent-single-post\">\n          <a href=\"{{url}}\" class=\"post-title\">{{title}}</a>\n          <div class=\"date\">{{date format=\"MMMM DD, YYYY\"}}</div>\n        </div>\n      {{/foreach}}\n    </div>\n  </div>\n{{/get}}\n<!-- end widget -->\n\n\n{{#get}}  will fetch posts, tags, or users within the given specifications. The\ntag does nothing on it's own; it simply allows us to work within the context of\ngetting these items, such as how we use {{#foreach posts}}  afterwards.\n\nThe filter  is actually quite powerful, and perhaps a bit under-documented. In\nthis case we're only fetching posts who have a visible main tag: you might want\nto do something like this if you sometimes use 'posts' to make announcements.\n\n{{#foreach posts}}  loops through our 3 posts and will create the result DOM\nstructure the number of times it loops.\n\n2. Related Posts Widget\nSimilar to the above, but only returns posts which share the same main tag:\n\n<!-- start widget -->\n<div class=\"widget\">\n  <h4 class=\"title\">Related</h4>\n  <div class=\"content recent-post\">\n    {{#get \"posts\" limit=\"3\" filter=\"id:-{{id}}+tag:{{primary_tag.slug}}\"}}\n      {{#foreach posts}}\n        <div class=\"recent-single-post\">\n          <a href=\"{{url}}\" class=\"post-title\">{{title}}</a>\n          <div class=\"date\">{{date format=\"MMMM DD\"}}</div>\n        </div>\n      {{/foreach}}\n    {{/get}}\n  </div>\n</div>\n<!-- end widget -->\n\n\n3. Authors Widget\nA surprisingly uncommon widget, we've actually yet to see this on another blog\nyet. This will list all contributors to your blog with their avatar, and link\nback to their author page:\n\n<!-- start widget -->\n<div class=\"widget contributors\">\n  <h3 class=\"title\">Contributors</h3>\n  <div class=\"recent-post\">\n    {{#get \"users\"}}\n      {{#foreach users}}\n        <div class=\"single-author {{slug}}\">\n          {{#unless profile_image}}\n            <a href=\"{{url}}\"><i class=\"fas fa-user\" style=\"width:18px; height:18px; display:inline-block; margin-right:10px;\"></i></a>\n          {{/unless}}\n          {{#if profile_image}}\n            <a href=\"{{url}}\"><img src=\"{{img_url profile_image}}\" alt=\"Author image\" class=\"avi\"></a>\n          {{/if}}\n          <div class=\"info\">\n            <a href=\"{{url}}\" class=\"single-author-name\">{{name}}</a>\n            <span class=\"role\"></span>\n          </div>\n        </div>\n      {{/foreach}}\n    {{/get}}\n  </div>\n</div>\n<!-- end widget -->\n\n\n4. About the Current Author Widget\nThis widget only exists within the context of pages/posts which have an explicit\nauthor. Also supports the use case of multiple authors.\n\n<!-- start about the author -->\n{{#foreach authors}}\n  <div class=\"about-author clearfix widget\">\n    <h4 class=\"title\">Author</h4>\n    {{#if profile_image}}\n      <a href=\"{{url}}\"><img src=\"{{profile_image}}\" alt=\"Author image\" class=\"avatar pull-left\"></a>\n    {{else}}\n      <a href=\"{{url}}\"><img src=\"{{asset \"images/default-user-image.jpg\"}}\" alt=\"Author image\" class=\"avatar pull-left\"></a>\n    {{/if}}\n    <div class=\"details\">\n      <div class=\"author\">\n        {{!--{{t \"About\"}}--}}<a href=\"{{url}}\">{{name}}</a>\n      </div>\n      <div class=\"meta-info\">\n        {{!--<span class=\"post-count\"><i class=\"fal fa-pencil\"></i><a href=\"{{url}}\">{{plural count.posts empty=(t \"0 Post\") singular=(t \"% Post\") plural=(t \"% Posts\")}}</a></span>--}}\n        {{#if location}}\n          <span class=\"location\"><i class=\"fal fa-home\"></i>{{location}}</span>\n        {{/if}}\n        {{#if website}}\n          <span class=\"website\"><a href=\"{{website}}\" targer=\"_BLANK\"><i class=\"fal fa-globe\"></i>{{t \"Website\"}}</a></span>\n        {{/if}}\n        {{#if twitter}}\n          <span class=\"twitter\"><a href=\"{{twitter_url}}\"><i class=\"fab fa-twitter\"></i>{{twitter}}</a></span>\n        {{/if}}\n        {{#if facebook}}\n          <span class=\"facebook\"><a href=\"{{facebook_url}}\"><i class=\"fab fa-facebook\"></i></a></span>\n        {{/if}}\n      </div>\n    </div>\n    {{#if bio}}\n      <div class=\"bio\">\n        {{{bio}}}\n      </div>\n    {{/if}}\n  </div>\n{{/foreach}}\n<!-- end about the author -->\n\n\n5. About all the Authors Widget\nA combination of the above two, this widget displays a blurb and information\nabout all authors who contribute to your publication.\n\n{{#get \"users\" limit=\"all\" include=\"count.posts\" order=\"count.posts desc\" }}\n  {{#foreach users}}\n    <div class=\"about-author clearfix\" style=\"background: url({{cover_img}}) center center; background-color: rgba(255, 255, 255, 0.9); background-blend-mode: overlay;\">\n      {{#if profile_image}}\n        <a href=\"{{url}}\"><img src=\"{{profile_image}}\" alt=\"Author image\" class=\"avatar pull-left\"></a>\n      {{else}}\n        <a href=\"{{url}}\"><img src=\"{{asset \"images/default-user-image.jpg\"}}\" alt=\"Author image\" class=\"avatar pull-left\"></a>\n      {{/if}}\n      <div class=\"details\">\n        <div class=\"author\">\n          <a href=\"{{url}}\">{{name}}</a>\n        </div>\n        <div class=\"meta-info\">\n          <span class=\"post-count\"><i class=\"fal fa-pencil\"></i><a href=\"{{url}}\">{{plural count.posts empty=(t \"0 Post\") singular=(t \"% Post\") plural=(t \"% Posts\")}}</a></span>\n          {{#if location}}\n            <span class=\"location\"><i class=\"fal fa-home\"></i>{{location}}</span>\n          {{/if}}\n          {{#if website}}\n            <span class=\"website\"><i class=\"fal fa-globe\"></i><a href=\"{{website}}\" targer=\"_BLANK\">{{website}}</a></span>\n          {{/if}}\n          {{#if twitter}}\n            <span class=\"twitter\"><i class=\"fab fa-twitter\"></i><a href=\"{{twitter_url}}\">{{twitter}}</a></span>\n          {{/if}}\n          {{#if facebook}}\n            <span class=\"facebook\"><a href=\"{{facebook_url}}\"><i class=\"fab fa-facebook\"></i></a></span>\n          {{/if}}\n        </div>\n      </div>\n      {{#if bio}}\n        <p class=\"bio\">\n          {{{bio}}}\n        </p>\n      {{/if}}\n    </div>\n  {{/foreach}}\n{{/get}}\n\n\nObviously you can customize your widgets as you see fit to include or exclude\nthe information you're looking for. Hopefully these snippets serve as a useful\nreference for some common use cases to help your blog be as baller as possible.","html":"<p>Here at H+S headquarters, we're pretty into the Ghost blogging platform. It's a lot like Wordpress, except without everything that sucks about Wordpress. It's a Node app, isn't bloated with widgets, is more secure, smarter, prettier, and so on. If you're a dev looking to get a quick clean CMS running, Ghost is pretty much a no-brainer.</p><p>While the platform has been around for a while, the community is still in its infancy as humanity lags behind the curve, with 80% of all sites victim of hacking being Wordpress-based. As such, we consider it our duty to share knowledge where possible to expedite the growth of independent blogging.</p><p>This is no means a \"getting started with Ghost\" post - Ghost's own documentation covers that quite well. Instead, we'd like to share the source for some of the widgets we've developed over the years to help your theme along.</p><h2 id=\"basics-of-ghost-theme-development\">Basics of Ghost Theme Development</h2><p>There are actually two stacks we should be conscious of when building Ghost themes: the core Ghost stack, and our theme's stack (yes, they are different... <em>kind of</em>).</p><p>Ghost is built on the following core stack:</p><ul><li>NodeJS</li><li>ExpressJS</li><li>Handlebars</li><li>Grunt</li></ul><p>Common to both Ghost's core stack and a Ghost theme stack is <strong>Handlebars. </strong>Handlebars is a templating system which adds logic to otherwise-static HTML pages. If you're not quite familiar with Handlebars, check out our <a href=\"https://hackersandslackers.com/handlebars-templating-in-expressjs/\">quick tutorial</a> on how to get the gist of things As long as you're familiar with Express and Handlebars, you'll be good to go. You could very well</p><p>Everything we're doing today happens at the <em>theme</em> level, which is your presentation layer that can be swapped at any given time. Running on your own installation, the path should look something like:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">/var/www/ghost/content/themes/myTheme/\n</code></pre>\n<!--kg-card-end: markdown--><p>This is where our development will be taking place.</p><h2 id=\"the-widgets\">The Widgets</h2><p>A \"widget\" is simply a Handlebars partial saved in your theme. Unlike your traditional monolithic Blog CMS (such as Wordpress), Ghost's widgets must be added to your theme programmatically (I would argue that this is not a bad thing).</p><h3 id=\"1-recent-posts-widget\">1. Recent Posts Widget</h3><p>This is a fairly common widget which displays X number of posts ranked by most recent.</p><!--kg-card-begin: markdown--><pre><code class=\"language-handlebars\">&lt;!-- start widget --&gt;\n{{#get &quot;posts&quot; limit=&quot;3&quot; filter=&quot;primary_tag:-#hidden&quot;}}\n  &lt;div class=&quot;widget&quot;&gt;\n    &lt;h4 class=&quot;title&quot;&gt;Recent&lt;/h4&gt;\n    &lt;div class=&quot;content recent-post&quot;&gt;\n      {{#foreach posts}}\n        &lt;div class=&quot;recent-single-post&quot;&gt;\n          &lt;a href=&quot;{{url}}&quot; class=&quot;post-title&quot;&gt;{{title}}&lt;/a&gt;\n          &lt;div class=&quot;date&quot;&gt;{{date format=&quot;MMMM DD, YYYY&quot;}}&lt;/div&gt;\n        &lt;/div&gt;\n      {{/foreach}}\n    &lt;/div&gt;\n  &lt;/div&gt;\n{{/get}}\n&lt;!-- end widget --&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p><code>{{#get}}</code> will fetch posts, tags, or users within the given specifications. The tag does nothing on it's own; it simply allows us to work within the context of getting these items, such as how we use <code>{{#foreach posts}}</code> afterwards.</p><p>The <em>filter</em> is actually quite powerful, and perhaps a bit under-documented. In this case we're only fetching posts who have a visible main tag: you might want to do something like this if you sometimes use 'posts' to make announcements.</p><p><code>{{#foreach posts}}</code> loops through our 3 posts and will create the result DOM structure the number of times it loops.</p><h3 id=\"2-related-posts-widget\">2. Related Posts Widget</h3><p>Similar to the above, but only returns posts which share the same main tag:</p><!--kg-card-begin: markdown--><pre><code class=\"language-handlebars\">&lt;!-- start widget --&gt;\n&lt;div class=&quot;widget&quot;&gt;\n  &lt;h4 class=&quot;title&quot;&gt;Related&lt;/h4&gt;\n  &lt;div class=&quot;content recent-post&quot;&gt;\n    {{#get &quot;posts&quot; limit=&quot;3&quot; filter=&quot;id:-{{id}}+tag:{{primary_tag.slug}}&quot;}}\n      {{#foreach posts}}\n        &lt;div class=&quot;recent-single-post&quot;&gt;\n          &lt;a href=&quot;{{url}}&quot; class=&quot;post-title&quot;&gt;{{title}}&lt;/a&gt;\n          &lt;div class=&quot;date&quot;&gt;{{date format=&quot;MMMM DD&quot;}}&lt;/div&gt;\n        &lt;/div&gt;\n      {{/foreach}}\n    {{/get}}\n  &lt;/div&gt;\n&lt;/div&gt;\n&lt;!-- end widget --&gt;\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"3-authors-widget\">3. Authors Widget</h3><p>A surprisingly uncommon widget, we've actually yet to see this on another blog yet. This will list all contributors to your blog with their avatar, and link back to their author page:</p><!--kg-card-begin: markdown--><pre><code class=\"language-handlebars\">&lt;!-- start widget --&gt;\n&lt;div class=&quot;widget contributors&quot;&gt;\n  &lt;h3 class=&quot;title&quot;&gt;Contributors&lt;/h3&gt;\n  &lt;div class=&quot;recent-post&quot;&gt;\n    {{#get &quot;users&quot;}}\n      {{#foreach users}}\n        &lt;div class=&quot;single-author {{slug}}&quot;&gt;\n          {{#unless profile_image}}\n            &lt;a href=&quot;{{url}}&quot;&gt;&lt;i class=&quot;fas fa-user&quot; style=&quot;width:18px; height:18px; display:inline-block; margin-right:10px;&quot;&gt;&lt;/i&gt;&lt;/a&gt;\n          {{/unless}}\n          {{#if profile_image}}\n            &lt;a href=&quot;{{url}}&quot;&gt;&lt;img src=&quot;{{img_url profile_image}}&quot; alt=&quot;Author image&quot; class=&quot;avi&quot;&gt;&lt;/a&gt;\n          {{/if}}\n          &lt;div class=&quot;info&quot;&gt;\n            &lt;a href=&quot;{{url}}&quot; class=&quot;single-author-name&quot;&gt;{{name}}&lt;/a&gt;\n            &lt;span class=&quot;role&quot;&gt;&lt;/span&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      {{/foreach}}\n    {{/get}}\n  &lt;/div&gt;\n&lt;/div&gt;\n&lt;!-- end widget --&gt;\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"4-about-the-current-author-widget\">4. About the Current Author Widget</h3><p>This widget only exists within the context of pages/posts which have an explicit author. Also supports the use case of multiple authors.</p><!--kg-card-begin: markdown--><pre><code class=\"language-handlebars\">&lt;!-- start about the author --&gt;\n{{#foreach authors}}\n  &lt;div class=&quot;about-author clearfix widget&quot;&gt;\n    &lt;h4 class=&quot;title&quot;&gt;Author&lt;/h4&gt;\n    {{#if profile_image}}\n      &lt;a href=&quot;{{url}}&quot;&gt;&lt;img src=&quot;{{profile_image}}&quot; alt=&quot;Author image&quot; class=&quot;avatar pull-left&quot;&gt;&lt;/a&gt;\n    {{else}}\n      &lt;a href=&quot;{{url}}&quot;&gt;&lt;img src=&quot;{{asset &quot;images/default-user-image.jpg&quot;}}&quot; alt=&quot;Author image&quot; class=&quot;avatar pull-left&quot;&gt;&lt;/a&gt;\n    {{/if}}\n    &lt;div class=&quot;details&quot;&gt;\n      &lt;div class=&quot;author&quot;&gt;\n        {{!--{{t &quot;About&quot;}}--}}&lt;a href=&quot;{{url}}&quot;&gt;{{name}}&lt;/a&gt;\n      &lt;/div&gt;\n      &lt;div class=&quot;meta-info&quot;&gt;\n        {{!--&lt;span class=&quot;post-count&quot;&gt;&lt;i class=&quot;fal fa-pencil&quot;&gt;&lt;/i&gt;&lt;a href=&quot;{{url}}&quot;&gt;{{plural count.posts empty=(t &quot;0 Post&quot;) singular=(t &quot;% Post&quot;) plural=(t &quot;% Posts&quot;)}}&lt;/a&gt;&lt;/span&gt;--}}\n        {{#if location}}\n          &lt;span class=&quot;location&quot;&gt;&lt;i class=&quot;fal fa-home&quot;&gt;&lt;/i&gt;{{location}}&lt;/span&gt;\n        {{/if}}\n        {{#if website}}\n          &lt;span class=&quot;website&quot;&gt;&lt;a href=&quot;{{website}}&quot; targer=&quot;_BLANK&quot;&gt;&lt;i class=&quot;fal fa-globe&quot;&gt;&lt;/i&gt;{{t &quot;Website&quot;}}&lt;/a&gt;&lt;/span&gt;\n        {{/if}}\n        {{#if twitter}}\n          &lt;span class=&quot;twitter&quot;&gt;&lt;a href=&quot;{{twitter_url}}&quot;&gt;&lt;i class=&quot;fab fa-twitter&quot;&gt;&lt;/i&gt;{{twitter}}&lt;/a&gt;&lt;/span&gt;\n        {{/if}}\n        {{#if facebook}}\n          &lt;span class=&quot;facebook&quot;&gt;&lt;a href=&quot;{{facebook_url}}&quot;&gt;&lt;i class=&quot;fab fa-facebook&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/span&gt;\n        {{/if}}\n      &lt;/div&gt;\n    &lt;/div&gt;\n    {{#if bio}}\n      &lt;div class=&quot;bio&quot;&gt;\n        {{{bio}}}\n      &lt;/div&gt;\n    {{/if}}\n  &lt;/div&gt;\n{{/foreach}}\n&lt;!-- end about the author --&gt;\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"5-about-all-the-authors-widget\">5. About all the Authors Widget</h3><p>A combination of the above two, this widget displays a blurb and information about all authors who contribute to your publication.</p><!--kg-card-begin: markdown--><pre><code class=\"language-handlebars\">{{#get &quot;users&quot; limit=&quot;all&quot; include=&quot;count.posts&quot; order=&quot;count.posts desc&quot; }}\n  {{#foreach users}}\n    &lt;div class=&quot;about-author clearfix&quot; style=&quot;background: url({{cover_img}}) center center; background-color: rgba(255, 255, 255, 0.9); background-blend-mode: overlay;&quot;&gt;\n      {{#if profile_image}}\n        &lt;a href=&quot;{{url}}&quot;&gt;&lt;img src=&quot;{{profile_image}}&quot; alt=&quot;Author image&quot; class=&quot;avatar pull-left&quot;&gt;&lt;/a&gt;\n      {{else}}\n        &lt;a href=&quot;{{url}}&quot;&gt;&lt;img src=&quot;{{asset &quot;images/default-user-image.jpg&quot;}}&quot; alt=&quot;Author image&quot; class=&quot;avatar pull-left&quot;&gt;&lt;/a&gt;\n      {{/if}}\n      &lt;div class=&quot;details&quot;&gt;\n        &lt;div class=&quot;author&quot;&gt;\n          &lt;a href=&quot;{{url}}&quot;&gt;{{name}}&lt;/a&gt;\n        &lt;/div&gt;\n        &lt;div class=&quot;meta-info&quot;&gt;\n          &lt;span class=&quot;post-count&quot;&gt;&lt;i class=&quot;fal fa-pencil&quot;&gt;&lt;/i&gt;&lt;a href=&quot;{{url}}&quot;&gt;{{plural count.posts empty=(t &quot;0 Post&quot;) singular=(t &quot;% Post&quot;) plural=(t &quot;% Posts&quot;)}}&lt;/a&gt;&lt;/span&gt;\n          {{#if location}}\n            &lt;span class=&quot;location&quot;&gt;&lt;i class=&quot;fal fa-home&quot;&gt;&lt;/i&gt;{{location}}&lt;/span&gt;\n          {{/if}}\n          {{#if website}}\n            &lt;span class=&quot;website&quot;&gt;&lt;i class=&quot;fal fa-globe&quot;&gt;&lt;/i&gt;&lt;a href=&quot;{{website}}&quot; targer=&quot;_BLANK&quot;&gt;{{website}}&lt;/a&gt;&lt;/span&gt;\n          {{/if}}\n          {{#if twitter}}\n            &lt;span class=&quot;twitter&quot;&gt;&lt;i class=&quot;fab fa-twitter&quot;&gt;&lt;/i&gt;&lt;a href=&quot;{{twitter_url}}&quot;&gt;{{twitter}}&lt;/a&gt;&lt;/span&gt;\n          {{/if}}\n          {{#if facebook}}\n            &lt;span class=&quot;facebook&quot;&gt;&lt;a href=&quot;{{facebook_url}}&quot;&gt;&lt;i class=&quot;fab fa-facebook&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/span&gt;\n          {{/if}}\n        &lt;/div&gt;\n      &lt;/div&gt;\n      {{#if bio}}\n        &lt;p class=&quot;bio&quot;&gt;\n          {{{bio}}}\n        &lt;/p&gt;\n      {{/if}}\n    &lt;/div&gt;\n  {{/foreach}}\n{{/get}}\n</code></pre>\n<!--kg-card-end: markdown--><p>Obviously you can customize your widgets as you see fit to include or exclude the information you're looking for. Hopefully these snippets serve as a useful reference for some common use cases to help your blog be as baller as possible.</p>","url":"https://hackersandslackers.com/build-custom-widgets-for-your-ghost-blog/","uuid":"a1d550bc-034d-4c2c-85f0-ff434f400d8c","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5afb64e93d0bf921d8b8804f"}}]}},"pageContext":{"slug":"todd","limit":12,"skip":60,"numberOfPages":8,"humanPageNumber":6,"prevPageNumber":5,"nextPageNumber":7,"previousPagePath":"/author/todd/page/5/","nextPagePath":"/author/todd/page/7/"}}