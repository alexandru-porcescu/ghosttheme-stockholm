{"data":{"ghostPost":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ec","title":"Tuning Machine Learning Hyperparameters with Binary Search","slug":"tuning-machine-learning-hyperparameters-with-binary-search","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/ai2@2x.jpg","excerpt":"Tune the n_estimators parameter in for a Random Forests classifier in scikit-learn in Python.","custom_excerpt":"Tune the n_estimators parameter in for a Random Forests classifier in scikit-learn in Python.","created_at_pretty":"30 August, 2018","published_at_pretty":"03 September, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-08-29T21:35:41.000-04:00","published_at":"2018-09-03T07:30:00.000-04:00","updated_at":"2019-02-13T22:50:35.000-05:00","meta_title":"Tune the n_estimators parameter in for a Random Forests classifier in scikit-learn in Python | Hackers And Slackers","meta_description":"RandomizedSearchCV goes noticeably faster than a full GridSearchCV but it still takes a while - which can be rough.","og_description":"Code Snippet Corner: Tuning Machine Learning Hyperparameters with Binary Search","og_image":"https://hackersandslackers.com/content/images/2018/08/ai2@2x.jpg","og_title":"Code Snippet Corner: Tuning Machine Learning Hyperparameters with Binary Search","twitter_description":"Tune the n_estimators parameter in for a Random Forests classifier in scikit-learn in Python","twitter_image":"https://hackersandslackers.com/content/images/2018/08/ai2@2x.jpg","twitter_title":"Code Snippet Corner: Tuning Machine Learning Hyperparameters with Binary Search","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},"tags":[{"name":"Code Snippet Corner","slug":"codesnippetcorner","description":"Real-world examples of Python being used to solve complex data problems, primarily using Jupyter notebooks.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o-1.jpg","meta_description":"Real-world examples of Python being used to solve complex data problems.","meta_title":"Python Code Snippet Corner","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},{"name":"Machine Learning","slug":"machine-learning","description":"The latest developments in machine learning tools and technology available to data scientists.","feature_image":null,"meta_description":"The latest developments in machine learning tools and technology available to data scientists.","meta_title":"Machine Learning | Hackers and Slackers","visibility":"public"},{"name":"#Code Snippet Corner","slug":"code-snippet-corner","description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","feature_image":"https://hackers.nyc3.cdn.digitaloceanspaces.com/posts/2019/02/codecornerseries_o_o.jpg","meta_description":"Your weekly dose of Python tidbits and Jupyter notebooks to get you feeling saucy.","meta_title":"Python Code Snippet Corner","visibility":"internal"}],"plaintext":"Ah, hyperparameter tuning.  Time & compute-intensive.  Frequently containing\nweird non-linearities in how changing a parameter changes the score and/or the\ntime it takes to train the model.\n\nRandomizedSearchCV  goes noticeably faster than a full GridSearchCV  but it\nstill takes a while - which can be rough, because in my experience you do still\nneed to be iterative with it and experiment with different distributions.  Plus,\nthen you've got hyper-hyperparameters to tune - how many iterations SHOULD you\nrun it for, anyway?\n\nI've been experimenting with using the trusty old Binary Search to tune\nhyperparameters.  I'm finding it has two advantages.\n\n 1. It's blazing fast\n 2. The performance is competitive with a Randomized Search\n 3. It gives you a rough sketch of \"the lay of the land\".  An initial binary\n    search can then provide parameters for future searches, including with Grid\n    or Randomized Searches.\n\nCode is here\n[https://github.com/mattalhonte/binary-grid-search/blob/master/binarygridsearch/binarygridsearch.py]\n\nNotebook summary is here\n[https://github.com/mattalhonte/binary-grid-search/blob/master/Binary%20Search%20Interactive%20(n_estimators).ipynb]\n\nLet's see it in action!\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nWe'll be using a Random Forest classifier, because, as with all my code posts,\nit's what I've been using recently.\n\nfrom sklearn.datasets import load_breast_cancer\ndata = load_breast_cancer()\nX, y = data.data, data.target\n\n\nWe'll be using scikit-learn's breast cancer dataset, because I remembered that\nthese packages I'm posting about have built-in demo datasets that I should be\nusing for posts.\n\nrfArgs = {\"random_state\": 0,\n          \"n_jobs\": -1,\n          \"class_weight\": \"balanced\",\n         \"oob_score\": True}\n\n\nLet's set our random_state  for better reproducibility.\nWe'll set n_jobs=-1  because obviously we want to use all our cores, we are not\npatient people.\n\n\nWe'll have class_weight=\"balanced\"  because that'll compensate for the fact that\nthe breast cancer dataset (like most medical datasets) has unbalanced classes.\nWe'll use oob_score  because we like being lazy, part of the appeal of Random\nForests is the opportunity to be extra lazy (no need to normalize features!),\nand oob  lets us be even lazier  by giving some built-in cross-validation.\n\nNow let's define a function that'll take all this, and spit out a score.  I\nwrote the binary search function to take a function like this as an argument -\nscikit-learn is usually pretty consistent when it comes to the interface it\nprovides you, but sometimes different algorithms need to work a little\ndifferently.  For instance, since we'll be using Area Under \nprecision_recall_curve  as our metric (a good choice for classifiers with\nunbalanced classes!), it takes a teensy bit of extra fiddling to get it to play\nnicely with our oob_decision_function_.\n\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\n\ndef getForestAccuracy(X, y, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    clf.fit(X, y)\n    y_pred = clf.oob_decision_function_[:, 1]\n    precision, recall, _ = precision_recall_curve(y, y_pred)\n    return auc(recall, precision)\n\n\nWe'll try to optimize the n_estimators  parameter first.  For two reasons:\n\n 1. Finding a good mix between speed and accuracy here will make it easier to\n    tune subsequent parameters.\n 2. It's the most straightforward to decide upper and lower bounds for.  Other\n    ones (like, say, max_depth) require a little work to figure the potential\n    range to search in.\n\nOkay!  So, let's put our lower limit as 32 and our upper limit as 128, because I\nread in a StackOverflow post that there's a paper that says to search within\nthat range.\n\nn_estimators = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    \"n_estimators\", \n                    0, \n                    18, \n                    128)\n\nbgs.showTimeScoreChartAndGraph(n_estimators)\n\n\nPlotting score, time, and the ratio between them - we're not just optimizing for\nthe best score right now, we're looking for tipping points that give us good\ntradeoffs.  Scores and times are normalized for a more-meaningful ratio between\nthem.\n\nn_estimators\n score\n time\n scoreTimeRatio\n 0\n 32\n 1.073532\n 0.002459\n 1.000000\n 1\n 128\n 1.867858\n 1.002459\n 0.000000\n 2\n 80\n 2.052255\n 0.440060\n 0.006443\n 3\n 56\n 1.605447\n 0.075185\n 0.044843\n 4\n 68\n 1.910411\n 0.107187\n 0.036721\n 5\n 74\n 2.066440\n 0.377136\n 0.008320\n 6\n 77\n 2.066440\n 0.388378\n 0.007955\n 7\n 75\n 2.073532\n 0.457481\n 0.006141\n n_estimators\n score\n time\n 0\n 32\n 0.988663\n 0.180521\n 1\n 128\n 0.989403\n 0.587113\n 2\n 80\n 0.989575\n 0.358446\n 3\n 56\n 0.989159\n 0.210091\n 4\n 68\n 0.989443\n 0.223102\n 5\n 74\n 0.989588\n 0.332861\n 6\n 77\n 0.989588\n 0.337432\n 7\n 75\n 0.989595\n 0.365529\n Hrm, looks like the score starts getting somewhere interesting around 68, and\ntime starts shooting up at about 80.  Let's do another with those as our bounds!\n\nn_estimators = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    \"n_estimators\", \n                    0, \n                    68, \n                    80)\n\nbgs.showTimeScoreChartAndGraph(n_estimators)\n\n\nn_estimators\n score\n time\n scoreTimeRatio\n 0\n 68\n 6.390333\n 0.333407\n 0.135692\n 1\n 80\n 7.223667\n 1.064343\n 0.000000\n 2\n 74\n 7.307000\n 0.404471\n 0.123622\n 3\n 71\n 6.307000\n 0.064343\n 1.000000\n 4\n 72\n 6.390333\n 0.175190\n 0.325419\n n_estimators\n score\n time\n 0\n 68\n 0.989443\n 0.344220\n 1\n 80\n 0.989575\n 0.355580\n 2\n 74\n 0.989588\n 0.345324\n 3\n 71\n 0.989430\n 0.340038\n 4\n 72\n 0.989443\n 0.341761\n 71 looks like our winner!  Or close enough for our purposes while we then go\noptimize other things.  And we only had to train our model 13 times - as opposed\nto the 96 we would have with a brute-force grid search.\n\nHopefully this will become a series on using this to tune other RF\nhyperparameters - other ones have some interesting quirks that I'd like to\nexpound upon.  Or you could just look at the GitHub repo for spoilers.  Or both!","html":"<p>Ah, hyperparameter tuning.  Time &amp; compute-intensive.  Frequently containing weird non-linearities in how changing a parameter changes the score and/or the time it takes to train the model.</p><p><code>RandomizedSearchCV</code> goes noticeably faster than a full <code>GridSearchCV</code> but it still takes a while - which can be rough, because in my experience you do still need to be iterative with it and experiment with different distributions.  Plus, then you've got hyper-hyperparameters to tune - how many iterations SHOULD you run it for, anyway?</p><p>I've been experimenting with using the trusty old Binary Search to tune hyperparameters.  I'm finding it has two advantages.</p><ol><li>It's blazing fast</li><li>The performance is competitive with a Randomized Search</li><li>It gives you a rough sketch of \"the lay of the land\".  An initial binary search can then provide parameters for future searches, including with Grid or Randomized Searches.</li></ol><p>Code is <a href=\"https://github.com/mattalhonte/binary-grid-search/blob/master/binarygridsearch/binarygridsearch.py\">here</a></p><p>Notebook summary is <a href=\"https://github.com/mattalhonte/binary-grid-search/blob/master/Binary%20Search%20Interactive%20(n_estimators).ipynb\">here</a></p><p>Let's see it in action!</p><pre><code class=\"language-python\">from sklearn.ensemble import RandomForestClassifier\n</code></pre>\n<p>We'll be using a Random Forest classifier, because, as with all my code posts, it's what I've been using recently.</p><pre><code class=\"language-python\">from sklearn.datasets import load_breast_cancer\ndata = load_breast_cancer()\nX, y = data.data, data.target\n</code></pre>\n<p>We'll be using scikit-learn's breast cancer dataset, because I remembered that these packages I'm posting about have built-in demo datasets that I should be using for posts.</p><pre><code class=\"language-python\">rfArgs = {&quot;random_state&quot;: 0,\n          &quot;n_jobs&quot;: -1,\n          &quot;class_weight&quot;: &quot;balanced&quot;,\n         &quot;oob_score&quot;: True}\n</code></pre>\n<p>Let's set our <code>random_state</code> for better reproducibility.<br>We'll set <code>n_jobs=-1</code> because obviously we want to use all our cores, we are not patient people.</p><p><br>We'll have <code>class_weight=\"balanced\"</code> because that'll compensate for the fact that the breast cancer dataset (like most medical datasets) has unbalanced classes.<br>We'll use <code>oob_score</code> because we like being lazy, part of the appeal of Random Forests is the opportunity to be extra lazy (no need to normalize features!), and <code>oob</code> lets us be <em>even lazier</em> by giving some built-in cross-validation.</p><p>Now let's define a function that'll take all this, and spit out a score.  I wrote the binary search function to take a function like this as an argument - scikit-learn is usually pretty consistent when it comes to the interface it provides you, but sometimes different algorithms need to work a little differently.  For instance, since we'll be using Area Under <code>precision_recall_curve</code> as our metric (a good choice for classifiers with unbalanced classes!), it takes a teensy bit of extra fiddling to get it to play nicely with our <code>oob_decision_function_</code>.</p><pre><code class=\"language-python\">from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\n\ndef getForestAccuracy(X, y, kwargs):\n    clf = RandomForestClassifier(**kwargs)\n    clf.fit(X, y)\n    y_pred = clf.oob_decision_function_[:, 1]\n    precision, recall, _ = precision_recall_curve(y, y_pred)\n    return auc(recall, precision)\n</code></pre>\n<p>We'll try to optimize the <code>n_estimators</code> parameter first.  For two reasons:</p><ol><li>Finding a good mix between speed and accuracy here will make it easier to tune subsequent parameters.</li><li>It's the most straightforward to decide upper and lower bounds for.  Other ones (like, say, <code>max_depth</code>) require a little work to figure the potential range to search in.</li></ol><p>Okay!  So, let's put our lower limit as 32 and our upper limit as 128, because I read in a StackOverflow post that there's a paper that says to search within that range.</p><pre><code class=\"language-python\">n_estimators = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    &quot;n_estimators&quot;, \n                    0, \n                    18, \n                    128)\n\nbgs.showTimeScoreChartAndGraph(n_estimators)\n</code></pre>\n<p>Plotting score, time, and the ratio between them - we're not just optimizing for the best score right now, we're looking for tipping points that give us good tradeoffs.  Scores and times are normalized for a more-meaningful ratio between them.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/visualization--2-.png\" class=\"kg-image\"></figure><div class=\"tableContainer\">\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_estimators</th>\n      <th>score</th>\n      <th>time</th>\n      <th>scoreTimeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32</td>\n      <td>1.073532</td>\n      <td>0.002459</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>128</td>\n      <td>1.867858</td>\n      <td>1.002459</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80</td>\n      <td>2.052255</td>\n      <td>0.440060</td>\n      <td>0.006443</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1.605447</td>\n      <td>0.075185</td>\n      <td>0.044843</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>68</td>\n      <td>1.910411</td>\n      <td>0.107187</td>\n      <td>0.036721</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>74</td>\n      <td>2.066440</td>\n      <td>0.377136</td>\n      <td>0.008320</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>77</td>\n      <td>2.066440</td>\n      <td>0.388378</td>\n      <td>0.007955</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>75</td>\n      <td>2.073532</td>\n      <td>0.457481</td>\n      <td>0.006141</td>\n    </tr>\n  </tbody>\n</table>\n</div><div class=\"tableContainer\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_estimators</th>\n      <th>score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32</td>\n      <td>0.988663</td>\n      <td>0.180521</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>128</td>\n      <td>0.989403</td>\n      <td>0.587113</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80</td>\n      <td>0.989575</td>\n      <td>0.358446</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>0.989159</td>\n      <td>0.210091</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>68</td>\n      <td>0.989443</td>\n      <td>0.223102</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>74</td>\n      <td>0.989588</td>\n      <td>0.332861</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>77</td>\n      <td>0.989588</td>\n      <td>0.337432</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>75</td>\n      <td>0.989595</td>\n      <td>0.365529</td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Hrm, looks like the score starts getting somewhere interesting around 68, and time starts shooting up at about 80.  Let's do another with those as our bounds!</p><pre><code class=\"language-python\">n_estimators = bgs.compareValsBaseCase(X, \n                    y, \n                    getForestAccuracy,        \n                    rfArgs, \n                    &quot;n_estimators&quot;, \n                    0, \n                    68, \n                    80)\n\nbgs.showTimeScoreChartAndGraph(n_estimators)\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/max_depth.png\" class=\"kg-image\"></figure><div class=\"tableContainer\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_estimators</th>\n      <th>score</th>\n      <th>time</th>\n      <th>scoreTimeRatio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>68</td>\n      <td>6.390333</td>\n      <td>0.333407</td>\n      <td>0.135692</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80</td>\n      <td>7.223667</td>\n      <td>1.064343</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>74</td>\n      <td>7.307000</td>\n      <td>0.404471</td>\n      <td>0.123622</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>71</td>\n      <td>6.307000</td>\n      <td>0.064343</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>72</td>\n      <td>6.390333</td>\n      <td>0.175190</td>\n      <td>0.325419</td>\n    </tr>\n  </tbody>\n</table>\n</div><div class=\"tableContainer\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_estimators</th>\n      <th>score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>68</td>\n      <td>0.989443</td>\n      <td>0.344220</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80</td>\n      <td>0.989575</td>\n      <td>0.355580</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>74</td>\n      <td>0.989588</td>\n      <td>0.345324</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>71</td>\n      <td>0.989430</td>\n      <td>0.340038</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>72</td>\n      <td>0.989443</td>\n      <td>0.341761</td>\n    </tr>\n  </tbody>\n</table>\n</div><p>71 looks like our winner!  Or close enough for our purposes while we then go optimize other things.  And we only had to train our model 13 times - as opposed to the 96 we would have with a brute-force grid search.</p><p>Hopefully this will become a series on using this to tune other RF hyperparameters - other ones have some interesting quirks that I'd like to expound upon.  Or you could just look at the GitHub repo for spoilers.  Or both!</p>","url":"https://hackersandslackers.com/tuning-machine-learning-hyperparameters-with-binary-search/","uuid":"ca7241c3-52cd-4910-86dc-0bb5474d07af","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b8749ed4b98380b152292ea"}},"pageContext":{"slug":"tuning-machine-learning-hyperparameters-with-binary-search"}}