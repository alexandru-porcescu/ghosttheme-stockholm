{"data":{"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673644","title":"Make Your First API Calls with JQuery AJAX","slug":"making-ajax-calls-with-jquery","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/jquery-2-2.jpg","excerpt":"Beginner's guide to consuming endpoints via Frontend Javascript.","custom_excerpt":"Beginner's guide to consuming endpoints via Frontend Javascript.","created_at_pretty":"24 April, 2018","published_at_pretty":"25 April, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-04-23T20:20:21.000-04:00","published_at":"2018-04-25T01:00:00.000-04:00","updated_at":"2019-03-28T09:44:00.000-04:00","meta_title":"Make Your First API Calls with JQuery AJAX | Hackers and Slackers","meta_description":"Beginner's guide to consuming endpoints via Frontend Javascript. Quick Introduction to REST APIs, as well as a hands-on tutorial.","og_description":"Beginner's guide to consuming endpoints via Frontend Javascript. Quick Introduction to REST APIs, as well as a hands-on tutorial.","og_image":"https://hackersandslackers.com/content/images/2019/03/jquery-2-2.jpg","og_title":"Make Your First API Calls with JQuery AJAX","twitter_description":"Beginner's guide to consuming endpoints via Frontend Javascript. Quick Introduction to REST APIs, as well as a hands-on tutorial.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/jquery-2-1.jpg","twitter_title":"Make Your First API Calls with JQuery AJAX","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Frontend","slug":"frontend","description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","feature_image":null,"meta_description":"Frontend Javascript Logic typically assisted by Babel and Webpack. Primarily focused on fundamentals, as opposed to bandwagon frameworks.","meta_title":"Frontend Development | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"}],"plaintext":"The information age is over: we have all the information now. All of it. We're\nin a unique place in human history where we've somehow managed to mine more data\nthan we know what to do with... and a lot of that data is easily accessible via\nAPIs.\n\nWe're going to get our feet wet with REST APIs today, thus allowing us to\ninteract with meaningful information. Making Ajax GET calls with JQuery  is\nperhaps as basic as it gets: there's a good chance we already know all this\nstuff, but even I constantly forget the exact syntax of everyday functions.\nChances are I'm going to come back to this post at some point just to copy and\npaste the snippets below. \n\nIntroduction to REST APIs\nIf you're new to executing AJAX requests, chances are you may be new to REST\nAPIs in general. This crash course is going to be fast and rough around the\nedges, so strap in.\n\nIn the most simple sense, a REST API endpoint is a URL. It just so happens that\nthis URL probably expects more from you than simply visiting it, and as a\nresult, should output something useful for you. API Endpoints will almost always\noutput either JSON or XML; these responses will give you information varying\nfrom error codes to the actual data you seek.\n\nREST APIs expect requests to come in one of the following forms:\n\n * GET: A request looking for read-only data. Some GET requests simply need to\n   be copy and pasted into a browser window to receive results, but usually we\n   need to either authenticate or specify what we're looking for.\n * POST: A write  request to the target resource. Expects that new information\n   will come as a result of this request.\n * PUT: Updates pre-existing data somewhere, likely in some database.\n * PATCH: Somewhat similar to PUT, and in my experience rarely used at all.\n * DELETE: Expects that information will be deleted as a result of the request\n\nIf this all seems like new information, I'd highly recommend downloading Postman\n[https://www.getpostman.com/]  to become familiar with how API calls are\nstructured.\n\nFor now, we'll focus on working with a simple GET endpoint.\n\nLearning By Doing\nIf you've been checking out Snkia's roundup posts\n[https://hackersandslackers.com/tag/roundup/]  lately, you may have noticed\nnifty link previews being generated. To demonstrate how to make API calls via a\nfrontend client with JQuery, we'll be walking through how to create link\npreviews using the LinkPreview API [https://www.linkpreview.net/]. This service\nserves as a good tutorial because:\n\n * It's an example of a simple GET endpoint\n * There's a quick and immediately useful end result\n * It's free\n\nTell me That Ain't Insecurr\nI want to stress here that we're doing this for the sake of learning; while this\nis probably the fastest  way to start working with an API, it is most definitely\n not secure.\n\nMaking calls with private keys stored and passed via the client side exposes\nyour key publicly. In a production environment, this is like shoving your\npassword in people's faces. People will most definitely want to steal and\nexploit your private key: if what you were doing didn't have any value, it\nwouldn't require a key in the first place.\n\nHopefully this has scared you enough to consider passing credentials in the\nfuture. That said, there's another solid reason we selected LinkPreview as\ntoday's example. LinkPreview offers domain whitelisting for requests, so even if\nsomebody did steal your key, they'd only be able to use it from your domain ;).\n\nMake sure you whitelist the domain you'll be working from.Fetch Me Daddy\nGo get started with an API key over at LinkPreview  if you're following along.\nI'm going to assume you already have JQuery  readily available from here\nforward.\n\nTo get started, we'll wait for our document to load, and set two critical\nvariables: the API URL, and our API key.\n\n$( document ).ready(function() {\n  var api_url = 'https://api.linkpreview.net'\n  var key = '5b578yg9yvi8sogirbvegoiufg9v9g579gviuiub8' // not real\n});\n\n\nIf you're following along what we've done with Lynx Roundups, our next step is\nto get all the relevant  <a>  tags on a page, loop through them, and replace\nthem with their respective link previews.\n\n$( document ).ready(function() {\n  var api_url = 'https://api.linkpreview.net'\n  var key = '5b578yg9yvi8sogirbvegoiufg9v9g579gviuiub8' // not real\n  \n  $( \".content a\" ).each(function( index, element ) {\n      console.log($( this ).text());\n  }\n});\n\n\nThe JQuery  .each  method creates a loop which iterates over every element\nmatching the provided selector. In our example, we only want <a>  tags in the\ncontent of our page; otherwise we would get all  links, like navigation links\nand so forth.\n\nNow it's time to bring in that $.ajax()  thing we've been going off about.\n\n$( document ).ready(function() {\n  var api_url = 'https://api.linkpreview.net'\n  var key = '5b578yg9yvi8sogirbvegoiufg9v9g579gviuiub8' // not real\n\n  $( \".content a\" ).each(function( index, element ) {\n\n    $.ajax({\n        url: api_url + \"?key=\" + key + \" &q=\" + $( this ).text(),\n        contentType: \"application/json\",\n        dataType: 'json',\n        success: function(result){\n            console.log(result);\n        }\n    })\n  });\n});\n\n\nThis is how Ajax request are structured: the contents of $.ajax()  is\nessentially an object taking values it will use to construct the request. The\nabove example is about as simple as it gets for making a barebones GET call.\nWe're looping through each <a>  tag and passing its contents (the url) to the\nAPI, and receiving an object in response.\n\nAjax requests can take way more parameters than the ones we just specified. I\nrecommend reading over the JQuery Ajax documentation\n[http://api.jquery.com/jquery.ajax/]  closely; not only for the sake of these\nrequests, but understanding the potential items we can specify will solidify an\nunderstanding for REST APIs in general.\n\nThe line contentType: \"application/json\"  specifies that the content coming back\nto us will be in JSON format - this is a very common header when dealing with\nREST APIs. \n\nWith any luck, your response should come back looking like:\n\n{\n    \"title\":\"Google\",\n    \"description\":\"Search webpages, images, videos and more.\",\n    \"image\":\"https//:www.google.com/images/logo.png\",\n    \"url\":\"https://www.google.com/\"\n}\n\n\nIf you'd like to use this in a meaningful way, feel free to do something like\nthe mess I've put together below:\n\n$( document ).ready(function() {\n  var api_url = 'https://api.linkpreview.net'\n  var key = '5b578yg9yvi8sogirbvegoiufg9v9g579gviuiub8' // not real\n\n  $( \".content a\" ).each(function( index, element ) {\n    $.ajax({\n        url: api_url + \"?key=\" + key + \" &q=\" + $( this ).text(),\n        contentType: \"application/json\",\n        dataType: 'json',\n        success: function(result){\n            $( element ).after(\n            '<a href=\"' + result.url + '\"> \\n ' +\n              '<div class=\"link-preview\"> \\n ' +\n                '<div class=\"preview-image\" style=\"background-image:url(' + result.image + ');\"></div> \\n ' + \n                '<div style=\"width:70%;\" class=\"link-info\"> \\n ' +\n                  '<h4>' + result.title +'</h4> \\n ' +\n                  '<p>' + result.description +'</p> \\n ' +\n                '</div><br> \\n ' +\n                  '<a href=\"' + result.url + '\" class=\"url-info\"><i class=\"far fa-link\"></i>' + result.url + '</a> \\n ' +\n                '</div></a>');\n            $( element ).remove();\n        }\n    })\n  });\n});\n\n\nThat template should serve you well for most GET API calls you're going to make\nvia JQuery. Go wild and see what you can do to leverage APIs and expose some\npeople's personal data or whatever.\n\nSee how I just created HTML by stringing together a bunch of ugly strings in\nJavascript? Don't do that; there are countless better ways to handle this, they\njust so happen to be out of scope for this post.If we were to truly complete\nthis example, we'd want to refine our logic to ensure we're not receiving\nnonsense. There's no validation on what's coming back in these calls, so there's\nnothing in place to protect us in the case that a page doesn't comply with our\nformat.","html":"<p>The information age is over: we have all the information now. All of it. We're in a unique place in human history where we've somehow managed to mine more data than we know what to do with... and a lot of that data is easily accessible via APIs.</p><p>We're going to get our feet wet with REST APIs today, thus allowing us to interact with meaningful information. Making Ajax GET calls with <strong>JQuery</strong> is perhaps as basic as it gets: there's a good chance we already know all this stuff, but even I constantly forget the exact syntax of everyday functions. Chances are I'm going to come back to this post at some point just to copy and paste the snippets below. </p><h2 id=\"introduction-to-rest-apis\">Introduction to REST APIs</h2><p>If you're new to executing AJAX requests, chances are you may be new to REST APIs in general. This crash course is going to be fast and rough around the edges, so strap in.</p><p>In the most simple sense, a REST API endpoint is a URL. It just so happens that this URL probably expects more from you than simply visiting it, and as a result, should output something useful for you. API Endpoints will almost always output either JSON or XML; these responses will give you information varying from error codes to the actual data you seek.</p><p>REST APIs expect requests to come in one of the following forms:</p><ul><li><strong>GET</strong>: A request looking for read-only data. Some GET requests simply need to be copy and pasted into a browser window to receive results, but usually we need to either authenticate or specify what we're looking for.</li><li><strong>POST</strong>: A <em>write</em> request to the target resource. Expects that new information will come as a result of this request.</li><li><strong>PUT</strong>: Updates pre-existing data somewhere, likely in some database.</li><li><strong>PATCH</strong>: Somewhat similar to PUT, and in my experience rarely used at all.</li><li><strong>DELETE: </strong>Expects that information will be deleted as a result of the request</li></ul><p>If this all seems like new information, I'd highly recommend downloading <a href=\"https://www.getpostman.com/\">Postman</a> to become familiar with how API calls are structured.</p><p>For now, we'll focus on working with a simple GET endpoint.</p><h2 id=\"learning-by-doing\">Learning By Doing</h2><p>If you've been checking out <a href=\"https://hackersandslackers.com/tag/roundup/\">Snkia's roundup posts</a> lately, you may have noticed nifty link previews being generated. To demonstrate how to make API calls via a frontend client with <strong>JQuery</strong>, we'll be walking through how to create link previews using the <a href=\"https://www.linkpreview.net/\">LinkPreview API</a>. This service serves as a good tutorial because:</p><ul><li>It's an example of a simple GET endpoint</li><li>There's a quick and immediately useful end result</li><li>It's free</li></ul><h3 id=\"tell-me-that-ain-t-insecurr\">Tell me That Ain't Insecurr</h3><p>I want to stress here that we're doing this for the sake of learning; while this is probably the <em>fastest</em> way to start working with an API, it is most definitely <strong>not secure</strong>.</p><p>Making calls with private keys stored and passed via the client side exposes your key publicly. In a production environment, this is like shoving your password in people's faces. People will most definitely want to steal and exploit your private key: if what you were doing didn't have any value, it wouldn't require a key in the first place.</p><p>Hopefully this has scared you enough to consider passing credentials in the future. That said, there's another solid reason we selected LinkPreview as today's example. LinkPreview offers domain whitelisting for requests, so even if somebody did steal your key, they'd only be able to use it from your domain ;).</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-11-25-at-6.06.44-AM.png\" class=\"kg-image\"><figcaption>Make sure you whitelist the domain you'll be working from.</figcaption></figure><h2 id=\"fetch-me-daddy\">Fetch Me Daddy</h2><p>Go get started with an API key over at <strong>LinkPreview</strong> if you're following along. I'm going to assume you already have <strong>JQuery</strong> readily available from here forward.</p><p>To get started, we'll wait for our document to load, and set two critical variables: the API URL, and our API key.</p><pre><code class=\"language-javascript\">$( document ).ready(function() {\n  var api_url = 'https://api.linkpreview.net'\n  var key = '5b578yg9yvi8sogirbvegoiufg9v9g579gviuiub8' // not real\n});\n</code></pre>\n<p>If you're following along what we've done with Lynx Roundups, our next step is to get all the <em>relevant</em> <code>&lt;a&gt;</code> tags on a page, loop through them, and replace them with their respective link previews.</p><pre><code class=\"language-javascript\">$( document ).ready(function() {\n  var api_url = 'https://api.linkpreview.net'\n  var key = '5b578yg9yvi8sogirbvegoiufg9v9g579gviuiub8' // not real\n  \n  $( &quot;.content a&quot; ).each(function( index, element ) {\n      console.log($( this ).text());\n  }\n});\n</code></pre>\n<p>The <strong>JQuery</strong> <code>.each</code> method creates a loop which iterates over every element matching the provided selector. In our example, we only want <code>&lt;a&gt;</code> tags in the content of our page; otherwise we would get <em>all</em> links, like navigation links and so forth.</p><p>Now it's time to bring in that <code>$.ajax()</code> thing we've been going off about.</p><pre><code class=\"language-javascript\">$( document ).ready(function() {\n  var api_url = 'https://api.linkpreview.net'\n  var key = '5b578yg9yvi8sogirbvegoiufg9v9g579gviuiub8' // not real\n\n  $( &quot;.content a&quot; ).each(function( index, element ) {\n\n    $.ajax({\n        url: api_url + &quot;?key=&quot; + key + &quot; &amp;q=&quot; + $( this ).text(),\n        contentType: &quot;application/json&quot;,\n        dataType: 'json',\n        success: function(result){\n            console.log(result);\n        }\n    })\n  });\n});\n</code></pre>\n<p>This is how Ajax request are structured: the contents of <code>$.ajax()</code> is essentially an object taking values it will use to construct the request. The above example is about as simple as it gets for making a barebones GET call. We're looping through each <code>&lt;a&gt;</code> tag and passing its contents (the url) to the API, and receiving an object in response.</p><p><strong>Ajax </strong>requests can take way more parameters than the ones we just specified. I recommend reading over the <a href=\"http://api.jquery.com/jquery.ajax/\">JQuery Ajax documentation</a> closely; not only for the sake of these requests, but understanding the potential items we can specify will solidify an understanding for REST APIs in general.</p><p>The line <code>contentType: \"application/json\"</code> specifies that the content coming back to us will be in JSON format - this is a very common header when dealing with REST APIs. </p><p>With any luck, your response should come back looking like:</p><pre><code class=\"language-json\">{\n    &quot;title&quot;:&quot;Google&quot;,\n    &quot;description&quot;:&quot;Search webpages, images, videos and more.&quot;,\n    &quot;image&quot;:&quot;https//:www.google.com/images/logo.png&quot;,\n    &quot;url&quot;:&quot;https://www.google.com/&quot;\n}\n</code></pre>\n<p>If you'd like to use this in a meaningful way, feel free to do something like the mess I've put together below:</p><pre><code class=\"language-javascript\">$( document ).ready(function() {\n  var api_url = 'https://api.linkpreview.net'\n  var key = '5b578yg9yvi8sogirbvegoiufg9v9g579gviuiub8' // not real\n\n  $( &quot;.content a&quot; ).each(function( index, element ) {\n    $.ajax({\n        url: api_url + &quot;?key=&quot; + key + &quot; &amp;q=&quot; + $( this ).text(),\n        contentType: &quot;application/json&quot;,\n        dataType: 'json',\n        success: function(result){\n            $( element ).after(\n            '&lt;a href=&quot;' + result.url + '&quot;&gt; \\n ' +\n              '&lt;div class=&quot;link-preview&quot;&gt; \\n ' +\n                '&lt;div class=&quot;preview-image&quot; style=&quot;background-image:url(' + result.image + ');&quot;&gt;&lt;/div&gt; \\n ' + \n                '&lt;div style=&quot;width:70%;&quot; class=&quot;link-info&quot;&gt; \\n ' +\n                  '&lt;h4&gt;' + result.title +'&lt;/h4&gt; \\n ' +\n                  '&lt;p&gt;' + result.description +'&lt;/p&gt; \\n ' +\n                '&lt;/div&gt;&lt;br&gt; \\n ' +\n                  '&lt;a href=&quot;' + result.url + '&quot; class=&quot;url-info&quot;&gt;&lt;i class=&quot;far fa-link&quot;&gt;&lt;/i&gt;' + result.url + '&lt;/a&gt; \\n ' +\n                '&lt;/div&gt;&lt;/a&gt;');\n            $( element ).remove();\n        }\n    })\n  });\n});\n</code></pre>\n<p>That template should serve you well for most GET API calls you're going to make via <strong>JQuery</strong>. Go wild and see what you can do to leverage APIs and expose some people's personal data or whatever.</p><div class=\"protip\">\n    See how I just created HTML by stringing together a bunch of ugly strings in Javascript? Don't do that; there are countless better ways to handle this, they just so happen to be out of scope for this post.\n</div><p>If we were to truly complete this example, we'd want to refine our logic to ensure we're not receiving nonsense. There's no validation on what's coming back in these calls, so there's nothing in place to protect us in the case that a page doesn't comply with our format.</p>","url":"https://hackersandslackers.com/making-ajax-calls-with-jquery/","uuid":"1fbf30e7-7ab7-48bb-8976-f100fdced4e0","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5ade784572a629364c5364c7"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673645","title":"Bedrooms and Kitchens","slug":"bedrooms-and-kitchens","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/04/metaphor@2x.jpg","excerpt":"Never metaphor I didn't like.","custom_excerpt":"Never metaphor I didn't like.","created_at_pretty":"24 April, 2018","published_at_pretty":"24 April, 2018","updated_at_pretty":"25 July, 2018","created_at":"2018-04-24T13:58:59.000-04:00","published_at":"2018-04-24T14:13:11.000-04:00","updated_at":"2018-07-24T22:06:02.000-04:00","meta_title":"Bedrooms and Kitchens | Hackers and Slackers","meta_description":"Never metaphor I didn't like","og_description":"Never metaphor I didn't like","og_image":"https://hackersandslackers.com/content/images/2018/04/metaphor@2x.jpg","og_title":"Bedrooms and Kitchens","twitter_description":"Never metaphor I didn't like","twitter_image":"https://hackersandslackers.com/content/images/2018/04/metaphor@2x.jpg","twitter_title":"Bedrooms and Kitchens","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":null,"tags":[],"plaintext":"Much miscommunication between technical folks and non-technical folks (or\ndifferent kinds of technical folks) stems from the fact that determining how\ndifficult a task is can be very  unintuitive from the outside. Sometimes a thing\ncan be changed by changing a single number, sometimes you have to re-architect\nhalf the system in order to make it, and it's not always obvious which is which.\n\nFor those of you who find yourself in this position, here's a metaphor that you\ncan use[1]  that might make it easier to talk about it:\n\nSome things are adding a bedroom, some things are adding a kitchen.\n\nMaking a room into a bedroom is easy - you just have to add a surface to sleep\non. Actually, you don't even have to do that - any room you can fall asleep in\ncan function as a bedroom. You can even turn a room into multiple bedrooms\nrelatively easily with a bit of drywall!\n\nMaking a room into a kitchen is another matter entirely. It needs gas (or\nappropriate electricity for an electric stove). You probably need to do things\nwith electricity. It needs water. You need to install fixtures. You need large &\nheavy appliances, some of which need to be hooked up to external systems. You\nmight have to shut important things off while you're hooking up your new stuff.\nThere's probably other things too!\n\nI think this adds some good vocabulary to talk about this sort of thing. Let's\nsee if people start saying/asking whether a feature is a \"kitchen\" or a\n\"bedroom\"!\n\n\n--------------------------------------------------------------------------------\n\n 1. With appropriate renumartion, of course. I'll take 2% of your total lifetime\n    earnings for each use. If I find you've violated my intellectual property\n    rights, I won't hesitate to file a DMCA takedown that will retroactively\n    remove any benefit you've derived from using this metaphor (+ punitive\n    damages). ↩︎","html":"<p>Much miscommunication between technical folks and non-technical folks (or different kinds of technical folks) stems from the fact that determining how difficult a task is can be <em>very</em> unintuitive from the outside.  Sometimes a thing can be changed by changing a single number, sometimes you have to re-architect half the system in order to make it, and it's not always obvious which is which.</p>\n<p>For those of you who find yourself in this position, here's a metaphor that you can use<sup class=\"footnote-ref\"><a href=\"#fn1\" id=\"fnref1\">[1]</a></sup> that might make it easier to talk about it:</p>\n<p>Some things are adding a bedroom, some things are adding a kitchen.</p>\n<p>Making a room into a bedroom is easy - you just have to add a surface to sleep on.  Actually, you don't even have to do that - any room you can fall asleep in can function as a bedroom.  You can even turn a room into multiple bedrooms relatively easily with a bit of drywall!</p>\n<p>Making a room into a kitchen is another matter entirely.  It needs gas (or appropriate electricity for an electric stove).  You probably need to do things with electricity.  It needs water.  You need to install fixtures.  You need large &amp; heavy appliances, some of which need to be hooked up to external systems.  You might have to shut important things off while you're hooking up your new stuff.  There's probably other things too!</p>\n<p>I think this adds some good vocabulary to talk about this sort of thing.  Let's see if people start saying/asking whether a feature is a &quot;kitchen&quot; or a &quot;bedroom&quot;!</p>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>With appropriate renumartion, of course.  I'll take 2% of your total lifetime earnings for each use.  If I find you've violated my intellectual property rights, I won't hesitate to file a DMCA takedown that will retroactively remove any benefit you've derived from using this metaphor (+ punitive damages). <a href=\"#fnref1\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n</ol>\n</section>\n","url":"https://hackersandslackers.com/bedrooms-and-kitchens/","uuid":"d60835f5-cb5b-447c-8839-804b8be4e8f3","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5adf70631fbbf808470e16d8"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673643","title":"Lynx Roundup, April 22nd","slug":"lynx-roundup-april-22nd","featured":false,"feature_image":"https://hackersandslackers.com/content/images/lynx/lynx21@2x.jpg","excerpt":"Data science with Snkia.","custom_excerpt":"Data science with Snkia.","created_at_pretty":"23 April, 2018","published_at_pretty":"23 April, 2018","updated_at_pretty":"25 July, 2018","created_at":"2018-04-22T22:24:15.000-04:00","published_at":"2018-04-22T23:11:46.000-04:00","updated_at":"2018-07-24T22:06:02.000-04:00","meta_title":"Lynx Roundup, April 22nd | Hackers and Slackers","meta_description":"Data science with Snkia","og_description":"Data science with Snkia","og_image":"https://hackersandslackers.com/content/images/lynx/lynx21@2x.jpg","og_title":"Lynx Roundup, April 22nd","twitter_description":"Data science with Snkia","twitter_image":"https://hackersandslackers.com/content/images/lynx/lynx21@2x.jpg","twitter_title":"Lynx Roundup, April 22nd","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"Pretty rad, also includes a link to a longer ebook on the subject.\nhttps://medium.com/@kadek/command-line-tricks-for-data-scientists-c98e0abe5da\n\nhttps://www.technologyreview.com/s/603366/mathematical-model-reveals-the-patterns-of-how-innovations-arise\n\nhttps://www.sciencealert.com/scientists-tested-how-much-know-it-alls-actually-know-and-the-results-speak-for-themselves\n\nNever used this, but looks interesting!\nhttps://simonwillison.net/2018/Apr/20/datasette-plugins/\n\nThere's a lot of overhead involved in making even pretty trivial blockchain\nstuff. I made a demo app with Hyperledger last year, and it took a lot just to\nbe able to set it up and have it be viewable.\nhttps://aws.amazon.com/about-aws/whats-new/2018/04/introducing-aws-blockchain-templates/\n\nVery neat bit of...Philosophy of Science? Sociology of Engineering?\nhttps://the-composition.com/the-origins-of-opera-and-the-future-of-programming-bcdaf8fbe960\n\nhttps://fosterelli.co/executing-gradient-descent-on-the-earth\n\nhttp://blog.pragmaticengineer.com/distributed-architecture-concepts-i-have-learned-while-building-payments-systems/\n\nhttps://www.theatlantic.com/magazine/archive/2018/05/barbara-ehrenreich-natural-causes/556859/\n\nI'm definitely in the camp that says AI is an experimental science (particularly\nDeep Learning stuff, but also generally). But hey, don't take my word for it,\nhere's Turing hisself from the original AI paper: \"Machines take me by surprise\nwith great frequency...The view that machines cannot give rise to surprises is\ndue, I believe, to a fallacy to which philosophers and mathematicians are\nparticularly subject. This is the assumption that as soon as a fact is presented\nto a mind all consequences of that fact spring into the mind simultaneously with\nit. It is a very useful assumption under many circumstances, but one too easily\nforgets that it is false.\" (by the way, if you've never read it, it's extremely\nreadable and absolutely worth reading)\nhttp://aiweirdness.com/post/172894792687/when-algorithms-surprise-us\n\nAlong somewhat similar lines (though trying to do the opposite):\nhttps://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\n\nI think this really gets at the heart of where quant-y people get crossed up\nwhen they have to do certain types of code-y things. As soon as I'm outside of\nthe realm of \"doing operations on data\", I'm on edge. If I'm, say, interacting\nwith a database from Python, I'm generally doing so in a way that hides as many\nof the details of connections & cursors as much as possible.\nhttps://twitter.com/kelseyhightower/status/985920494728720384\n\nhttps://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7","html":"<p>Pretty rad, also includes a link to a longer ebook on the subject.<br>\n<a href=\"https://medium.com/@kadek/command-line-tricks-for-data-scientists-c98e0abe5da\">https://medium.com/@kadek/command-line-tricks-for-data-scientists-c98e0abe5da</a></p>\n<p><a href=\"https://www.technologyreview.com/s/603366/mathematical-model-reveals-the-patterns-of-how-innovations-arise\">https://www.technologyreview.com/s/603366/mathematical-model-reveals-the-patterns-of-how-innovations-arise</a></p>\n<p><a href=\"https://www.sciencealert.com/scientists-tested-how-much-know-it-alls-actually-know-and-the-results-speak-for-themselves\">https://www.sciencealert.com/scientists-tested-how-much-know-it-alls-actually-know-and-the-results-speak-for-themselves</a></p>\n<p>Never used this, but looks interesting!<br>\n<a href=\"https://simonwillison.net/2018/Apr/20/datasette-plugins/\">https://simonwillison.net/2018/Apr/20/datasette-plugins/</a></p>\n<p>There's a lot of overhead involved in making even pretty trivial blockchain stuff.  I made a demo app with Hyperledger last year, and it took a lot just to be able to set it up and have it be viewable.<br>\n<a href=\"https://aws.amazon.com/about-aws/whats-new/2018/04/introducing-aws-blockchain-templates/\">https://aws.amazon.com/about-aws/whats-new/2018/04/introducing-aws-blockchain-templates/</a></p>\n<p>Very neat bit of...Philosophy of Science?  Sociology of Engineering?<br>\n<a href=\"https://the-composition.com/the-origins-of-opera-and-the-future-of-programming-bcdaf8fbe960\">https://the-composition.com/the-origins-of-opera-and-the-future-of-programming-bcdaf8fbe960</a></p>\n<p><a href=\"https://fosterelli.co/executing-gradient-descent-on-the-earth\">https://fosterelli.co/executing-gradient-descent-on-the-earth</a></p>\n<p><a href=\"http://blog.pragmaticengineer.com/distributed-architecture-concepts-i-have-learned-while-building-payments-systems/\">http://blog.pragmaticengineer.com/distributed-architecture-concepts-i-have-learned-while-building-payments-systems/</a></p>\n<p><a href=\"https://www.theatlantic.com/magazine/archive/2018/05/barbara-ehrenreich-natural-causes/556859/\">https://www.theatlantic.com/magazine/archive/2018/05/barbara-ehrenreich-natural-causes/556859/</a></p>\n<p>I'm definitely in the camp that says AI is an experimental science (particularly Deep Learning stuff, but also generally).  But hey, don't take my word for it, here's Turing hisself from the original AI paper: &quot;Machines take me by surprise with great frequency...The view that machines cannot give rise to surprises is due, I believe, to a fallacy to which philosophers and mathematicians are particularly subject. This is the assumption that as soon as a fact is presented to a mind all consequences of that fact spring into the mind simultaneously with it. It is a very useful assumption under many circumstances, but one too easily forgets that it is false.&quot;  (by the way, if you've never read it, it's extremely readable and absolutely worth reading)<br>\n<a href=\"http://aiweirdness.com/post/172894792687/when-algorithms-surprise-us\">http://aiweirdness.com/post/172894792687/when-algorithms-surprise-us</a></p>\n<p>Along somewhat similar lines (though trying to do the opposite):<br>\n<a href=\"https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\">https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27</a></p>\n<p>I think this really gets at the heart of where quant-y people get crossed up when they have to do certain types of code-y things.  As soon as I'm outside of the realm of &quot;doing operations on data&quot;, I'm on edge.  If I'm, say, interacting with a database from Python, I'm generally doing so in a way that hides as many of the details of connections &amp; cursors as much as possible.<br>\n<a href=\"https://twitter.com/kelseyhightower/status/985920494728720384\">https://twitter.com/kelseyhightower/status/985920494728720384</a></p>\n<p><a href=\"https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7\">https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7</a></p>\n","url":"https://hackersandslackers.com/lynx-roundup-april-22nd/","uuid":"b002e1d3-10e4-4477-a93f-c0a8ab4b503a","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5add43cfc142de276c90e369"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673641","title":"Accessing Self-Hosted MySQL  Externally","slug":"accessing-mysql-from-external-domains","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/mysql2-2.jpg","excerpt":"Connecting to MySQL instances hosted on a VPS.","custom_excerpt":"Connecting to MySQL instances hosted on a VPS.","created_at_pretty":"22 April, 2018","published_at_pretty":"22 April, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-04-22T16:27:48.000-04:00","published_at":"2018-04-22T17:20:18.000-04:00","updated_at":"2019-03-28T04:54:42.000-04:00","meta_title":"Accessing MySQL Externally | Hackers and Slackers","meta_description":"How to configure a remote instance of MySQL to accept external connections.","og_description":"How to configure a remote instance of MySQL to accept external connections.","og_image":"https://hackersandslackers.com/content/images/2019/03/mysql2-2.jpg","og_title":"Accessing MySQL Externally","twitter_description":"How to configure a remote instance of MySQL to accept external connections.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/mysql2-2.jpg","twitter_title":"Accessing MySQL Externally","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"#Working with MySQL","slug":"working-with-mysql","description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysql1_o-1.jpg","meta_description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","meta_title":"Working with MySQL","visibility":"internal"}],"plaintext":"In the previous post [https://hackersandslackers.com/set-up-mysql-database/], we\ngot familiar with the basics of creating and navigating MySQL databases. This\nleads us to the next most logical thing to ask: how can I use this in any\nmeaningful way?\n\nMySQL installations default to refusing connections outside of the local\nmachine's IP address, as we should expect. That said, relational databases\naren't usually being used by a single person on a single machine forever (but if\nyou do, we should hang out). It goes without saying that our MySQL instance\nshould be focusing on uptime and accessibility, or in other terms, far away from\nour destructive personalities.\n\nI adore maintaining databases in the command line as much as the next\nself-hating masochist, but we'll need to accomplish work at some point. That\nmeans the remote database we just set up needs to be open-minded enough to allow\na connection from, say, the IP address of our personal local machine, which\nhappens to have a sexy GUI installed for this very purpose.\n\nMaking these kinds of configuration changes to any service or web server is\nalways a bit of fun. You think your day might suck until you cone home and a\npiece of software treats you like a cyber criminal, kicking and screaming while\nwe attempt the most basic out-of-the-box functionality.\n\nThe fine print here is that we wouldn't recommend messing with any of these\nsettings unless you know what you're doing. Then again, if you knew what you\nwere doing you probably wouldn't be reading this. The point is, if you mess up,\nit's your fault because we warned you.\n\nThe first thing we'll need to touch is the MySQL config found here on Ubuntu:\n\nvim /etc/mysql/mysql.conf.d/mysqld.cnf\n\n\nHere you can set various configurations for MySQL, such as the port number,\ndefault user, etc. The line we're interested in is bind-address.\n\n# The MySQL database server configuration file.\n#\n# You can copy this to one of:\n# - \"/etc/mysql/my.cnf\" to set global options,\n# - \"~/.my.cnf\" to set user-specific options.\n# \n# One can use all long options that the program supports.\n# Run program with --help to get a list of available options and with\n# --print-defaults to see which it would actually understand and use.\n#\n# For explanations see\n# http://dev.mysql.com/doc/mysql/en/server-system-variables.html\n\n# This will be passed to all mysql clients\n# It has been reported that passwords should be enclosed with ticks/quotes\n# escpecially if they contain \"#\" chars...\n# Remember to edit /etc/mysql/debian.cnf when changing the socket location.\n\n# Here is entries for some specific programs\n# The following values assume you have at least 32M ram\n\n[mysqld_safe]\nsocket          = /var/run/mysqld/mysqld.sock\nnice            = 0\n\n[mysqld]\n#\n# * Basic Settings\n#\nuser            = mysql\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nport            = 3306\nbasedir         = /usr\ndatadir         = /var/lib/mysql\ntmpdir          = /tmp\nlc-messages-dir = /usr/share/mysql\nskip-external-locking\n#\n# Instead of skip-networking the default is now to listen only on\n# localhost which is more compatible and is not less secure.\nbind-address           = 127.0.0.1\n\n\nBy default, bind-address is set to your local host. This is basically a\nwhitelist that allows changes only from the domains or IP addresses specified.\nYou can go ahead and add the address of the external domain you'd like to grant\naccess to here.\n\nCommenting out the line completely opens up MySQL to everybody. So there's that.\n\nNow we need to create a user with which to access the DBL:\n\nmysql -u root -p -h localhost -P 3306\n\n\nUse the CREATE USER  command to create a new homie. In the example below,\n'newuser' is the name of the new user, and '%' is from which location the user\nwill be permitted to make changes. This is usually 'localhost', for example. In\nthis case, we added '%' which means everywhere.\n\nmysql> CREATE USER ‘newuser’@‘%' IDENTIFIED BY ‘password123’;\n\n\nGrant all privileges to the new user, and always flush privileges  after making\nsuch modifications.\n\nmysql> GRANT ALL ON *.* to newuser@'%' IDENTIFIED BY 'password123';\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\n\nmysql> FLUSH PRIVILEGES;\nQuery OK, 0 rows affected (0.00 sec)\n\n\nWith these changes made, restart MySQL.\n\nservice mysql restart\n\n\nAssuming this was done correctly, your DB should now be able to receive\nread/write queries from an external source, provided the correct username and\npassword are used.","html":"<p>In the <a href=\"https://hackersandslackers.com/set-up-mysql-database/\">previous post</a>, we got familiar with the basics of creating and navigating MySQL databases. This leads us to the next most logical thing to ask: how can I use this in any meaningful way?</p><p>MySQL installations default to refusing connections outside of the local machine's IP address, as we should expect. That said, relational databases aren't usually being used by a single person on a single machine forever (but if you do, we should hang out). It goes without saying that our MySQL instance should be focusing on uptime and accessibility, or in other terms, far away from our destructive personalities.</p><p>I adore maintaining databases in the command line as much as the next self-hating masochist, but we'll need to accomplish work at some point. That means the remote database we just set up needs to be open-minded enough to allow a connection from, say, the IP address of our personal local machine, which happens to have a sexy GUI installed for this very purpose.</p><p>Making these kinds of configuration changes to any service or web server is always a bit of fun. You think your day might suck until you cone home and a piece of software treats you like a cyber criminal, kicking and screaming while we attempt the most basic out-of-the-box functionality.</p><p>The fine print here is that we wouldn't recommend messing with any of these settings unless you know what you're doing. Then again, if you knew what you were doing you probably wouldn't be reading this. The point is, if you mess up, it's your fault because we warned you.</p><p>The first thing we'll need to touch is the MySQL config found here on Ubuntu:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">vim /etc/mysql/mysql.conf.d/mysqld.cnf\n</code></pre>\n<!--kg-card-end: markdown--><p>Here you can set various configurations for MySQL, such as the port number, default user, etc. The line we're interested in is <em>bind-address.</em></p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\"># The MySQL database server configuration file.\n#\n# You can copy this to one of:\n# - &quot;/etc/mysql/my.cnf&quot; to set global options,\n# - &quot;~/.my.cnf&quot; to set user-specific options.\n# \n# One can use all long options that the program supports.\n# Run program with --help to get a list of available options and with\n# --print-defaults to see which it would actually understand and use.\n#\n# For explanations see\n# http://dev.mysql.com/doc/mysql/en/server-system-variables.html\n\n# This will be passed to all mysql clients\n# It has been reported that passwords should be enclosed with ticks/quotes\n# escpecially if they contain &quot;#&quot; chars...\n# Remember to edit /etc/mysql/debian.cnf when changing the socket location.\n\n# Here is entries for some specific programs\n# The following values assume you have at least 32M ram\n\n[mysqld_safe]\nsocket          = /var/run/mysqld/mysqld.sock\nnice            = 0\n\n[mysqld]\n#\n# * Basic Settings\n#\nuser            = mysql\npid-file        = /var/run/mysqld/mysqld.pid\nsocket          = /var/run/mysqld/mysqld.sock\nport            = 3306\nbasedir         = /usr\ndatadir         = /var/lib/mysql\ntmpdir          = /tmp\nlc-messages-dir = /usr/share/mysql\nskip-external-locking\n#\n# Instead of skip-networking the default is now to listen only on\n# localhost which is more compatible and is not less secure.\nbind-address           = 127.0.0.1\n</code></pre>\n<!--kg-card-end: markdown--><p>By default, bind-address is set to your local host. This is basically a whitelist that allows changes only from the domains or IP addresses specified. You can go ahead and add the address of the external domain you'd like to grant access to here.</p><p>Commenting out the line completely opens up MySQL to everybody. So there's that.</p><p>Now we need to create a user with which to access the DBL:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql -u root -p -h localhost -P 3306\n</code></pre>\n<!--kg-card-end: markdown--><p>Use the <em>CREATE USER</em> command to create a new homie. In the example below, 'newuser' is the name of the new user, and '%' is from which location the user will be permitted to make changes. This is usually 'localhost', for example. In this case, we added '%' which means <em>everywhere.</em></p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; CREATE USER ‘newuser’@‘%' IDENTIFIED BY ‘password123’;\n</code></pre>\n<!--kg-card-end: markdown--><p>Grant all privileges to the new user, and always <code>flush privileges</code> after making such modifications.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; GRANT ALL ON *.* to newuser@'%' IDENTIFIED BY 'password123';\nQuery OK, 0 rows affected, 1 warning (0.00 sec)\n\nmysql&gt; FLUSH PRIVILEGES;\nQuery OK, 0 rows affected (0.00 sec)\n</code></pre>\n<!--kg-card-end: markdown--><p>With these changes made, restart MySQL.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">service mysql restart\n</code></pre>\n<!--kg-card-end: markdown--><p>Assuming this was done correctly, your DB should now be able to receive read/write queries from an external source, provided the correct username and password are used.</p>","url":"https://hackersandslackers.com/accessing-mysql-from-external-domains/","uuid":"ca2500b8-b307-4b1c-8ccd-d9cdf4f1e8eb","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5adcf04441f6cf7b7a136a4a"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673640","title":"Link Roundup, April 19th","slug":"link-roundup-april-19th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/118.jpg","excerpt":"Data science with Snkia.","custom_excerpt":"Data science with Snkia.","created_at_pretty":"20 April, 2018","published_at_pretty":"20 April, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-04-19T21:55:32.000-04:00","published_at":"2018-04-19T22:18:59.000-04:00","updated_at":"2019-04-10T02:44:28.000-04:00","meta_title":"Link Roundup, April 19th | Hackers and Slackers","meta_description":"Data science with Snkia","og_description":"Data science with Snkia","og_image":"https://hackersandslackers.com/content/images/2019/04/118-2.jpg","og_title":"Link Roundup, April 19th","twitter_description":"Data science with Snkia","twitter_image":"https://hackersandslackers.com/content/images/2019/04/118-1.jpg","twitter_title":"Link Roundup, April 19th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"Useful little rundown!\n\nhttps://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques\n\nI really, really like the idea of eventually doing data stuff in Clojure.\n Python's got some fundamental issues with scalability, and R's not really\nbetter in that regard.  Clojure's a joy to code in, and the fact that it targets\nthe JVM means that a good set of bindings to Spark (+ friends) would probably be\nable to keep pace better than the Python bindings (which are excellent, but I've\ncome across times where I'd have to drop into Scala, which I don't know and\nseems more intimidating than a friendly Lisp).\n\nhttps://github.com/hswick/jutsu.ai\n\nhttps://www.quantamagazine.org/how-many-genes-do-cells-need-maybe-almost-all-of-them-20180419/\n\nTechnology's cool\n\nhttps://spectrum.ieee.org/geek-life/profiles/why-your-gps-receiver-isnt-bigger-than-a-breadbox\n\nFriendly breakdown of how we got here!\n\nhttps://www.kdnuggets.com/2018/04/derivation-convolutional-neural-network-fully-connected-step-by-step.html\n\nhttp://wesmckinney.com/blog/announcing-ursalabs/\n\nSounds exciting!  Especially if it turns into a better model for Open Source to\nsustain itself.\n\nhttps://www.quantamagazine.org/new-brain-maps-with-unmatched-detail-may-change-neuroscience-20180404/\n\nMeanwhile, in Scotland...\n\nhttps://www.theguardian.com/environment/2018/apr/19/very-angry-badger-causes-part-of-scottish-castle-to-be-closed-to-public\n\nhttps://www.quantamagazine.org/ultra-accurate-clocks-lead-search-for-new-laws-of-physics-20180416/\n\nhttps://medium.com/applied-data-science/how-to-build-your-own-world-model-using-python-and-keras-64fb388ba459\n\nAn AI got trained to turn a script into a cartoon.  This, when combined with\nthat DeepFake thing Jordan Peale used to make that fake Obama PSA, is definitely\ngoing to cause the end of the world.  Exciting!\n\nhttps://arxiv.org/pdf/1804.03608.pdf\n\nI'm into anything that can be summarized as \"Do X, except in one function call\".\n\nhttps://medium.com/@keeper6928/mltest-automatically-test-neural-network-models-in-one-function-call-eb6f1fa5019d\n\nhttps://hackernoon.com/ethereum-smart-contracts-in-python-a-comprehensive-ish-guide-771b03990988\n\nHashtag Goals:","html":"<p>Useful little rundown!</p><p><a href=\"https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques\">https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques</a></p><p>I really, really like the idea of eventually doing data stuff in Clojure.  Python's got some fundamental issues with scalability, and R's not really better in that regard.  Clojure's a joy to code in, and the fact that it targets the JVM means that a good set of bindings to Spark (+ friends) would probably be able to keep pace better than the Python bindings (which are excellent, but I've come across times where I'd have to drop into Scala, which I don't know and seems more intimidating than a friendly Lisp).</p><p><a href=\"https://github.com/hswick/jutsu.ai\">https://github.com/hswick/jutsu.ai</a></p><p><a href=\"https://www.quantamagazine.org/how-many-genes-do-cells-need-maybe-almost-all-of-them-20180419/\">https://www.quantamagazine.org/how-many-genes-do-cells-need-maybe-almost-all-of-them-20180419/</a></p><p>Technology's cool</p><p><a href=\"https://spectrum.ieee.org/geek-life/profiles/why-your-gps-receiver-isnt-bigger-than-a-breadbox\">https://spectrum.ieee.org/geek-life/profiles/why-your-gps-receiver-isnt-bigger-than-a-breadbox</a></p><p>Friendly breakdown of how we got here!</p><p><a href=\"https://www.kdnuggets.com/2018/04/derivation-convolutional-neural-network-fully-connected-step-by-step.html\">https://www.kdnuggets.com/2018/04/derivation-convolutional-neural-network-fully-connected-step-by-step.html</a></p><p><a href=\"http://wesmckinney.com/blog/announcing-ursalabs/\">http://wesmckinney.com/blog/announcing-ursalabs/</a></p><p>Sounds exciting!  Especially if it turns into a better model for Open Source to sustain itself.</p><p><a href=\"https://www.quantamagazine.org/new-brain-maps-with-unmatched-detail-may-change-neuroscience-20180404/\">https://www.quantamagazine.org/new-brain-maps-with-unmatched-detail-may-change-neuroscience-20180404/</a></p><p>Meanwhile, in Scotland...</p><p><a href=\"https://www.theguardian.com/environment/2018/apr/19/very-angry-badger-causes-part-of-scottish-castle-to-be-closed-to-public\">https://www.theguardian.com/environment/2018/apr/19/very-angry-badger-causes-part-of-scottish-castle-to-be-closed-to-public</a></p><p><a href=\"https://www.quantamagazine.org/ultra-accurate-clocks-lead-search-for-new-laws-of-physics-20180416/\">https://www.quantamagazine.org/ultra-accurate-clocks-lead-search-for-new-laws-of-physics-20180416/</a></p><p><a href=\"https://medium.com/applied-data-science/how-to-build-your-own-world-model-using-python-and-keras-64fb388ba459\">https://medium.com/applied-data-science/how-to-build-your-own-world-model-using-python-and-keras-64fb388ba459</a></p><p>An AI got trained to turn a script into a cartoon.  This, when combined with that DeepFake thing Jordan Peale used to make that fake Obama PSA, is definitely going to cause the end of the world.  Exciting!</p><p><a href=\"https://arxiv.org/pdf/1804.03608.pdf\">https://arxiv.org/pdf/1804.03608.pdf</a></p><p>I'm into anything that can be summarized as \"Do X, except in one function call\".</p><p><a href=\"https://medium.com/@keeper6928/mltest-automatically-test-neural-network-models-in-one-function-call-eb6f1fa5019d\">https://medium.com/@keeper6928/mltest-automatically-test-neural-network-models-in-one-function-call-eb6f1fa5019d</a></p><p><a href=\"https://hackernoon.com/ethereum-smart-contracts-in-python-a-comprehensive-ish-guide-771b03990988\">https://hackernoon.com/ethereum-smart-contracts-in-python-a-comprehensive-ish-guide-771b03990988</a></p><p>Hashtag Goals:</p>","url":"https://hackersandslackers.com/link-roundup-april-19th/","uuid":"7544a238-9275-410a-940d-ac7700c1b802","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5ad948940929987df099ebaf"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673636","title":"Dropping Rows of Data Using Pandas","slug":"pandas-dataframe-drop","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/pandasmerge-2.jpg","excerpt":"Square one of cleaning your Pandas Dataframes: dropping empty or problematic data.","custom_excerpt":"Square one of cleaning your Pandas Dataframes: dropping empty or problematic data.","created_at_pretty":"22 November, 2017","published_at_pretty":"18 April, 2018","updated_at_pretty":"08 March, 2019","created_at":"2017-11-22T01:21:36.000-05:00","published_at":"2018-04-18T15:00:00.000-04:00","updated_at":"2019-03-08T14:23:37.000-05:00","meta_title":"Dropping Rows Using Pandas | Hackers and Slackers","meta_description":"Cleaning your Pandas Dataframes: dropping empty or problematic data. Learn the basic methods to get our data workable in a timely fashion.","og_description":"Cleaning your Pandas Dataframes: dropping empty or problematic data. Learn the basic methods to get our data workable in a timely fashion.","og_image":"https://hackersandslackers.com/content/images/2019/03/pandasmerge-2.jpg","og_title":"Dropping Rows Using Pandas","twitter_description":"Cleaning your Pandas Dataframes: dropping empty or problematic data. Learn the basic methods to get our data workable in a timely fashion.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/pandasmerge-2.jpg","twitter_title":"Dropping Rows Using Pandas","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Analysis","slug":"data-analysis","description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","feature_image":null,"meta_description":"Drawing meaningful conclusions from data. Includes interpretation, dashboard creation, and data manipulation.","meta_title":"Data Analysis | Hackers and Slackers","visibility":"public"},{"name":"#Data Analysis with Pandas","slug":"data-analysis-pandas","description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pandasseries-1.jpg","meta_description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","meta_title":"Data Analysis with Pandas","visibility":"internal"}],"plaintext":"You've heard the cliché before: it is often cited that roughly %80~ of a data\nscientist's role is dedicated to cleaning data sets. I Personally haven't looked\nin to the papers or clinical trials which prove this number (that was a joke),\nbut the idea holds true: in the data profession, we find ourselves doing away\nwith blatantly corrupt or useless data. The simplistic approach is to discard\nsuch data entirely, thus here we are.\n\nWhat constitutes 'filthy' data is project-specific, and at times borderline\nsubjective. Occasionally, the offenders are more obvious: these might include\nchunks of data which are empty, poorly formatted, or simply irrelevant. While\n'bad' data can occasionally be fixed or salvaged via transforms, in many cases\nit's best to do away with rows entirely to ensure that only the fittest survive.\n\nDrop Empty Rows or Columns\nIf you're looking to drop rows (or columns) containing empty data, you're in\nluck: Pandas' dropna()  method is specifically for this. \n\nUsing dropna()  is a simple one-liner which accepts a number of useful\narguments:\n\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop rows with any empty cells\nmy_dataframe.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n\nTechnically you could run MyDataFrame.dropna()  without any parameters, and this\n would default to dropping all rows where are completely empty. If thats all you\nneeded, well, I guess you're done already. Otherwise, here are the parameters\nyou can include:\n\n * Axis: Specifies to drop by row  or column. 0  means row, 1  means column.\n * How: Accepts one of two possible values: any  or all. This will either drop\n   an axis which is completely empty (all), or an axis with even just a single\n   empty cell (any).\n * Thresh: Here's an interesting one: thresh  accepts an integer, and will drop\n   an axis only if that number threshold of empty cells is breached.\n * Subset: Accepts an array of which axis' to consider, as opposed to\n   considering all by default.\n * Inplace: If you haven't come across inplace  yet, learn this now: changes\n   will NOT be made to the DataFrame you're touching unless this is set to True.\n   It's False  by default.\n\nPandas' .drop() Method\nThe pandas .drop()  method is used to remove entire rows or columns based on\ntheir name. If we can see that our DataFrame contains extraneous information\n(perhaps for example, the HR team is storing a preferred_icecream_flavor  in\ntheir master records), we can destroy the column (or row) outright.\n\nUsing drop()  looks something like this:\n\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\nmy_dataframe.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n\n\nWe'll attempt to cover the usage of these parameters in plain English before\ninevitably falling into useless lingo which you have not yet learned.\n\n *   Axis: Similar to the above, setting the axis specifies if you're trying to\n   drop rows or columns. \n *   Labels: May refer to either the name (string) of the target axis, or its\n   index (int). Of course, whether this is referring to columns or rows in the\n   DataFrame is dependent on the value of the axis parameter. Labels are always\n   defined in the 0th axis of the target DataFrame, and may accept multiple\n   values in the form of an array when dropping multiple rows/columns at once. \n\nDrop by Index:\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop by row or column index\nmy_dataframe.drop([0, 1])\n\n\nDrop by Label:\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop by column name\nmy_dataframe.drop(['B', 'C'])\n\n\n *   Index, Columns: An alternative method for specifying the same as the above.\n   Accepts single or multiple values. Setting columns=labels  is equivalent to \n   labels, axis=1.  index=0* is equivalent to *labels=0.  \n *   Levels: Used in sets of data which contain multiple hierarchical levels,\n   similar to that of nested arrays. A high-level few of Hierarchical indexing\n   can be found here\n   [https://pandas.pydata.org/pandas-docs/stable/advanced.html]. \n *   Inplace: Again, drop methods are not carried out on the target Dataframe\n   unless explicitly stated. The purpose of this is to presumably preserve the\n   original set of data during ad hoc manipulation.This adheres to the Python\n   style-guide which states that actions should not be performed on live sets of\n   data unless explicitly stated. Here\n   [https://www.youtube.com/watch?v=XaCSdr7pPmY]  is a video of some guy\n   describing this for some reason. \n *   Errors: Accepts either ignore  or raise, with 'raise' set as default. When \n   errors='ignore'  is set, no errors will be thrown and existing labels are\n   dropped. \n\nDrop by Criteria\nWe can also remove rows or columns based on whichever criteria your little heart\ndesires. For example, if you really hate people named Chad, you can drop all\nrows in your Customer database who have the name Chad. Screw Chad.\n\nUnlike previous methods, the popular way of handling this is simply by saving\nyour Dataframe over itself give a passed value. Here's how we'd get rid of Chad:\n\nimport pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop via logic: similar to SQL 'WHERE' clause\nmy_dataframe = my_dataframe[my_dataframe.employee_name != 'chad')]\n\n\nThe syntax may seem a bit off-putting to newcomers (note the repetition of \nmy_dataframe  3 times). The format of my_dataframe[CONDITION]  simply returns a\nmodified version of my_dataframe, where only the data matching the given\ncondition is affected. \n\nSince we're purging this data altogether, statingmy_dataframe =\nmy_dataframe[CONDITION]  is an easy (albeit destructive) method for shedding\ndata and moving on with our lives.","html":"<p>You've heard the cliché before: it is often cited that roughly %80~ of a data scientist's role is dedicated to cleaning data sets. I Personally haven't looked in to the papers or clinical trials which prove this number (that was a joke), but the idea holds true: in the data profession, we find ourselves doing away with blatantly corrupt or useless data. The simplistic approach is to discard such data entirely, thus here we are.</p><p>What constitutes 'filthy' data is project-specific, and at times borderline subjective. Occasionally, the offenders are more obvious: these might include chunks of data which are empty, poorly formatted, or simply irrelevant. While 'bad' data can occasionally be fixed or salvaged via transforms, in many cases it's best to do away with rows entirely to ensure that only the fittest survive.</p><h2 id=\"drop-empty-rows-or-columns\">Drop Empty Rows or Columns</h2><p>If you're looking to drop rows (or columns) containing empty data, you're in luck: Pandas' <code>dropna()</code> method is specifically for this. </p><p>Using <code>dropna()</code> is a simple one-liner which accepts a number of useful arguments:</p><!--kg-card-begin: code--><pre><code>import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop rows with any empty cells\nmy_dataframe.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)</code></pre><!--kg-card-end: code--><p>Technically you could run <code>MyDataFrame.dropna()</code> without any parameters, and this  would default to dropping all rows where are completely empty. If thats all you needed, well, I guess you're done already. Otherwise, here are the parameters you can include:</p><ul><li><strong>Axis</strong>: Specifies to drop by <em>row</em> or <em>column</em>. <code>0</code> means <em>row</em>, <code>1</code> means <em>column</em>.</li><li><strong>How</strong>: Accepts one of two possible values: <em>any</em> or <em>all</em>. This will either drop an axis which is completely empty (all), or an axis with even just a single empty cell (any).</li><li><strong>Thresh</strong>: Here's an interesting one: <em>thresh</em> accepts an integer, and will drop an axis only if that number threshold of empty cells is breached.</li><li><strong>Subset</strong>: Accepts an array of which axis' to consider, as opposed to considering all by default.</li><li><strong>Inplace</strong>: If you haven't come across <code>inplace</code> yet, learn this now: changes will NOT be made to the DataFrame you're touching unless this is set to <code>True</code>. It's <code>False</code> by default.</li></ul><h2 id=\"pandas-drop-method\">Pandas' .drop() Method</h2><p>The pandas <code>.drop()</code> method is used to remove entire rows or columns based on their name. If we can see that our DataFrame contains extraneous information (perhaps for example, the HR team is storing a <strong>preferred_icecream_flavor</strong> in their master records), we can destroy the column (or row) outright.</p><p>Using <code>drop()</code> looks something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\nmy_dataframe.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n</code></pre>\n<!--kg-card-end: markdown--><p>We'll attempt to cover the usage of these parameters in plain English before inevitably falling into useless lingo which you have not yet learned.</p><ul><li> <strong>Axis</strong>: Similar to the above, setting the axis specifies if you're trying to drop rows or columns. </li><li> <strong>Labels</strong>: May refer to either the name (string) of the target axis, or its index (int). Of course, whether this is referring to columns or rows in the DataFrame is dependent on the value of the axis parameter. Labels are always defined in the 0th axis of the target DataFrame, and may accept multiple values in the form of an array when dropping multiple rows/columns at once. </li></ul><h3 id=\"drop-by-index-\">Drop by Index:</h3><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop by row or column index\nmy_dataframe.drop([0, 1])\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"drop-by-label-\">Drop by Label:</h3><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop by column name\nmy_dataframe.drop(['B', 'C'])\n</code></pre>\n<!--kg-card-end: markdown--><ul><li> <strong>Index, Columns</strong>: An alternative method for specifying the same as the above. Accepts single or multiple values. Setting <em>columns=labels</em> is equivalent to <em>labels, axis=1.</em> <em>index=0</em>* is equivalent to *<em>labels=0.</em> </li><li> <strong>Levels</strong>: Used in sets of data which contain multiple hierarchical levels, similar to that of nested arrays. A high-level few of Hierarchical indexing can be found <a href=\"https://pandas.pydata.org/pandas-docs/stable/advanced.html\">here</a>. </li><li> <strong>Inplace</strong>: Again, drop methods are not carried out on the target Dataframe unless explicitly stated. The purpose of this is to presumably preserve the original set of data during ad hoc manipulation.This adheres to the Python style-guide which states that actions should not be performed on live sets of data unless explicitly stated. <a href=\"https://www.youtube.com/watch?v=XaCSdr7pPmY\">Here</a> is a video of some guy describing this for some reason. </li><li> <strong>Errors</strong>: Accepts either <em>ignore</em> or <em>raise</em>, with 'raise' set as default. When <em>errors='ignore'</em> is set, no errors will be thrown and existing labels are dropped. </li></ul><h2 id=\"drop-by-criteria\">Drop by Criteria</h2><p>We can also remove rows or columns based on whichever criteria your little heart desires. For example, if you really hate people named Chad, you can drop all rows in your Customer database who have the name Chad. Screw Chad.</p><p>Unlike previous methods, the popular way of handling this is simply by saving your Dataframe over itself give a passed value. Here's how we'd get rid of Chad:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import pandas as pd\n\n# Create a Dataframe from CSV\nmy_dataframe = pd.read_csv('example.csv')\n\n# Drop via logic: similar to SQL 'WHERE' clause\nmy_dataframe = my_dataframe[my_dataframe.employee_name != 'chad')]\n</code></pre>\n<!--kg-card-end: markdown--><p>The syntax may seem a bit off-putting to newcomers (note the repetition of <code>my_dataframe</code> 3 times). The format of <code>my_dataframe[CONDITION]</code> simply returns a modified version of <code>my_dataframe</code>, where only the data matching the given condition is affected. </p><p>Since we're purging this data altogether, stating  <code>my_dataframe = my_dataframe[CONDITION]</code> is an easy (albeit destructive) method for shedding data and moving on with our lives.</p>","url":"https://hackersandslackers.com/pandas-dataframe-drop/","uuid":"6f57d667-6bab-4d97-a62a-adfb2e887d6c","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5a151770ade7aa41676efce7"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867363e","title":"Link Roundup, April 18th","slug":"link-roundup-april-18th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/109.jpg","excerpt":"Data science with Snkia.","custom_excerpt":"Data science with Snkia.","created_at_pretty":"19 April, 2018","published_at_pretty":"18 April, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-04-18T21:09:13.000-04:00","published_at":"2018-04-18T10:00:00.000-04:00","updated_at":"2019-04-10T02:46:34.000-04:00","meta_title":"Link Roundup, April 18th | Hackers and Slackers","meta_description":"Data science with Snkia","og_description":"Data science with Snkia","og_image":"https://hackersandslackers.com/content/images/2019/04/109-2.jpg","og_title":"Link Roundup, April 18th","twitter_description":"Data science with Snkia","twitter_image":"https://hackersandslackers.com/content/images/2019/04/109-1.jpg","twitter_title":"Link Roundup, April 18th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"https://www.quantamagazine.org/machine-learnings-amazing-ability-to-predict-chaos-20180418/ \n These are a few of my faaaavorite things\n\nhttps://medium.com/@NetflixTechBlog/titus-the-netflix-container-management-platform-is-now-open-source-f868c9fb5436\n\nhttps://research.googleblog.com/2018/04/introducing-semantic-experiences-with.html \n Cautiously optimistic!  Lotsa stuff has promised to do this and\nnot-quite-done-it, but hey, nothing happens until it does.\n\nhttps://medium.com/activewizards-machine-learning-company/a-comparative-analysis-of-chatbots-apis-f9d240263e1d \n Kinda kooky how mature this tech is getting\n\nhttps://medium.com/scribd-data-science-engineering/multi-armed-bandits-for-the-win-240b71bc3464 \n  Ah, multi-armed bandits.  The old \"explore vs exploit\" tradeoff.  Or as I like\nto call it, \"I wish I spent more time reading through that Distributed Systems\nbook instead of browsing Reddit, but then again I found that book on Reddit to\nbegin with.\"","html":"<p><a href=\"https://www.quantamagazine.org/machine-learnings-amazing-ability-to-predict-chaos-20180418/\">https://www.quantamagazine.org/machine-learnings-amazing-ability-to-predict-chaos-20180418/</a> These are a few of my faaaavorite things</p><p><a href=\"https://medium.com/@NetflixTechBlog/titus-the-netflix-container-management-platform-is-now-open-source-f868c9fb5436\">https://medium.com/@NetflixTechBlog/titus-the-netflix-container-management-platform-is-now-open-source-f868c9fb5436</a></p><p><a href=\"https://research.googleblog.com/2018/04/introducing-semantic-experiences-with.html\">https://research.googleblog.com/2018/04/introducing-semantic-experiences-with.html</a> Cautiously optimistic!  Lotsa stuff has promised to do this and not-quite-done-it, but hey, nothing happens until it does.</p><p><a href=\"https://medium.com/activewizards-machine-learning-company/a-comparative-analysis-of-chatbots-apis-f9d240263e1d\">https://medium.com/activewizards-machine-learning-company/a-comparative-analysis-of-chatbots-apis-f9d240263e1d</a> Kinda kooky how mature this tech is getting</p><p><a href=\"https://medium.com/scribd-data-science-engineering/multi-armed-bandits-for-the-win-240b71bc3464\">https://medium.com/scribd-data-science-engineering/multi-armed-bandits-for-the-win-240b71bc3464</a>  Ah, multi-armed bandits.  The old \"explore vs exploit\" tradeoff.  Or as I like to call it, \"I wish I spent more time reading through that Distributed Systems book instead of browsing Reddit, but then again I found that book on Reddit to begin with.\"</p>","url":"https://hackersandslackers.com/link-roundup-april-18th/","uuid":"a3adad2a-1f4e-4f83-af17-1a0fdbbe7387","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5ad7ec3965cd784d6288cb01"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867363b","title":"Setting up a MySQL Database on Ubuntu","slug":"set-up-mysql-database","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/04/mysql1@2x.jpg","excerpt":"Setting up MySQL the old-fashioned way: on a Linux server.","custom_excerpt":"Setting up MySQL the old-fashioned way: on a Linux server.","created_at_pretty":"17 April, 2018","published_at_pretty":"18 April, 2018","updated_at_pretty":"28 March, 2019","created_at":"2018-04-16T23:53:52.000-04:00","published_at":"2018-04-17T22:58:58.000-04:00","updated_at":"2019-03-28T04:52:03.000-04:00","meta_title":"Setting up a MySQL Database on Ubuntu | Hackers and Slackers","meta_description":"Setting up MySQL the old-fashioned way: on a linux server","og_description":"Setting up MySQL the old-fashioned way: on a Linux server","og_image":"https://hackersandslackers.com/content/images/2018/04/mysql1@2x.jpg","og_title":"Setting up a MySQL Database on Ubuntu","twitter_description":"Setting up MySQL the old-fashioned way: on a Linux server","twitter_image":"https://hackersandslackers.com/content/images/2018/04/mysql1@2x.jpg","twitter_title":"Setting up a MySQL Database on Ubuntu","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"MySQL","slug":"mysql","description":"Database configuration, building queries, and cloud hosting options for MySQL.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysqlrevamp_o.jpg","meta_description":"Database configuration, building queries, and cloud hosting options for MySQL.","meta_title":"Working with MySQL | Hackers and Slackers","visibility":"public"},{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"#Working with MySQL","slug":"working-with-mysql","description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/mysql1_o-1.jpg","meta_description":"Learn about MySQL database configuration, the query language, and cloud hosted instances.","meta_title":"Working with MySQL","visibility":"internal"}],"plaintext":"As frameworks and services evolve to remove us further away from boilerplate\ncode, the first casualty of saved time is the fundamental understanding of what\nwe're actually doing sometimes. This has good reason; one can only learn so much\nfrom repetitive command-line interactions with databases, thus making any\nservice's one-click-deploy  button all the more sensible.  If I  had to imagine\nthe least sexy title for a post in software development, it would be something\nalong the lines of How to Configure MySQL on a VPS, as opposed to like, a\ncloud-based solution, or Even a Docker Container, as Though we Live in the God\nDamn 90s or Something.\" And that's more or less the gist of this post.\n\nI'm not exactly crushing it in the MySQL shell every day- chances are a lot of\nus aren't considering we have plenty of tools to protect us from ever thinking\nabout doing so. That said, this is very much a real use-case for pretty much any\nself-hosted application running a database natively.\n\nSo here it goes: a crash course in MySQL, by An Idiot.\n\nInstallation\nInstalling MySQL server on Ubuntu is simple:\n\nsudo apt-get install mysql-server\n\n\nConfigure MySQL via the Shell\nCreating databases, users, and permissions all happens within the MySQL shell.\nThis can be accessed via:\n\nmysql -u root -p\n\n\nThis will log you in to MySQL as the root  user. In the future, the shell can be\naccessed as any other MySQL user you may create in the future.\n\nExplore your Databases\nSee which MySQL databases exit:\n\nmysql> SHOW DATABASES;\n\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| ghost_prod         |\n| hackers_prod       |\n| ind_prod           |\n| mysql              |\n| performance_schema |\n| sys                |\n+--------------------+\n\n\nNice databases bro. Notice the mysql  database. As you might imagine, there's\nprobably a lot of cool important shit in there that makes everything work. Let's\ncheck it out.\n\nGet in There\nTo access and start messing with your db, use the USE  query:\n\nmysql> USE mysql;\n\nDatabase changed\n\n\nLet's see which tables are chillin in here.\n\nmysql> SHOW tables;\n\n+---------------------------+\n| Tables_in_mysql           |\n+---------------------------+\n| columns_priv              |\n| db                        |\n| engine_cost               |\n| event                     |\n| func                      |\n| general_log               |\n| gtid_executed             |\n| help_category             |\n| help_keyword              |\n| help_relation             |\n| help_topic                |\n| innodb_index_stats        |\n| innodb_table_stats        |\n| ndb_binlog_index          |\n| plugin                    |\n| proc                      |\n| procs_priv                |\n| proxies_priv              |\n| server_cost               |\n| servers                   |\n| slave_master_info         |\n| slave_relay_log_info      |\n| slave_worker_info         |\n| slow_log                  |\n| tables_priv               |\n| time_zone                 |\n| time_zone_leap_second     |\n| time_zone_name            |\n| time_zone_transition      |\n| time_zone_transition_type |\n| user                      |\n+---------------------------+\n\n\nOh wow yeah, that looks pretty important. This is where configurations such as\nuser information exists. When we create users and grant them permissions, we'll\nbe doing so in mysql. We'll worry about that later, but let's see who's in there\nanyway for the hell of it:\n\nmysql> select user from user;\n\n+------------------+\n| user             |\n+------------------+\n| debian-sys-maint |\n| mysql.session    |\n| mysql.sys        |\n| root             |\n+------------------+\n\n\nSick. Without knowing much SQL at all, we can already see our databases, their\ntables, and get the values of whichever columns they might have. Now let's start\ndoing stuff.\n\nCreate a Database\nGo ahead and create a new database. In my case, I want to create a database\nwhich lists my Github repositories, so I'll create a db named github_repos:\n\nCREATE DATABASE github_repos;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> USE github_repos;\nDatabase changed\n\n\nCreating a table\nNow it's getting good: we're going to create a table in our database: to do\nthis, we're going to need to define our columns upfront, including the type of\ndata each column can accept as well as the restrictions on that column. I'm\nkeeping it simple and storing values of text for now.\n\nmysql> CREATE TABLE githubrepos (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, \n    -> full_name VARCHAR(100),\n    -> description VARCHAR(300),\n    -> name VARCHAR(200),\n    -> url VARCHAR(150));\n\n\nid  is a standard column which indicates the numerical index of each row. Here,\nwe're stating that our rows will count themselves.\n\nEach following line creates a column by [name]  [type of data]****[limit]. In\nthis example we're creating columns which accept alphanumeric characters, up to\na maximum of the the number specified.\n\nNOTE: you should really overestimate the number of characters each field can\naccept. I didn't. Its a waste of time and might drive you crazy down the line:\njust accept a large number and be done with it.\n\nFruits of your labor\nGo ahead and check out what you've done:\n\nmysql> SHOW tables;\n\n+------------------------+\n| Tables_in_github_repos |\n+------------------------+\n| githubrepos            |\n+------------------------+\n\n\nDamn dude, you did it. Let's take a look just to make sure:\n\n+-------------+--------------+------+-----+---------+----------------+\n| Field       | Type         | Null | Key | Default | Extra          |\n+-------------+--------------+------+-----+---------+----------------+\n| id          | int(11)      | NO   | PRI | NULL    | auto_increment |\n| full_name   | varchar(200) | YES  |     | NULL    |                |\n| description | varchar(300) | YES  |     | NULL    |                |\n| name        | varchar(200) | YES  |     | NULL    |                |\n| url         | varchar(200) | YES  |     | NULL    |                |\n+-------------+--------------+------+-----+---------+----------------+\n5 rows in set (0.01 sec)\n\n\nHoly shit it's literally a table.\n\nMaking Changes\nLet's make some changes to our table after the fact. We can use ALTER TABLE to\nadd, modify, or remove columns.\n\nmysql> ALTER TABLE githubrepos ADD homepage VARCHAR(255);\nQuery OK, 0 rows affected (0.09 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n\n\nThis added column homepage  which accepts alphanumeric characters.\n\nNow that we've created our own database with our own defined structure, the\npossibilities are endless. The next step is to actually fill it with data, but\nlet's save that for next time.\n\nmysql> \\q\nBye","html":"<p>As frameworks and services evolve to remove us further away from boilerplate code, the first casualty of saved time is the fundamental understanding of what we're actually doing sometimes. This has good reason; one can only learn so much from repetitive command-line interactions with databases, thus making any service's <em>one-click-deploy</em> button all the more sensible.  If I  had to imagine the least sexy title for a post in software development, it would be something along the lines of <em><strong>How to Configure MySQL on a VPS, as opposed to like, a cloud-based solution, or Even a Docker Container, as Though we Live in the God Damn 90s or Something.\" </strong> </em>And that's more or less the gist of this post.</p><p>I'm not exactly crushing it in the MySQL shell every day- chances are a lot of us aren't considering we have plenty of tools to protect us from ever thinking about doing so. That said, this is very much a real use-case for pretty much any self-hosted application running a database natively.</p><p>So here it goes: a crash course in MySQL, by An Idiot.</p><h3 id=\"installation\">Installation</h3><p>Installing MySQL server on Ubuntu is simple:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">sudo apt-get install mysql-server\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"configure-mysql-via-the-shell\">Configure MySQL via the Shell</h3><p>Creating databases, users, and permissions all happens within the MySQL shell. This can be accessed via:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql -u root -p\n</code></pre>\n<!--kg-card-end: markdown--><p>This will log you in to MySQL as the <strong>root</strong> user. In the future, the shell can be accessed as any other MySQL user you may create in the future.</p><h3 id=\"explore-your-databases\">Explore your Databases</h3><p>See which MySQL databases exit:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; SHOW DATABASES;\n\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| ghost_prod         |\n| hackers_prod       |\n| ind_prod           |\n| mysql              |\n| performance_schema |\n| sys                |\n+--------------------+\n</code></pre>\n<!--kg-card-end: markdown--><p>Nice databases bro. Notice the <em>mysql</em> database. As you might imagine, there's probably a lot of cool important shit in there that makes everything work. Let's check it out.</p><h3 id=\"get-in-there\">Get in There</h3><p>To access and start messing with your db, use the <strong>USE</strong> query:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; USE mysql;\n\nDatabase changed\n</code></pre>\n<!--kg-card-end: markdown--><p>Let's see which tables are chillin in here.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; SHOW tables;\n\n+---------------------------+\n| Tables_in_mysql           |\n+---------------------------+\n| columns_priv              |\n| db                        |\n| engine_cost               |\n| event                     |\n| func                      |\n| general_log               |\n| gtid_executed             |\n| help_category             |\n| help_keyword              |\n| help_relation             |\n| help_topic                |\n| innodb_index_stats        |\n| innodb_table_stats        |\n| ndb_binlog_index          |\n| plugin                    |\n| proc                      |\n| procs_priv                |\n| proxies_priv              |\n| server_cost               |\n| servers                   |\n| slave_master_info         |\n| slave_relay_log_info      |\n| slave_worker_info         |\n| slow_log                  |\n| tables_priv               |\n| time_zone                 |\n| time_zone_leap_second     |\n| time_zone_name            |\n| time_zone_transition      |\n| time_zone_transition_type |\n| user                      |\n+---------------------------+\n</code></pre>\n<!--kg-card-end: markdown--><p>Oh wow yeah, that looks pretty important. This is where configurations such as user information exists. When we create users and grant them permissions, we'll be doing so in <em>mysql</em>. We'll worry about that later, but let's see who's in there anyway for the hell of it:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; select user from user;\n\n+------------------+\n| user             |\n+------------------+\n| debian-sys-maint |\n| mysql.session    |\n| mysql.sys        |\n| root             |\n+------------------+\n</code></pre>\n<!--kg-card-end: markdown--><p>Sick. Without knowing much SQL at all, we can already see our databases, their tables, and get the values of whichever columns they might have. Now let's start doing stuff.</p><h3 id=\"create-a-database\">Create a Database</h3><p>Go ahead and create a new database. In my case, I want to create a database which lists my Github repositories, so I'll create a db named <em>github_repos</em>:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">CREATE DATABASE github_repos;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql&gt; USE github_repos;\nDatabase changed\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"creating-a-table\">Creating a table</h3><p>Now it's getting good: we're going to create a table in our database: to do this, we're going to need to define our columns upfront, including the type of data each column can accept as well as the restrictions on that column. I'm keeping it simple and storing values of text for now.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; CREATE TABLE githubrepos (id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, \n    -&gt; full_name VARCHAR(100),\n    -&gt; description VARCHAR(300),\n    -&gt; name VARCHAR(200),\n    -&gt; url VARCHAR(150));\n</code></pre>\n<!--kg-card-end: markdown--><p><strong>id</strong> is a standard column which indicates the numerical index of each row. Here, we're stating that our rows will count themselves.</p><p>Each following line creates a column by <strong>[name]</strong> <strong>[type of data]****[limit]</strong>. In this example we're creating columns which accept alphanumeric characters, up to a maximum of the the number specified.</p><p><em><strong>NOTE: you should really overestimate the number of characters each field can accept. I didn't. Its a waste of time and might drive you crazy down the line: just accept a large number and be done with it.</strong></em></p><h3 id=\"fruits-of-your-labor\">Fruits of your labor</h3><p>Go ahead and check out what you've done:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; SHOW tables;\n\n+------------------------+\n| Tables_in_github_repos |\n+------------------------+\n| githubrepos            |\n+------------------------+\n</code></pre>\n<!--kg-card-end: markdown--><p>Damn dude, you did it. Let's take a look just to make sure:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">+-------------+--------------+------+-----+---------+----------------+\n| Field       | Type         | Null | Key | Default | Extra          |\n+-------------+--------------+------+-----+---------+----------------+\n| id          | int(11)      | NO   | PRI | NULL    | auto_increment |\n| full_name   | varchar(200) | YES  |     | NULL    |                |\n| description | varchar(300) | YES  |     | NULL    |                |\n| name        | varchar(200) | YES  |     | NULL    |                |\n| url         | varchar(200) | YES  |     | NULL    |                |\n+-------------+--------------+------+-----+---------+----------------+\n5 rows in set (0.01 sec)\n</code></pre>\n<!--kg-card-end: markdown--><p>Holy shit it's literally a table.</p><h3 id=\"making-changes\">Making Changes</h3><p>Let's make some changes to our table after the fact. We can use ALTER TABLE to add, modify, or remove columns.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; ALTER TABLE githubrepos ADD homepage VARCHAR(255);\nQuery OK, 0 rows affected (0.09 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n</code></pre>\n<!--kg-card-end: markdown--><p>This added column <em>homepage</em> which accepts alphanumeric characters.</p><p>Now that we've created our own database with our own defined structure, the possibilities are endless. The next step is to actually fill it with data, but let's save that for next time.</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">mysql&gt; \\q\nBye\n</code></pre>\n<!--kg-card-end: markdown-->","url":"https://hackersandslackers.com/set-up-mysql-database/","uuid":"697bc755-a833-43fe-b807-5668b8c284f4","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5ad56fd09bfe350c74e8a8cb"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867363c","title":"Link Roundup, April 17th","slug":"link-roundup-april-17th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/100.jpg","excerpt":"Data science with Snkia.","custom_excerpt":"Data science with Snkia.","created_at_pretty":"18 April, 2018","published_at_pretty":"18 April, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-04-17T23:08:40.000-04:00","published_at":"2018-04-17T21:14:00.000-04:00","updated_at":"2019-04-10T02:47:04.000-04:00","meta_title":"Link Roundup, April 17th | Hackers and Slackers","meta_description":"Data science with Snkia","og_description":"Data science with Snkia","og_image":"https://hackersandslackers.com/content/images/2019/04/100-2.jpg","og_title":"Link Roundup, April 17th","twitter_description":"Data science with Snkia","twitter_image":"https://hackersandslackers.com/content/images/2019/04/100-1.jpg","twitter_title":"Link Roundup, April 17th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"Stuck on a visualization?  Try this data visualization checklist!  Also has a\ntool for scoring stuff according to its method.  I don't think ya should totally\nenslave yourself to methods like this, but it can be useful\nhttps://datavizchecklist.stephanieevergreen.com/\n\nThe first rule of Good Documentation is...you do not talk about Good\nDocumentation\nhttps://www.oreilly.com/ideas/the-eight-rules-of-good-documentation\n\nYay maffs, yay amateurs\nhttps://www.quantamagazine.org/decades-old-graph-problem-yields-to-amateur-mathematician-20180417/","html":"<p>Stuck on a visualization?  Try this data visualization checklist!  Also has a tool for scoring stuff according to its method.  I don't think ya should totally enslave yourself to methods like this, but it can be useful<br><a href=\"https://datavizchecklist.stephanieevergreen.com/\">https://datavizchecklist.stephanieevergreen.com/</a></p><p>The first rule of Good Documentation is...you do not talk about Good Documentation<br><a href=\"https://www.oreilly.com/ideas/the-eight-rules-of-good-documentation\">https://www.oreilly.com/ideas/the-eight-rules-of-good-documentation</a></p><p>Yay maffs, yay amateurs<br><a href=\"https://www.quantamagazine.org/decades-old-graph-problem-yields-to-amateur-mathematician-20180417/\">https://www.quantamagazine.org/decades-old-graph-problem-yields-to-amateur-mathematician-20180417/</a></p>","url":"https://hackersandslackers.com/link-roundup-april-17th/","uuid":"ffae741a-3f3c-440c-bc61-0a60acd87a4f","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5ad6b6b8dd09a2490ab6f9e5"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867363a","title":"Link Roundup, April 16th","slug":"link-roundup-april-16","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/04/linksagain.png","excerpt":"Data science with Snkia.","custom_excerpt":"Data science with Snkia.","created_at_pretty":"17 April, 2018","published_at_pretty":"17 April, 2018","updated_at_pretty":"25 July, 2018","created_at":"2018-04-16T20:21:57.000-04:00","published_at":"2018-04-16T20:26:10.000-04:00","updated_at":"2018-07-24T22:06:02.000-04:00","meta_title":"Link Roundup, April 16th | Hackers and Slackers","meta_description":"Data science with Snkia","og_description":"Data science with Snkia","og_image":"https://hackersandslackers.com/content/images/2018/04/linksagain.png","og_title":"Link Roundup, April 16th","twitter_description":"Data science with Snkia","twitter_image":"https://hackersandslackers.com/content/images/2018/04/linksagain.png","twitter_title":"Link Roundup, April 16th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"}],"plaintext":"Algorithms as IKEA instructions:\nhttps://idea-instructions.com/\n\nAn Augmented Reality Microscope for Cancer Detection\nhttps://research.googleblog.com/2018/04/an-augmented-reality-microscope.html\n\nSuper into everything about this - using AI to help enforce financial\nregulations\nhttps://www.oreilly.com/ideas/simon-moss-on-using-artificial-intelligence-to-fight-financial-crimes\n\nYay mutants\nhttps://www.theguardian.com/environment/2018/apr/16/scientists-accidentally-create-mutant-enzyme-that-eats-plastic-bottles\n\nCool tools for cool tasks!\nhttp://ataspinar.com/2018/04/04/machine-learning-with-signal-processing-techniques/","html":"<p>Algorithms as IKEA instructions:<br>\n<a href=\"https://idea-instructions.com/\">https://idea-instructions.com/</a></p>\n<p>An Augmented Reality Microscope for Cancer Detection<br>\n<a href=\"https://research.googleblog.com/2018/04/an-augmented-reality-microscope.html\">https://research.googleblog.com/2018/04/an-augmented-reality-microscope.html</a></p>\n<p>Super into everything about this - using AI to help enforce financial regulations<br>\n<a href=\"https://www.oreilly.com/ideas/simon-moss-on-using-artificial-intelligence-to-fight-financial-crimes\">https://www.oreilly.com/ideas/simon-moss-on-using-artificial-intelligence-to-fight-financial-crimes</a></p>\n<p>Yay mutants<br>\n<a href=\"https://www.theguardian.com/environment/2018/apr/16/scientists-accidentally-create-mutant-enzyme-that-eats-plastic-bottles\">https://www.theguardian.com/environment/2018/apr/16/scientists-accidentally-create-mutant-enzyme-that-eats-plastic-bottles</a></p>\n<p>Cool tools for cool tasks!<br>\n<a href=\"http://ataspinar.com/2018/04/04/machine-learning-with-signal-processing-techniques/\">http://ataspinar.com/2018/04/04/machine-learning-with-signal-processing-techniques/</a></p>\n","url":"https://hackersandslackers.com/link-roundup-april-16/","uuid":"4f7609ff-5298-49de-8b56-686ad50dc3bf","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5ad53e25419b455c593427df"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673639","title":"Link Roundup, April 15th","slug":"lynx-roundup-april-15th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/04/120.jpg","excerpt":"Data science with Snkia.","custom_excerpt":"Data science with Snkia.","created_at_pretty":"16 April, 2018","published_at_pretty":"16 April, 2018","updated_at_pretty":"10 April, 2019","created_at":"2018-04-15T23:43:20.000-04:00","published_at":"2018-04-15T23:55:12.000-04:00","updated_at":"2019-04-10T02:45:51.000-04:00","meta_title":"Link Roundup, April 15th | Hackers and Slackers","meta_description":"Data science with Snkia","og_description":"Data science with Snkia","og_image":"https://hackersandslackers.com/content/images/2019/04/120-2.jpg","og_title":"Link Roundup, April 15th","twitter_description":"Data science with Snkia","twitter_image":"https://hackersandslackers.com/content/images/2019/04/120-1.jpg","twitter_title":"Link Roundup, April 15th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"Things I've come across recently that I thought were neat.  Freshness not\nguaranteed.\n\nhttps://medium.com/tensorflow/introducing-tensorflow-probability-dca4c304e245\nSweet.  Probabilistic Programming languages are pretty rad - only one I've ever\nreally messed with is Anglican in Clojure, though.\n\nhttps://www.cnn.com/2018/04/12/health/stonefish-switchblade-lachrymal-saber-trnd/index.html\nGood news, everyone!  These dangerous beasties just got more dangerous and more\nbeastly.\n\nhttp://www.iflscience.com/physics/7-animated-gifs-that-will-make-you-instantly-understant-trigonometry/all/\n\nhttps://paulromer.net/jupyter-mathematica-and-the-future-of-the-research-paper/\nLegitimately think Literate Programming is a super important development in\nPhilosophy of Science.\n\nhttps://www.ccn.com/an-ethereum-blockchain-is-restoring-the-identity-of-syrian-refugees/\nAwesome application of the tech.  Fun fact: Iron Mountain was started so that\nimportant records wouldn't be lost in the event of war.  Original name was \"Iron\nMountain Atomic Storage Corporation\".","html":"<p>Things I've come across recently that I thought were neat.  Freshness not guaranteed.</p><p><a href=\"https://medium.com/tensorflow/introducing-tensorflow-probability-dca4c304e245\">https://medium.com/tensorflow/introducing-tensorflow-probability-dca4c304e245</a><br>Sweet.  Probabilistic Programming languages are pretty rad - only one I've ever really messed with is Anglican in Clojure, though.</p><p><a href=\"https://www.cnn.com/2018/04/12/health/stonefish-switchblade-lachrymal-saber-trnd/index.html\">https://www.cnn.com/2018/04/12/health/stonefish-switchblade-lachrymal-saber-trnd/index.html</a><br>Good news, everyone!  These dangerous beasties just got more dangerous and more beastly.</p><p><a href=\"http://www.iflscience.com/physics/7-animated-gifs-that-will-make-you-instantly-understant-trigonometry/all/\">http://www.iflscience.com/physics/7-animated-gifs-that-will-make-you-instantly-understant-trigonometry/all/</a></p><p><a href=\"https://paulromer.net/jupyter-mathematica-and-the-future-of-the-research-paper/\">https://paulromer.net/jupyter-mathematica-and-the-future-of-the-research-paper/</a><br>Legitimately think Literate Programming is a super important development in Philosophy of Science.</p><p><a href=\"https://www.ccn.com/an-ethereum-blockchain-is-restoring-the-identity-of-syrian-refugees/\">https://www.ccn.com/an-ethereum-blockchain-is-restoring-the-identity-of-syrian-refugees/</a><br>Awesome application of the tech.  Fun fact: Iron Mountain was started so that important records wouldn't be lost in the event of war.  Original name was \"Iron Mountain Atomic Storage Corporation\".</p>","url":"https://hackersandslackers.com/lynx-roundup-april-15th/","uuid":"22cd260f-908e-40b6-9c09-a4cde4909786","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5ad41bd8ba79aa35d59fd25c"}},{"node":{"id":"Ghost__Post__5c64981a7c8ecc6ee30c6870","title":"Starting a Python Web App with Heroku","slug":"starting-a-python-web-app-with-heroku","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/flask2@2x.jpg","excerpt":"Pairing Flask with zero-effort container deployments is a deadly path to addiction.","custom_excerpt":"Pairing Flask with zero-effort container deployments is a deadly path to addiction.","created_at_pretty":"13 February, 2019","published_at_pretty":"13 February, 2018","updated_at_pretty":"13 February, 2019","created_at":"2019-02-13T17:20:10.000-05:00","published_at":"2018-02-13T17:20:00.000-05:00","updated_at":"2019-02-13T17:57:20.000-05:00","meta_title":"Starting a Python Application with Heroku | Hackers and Slackers","meta_description":"Flask is a gift to developers who value the act of development. Pairing Python with zero-effort container deployments is a deadly path to addiction.","og_description":"Flask is a gift to developers who value the act of development. Pairing Python with zero-effort container deployments is a deadly path to addiction.","og_image":"https://hackersandslackers.com/content/images/2019/02/flask2@2x.jpg","og_title":"Starting a Python Application with Heroku | Hackers and Slackers","twitter_description":"Flask is a gift to developers who value the act of development. Pairing Python with zero-effort container deployments is a deadly path to addiction.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/flask2@2x.jpg","twitter_title":"Starting a Python Application with Heroku | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"}],"plaintext":"It's difficult to cover every cloud solution on the market without at least\nmentioning Heroku. Heroku contrasts nearly every cloud hosting solution by\noffering a clear purpose: make deploying apps of any kind as easy as possible.\nDeploying to a VPS requires knowledge of web servers and configurations.\nDeploying to containers requires knowledge of Docker or Kubernetes. Deploying to\nHeroku requires nearly no prior knowledge of anything.\n\nHeroku is great for getting MVPs out the door, or for devs who want to jump into\ndeveloping web applications with knowledge of a specific language. Even\ndevelopers with advanced knowledge of how to deploy production applications may\nwant to use Heroku for fast internal deployments, or as a platform for\n\"sketching out\" a quick prototype.\n\nIn this exploration, we'll be using Heroku to deploy a Python application using\nthe Flask framework.\n\nWhy Heroku?\nWe're on the topic of simplicity, so let's keep that theme going. Heroku's\ninfrastructure offering is unique in that Heroku obfuscates the DevOps aspect of\nweb development completely. That means that configuring web servers, managing\nLinux packages, and supplying SSL certs are entirely taken care of by Heroku. \n\nLet's consider Heroku's ease-of-use services to be luxuries which save us time.\nThey are NOT  a replacement for grasping these concepts.\n\nPipelines\nAside from VPS upkeep, Heroku obfuscates the process of moving an app through\ndevelopment and production environments by defining pipelines. That's right,\nCI/CD is built directly into Heroku's interface.\n\nAdd-ons\nThe most addictive aspect of Heroku is probably the Elements marketplace. This\nis a place to window-shop for set-it-and-forget-it plugins for your app, most of\nwhich are very easy to integrate with. \n\nMost add-ons fall under a few major categories: database resellers, analytics,\nand Redis, to name a few (interestingly enough, using the base Redis add-on in\nHeroku is free, while the equivalent instance would cost you 5 dollars from the\nsame provider had you used them directly. Add-ons are \"deployed\" after a single\nclick, and the ensuing configuration process varies from vendor-to-vendor after\nthat.\n\nSpeaking of single-click, they handle single-click deployments of popular build\npacks, too. You, the thing that made DigitalOcean a big deal way back. You get\nthe idea.\n\nCreating your Project\nLog in to the Heroku UI and create an app on a fresh Dyno. A Dyno is merely a\nfancy, overly branded word for \"container.\" Next, you'll be prompted to download\nthe Heroku CLI locally on your OS of choice, which is quick and painless. Now\nwe're cooking with gas.\n\nCreate an empty local directory and type the following command to be prompted\nfor your Heroku account credentials:\n\n$ heroku login\nEnter your Heroku credentials.\nEmail: python@example.com\nPassword:\n\n\nAt this point, Heroku has already magically created a git repository for your\napplication from which you'll be doing development from.\n\n$ git clone https://github.com/heroku/example-flask-project.git\n$ cd example-flask-project\n\n$ heroku create\nCreating example-flask-project in organization heroku... done, stack is cedar-14\nhttp://example-flask-project.herokuapp.com/ | https://git.heroku.com/example-flask-project.git\nGit remote heroku added\n\n\nWow, that sure looks a lot like we're working with Github huh? That's actually\nthe point: if you so chose, you can configure the Heroku CLI to recognize your\nGithub username with a simple heroku config:get GITHUB_USERNAME=yourname. With\nthis configured, Heroku will actually allow you to simply deploy to your\npersonal Github repo and mimic the changes on your Dyno. Now let's configure\nthis thing.\n\nA Project For Ants\nWe're going to get started by building you obligatory \"hello world\" app. The\nresulting file structure is going to end up looking like this:\n\nexample-flask-project\n├── app.py\n├── Procfile\n├── Pipfile\n├── Pipfile.lock\n├── runtime.txt\n├── requirements.txt\n├── Pipfile.lock\n└── setup.py\n\n\nNote the existence of two files you may not have seen before if you're new to\nHeroku: the Procfile  (no file extension) and requirements.txt. These are tiny\nfiles which specify which language we're using and how to start our app, but\nwe'll get to that in a moment.\n\nManaging Your Python Packages \nHeroku impressively supports Pipenv out-of-the-box for handling and installing\ndependencies. Every time you deploy your application, Heroku will install the\npackage version specified in Pipfile.lock to build your app from scratch. If\nyou're new to using Pipenv consider quickly picking up the basics from this\nquick tutorial\n[https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/]\n. If you're still using virtualenv, you should consider switching to Pipenv\nregardless.\n\nCreate a local folder for your project. In that folder, start a Pipenv shell:\n\n$ pip install pipenv\npipenv shell\n\n\nWith the shell activated, we can now install dependencies specific to our\nenvironment. At a bare minimum, we need to install two packages: Flask  as our\nframework, and Gunicorn  to run our app process.\n\n(my-project)$ pip3 install flask gunicorn\n\n\nGood job; now let's build out the files in our tree one-by-one.\n\nProcfile\nThe Procfile (no file extension) is a unique file to Heroku which is essentially\na build command. This will be a one-liner to tell Gunicorn  to startup our\napplication from our base app.py  file.\n\nweb: gunicorn app:app\n\nA quick breakdown here: web  is our process 'type'. other types exists, such as \nworker, urgentworker, and clock, but that's not important for now.\n\napp:app  signifies looking for the 'app' module in our app.py  file. If you'd\nlike to move app.py to . a different folder down the line, this can be adjusted\nas such:\n\nweb: gunicorn differentfolder app:app\n\nRuntime\nThe runtime.txt  file notifies Heroku of the language it's dealing with as well\nas the proper version. Heroku only supports up to a particular version of Python\nat any given moment (which is currently Python-3.7.1), but specifying a higher\nversion will default to the latest version Heroku supports.\n\nPython-3.7.1\n\nRequirements.txt\nEven though Heroku uses your Pipfile to build dependencies, it's still best\npractice to keep a requirements.txt  present for numerous reasons. For example,\nif you remove dependencies from your Pipfile without uninstalling them, \nrequirements.txt  is a useful way of identifying old packages in your\nenvironment that can be uninstalled.\n\n(my-project)$ pip freeze > requirements.txt\n\n\nAs I'm sure you know, pip freeze  will print all packages and their versions\ninto the designated file as such:\n\nasn1crypto==0.24.0\nbcrypt==3.1.4\nbeautifulsoup4==4.6.0\nblinker==1.4\ncffi==1.11.5\nclick==6.7\ncryptography==2.2.2\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Mail==0.9.1\nflask-mongoengine==0.9.5\nFlask-SQLAlchemy==2.3.2\nFlask-Static-Compress==1.0.2\nFlask-User==1.0.1.5\nFlask-WTF==0.14.2\ngunicorn==19.9.0\nidna==2.7\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nMarkupSafe==1.0\nmongoengine==0.15.0\nordereddict==1.1\npasslib==1.7.1\npycparser==2.18\npymongo==3.7.0\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.9\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\n\n\nPipfile\nOur Pipfile is automatically generated by Pipenv by default, but be sure to call\nout packages which are essential to the build our app as. Packages which are\nrequired for your app to work belong under the [packages]  section.\n\n[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\ngunicorn = \"*\"\nflask = \"*\"\nrequests = \"*\"\nwtforms = \"*\"\nflask_assets = \"*\"\nflask_static_compress = \"*\"\n\n[dev-packages]\n\n[requires]\npython_version = \"3.7.1\"\n\n\nPipfile.lock\nHeroku looks at Pipfile.lock  every time our app builds to know which packages\nto install on the server side. Changing dependencies locally without updating\nthe Pipfile.lock  will not carry the changes over to your Dyno. Thus, be sure to\ngenerate this file when needed:\n\n(my-project)$ pipenv lock\n\n\nBetter yet, running the following will check your Pipfile for packages which can\nbe updated, will update those packages, and then  generate a lock file:\n\n(my-project)$ pipenv update\n\n\nSetup.py\nTechnically this file isn't required, but is a general best practice when\ncreating projects. Most of Setup.py's purpose comes in to play if you plan on\nsubmitting your project as a standalone package,\n\nfrom setuptools import setup, find_packages\n\nsetup(\n    name='my-project',\n    version='1.0',\n    long_description=__doc__,\n    packages=find_packages(),\n    include_package_data=True,\n    zip_safe=False,\n    install_requires=['Flask'],\n)\n\n\n.env\nOkay, okay, just one last thing. Heroku will be upset unless there's a .env \nfile in its root directory at run time. .env  is where we would store sensitive\ninformation (such as secrets), but feel free to leave this empty for now. \n\nHeroku allows you to manage environment variables via their web UI as well.\nThese can then be conveniently saved to your local environment to run your app\nlocally, but let's stay focused on the task at hand: saying \"hello\" to the\nworld.\n\nDeployment\nRunning your app locally is as simple as two words: heroku local. This spins up\nan instance of your app on your machine at 0.0.0.0:5000.\n\nDeploying to your Heroku Dyno is much like deploying to Github (they can in fact\nbe the exact same if you configure it as such). Here's how deployment via the\nHeroku CLI looks:\n\ngit add .\ngit commit -am 'initial commit'\ngit push heroku master\n\n\nIf all went well, your app should be live at the URL Heroku generated for you\nwhen you created your project. Go ahead and checkout the Heroku UI to see how\nthings went. \n\nI highly suggest checking out the logs on the Heroku UI after each deploy. Often\ntimes issues which don't appear on your local environment will pop up on the\nserver:\n\nHeroku's logging system is surprisingly both helpful and aesthetically pleasing.\nWhat Do We Make Of This?\nThere are two general takeaways I suppose I'm getting at:\n\n * Heroku is easy and fun to use.\n * Flask is awesome. \n\nAs much as #1 is true, I think it's important to distinguish Heroku's place in a\ncrowded cloud market. Heroku is a platform best suited for dumping MVPs and side\nprojects... NOT production applications. While you certainly can host large apps\non Heroku, I consider it to highly unprofessional. Remember: Heroku is basically\na reseller. They host their containers on AWS, and sell add-ons from other\nvendors. If you depend too heavily on Heroku, you are essentially just adding a\nmiddle man to your billing cycle.\n\nOn the Flask side: Flask's development may not be as vast as the npm  packages\noffered by Node, there's more or less a package for anything you possibly need.\nI'd recommend checking out Flask's official list of packages\n[http://flask.pocoo.org/extensions/].\n\nWhile we may have set up our first Flask application, as it stands we've only\nbuilt something useless so far. Consider this to be the beginning of many, many\nFlask tips to come.","html":"<p>It's difficult to cover every cloud solution on the market without at least mentioning Heroku. Heroku contrasts nearly every cloud hosting solution by offering a clear purpose: make deploying apps of any kind as easy as possible. Deploying to a VPS requires knowledge of web servers and configurations. Deploying to containers requires knowledge of Docker or Kubernetes. Deploying to Heroku requires nearly no prior knowledge of anything.</p><p>Heroku is great for getting MVPs out the door, or for devs who want to jump into developing web applications with knowledge of a specific language. Even developers with advanced knowledge of how to deploy production applications may want to use Heroku for fast internal deployments, or as a platform for \"sketching out\" a quick prototype.</p><p>In this exploration, we'll be using Heroku to deploy a Python application using the Flask framework.</p><h2 id=\"why-heroku\">Why Heroku?</h2><p>We're on the topic of simplicity, so let's keep that theme going. Heroku's infrastructure offering is unique in that Heroku obfuscates the DevOps aspect of web development completely. That means that configuring web servers, managing Linux packages, and supplying SSL certs are entirely taken care of by Heroku. </p><p>Let's consider Heroku's ease-of-use services to be luxuries which save us time. They are <strong>NOT</strong> a replacement for grasping these concepts.</p><h3 id=\"pipelines\">Pipelines</h3><p>Aside from VPS upkeep, Heroku obfuscates the process of moving an app through development and production environments by defining <em>pipelines. </em>That's right, CI/CD is built directly into Heroku's interface.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-07-10-at-10.19.41-AM.png\" class=\"kg-image\"></figure><h3 id=\"add-ons\">Add-ons</h3><p>The most addictive aspect of Heroku is probably the Elements marketplace. This is a place to window-shop for set-it-and-forget-it plugins for your app, most of which are very easy to integrate with. </p><p>Most add-ons fall under a few major categories: database resellers, analytics, and Redis, to name a few (interestingly enough, using the base Redis add-on in Heroku is free, while the equivalent instance would cost you 5 dollars from the same provider had you used them directly. Add-ons are \"deployed\" after a single click, and the ensuing configuration process varies from vendor-to-vendor after that.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screenshot-2018-07-08-17.30.07.png\" class=\"kg-image\"></figure><p>Speaking of single-click, they handle single-click deployments of popular build packs, too. You, the thing that made DigitalOcean a big deal way back. You get the idea.</p><h2 id=\"creating-your-project\">Creating your Project</h2><p>Log in to the Heroku UI and create an app on a fresh Dyno. A Dyno is merely a fancy, overly branded word for \"container.\" Next, you'll be prompted to download the Heroku CLI locally on your OS of choice, which is quick and painless. Now we're cooking with gas.</p><p>Create an empty local directory and type the following command to be prompted for your Heroku account credentials:</p><pre><code class=\"language-bash\">$ heroku login\nEnter your Heroku credentials.\nEmail: python@example.com\nPassword:\n</code></pre>\n<p>At this point, Heroku has already magically created a git repository for your application from which you'll be doing development from.</p><pre><code class=\"language-bash\">$ git clone https://github.com/heroku/example-flask-project.git\n$ cd example-flask-project\n\n$ heroku create\nCreating example-flask-project in organization heroku... done, stack is cedar-14\nhttp://example-flask-project.herokuapp.com/ | https://git.heroku.com/example-flask-project.git\nGit remote heroku added\n</code></pre>\n<p>Wow, that sure looks a lot like we're working with Github huh? That's actually the point: if you so chose, you can configure the Heroku CLI to recognize your Github username with a simple <code>heroku config:get GITHUB_USERNAME=yourname</code>. With this configured, Heroku will actually allow you to simply deploy to your personal Github repo and mimic the changes on your Dyno. Now let's configure this thing.</p><h2 id=\"a-project-for-ants\">A Project For Ants</h2><p>We're going to get started by building you obligatory \"hello world\" app. The resulting file structure is going to end up looking like this:</p><pre><code class=\"language-bash\">example-flask-project\n├── app.py\n├── Procfile\n├── Pipfile\n├── Pipfile.lock\n├── runtime.txt\n├── requirements.txt\n├── Pipfile.lock\n└── setup.py\n</code></pre>\n<p>Note the existence of two files you may not have seen before if you're new to Heroku: the <strong>Procfile</strong> (no file extension) and <strong>requirements.txt</strong>. These are tiny files which specify which language we're using and how to start our app, but we'll get to that in a moment.</p><h3 id=\"managing-your-python-packages\">Managing Your Python Packages </h3><p>Heroku impressively supports Pipenv out-of-the-box for handling and installing dependencies. Every time you deploy your application, Heroku will install the package version specified in Pipfile.lock to build your app from scratch. If you're new to using Pipenv consider quickly picking up the basics from <a href=\"https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/\">this quick tutorial</a>. If you're still using virtualenv, you should consider switching to Pipenv regardless.</p><p>Create a local folder for your project. In that folder, start a Pipenv shell:</p><pre><code class=\"language-bash\">$ pip install pipenv\npipenv shell\n</code></pre>\n<p>With the shell activated, we can now install dependencies specific to our environment. At a bare minimum, we need to install two packages: <strong>Flask</strong> as our framework, and <strong>Gunicorn</strong> to run our app process.</p><pre><code class=\"language-bash\">(my-project)$ pip3 install flask gunicorn\n</code></pre>\n<p>Good job; now let's build out the files in our tree one-by-one.</p><h3 id=\"procfile\">Procfile</h3><p>The Procfile (no file extension) is a unique file to Heroku which is essentially a build command. This will be a one-liner to tell <strong>Gunicorn</strong> to startup our application from our base <code>app.py</code> file.</p><pre><code>web: gunicorn app:app</code></pre><p>A quick breakdown here: <code>web</code> is our process 'type'. other types exists, such as <code>worker</code>, <code>urgentworker</code>, and <code>clock</code>, but that's not important for now.</p><p><code>app:app</code> signifies looking for the 'app' module in our <em>app.py</em> file. If you'd like to move app.py to . a different folder down the line, this can be adjusted as such:</p><pre><code>web: gunicorn differentfolder app:app</code></pre><h3 id=\"runtime\">Runtime</h3><p>The runtime.txt  file notifies Heroku of the language it's dealing with as well as the proper version. Heroku only supports up to a particular version of Python at any given moment (which is currently <em>Python-3.7.1</em>), but specifying a higher version will default to the latest version Heroku supports.</p><pre><code>Python-3.7.1</code></pre><h3 id=\"requirements-txt\">Requirements.txt</h3><p>Even though Heroku uses your Pipfile to build dependencies, it's still best practice to keep a <code>requirements.txt</code> present for numerous reasons. For example, if you remove dependencies from your Pipfile without uninstalling them, <code>requirements.txt</code> is a useful way of identifying old packages in your environment that can be uninstalled.</p><pre><code class=\"language-bash\">(my-project)$ pip freeze &gt; requirements.txt\n</code></pre>\n<p>As I'm sure you know, <code>pip freeze</code> will print all packages and their versions into the designated file as such:</p><pre><code class=\"language-bash\">asn1crypto==0.24.0\nbcrypt==3.1.4\nbeautifulsoup4==4.6.0\nblinker==1.4\ncffi==1.11.5\nclick==6.7\ncryptography==2.2.2\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Login==0.4.1\nFlask-Mail==0.9.1\nflask-mongoengine==0.9.5\nFlask-SQLAlchemy==2.3.2\nFlask-Static-Compress==1.0.2\nFlask-User==1.0.1.5\nFlask-WTF==0.14.2\ngunicorn==19.9.0\nidna==2.7\nitsdangerous==0.24\njac==0.17.1\nJinja2==2.10\nMarkupSafe==1.0\nmongoengine==0.15.0\nordereddict==1.1\npasslib==1.7.1\npycparser==2.18\npymongo==3.7.0\nrjsmin==1.0.12\nsix==1.11.0\nSQLAlchemy==1.2.9\nwebassets==0.12.1\nWerkzeug==0.14.1\nWTForms==2.2.1\n</code></pre>\n<h3 id=\"pipfile\">Pipfile</h3><p>Our Pipfile is automatically generated by Pipenv by default, but be sure to call out packages which are essential to the build our app as. Packages which are required for your app to work belong under the <code>[packages]</code> section.</p><pre><code>[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\ngunicorn = \"*\"\nflask = \"*\"\nrequests = \"*\"\nwtforms = \"*\"\nflask_assets = \"*\"\nflask_static_compress = \"*\"\n\n[dev-packages]\n\n[requires]\npython_version = \"3.7.1\"\n</code></pre><h3 id=\"pipfile-lock\">Pipfile.lock</h3><p>Heroku looks at <code>Pipfile.lock</code><em> </em>every time our app builds to know which packages to install on the server side. Changing dependencies locally without updating the <code>Pipfile.lock</code> will not carry the changes over to your Dyno. Thus, be sure to generate this file when needed:</p><pre><code class=\"language-bash\">(my-project)$ pipenv lock\n</code></pre>\n<p>Better yet, running the following will check your Pipfile for packages which can be updated, will update those packages, and <em>then</em> generate a lock file:</p><pre><code class=\"language-bash\">(my-project)$ pipenv update\n</code></pre>\n<h3 id=\"setup-py\">Setup.py</h3><p>Technically this file isn't required, but is a general best practice when creating projects. Most of <code>Setup.py</code>'s purpose comes in to play if you plan on submitting your project as a standalone package,</p><pre><code class=\"language-python\">from setuptools import setup, find_packages\n\nsetup(\n    name='my-project',\n    version='1.0',\n    long_description=__doc__,\n    packages=find_packages(),\n    include_package_data=True,\n    zip_safe=False,\n    install_requires=['Flask'],\n)\n</code></pre>\n<h2 id=\"-env\">.env</h2><p>Okay, okay, just one last thing. Heroku will be upset unless there's a <code>.env</code> file in its root directory at run time. <code>.env</code> is where we would store sensitive information (such as secrets), but feel free to leave this empty for now. </p><p>Heroku allows you to manage environment variables via their web UI as well. These can then be conveniently saved to your local environment to run your app locally, but let's stay focused on the task at hand: saying \"hello\" to the world.</p><h2 id=\"deployment\">Deployment</h2><p>Running your app locally is as simple as two words: <code>heroku local</code>. This spins up an instance of your app on your machine at <code>0.0.0.0:5000</code>.</p><p>Deploying to your Heroku Dyno is much like deploying to Github (they can in fact be the exact same if you configure it as such). Here's how deployment via the Heroku CLI looks:</p><pre><code class=\"language-bash\">git add .\ngit commit -am 'initial commit'\ngit push heroku master\n</code></pre>\n<p>If all went well, your app should be live at the URL Heroku generated for you when you created your project. Go ahead and checkout the Heroku UI to see how things went. </p><p>I highly suggest checking out the logs on the Heroku UI after each deploy. Often times issues which don't appear on your local environment will pop up on the server:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screenshot-2018-07-08-17.16.33.png\" class=\"kg-image\"><figcaption>Heroku's logging system is surprisingly both helpful and aesthetically pleasing.</figcaption></figure><h2 id=\"what-do-we-make-of-this\">What Do We Make Of This?</h2><p>There are two general takeaways I suppose I'm getting at:</p><ul><li>Heroku is easy and fun to use.</li><li>Flask is awesome. </li></ul><p>As much as #1 is true, I think it's important to distinguish Heroku's place in a crowded cloud market. Heroku is a platform best suited for dumping MVPs and side projects... NOT production applications. While you certainly can host large apps on Heroku, I consider it to highly unprofessional. Remember: Heroku is basically a reseller. They host their containers on AWS, and sell add-ons from other vendors. If you depend too heavily on Heroku, you are essentially just adding a middle man to your billing cycle.</p><p>On the Flask side: Flask's development may not be as vast as the <code>npm</code> packages offered by Node, there's more or less a package for anything you possibly need. I'd recommend checking out Flask's official list of <a href=\"http://flask.pocoo.org/extensions/\">packages</a>.</p><p>While we may have set up our first Flask application, as it stands we've only built something useless so far. Consider this to be the beginning of many, many Flask tips to come.</p>","url":"https://hackersandslackers.com/starting-a-python-web-app-with-heroku/","uuid":"c426aeae-5f78-405e-8452-57e8fc110b12","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c64981a7c8ecc6ee30c6870"}}]}},"pageContext":{"pageNumber":31,"humanPageNumber":32,"skip":372,"limit":12,"numberOfPages":33,"previousPagePath":"/page/31","nextPagePath":"/page/33"}}