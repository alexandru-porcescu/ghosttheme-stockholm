{"data":{"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c36debc797a4f6f1db68dbf","title":"Lynx Roundup, January 13th","slug":"lynx-roundup-january-13th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/lynx/134@2x.jpg","excerpt":"The neural net that knows when your cat wants to go out!  Cool old-timey graphs!  Collective intelligence with ants!","custom_excerpt":"The neural net that knows when your cat wants to go out!  Cool old-timey graphs!  Collective intelligence with ants!","created_at_pretty":"10 January, 2019","published_at_pretty":"13 January, 2019","updated_at_pretty":"13 January, 2019","created_at":"2019-01-10T00:57:16.000-05:00","published_at":"2019-01-13T07:00:00.000-05:00","updated_at":"2019-01-13T07:00:00.000-05:00","meta_title":"Lynx Roundup, January 13th | Hackers and Slackers","meta_description":"The neural net that knows when your cat wants to go out!  Cool old-timey graphs!  Collective intelligence with ants!","og_description":"The neural net that knows when your cat wants to go out!  Cool old-timey graphs!  Collective intelligence with ants!","og_image":"https://hackersandslackers.com/content/images/lynx/134@2x.jpg","og_title":"Lynx Roundup, January 13th","twitter_description":"The neural net that knows when your cat wants to go out!  Cool old-timey graphs!  Collective intelligence with ants!","twitter_image":"https://hackersandslackers.com/content/images/lynx/134@2x.jpg","twitter_title":"Lynx Roundup, January 13th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"https://hackaday.com/2018/12/21/neural-network-knows-when-cat-wants-to-go-outside/\n\nhttps://richardbrath.wordpress.com/2018/12/31/album-de-statistique-graphique/\n\nhttps://bair.berkeley.edu/blog/2018/12/12/rllib/\n\nhttps://twitter.com/SarahTaber_bww/status/1074864735143804928\n\nhttps://phys.org/news/2018-12-metabolic-machine.html\n\nhttps://www.npr.org/sections/health-shots/2018/12/21/678342879/scientists-find-a-brain-circuit-that-could-explain-seasonal-depression\n\nhttps://aeon.co/ideas/an-ant-colony-has-memories-that-its-individual-members-dont-have","html":"<p></p><p><a href=\"https://hackaday.com/2018/12/21/neural-network-knows-when-cat-wants-to-go-outside/\">https://hackaday.com/2018/12/21/neural-network-knows-when-cat-wants-to-go-outside/</a></p><p><a href=\"https://richardbrath.wordpress.com/2018/12/31/album-de-statistique-graphique/\">https://richardbrath.wordpress.com/2018/12/31/album-de-statistique-graphique/</a></p><p><a href=\"https://bair.berkeley.edu/blog/2018/12/12/rllib/\">https://bair.berkeley.edu/blog/2018/12/12/rllib/</a></p><p><a href=\"https://twitter.com/SarahTaber_bww/status/1074864735143804928\">https://twitter.com/SarahTaber_bww/status/1074864735143804928</a></p><p><a href=\"https://phys.org/news/2018-12-metabolic-machine.html\">https://phys.org/news/2018-12-metabolic-machine.html</a></p><p><a href=\"https://www.npr.org/sections/health-shots/2018/12/21/678342879/scientists-find-a-brain-circuit-that-could-explain-seasonal-depression\">https://www.npr.org/sections/health-shots/2018/12/21/678342879/scientists-find-a-brain-circuit-that-could-explain-seasonal-depression</a></p><p><a href=\"https://aeon.co/ideas/an-ant-colony-has-memories-that-its-individual-members-dont-have\">https://aeon.co/ideas/an-ant-colony-has-memories-that-its-individual-members-dont-have</a></p>","url":"https://hackersandslackers.com/lynx-roundup-january-13th/","uuid":"f431de1f-7982-4a13-b26c-d896a65236a9","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c36debc797a4f6f1db68dbf"}},{"node":{"id":"Ghost__Post__5c36de56797a4f6f1db68dba","title":"Lynx Roundup, January 12th","slug":"lynx-roundup-january-12th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/lynx/133@2x.jpg","excerpt":"Quines in Clojure!  Brain activity into speech via AI!  Dealing with big-ish data in Pandas!","custom_excerpt":"Quines in Clojure!  Brain activity into speech via AI!  Dealing with big-ish data in Pandas!","created_at_pretty":"10 January, 2019","published_at_pretty":"12 January, 2019","updated_at_pretty":"12 January, 2019","created_at":"2019-01-10T00:55:34.000-05:00","published_at":"2019-01-12T07:00:00.000-05:00","updated_at":"2019-01-12T07:00:00.000-05:00","meta_title":"Lynx Roundup, January 12th | Hackers and Slackers","meta_description":"Quines in Clojure!  Brain activity into speech via AI!  Dealing with big-ish data in Pandas!","og_description":"Quines in Clojure!  Brain activity into speech via AI!  Dealing with big-ish data in Pandas!","og_image":"https://hackersandslackers.com/content/images/lynx/133@2x.jpg","og_title":"Lynx Roundup, January 12th","twitter_description":"Quines in Clojure!  Brain activity into speech via AI!  Dealing with big-ish data in Pandas!","twitter_image":"https://hackersandslackers.com/content/images/lynx/133@2x.jpg","twitter_title":"Lynx Roundup, January 12th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"https://github.com/trekhleb/homemade-machine-learning\n\nhttps://www.theverge.com/2018/12/31/18162541/vein-authentication-wax-hand-hack-starbug\n\nhttp://blog.klipse.tech/clojure/2019/01/08/quines-in-clojure.html\n\nhttp://russolsen.com/articles/2012/08/09/the-best-programming-advice-i-ever-got.html\n\nhttps://github.com/dmlc/tvm\n\nhttps://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas\n\nhttps://www.sciencemag.org/news/2019/01/artificial-intelligence-turns-brain-activity-speech","html":"<p></p><p><a href=\"https://github.com/trekhleb/homemade-machine-learning\">https://github.com/trekhleb/homemade-machine-learning</a></p><p><a href=\"https://www.theverge.com/2018/12/31/18162541/vein-authentication-wax-hand-hack-starbug\">https://www.theverge.com/2018/12/31/18162541/vein-authentication-wax-hand-hack-starbug</a></p><p><a href=\"http://blog.klipse.tech/clojure/2019/01/08/quines-in-clojure.html\">http://blog.klipse.tech/clojure/2019/01/08/quines-in-clojure.html</a></p><p><a href=\"http://russolsen.com/articles/2012/08/09/the-best-programming-advice-i-ever-got.html\">http://russolsen.com/articles/2012/08/09/the-best-programming-advice-i-ever-got.html</a></p><p><a href=\"https://github.com/dmlc/tvm\">https://github.com/dmlc/tvm</a></p><p><a href=\"https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas\">https://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas</a></p><p><a href=\"https://www.sciencemag.org/news/2019/01/artificial-intelligence-turns-brain-activity-speech\">https://www.sciencemag.org/news/2019/01/artificial-intelligence-turns-brain-activity-speech</a></p>","url":"https://hackersandslackers.com/lynx-roundup-january-12th/","uuid":"854a535c-ef4c-4d0c-bd99-a5dc5f11a184","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c36de56797a4f6f1db68dba"}},{"node":{"id":"Ghost__Post__5c36ddea797a4f6f1db68db5","title":"Lynx Roundup, January 11th","slug":"lynx-roundup-january-11th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/71-1@2x.jpg","excerpt":"Euclid's Elements with cool modern graphic design!  Vaex for out-of-core data processing!  Why data is never raw!","custom_excerpt":"Euclid's Elements with cool modern graphic design!  Vaex for out-of-core data processing!  Why data is never raw!","created_at_pretty":"10 January, 2019","published_at_pretty":"11 January, 2019","updated_at_pretty":"14 February, 2019","created_at":"2019-01-10T00:53:46.000-05:00","published_at":"2019-01-11T07:00:00.000-05:00","updated_at":"2019-02-14T04:51:52.000-05:00","meta_title":"Lynx Roundup, January 11th | Hackers and Slackers","meta_description":"Euclid's Elements with cool modern graphic design!  Vaex for out-of-core data processing!  Why data is never raw!","og_description":"Euclid's Elements with cool modern graphic design!  Vaex for out-of-core data processing!  Why data is never raw!","og_image":"https://hackersandslackers.com/content/images/2019/02/71-1@2x.jpg","og_title":"Lynx Roundup, January 11th","twitter_description":"Euclid's Elements with cool modern graphic design!  Vaex for out-of-core data processing!  Why data is never raw!","twitter_image":"https://hackersandslackers.com/content/images/2019/02/71-1@2x.jpg","twitter_title":"Lynx Roundup, January 11th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"https://flowingdata.com/2018/12/18/modern-reproduction-of-1847-geometry-books/\n\nhttps://medium.com/vaex/vaex-out-of-core-dataframes-for-python-and-fast-visualization-12c102db044a\n\nhttps://www.geodose.com/2018/11/create-simple-live-flight-tracking-python.html\n\nhttps://www.thenewatlantis.com/publications/why-data-is-never-raw\n\nhttps://towardsdatascience.com/should-data-scientists-know-how-to-write-production-code-ae38f9e2f339\n\nhttps://github.com/ericmjl/pyjanitor/tree/master\n\nhttps://medium.com/incerto/iq-is-largely-a-pseudoscientific-swindle-f131c101ba39","html":"<p></p><p><a href=\"https://flowingdata.com/2018/12/18/modern-reproduction-of-1847-geometry-books/\">https://flowingdata.com/2018/12/18/modern-reproduction-of-1847-geometry-books/</a></p><p><a href=\"https://medium.com/vaex/vaex-out-of-core-dataframes-for-python-and-fast-visualization-12c102db044a\">https://medium.com/vaex/vaex-out-of-core-dataframes-for-python-and-fast-visualization-12c102db044a</a></p><p><a href=\"https://www.geodose.com/2018/11/create-simple-live-flight-tracking-python.html\">https://www.geodose.com/2018/11/create-simple-live-flight-tracking-python.html</a></p><p><a href=\"https://www.thenewatlantis.com/publications/why-data-is-never-raw\">https://www.thenewatlantis.com/publications/why-data-is-never-raw</a></p><p><a href=\"https://towardsdatascience.com/should-data-scientists-know-how-to-write-production-code-ae38f9e2f339\">https://towardsdatascience.com/should-data-scientists-know-how-to-write-production-code-ae38f9e2f339</a></p><p><a href=\"https://github.com/ericmjl/pyjanitor/tree/master\">https://github.com/ericmjl/pyjanitor/tree/master</a></p><p><a href=\"https://medium.com/incerto/iq-is-largely-a-pseudoscientific-swindle-f131c101ba39\">https://medium.com/incerto/iq-is-largely-a-pseudoscientific-swindle-f131c101ba39</a></p>","url":"https://hackersandslackers.com/lynx-roundup-january-11th/","uuid":"c81126e2-cb2c-4551-997a-97864c3ec3d2","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c36ddea797a4f6f1db68db5"}},{"node":{"id":"Ghost__Post__5c36dc57797a4f6f1db68db0","title":"Lynx Roundup, January 10th","slug":"lynx-roundup-january-10th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/lynx/70@2x.jpg","excerpt":"Bit selectors!  Cleaning data with unsupervised learning!  Interactive exploration of a Python dictionary!","custom_excerpt":"Bit selectors!  Cleaning data with unsupervised learning!  Interactive exploration of a Python dictionary!","created_at_pretty":"10 January, 2019","published_at_pretty":"10 January, 2019","updated_at_pretty":"10 January, 2019","created_at":"2019-01-10T00:47:03.000-05:00","published_at":"2019-01-10T07:00:00.000-05:00","updated_at":"2019-01-10T07:00:00.000-05:00","meta_title":"Lynx Roundup, January 10th | Hackers and Slackers","meta_description":"Bit selectors!  Cleaning data with unsupervised learning!  Interactive exploration of a Python dictionary!","og_description":"Bit selectors!  Cleaning data with unsupervised learning!  Interactive exploration of a Python dictionary!","og_image":"https://hackersandslackers.com/content/images/lynx/70@2x.jpg","og_title":"Lynx Roundup, January 10th","twitter_description":"Bit selectors!  Cleaning data with unsupervised learning!  Interactive exploration of a Python dictionary!","twitter_image":"https://hackersandslackers.com/content/images/lynx/70@2x.jpg","twitter_title":"Lynx Roundup, January 10th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"https://thememoryguy.com/emerging-memories-today-understanding-bit-selectors/\n\nhttps://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book\n\nhttps://towardsdatascience.com/clean-your-data-with-unsupervised-machine-learning-8491af733595\n\nhttps://just-taking-a-ride.com/inside_python_dict/chapter1.html\n\nhttps://treyhunner.com/2018/12/why-you-should-be-using-pathlib/\n\nhttps://www.theverge.com/circuitbreaker/2018/12/26/18156600/doomba-roomba-cleaning-maps-doom-levels-rich-whitehouse\n\nhttps://sisu.ai/blog/making-ml-useful-is-a-platform-problem/","html":"<p></p><p><a href=\"https://thememoryguy.com/emerging-memories-today-understanding-bit-selectors/\">https://thememoryguy.com/emerging-memories-today-understanding-bit-selectors/</a></p><p><a href=\"https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book\">https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book</a></p><p><a href=\"https://towardsdatascience.com/clean-your-data-with-unsupervised-machine-learning-8491af733595\">https://towardsdatascience.com/clean-your-data-with-unsupervised-machine-learning-8491af733595</a></p><p><a href=\"https://just-taking-a-ride.com/inside_python_dict/chapter1.html\">https://just-taking-a-ride.com/inside_python_dict/chapter1.html</a></p><p><a href=\"https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/\">https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/</a></p><p><a href=\"https://www.theverge.com/circuitbreaker/2018/12/26/18156600/doomba-roomba-cleaning-maps-doom-levels-rich-whitehouse\">https://www.theverge.com/circuitbreaker/2018/12/26/18156600/doomba-roomba-cleaning-maps-doom-levels-rich-whitehouse</a></p><p><a href=\"https://sisu.ai/blog/making-ml-useful-is-a-platform-problem/\">https://sisu.ai/blog/making-ml-useful-is-a-platform-problem/</a></p>","url":"https://hackersandslackers.com/lynx-roundup-january-10th/","uuid":"f251a7b0-010c-405f-ad41-3ab9a339649d","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c36dc57797a4f6f1db68db0"}},{"node":{"id":"Ghost__Post__5c3409a094d3e847951adf44","title":"Pythonic Database Management with SQLAlchemy","slug":"pythonic-database-management-with-sqlalchemy","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/sqlalchemy2-1-2.jpg","excerpt":"The iconic Python library for handling any conceivable database interaction.","custom_excerpt":"The iconic Python library for handling any conceivable database interaction.","created_at_pretty":"08 January, 2019","published_at_pretty":"09 January, 2019","updated_at_pretty":"28 March, 2019","created_at":"2019-01-07T21:23:28.000-05:00","published_at":"2019-01-09T08:00:00.000-05:00","updated_at":"2019-03-28T11:17:45.000-04:00","meta_title":"Pythonic Database Management with SQLAlchemy | Hackers and Slackers","meta_description":"The iconic Python library for handling any conceivable database interaction.","og_description":"The iconic Python library for handling any conceivable database interaction.","og_image":"https://hackersandslackers.com/content/images/2019/03/sqlalchemy2-1-2.jpg","og_title":"Pythonic Database Management with SQLAlchemy","twitter_description":"The iconic Python library for handling any conceivable database interaction.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/sqlalchemy2-1-1.jpg","twitter_title":"Pythonic Database Management with SQLAlchemy","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"SQL","slug":"sql","description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","feature_image":"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/sql-tag.jpg","meta_description":"Configure relational databases, brush up on your query language syntax, or find third-party services to interact with your data.","meta_title":"Working with SQL | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"Something we've taken for granted thus far on Hackers and Slackers is a library\nmost data professionals have accepted as an undisputed standard: SQLAlchemy\n[https://www.sqlalchemy.org/].\n\nIn the past, we've covered database connection management and querying using\nlibraries such as PyMySQL [https://hackersandslackers.com/using-pymysql/]  and \nPsycopg2\n[https://hackersandslackers.com/psycopg2-postgres-python-the-old-fashioned-way/]\n, both of which do an excellent job of interacting with databases just as we'd\nexpect them to. The nature of opening/closing DB connections and working with\ncursors hasn't changed much in the past few decades (nearly the lifespan of\nrelational databases themselves). While boilerplate is boring, at least it has\nremained consistent, one might figure. That may  have been the case, but the\nphilosophical boom of MVC frameworks nearly a decade ago sparked the emergence\nof popularity for ORMs. While the world was singing praises of object-oriented\nprogramming, containing database-oriented functionality within objects must have\nbeen a wet dream.\n\nThe only thing shocking about SQLAlchemy's popularity is its flip side: the\ncontingency of those functioning without  SQLAlchemy as a part of their regular\nstack. Whether this stems from unawareness or active reluctance to change, data\nteams using Python without a proper ORM are surprisingly prevalent. It's easy to\nforget the reality of the workforce when our interactions with other\nprofessionals come mostly from blogs published by those at the top of their\nfield.\n\nI realize the \"this is how we've always done it\" attitude is a cliché with no\nshortage of commentary. Tales of adopting new (relatively speaking) practices\ndominate Silicon Valley blogs every day- it's the manner in which this is\nmanifested, however, that catches me off guard. In this case, resistance to a\nsingle Python library can shed light on a frightening mental model that has\nimplications up and down a corporation's stack.\n\nPutting The 'M' In MVC\nFrameworks which enforce a Model-View-Controller have held undisputed consensus\nfor long enough: none of us need to recap why creating apps this way is\nunequivocally correct. To understand why side-stepping an ORM is so significant,\nlet's recall what ORM stands for:\n\n> Object-Relational Mapping, commonly referred to as its abbreviation ORM, is a\ntechnique that connects the rich objects of an application to tables in a\nrelational database management system. Using ORM, the properties and\nrelationships of the objects in an application can be easily stored and\nretrieved from a database without writing SQL statements directly and with less\noverall database access code. - Active Record\n[https://guides.rubyonrails.org/active_record_basics.html]\nORMs allow us to interact with databases simply by modifying objects in code\n(such as classes) as opposed to generating SQL queries by hand for each database\ninteraction. Bouncing from application code to SQL is a major context switch,\nand the more interactions we introduce, the more out of control our app becomes.\n \n\nTo illustrate the alternative to this using models, I'll use an example offered\nby Flask-SQLAlchemy. Let's say we have a table of users which contains columns\nfor id, username,  and email. A model for such a table would look as such:\n\nclass User(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    email = db.Column(db.String(120), unique=True, nullable=False)\n\n    def __repr__(self):\n        return '<User %r>' % self.username\n\n\nThe 'model' is an object representing the structure of a single entry in our\ntable. Once our model exists, this is all it takes to create an entry:\n\nnewuser = User(username='admin', email='admin@example.com')\n\n\nThat's a single readable line of code without writing a single line of SQL.\nCompare this to the alternative, which would be to use Psycopg2:\n\nquery = \"INSERT INTO users VALUES username='admin', email='admin@example.com';\"\n\ndef query_function(query):\n  \"\"\"Runs a database query.\"\"\"\n  try:\n    conn = psycopg2.connect(\n      user = config.username,\n      password = config.password,\n      host = config.host,\n      port = config.port,\n      database = config.database)\n      with conn.cursor() as cur:\n         cur.execute(query)\n           cur.close()\n           conn.close()\n  except Exception as e:\n      print(e)\n        \nquery_function(query)\n\n\nSure, query_function()  only needs to be set once, but compare the readability\nof using a model to the following:\n\nquery = \"INSERT INTO users VALUES username='admin', email='admin@example.com';\"\n\nquery_function(query)\n\n\nDespite achieving the same effect, the latter is much less readable or\nmaintainable by human beings. Building an application around raw string queries\ncan quickly become a nightmare.\n\nIntegration With Other Data Libraries\nWhen it comes to golden standards of Python libraries, there is none more\nquintessential to data analysis than Pandas. The pairing of Pandas and\nSQLAlchemy is standard to the point where Pandas has built-in integrations to\ninteract with data from SQLAlchemy. Here's what it takes to turn a database\ntable into a Pandas dataframe with SQLAlchemy as our connector:\n\ndf = pd.read_sql(session.query(Table).filter(User.id == 2).statement,session.bind)\n\n\nOnce again, a single line of Python code!\n\nWriting Queries Purely in Python\nSo far by using SQLAlchemy, we haven't needed to write a single line of SQL: how\nfar could we take this? As far as we want, in fact. SQLAlchemy contains what\nthey've dubbed as function-based query construction, which is to say we can\nconstruct nearly any conceivable SQL query purely in Python by using the methods\noffered to us. For example, here's an update query:\n\nstmt = users.update().values(fullname=\"Fullname: \" + users.c.name)\nconn.execute(stmt)\n\n\nCheck the  full reference to see what I mean\n[https://docs.sqlalchemy.org/en/latest/core/tutorial.html#inserts-and-updates].\nEvery query you've ever needed to write: it's all there. All of it.\n\nSimple Connection Management\nSeeing as how we all now agree that SQLAlchemy is beneficial to our workflow,\nlet's visit square one and see how simple it is to manage connections. The two\nkey words to remember here are engines  and sessions.\n\nThe Engine\nAn engine in SQLAlchemy is merely a bare-bones object representing our database.\nMaking SQLAlchemy aware of our database is as simple as these two lines:\n\nfrom sqlalchemy import create_engine\nengine = create_engine('sqlite:///:memory:', echo=True)\n\n\nThe Engine can interact with our database by accepting a simple URI. Once engine \n exists, we could in theory use engine exclusively via functions such as \nengine.connect()  and engine.execute().\n\nSessions\nTo interact with our database in a Pythonic manner via the ORM, we'll need to\ncreate a session  from the engine we just declared. Thus our code expands:\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\nengine = create_engine('sqlite:///:memory:', echo=True)\nSession = sessionmaker(bind=engine)\n\n\nThat's all it takes! Now just as before, we can use SQLAlchemy's ORM and\nbuilt-in functions to make simple interacts:\n\nnew_user = User(name='todd', fullname='Todd Hacker', password='toddspassword')\nsession.add(new_user)\n\n\nTakeaway Goodies\nIt's worth mentioning that SQLAlchemy works with nearly every type of database,\nand does so by leveraging the base Python library for the respective type of\ndatabase. For example, it probably seems to the outsider that we've spent some\ntime shitting on Psycopg2. On the contrary, when SQLAlchemy connects to a\nPostgres database, it is using the Psycopg2 library under the hood to manage the\nboilerplate for us. The same goes for every other type of relational database\n[https://docs.sqlalchemy.org/en/latest/core/engines.html]  along with their\nstandard libraries.\n\nThere are plenty of more reasons [https://www.sqlalchemy.org/features.html]  why\nSQLAlchemy is beneficial to the point where it is arguably critical to data\nanalysis workflows. The critical point to be made here is that leaving\nSQLAlchemy out of any data workflow only hurts the person writing the code, or\nmore importantly, all those who come after.","html":"<p>Something we've taken for granted thus far on Hackers and Slackers is a library most data professionals have accepted as an undisputed standard: <strong><a href=\"https://www.sqlalchemy.org/\">SQLAlchemy</a></strong>.</p><p>In the past, we've covered database connection management and querying using libraries such as <a href=\"https://hackersandslackers.com/using-pymysql/\"><strong>PyMySQL</strong></a> and <strong><a href=\"https://hackersandslackers.com/psycopg2-postgres-python-the-old-fashioned-way/\">Psycopg2</a></strong>, both of which do an excellent job of interacting with databases just as we'd expect them to. The nature of opening/closing DB connections and working with cursors hasn't changed much in the past few decades (nearly the lifespan of relational databases themselves). While boilerplate is boring, at least it has remained consistent, one might figure. That <strong><em>may</em></strong> have been the case, but the philosophical boom of MVC frameworks nearly a decade ago sparked the emergence of popularity for ORMs. While the world was singing praises of object-oriented programming, containing database-oriented functionality within objects must have been a wet dream.</p><p>The only thing shocking about SQLAlchemy's popularity is its flip side: the contingency of those functioning <em>without</em> SQLAlchemy as a part of their regular stack. Whether this stems from unawareness or active reluctance to change, data teams using Python without a proper ORM are surprisingly prevalent. It's easy to forget the reality of the workforce when our interactions with other professionals come mostly from blogs published by those at the top of their field.</p><p>I realize the \"this is how we've always done it\" attitude is a cliché with no shortage of commentary. Tales of adopting new (relatively speaking) practices dominate Silicon Valley blogs every day- it's the manner in which this is manifested, however, that catches me off guard. In this case, resistance to a single Python library can shed light on a frightening mental model that has implications up and down a corporation's stack.</p><h2 id=\"putting-the-m-in-mvc\">Putting The 'M' In MVC</h2><p>Frameworks which enforce a Model-View-Controller have held undisputed consensus for long enough: none of us need to recap why creating apps this way is unequivocally correct. To understand why side-stepping an ORM is so significant, let's recall what ORM stands for:</p><blockquote><em>Object-Relational Mapping, commonly referred to as its abbreviation ORM, is a technique that connects the rich objects of an application to tables in a relational database management system. Using ORM, the properties and relationships of the objects in an application can be easily stored and retrieved from a database without writing SQL statements directly and with less overall database access code. <strong>- <a href=\"https://guides.rubyonrails.org/active_record_basics.html\">Active Record</a></strong></em></blockquote><p>ORMs allow us to interact with databases simply by modifying objects in code (such as classes) as opposed to generating SQL queries by hand for each database interaction. Bouncing from application code to SQL is a <em>major context switch</em>, and the more interactions we introduce, the more out of control our app becomes. </p><p>To illustrate the alternative to this using models, I'll use an example offered by <strong>Flask-SQLAlchemy</strong>. Let's say we have a table of users which contains columns for <strong>id, username,</strong> and <strong>email. </strong>A model for such a table would look as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">class User(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    email = db.Column(db.String(120), unique=True, nullable=False)\n\n    def __repr__(self):\n        return '&lt;User %r&gt;' % self.username\n</code></pre>\n<!--kg-card-end: markdown--><p>The 'model' is an object representing the structure of a single entry in our table. Once our model exists, this is all it takes to create an entry:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">newuser = User(username='admin', email='admin@example.com')\n</code></pre>\n<!--kg-card-end: markdown--><p>That's a single readable line of code without writing a single line of SQL. Compare this to the alternative, which would be to use Psycopg2:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">query = &quot;INSERT INTO users VALUES username='admin', email='admin@example.com';&quot;\n\ndef query_function(query):\n  &quot;&quot;&quot;Runs a database query.&quot;&quot;&quot;\n  try:\n    conn = psycopg2.connect(\n      user = config.username,\n      password = config.password,\n      host = config.host,\n      port = config.port,\n      database = config.database)\n      with conn.cursor() as cur:\n         cur.execute(query)\n           cur.close()\n           conn.close()\n  except Exception as e:\n      print(e)\n        \nquery_function(query)\n</code></pre>\n<!--kg-card-end: markdown--><p>Sure, <code>query_function()</code> only needs to be set once, but compare the readability of using a model to the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">query = &quot;INSERT INTO users VALUES username='admin', email='admin@example.com';&quot;\n\nquery_function(query)\n</code></pre>\n<!--kg-card-end: markdown--><p>Despite achieving the same effect, the latter is much less readable or maintainable by human beings. Building an application around raw string queries can quickly become a nightmare.</p><h2 id=\"integration-with-other-data-libraries\">Integration With Other Data Libraries</h2><p>When it comes to golden standards of Python libraries, there is none more quintessential to data analysis than Pandas. The pairing of Pandas and SQLAlchemy is standard to the point where Pandas has built-in integrations to interact with data from SQLAlchemy. Here's what it takes to turn a database table into a Pandas dataframe with SQLAlchemy as our connector:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">df = pd.read_sql(session.query(Table).filter(User.id == 2).statement,session.bind)\n</code></pre>\n<!--kg-card-end: markdown--><p>Once again, a single line of Python code!</p><h2 id=\"writing-queries-purely-in-python\">Writing Queries Purely in Python</h2><p>So far by using SQLAlchemy, we haven't needed to write a single line of SQL: how far could we take this? As far as we want, in fact. SQLAlchemy contains what they've dubbed as <strong>function-based query construction, </strong>which is to say we can construct nearly any conceivable SQL query purely in Python by using the methods offered to us. For example, here's an update query:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">stmt = users.update().values(fullname=&quot;Fullname: &quot; + users.c.name)\nconn.execute(stmt)\n</code></pre>\n<!--kg-card-end: markdown--><p>Check the<a href=\"https://docs.sqlalchemy.org/en/latest/core/tutorial.html#inserts-and-updates\"> full reference to see what I mean</a>. Every query you've ever needed to write: it's all there. All of it.</p><h2 id=\"simple-connection-management\">Simple Connection Management</h2><p>Seeing as how we all now agree that SQLAlchemy is beneficial to our workflow, let's visit square one and see how simple it is to manage connections. The two key words to remember here are <strong>engines</strong> and <strong>sessions</strong>.</p><h3 id=\"the-engine\">The Engine</h3><p>An engine in SQLAlchemy is merely a bare-bones object representing our database. Making SQLAlchemy aware of our database is as simple as these two lines:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from sqlalchemy import create_engine\nengine = create_engine('sqlite:///:memory:', echo=True)\n</code></pre>\n<!--kg-card-end: markdown--><p>The Engine can interact with our database by accepting a simple URI. Once <code>engine</code> exists, we could in theory use engine exclusively via functions such as <code>engine.connect()</code> and <code>engine.execute()</code>.</p><h3 id=\"sessions\">Sessions</h3><p>To interact with our database in a Pythonic manner via the ORM, we'll need to create a <strong>session</strong> from the <strong>engine </strong>we just declared. Thus our code expands:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\nengine = create_engine('sqlite:///:memory:', echo=True)\nSession = sessionmaker(bind=engine)\n</code></pre>\n<!--kg-card-end: markdown--><p>That's all it takes! Now just as before, we can use SQLAlchemy's ORM and built-in functions to make simple interacts:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">new_user = User(name='todd', fullname='Todd Hacker', password='toddspassword')\nsession.add(new_user)\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"takeaway-goodies\">Takeaway Goodies</h2><p>It's worth mentioning that SQLAlchemy works with nearly every type of database, and does so by leveraging the base Python library for the respective type of database. For example, it probably seems to the outsider that we've spent some time shitting on Psycopg2. On the contrary, when SQLAlchemy connects to a Postgres database, it is using the Psycopg2 library under the hood to manage the boilerplate for us. The same goes for <a href=\"https://docs.sqlalchemy.org/en/latest/core/engines.html\">every other type of relational database</a> along with their standard libraries.</p><p>There are <a href=\"https://www.sqlalchemy.org/features.html\">plenty of more reasons</a> why SQLAlchemy is beneficial to the point where it is arguably critical to data analysis workflows. The critical point to be made here is that leaving SQLAlchemy out of any data workflow only hurts the person writing the code, or more importantly, all those who come after.</p>","url":"https://hackersandslackers.com/pythonic-database-management-with-sqlalchemy/","uuid":"7246d9db-39cb-44aa-9da8-cf87df00eeff","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c3409a094d3e847951adf44"}},{"node":{"id":"Ghost__Post__5c34086694d3e847951adf3e","title":"Poetically Packaging Your Python Project","slug":"poetic-python-project-packaging","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/01/poetry4@2x.jpg","excerpt":"Manage your projects with Poetry to handle dependencies, envs, packaging, etc.","custom_excerpt":"Manage your projects with Poetry to handle dependencies, envs, packaging, etc.","created_at_pretty":"08 January, 2019","published_at_pretty":"08 January, 2019","updated_at_pretty":"09 April, 2019","created_at":"2019-01-07T21:18:14.000-05:00","published_at":"2019-01-08T10:16:00.000-05:00","updated_at":"2019-04-09T17:59:40.000-04:00","meta_title":"Poetically Packaging Your Python Project | Hackers and Slackers","meta_description":"Manage your projects with Poetry: a dependency manager and project packager all in one. Handle your environment and project data in a single file.","og_description":"Manage your projects with Poetry to handle dependencies, envs, packaging, etc.","og_image":"https://hackersandslackers.com/content/images/2019/01/poetry4@2x.jpg","og_title":"Poetically Packaging Your Python Project","twitter_description":"Manage your projects with Poetry to handle dependencies, envs, packaging, etc.","twitter_image":"https://hackersandslackers.com/content/images/2019/01/poetry4@2x.jpg","twitter_title":"Poetically Packaging Your Python Project","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"}],"plaintext":"It wasn't long ago that we Hackers were singing the praises of Pipenv\n[https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/]\n: Python's seemingly superior dependency manager at the time. While we hold much\nlove in hearts, sometimes there is love to go around. We just so happen to be\nfair weather fans, which reminds me: what has Pipenv done for me lately?\n\nAs you've probably guessed (considering its a piece of software), nothing much.\nWell, there was that time when pip upgraded from v.18  to v.18.1, which broke\nPipenv entirely with almost minimal acknowledgment (for all I know this might\nstill be broken). As our lives seemed to fade, a miracle emerged from the ashes:\na young, smart, attractive alternative to Pipenv that's been whispering in my\near, and promising the world. Her name is Poetry [https://poetry.eustace.io/].\n\nWhat Light Through Yonder GitHub Breaks?\nPoetry stems from the genuine frustration that comes with not only managing\nenvironments and dependencies in Python, but the fact that even solving this\nproblem (albeit poorly) still doesn't solve the related tasks needing\nfulfillment when creating respectable Python projects. Consider Node's \npackage.json: a single file which contains a project's metadata, prod\ndependencies, dev dependencies, contact information, etc. Instead, Python\nprojects usually come with the following:\n\nSetup.py\nIf you've never bothered to publish a package to PyPI before, there's a decent\nchance you may not be very familiar with some of the nuances that come with \nsetup.py  or why you'd bother creating one. This is a losing mentality: we\nshould assume that most (or some) of the things we build might become useful\nenough to distribute some day.\n\nThus, we get this monstrosity:\n\nfrom setuptools import setup, find_packages, tests_require, packages, name\n\nwith open(\"README\", 'r') as f:\n    long_description = f.read()\n\nsetup = (\n    name='Fake Project',\n    version='1.0',\n    description='A fake project used for example purposes.',\n    long_description=long_description,\n    author='Todd Birchard',\n    author_email='todd@hackersandslackers.com',\n    maintainer='Some Loser',\n    maintainer_email='some.loser@example.com,\n    url=\"https://github.com/toddbirchard/fake-project\",\n    license='MIT',\n    include_package_data=True,\n    package_dir={'application'}\n    packages=['distutils', 'modules'],\n    tests_require=[\"pytest\"],\n    cmdclass={\"pytest\": PyTest},\n    classifiers=[\n          'Development Status :: 2 - Beta',\n          'Environment :: Console',\n          'Environment :: Web Environment',\n          'Intended Audience :: End Users/Desktop',\n          'Intended Audience :: Developers',\n          'Intended Audience :: System Administrators',\n          'License :: OSI Approved :: Python Software Foundation License',\n          'Operating System :: MacOS :: MacOS X',\n          'Operating System :: Microsoft :: Windows',\n          'Operating System :: POSIX',\n          'Programming Language :: Python',\n          'Topic :: Communications :: Email',\n          'Topic :: Office/Business',\n          'Topic :: Software Development :: Bug Tracking',\n          ],\n)\n\n\nMany of the metadata fields are rather self-explanatory. But what about the\nfields related to package dependencies, such as package_dir or packages? Wasn't\nthis already handled in our Pipfile? On top of that, we need to specify then the\ntest suite we're using via tests_require  and cmdclass? Short answer: pretty\nmuch.\n\nSetup.cfg\nThe real joke with setup.py  is that it needs its own configuration file: yes, a\nconfiguration file for your configuration file. setup.cfg, as the name\nsuggestions, sets even more granular configurations for the things mentioned in \nsetup.py, such as how pytest  should be handled, etc. Let's not get into it, but\nhere's an example:\n\n[coverage:run]\nomit = */test/*\n\n[flake8]\nexclude = *.egg*,.env,.git,.tox,_*,build*,dist*,venv*,python2/,python3/\nignore = E261,W503\nmax-line-length = 121\n\n[tool:pytest]\nminversion = 3.2\naddopts =\n  # --fulltrace\n  # -n auto\n  --cov-config=setup.cfg\n  --cov=httplib2\n  --noconftest\n  --showlocals\n  --strict\n  --tb=short\n  --timeout=17\n  --verbose\n  -ra\n\n\nPipfile and Pipfile.lock\nIf you have been using Pipenv, you'll recognize these files as being responsible\nfor setting your Python version and dependencies. But wait- didn't we also need\nto specify dependencies in setup.py?  Yes, we did. There is no God, but if there\nwere, he'd probably hate you. Here's all the work you'd need to do creating an\nacceptable Pipfile:\n\n[[source]]\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\nFlask-SQLAlchemy = \"*\"\npsycopg2 = \"*\"\npsycopg2-binary = \"*\"\nrequests = \"*\"\nconfigparser=\"*\"\nmapbox=\"*\"\nflask=\"*\"\npandas=\"*\"\nFlask-Assets=\"*\"\nlibsass=\"*\"\njsmin=\"*\"\ndash_core_components=\"*\"\ndash-table=\"*\"\ndash_html_components=\"*\"\ndash=\"*\"\nflask-session=\"*\"\nflask-redis=\"*\"\ngunicorn=\"*\"\npytest-flask=\"*\"\n\n\n[dev-packages]\n\n[requires]\npython_version = \"3.7.1\"\n\n\n\nBut wait, there's more!\n\nRequirements.txt\nBecause the Pipfile format has not been adopted as a standard for dependency\nmanagement, we still  need to create a requirements.txt file if we want to\ndeploy our application to respectable hosts such as Google App Engine  or\nwhat-have-you. So now we have this ugly son of a bitch from the stone age to\ndeal with as well:\n\natomicwrites==1.2.1\nattrs==18.2.0\nboto3==1.9.75\nbotocore==1.12.75\nCacheControl==0.12.5\ncertifi==2018.11.29\nchardet==3.0.4\nClick==7.0\nconfigparser==3.5.0\ndash==0.35.1\ndash-core-components==0.42.0\ndash-html-components==0.13.4\ndash-renderer==0.16.1\ndash-table==3.1.11\ndecorator==4.3.0\ndocutils==0.14\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Compress==1.4.0\nFlask-Redis==0.3.0\nFlask-Session==0.3.1\nFlask-SQLAlchemy==2.3.2\ngunicorn==19.9.0\nidna==2.8\nipython-genutils==0.2.0\niso3166==0.9\nitsdangerous==1.1.0\nJinja2==2.10\njmespath==0.9.3\njsmin==2.2.2\njsonschema==2.6.0\njupyter-core==4.4.0\nlibsass==0.17.0\nmapbox==0.17.2\nMarkupSafe==1.1.0\nmore-itertools==5.0.0\nmsgpack==0.6.0\nnbformat==4.4.0\nnumpy==1.15.4\npandas==0.23.4\nplotly==3.5.0\npluggy==0.8.0\npolyline==1.3.2\npsycopg2==2.7.6.1\npsycopg2-binary==2.7.6.1\npy==1.7.0\npytest==4.1.0\npytest-flask==0.14.0\npython-dateutil==2.7.5\npytz==2018.9\nredis==3.0.1\nrequests==2.21.0\nretrying==1.3.3\ns3transfer==0.1.13\nsix==1.12.0\nSQLAlchemy==1.2.15\ntraitlets==4.3.2\nuritemplate==3.0.0\nurllib3==1.24.1\nwebassets==0.12.1\nWerkzeug==0.14.1\n\n\nMANIFEST.in\nYES, THERE'S MORE. If you're not bothered by now, please leave this blog\nimmediately. The job market is ripe for neckbeards who take pleasure in\nunnecessary complexity. Until the robots take over, this blog is for humans.\n\nAnyway, there's an entire file dedicated to including files in your project\nwhich aren't code. We're entering comically ridiculous territory:\n\ninclude README.rst\ninclude docs/*.txt\ninclude funniest/data.json\n\n\nIt's a Bird! It's a Plane! Its... A Single, Sophisticated Config File?\nI hope you're thoroughly pissed off after looking back at all the things we've\nlet slide by year after year, telling ourselves that this patchwork of standards\nis just fine. Cue our hero: the creator of Poetry:\n\n> Packaging systems and dependency management in Python are rather convoluted and\nhard to understand for newcomers. Even for seasoned developers it might be\ncumbersome at times to create all files needed in a Python project: setup.py,\nrequirements.txt, setup.cfg, MANIFEST.in  and the newly added Pipfile. So I\nwanted a tool that would limit everything to a single configuration file to do:\ndependency management, packaging and publishing.\nOh God yes, but HOW?!?!\n\nIntroducing pyproject.toml\nPoetry is built around a single configuration dubbed pyproject.toml  which has\nbecome an accepted standard in the Python community\n[https://www.python.org/dev/peps/pep-0518/]  by way of PEP 518.  With the weight\nof the Python development community itself, it's safe to say this isn't another\nfad and is worth using.\n\nHere's an example .toml file from the Poetry Github repository\n[https://github.com/sdispater/poetry]:\n\n[tool.poetry]\nname = \"my-package\"\nversion = \"0.1.0\"\ndescription = \"The description of the package\"\n\nlicense = \"MIT\"\n\nauthors = [\n    \"Sébastien Eustace <sebastien@eustace.io>\"\n]\n\nreadme = 'README.md'  # Markdown files are supported\n\nrepository = \"https://github.com/sdispater/poetry\"\nhomepage = \"https://github.com/sdispater/poetry\"\n\nkeywords = ['packaging', 'poetry']\n\n[tool.poetry.dependencies]\npython = \"~2.7 || ^3.2\"  # Compatible python versions must be declared here\ntoml = \"^0.9\"\n# Dependencies with extras\nrequests = { version = \"^2.13\", extras = [ \"security\" ] }\n# Python specific dependencies with prereleases allowed\npathlib2 = { version = \"^2.2\", python = \"~2.7\", allows-prereleases = true }\n# Git dependencies\ncleo = { git = \"https://github.com/sdispater/cleo.git\", branch = \"master\" }\n\n# Optional dependencies (extras)\npendulum = { version = \"^1.4\", optional = true }\n\n[tool.poetry.dev-dependencies]\npytest = \"^3.0\"\npytest-cov = \"^2.4\"\n\n[tool.poetry.scripts]\nmy-script = 'my_package:main'\n\n\nIn addition to covering the scope of all previously mentioned files, using \npyproject.toml  with Poetry also covers:\n\n * Auto-populating the exclude  section from values found in .gitignore\n * The addition of a keywords  section to be included with the resulting PyPi\n   package\n * Support for version numbers using any syntax, such as wildcard (*)  or carrot\n   (^1.0.0)  syntax\n * Auto-detection for virtual environments, thus a global install that can be\n   used within envs\n\nCreating Poetic Art\nAre we all fired up yet? Right: let's change our workflow forever.\n\nInstallation\n  To install Poetry on OSX, use the following:\n\n$ curl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python\n\n\nThis will create an addition to your ~/.bash_profile. Restart your terminal and\nverify the installation:\n\n$ poetry --version\nPoetry 0.12.10\n\n\nCreating a New Python Project\nNavigate to whichever file path you'd like your new project to call home. To get\nstarted, all we need next is the following command:\n\npoetry new my-package\n\n\nReady for a breath of fresh air? This command generates a basic project\nstructure for you- something that's been missing from Python for a long time\nwhen compared to similar generators for Node or otherwise. The resulting project\nstructure looks as such:\n\nmy-package\n├── pyproject.toml\n├── README.rst\n├── my_package\n│   └── __init__.py\n└── tests\n    ├── __init__.py\n    └── test_my_package\n\n\nOf the beautiful things happening here, the only one we haven't touched on yet\nis Poetry's built-in integration with pytest. Oh, happy day!\n\nAlternative Interactive Installation Method\nIf you'd prefer a bit more handholding, feel free to use poetry init  in an\nempty directory (or a directory without the existing .toml  file) to be walked\nthrough the creation process:\n\n$ poetry init\n\nThis command will guide you through creating your pyproject.toml config.\n\nPackage name [my-package]: Great Package\nVersion [0.1.0]:\nDescription []: Great package for great people.\nAuthor [Todd Birchard <todd@hackersandslackers.com>, n to skip]:\nLicense []: MIT\nCompatible Python versions [^2.7]: ^3.7\n\nWould you like to define your dependencies (require) interactively? (yes/no) [yes] no\n\n\n\nWould you like to define your dev dependencies (require-dev) interactively (yes/no) [yes] no\n\nGenerated file\n\n[tool.poetry]\nname = \"Great Package\"\nversion = \"0.1.0\"\ndescription = \"Great package for great people.\"\nauthors = [\"Todd Birchard <todd@hackersandslackers.com>\"]\nlicense = \"MIT\"\n\n[tool.poetry.dependencies]\npython = \"^3.7\"\n\n[tool.poetry.dev-dependencies]\n\n[build-system]\nrequires = [\"poetry>=0.12\"]\nbuild-backend = \"poetry.masonry.api\"\n\n\nDo you confirm generation? (yes/no) [yes] yes\n\n\nManaging Dependencies in pyproject.toml\nIf you're familiar with Pipfiles, pyproject.toml handles dependencies the same\nway. Just remember that poetry install  installs your listed dependencies, and \npoetry update  will update dependencies in poetry.lock to their latest versions.\n\nCarry on my Wayward Son\nI could spend all day copy-pasting general usage from the Poetry Github page,\nbut I think my work here is done. Do yourself a favor and  take a look at the\nGithub repo [https://github.com/sdispater/poetry]  to make your life easier\nforever. Or at least until the next replacement solution comes along.","html":"<p>It wasn't long ago that we Hackers were <a href=\"https://hackersandslackers.com/pipenv-etc-tracking-your-projects-dependancies/\">singing the praises of Pipenv</a>: Python's seemingly superior dependency manager at the time. While we hold much love in hearts, sometimes there is love to go around. We just so happen to be fair weather fans, which reminds me: what has Pipenv done for me <em>lately</em>?</p><p>As you've probably guessed (considering its a piece of software), nothing much. Well, there was that time when pip upgraded from <code>v.18</code> to <code>v.18.1</code>, which broke Pipenv entirely with almost minimal acknowledgment (for all I know this might still be broken). As our lives seemed to fade, a miracle emerged from the ashes: a young, smart, attractive alternative to Pipenv that's been whispering in my ear, and promising the world. Her name is <a href=\"https://poetry.eustace.io/\"><strong>Poetry</strong></a>.</p><h2 id=\"what-light-through-yonder-github-breaks\">What Light Through Yonder GitHub Breaks?</h2><p>Poetry stems from the genuine frustration that comes with not only managing environments and dependencies in Python, but the fact that even solving this problem (albeit poorly) still doesn't solve the related tasks needing fulfillment when creating respectable Python projects. Consider Node's <code>package.json</code>: a single file which contains a project's metadata, prod dependencies, dev dependencies, contact information, etc. Instead, Python projects usually come with the following:</p><h3 id=\"setup-py\">Setup.py</h3><p>If you've never bothered to publish a package to PyPI before, there's a decent chance you may not be very familiar with some of the nuances that come with <code>setup.py</code> or why you'd bother creating one. This is a losing mentality: we should assume that most (or some) of the things we build might become useful enough to distribute some day.</p><p>Thus, we get this monstrosity:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from setuptools import setup, find_packages, tests_require, packages, name\n\nwith open(&quot;README&quot;, 'r') as f:\n    long_description = f.read()\n\nsetup = (\n    name='Fake Project',\n    version='1.0',\n    description='A fake project used for example purposes.',\n    long_description=long_description,\n    author='Todd Birchard',\n    author_email='todd@hackersandslackers.com',\n    maintainer='Some Loser',\n    maintainer_email='some.loser@example.com,\n    url=&quot;https://github.com/toddbirchard/fake-project&quot;,\n    license='MIT',\n    include_package_data=True,\n    package_dir={'application'}\n    packages=['distutils', 'modules'],\n    tests_require=[&quot;pytest&quot;],\n    cmdclass={&quot;pytest&quot;: PyTest},\n    classifiers=[\n          'Development Status :: 2 - Beta',\n          'Environment :: Console',\n          'Environment :: Web Environment',\n          'Intended Audience :: End Users/Desktop',\n          'Intended Audience :: Developers',\n          'Intended Audience :: System Administrators',\n          'License :: OSI Approved :: Python Software Foundation License',\n          'Operating System :: MacOS :: MacOS X',\n          'Operating System :: Microsoft :: Windows',\n          'Operating System :: POSIX',\n          'Programming Language :: Python',\n          'Topic :: Communications :: Email',\n          'Topic :: Office/Business',\n          'Topic :: Software Development :: Bug Tracking',\n          ],\n)\n</code></pre>\n<!--kg-card-end: markdown--><p>Many of the metadata fields are rather self-explanatory. But what about the fields related to package dependencies, such as package_dir or packages? Wasn't this already handled in our Pipfile? On top of that, we need to specify then the test suite we're using via <strong>tests_require</strong> and <strong>cmdclass</strong>? Short answer: pretty much.</p><h3 id=\"setup-cfg\">Setup.cfg</h3><p>The real joke with <code>setup.py</code> is that it needs its own configuration file: yes, a configuration file for your configuration file. <code>setup.cfg</code>, as the name suggestions, sets even more granular configurations for the things mentioned in <code>setup.py</code>, such as how <strong>pytest</strong> should be handled, etc. Let's not get into it, but here's an example:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">[coverage:run]\nomit = */test/*\n\n[flake8]\nexclude = *.egg*,.env,.git,.tox,_*,build*,dist*,venv*,python2/,python3/\nignore = E261,W503\nmax-line-length = 121\n\n[tool:pytest]\nminversion = 3.2\naddopts =\n  # --fulltrace\n  # -n auto\n  --cov-config=setup.cfg\n  --cov=httplib2\n  --noconftest\n  --showlocals\n  --strict\n  --tb=short\n  --timeout=17\n  --verbose\n  -ra\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"pipfile-and-pipfile-lock\">Pipfile and Pipfile.lock</h3><p>If you have been using Pipenv, you'll recognize these files as being responsible for setting your Python version and dependencies. <em>But wait- didn't we also need to specify dependencies in setup.py?</em> Yes, we did. There is no God, but if there were, he'd probably hate you. Here's all the work you'd need to do creating an acceptable Pipfile:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">[[source]]\nurl = &quot;https://pypi.org/simple&quot;\nverify_ssl = true\nname = &quot;pypi&quot;\n\n[packages]\nFlask-SQLAlchemy = &quot;*&quot;\npsycopg2 = &quot;*&quot;\npsycopg2-binary = &quot;*&quot;\nrequests = &quot;*&quot;\nconfigparser=&quot;*&quot;\nmapbox=&quot;*&quot;\nflask=&quot;*&quot;\npandas=&quot;*&quot;\nFlask-Assets=&quot;*&quot;\nlibsass=&quot;*&quot;\njsmin=&quot;*&quot;\ndash_core_components=&quot;*&quot;\ndash-table=&quot;*&quot;\ndash_html_components=&quot;*&quot;\ndash=&quot;*&quot;\nflask-session=&quot;*&quot;\nflask-redis=&quot;*&quot;\ngunicorn=&quot;*&quot;\npytest-flask=&quot;*&quot;\n\n\n[dev-packages]\n\n[requires]\npython_version = &quot;3.7.1&quot;\n\n</code></pre>\n<!--kg-card-end: markdown--><p>But wait, there's more!</p><h3 id=\"requirements-txt\">Requirements.txt</h3><p>Because the Pipfile format has not been adopted as a standard for dependency management, we <em>still</em> need to create a requirements.txt file if we want to deploy our application to respectable hosts such as <strong>Google App Engine</strong> or what-have-you. So now we have this ugly son of a bitch from the stone age to deal with as well:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">atomicwrites==1.2.1\nattrs==18.2.0\nboto3==1.9.75\nbotocore==1.12.75\nCacheControl==0.12.5\ncertifi==2018.11.29\nchardet==3.0.4\nClick==7.0\nconfigparser==3.5.0\ndash==0.35.1\ndash-core-components==0.42.0\ndash-html-components==0.13.4\ndash-renderer==0.16.1\ndash-table==3.1.11\ndecorator==4.3.0\ndocutils==0.14\nFlask==1.0.2\nFlask-Assets==0.12\nFlask-Compress==1.4.0\nFlask-Redis==0.3.0\nFlask-Session==0.3.1\nFlask-SQLAlchemy==2.3.2\ngunicorn==19.9.0\nidna==2.8\nipython-genutils==0.2.0\niso3166==0.9\nitsdangerous==1.1.0\nJinja2==2.10\njmespath==0.9.3\njsmin==2.2.2\njsonschema==2.6.0\njupyter-core==4.4.0\nlibsass==0.17.0\nmapbox==0.17.2\nMarkupSafe==1.1.0\nmore-itertools==5.0.0\nmsgpack==0.6.0\nnbformat==4.4.0\nnumpy==1.15.4\npandas==0.23.4\nplotly==3.5.0\npluggy==0.8.0\npolyline==1.3.2\npsycopg2==2.7.6.1\npsycopg2-binary==2.7.6.1\npy==1.7.0\npytest==4.1.0\npytest-flask==0.14.0\npython-dateutil==2.7.5\npytz==2018.9\nredis==3.0.1\nrequests==2.21.0\nretrying==1.3.3\ns3transfer==0.1.13\nsix==1.12.0\nSQLAlchemy==1.2.15\ntraitlets==4.3.2\nuritemplate==3.0.0\nurllib3==1.24.1\nwebassets==0.12.1\nWerkzeug==0.14.1\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"manifest-in\">MANIFEST.in</h3><p>YES, THERE'S MORE. If you're not bothered by now, please leave this blog immediately. The job market is ripe for neckbeards who take pleasure in unnecessary complexity. Until the robots take over, this blog is for humans.</p><p>Anyway, there's an entire file dedicated to including files in your project which aren't code. We're entering comically ridiculous territory:</p><!--kg-card-begin: markdown--><pre><code class=\"language-ini\">include README.rst\ninclude docs/*.txt\ninclude funniest/data.json\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"it-s-a-bird-it-s-a-plane-its-a-single-sophisticated-config-file\">It's a Bird! It's a Plane! Its... A Single, Sophisticated Config File?</h2><p>I hope you're thoroughly pissed off after looking back at all the things we've let slide by year after year, telling ourselves that this patchwork of standards is just fine. Cue our hero: the creator of Poetry:</p><blockquote>Packaging systems and dependency management in Python are rather convoluted and hard to understand for newcomers. Even for seasoned developers it might be cumbersome at times to create all files needed in a Python project: <code>setup.py</code>,<code>requirements.txt</code>, <code>setup.cfg</code>, <code>MANIFEST.in</code> and the newly added <code>Pipfile</code>. So I wanted a tool that would limit everything to a single configuration file to do: dependency management, packaging and publishing.</blockquote><p>Oh God yes, but HOW?!?!</p><h3 id=\"introducing-pyproject-toml\">Introducing pyproject.toml</h3><p>Poetry is built around a single configuration dubbed <code>pyproject.toml</code> which has become an <a href=\"https://www.python.org/dev/peps/pep-0518/\">accepted standard in the Python community</a> by way of <strong>PEP 518.</strong> With the weight of the Python development community itself, it's safe to say this isn't another fad and is worth using.</p><p>Here's an example <strong>.toml </strong>file from the <a href=\"https://github.com/sdispater/poetry\">Poetry Github repository</a>:</p><!--kg-card-begin: markdown--><pre><code class=\"language-toml\">[tool.poetry]\nname = &quot;my-package&quot;\nversion = &quot;0.1.0&quot;\ndescription = &quot;The description of the package&quot;\n\nlicense = &quot;MIT&quot;\n\nauthors = [\n    &quot;Sébastien Eustace &lt;sebastien@eustace.io&gt;&quot;\n]\n\nreadme = 'README.md'  # Markdown files are supported\n\nrepository = &quot;https://github.com/sdispater/poetry&quot;\nhomepage = &quot;https://github.com/sdispater/poetry&quot;\n\nkeywords = ['packaging', 'poetry']\n\n[tool.poetry.dependencies]\npython = &quot;~2.7 || ^3.2&quot;  # Compatible python versions must be declared here\ntoml = &quot;^0.9&quot;\n# Dependencies with extras\nrequests = { version = &quot;^2.13&quot;, extras = [ &quot;security&quot; ] }\n# Python specific dependencies with prereleases allowed\npathlib2 = { version = &quot;^2.2&quot;, python = &quot;~2.7&quot;, allows-prereleases = true }\n# Git dependencies\ncleo = { git = &quot;https://github.com/sdispater/cleo.git&quot;, branch = &quot;master&quot; }\n\n# Optional dependencies (extras)\npendulum = { version = &quot;^1.4&quot;, optional = true }\n\n[tool.poetry.dev-dependencies]\npytest = &quot;^3.0&quot;\npytest-cov = &quot;^2.4&quot;\n\n[tool.poetry.scripts]\nmy-script = 'my_package:main'\n</code></pre>\n<!--kg-card-end: markdown--><p>In addition to covering the scope of all previously mentioned files, using <strong>pyproject.toml</strong> with Poetry also covers:</p><ul><li>Auto-populating the <strong>exclude</strong> section from values found in <code>.gitignore</code></li><li>The addition of a <strong>keywords</strong> section to be included with the resulting PyPi package</li><li>Support for version numbers using any syntax, such as <strong>wildcard (*)</strong> or <strong>carrot (^1.0.0)</strong> syntax</li><li>Auto-detection for virtual environments, thus a global install that can be used within envs</li></ul><h2 id=\"creating-poetic-art\">Creating Poetic Art</h2><p>Are we all fired up yet? Right: let's change our workflow forever.</p><h3 id=\"installation\">Installation</h3><p> To install Poetry on OSX, use the following:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ curl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python\n</code></pre>\n<!--kg-card-end: markdown--><p>This will create an addition to your <code>~/.bash_profile</code>. Restart your terminal and verify the installation:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ poetry --version\nPoetry 0.12.10\n</code></pre>\n<!--kg-card-end: markdown--><h3 id=\"creating-a-new-python-project\">Creating a New Python Project</h3><p>Navigate to whichever file path you'd like your new project to call home. To get started, all we need next is the following command:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">poetry new my-package\n</code></pre>\n<!--kg-card-end: markdown--><p>Ready for a breath of fresh air? This command generates a basic project structure for you- something that's been missing from Python for a long time when compared to similar generators for Node or otherwise. The resulting project structure looks as such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">my-package\n├── pyproject.toml\n├── README.rst\n├── my_package\n│   └── __init__.py\n└── tests\n    ├── __init__.py\n    └── test_my_package\n</code></pre>\n<!--kg-card-end: markdown--><p>Of the beautiful things happening here, the only one we haven't touched on yet is Poetry's built-in integration with <strong>pytest</strong>. Oh, happy day!</p><h4 id=\"alternative-interactive-installation-method\">Alternative Interactive Installation Method</h4><p>If you'd prefer a bit more handholding, feel free to use <code>poetry init</code> in an empty directory (or a directory without the existing <strong>.toml</strong> file) to be walked through the creation process:</p><!--kg-card-begin: markdown--><pre><code class=\"language-bash\">$ poetry init\n\nThis command will guide you through creating your pyproject.toml config.\n\nPackage name [my-package]: Great Package\nVersion [0.1.0]:\nDescription []: Great package for great people.\nAuthor [Todd Birchard &lt;todd@hackersandslackers.com&gt;, n to skip]:\nLicense []: MIT\nCompatible Python versions [^2.7]: ^3.7\n\nWould you like to define your dependencies (require) interactively? (yes/no) [yes] no\n\n\n\nWould you like to define your dev dependencies (require-dev) interactively (yes/no) [yes] no\n\nGenerated file\n\n[tool.poetry]\nname = &quot;Great Package&quot;\nversion = &quot;0.1.0&quot;\ndescription = &quot;Great package for great people.&quot;\nauthors = [&quot;Todd Birchard &lt;todd@hackersandslackers.com&gt;&quot;]\nlicense = &quot;MIT&quot;\n\n[tool.poetry.dependencies]\npython = &quot;^3.7&quot;\n\n[tool.poetry.dev-dependencies]\n\n[build-system]\nrequires = [&quot;poetry&gt;=0.12&quot;]\nbuild-backend = &quot;poetry.masonry.api&quot;\n\n\nDo you confirm generation? (yes/no) [yes] yes\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"managing-dependencies-in-pyproject-toml\">Managing Dependencies in pyproject.toml</h2><p>If you're familiar with Pipfiles, pyproject.toml handles dependencies the same way. Just remember that <code>poetry install</code> installs your listed dependencies, and <code>poetry update</code> will update dependencies in <em>poetry.lock </em>to their latest versions.</p><h3 id=\"carry-on-my-wayward-son\">Carry on my Wayward Son</h3><p>I could spend all day copy-pasting general usage from the Poetry Github page, but I think my work here is done. Do yourself a favor and<a href=\"https://github.com/sdispater/poetry\"> take a look at the Github repo</a> to make your life easier forever. Or at least until the next replacement solution comes along.</p>","url":"https://hackersandslackers.com/poetic-python-project-packaging/","uuid":"10ddf06a-b12f-40b4-9849-2b057d3fe2f4","page":false,"codeinjection_foot":null,"codeinjection_head":"<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@glorious/demo/dist/gdemo.min.css\">\n<script src=\"https://cdn.jsdelivr.net/npm/@glorious/demo/dist/gdemo.min.js\"></script>\n","comment_id":"5c34086694d3e847951adf3e"}},{"node":{"id":"Ghost__Post__5c307c9493bed0776a0a3d80","title":"Using Redis to Store Information in Python Applications","slug":"using-redis-with-python","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/redis-1-2.jpg","excerpt":"A temporary data store for everything from session variables to chat queues.","custom_excerpt":"A temporary data store for everything from session variables to chat queues.","created_at_pretty":"05 January, 2019","published_at_pretty":"05 January, 2019","updated_at_pretty":"28 March, 2019","created_at":"2019-01-05T04:44:52.000-05:00","published_at":"2019-01-05T08:21:00.000-05:00","updated_at":"2019-03-28T05:41:12.000-04:00","meta_title":"Using Redis to Store Information in Python Apps | Hackers and Slackers","meta_description":"Take the guesswork out of storing values in memory: use Redis in your Python stack to have full control over session variables.","og_description":"Take the guesswork out of storing values in memory: use Redis in your Python stack to have full control over session variables.","og_image":"https://hackersandslackers.com/content/images/2019/03/redis-1-2.jpg","og_title":"Using Redis to Store Information in Python Applications","twitter_description":"Take the guesswork out of storing values in memory: use Redis in your Python stack to have full control over session variables.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/redis-1-1.jpg","twitter_title":"Using Redis to Store Information in Python Applications","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"We’re hacking into the new year here at Hackers and Slackers, and in the\nprocess, we’ve received plenty of new gifts to play with. Nevermind how Santa\nmanages to fit physically non-existent SaaS products under the Christmas tree.\nWe ask for abstract enterprise software every year, and this time we happened to\nget a little red box.\n\nIf you've never personally used Redis, the name probably sounds familiar as\nyou've been bombarded with obscure technology brand names in places like the\nHeroku marketplace, or your unacceptably nerdy Twitter account (I assure you,\nmine is worse). So what is Redis, you ask? Well, it's a NoSQL datasto- wait,\nwhere are you... NO! Don't leave! It's not like THAT, I swear!\n\nWhat Redis is and When to Use It\nRedis stores information in the familiar key/value pair format, but the term\n‘NoSQL’ is more of a technicality than an indicator of use cases synonymous with\nNoSQL databases of the past. Redis looks the part for the very purpose it\nserves: a box that you fill with crap which may or may not be important down the\nline. It’s the perfect place to put a Starbucks gift card or the clothes you’ve\nalready worn which aren’t quite ready to be washed yet.\n\nAll Users go to Heaven: Cloud Storage for User Sessions\nPerhaps the most common use case is a glorified session cache. Similar to the\nway users might store temporary app information in cookies, Redis holds on to\ninformation which is fleeting. The difference is we now own this information\ninside our very own box, thus the Redis motto: “your box, your rules.”* \n\n* I made this up: it holds zero truth.Because temporary user information is in\nour hands as opposed to a fickle browser, we can decide just how  temporary our\n“cache” is, having it persist across sessions or even devices. While local\nmemory storage may as well be a place for throwaway information, and databases\nfor persistent or eternal information, Redis is somewhere in between. As users\ninteract and the information they create within our app evolves, we may choose\nat any point to promote information stored in Redis to a database, or perhaps\nhave it stick around a little while longer. They’ll be thrilled to see their\nshopping cart still filled with the stupid things they almost bought while they\nwere drunk yesterday.\n\nWhen Variables are on a Bagel, You can Have Variables Any Time \nIn other words, Redis is great for solving the need of globally accessible\nvariables throughout an entire application, on a per-user basis. Users who\naccidentally quit your app, move to a new context, or merely use your app for\nlonger than your QA team are easier to manage when their temporary information\nis in a safe and global environment. Compare this to saving a user’s Pac-Man\nscore to a global variable:  the moment an app like Pac-Man crashes or restarts,\nthat session is gone forever. Thus dies another three-letter app obscenity\nbelonging to a leaderboard.\n\nSpeaking of Leaderboards...\nRedis is great at counting in increments. This is probably made evident by the\nfact that it is a computer, and these are the things computers do. Something\nelse that’s made great by counting: queues! Cues of tasks, notifications, chats,\ndisappearing naked photos, etc: all of these things are ideally suited for our\nred box.\n\nGetting a Red Box of Your Own\nPlaying around with a cloud-hosted Redis box will cost you maybe 5 bucks\n(monthly if you forget to cancel). Redis is open source so there are plenty of\nvendors to choose from with little differentiation between them. I’ll consider\nrecommending whichever vendor offers to bribe me the most, but in the meantime\nI’ll leave the window shopping to you.\n\nSetting up Redis should feel like setting up a cloud SQL database, except\nsmaller and cuter. You’ll be able to pick adorable features for your box of\npossibly-but-not-surely-worthless stuff, such as hosted region, etc. Once you're\nset up you should have a host URL for reaching your instance:\n\nredis-1738.c62.us-east-1-4.ec2.cloud.fakeredisprovider.com:42069\n\nNow we’re cooking with gas.\n\nUsing the redis-py Python Library\nThe main Python Redis library is typed as redis, as in pip install Redis. The\neasiest way to connect in any case is via a URI connection string, like such:\n\nr = redis.Redis( url='rediss://:password@hostname:port/0')\n\n\nNote the unique structure of the URI above:\n\n * rediss://: precedes all Redis URIs; NOTE THE TRAILING COLON.\n * password  comes next, with the interesting choice to bypass usernames.\n * hostname  is the instance's URL... almost always a thinly veiled repurposed\n   EC2 instance. That's right, we're being sold simple open source software\n   hosted on AWS. Don't think about it.\n * port is your preferred port of call after pillaging British trade ships. Just\n   making sure you're still here.\n * /database brings up the rear, which is the name of your database.\n\nAs with regular databases, other connection methods exist such as via SSL\ncertificates, etc.\n\nStoring and Getting Values\nThis is your bread and butter for interacting with Redis:\n\n * .set():  Set a key/value pair by either overwriting or creating a new value\n * .get():  Retrieve a value by naming the associated key\n * hmget():  Accepts a variable number of keys, and will return values for each\n   if they exist\n * hmset():  Set multiple values to a single key.\n * hgetall():  Get all values for a key where a key has been assigned multiple\n   values.\n\nIt’s important to note that Redis by default returns bytes as opposed to\nstrings. As a result, it is important to remember the encoding/decoding of\nvalues in order to retrieve them properly. For example:\n\n# Setting a Value\nr.set('uri', str(app.config['SQLALCHEMY_DATABASE_URI']).encode('utf-8'))\n\n# Getting a Value\nr.get('uri').decode('utf-8')\n\n\nIf you happen to be remotely sane, you probably don't want to deal with encoding\nand decoding values over and again. Luckily we can ensure that responses are\nalways decoded for us by setting the decode_responses  parameter to True  when\nsetting up our Redis instance:\n\nredis.StrictRedis(host=\"localhost\", port=6379, charset=\"utf-8\", decode_responses=True)\n\n\nThe redis-py documentation [https://redis-py.readthedocs.io/en/latest/] \nactually goes wayyy deeper than the 5 methods listed above. If you ever somehow\nmanage to cover all of it, I have many questions about the type of person you\nare.\n\nMore Redis Libraries for Python\nIf the above encoding/decoding seems annoying, you aren’t the first. That’s why\nlibraries like Redisworks [https://github.com/seperman/redisworks]  exist.\nRedisworks allows for the seamless exchange of Python data types to and from\nRedis. Want to shove a Python dict down your box’s throat? Go ahead! You won’t\neven have to think about it very hard. There are plenty of similar libraries all\naimed to make sad lives easier.\n\nWant more? How about Asyncio’s very own asynchronous Redis library\n[https://asyncio-redis.readthedocs.io/en/latest/]?  Or how about the similar \naioredis [aioredis.readthedocs.org], another Asyncio Redis plug-in, which also\nincludes pure Python parsing, clustering support, and things I don’t even\nunderstand! There are truly more Python libraries for Redis\n[https://redis.io/clients#python]  than you could need.\n\nFinally, how could we ever forget Flask-Redis? We’ve already covered this\n[https://hackersandslackers.com/demystifying-flasks-application-context/], but\nis easily the first and last Redis library any Flask developer will use.\n\nYour Box, Your Treasure, Your World™\nNow that we’ve uncovered this niche between cached data and stored data, the\npossibilities are endless. The world is your oyster full of things which you may\nor may not choose to shove in your box.\n\nOk, fine. Perhaps this whole concept feels like a bit of an obscure niche hardly\nworthy of the words on this page. Just remember that feeling when the time comes\nthat you too need a little red cube, and it will be waiting with love and\ncompassion. A companion cube, if you will.","html":"<p>We’re hacking into the new year here at Hackers and Slackers, and in the process, we’ve received plenty of new gifts to play with. Nevermind how Santa manages to fit physically non-existent SaaS products under the Christmas tree. We ask for abstract enterprise software every year, and this time we happened to get a little red box.</p><p>If you've never personally used Redis, the name probably sounds familiar as you've been bombarded with obscure technology brand names in places like the Heroku marketplace, or your unacceptably nerdy Twitter account (I assure you, mine is worse). So what is Redis, you ask? Well, it's a NoSQL datasto- wait, where are you... NO! Don't leave! It's not like THAT, I swear!</p><h2 id=\"what-redis-is-and-when-to-use-it\">What Redis is and When to Use It</h2><p>Redis stores information in the familiar key/value pair format, but the term ‘NoSQL’ is more of a technicality than an indicator of use cases synonymous with NoSQL databases of the past. Redis looks the part for the very purpose it serves: a box that you fill with crap which may or may not be important down the line. It’s the perfect place to put a Starbucks gift card or the clothes you’ve already worn which aren’t quite ready to be washed yet.</p><h3 id=\"all-users-go-to-heaven-cloud-storage-for-user-sessions\">All Users go to Heaven: Cloud Storage for User Sessions</h3><p>Perhaps the most common use case is a glorified <strong>session cache</strong>. Similar to the way users might store temporary app information in cookies, Redis holds on to information which is fleeting. The difference is we now own this information inside our very own box, thus the Redis motto: “<em>your box, your rules</em>.”* </p><!--kg-card-begin: html--><span style=\"color:#9DA0A0;font-style:italic;margin-bottom:30px;display:block;text-align:right;width:100%;\">* I made this up: it holds zero truth.</span><!--kg-card-end: html--><p>Because temporary user information is in our hands as opposed to a fickle browser, we can decide just <em>how</em> temporary our “cache” is, having it persist across sessions or even devices. While local memory storage may as well be a place for throwaway information, and databases for persistent or eternal information, Redis is somewhere in between. As users interact and the information they create within our app evolves, we may choose at any point to promote information stored in Redis to a database, or perhaps have it stick around a little while longer. They’ll be thrilled to see their shopping cart still filled with the stupid things they almost bought while they were drunk yesterday.</p><h3 id=\"when-variables-are-on-a-bagel-you-can-have-variables-any-time\">When Variables are on a Bagel, You can Have Variables Any Time </h3><p>In other words, Redis is great for solving the need of globally accessible variables throughout an entire application, on a per-user basis. Users who accidentally quit your app, move to a new context, or merely use your app for longer than your QA team are easier to manage when their temporary information is in a safe and global environment. Compare this to saving a user’s Pac-Man score to a global variable:  the moment an app like Pac-Man crashes or restarts, that session is gone forever. Thus dies another three-letter app obscenity belonging to a leaderboard.</p><h3 id=\"speaking-of-leaderboards-\">Speaking of Leaderboards...</h3><p>Redis is great at counting in increments. This is probably made evident by the fact that it is a computer, and these are the things computers do. Something else that’s made great by counting: queues! Cues of tasks, notifications, chats, disappearing naked photos, etc: all of these things are ideally suited for our red box.</p><h2 id=\"getting-a-red-box-of-your-own\">Getting a Red Box of Your Own</h2><p>Playing around with a cloud-hosted Redis box will cost you maybe 5 bucks (monthly if you forget to cancel). Redis is open source so there are plenty of vendors to choose from with little differentiation between them. I’ll consider recommending whichever vendor offers to bribe me the most, but in the meantime I’ll leave the window shopping to you.</p><p>Setting up Redis should feel like setting up a cloud SQL database, except smaller and cuter. You’ll be able to pick adorable features for your box of possibly-but-not-surely-worthless stuff, such as hosted region, etc. Once you're set up you should have a host URL for reaching your instance:</p><!--kg-card-begin: code--><pre><code>redis-1738.c62.us-east-1-4.ec2.cloud.fakeredisprovider.com:42069</code></pre><!--kg-card-end: code--><p>Now we’re cooking with gas.</p><h2 id=\"using-the-redis-py-python-library\">Using the redis-py Python Library</h2><p>The main Python Redis library is typed as <code>redis</code>, as in <code>pip install Redis</code>. The easiest way to connect in any case is via a URI connection string, like such:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">r = redis.Redis( url='rediss://:password@hostname:port/0')\n</code></pre>\n<!--kg-card-end: markdown--><p>Note the unique structure of the URI above:</p><ul><li><strong>rediss://: </strong>precedes all Redis URIs; <em>NOTE THE TRAILING COLON.</em></li><li><strong>password</strong> comes next, with the interesting choice to bypass usernames.</li><li><strong>hostname</strong> is the instance's URL... almost always a thinly veiled repurposed EC2 instance. That's right, we're being sold simple open source software hosted on AWS. Don't think about it.</li><li><strong>port </strong>is your preferred port of call after pillaging British trade ships. Just making sure you're still here.</li><li><strong>/database </strong>brings up the rear, which is the name of your database.</li></ul><p>As with regular databases, other connection methods exist such as via SSL certificates, etc.</p><h3 id=\"storing-and-getting-values\">Storing and Getting Values</h3><p>This is your bread and butter for interacting with Redis:</p><ul><li><strong>.set():</strong> Set a key/value pair by either overwriting or creating a new value</li><li><strong>.get():</strong> Retrieve a value by naming the associated key</li><li><strong>hmget():</strong> Accepts a variable number of keys, and will return values for each if they exist</li><li><strong>hmset():</strong> Set multiple values to a single key.</li><li><strong>hgetall():</strong> Get all values for a key where a key has been assigned multiple values.</li></ul><p>It’s important to note that Redis by default returns bytes as opposed to strings. As a result, it is important to remember the encoding/decoding of values in order to retrieve them properly. For example:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\"># Setting a Value\nr.set('uri', str(app.config['SQLALCHEMY_DATABASE_URI']).encode('utf-8'))\n\n# Getting a Value\nr.get('uri').decode('utf-8')\n</code></pre>\n<!--kg-card-end: markdown--><p>If you happen to be remotely sane, you probably don't want to deal with encoding and decoding values over and again. Luckily we can ensure that responses are always decoded for us by setting the <code>decode_responses</code> parameter to <code>True</code> when setting up our Redis instance:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">redis.StrictRedis(host=&quot;localhost&quot;, port=6379, charset=&quot;utf-8&quot;, decode_responses=True)\n</code></pre>\n<!--kg-card-end: markdown--><p>The <a href=\"https://redis-py.readthedocs.io/en/latest/\" rel=\"noopener\"><strong>redis-py</strong> documentation</a> actually goes wayyy deeper than the 5 methods listed above. If you ever somehow manage to cover all of it, I have many questions about the type of person you are.</p><h2 id=\"more-redis-libraries-for-python\">More Redis Libraries for Python</h2><p>If the above encoding/decoding seems annoying, you aren’t the first. That’s why libraries like <a href=\"https://github.com/seperman/redisworks\" rel=\"noopener\"><strong>Redisworks</strong></a> exist. Redisworks allows for the seamless exchange of Python data types to and from Redis. Want to shove a Python dict down your box’s throat? Go ahead! You won’t even have to think about it very hard. There are plenty of similar libraries all aimed to make sad lives easier.</p><p>Want more? How about Asyncio’s very own <a href=\"https://asyncio-redis.readthedocs.io/en/latest/\">asynchronous Redis library</a>?  Or how about the similar <strong><a href=\"aioredis.readthedocs.org\">aioredis</a></strong>, another Asyncio Redis plug-in, which also includes pure Python parsing, clustering support, and things I don’t even understand! There are truly <a href=\"https://redis.io/clients#python\">more Python libraries for Redis</a> than you could need.</p><p>Finally, how could we ever forget <strong>Flask-Redis</strong>? We’ve <a href=\"https://hackersandslackers.com/demystifying-flasks-application-context/\" rel=\"noopener\">already covered this</a>, but is easily the first and last Redis library any Flask developer will use.</p><h2 id=\"your-box-your-treasure-your-world-\">Your Box, Your Treasure, Your World<strong>™</strong></h2><p>Now that we’ve uncovered this niche between cached data and stored data, the possibilities are endless. The world is your oyster full of things which you may or may not choose to shove in your box.</p><p>Ok, fine. Perhaps this whole concept feels like a bit of an obscure niche hardly worthy of the words on this page. Just remember that feeling when the time comes that you too need a little red cube, and it will be waiting with love and compassion. A companion cube, if you will.</p>","url":"https://hackersandslackers.com/using-redis-with-python/","uuid":"fcf41325-f7d3-4f3f-b43f-8609e5dc6b07","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c307c9493bed0776a0a3d80"}},{"node":{"id":"Ghost__Post__5c27630bda392c696eab97de","title":"Tableau's REST API: Turning Tableau into an ETL Pipeline GUI","slug":"tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/hacktaleau-4@2x.jpg","excerpt":"Organizing a heist on Tableau Server to reclaim workbook data.","custom_excerpt":"Organizing a heist on Tableau Server to reclaim workbook data.","created_at_pretty":"29 December, 2018","published_at_pretty":"29 December, 2018","updated_at_pretty":"13 March, 2019","created_at":"2018-12-29T07:05:31.000-05:00","published_at":"2018-12-29T07:18:53.000-05:00","updated_at":"2019-03-13T05:53:25.000-04:00","meta_title":"Tableau's View Extraction REST API | Hackers and Slackers","meta_description":"Our siege on Tableau Server continues as we organize a heist to reclaim our workbook data","og_description":"Our siege on Tableau Server continues as we organize a heist to reclaim our workbook data","og_image":"https://hackersandslackers.com/content/images/2018/12/hacktaleau-4@2x.jpg","og_title":"Tableau's REST API: Turning Tableau into an ETL Pipeline GUI","twitter_description":"Our siege on Tableau Server continues as we organize a heist to reclaim our workbook data","twitter_image":"https://hackersandslackers.com/content/images/2018/12/hacktaleau-4@2x.jpg","twitter_title":"Tableau's REST API: Turning Tableau into an ETL Pipeline GUI","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Hacking Tableau Server","slug":"hacking-tableau-server","description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauseries-2.jpg","meta_description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","meta_title":"Hacking Tableau Server","visibility":"internal"}],"plaintext":"There's nothing I love more than exposing expensive enterprise software. \n\nIt may not seem obvious, but most SaaS products have an underlying core goal:\nshackle businesses to depend on proprietary, closed-source, costly software.\nWhen you pair a surplus of money with a reluctance to work, you've arrived at\nCorporate America: a prime victim yearning to marry itself to any vendor with a\nnice pitch deck and a vague promise.\n\nIn the case of Tableau, this becomes obvious when you attempt to do anything\nbesides create visuals. I don't like spending hours of my time cleaning data to\nbe rewarded with a shitty iframe embed: I want my data. As we've already seen by\nexposing Tableau's hidden Superadmin access\n[\thttps://hackersandslackers.com/hacking-linux-tableu-server/], it's pretty\nclear Tableau doesn't want you to do this. \n\nI realize Tableau is a BI tool, and some might argue we're barking up the wrong\ntree, and all data should be clean before reaching Tableau. My sentiment is\nthis: fuck that. If a single license costs one thousand dollars, and we have the\npower to manipulate data faster  as we visualize it, we should at least be able\nto own  that data: and by \"own,\" I don't mean a CSV export. I want it in my own \ndatabase of choice, not a locked down and hidden Postgres database living on a\nVPS filled with Tableau stuff.\n\nHere's how we'd do that.\n\n\"You Expect us to Just Walk out the Casino with Millions of Dollars on us?\"\nYou're looking at a Boeski, a Jim Brown, a Miss Daisy, two Jethros and a Leon\nSpinks, not to mention the biggest Ella Fitzgerald ever.You're here because\nyou're the best of the best. If you're feeling scared, feel free to back out\nnow.\n\nThis tutorial assumes you have a Tableau Server instance, with a workbook\npublished to a site within said instance. We're going to take a page out of that\nworkbook and turn the raw data into a database table. FAIR  WARNING: We're about\nto dive deep into the obscure world of the Tableau Server REST API\n[https://onlinehelp.tableau.com/current/api/rest_api/en-us/REST/rest_api_ref.htm]\n. It's clunky, it's ugly, and it returns XML. Strap yourself in. \n\nWe're going to be working with 3 core endpoints. Let's walk through them, and\nI'll show you how to exploit said endpoints to create a ruthless data mining\nmachine in Python.\n\n'Tableau Authorization' Endpoint\nLike all obnoxious (aka useful) APIs, we need to authorize each API call with a\ntemporary token. Of course, we'll just have Python generate said token for every\ncall we make.\n\nPOST: http://[MyTaleauServerURL]/api/3.0/auth/signin\n\nHitting this endpoint successfully will result in an XML response (ugh). The\nresponse should look something like this:\n\n<?xml version='1.0' encoding='UTF-8'?>\n<tsResponse xmlns=\"http://tableau.com/api\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd\">\n    <credentials token=\"KBIuvu6FTViuyivuTUR^yfvgTUycvjGubgc\">\n        <site id=\"09Hiugv-345-45d0-b48b-34543giuyvg\" contentUrl=\"hackers\"/>\n        <user id=\"Uohiiyu-3455-8675-9b42-bugvdr876gv\"/>\n    </credentials>\n</tsResponse>\n\n\nThere are a number of things going on here that we should take note of. The\nfirst being a marvel of modern technology: this is perhaps the shittiest\nresponse to a token API call in modern history. Other than that, we need two\nthings from this response:\n\n * The token  is required for every API call from here on out. It is intended to\n   be passed as a header value with the key X-Tableau-Auth.\n * The site ID  is what we'll be using to look up the location of our workbooks\n   in our server instance. This is added to the URL of future API calls (again,\n   impressively shitty design here).\n\n'List All Views by Site' Endpoint\nThere are actually a number of methods we could use to retrieve views, but we're\nspecifically settling on listing our views by 'site,' in the Tableau sense of\nthe word. If you're unfamiliar, a Tableau site  is not a site at all: it's more\nof project within a greater Tableau instance. They probably should've named them\nthat.\n\nGET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views\n\nAs mentioned, we use the site ID  from step 1 to construct this endpoint. In my\nparticular instance, I've only saved a single workbook for simplicity's sake.\nThe response for such a case is as follows:\n\n<?xml version='1.0' encoding='UTF-8'?>\n<tsResponse xmlns=\"http://tableau.com/api\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd\">\n    <pagination pageNumber=\"1\" pageSize=\"100\" totalAvailable=\"1\"/>\n    <views>\n        <view id=\"9a4a1de9-b7af-4a4a-8556-fd5ac82f92bd\" name=\"Jira\" contentUrl=\"JiraIssues/sheets/Jira\" createdAt=\"2018-12-21T09:11:39Z\" updatedAt=\"2018-12-21T09:11:39Z\">\n            <workbook id=\"208a0c4e-e1d9-4852-9d19-7a2fe2717191\"/>\n            <owner id=\"Uohiiyu-3455-8675-9b42-bugvdr876gv\"/>\n            <project id=\"4d1ca337-20b4-442c-aa7b-1dfd470b68bd\"/>\n            <tags/>\n        </view>\n    </views>\n</tsResponse>\n\n\nCheck out the views  node: when we make this API call, <views>  will contain a\nlist of every view saved to the specified site. Keep in mind that a view is\nequivalent to a \"sheet\" of a workbook: in almost any case, you will have many\nviews listed here. \n\nMy sheet happens to be called \"Jira,\" as stated by name=\"Jira\". The thing we\nreally need however is the view id attribute: this will be used in our third and\nfinal API call.\n\n'Get View Data' Endpoint\nNow let's get the raw data from a view of our choice.\n\nGET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views/[MyViewID]/data\n\n\nHere's where we hit pay dirt. This request will result in an output of\ncomma-separated values; I don't need to tell you what we can do with\ncomma-separated values. Here's what my response looks like after formatting it\nas a table:\n\nCurrent AssigneeCurrent StatusDay of Updatedepic_colorepic_nameIssue Type\nissuetype_colorissuetype_urlkeyPriorityprojectsummaryTodd BirchardDoneJune 7,\n2018#42526EWidgetsBug#db5d5dhttps://hackers.nyc3.digitaloceanspaces.com/bug.png\nHACK-96LowestHackers and Slackers\"Recent Posts\" widget does not have link\nrolloverTodd BirchardBacklogJune 15, 2018#57D9A3Page TemplatesTask#73B0E1\nhttps://hackers.nyc3.digitaloceanspaces.com/task.pngHACK-32LowestHackers and\nSlackers“Join” pageTodd BirchardDoneNovember 13, 2018#42526EWidgetsTask#73B0E1\nhttps://hackers.nyc3.digitaloceanspaces.com/task.pngHACK-543MediumHackers and\nSlackersAdd “pro tip” boxTodd BirchardTo DoDecember 14, 2018#679EEFSEOMajor\nFunctionality#93d171https://hackers.nyc3.digitaloceanspaces.com/story.png\nHACK-656LowHackers and SlackersAdd alt attributes to images vis clarifai Todd\nBirchardBacklogOctober 16, 2018#FDDA3EAccountsMajor Functionality#93d171\nhttps://hackers.nyc3.digitaloceanspaces.com/story.pngHACK-473MediumHackers and\nSlackersAdd avatar selection to signupTodd BirchardDoneNovember 13, 2018#57D9A3\nPage TemplatesSub-task#92BFE5\nhttps://hackers.nyc3.digitaloceanspaces.com/subtask.pngHACK-231MediumHackers and\nSlackersAdd blurb to each post page explaining what these areTodd BirchardDone\nDecember 10, 2018#291BA9Code snippetsTask#73B0E1\nhttps://hackers.nyc3.digitaloceanspaces.com/task.pngHACK-452MediumHackers and\nSlackersAdd color styles for json snippetsThat's right, a table.  Databases are comprised of tables. Perhaps you see where\nI'm going with this.\n\n\"There's a Ninety-five Pound Chinese Man with a Hundred Sixty Million Dollars\nBehind this Door.\"\nLet's get him out.We've got the goods, but calling all these individual\nendpoints manually does nothing for us. We don't want to steal a single view, we\nwant to systematically rob Tableau of it's views on a scheduler and Shanghai\nthem off to a database of our choosing.\n\nIt would be a crime not to automate this, so I've created a class containing all\nthe relevant methods we'd want when it comes to interacting with Tableau's REST\nAPI:\n\nimport requests\nimport xml.etree.ElementTree as ET\nfrom . import r\nimport pandas as pd\nimport io\n\n\nclass ExtractTableauView:\n    \"\"\"Class for with the Tableau server API.\"\"\"\n\n    __baseurl = r.get('baseurl')\n    __username = r.get('username')\n    __password = r.get('password')\n    __database = r.get('uri')\n    __contenturl = r.get('contenturl')\n\n    @classmethod\n    def get_view(cls, site, xml, view, token):\n        \"\"\"Extract contents of a single view.\"\"\"\n        headers = {'X-Tableau-Auth': token,\n                   'Content-Type': 'text/csv'\n                   }\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + str(site) +'/views/' + str(view) + '/data', headers=headers, stream=True)\n        csv_text = req.text\n        view_df = pd.read_csv(io.StringIO(csv_text), header=0)\n        return view_df\n\n    @classmethod\n    def list_views(cls, site, xml, token):\n        \"\"\"List all views belonging to a Tableau Site.\"\"\"\n        headers = {'X-Tableau-Auth': token}\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + site + '/views', auth=(cls.__username, cls.__password), headers=headers)\n        root = ET.fromstring(req.content)\n        views_arr = []\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}views':\n                for view in child:\n                    view_dict = {\n                        'name': view.attrib.get('name'),\n                        'id': view.attrib.get('id'),\n                        'url': cls.__baseurl + '/' + view.attrib.get('contentUrl'),\n                        'created': view.attrib.get('createdAt'),\n                        'updated': view.attrib.get('updatedAt')\n                    }\n                    views_arr.append(view_dict)\n        return views_arr\n\n    @classmethod\n    def get_token(cls, xml):\n        \"\"\"Receive Auth token to perform API requests.\"\"\"\n        for child in xml.iter('*'):\n            if child.tag == '{http://tableau.com/api}credentials':\n                token = child.attrib.get('token')\n                return token\n\n    @classmethod\n    def get_site(cls, xml):\n        \"\"\"Retrieve ID of Tableau 'site' instance.\"\"\"\n        root = xml\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}site':\n                site = child.attrib.get('id')\n                return site\n\n    @classmethod\n    def initialize_tableau_request(cls):\n        \"\"\"Retrieve core XML for interacting with Tableau.\"\"\"\n        headers = {'Content-Type': 'application/xml'}\n        body = '<tsRequest><credentials name=\"' + cls.__username + '\" password=\"' + cls.__password + '\" ><site contentUrl=\"' + cls.__contenturl + '\" /></credentials></tsRequest>'\n        req = requests.post(cls.__baseurl + '/api/3.2/auth/signin', auth=(cls.__username, cls.__password), headers=headers, data=body)\n        root = ET.fromstring(req.content)\n        return root\n\n\nThe above snippet is a Python class utilizing all the API endpoints we explored\nin a mostly effortless manner. Instantiating the class immediately covers the\ngrunt work of:\n\n *   Generating a token\n * Getting your (unfriendly) site ID\n * Listing all views belonging to the provided site\n * Retrieving data from a worksheet of choice\n\nGet a list of views in your Tableau site by using the list_views()  method. When\nyou see the view you want, pass the view ID  to the .get_view()  method. This\nwill result in response of all raw data in the view in the form of a CSV. \n\nHow to Pull a Heist (Final Chapter): Storing in Offshore Accounts\nTo earn your title as a true con artist, I'm leaving the final step up to you.\nYou've escaped with the loot, but you'll need to put all that data somewhere.\nThis should be a trivial matter of automating a simple database query, but the\nspecifics are up to you.\n\nIf you're ready to liberate your data, feel free to grab the source off of\nGithub [https://gist.github.com/toddbirchard/ad1386b4334e7b22b2f7b38edca3bd5c] \nand go nuts.","html":"<p>There's nothing I love more than exposing expensive enterprise software. </p><p>It may not seem obvious, but most SaaS products have an underlying core goal: shackle businesses to depend on proprietary, closed-source, costly software. When you pair a surplus of money with a reluctance to work, you've arrived at Corporate America: a prime victim yearning to marry itself to any vendor with a nice pitch deck and a vague promise.</p><p>In the case of Tableau, this becomes obvious when you attempt to do anything besides create visuals. I don't like spending hours of my time cleaning data to be rewarded with a shitty iframe embed: I want my <em>data</em>. As we've already seen by exposing Tableau's hidden <a href=\"\thttps://hackersandslackers.com/hacking-linux-tableu-server/\">Superadmin access</a>, it's pretty clear Tableau doesn't want you to do this. </p><p>I realize Tableau is a BI tool, and some might argue we're barking up the wrong tree, and all data should be clean before reaching Tableau. My sentiment is this: <em>fuck that</em>. If a single license costs <em><strong>one thousand dollars</strong></em>, and we have the power to manipulate data <em>faster</em> as we visualize it, we should at least be able to <em>own</em> that data: and by \"own,\" I don't mean a CSV export. I want it in my <em>own</em> database of choice, not a locked down and hidden Postgres database living on a VPS filled with Tableau stuff.</p><p>Here's how we'd do that.</p><h2 id=\"you-expect-us-to-just-walk-out-the-casino-with-millions-of-dollars-on-us\">\"You Expect us to Just Walk out the Casino with Millions of Dollars on us?\"</h2><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/oceans.gif\" class=\"kg-image\"><figcaption>You're looking at a Boeski, a Jim Brown, a Miss Daisy, two Jethros and a Leon Spinks, not to mention the biggest Ella Fitzgerald ever.</figcaption></figure><!--kg-card-end: image--><p>You're here because you're the best of the best. If you're feeling scared, feel free to back out now.</p><p>This tutorial assumes you have a Tableau Server instance, with a workbook published to a site within said instance. We're going to take a page out of that workbook and turn the raw data into a database table. <strong>FAIR</strong> <strong>WARNING</strong>: We're about to dive deep into the obscure world of the <a href=\"https://onlinehelp.tableau.com/current/api/rest_api/en-us/REST/rest_api_ref.htm\">Tableau Server REST API</a>. It's clunky, it's ugly, and it returns XML. Strap yourself in. </p><p>We're going to be working with 3 core endpoints. Let's walk through them, and I'll show you how to exploit said endpoints to create a ruthless data mining machine in Python.</p><h3 id=\"-tableau-authorization-endpoint\">'Tableau Authorization' Endpoint</h3><p>Like all obnoxious (aka useful) APIs, we need to authorize each API call with a temporary token. Of course, we'll just have Python generate said token for every call we make.</p><!--kg-card-begin: code--><pre><code>POST: http://[MyTaleauServerURL]/api/3.0/auth/signin</code></pre><!--kg-card-end: code--><p>Hitting this endpoint successfully will result in an XML response (ugh). The response should look something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-xml\">&lt;?xml version='1.0' encoding='UTF-8'?&gt;\n&lt;tsResponse xmlns=&quot;http://tableau.com/api&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd&quot;&gt;\n    &lt;credentials token=&quot;KBIuvu6FTViuyivuTUR^yfvgTUycvjGubgc&quot;&gt;\n        &lt;site id=&quot;09Hiugv-345-45d0-b48b-34543giuyvg&quot; contentUrl=&quot;hackers&quot;/&gt;\n        &lt;user id=&quot;Uohiiyu-3455-8675-9b42-bugvdr876gv&quot;/&gt;\n    &lt;/credentials&gt;\n&lt;/tsResponse&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>There are a number of things going on here that we should take note of. The first being a marvel of modern technology: this is perhaps the shittiest response to a token API call in modern history. Other than that, we need two things from this response:</p><ul><li>The <strong>token</strong> is required for every API call from here on out. It is intended to be passed as a header value with the key <code>X-Tableau-Auth</code>.</li><li>The <strong>site ID</strong> is what we'll be using to look up the location of our workbooks in our server instance. This is added to the URL of future API calls (again, impressively shitty design here).</li></ul><h3 id=\"-list-all-views-by-site-endpoint\">'List All Views by Site' Endpoint</h3><p>There are actually a number of methods we could use to retrieve views, but we're specifically settling on listing our views by '<em>site,' </em>in the Tableau sense of the word<em>. </em>If you're unfamiliar, a Tableau <em>site</em> is not a site at all: it's more of project within a greater Tableau instance. They probably should've named them that.</p><!--kg-card-begin: code--><pre><code>GET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views</code></pre><!--kg-card-end: code--><p>As mentioned, we use the <strong>site ID</strong> from step 1 to construct this endpoint. In my particular instance, I've only saved a single workbook for simplicity's sake. The response for such a case is as follows:</p><!--kg-card-begin: markdown--><pre><code class=\"language-xml\">&lt;?xml version='1.0' encoding='UTF-8'?&gt;\n&lt;tsResponse xmlns=&quot;http://tableau.com/api&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd&quot;&gt;\n    &lt;pagination pageNumber=&quot;1&quot; pageSize=&quot;100&quot; totalAvailable=&quot;1&quot;/&gt;\n    &lt;views&gt;\n        &lt;view id=&quot;9a4a1de9-b7af-4a4a-8556-fd5ac82f92bd&quot; name=&quot;Jira&quot; contentUrl=&quot;JiraIssues/sheets/Jira&quot; createdAt=&quot;2018-12-21T09:11:39Z&quot; updatedAt=&quot;2018-12-21T09:11:39Z&quot;&gt;\n            &lt;workbook id=&quot;208a0c4e-e1d9-4852-9d19-7a2fe2717191&quot;/&gt;\n            &lt;owner id=&quot;Uohiiyu-3455-8675-9b42-bugvdr876gv&quot;/&gt;\n            &lt;project id=&quot;4d1ca337-20b4-442c-aa7b-1dfd470b68bd&quot;/&gt;\n            &lt;tags/&gt;\n        &lt;/view&gt;\n    &lt;/views&gt;\n&lt;/tsResponse&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>Check out the <strong>views</strong> node: when we make this API call, <code>&lt;views&gt;</code> will contain a list of every view saved to the specified site. Keep in mind that a view is equivalent to a \"sheet\" of a workbook: in almost any case, you will have many views listed here. </p><p>My sheet happens to be called \"Jira,\" as stated by <code>name=\"Jira\"</code>. The thing we really need however is the <strong>view id </strong>attribute: this will be used in our third and final API call.</p><h3 id=\"-get-view-data-endpoint\">'Get View Data' Endpoint</h3><p>Now let's get the raw data from a view of our choice.</p><!--kg-card-begin: code--><pre><code>GET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views/[MyViewID]/data\n</code></pre><!--kg-card-end: code--><p>Here's where we hit pay dirt. This request will result in an output of comma-separated values; I don't need to tell you what we can do with comma-separated values. Here's what my response looks like after formatting it as a table:</p><!--kg-card-begin: html--><div class=\"tableContainer\">\n<table class=\"table table-bordered table-hover table-condensed\">\n<thead><tr><th title=\"Field #1\">Current Assignee</th>\n<th title=\"Field #2\">Current Status</th>\n<th title=\"Field #3\">Day of Updated</th>\n<th title=\"Field #4\">epic_color</th>\n<th title=\"Field #5\">epic_name</th>\n<th title=\"Field #6\">Issue Type</th>\n<th title=\"Field #7\">issuetype_color</th>\n<th title=\"Field #8\">issuetype_url</th>\n<th title=\"Field #9\">key</th>\n<th title=\"Field #10\">Priority</th>\n<th title=\"Field #11\">project</th>\n<th title=\"Field #12\">summary</th>\n</tr></thead>\n<tbody><tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>June 7, 2018</td>\n<td>#42526E</td>\n<td>Widgets</td>\n<td>Bug</td>\n<td>#db5d5d</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/bug.png</td>\n<td>HACK-96</td>\n<td>Lowest</td>\n<td>Hackers and Slackers</td>\n<td>&quot;Recent Posts&quot; widget does not have link rollover</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Backlog</td>\n<td>June 15, 2018</td>\n<td>#57D9A3</td>\n<td>Page Templates</td>\n<td>Task</td>\n<td>#73B0E1</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/task.png</td>\n<td>HACK-32</td>\n<td>Lowest</td>\n<td>Hackers and Slackers</td>\n<td>“Join” page</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>November 13, 2018</td>\n<td>#42526E</td>\n<td>Widgets</td>\n<td>Task</td>\n<td>#73B0E1</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/task.png</td>\n<td>HACK-543</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add “pro tip” box</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>To Do</td>\n<td>December 14, 2018</td>\n<td>#679EEF</td>\n<td>SEO</td>\n<td>Major Functionality</td>\n<td>#93d171</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/story.png</td>\n<td>HACK-656</td>\n<td>Low</td>\n<td>Hackers and Slackers</td>\n<td>Add alt attributes to images vis clarifai </td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Backlog</td>\n<td>October 16, 2018</td>\n<td>#FDDA3E</td>\n<td>Accounts</td>\n<td>Major Functionality</td>\n<td>#93d171</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/story.png</td>\n<td>HACK-473</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add avatar selection to signup</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>November 13, 2018</td>\n<td>#57D9A3</td>\n<td>Page Templates</td>\n<td>Sub-task</td>\n<td>#92BFE5</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/subtask.png</td>\n<td>HACK-231</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add blurb to each post page explaining what these are</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>December 10, 2018</td>\n<td>#291BA9</td>\n<td>Code snippets</td>\n<td>Task</td>\n<td>#73B0E1</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/task.png</td>\n<td>HACK-452</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add color styles for json snippets</td>\n</tr>\n</tbody></table>\n</div><!--kg-card-end: html--><p>That's right, a <em>table.</em> Databases are comprised of tables. Perhaps you see where I'm going with this.</p><h2 id=\"there-s-a-ninety-five-pound-chinese-man-with-a-hundred-sixty-million-dollars-behind-this-door-\">\"There's a Ninety-five Pound Chinese Man with a Hundred Sixty Million Dollars Behind this Door.\"</h2><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/1379892761308689767.jpg\" class=\"kg-image\"><figcaption>Let's get him out.</figcaption></figure><!--kg-card-end: image--><p>We've got the goods, but calling all these individual endpoints manually does nothing for us. We don't want to steal a single view, we want to systematically rob Tableau of it's views on a scheduler and Shanghai them off to a database of our choosing.</p><p>It would be a crime not to automate this, so I've created a class containing all the relevant methods we'd want when it comes to interacting with Tableau's REST API:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import requests\nimport xml.etree.ElementTree as ET\nfrom . import r\nimport pandas as pd\nimport io\n\n\nclass ExtractTableauView:\n    &quot;&quot;&quot;Class for with the Tableau server API.&quot;&quot;&quot;\n\n    __baseurl = r.get('baseurl')\n    __username = r.get('username')\n    __password = r.get('password')\n    __database = r.get('uri')\n    __contenturl = r.get('contenturl')\n\n    @classmethod\n    def get_view(cls, site, xml, view, token):\n        &quot;&quot;&quot;Extract contents of a single view.&quot;&quot;&quot;\n        headers = {'X-Tableau-Auth': token,\n                   'Content-Type': 'text/csv'\n                   }\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + str(site) +'/views/' + str(view) + '/data', headers=headers, stream=True)\n        csv_text = req.text\n        view_df = pd.read_csv(io.StringIO(csv_text), header=0)\n        return view_df\n\n    @classmethod\n    def list_views(cls, site, xml, token):\n        &quot;&quot;&quot;List all views belonging to a Tableau Site.&quot;&quot;&quot;\n        headers = {'X-Tableau-Auth': token}\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + site + '/views', auth=(cls.__username, cls.__password), headers=headers)\n        root = ET.fromstring(req.content)\n        views_arr = []\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}views':\n                for view in child:\n                    view_dict = {\n                        'name': view.attrib.get('name'),\n                        'id': view.attrib.get('id'),\n                        'url': cls.__baseurl + '/' + view.attrib.get('contentUrl'),\n                        'created': view.attrib.get('createdAt'),\n                        'updated': view.attrib.get('updatedAt')\n                    }\n                    views_arr.append(view_dict)\n        return views_arr\n\n    @classmethod\n    def get_token(cls, xml):\n        &quot;&quot;&quot;Receive Auth token to perform API requests.&quot;&quot;&quot;\n        for child in xml.iter('*'):\n            if child.tag == '{http://tableau.com/api}credentials':\n                token = child.attrib.get('token')\n                return token\n\n    @classmethod\n    def get_site(cls, xml):\n        &quot;&quot;&quot;Retrieve ID of Tableau 'site' instance.&quot;&quot;&quot;\n        root = xml\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}site':\n                site = child.attrib.get('id')\n                return site\n\n    @classmethod\n    def initialize_tableau_request(cls):\n        &quot;&quot;&quot;Retrieve core XML for interacting with Tableau.&quot;&quot;&quot;\n        headers = {'Content-Type': 'application/xml'}\n        body = '&lt;tsRequest&gt;&lt;credentials name=&quot;' + cls.__username + '&quot; password=&quot;' + cls.__password + '&quot; &gt;&lt;site contentUrl=&quot;' + cls.__contenturl + '&quot; /&gt;&lt;/credentials&gt;&lt;/tsRequest&gt;'\n        req = requests.post(cls.__baseurl + '/api/3.2/auth/signin', auth=(cls.__username, cls.__password), headers=headers, data=body)\n        root = ET.fromstring(req.content)\n        return root\n</code></pre>\n<!--kg-card-end: markdown--><p>The above snippet is a Python class utilizing all the API endpoints we explored in a mostly effortless manner. Instantiating the class immediately covers the grunt work of:</p><ul><li> Generating a token</li><li>Getting your (unfriendly) site ID</li><li>Listing all views belonging to the provided site</li><li>Retrieving data from a worksheet of choice</li></ul><p>Get a list of views in your Tableau site by using the <code>list_views()</code> method. When you see the view you want, pass the <strong>view ID</strong> to the <code>.get_view()</code> method. This will result in response of all raw data in the view in the form of a CSV. </p><h3 id=\"how-to-pull-a-heist-final-chapter-storing-in-offshore-accounts\">How to Pull a Heist (Final Chapter): Storing in Offshore Accounts</h3><p>To earn your title as a true con artist, I'm leaving the final step up to you. You've escaped with the loot, but you'll need to put all that data somewhere. This should be a trivial matter of automating a simple database query, but the specifics are up to you.</p><p>If you're ready to liberate your data, feel free to <a href=\"https://gist.github.com/toddbirchard/ad1386b4334e7b22b2f7b38edca3bd5c\">grab the source off of Github</a> and go nuts.</p>","url":"https://hackersandslackers.com/tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui/","uuid":"77d21a34-e5c1-4582-aade-ff92d8596387","page":false,"codeinjection_foot":null,"codeinjection_head":"<style>\n  .post-template .post-content img {\n    width: 100% !important;\n  }\n\n  figcaption {\n    width: -webkit-fill-available !important;\n    width: -moz-available !important;\n    margin: 0 auto 0;\n    margin-top: -10px;\n    padding: 10px !important;\n    background-color: rgba(33, 69, 138, .04);\n    color: #5e6167;\n    font-size: .8em !important;\n    font-style: italic;\n    text-align: center !important;\n    white-space: normal !important;\n    line-height: 1.5 !important;\n  }\n\n  .language-xml::before {\n    content: \"XML\" !important;\n  }\n\n  .language-html::before {\n    content: \"XML\" !important;\n  }\n\n  td {\n    display: table-cell;\n    padding: 15px 10px !important;\n    font-size: .7em !important;\n    line-height: 1.2 !important;\n    text-align: left !important;\n    text-align: center !important;\n    vertical-align: middle !important;\n    max-width: 150px !important;\n    overflow: hidden !important;\n    white-space: nowrap !important;\n  }\n\n  th {\n    padding: 10px !important;\n    font-size: .7em !important;\n    text-align: center !important;\n    min-width: none !important;\n  }\n\n  .tableContainer {\n    margin-top: 30px;\n    overflow: hidden;\n  }\n</style>","comment_id":"5c27630bda392c696eab97de"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673755","title":"Lynx Roundup, December 27th","slug":"lynx-roundup-december-27th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/lynx/133@2x.jpg","excerpt":"Lessons from writing 300k lines of infrastructure code!  Deepmind to predict protein folding!  GPUs!","custom_excerpt":"Lessons from writing 300k lines of infrastructure code!  Deepmind to predict protein folding!  GPUs!","created_at_pretty":"10 December, 2018","published_at_pretty":"27 December, 2018","updated_at_pretty":"27 December, 2018","created_at":"2018-12-10T01:10:39.000-05:00","published_at":"2018-12-27T07:00:00.000-05:00","updated_at":"2018-12-27T07:00:00.000-05:00","meta_title":"Lynx Roundup, December 27th | Hackers and Slackers","meta_description":"Lessons from writing 300k lines of infrastructure code!  Deepmind to predict protein folding!  GPUs!","og_description":"Lessons from writing 300k lines of infrastructure code!  Deepmind to predict protein folding!  GPUs!","og_image":"https://hackersandslackers.com/content/images/lynx/133@2x.jpg","og_title":"Lynx Roundup, December 27th","twitter_description":"Lessons from writing 300k lines of infrastructure code!  Deepmind to predict protein folding!  GPUs!","twitter_image":"https://hackersandslackers.com/content/images/lynx/133@2x.jpg","twitter_title":"Lynx Roundup, December 27th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"https://www.wired.com/story/mcsweeneys-excerpt-the-right-to-experiment/\n\nhttp://aras-p.info/texts/files/2018Academy - GPU.pdf\n[http://aras-p.info/texts/files/2018Academy%20-%20GPU.pdf]\n\nhttp://composition.al/CMPS290S-2018-09/2018/11/17/time-is-partial-or-why-do-distributed-consistency-models-and-weak-memory-models-look-so-similar-anyway.html\n\nhttps://www.theguardian.com/science/2018/dec/02/google-deepminds-ai-program-alphafold-predicts-3d-shapes-of-proteins\n\nhttps://twitter.com/mckelveyf/status/1065402954918895619\n\nhttps://a16z.com/2017/08/01/how-aristotle-created-the-computer-atlantic/\n\nhttps://blog.gruntwork.io/5-lessons-learned-from-writing-over-300-000-lines-of-infrastructure-code-36ba7fadeac1","html":"<p></p><p><a href=\"https://www.wired.com/story/mcsweeneys-excerpt-the-right-to-experiment/\">https://www.wired.com/story/mcsweeneys-excerpt-the-right-to-experiment/</a></p><p><a href=\"http://aras-p.info/texts/files/2018Academy%20-%20GPU.pdf\">http://aras-p.info/texts/files/2018Academy - GPU.pdf</a></p><p><a href=\"http://composition.al/CMPS290S-2018-09/2018/11/17/time-is-partial-or-why-do-distributed-consistency-models-and-weak-memory-models-look-so-similar-anyway.html\">http://composition.al/CMPS290S-2018-09/2018/11/17/time-is-partial-or-why-do-distributed-consistency-models-and-weak-memory-models-look-so-similar-anyway.html</a></p><p><a href=\"https://www.theguardian.com/science/2018/dec/02/google-deepminds-ai-program-alphafold-predicts-3d-shapes-of-proteins\">https://www.theguardian.com/science/2018/dec/02/google-deepminds-ai-program-alphafold-predicts-3d-shapes-of-proteins</a></p><p><a href=\"https://twitter.com/mckelveyf/status/1065402954918895619\">https://twitter.com/mckelveyf/status/1065402954918895619</a></p><p><a href=\"https://a16z.com/2017/08/01/how-aristotle-created-the-computer-atlantic/\">https://a16z.com/2017/08/01/how-aristotle-created-the-computer-atlantic/</a></p><p><a href=\"https://blog.gruntwork.io/5-lessons-learned-from-writing-over-300-000-lines-of-infrastructure-code-36ba7fadeac1\">https://blog.gruntwork.io/5-lessons-learned-from-writing-over-300-000-lines-of-infrastructure-code-36ba7fadeac1</a></p>","url":"https://hackersandslackers.com/lynx-roundup-december-27th/","uuid":"13acdf2e-d4c9-4e11-b325-ab312a478af9","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c0e035f1556321bd84c33b0"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673754","title":"Lynx Roundup, December 26th","slug":"lynx-roundup-december-26th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/lynx/86@2x.jpg","excerpt":"Bell Labs!  The future of REST!  A mental model of AWS!","custom_excerpt":"Bell Labs!  The future of REST!  A mental model of AWS!","created_at_pretty":"10 December, 2018","published_at_pretty":"26 December, 2018","updated_at_pretty":"26 December, 2018","created_at":"2018-12-10T01:08:51.000-05:00","published_at":"2018-12-26T07:00:00.000-05:00","updated_at":"2018-12-26T07:00:00.000-05:00","meta_title":"Lynx Roundup, December 26th | Hackers and Slackers","meta_description":"Bell Labs!  The future of REST!  A mental model of AWS!","og_description":"Bell Labs!  The future of REST!  A mental model of AWS!","og_image":"https://hackersandslackers.com/content/images/lynx/86@2x.jpg","og_title":"Lynx Roundup, December 26th","twitter_description":"Bell Labs!  The future of REST!  A mental model of AWS!","twitter_image":"https://hackersandslackers.com/content/images/lynx/86@2x.jpg","twitter_title":"Lynx Roundup, December 26th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"https://research.swtch.com/bell-labs\n\nhttps://www.tbray.org/ongoing/When/201x/2018/11/18/Post-REST\n\nhttps://www.nytimes.com/interactive/2018/11/15/magazine/tech-design-ai-prediction.html\n\nhttps://semiengineering.com/system-bits-nov-20/\n\nhttps://www.allthingsdistributed.com/2018/11/amazon-redshift-performance-optimization.html\n\nhttps://cloudonaut.io/my-mental-model-of-aws/\n\nhttps://www.tedinski.com/2018/11/20/message-oriented-programming.html","html":"<p></p><p><a href=\"https://research.swtch.com/bell-labs\">https://research.swtch.com/bell-labs</a></p><p><a href=\"https://www.tbray.org/ongoing/When/201x/2018/11/18/Post-REST\">https://www.tbray.org/ongoing/When/201x/2018/11/18/Post-REST</a></p><p><a href=\"https://www.nytimes.com/interactive/2018/11/15/magazine/tech-design-ai-prediction.html\">https://www.nytimes.com/interactive/2018/11/15/magazine/tech-design-ai-prediction.html</a></p><p><a href=\"https://semiengineering.com/system-bits-nov-20/\">https://semiengineering.com/system-bits-nov-20/</a></p><p><a href=\"https://www.allthingsdistributed.com/2018/11/amazon-redshift-performance-optimization.html\">https://www.allthingsdistributed.com/2018/11/amazon-redshift-performance-optimization.html</a></p><p><a href=\"https://cloudonaut.io/my-mental-model-of-aws/\">https://cloudonaut.io/my-mental-model-of-aws/</a></p><p><a href=\"https://www.tedinski.com/2018/11/20/message-oriented-programming.html\">https://www.tedinski.com/2018/11/20/message-oriented-programming.html</a></p>","url":"https://hackersandslackers.com/lynx-roundup-december-26th/","uuid":"b9e582c3-da36-4aca-acb8-c2ce9965e9d7","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c0e02f31556321bd84c33ab"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673753","title":"Lynx Roundup, December 25th","slug":"lynx-roundup-december-25th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/lynx/xmas-lynx@2x.jpg","excerpt":"Blockchain and supply chains!  Spider milk!  In-database machine learning!","custom_excerpt":"Blockchain and supply chains!  Spider milk!  In-database machine learning!","created_at_pretty":"10 December, 2018","published_at_pretty":"25 December, 2018","updated_at_pretty":"25 December, 2018","created_at":"2018-12-10T01:07:18.000-05:00","published_at":"2018-12-25T07:00:00.000-05:00","updated_at":"2018-12-25T07:00:00.000-05:00","meta_title":"Lynx Roundup, December 25th | Hackers and Slackers","meta_description":"Blockchain and supply chains!  Spider milk!  In-database machine learning!","og_description":"Blockchain and supply chains!  Spider milk!  In-database machine learning!","og_image":"https://hackersandslackers.com/content/images/lynx/xmas-lynx@2x.jpg","og_title":"Lynx Roundup, December 25th","twitter_description":"Blockchain and supply chains!  Spider milk!  In-database machine learning!","twitter_image":"https://hackersandslackers.com/content/images/lynx/xmas-lynx@2x.jpg","twitter_title":"Lynx Roundup, December 25th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"https://muratbuffalo.blogspot.com/2018/11/hotnets18-networking-in-space.html\n\nhttp://www.odbms.org/blog/2018/11/on-in-database-machine-learning-interview-with-waqas-dhillon/\n\nhttps://datafloq.com/read/blockchain-gold-standard-supply-chains/5747\n\nhttp://www.newscientist.com/article/2186972-some-spiders-produce-milk-and-its-more-nutritious-than-cows-milk/\n\nhttps://www.nj.com/news/index.ssf/2018/11/nj_police_use_of_force_punch_kick_pepper_spray_sho.html\n\nhttps://machinelearningmastery.com/applied-machine-learning-as-a-search-problem/\n\nhttps://phys.org/news/2018-11-swarmlike-behavior-bicycling.html","html":"<p></p><p><a href=\"https://muratbuffalo.blogspot.com/2018/11/hotnets18-networking-in-space.html\">https://muratbuffalo.blogspot.com/2018/11/hotnets18-networking-in-space.html</a></p><p><a href=\"http://www.odbms.org/blog/2018/11/on-in-database-machine-learning-interview-with-waqas-dhillon/\">http://www.odbms.org/blog/2018/11/on-in-database-machine-learning-interview-with-waqas-dhillon/</a></p><p><a href=\"https://datafloq.com/read/blockchain-gold-standard-supply-chains/5747\">https://datafloq.com/read/blockchain-gold-standard-supply-chains/5747</a></p><p><a href=\"http://www.newscientist.com/article/2186972-some-spiders-produce-milk-and-its-more-nutritious-than-cows-milk/\">http://www.newscientist.com/article/2186972-some-spiders-produce-milk-and-its-more-nutritious-than-cows-milk/</a></p><p><a href=\"https://www.nj.com/news/index.ssf/2018/11/nj_police_use_of_force_punch_kick_pepper_spray_sho.html\">https://www.nj.com/news/index.ssf/2018/11/nj_police_use_of_force_punch_kick_pepper_spray_sho.html</a></p><p><a href=\"https://machinelearningmastery.com/applied-machine-learning-as-a-search-problem/\">https://machinelearningmastery.com/applied-machine-learning-as-a-search-problem/</a></p><p><a href=\"https://phys.org/news/2018-11-swarmlike-behavior-bicycling.html\">https://phys.org/news/2018-11-swarmlike-behavior-bicycling.html</a></p>","url":"https://hackersandslackers.com/lynx-roundup-december-25th/","uuid":"914be999-ab0c-45d3-bff8-3703c4b4b307","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c0e02961556321bd84c33a6"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673752","title":"Lynx Roundup, December 24th","slug":"lynx-roundup-december-24th","featured":false,"feature_image":"https://hackersandslackers.com/content/images/lynx/84-1@2x.jpg","excerpt":"Just a few self-driving cars will help traffic jams!  Chips in space!  Model-driven vs data-driven!","custom_excerpt":"Just a few self-driving cars will help traffic jams!  Chips in space!  Model-driven vs data-driven!","created_at_pretty":"10 December, 2018","published_at_pretty":"24 December, 2018","updated_at_pretty":"12 January, 2019","created_at":"2018-12-10T01:05:04.000-05:00","published_at":"2018-12-24T07:00:00.000-05:00","updated_at":"2019-01-12T01:34:32.000-05:00","meta_title":"Lynx Roundup, December 24th | Hackers and Slackers","meta_description":"Just a few self-driving cars will help traffic jams!  Chips in space!  Model-driven vs data-driven!","og_description":"Just a few self-driving cars will help traffic jams!  Chips in space!  Model-driven vs data-driven!","og_image":"https://hackersandslackers.com/content/images/lynx/84-1@2x.jpg","og_title":"Lynx Roundup, December 24th","twitter_description":"Just a few self-driving cars will help traffic jams!  Chips in space!  Model-driven vs data-driven!","twitter_image":"https://hackersandslackers.com/content/images/lynx/84-1@2x.jpg","twitter_title":"Lynx Roundup, December 24th","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Roundup","slug":"roundup","description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","feature_image":null,"meta_description":"Subscribe to our daily roundups of top data science news articles, slimmed down to only the good stuff.","meta_title":"Lynx Roundup | Hackers and Slackers","visibility":"public"}],"plaintext":"https://physicsworld.com/a/elastic-foam-uses-machine-learning-to-detect-how-its-shape-changes/\n\nhttps://arxiv.org/abs/1811.03493\n\nhttps://aws.amazon.com/blogs/aws/new-predictive-scaling-for-ec2-powered-by-machine-learning/\n\nhttps://pdfs.semanticscholar.org/2556/7f576f4ba300ac028dcef9c11966fe25df99.pdf\n\nhttps://reality.ai/model-driven-vs-data-driven-methods-for-working-with-sensors-and-signals/\n\nhttps://semiengineering.com/chips-in-space/\n\nhttps://www.sciencemag.org/news/2018/11/watch-just-few-self-driving-cars-stop-traffic-jams","html":"<p></p><p><a href=\"https://physicsworld.com/a/elastic-foam-uses-machine-learning-to-detect-how-its-shape-changes/\">https://physicsworld.com/a/elastic-foam-uses-machine-learning-to-detect-how-its-shape-changes/</a></p><p><a href=\"https://arxiv.org/abs/1811.03493\">https://arxiv.org/abs/1811.03493</a></p><p><a href=\"https://aws.amazon.com/blogs/aws/new-predictive-scaling-for-ec2-powered-by-machine-learning/\">https://aws.amazon.com/blogs/aws/new-predictive-scaling-for-ec2-powered-by-machine-learning/</a></p><p><a href=\"https://pdfs.semanticscholar.org/2556/7f576f4ba300ac028dcef9c11966fe25df99.pdf\">https://pdfs.semanticscholar.org/2556/7f576f4ba300ac028dcef9c11966fe25df99.pdf</a></p><p><a href=\"https://reality.ai/model-driven-vs-data-driven-methods-for-working-with-sensors-and-signals/\">https://reality.ai/model-driven-vs-data-driven-methods-for-working-with-sensors-and-signals/</a></p><p><a href=\"https://semiengineering.com/chips-in-space/\">https://semiengineering.com/chips-in-space/</a></p><p><a href=\"https://www.sciencemag.org/news/2018/11/watch-just-few-self-driving-cars-stop-traffic-jams\">https://www.sciencemag.org/news/2018/11/watch-just-few-self-driving-cars-stop-traffic-jams</a></p>","url":"https://hackersandslackers.com/lynx-roundup-december-24th/","uuid":"a0a2e0a5-2df4-45f9-b62a-358d2e576e2f","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c0e02101556321bd84c33a1"}}]}},"pageContext":{"pageNumber":8,"humanPageNumber":9,"skip":96,"limit":12,"numberOfPages":33,"previousPagePath":"/page/8","nextPagePath":"/page/10"}}