{"data":{"ghostTag":{"slug":"restapis","name":"REST APIs","visibility":"public","feature_image":null,"description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language."},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5c95e08ef654036aa06c6a02","title":"Building an ETL Pipeline: From JIRA to SQL","slug":"building-an-etl-pipeline-from-jira-to-postgresql","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/jira-etl-3-3.jpg","excerpt":"An example data pipeline which extracts data from the JIRA Cloud API and loads it to a SQL database.","custom_excerpt":"An example data pipeline which extracts data from the JIRA Cloud API and loads it to a SQL database.","created_at_pretty":"23 March, 2019","published_at_pretty":"28 March, 2019","updated_at_pretty":"09 April, 2019","created_at":"2019-03-23T03:30:22.000-04:00","published_at":"2019-03-28T04:15:00.000-04:00","updated_at":"2019-04-08T23:34:47.000-04:00","meta_title":"Building an ETL Pipeline: From JIRA to SQL | Hackers and Slackers","meta_description":"How to build and structure a data pipeline. This example takes issue data extracted from the JIRA Cloud API, transforms it, and loads it to a SQL database.","og_description":"How to build and structure a data pipeline. This example takes issue data extracted from the JIRA Cloud API, transforms it, and loads it to a SQL database.","og_image":"https://hackersandslackers.com/content/images/2019/03/jira-etl-3-2.jpg","og_title":"Building an ETL Pipeline: From JIRA to SQL","twitter_description":"How to build and structure a data pipeline. This example takes issue data extracted from the JIRA Cloud API, transforms it, and loads it to a SQL database.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/jira-etl-3-1.jpg","twitter_title":"Building an ETL Pipeline: From JIRA to SQL","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"}],"plaintext":"Something we haven't done just yet on this site is walking through the humble\nprocess of creating data pipelines: the art of taking a bunch of data, changing\nsaid data, and putting it somewhere else. It's kind of a weird thing to be into,\nhence why the MoMA has been rejecting my submissions of Github repositories.\nDon't worry; I'll keep at it.\n\nSomething you don't see every day are people sharing their pipelines, which is\nunderstandable. Presumably, the other people who do this kind of stuff do it for\nwork; nobody is happily building stupid pipelines in their free time begging to\nbe open sourced. Except me.\n\nWe've recently revamped our projects [https://hackersandslackers.com/projects/] \npage to include a public-facing Kanban board using GraphQL. To achieve this, we\nneed to extract JIRA data from the JIRA Cloud REST API and place it securely in\nour database.\n\nStructuring our Pipeline\nAn ETL pipeline which is considered 'well-structured' is in the eyes of the\nbeholder. There are a million different ways to pull and mess with data, so\nthere isn't a \"template\" for building these things out. In my case, the\nstructure of my script just so happened to end up as three modules: one for \nextracting, one for loading, and one for transforming. This was unplanned, but\nit's a good sign when our app matches our mindset. Here's the breakdown:\n\njira-database-etl\n├── __main__.py\n├── jira_etl\n│   ├── __init__.py\n│   ├── fetch.py\n│   ├── data.py\n│   └── db.py\n├── LICENSE\n├── MANIFEST.in\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── requirements.txt\n├── setup.cfg\n└── setup.py\n\n\nmain.py  is our application entry point. The logic of our pipeline is stored in\nthree parts under the jira_etl  directory:\n\n * fetch.py  grabs the data from the source (JIRA Cloud's REST API) and handles\n   fetching all JIRA issues.\n * data.py  transforms the data we've fetched and constructs a neat DataFrame\n   containing only the information we're after.\n * db.py  finally loads the data into a SQL database.\n\nDon't look into it too much, but here's our entry point:\n\nfrom jira_etl import fetch\nfrom jira_etl import data\nfrom jira_etl import db\n\n\ndef main():\n    \"\"\"Application Entry Point.\n\n    1. Fetch all desired JIRA issues from an instance's REST API.\n    2. Sanitize the data and add secondary metadata.\n    3. Upload resulting DataFrame to database.\n    \"\"\"\n    jira_issues_json = fetch.FetchJiraIssues.fetch_all_results()\n    jira_issues_df = data.TransformData.construct_dataframe(jira_issues_json)\n    upload_status = db.DatabaseImport.upload_dataframe(jira_issues_df)\n    return upload_status\n\n\nWithout further adieu, let's dig into the logic!\n\nExtracting Our Data\nBefore doing anything, it's essential we become familiar with the data we're\nabout to pull. Firstly, JIRA's REST API returns paginated results which max out\nat 100 results per page. This means we'll have to loop through the pages\nrecursively until all results are loaded.\n\nNext, let's look at an example of a single  JIRA issue JSON object returned by\nthe API:\n\n{\n    \"expand\": \"names,schema\",\n    \"startAt\": 0,\n    \"maxResults\": 1,\n    \"total\": 888,\n    \"issues\": [\n        {\n            \"expand\": \"operations,versionedRepresentations,editmeta,changelog,renderedFields\",\n            \"id\": \"11718\",\n            \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/issue/11718\",\n            \"key\": \"HACK-756\",\n            \"fields\": {\n                \"issuetype\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/issuetype/10014\",\n                    \"id\": \"10014\",\n                    \"description\": \"Placeholder item for \\\"holy shit this is going to be a lot of work\\\"\",\n                    \"iconUrl\": \"https://hackersandslackers.atlassian.net/secure/viewavatar?size=xsmall&avatarId=10311&avatarType=issuetype\",\n                    \"name\": \"Major Functionality\",\n                    \"subtask\": false,\n                    \"avatarId\": 10311\n                },\n                \"customfield_10070\": null,\n                \"customfield_10071\": null,\n                \"customfield_10073\": null,\n                \"customfield_10074\": null,\n                \"customfield_10075\": null,\n                \"project\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/project/10015\",\n                    \"id\": \"10015\",\n                    \"key\": \"HACK\",\n                    \"name\": \"Hackers and Slackers\",\n                    \"projectTypeKey\": \"software\",\n                    \"avatarUrls\": {\n                        \"48x48\": \"https://hackersandslackers.atlassian.net/secure/projectavatar?pid=10015&avatarId=10535\",\n                        \"24x24\": \"https://hackersandslackers.atlassian.net/secure/projectavatar?size=small&pid=10015&avatarId=10535\",\n                        \"16x16\": \"https://hackersandslackers.atlassian.net/secure/projectavatar?size=xsmall&pid=10015&avatarId=10535\",\n                        \"32x32\": \"https://hackersandslackers.atlassian.net/secure/projectavatar?size=medium&pid=10015&avatarId=10535\"\n                    }\n                },\n                \"fixVersions\": [],\n                \"resolution\": null,\n                \"resolutiondate\": null,\n                \"workratio\": -1,\n                \"lastViewed\": \"2019-03-24T02:01:31.355-0400\",\n                \"watches\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/issue/HACK-756/watchers\",\n                    \"watchCount\": 1,\n                    \"isWatching\": true\n                },\n                \"created\": \"2019-02-03T00:47:36.677-0500\",\n                \"customfield_10062\": null,\n                \"customfield_10063\": null,\n                \"customfield_10064\": null,\n                \"customfield_10065\": null,\n                \"customfield_10066\": null,\n                \"priority\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/priority/2\",\n                    \"iconUrl\": \"https://hackersandslackers.atlassian.net/images/icons/priorities/high.svg\",\n                    \"name\": \"High\",\n                    \"id\": \"2\"\n                },\n                \"customfield_10067\": null,\n                \"customfield_10068\": null,\n                \"customfield_10069\": [],\n                \"labels\": [],\n                \"versions\": [],\n                \"issuelinks\": [],\n                \"assignee\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"name\": \"bro\",\n                    \"key\": \"admin\",\n                    \"accountId\": \"557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"emailAddress\": \"toddbirchard@gmail.com\",\n                    \"avatarUrls\": {\n                        \"48x48\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue\",\n                        \"24x24\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue\",\n                        \"16x16\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue\",\n                        \"32x32\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue\"\n                    },\n                    \"displayName\": \"Todd Birchard\",\n                    \"active\": true,\n                    \"timeZone\": \"America/New_York\",\n                    \"accountType\": \"atlassian\"\n                },\n                \"updated\": \"2019-03-24T02:01:30.724-0400\",\n                \"status\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/status/10004\",\n                    \"description\": \"\",\n                    \"iconUrl\": \"https://hackersandslackers.atlassian.net/\",\n                    \"name\": \"To Do\",\n                    \"id\": \"10004\",\n                    \"statusCategory\": {\n                        \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/statuscategory/2\",\n                        \"id\": 2,\n                        \"key\": \"new\",\n                        \"colorName\": \"blue-gray\",\n                        \"name\": \"To Do\"\n                    }\n                },\n                \"components\": [],\n                \"description\": {\n                    \"version\": 1,\n                    \"type\": \"doc\",\n                    \"content\": [\n                        {\n                            \"type\": \"paragraph\",\n                            \"content\": [\n                                {\n                                    \"type\": \"text\",\n                                    \"text\": \"https://mailchimp.com/help/share-your-blog-posts-with-mailchimp/\",\n                                    \"marks\": [\n                                        {\n                                            \"type\": \"link\",\n                                            \"attrs\": {\n                                                \"href\": \"https://mailchimp.com/help/share-your-blog-posts-with-mailchimp/\"\n                                            }\n                                        }\n                                    ]\n                                }\n                            ]\n                        }\n                    ]\n                },\n                \"customfield_10010\": null,\n                \"customfield_10011\": \"0|i0064j:i\",\n                \"customfield_10012\": null,\n                \"customfield_10013\": null,\n                \"security\": null,\n                \"customfield_10008\": \"HACK-143\",\n                \"customfield_10009\": {\n                    \"hasEpicLinkFieldDependency\": false,\n                    \"showField\": false,\n                    \"nonEditableReason\": {\n                        \"reason\": \"PLUGIN_LICENSE_ERROR\",\n                        \"message\": \"Portfolio for Jira must be licensed for the Parent Link to be available.\"\n                    }\n                },\n                \"summary\": \"Automate newsletter\",\n                \"creator\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"name\": \"bro\",\n                    \"key\": \"admin\",\n                    \"accountId\": \"557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"emailAddress\": \"toddbirchard@gmail.com\",\n                    \"avatarUrls\": {\n                        \"48x48\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue\",\n                        \"24x24\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue\",\n                        \"16x16\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue\",\n                        \"32x32\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue\"\n                    },\n                    \"displayName\": \"Todd Birchard\",\n                    \"active\": true,\n                    \"timeZone\": \"America/New_York\",\n                    \"accountType\": \"atlassian\"\n                },\n                \"subtasks\": [],\n                \"reporter\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"name\": \"bro\",\n                    \"key\": \"admin\",\n                    \"accountId\": \"557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8\",\n                    \"emailAddress\": \"toddbirchard@gmail.com\",\n                    \"avatarUrls\": {\n                        \"48x48\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue\",\n                        \"24x24\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue\",\n                        \"16x16\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue\",\n                        \"32x32\": \"https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue\"\n                    },\n                    \"displayName\": \"Todd Birchard\",\n                    \"active\": true,\n                    \"timeZone\": \"America/New_York\",\n                    \"accountType\": \"atlassian\"\n                },\n                \"customfield_10000\": \"{}\",\n                \"customfield_10001\": null,\n                \"customfield_10004\": null,\n                \"environment\": null,\n                \"duedate\": null,\n                \"votes\": {\n                    \"self\": \"https://hackersandslackers.atlassian.net/rest/api/3/issue/HACK-756/votes\",\n                    \"votes\": 0,\n                    \"hasVoted\": false\n                }\n            }\n        }\n    ]\n}\n\n\nWhoa, mama! That's a ton of BS for a single issue. You can see now why we'd want\nto transform this data before importing ten million fields into any database.\nMake note of these important fields:\n\n * startAt: An integer which tells us which issue number the paginated results\n   start at.\n * maxResults: Denotes the maximum number of results page - maxes out at 100\n   issues.\n * total: The total number of issues across all pages.\n * issues: A list of objects which contain the information for exactly one JIRA\n   issue per object\n\nGreat. So the purpose of fetch.py will essentially consist of creating a list of\nall 888  issues (in my case), and passing that off for transformation. Check it\nthe source I came up with:\n\nimport os\nimport math\nimport requests\n\n\nclass FetchJiraIssues:\n    \"\"\"Fetch all public-facing issues from JIRA instance.\n\n    1. Retrieve all values from env vars.\n    2. Construct request against JIRA REST API.\n    3. Fetch paginated issues via recursion.\n    4. Pass final JSON to be transformed into a DataFrame.\n     \"\"\"\n    results_per_page = 100\n    username = os.environ.get('JIRA_USERNAME')\n    password = os.environ.get('JIRA_PASSWORD')\n    endpoint = os.environ.get('JIRA_ENDPOINT')\n    jql = os.environ.get('JIRA_QUERY')\n    headers = {\n        \"Accept\": \"application/json\"\n    }\n\n    @classmethod\n    def get_total_number_of_issues(cls):\n        \"\"\"Gets the total number of results.\"\"\"\n        params = {\n            \"jql\": cls.jql,\n            \"maxResults\": 0,\n            \"startAt\": 0\n        }\n        req = requests.get(cls.endpoint,\n                           headers=cls.headers,\n                           params=params,\n                           auth=(cls.username, cls.password)\n                           )\n        response = req.json()\n        try:\n            total_results = response['total']\n            return total_results\n        except KeyError:\n            print('Could not find any issues!')\n\n    @classmethod\n    def fetch_all_results(cls):\n        \"\"\"Recursively retrieve all pages of JIRA issues.\"\"\"\n        total_results = cls.get_total_number_of_issues()\n        issue_arr = []\n\n        def fetch_single_page():\n            \"\"\"Fetch one page of results, and determine if another page exists.\"\"\"\n            params = {\n                \"jql\": cls.jql,\n                \"maxResults\": cls.results_per_page,\n                \"startAt\": len(issue_arr)\n            }\n            req = requests.get(cls.endpoint,\n                               headers=cls.headers,\n                               params=params,\n                               auth=(cls.username, cls.password)\n                               )\n            response = req.json()\n            issues = response['issues']\n            issues_so_far = len(issue_arr) + cls.results_per_page\n            print(issues_so_far, ' out of', total_results)\n            issue_arr.extend(issues)\n            # Check if additional pages of results exist.\n        count = math.ceil(total_results/cls.results_per_page)\n        for x in range(0, count):\n            fetch_single_page()\n        return issue_arr\n\n\nYep, I'm using classes. This class has two methods:\n\n * get_total_number_of_issues: All this does is essentially pull the number of\n   issues (888) from the REST API. We'll use this number in our next function to\n   check if additional pages exist.\n * fetch_all_results: This is where things start getting fun. fetch_all_results \n   is a @classmethod  which contains a function within itself. fetch_all_results \n    gets the total number of JIRA issues and then calls upon child function \n   fetch_single_page to pull JIRA issue JSON objects and dump them into a list\n   called issue_arr  until all issues are accounted for.\n\nBecause we have 888 issues and can retrieve 100 issues  at a time, our function\nfetch_single_page  should run 9 times. And it does!\n\nTransforming Our Data\nSo now we have a list of 888 messy JIRA issues. The scope of data.py  should be\nto pull out only the data we want, and make sure that data is clean:\n\nimport os\nimport json\nfrom pandas.io.json import json_normalize\nfrom datetime import datetime\n\n\nclass TransformData:\n    \"\"\"Build JIRA issue DataFrame.\n\n    1. Loop through JIRA issues and create a dictionary of desired data.\n    2. Convert each issue dictionary into a JSON object.\n    3. Load all issues into a Pandas DataFrame.\n    \"\"\"\n\n    issue_count = 0\n\n    @classmethod\n    def construct_dataframe(cls, issue_list_chunk):\n        \"\"\"Make DataFrame out of data received from JIRA API.\"\"\"\n        issue_list = [cls.make_issue_body(issue) for issue in issue_list_chunk]\n        issue_json_list = [cls.dict_to_json_string(issue) for issue in issue_list]\n        jira_issues_df = json_normalize(issue_json_list)\n        return jira_issues_df\n\n    @staticmethod\n    def dict_to_json_string(issue_dict):\n        \"\"\"Convert dict to JSON to string.\"\"\"\n        issue_json_string = json.dumps(issue_dict)\n        issue_json = json.loads(issue_json_string)\n        return issue_json\n\n    @classmethod\n    def make_issue_body(cls, issue):\n        \"\"\"Create a JSON body for each ticket.\"\"\"\n        updated_date = datetime.strptime(issue['fields']['updated'], \"%Y-%m-%dT%H:%M:%S.%f%z\")\n        body = {\n            'id': str(cls.issue_count),\n            'key': str(issue['key']),\n            'assignee_name': str(issue['fields']['assignee']['displayName']),\n            'assignee_url': str(issue['fields']['assignee']['avatarUrls']['48x48']),\n            'summary': str(issue['fields']['summary']),\n            'status': str(issue['fields']['status']['name']),\n            'priority_url': str(issue['fields']['priority']['iconUrl']),\n            'priority_rank': int(issue['fields']['priority']['id']),\n            'issuetype_name': str(issue['fields']['issuetype']['name']),\n            'issuetype_icon': str(issue['fields']['issuetype']['iconUrl']),\n            'epic_link': str(issue['fields']['customfield_10008']),\n            'project': str(issue['fields']['project']['name']),\n            'updated': int(datetime.timestamp(updated_date)),\n            'updatedAt': str(updated_date)\n        }\n        cls.issue_count += 1\n        return body\n\n\nAgain, let's see the methods at work:\n\n * construct_dataframe: The main function we invoke to build our DataFrame\n   (mostly just calls other methods). Once all transformations are completed,\n   creates a DataFrame called jira_df  by using the Pandas json_normalize() \n   method.\n * make_issue_body: Creates a new dictionary per singular JIRA issue. Extracts \n   only  the fields we want to be imported into our database. Converts each\n   field into either a string or an int as a lazy way of avoiding null values\n   (for example, if issue['fields']['priority']['name']  contained a null value,\n   the script would error out. Wrapping this in str() is a dirty way of\n   converting null  to an empty string).\n * dict_to_json_string  Takes each issue dictionary and converts it to a JSON\n   object, which is then turned into a string (this is done for Pandas).\n\nLoading Our Data\nAnd now for the final step! Thanks to the joyful marriage of Pandas and\nSQLAlchemy, turning DataFrames into SQL tables is super simple. We never make\nthings simple, though.\n\nimport os\nimport logging\nfrom sqlalchemy import create_engine, text, MetaData\nfrom sqlalchemy.types import Integer, Text, TIMESTAMP, String\nimport pandas as pd\n\nlogging.basicConfig()\nlogging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)\n\n\nclass DatabaseImport:\n    \"\"\"Merge Epic metadata and upload JIRA issues.\n\n    1. Merge Epic metadata by fetching an existing table.\n    2. Explicitly set data types for all columns found in jira_issues_df.\n    2. Create a new table from the final jira_issues_df.\n    \"\"\"\n\n    URI = os.environ.get('SQLALCHEMY_DATABASE_URI')\n    db_epic_table = os.environ.get('SQLALCHEMY_EPIC_TABLE')\n    db_jira_table = os.environ.get('SQLALCHEMY_JIRA_TABLE')\n    db_schema = os.environ.get('SQLALCHEMY_DB_SCHEMA')\n\n    # Create Engine\n    meta = MetaData(schema=\"hackers$prod\")\n    engine = create_engine(URI, echo=True)\n\n    @staticmethod\n    def truncate_table(engine):\n        \"\"\"Clear table of data.\"\"\"\n        sql = text('TRUNCATE TABLE \"hackers$prod\".\"JiraIssue\"')\n        engine.execute(sql)\n\n    @classmethod\n    def merge_epic_metadata(cls, jira_issues_df):\n        \"\"\"Merge epic metadata from existing SQL table.\"\"\"\n        cls.truncate_table(cls.engine)\n        epics_df = pd.read_sql_table(cls.db_epic_table,\n                                     cls.engine,\n                                     schema=cls.db_schema)\n        jira_issues_df = pd.merge(jira_issues_df,\n                                  epics_df[['epic_link', 'epic_name', 'epic_color']],\n                                  how='left',\n                                  on='epic_link',\n                                  copy=False)\n        return jira_issues_df\n\n    @classmethod\n    def upload_dataframe(cls, jira_issues_df):\n        \"\"\"Upload JIRA DataFrame to PostgreSQL database.\"\"\"\n        jira_issues_df = cls.merge_epic_metadata(jira_issues_df)\n        jira_issues_df.to_sql(cls.db_jira_table,\n                              cls.engine,\n                              if_exists='append',\n                              schema=cls.db_schema,\n                              index=False,\n                              dtype={\"assignee\": String(30),\n                                     \"assignee_url\": Text,\n                                     \"epic_link\": String(50),\n                                     \"issuetype_name\": String(50),\n                                     \"issuetype_icon\": Text,\n                                     \"key\": String(10),\n                                     \"priority_name\": String(30),\n                                     \"priority_rank\": Integer,\n                                     \"priority_url\": Text,\n                                     \"project\": String(50),\n                                     \"status\": String(30),\n                                     \"summary\": Text,\n                                     \"updated\": Integer,\n                                     \"updatedAt\": TIMESTAMP,\n                                     \"createdAt\": TIMESTAMP,\n                                     \"epic_color\": String(20),\n                                     \"epic_name\": String(50)\n                                     })\n        success_message = 'Successfully uploaded' \\\n                          + str(len(jira_issues_df.index)) \\\n                          + ' rows to ' + cls.db_jira_table\n        return success_message\n\n\n * merge_epic_metadata: Due to the nature of the JIRA REST API, some metadata is\n   missing per issue. If you're interested, the data missing revolves around \n   Epics: JIRA's REST API does not include the Epic Name  or Epic Color  fields\n   of linked epics.\n * upload_dataframe: Uses Panda's to_sql()  method to upload our DataFrame into\n   a SQL table (our target happens to be PostgreSQL, so we pass schema  here).\n   To make things explicit, we set the data type of every column on upload.\n\nWell, let's see how we made out!\n\nA look at our resulting database table.Whoaaa nelly, we did it! With our data\nclean, we can now build something useful! Here's what I built:\n\nFruits of our labor!There we have it: a pipeline that takes a bunch of messy\ndata, cleans it, and puts it somewhere else for proper use.\n\nIf you're interested in how we created the frontend for our Kanban board, check\nout our series on building features with GraphQL\n[https://hackersandslackers.com/series/graphql-hype/]. For the source code,\ncheck out the Github repository\n[https://github.com/toddbirchard/jira-database-etl].","html":"<p>Something we haven't done just yet on this site is walking through the humble process of creating data pipelines: the art of taking a bunch of data, changing said data, and putting it somewhere else. It's kind of a weird thing to be into, hence why the MoMA has been rejecting my submissions of Github repositories. Don't worry; I'll keep at it.</p><p>Something you don't see every day are people sharing their pipelines, which is understandable. Presumably, the other people who do this kind of stuff do it for work; nobody is happily building stupid pipelines in their free time begging to be open sourced. Except me.</p><p>We've recently revamped our <strong><a href=\"https://hackersandslackers.com/projects/\">projects</a></strong> page to include a public-facing Kanban board using GraphQL. To achieve this, we need to extract JIRA data from the JIRA Cloud REST API and place it securely in our database.</p><h2 id=\"structuring-our-pipeline\">Structuring our Pipeline</h2><p>An ETL pipeline which is considered 'well-structured' is in the eyes of the beholder. There are a million different ways to pull and mess with data, so there isn't a \"template\" for building these things out. In my case, the structure of my script just so happened to end up as three modules: one for <em>extracting</em>, one for <em>loading</em>, and one for <em>transforming</em>. This was unplanned, but it's a good sign when our app matches our mindset. Here's the breakdown:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">jira-database-etl\n├── __main__.py\n├── jira_etl\n│   ├── __init__.py\n│   ├── fetch.py\n│   ├── data.py\n│   └── db.py\n├── LICENSE\n├── MANIFEST.in\n├── Pipfile\n├── Pipfile.lock\n├── README.md\n├── requirements.txt\n├── setup.cfg\n└── setup.py\n</code></pre>\n<!--kg-card-end: markdown--><p><strong>main.py</strong> is our application entry point. The logic of our pipeline is stored in three parts under the <strong>jira_etl</strong> directory:</p><ul><li><strong>fetch.py</strong> grabs the data from the source (JIRA Cloud's REST API) and handles fetching all JIRA issues.</li><li><strong>data.py</strong> transforms the data we've fetched and constructs a neat DataFrame containing only the information we're after.</li><li><strong>db.py</strong> finally loads the data into a SQL database.</li></ul><p>Don't look into it too much, but here's our entry point:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">from jira_etl import fetch\nfrom jira_etl import data\nfrom jira_etl import db\n\n\ndef main():\n    &quot;&quot;&quot;Application Entry Point.\n\n    1. Fetch all desired JIRA issues from an instance's REST API.\n    2. Sanitize the data and add secondary metadata.\n    3. Upload resulting DataFrame to database.\n    &quot;&quot;&quot;\n    jira_issues_json = fetch.FetchJiraIssues.fetch_all_results()\n    jira_issues_df = data.TransformData.construct_dataframe(jira_issues_json)\n    upload_status = db.DatabaseImport.upload_dataframe(jira_issues_df)\n    return upload_status\n</code></pre>\n<!--kg-card-end: markdown--><p>Without further adieu, let's dig into the logic!</p><h2 id=\"extracting-our-data\">Extracting Our Data</h2><p>Before doing anything, it's essential we become familiar with the data we're about to pull. Firstly, JIRA's REST API returns paginated results which max out at 100 results per page. This means we'll have to loop through the pages recursively until all results are loaded.</p><p>Next, let's look at an example of a <strong><em>single</em></strong> JIRA issue JSON object returned by the API:</p><!--kg-card-begin: markdown--><pre><code class=\"language-json\">{\n    &quot;expand&quot;: &quot;names,schema&quot;,\n    &quot;startAt&quot;: 0,\n    &quot;maxResults&quot;: 1,\n    &quot;total&quot;: 888,\n    &quot;issues&quot;: [\n        {\n            &quot;expand&quot;: &quot;operations,versionedRepresentations,editmeta,changelog,renderedFields&quot;,\n            &quot;id&quot;: &quot;11718&quot;,\n            &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/issue/11718&quot;,\n            &quot;key&quot;: &quot;HACK-756&quot;,\n            &quot;fields&quot;: {\n                &quot;issuetype&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/issuetype/10014&quot;,\n                    &quot;id&quot;: &quot;10014&quot;,\n                    &quot;description&quot;: &quot;Placeholder item for \\&quot;holy shit this is going to be a lot of work\\&quot;&quot;,\n                    &quot;iconUrl&quot;: &quot;https://hackersandslackers.atlassian.net/secure/viewavatar?size=xsmall&amp;avatarId=10311&amp;avatarType=issuetype&quot;,\n                    &quot;name&quot;: &quot;Major Functionality&quot;,\n                    &quot;subtask&quot;: false,\n                    &quot;avatarId&quot;: 10311\n                },\n                &quot;customfield_10070&quot;: null,\n                &quot;customfield_10071&quot;: null,\n                &quot;customfield_10073&quot;: null,\n                &quot;customfield_10074&quot;: null,\n                &quot;customfield_10075&quot;: null,\n                &quot;project&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/project/10015&quot;,\n                    &quot;id&quot;: &quot;10015&quot;,\n                    &quot;key&quot;: &quot;HACK&quot;,\n                    &quot;name&quot;: &quot;Hackers and Slackers&quot;,\n                    &quot;projectTypeKey&quot;: &quot;software&quot;,\n                    &quot;avatarUrls&quot;: {\n                        &quot;48x48&quot;: &quot;https://hackersandslackers.atlassian.net/secure/projectavatar?pid=10015&amp;avatarId=10535&quot;,\n                        &quot;24x24&quot;: &quot;https://hackersandslackers.atlassian.net/secure/projectavatar?size=small&amp;pid=10015&amp;avatarId=10535&quot;,\n                        &quot;16x16&quot;: &quot;https://hackersandslackers.atlassian.net/secure/projectavatar?size=xsmall&amp;pid=10015&amp;avatarId=10535&quot;,\n                        &quot;32x32&quot;: &quot;https://hackersandslackers.atlassian.net/secure/projectavatar?size=medium&amp;pid=10015&amp;avatarId=10535&quot;\n                    }\n                },\n                &quot;fixVersions&quot;: [],\n                &quot;resolution&quot;: null,\n                &quot;resolutiondate&quot;: null,\n                &quot;workratio&quot;: -1,\n                &quot;lastViewed&quot;: &quot;2019-03-24T02:01:31.355-0400&quot;,\n                &quot;watches&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/issue/HACK-756/watchers&quot;,\n                    &quot;watchCount&quot;: 1,\n                    &quot;isWatching&quot;: true\n                },\n                &quot;created&quot;: &quot;2019-02-03T00:47:36.677-0500&quot;,\n                &quot;customfield_10062&quot;: null,\n                &quot;customfield_10063&quot;: null,\n                &quot;customfield_10064&quot;: null,\n                &quot;customfield_10065&quot;: null,\n                &quot;customfield_10066&quot;: null,\n                &quot;priority&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/priority/2&quot;,\n                    &quot;iconUrl&quot;: &quot;https://hackersandslackers.atlassian.net/images/icons/priorities/high.svg&quot;,\n                    &quot;name&quot;: &quot;High&quot;,\n                    &quot;id&quot;: &quot;2&quot;\n                },\n                &quot;customfield_10067&quot;: null,\n                &quot;customfield_10068&quot;: null,\n                &quot;customfield_10069&quot;: [],\n                &quot;labels&quot;: [],\n                &quot;versions&quot;: [],\n                &quot;issuelinks&quot;: [],\n                &quot;assignee&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;name&quot;: &quot;bro&quot;,\n                    &quot;key&quot;: &quot;admin&quot;,\n                    &quot;accountId&quot;: &quot;557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;emailAddress&quot;: &quot;toddbirchard@gmail.com&quot;,\n                    &quot;avatarUrls&quot;: {\n                        &quot;48x48&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue&quot;,\n                        &quot;24x24&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue&quot;,\n                        &quot;16x16&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue&quot;,\n                        &quot;32x32&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue&quot;\n                    },\n                    &quot;displayName&quot;: &quot;Todd Birchard&quot;,\n                    &quot;active&quot;: true,\n                    &quot;timeZone&quot;: &quot;America/New_York&quot;,\n                    &quot;accountType&quot;: &quot;atlassian&quot;\n                },\n                &quot;updated&quot;: &quot;2019-03-24T02:01:30.724-0400&quot;,\n                &quot;status&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/status/10004&quot;,\n                    &quot;description&quot;: &quot;&quot;,\n                    &quot;iconUrl&quot;: &quot;https://hackersandslackers.atlassian.net/&quot;,\n                    &quot;name&quot;: &quot;To Do&quot;,\n                    &quot;id&quot;: &quot;10004&quot;,\n                    &quot;statusCategory&quot;: {\n                        &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/statuscategory/2&quot;,\n                        &quot;id&quot;: 2,\n                        &quot;key&quot;: &quot;new&quot;,\n                        &quot;colorName&quot;: &quot;blue-gray&quot;,\n                        &quot;name&quot;: &quot;To Do&quot;\n                    }\n                },\n                &quot;components&quot;: [],\n                &quot;description&quot;: {\n                    &quot;version&quot;: 1,\n                    &quot;type&quot;: &quot;doc&quot;,\n                    &quot;content&quot;: [\n                        {\n                            &quot;type&quot;: &quot;paragraph&quot;,\n                            &quot;content&quot;: [\n                                {\n                                    &quot;type&quot;: &quot;text&quot;,\n                                    &quot;text&quot;: &quot;https://mailchimp.com/help/share-your-blog-posts-with-mailchimp/&quot;,\n                                    &quot;marks&quot;: [\n                                        {\n                                            &quot;type&quot;: &quot;link&quot;,\n                                            &quot;attrs&quot;: {\n                                                &quot;href&quot;: &quot;https://mailchimp.com/help/share-your-blog-posts-with-mailchimp/&quot;\n                                            }\n                                        }\n                                    ]\n                                }\n                            ]\n                        }\n                    ]\n                },\n                &quot;customfield_10010&quot;: null,\n                &quot;customfield_10011&quot;: &quot;0|i0064j:i&quot;,\n                &quot;customfield_10012&quot;: null,\n                &quot;customfield_10013&quot;: null,\n                &quot;security&quot;: null,\n                &quot;customfield_10008&quot;: &quot;HACK-143&quot;,\n                &quot;customfield_10009&quot;: {\n                    &quot;hasEpicLinkFieldDependency&quot;: false,\n                    &quot;showField&quot;: false,\n                    &quot;nonEditableReason&quot;: {\n                        &quot;reason&quot;: &quot;PLUGIN_LICENSE_ERROR&quot;,\n                        &quot;message&quot;: &quot;Portfolio for Jira must be licensed for the Parent Link to be available.&quot;\n                    }\n                },\n                &quot;summary&quot;: &quot;Automate newsletter&quot;,\n                &quot;creator&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;name&quot;: &quot;bro&quot;,\n                    &quot;key&quot;: &quot;admin&quot;,\n                    &quot;accountId&quot;: &quot;557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;emailAddress&quot;: &quot;toddbirchard@gmail.com&quot;,\n                    &quot;avatarUrls&quot;: {\n                        &quot;48x48&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue&quot;,\n                        &quot;24x24&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue&quot;,\n                        &quot;16x16&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue&quot;,\n                        &quot;32x32&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue&quot;\n                    },\n                    &quot;displayName&quot;: &quot;Todd Birchard&quot;,\n                    &quot;active&quot;: true,\n                    &quot;timeZone&quot;: &quot;America/New_York&quot;,\n                    &quot;accountType&quot;: &quot;atlassian&quot;\n                },\n                &quot;subtasks&quot;: [],\n                &quot;reporter&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/user?accountId=557058%3A713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;name&quot;: &quot;bro&quot;,\n                    &quot;key&quot;: &quot;admin&quot;,\n                    &quot;accountId&quot;: &quot;557058:713aac6d-44ef-416d-9a1d-3e524a5c4dc8&quot;,\n                    &quot;emailAddress&quot;: &quot;toddbirchard@gmail.com&quot;,\n                    &quot;avatarUrls&quot;: {\n                        &quot;48x48&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=48&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D48%26noRedirect%3Dtrue&quot;,\n                        &quot;24x24&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=24&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D24%26noRedirect%3Dtrue&quot;,\n                        &quot;16x16&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=16&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D16%26noRedirect%3Dtrue&quot;,\n                        &quot;32x32&quot;: &quot;https://avatar-cdn.atlassian.com/9eb3868db428fb602e03b3059608199b?s=32&amp;d=https%3A%2F%2Fsecure.gravatar.com%2Favatar%2F9eb3868db428fb602e03b3059608199b%3Fd%3Dmm%26s%3D32%26noRedirect%3Dtrue&quot;\n                    },\n                    &quot;displayName&quot;: &quot;Todd Birchard&quot;,\n                    &quot;active&quot;: true,\n                    &quot;timeZone&quot;: &quot;America/New_York&quot;,\n                    &quot;accountType&quot;: &quot;atlassian&quot;\n                },\n                &quot;customfield_10000&quot;: &quot;{}&quot;,\n                &quot;customfield_10001&quot;: null,\n                &quot;customfield_10004&quot;: null,\n                &quot;environment&quot;: null,\n                &quot;duedate&quot;: null,\n                &quot;votes&quot;: {\n                    &quot;self&quot;: &quot;https://hackersandslackers.atlassian.net/rest/api/3/issue/HACK-756/votes&quot;,\n                    &quot;votes&quot;: 0,\n                    &quot;hasVoted&quot;: false\n                }\n            }\n        }\n    ]\n}\n</code></pre>\n<!--kg-card-end: markdown--><p>Whoa, mama! That's a ton of BS for a single issue. You can see now why we'd want to transform this data before importing ten million fields into any database. Make note of these important fields:</p><ul><li><code>startAt</code>: An integer which tells us which issue number the paginated results start at.</li><li><code>maxResults</code>: Denotes the maximum number of results page - maxes out at 100 issues.</li><li><code>total</code>: The total number of issues across all pages.</li><li><code>issues</code>: A list of objects which contain the information for exactly one JIRA issue per object</li></ul><p>Great. So the purpose of <strong>fetch.py </strong>will essentially consist of creating a list of all <strong>888</strong> issues (in my case), and passing that off for transformation. Check it the source I came up with:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nimport math\nimport requests\n\n\nclass FetchJiraIssues:\n    &quot;&quot;&quot;Fetch all public-facing issues from JIRA instance.\n\n    1. Retrieve all values from env vars.\n    2. Construct request against JIRA REST API.\n    3. Fetch paginated issues via recursion.\n    4. Pass final JSON to be transformed into a DataFrame.\n     &quot;&quot;&quot;\n    results_per_page = 100\n    username = os.environ.get('JIRA_USERNAME')\n    password = os.environ.get('JIRA_PASSWORD')\n    endpoint = os.environ.get('JIRA_ENDPOINT')\n    jql = os.environ.get('JIRA_QUERY')\n    headers = {\n        &quot;Accept&quot;: &quot;application/json&quot;\n    }\n\n    @classmethod\n    def get_total_number_of_issues(cls):\n        &quot;&quot;&quot;Gets the total number of results.&quot;&quot;&quot;\n        params = {\n            &quot;jql&quot;: cls.jql,\n            &quot;maxResults&quot;: 0,\n            &quot;startAt&quot;: 0\n        }\n        req = requests.get(cls.endpoint,\n                           headers=cls.headers,\n                           params=params,\n                           auth=(cls.username, cls.password)\n                           )\n        response = req.json()\n        try:\n            total_results = response['total']\n            return total_results\n        except KeyError:\n            print('Could not find any issues!')\n\n    @classmethod\n    def fetch_all_results(cls):\n        &quot;&quot;&quot;Recursively retrieve all pages of JIRA issues.&quot;&quot;&quot;\n        total_results = cls.get_total_number_of_issues()\n        issue_arr = []\n\n        def fetch_single_page():\n            &quot;&quot;&quot;Fetch one page of results, and determine if another page exists.&quot;&quot;&quot;\n            params = {\n                &quot;jql&quot;: cls.jql,\n                &quot;maxResults&quot;: cls.results_per_page,\n                &quot;startAt&quot;: len(issue_arr)\n            }\n            req = requests.get(cls.endpoint,\n                               headers=cls.headers,\n                               params=params,\n                               auth=(cls.username, cls.password)\n                               )\n            response = req.json()\n            issues = response['issues']\n            issues_so_far = len(issue_arr) + cls.results_per_page\n            print(issues_so_far, ' out of', total_results)\n            issue_arr.extend(issues)\n            # Check if additional pages of results exist.\n        count = math.ceil(total_results/cls.results_per_page)\n        for x in range(0, count):\n            fetch_single_page()\n        return issue_arr\n</code></pre>\n<!--kg-card-end: markdown--><p>Yep, I'm using classes. This class has two methods:</p><ul><li><code>get_total_number_of_issues</code>: All this does is essentially pull the number of issues (888) from the REST API. We'll use this number in our next function to check if additional pages exist.</li><li><code>fetch_all_results</code>: This is where things start getting fun. <strong>fetch_all_results</strong> is a <em>@classmethod</em> which contains a function within itself. <strong>fetch_all_results</strong> gets the total number of JIRA issues and then calls upon child function <strong>fetch_single_page </strong>to pull JIRA issue JSON objects and dump them into a list called <code>issue_arr</code> until all issues are accounted for.</li></ul><p>Because we have <em>888 issues </em>and can retrieve <em>100 issues</em> at a time, our function  <code>fetch_single_page</code> should run <em>9 times</em>. And it does!</p><h2 id=\"transforming-our-data\">Transforming Our Data</h2><p>So now we have a list of 888 messy JIRA issues. The scope of <strong>data.py</strong> should be to pull out only the data we want, and make sure that data is clean:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nimport json\nfrom pandas.io.json import json_normalize\nfrom datetime import datetime\n\n\nclass TransformData:\n    &quot;&quot;&quot;Build JIRA issue DataFrame.\n\n    1. Loop through JIRA issues and create a dictionary of desired data.\n    2. Convert each issue dictionary into a JSON object.\n    3. Load all issues into a Pandas DataFrame.\n    &quot;&quot;&quot;\n\n    issue_count = 0\n\n    @classmethod\n    def construct_dataframe(cls, issue_list_chunk):\n        &quot;&quot;&quot;Make DataFrame out of data received from JIRA API.&quot;&quot;&quot;\n        issue_list = [cls.make_issue_body(issue) for issue in issue_list_chunk]\n        issue_json_list = [cls.dict_to_json_string(issue) for issue in issue_list]\n        jira_issues_df = json_normalize(issue_json_list)\n        return jira_issues_df\n\n    @staticmethod\n    def dict_to_json_string(issue_dict):\n        &quot;&quot;&quot;Convert dict to JSON to string.&quot;&quot;&quot;\n        issue_json_string = json.dumps(issue_dict)\n        issue_json = json.loads(issue_json_string)\n        return issue_json\n\n    @classmethod\n    def make_issue_body(cls, issue):\n        &quot;&quot;&quot;Create a JSON body for each ticket.&quot;&quot;&quot;\n        updated_date = datetime.strptime(issue['fields']['updated'], &quot;%Y-%m-%dT%H:%M:%S.%f%z&quot;)\n        body = {\n            'id': str(cls.issue_count),\n            'key': str(issue['key']),\n            'assignee_name': str(issue['fields']['assignee']['displayName']),\n            'assignee_url': str(issue['fields']['assignee']['avatarUrls']['48x48']),\n            'summary': str(issue['fields']['summary']),\n            'status': str(issue['fields']['status']['name']),\n            'priority_url': str(issue['fields']['priority']['iconUrl']),\n            'priority_rank': int(issue['fields']['priority']['id']),\n            'issuetype_name': str(issue['fields']['issuetype']['name']),\n            'issuetype_icon': str(issue['fields']['issuetype']['iconUrl']),\n            'epic_link': str(issue['fields']['customfield_10008']),\n            'project': str(issue['fields']['project']['name']),\n            'updated': int(datetime.timestamp(updated_date)),\n            'updatedAt': str(updated_date)\n        }\n        cls.issue_count += 1\n        return body\n</code></pre>\n<!--kg-card-end: markdown--><p>Again, let's see the methods at work:</p><ul><li><code>construct_dataframe</code>: The main function we invoke to build our DataFrame (mostly just calls other methods). Once all transformations are completed, creates a DataFrame called <strong>jira_df</strong> by using the Pandas <em>json_normalize()</em> method.</li><li><code>make_issue_body</code>: Creates a new dictionary per singular JIRA issue. Extracts <em>only</em> the fields we want to be imported into our database. Converts each field into either a string or an int as a lazy way of avoiding null values (for example, if <code>issue['fields']['priority']['name']</code> contained a null value, the script would error out. Wrapping this in <strong>str() </strong>is a dirty way of converting <em>null</em> to an empty string).</li><li><code>dict_to_json_string</code> Takes each issue dictionary and converts it to a JSON object, which is then turned into a string (this is done for Pandas).</li></ul><h2 id=\"loading-our-data\">Loading Our Data</h2><p>And now for the final step! Thanks to the joyful marriage of Pandas and SQLAlchemy, turning DataFrames into SQL tables is super simple. We never make things simple, though.</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import os\nimport logging\nfrom sqlalchemy import create_engine, text, MetaData\nfrom sqlalchemy.types import Integer, Text, TIMESTAMP, String\nimport pandas as pd\n\nlogging.basicConfig()\nlogging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)\n\n\nclass DatabaseImport:\n    &quot;&quot;&quot;Merge Epic metadata and upload JIRA issues.\n\n    1. Merge Epic metadata by fetching an existing table.\n    2. Explicitly set data types for all columns found in jira_issues_df.\n    2. Create a new table from the final jira_issues_df.\n    &quot;&quot;&quot;\n\n    URI = os.environ.get('SQLALCHEMY_DATABASE_URI')\n    db_epic_table = os.environ.get('SQLALCHEMY_EPIC_TABLE')\n    db_jira_table = os.environ.get('SQLALCHEMY_JIRA_TABLE')\n    db_schema = os.environ.get('SQLALCHEMY_DB_SCHEMA')\n\n    # Create Engine\n    meta = MetaData(schema=&quot;hackers$prod&quot;)\n    engine = create_engine(URI, echo=True)\n\n    @staticmethod\n    def truncate_table(engine):\n        &quot;&quot;&quot;Clear table of data.&quot;&quot;&quot;\n        sql = text('TRUNCATE TABLE &quot;hackers$prod&quot;.&quot;JiraIssue&quot;')\n        engine.execute(sql)\n\n    @classmethod\n    def merge_epic_metadata(cls, jira_issues_df):\n        &quot;&quot;&quot;Merge epic metadata from existing SQL table.&quot;&quot;&quot;\n        cls.truncate_table(cls.engine)\n        epics_df = pd.read_sql_table(cls.db_epic_table,\n                                     cls.engine,\n                                     schema=cls.db_schema)\n        jira_issues_df = pd.merge(jira_issues_df,\n                                  epics_df[['epic_link', 'epic_name', 'epic_color']],\n                                  how='left',\n                                  on='epic_link',\n                                  copy=False)\n        return jira_issues_df\n\n    @classmethod\n    def upload_dataframe(cls, jira_issues_df):\n        &quot;&quot;&quot;Upload JIRA DataFrame to PostgreSQL database.&quot;&quot;&quot;\n        jira_issues_df = cls.merge_epic_metadata(jira_issues_df)\n        jira_issues_df.to_sql(cls.db_jira_table,\n                              cls.engine,\n                              if_exists='append',\n                              schema=cls.db_schema,\n                              index=False,\n                              dtype={&quot;assignee&quot;: String(30),\n                                     &quot;assignee_url&quot;: Text,\n                                     &quot;epic_link&quot;: String(50),\n                                     &quot;issuetype_name&quot;: String(50),\n                                     &quot;issuetype_icon&quot;: Text,\n                                     &quot;key&quot;: String(10),\n                                     &quot;priority_name&quot;: String(30),\n                                     &quot;priority_rank&quot;: Integer,\n                                     &quot;priority_url&quot;: Text,\n                                     &quot;project&quot;: String(50),\n                                     &quot;status&quot;: String(30),\n                                     &quot;summary&quot;: Text,\n                                     &quot;updated&quot;: Integer,\n                                     &quot;updatedAt&quot;: TIMESTAMP,\n                                     &quot;createdAt&quot;: TIMESTAMP,\n                                     &quot;epic_color&quot;: String(20),\n                                     &quot;epic_name&quot;: String(50)\n                                     })\n        success_message = 'Successfully uploaded' \\\n                          + str(len(jira_issues_df.index)) \\\n                          + ' rows to ' + cls.db_jira_table\n        return success_message\n</code></pre>\n<!--kg-card-end: markdown--><ul><li><code>merge_epic_metadata</code>: Due to the nature of the JIRA REST API, some metadata is missing per issue. If you're interested, the data missing revolves around <strong>Epics</strong>: JIRA's REST API does not include the <em>Epic Name</em> or <em>Epic Color</em> fields of linked epics.</li><li><code>upload_dataframe</code>: Uses Panda's <strong>to_sql()</strong> method to upload our DataFrame into a SQL table (our target happens to be PostgreSQL, so we pass <em>schema</em> here). To make things explicit, we set the data type of every column on upload.</li></ul><p>Well, let's see how we made out!</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-27-at-9.03.51-PM.png\" class=\"kg-image\"><figcaption>A look at our resulting database table.</figcaption></figure><!--kg-card-end: image--><p>Whoaaa nelly, we did it! With our data clean, we can now build something useful! Here's what I built:</p><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://hackersandslackers.com/content/images/2019/03/Screen-Shot-2019-03-27-at-9.29.20-PM.png\" class=\"kg-image\"><figcaption>Fruits of our labor!</figcaption></figure><!--kg-card-end: image--><p>There we have it: a pipeline that takes a bunch of messy data, cleans it, and puts it somewhere else for proper use.</p><p>If you're interested in how we created the frontend for our Kanban board, check out our series on <a href=\"https://hackersandslackers.com/series/graphql-hype/\">building features with GraphQL</a>. For the source code, check out the <a href=\"https://github.com/toddbirchard/jira-database-etl\">Github repository</a>.</p>","url":"https://hackersandslackers.com/building-an-etl-pipeline-from-jira-to-postgresql/","uuid":"23647abe-9b47-4f58-8206-cff1fb2ae891","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c95e08ef654036aa06c6a02"}},{"node":{"id":"Ghost__Post__5c6dd08fa624d869fba41325","title":"Making API Requests With node-fetch","slug":"making-api-requests-with-nodejs","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/02/node-fetch.jpg","excerpt":"Using the lightweight node-fetch library for REST API requests in NodeJS.","custom_excerpt":"Using the lightweight node-fetch library for REST API requests in NodeJS.","created_at_pretty":"20 February, 2019","published_at_pretty":"21 February, 2019","updated_at_pretty":"09 April, 2019","created_at":"2019-02-20T17:11:27.000-05:00","published_at":"2019-02-20T20:22:20.000-05:00","updated_at":"2019-04-08T23:21:34.000-04:00","meta_title":"Making API Requests with node-fetch | Hackers and Slackers","meta_description":"Using the lightweight node-fetch library for REST API requests in NodeJS.","og_description":"Using the lightweight node-fetch library for REST API requests in NodeJS.","og_image":"https://hackersandslackers.com/content/images/2019/02/node-fetch.jpg","og_title":"Making API Requests with node-fetch","twitter_description":"Using the lightweight node-fetch library for REST API requests in NodeJS.","twitter_image":"https://hackersandslackers.com/content/images/2019/02/node-fetch.jpg","twitter_title":"Making API Requests with node-fetch","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NodeJS","slug":"nodejs","description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","feature_image":null,"meta_description":"All things related to backend JavaScript. Learn frameworks or take our word for selecting the right NPM packages.","meta_title":"NodeJS | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"}],"plaintext":"If you're the type of person to read technical Javascript posts in your free\ntime (you are), you don't need me to tell you that JQuery is dead. JQuery\nthemselves have proclaimed JQuery to be dead. The only cool thing about JQuery\nis who can remove it from their legacy stack the fastest, which begs the\nquestion: why is the third most popular page on this site an old post about\nJQuery?\n\nMaintaining a blog of tutorials has taught me a lot about the gap between\nperception and reality. While we content publishers sling Medium posts from our\nivory towers, we quickly create a perception of what \"everybody\" is doing, but\nit turns out \"everybody\" only includes individuals who are exceptionally\nvisible. That demographic makes up significantly less than 10-20% of the active\nworkforce. I would have assumed any post with the word \"React\" would immediately\nexplode, when in reality people are more interested in using Handlebars with\nExpressJS [https://hackersandslackers.com/handlebars-templating-in-expressjs/] \n(I'm not proud of that post by the way, please don't read it).\n\nI want to provide an alternative to using AJAX calls when interacting with REST\nAPIs to clear my conscious of ever enabling bad behavior in the first place.\nHopefully, those who have lost their way might find something to take from it.\nConsidering how deep I've gone down the GraphQL rabbit hole myself, this may be\nthe last chance to bother writing about REST at all.\n\nLibrary of Choice: node-fetch\nLike everything in Javascript, there are way too many packages doing the same\nthing and solving the same problem. Making API requests is no exception. http\n[https://www.npmjs.com/package/http]  is a bit primitive, request\n[https://www.npmjs.com/package/request]  breaks when building with Webpack, r2\n[https://www.npmjs.com/package/r2]  seems like a pointless clone, and so on.\nDon't get me started with async libraries with 40 different methods for chaining\nrequests. Who is gunslinging API requests to the point where we need this many\noptions to pipe or parallel API requests anyway?\n\nAfter using all of these libraries, node-fetch\n[https://www.npmjs.com/package/node-fetch]  is the weapon of choice for today.\nTo put it simply: it's straightforward, and the only one that actually works out\nof the box with Webpack without absurd configuration nonsense. \n\nThe other request library worth mentioning is isomorphic-fetch\n[https://www.npmjs.com/package/isomorphic-fetch], which is intended to be a\ndrop-in replacement for node-fetch. isometric-fetch  mimics the syntax of \nnode-fetch, but impressively works on both  the client and server-side. When\nused on the client side, isomorphicfetch works by first importing the \nes6-promise  polyfill.\n\nGetting Set Up\nStart a Node project and install node-fetch:\n\nnpm install --save node-fetch\n\n\nIn the JS file we'd like to make a request, we can reference node-fetch  using \nrequire():\n\nconst fetch = require('node-fetch');\n\n\nCreating a node-fetch Request\nWe'll start with the most basic GET request possible:\n\nfetch('https://example.com')\n  .then(response => response.json())\n  .then(data => {\n    console.log(data)\n  })\n  .catch(err => ...)\n\n\nIndeed, that's all it takes a base level. Without specifying a method,\nnode-fetch assumes we're making a GET request. From we generate JSON from the\nrequest body and print the result to the console.\n\nChances are you're not going to get much value out of any request without\npassing headers, parameters, or a body to the target endpoint. Here's how we'd\nmake a more complicated (and realistic) POST call:\n\nvar url ='https://example.com';\nvar headers = {\n  \"Content-Type\": \"application/json\",\n  \"client_id\": \"1001125\",\n  \"client_secret\": \"876JHG76UKFJYGVHf867rFUTFGHCJ8JHV\"\n}\nvar data = {\n  \"name\": \"Wade Wilson\",\n  \"occupation\": \"Murderer\",\n  \"age\": \"30 (forever)\"\n}\nfetch(url, { method: 'POST', headers: headers, body: data})\n  .then((res) => {\n     return res.json()\n})\n.then((json) => {\n  console.log(json);\n  // Do something with the returned data.\n});\n\n\nThat's more like it: now we're passing headers and a JSON body. If needed, the \nfetch()  method also accepts a credentials  parameter for authentication.\n\nNote that we are avoiding callback hell by keeping logic that utilizes the\nresponse JSON in our then()  arrow functions. We can chain together as many of\nthese statements as we want.\n\nProperties of a Response\nThe response object contains much more than just the response body JSON:\n\nfetch('https://example.com')\n.then(res => {\n  res.text()       // response body (=> Promise)\n  res.json()       // parse via JSON (=> Promise)\n  res.status       //=> 200\n  res.statusText   //=> 'OK'\n  res.redirected   //=> false\n  res.ok           //=> true\n  res.url          //=> 'https://example.com'\n  res.type         //=> 'basic'\n                   //   ('cors' 'default' 'error'\n                   //    'opaque' 'opaqueredirect')\n\n  res.headers.get('Content-Type')\n})\n\n\nres.status  is particularly handy when building functionality around catching\nerrors:\n\nfetch('https://example.com')\n  .then(reportStatus)\n  \nfunction checkStatus (res) {\n  if (res.status >= 200 && res.status < 300) {\n    return res\n  } else {\n    let err = new Error(res.statusText)\n    err.response = res\n    throw err\n  }\n}\n\n\nMaking Asynchronous Requests\nChances are that when we make an API request, we're planning to do something\nwith the resulting data. Once we start building logic which depends on the\noutcome of a request, this is when we start running into Callback Hell: perhaps\nthe worst  part of JavaScript. In a nutshell, JavaScript will not wait for a\nrequest to execute the next line of code, therefore making a request and\nreferencing it immediately will result in no data returned. We can get around\nthis by using a combination of async  and await.\n\nasync  is a keyword which denotes that a function is to be executed\nasynchronously (as in async function my_func(){...}). await  can be used when\ncalling async  functions to wait on the result of an async function to be\nreturned (ie: const response = await my_func()).\n\nHere's an example of async/await  in action:\n\nconst fetch = require(\"node-fetch\");\n\nconst url = \"https://example.com\";\n\nconst get_data = async url => {\n  try {\n    const response = await fetch(url);\n    const json = await response.json();\n    console.log(json);\n  } catch (error) {\n    console.log(error);\n  }\n};\n\ngetData(url);","html":"<p>If you're the type of person to read technical Javascript posts in your free time (you are), you don't need me to tell you that JQuery is dead. JQuery themselves have proclaimed JQuery to be dead. The only cool thing about JQuery is who can remove it from their legacy stack the fastest, which begs the question: why is the third most popular page on this site an old post about JQuery?</p><p>Maintaining a blog of tutorials has taught me a lot about the gap between perception and reality. While we content publishers sling Medium posts from our ivory towers, we quickly create a perception of what \"everybody\" is doing, but it turns out \"everybody\" only includes individuals who are exceptionally visible. That demographic makes up significantly less than 10-20% of the active workforce. I would have assumed any post with the word \"React\" would immediately explode, when in reality people are more interested in using <a href=\"https://hackersandslackers.com/handlebars-templating-in-expressjs/\">Handlebars with ExpressJS</a> (I'm not proud of that post by the way, please don't read it).</p><p>I want to provide an alternative to using AJAX calls when interacting with REST APIs to clear my conscious of ever enabling bad behavior in the first place. Hopefully, those who have lost their way might find something to take from it. Considering how deep I've gone down the GraphQL rabbit hole myself, this may be the last chance to bother writing about REST at all.</p><h2 id=\"library-of-choice-node-fetch\">Library of Choice: node-fetch</h2><p>Like everything in Javascript, there are way too many packages doing the same thing and solving the same problem. Making API requests is no exception. <strong><a href=\"https://www.npmjs.com/package/http\">http</a> </strong>is a bit primitive, <strong><a href=\"https://www.npmjs.com/package/request\">request</a></strong> breaks when building with Webpack, <strong><a href=\"https://www.npmjs.com/package/r2\">r2</a></strong> seems like a pointless clone, and so on. Don't get me started with async libraries with 40 different methods for chaining requests. Who is gunslinging API requests to the point where we need this many options to pipe or parallel API requests anyway?</p><p>After using all of these libraries, <strong><a href=\"https://www.npmjs.com/package/node-fetch\">node-fetch</a></strong> is the weapon of choice for today. To put it simply: it's straightforward, and the only one that actually works out of the box with Webpack without absurd configuration nonsense. </p><p>The other request library worth mentioning is <strong><a href=\"https://www.npmjs.com/package/isomorphic-fetch\">isomorphic-fetch</a>, </strong>which is intended to be a drop-in replacement for <em>node-fetch</em>. <strong>isometric-fetch</strong> mimics the syntax of <strong>node-fetch</strong>, but impressively works on <em>both</em> the client and server-side. When used on the client side, <em>isomorphicfetch </em>works by first importing the <code>es6-promise</code> polyfill.</p><h3 id=\"getting-set-up\">Getting Set Up</h3><p>Start a Node project and install node-fetch:</p><!--kg-card-begin: markdown--><pre><code class=\"language-shell\">npm install --save node-fetch\n</code></pre>\n<!--kg-card-end: markdown--><p>In the JS file we'd like to make a request, we can reference <strong>node-fetch</strong> using <strong>require():</strong></p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">const fetch = require('node-fetch');\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"creating-a-node-fetch-request\">Creating a node-fetch Request</h2><p>We'll start with the most basic GET request possible:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">fetch('https://example.com')\n  .then(response =&gt; response.json())\n  .then(data =&gt; {\n    console.log(data)\n  })\n  .catch(err =&gt; ...)\n</code></pre>\n<!--kg-card-end: markdown--><p>Indeed, that's all it takes a base level. Without specifying a method, node-fetch assumes we're making a GET request. From we generate JSON from the request body and print the result to the console.</p><p>Chances are you're not going to get much value out of any request without passing headers, parameters, or a body to the target endpoint. Here's how we'd make a more complicated (and realistic) POST call:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">var url ='https://example.com';\nvar headers = {\n  &quot;Content-Type&quot;: &quot;application/json&quot;,\n  &quot;client_id&quot;: &quot;1001125&quot;,\n  &quot;client_secret&quot;: &quot;876JHG76UKFJYGVHf867rFUTFGHCJ8JHV&quot;\n}\nvar data = {\n  &quot;name&quot;: &quot;Wade Wilson&quot;,\n  &quot;occupation&quot;: &quot;Murderer&quot;,\n  &quot;age&quot;: &quot;30 (forever)&quot;\n}\nfetch(url, { method: 'POST', headers: headers, body: data})\n  .then((res) =&gt; {\n     return res.json()\n})\n.then((json) =&gt; {\n  console.log(json);\n  // Do something with the returned data.\n});\n</code></pre>\n<!--kg-card-end: markdown--><p>That's more like it: now we're passing headers and a JSON body. If needed, the <strong>fetch()</strong> method also accepts a <code>credentials</code> parameter for authentication.</p><p>Note that we are avoiding callback hell by keeping logic that utilizes the response JSON in our <strong>then()</strong> arrow functions. We can chain together as many of these statements as we want.</p><h3 id=\"properties-of-a-response\">Properties of a Response</h3><p>The response object contains much more than just the response body JSON:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">fetch('https://example.com')\n.then(res =&gt; {\n  res.text()       // response body (=&gt; Promise)\n  res.json()       // parse via JSON (=&gt; Promise)\n  res.status       //=&gt; 200\n  res.statusText   //=&gt; 'OK'\n  res.redirected   //=&gt; false\n  res.ok           //=&gt; true\n  res.url          //=&gt; 'https://example.com'\n  res.type         //=&gt; 'basic'\n                   //   ('cors' 'default' 'error'\n                   //    'opaque' 'opaqueredirect')\n\n  res.headers.get('Content-Type')\n})\n</code></pre>\n<!--kg-card-end: markdown--><p><code>res.status</code> is particularly handy when building functionality around catching errors:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">fetch('https://example.com')\n  .then(reportStatus)\n  \nfunction checkStatus (res) {\n  if (res.status &gt;= 200 &amp;&amp; res.status &lt; 300) {\n    return res\n  } else {\n    let err = new Error(res.statusText)\n    err.response = res\n    throw err\n  }\n}\n</code></pre>\n<!--kg-card-end: markdown--><h2 id=\"making-asynchronous-requests\">Making Asynchronous Requests</h2><p>Chances are that when we make an API request, we're planning to do something with the resulting data. Once we start building logic which depends on the outcome of a request, this is when we start running into <strong>Callback Hell</strong>: perhaps the <em>worst</em> part of JavaScript. In a nutshell, JavaScript will not wait for a request to execute the next line of code, therefore making a request and referencing it immediately will result in no data returned. We can get around this by using a combination of <strong>async</strong> and <strong>await.</strong></p><p><code>async</code> is a keyword which denotes that a function is to be executed asynchronously (as in <code>async function my_func(){...}</code>). <code>await</code> can be used when calling <code>async</code> functions to wait on the result of an async function to be returned (ie: <code>const response = await my_func()</code>).</p><p>Here's an example of <strong>async/await</strong> in action:</p><!--kg-card-begin: markdown--><pre><code class=\"language-javascript\">const fetch = require(&quot;node-fetch&quot;);\n\nconst url = &quot;https://example.com&quot;;\n\nconst get_data = async url =&gt; {\n  try {\n    const response = await fetch(url);\n    const json = await response.json();\n    console.log(json);\n  } catch (error) {\n    console.log(error);\n  }\n};\n\ngetData(url);\n</code></pre>\n<!--kg-card-end: markdown-->","url":"https://hackersandslackers.com/making-api-requests-with-nodejs/","uuid":"9b46eb2c-0339-44f9-8909-13474dff9377","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c6dd08fa624d869fba41325"}},{"node":{"id":"Ghost__Post__5c3fc99b89c81d4ccc3f64b1","title":"The Hostile Extraction of Tableau Server Data","slug":"hostile-extraction-of-tableau-server-data","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauextraction-1-2.jpg","excerpt":"Say no to proprietary software constraints. Say no to vendor lock. Say yes to freedom.","custom_excerpt":"Say no to proprietary software constraints. Say no to vendor lock. Say yes to freedom.","created_at_pretty":"17 January, 2019","published_at_pretty":"17 January, 2019","updated_at_pretty":"28 March, 2019","created_at":"2019-01-16T19:17:31.000-05:00","published_at":"2019-01-17T07:43:00.000-05:00","updated_at":"2019-03-28T11:06:50.000-04:00","meta_title":"The Hostile Extraction of Tableau Server Data | Hackers and Slackers","meta_description":"How to create a Python application to take back your Tableau data. Say no to proprietary software constraints. Say no to vendor lock. Say yes to freedom.","og_description":"Say no to proprietary software constraints. Say no to vendor lock. Say yes to freedom.","og_image":"https://hackersandslackers.com/content/images/2019/03/tableauextraction-1-2.jpg","og_title":"The Hostile Extraction of Tableau Server Data","twitter_description":"Say no to proprietary software constraints. Say no to vendor lock. Say yes to freedom.","twitter_image":"https://hackersandslackers.com/content/images/2019/03/tableauextraction-1-1.jpg","twitter_title":"The Hostile Extraction of Tableau Server Data","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Hacking Tableau Server","slug":"hacking-tableau-server","description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauseries-2.jpg","meta_description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","meta_title":"Hacking Tableau Server","visibility":"internal"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"}],"plaintext":"I try my best not to hate on Tableau. It was the software’s combination of power\nand ease-of-use that drove me to purchase a license in the first place. Ever\nsince then, I’m finding new and exciting ways Tableau intentionally locks users\nout of their data. \n\nI gave the Tableau Server Client Python library\n[https://tableau.github.io/server-client-python/docs/]  a spin recently in hopes\nof finding something useful. I decided to (sigh, once more) allow Tableau the\nbenefit of the doubt: after pushing four updates in a single month, maybe things\nhad changed. On the contrary, the Tableau business strategy stands strong: to be\na raging, flaming turd pile. A perfect example of this is the View  object\nTableau allows you to interact with on your server. Those familiar know that \nviews  are slang for sheets  of workbooks  stored on Tableau server. \n\nConnecting to your Tableau instance via Python to retrieve your view objects is\na piece of cake:\n\nimport tableauserverclient as TSC\ntableau_auth = TSC.TableauAuth('username', 'password')\nserver = TSC.Server('http://servername')\n\nwith server.auth.sign_in(tableau_auth):\n  all_views, pagination_item = server.views.get()\n  print([view.name for view in all_views])\n\n\nThis simple snippet lists every view object on your server. Wow! Think of what\nwe can do with all that tabular data we worked so hard to transform, rig- WRONG.\nLook at what Tableau's Python 'View Object' actually contains:\n\n * id  The identifier of the view item.\n * name  The name of the view.\n * owner_id  The id for the owner of the view.\n * preview_image  The thumbnail image for the view.\n * total_views  The usage statistics for the view. Indicates the total number of\n   times the view has been accessed.\n * workbook_id  The id of the workbook associated with the view.\n\nHOLY MOSES STOP THE PRESSES, we can get a thumbnail image  of our data?! THANK\nYOU GENEROUS TABLEAU OVERLORDS!\n\nNotice how there's no mention of, you know, the actual data.\n\nWe're going to play a game. In the wake of my time has been wasted, I feel that\nwarm tickling feeling which seems to say \"Viciously dismantle the ambitions of\nan establishment!\"  May I remind you, we're talking about the kind of\nestablishment that bills customer licenses based on the number of CPUs being\nutilized by their server infrastructure.  This is effectively recognizing the\nhorrifying and inefficient codebase behind Tableau server, and leveraging this\nflaw for monetization. Yes, you're paying more money to incentivize worst\npractices.\n\nLet's Make a Flask App. An Angry One.\nIn our last post I shared a little script to help you get started stealing data\n[https://hackersandslackers.com/tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui/] \n off your own Tableau Server. That doesn't quite scratch my itch anymore. I'm\ngoing to build an interface. I want to make it easy as possible for anybody to\nsystemically rob Tableau Server of every penny its got. That's a lot of pennies\nwhen we consider the equation: data = oil + new.\n\nBefore I bore you, here's a quick demo of the MVP we're building:\n\nEach table is a view being pulled from Tableau Server.This POC demonstrates that\nit is very  possible to automate the extraction of Tableau views from Tableau\nServer. The success  message is signaling that we've successfully taken a\nTableau view and created a corresponding table in an external database. Any data\nwe manipulate in Tableau is now truly ours: we can now leverage the transforms\nwe've applied in workbooks, use this data in other applications, and utilize an\nextract scheduler to keep the data coming. We've turned a BI tool into an ETL\ntool. In other words, you can kindly take those thumbnail previews and shove it.\n\nI'll be open sourcing all of this, as is my civic duty. Let us be clear to\nenterprises: withholding freedom to one's own data is an act of war. Pricing\nmodels which reward poor craftsmanship are an insult to our intellect. For every\narrogant atrocity committed against consumers, the war will wage twice as hard.\nI should probably mention these opinions are my own.\n\nThe Proletariat Strikes Back\nGet a feel for where we're heading with the obligatory project-file-structure\ntree:\n\ntableau-exporter\n├── application\n│   ├── __init__.py\n│   ├── database.py\n│   ├── tableau.py\n│   ├── routes.py\n│   ├── static\n│   │   ├── data\n│   │   │   └── view.csv\n│   │   ├── dist\n│   │   │   ├── all.css\n│   │   │   ├── packed.js\n│   │   ├── img\n│   │   │   └── tableaugithub.jpg\n│   │   ├── js\n│   │   │   └── main.js\n│   │   └── scss\n│   │       └── main.scss\n│   └── templates\n│       ├── export.html\n│       ├── index.html\n│       ├── layout.html\n│       └── view.html\n├── config.ini\n├── config.py\n├── app.yaml\n├── start.sh\n├── wsgi.py\n├── Pipfile\n├── README.md\n└── requirements.txt\n\n\nAs usual, we're using a classic Flask application factory  set up here.\n\nWeapons Of Choice\nLet's have a look at our core arsenal:\n\n * requests: We're achieving our goal by exploiting some loopholes exposed in\n   the Tableau REST API.\n * pandas: Will handle everything from extracting comma-separated data into a\n   CSV, render HTML tables, and output SQL.\n * flask_sqlalchemy: Used in tandem with pandas  to handle shipping our data off\n   elsewhere.\n * flask_redis: To handle session variables.\n\nInitiating our Application\nHere's how we construct our app:\n\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_redis import FlaskRedis\n\n# Set global entities\ndb = SQLAlchemy()\nr = FlaskRedis()\n\n\ndef create_app():\n    \"\"\"Construct the core application.\"\"\"\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n\n    with app.app_context():\n        # Initiate globals\n        db.init_app(app)\n        r.init_app(app, charset=\"utf-8\", decode_responses=True)\n\n        # Set global contexts\n        r.set('uri', app.config['SQLALCHEMY_DATABASE_URI'])\n        r.set('baseurl',  app.config['BASE_URL'])\n        r.set('username',  app.config['USERNAME'])\n        r.set('password', app.config['PASSWORD'])\n\n        # Import our modules\n        from . import routes\n        from . import tableau\n        app.register_blueprint(routes.home_blueprint)\n\n        return app\n\n\nThis should all feel like business-as-usual. The core of our application is\nsplit between routes.py, which handles views, and tableau.py, which handles the\nanti-establishment logic. Let's begin with the latter.\n\nLife, Liberty, and The Pursuit of Sick Data Pipelines\nOur good friend tableau.py  might look familiar to those who joined us last time\n[https://hackersandslackers.com/tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui/]\n. tableau.py  has been busy hitting the gym since then and is looking sharp for\nprimetime:\n\nimport requests\nimport xml.etree.ElementTree as ET\nfrom . import r\nimport pandas as pd\nimport io\n\n\nclass ExtractTableauView:\n    \"\"\"Class for working in a Tableau instance.\"\"\"\n\n    __baseurl = r.get('baseurl')\n    __username = r.get('username')\n    __password = r.get('password')\n    __database = r.get('uri')\n    __contenturl = r.get('contenturl')\n\n    @classmethod\n    def get_view(cls, site, xml, view, token):\n        \"\"\"Extract contents of a single view.\"\"\"\n        headers = {'X-Tableau-Auth': token,\n                   'Content-Type': 'text/csv'\n                   }\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + str(site) +'/views/' + str(view) + '/data', headers=headers, stream=True)\n        csv_text = req.text\n        view_df = pd.read_csv(io.StringIO(csv_text), header=0)\n        return view_df\n\n    @classmethod\n    def list_views(cls, site, xml, token):\n        \"\"\"List all views belonging to a Tableau Site.\"\"\"\n        headers = {'X-Tableau-Auth': token}\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + site + '/views', auth=(cls.__username, cls.__password), headers=headers)\n        root = ET.fromstring(req.content)\n        views_arr = []\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}views':\n                for view in child:\n                    view_dict = {\n                        'name': view.attrib.get('name'),\n                        'id': view.attrib.get('id'),\n                        'url': cls.__baseurl + '/' + view.attrib.get('contentUrl'),\n                        'created': view.attrib.get('createdAt'),\n                        'updated': view.attrib.get('updatedAt')\n                    }\n                    views_arr.append(view_dict)\n        return views_arr\n\n    @classmethod\n    def get_token(cls, xml):\n        \"\"\"Receive Auth token to perform API requests.\"\"\"\n        for child in xml.iter('*'):\n            if child.tag == '{http://tableau.com/api}credentials':\n                token = child.attrib.get('token')\n                return token\n\n    @classmethod\n    def get_site(cls, xml):\n        \"\"\"Retrieve ID of Tableau 'site' instance.\"\"\"\n        root = xml\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}site':\n                site = child.attrib.get('id')\n                return site\n\n    @classmethod\n    def initialize_tableau_request(cls):\n        \"\"\"Retrieve core XML for interacting with Tableau.\"\"\"\n        headers = {'Content-Type': 'application/xml'}\n        body = '<tsRequest><credentials name=\"' + cls.__username + '\" password=\"' + cls.__password + '\" ><site contentUrl=\"' + cls.__contenturl + '\" /></credentials></tsRequest>'\n        req = requests.post(cls.__baseurl + '/api/3.2/auth/signin', auth=(cls.__username, cls.__password), headers=headers, data=body)\n        root = ET.fromstring(req.content)\n        return root\n\n\nI wish I could take full credit for what a shit show this class appears to be at\nfirst glance, but I assure you we've been left with no choice. For example: have\nI mentioned that Tableau's REST API returns XML so malformed that it breaks XML\nparsers? I can't tell incompetence from malicious intent at this point.\n\nHere's a method breakdown of our class:\n\n * initialize_tableau_request(): Handles initial auth and returns valuable\n   information such as site ID and API Token to be used thereafter.\n * get_site(): Extracts the site ID from XML returned by the above.\n * get_token(): Similarly extracts our token.\n * list_views(): Compiles a list of all views within a Tableau site, giving us a\n   chance to select ones for extraction.\n * get_view(): Takes a view of our choice and creates a DataFrame, which is to\n   be shipped off to a foreign database.\n\nOur Routing Logic\nMoving on we have routes.py  building the views and associated logic for our\napp:\n\nfrom flask import current_app as app\nfrom flask import render_template, Blueprint, request, Markup\nfrom flask_assets import Bundle, Environment\nfrom . import tableau\nfrom . import database\nimport pandas as pd\n\nhome_blueprint = Blueprint('home', __name__, template_folder='templates', static_folder='static')\n\nassets = Environment(app)\njs = Bundle('js/*.js', filters='jsmin', output='dist/packed.js')\nscss = Bundle('scss/*.scss', filters='libsass', output='dist/all.css')\nassets.register('scss_all', scss)\nassets.register('js_all', js)\nscss.build()\njs.build()\n\n\n@home_blueprint.route('/', methods=['GET', 'POST'])\ndef entry():\n    \"\"\"Homepage which lists all available views.\"\"\"\n    tableau_view_extractor = tableau.ExtractTableauView()\n    xml = tableau_view_extractor.initialize_tableau_request()\n    token = tableau_view_extractor.get_token(xml)\n    site = tableau_view_extractor.get_site(xml)\n    views = tableau_view_extractor.list_views(site, xml, token)\n    return render_template(\n        'index.html',\n        title=\"Here are your views.\",\n        template=\"home-template\",\n        views=views,\n        token=token,\n        xml=xml,\n        site=site\n    )\n\n\n@home_blueprint.route('/view', methods=['GET', 'POST'])\ndef view():\n    \"\"\"Displays a preview of a selected view.\"\"\"\n    site = request.args.get('site')\n    xml = request.args.get('xml')\n    view = request.args.get('view')\n    token = request.args.get('token')\n    tableau_view_extractor = tableau.ExtractTableauView()\n    view_df = tableau_view_extractor.get_view(site, xml, view, token)\n    view_df.to_csv('application/static/data/view.csv')\n    return render_template(\n        'view.html',\n        title='Your View',\n        template=\"home-template\",\n        view=view,\n        token=token,\n        xml=xml,\n        site=site,\n        view_df=Markup(view_df.to_html(index=False))\n    )\n\n\n@home_blueprint.route('/export', methods=['GET', 'POST'])\ndef export():\n    \"\"\"Exports view to external database.\"\"\"\n    view_df = pd.read_csv('application/static/data/view.csv')\n    view_df.to_sql(name='temp', con=database.engine, if_exists='replace', chunksize=50, index=True)\n    return render_template(\n        'export.html',\n        title='Success!',\n        template=\"success-template\",\n    )\n\n\nWe only have 3 pages to our application. They include our list of views, a\npreview of a single view, and a success page for when said view is exported.\nThis is all core Flask logic.\n\nPutting it On Display\nWe build our pages dynamically based on the values we pass our Jinja templates.\nThe homepage utilizes some nested loops to list the views we returned from \ntableau.py, and also makes use of query strings to pass values on to other\ntemplates.\n\n{% extends \"layout.html\" %}\n\n{% block content %}\n<div class=\"extended-container {{template}}\">\n  <div class=\"container\">\n    <div class=\"row\">\n      <div class=\"col s12\">\n        <h1>{{title}}</h1>\n      </div>\n      <div class=\"col s12 flex-container\">\n        {% for view in views %}\n        <div class=\"download\">\n          <a href=\"{{ url_for('home.view') }}?token={{token}}&site={{site}}&view={{view.id}}&xml={{xml}}\">\n            <ul>\n              {% for key, value in view.items() %}\n              <li><span class=\"key {{key}}\">{{key}}</span> {{ value }}</li>\n              {% endfor %}\n            </ul>\n          </a>\n        </div>\n        {% endfor %}\n      </div>\n    </div>\n  </div>\n  {% endblock %}\n\n\nMoving on: our humble view.html  page has two purposes: display the selected\nview, and export it in the name of justice.\n\n{% extends \"layout.html\" %}\n\n{% block content %}\n<div class=\"extended-container {{template}}\">\n  <div class=\"container\">\n    <div class=\"row\">\n      <div class=\"col s12\">\n        <h1>{{title}}</h1>\n        <a href=\"{{ url_for('home.export') }}\" class=\"export\"><i class=\"far fa-file-export\"></i></a>\n        {{view_df}}\n      </div>\n    </div>\n  </div>\n  {% endblock %}\n\n\nThe War is Not Over\nThis repository is open to the public and can be found here\n[https://github.com/toddbirchard/tableau-extraction]. There are still crusades\nleft ahead of us: for instance, building out this interface to accept\ncredentials via login as opposed to a config file, and the scheduling of view\nexports, as opposed to on-demand.\n\nWhere we go from here depends on what we the people decide. For all I know, I\ncould be shouting to an empty room here (I'm almost positive anybody who pays\nfor enterprise software prefers the blind eye of denial). If the opposite holds\ntrue, I dare say the revolution is only getting started.","html":"<p>I try my best not to hate on Tableau. It was the software’s combination of power and ease-of-use that drove me to purchase a license in the first place. Ever since then, I’m finding new and exciting ways Tableau intentionally locks users out of their data. </p><p>I gave the <a href=\"https://tableau.github.io/server-client-python/docs/\"><strong>Tableau Server Client</strong> Python library</a> a spin recently in hopes of finding something useful. I decided to (sigh, <em>once more</em>) allow Tableau the benefit of the doubt: after pushing <strong>four updates in a single month</strong>, maybe things had changed. On the contrary, the Tableau business strategy stands strong: to be a raging, flaming turd pile. A perfect example of this is the <strong>View</strong> object Tableau allows you to interact with on your server. Those familiar know that <strong>views</strong> are slang for <em>sheets</em> of <em>workbooks</em> stored on Tableau server. </p><p>Connecting to your Tableau instance via Python to retrieve your view objects is a piece of cake:</p><pre><code class=\"language-python\">import tableauserverclient as TSC\ntableau_auth = TSC.TableauAuth('username', 'password')\nserver = TSC.Server('http://servername')\n\nwith server.auth.sign_in(tableau_auth):\n  all_views, pagination_item = server.views.get()\n  print([view.name for view in all_views])\n</code></pre>\n<p>This simple snippet lists every view object on your server. Wow! Think of what we can do with all that tabular data we worked so hard to transform, rig- <strong>WRONG</strong>. Look at what Tableau's Python 'View Object' actually contains:</p><ul><li><code>id</code> The identifier of the view item.</li><li><code>name</code> The name of the view.</li><li><code>owner_id</code> The id for the owner of the view.</li><li><code>preview_image</code> The thumbnail image for the view.</li><li><code>total_views</code> The usage statistics for the view. Indicates the total number of times the view has been accessed.</li><li><code>workbook_id</code> The id of the workbook associated with the view.</li></ul><p>HOLY MOSES STOP THE PRESSES, we can get a <strong><em>thumbnail image</em></strong> of our data?! THANK YOU GENEROUS TABLEAU OVERLORDS!</p><p>Notice how there's no mention of, you know, the <em>actual data</em>.</p><p>We're going to play a game. In the wake of my time has been wasted, I feel that warm tickling feeling which seems to say <em>\"Viciously dismantle the ambitions of an establishment!\"</em> May I remind you, we're talking about the kind of establishment that bills customer licenses based on the <strong><em>number of CPUs being utilized by their server infrastructure.</em></strong> This is effectively recognizing the horrifying and inefficient codebase behind Tableau server, and leveraging this flaw for monetization. Yes, you're paying more money to incentivize worst practices.</p><h2 id=\"let-s-make-a-flask-app-an-angry-one-\">Let's Make a Flask App. An Angry One.</h2><p>In our last post I shared <a href=\"https://hackersandslackers.com/tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui/\">a little script to help you get started stealing data</a> off your own Tableau Server. That doesn't quite scratch my itch anymore. I'm going to build an interface. I want to make it easy as possible for anybody to systemically rob Tableau Server of every penny its got. That's a lot of pennies when we consider the equation: <strong>data = oil + new</strong>.</p><p>Before I bore you, here's a quick demo of the MVP we're building:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/tableau.gif\" class=\"kg-image\"><figcaption>Each table is a view being pulled from Tableau Server.</figcaption></figure><p>This POC demonstrates that it is <em>very</em> possible to automate the extraction of Tableau views from Tableau Server. The <em>success</em> message is signaling that we've successfully taken a Tableau view and <strong>created a corresponding table in an external database</strong>. Any data we manipulate in Tableau is now truly ours: we can now leverage the transforms we've applied in workbooks, use this data in other applications, and utilize an extract scheduler to keep the data coming. We've turned a BI tool into an ETL tool. In other words, you can kindly take those thumbnail previews and shove it.</p><p>I'll be open sourcing all of this, as is my civic duty. Let us be clear to enterprises: withholding freedom to one's own data is an act of war. Pricing models which reward poor craftsmanship are an insult to our intellect. For every arrogant atrocity committed against consumers, the war will wage twice as hard. I should probably mention these opinions are my own.</p><h2 id=\"the-proletariat-strikes-back\">The Proletariat Strikes Back</h2><p>Get a feel for where we're heading with the obligatory project-file-structure tree:</p><pre><code class=\"language-bash\">tableau-exporter\n├── application\n│   ├── __init__.py\n│   ├── database.py\n│   ├── tableau.py\n│   ├── routes.py\n│   ├── static\n│   │   ├── data\n│   │   │   └── view.csv\n│   │   ├── dist\n│   │   │   ├── all.css\n│   │   │   ├── packed.js\n│   │   ├── img\n│   │   │   └── tableaugithub.jpg\n│   │   ├── js\n│   │   │   └── main.js\n│   │   └── scss\n│   │       └── main.scss\n│   └── templates\n│       ├── export.html\n│       ├── index.html\n│       ├── layout.html\n│       └── view.html\n├── config.ini\n├── config.py\n├── app.yaml\n├── start.sh\n├── wsgi.py\n├── Pipfile\n├── README.md\n└── requirements.txt\n</code></pre>\n<p>As usual, we're using a classic Flask <em>application factory</em> set up here.</p><h3 id=\"weapons-of-choice\">Weapons Of Choice</h3><p>Let's have a look at our core arsenal:</p><ul><li><code>requests</code>: We're achieving our goal by exploiting some loopholes exposed in the Tableau REST API.</li><li><code>pandas</code>: Will handle everything from extracting comma-separated data into a CSV, render HTML tables, and output SQL.</li><li><code>flask_sqlalchemy</code>: Used in tandem with <em>pandas</em> to handle shipping our data off elsewhere.</li><li><code>flask_redis</code>: To handle session variables.</li></ul><h3 id=\"initiating-our-application\">Initiating our Application</h3><p>Here's how we construct our app:</p><pre><code class=\"language-python\">from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_redis import FlaskRedis\n\n# Set global entities\ndb = SQLAlchemy()\nr = FlaskRedis()\n\n\ndef create_app():\n    &quot;&quot;&quot;Construct the core application.&quot;&quot;&quot;\n    app = Flask(__name__, instance_relative_config=False)\n    app.config.from_object('config.Config')\n\n    with app.app_context():\n        # Initiate globals\n        db.init_app(app)\n        r.init_app(app, charset=&quot;utf-8&quot;, decode_responses=True)\n\n        # Set global contexts\n        r.set('uri', app.config['SQLALCHEMY_DATABASE_URI'])\n        r.set('baseurl',  app.config['BASE_URL'])\n        r.set('username',  app.config['USERNAME'])\n        r.set('password', app.config['PASSWORD'])\n\n        # Import our modules\n        from . import routes\n        from . import tableau\n        app.register_blueprint(routes.home_blueprint)\n\n        return app\n</code></pre>\n<p>This should all feel like business-as-usual. The core of our application is split between <code>routes.py</code>, which handles views, and <code>tableau.py</code>, which handles the anti-establishment logic. Let's begin with the latter.</p><h2 id=\"life-liberty-and-the-pursuit-of-sick-data-pipelines\">Life, Liberty, and The Pursuit of Sick Data Pipelines</h2><p>Our good friend <code>tableau.py</code> might look familiar to those who joined us <a href=\"https://hackersandslackers.com/tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui/\">last time</a>. <code>tableau.py</code> has been busy hitting the gym since then and is looking sharp for primetime:</p><pre><code class=\"language-python\">import requests\nimport xml.etree.ElementTree as ET\nfrom . import r\nimport pandas as pd\nimport io\n\n\nclass ExtractTableauView:\n    &quot;&quot;&quot;Class for working in a Tableau instance.&quot;&quot;&quot;\n\n    __baseurl = r.get('baseurl')\n    __username = r.get('username')\n    __password = r.get('password')\n    __database = r.get('uri')\n    __contenturl = r.get('contenturl')\n\n    @classmethod\n    def get_view(cls, site, xml, view, token):\n        &quot;&quot;&quot;Extract contents of a single view.&quot;&quot;&quot;\n        headers = {'X-Tableau-Auth': token,\n                   'Content-Type': 'text/csv'\n                   }\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + str(site) +'/views/' + str(view) + '/data', headers=headers, stream=True)\n        csv_text = req.text\n        view_df = pd.read_csv(io.StringIO(csv_text), header=0)\n        return view_df\n\n    @classmethod\n    def list_views(cls, site, xml, token):\n        &quot;&quot;&quot;List all views belonging to a Tableau Site.&quot;&quot;&quot;\n        headers = {'X-Tableau-Auth': token}\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + site + '/views', auth=(cls.__username, cls.__password), headers=headers)\n        root = ET.fromstring(req.content)\n        views_arr = []\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}views':\n                for view in child:\n                    view_dict = {\n                        'name': view.attrib.get('name'),\n                        'id': view.attrib.get('id'),\n                        'url': cls.__baseurl + '/' + view.attrib.get('contentUrl'),\n                        'created': view.attrib.get('createdAt'),\n                        'updated': view.attrib.get('updatedAt')\n                    }\n                    views_arr.append(view_dict)\n        return views_arr\n\n    @classmethod\n    def get_token(cls, xml):\n        &quot;&quot;&quot;Receive Auth token to perform API requests.&quot;&quot;&quot;\n        for child in xml.iter('*'):\n            if child.tag == '{http://tableau.com/api}credentials':\n                token = child.attrib.get('token')\n                return token\n\n    @classmethod\n    def get_site(cls, xml):\n        &quot;&quot;&quot;Retrieve ID of Tableau 'site' instance.&quot;&quot;&quot;\n        root = xml\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}site':\n                site = child.attrib.get('id')\n                return site\n\n    @classmethod\n    def initialize_tableau_request(cls):\n        &quot;&quot;&quot;Retrieve core XML for interacting with Tableau.&quot;&quot;&quot;\n        headers = {'Content-Type': 'application/xml'}\n        body = '&lt;tsRequest&gt;&lt;credentials name=&quot;' + cls.__username + '&quot; password=&quot;' + cls.__password + '&quot; &gt;&lt;site contentUrl=&quot;' + cls.__contenturl + '&quot; /&gt;&lt;/credentials&gt;&lt;/tsRequest&gt;'\n        req = requests.post(cls.__baseurl + '/api/3.2/auth/signin', auth=(cls.__username, cls.__password), headers=headers, data=body)\n        root = ET.fromstring(req.content)\n        return root\n</code></pre>\n<p>I wish I could take full credit for what a shit show this class appears to be at first glance, but I assure you we've been left with no choice. For example: have I mentioned that Tableau's REST API returns XML so malformed that it breaks XML parsers? I can't tell incompetence from malicious intent at this point.</p><p>Here's a method breakdown of our class:</p><ul><li><code>initialize_tableau_request()</code>: Handles initial auth and returns valuable information such as site ID and API Token to be used thereafter.</li><li><code>get_site()</code>: Extracts the site ID from XML returned by the above.</li><li><code>get_token()</code>: Similarly extracts our token.</li><li><code>list_views()</code>: Compiles a list of all views within a Tableau site, giving us a chance to select ones for extraction.</li><li><code>get_view()</code>: Takes a view of our choice and creates a DataFrame, which is to be shipped off to a foreign database.</li></ul><h2 id=\"our-routing-logic\">Our Routing Logic</h2><p>Moving on we have <code>routes.py</code> building the views and associated logic for our app:</p><pre><code class=\"language-python\">from flask import current_app as app\nfrom flask import render_template, Blueprint, request, Markup\nfrom flask_assets import Bundle, Environment\nfrom . import tableau\nfrom . import database\nimport pandas as pd\n\nhome_blueprint = Blueprint('home', __name__, template_folder='templates', static_folder='static')\n\nassets = Environment(app)\njs = Bundle('js/*.js', filters='jsmin', output='dist/packed.js')\nscss = Bundle('scss/*.scss', filters='libsass', output='dist/all.css')\nassets.register('scss_all', scss)\nassets.register('js_all', js)\nscss.build()\njs.build()\n\n\n@home_blueprint.route('/', methods=['GET', 'POST'])\ndef entry():\n    &quot;&quot;&quot;Homepage which lists all available views.&quot;&quot;&quot;\n    tableau_view_extractor = tableau.ExtractTableauView()\n    xml = tableau_view_extractor.initialize_tableau_request()\n    token = tableau_view_extractor.get_token(xml)\n    site = tableau_view_extractor.get_site(xml)\n    views = tableau_view_extractor.list_views(site, xml, token)\n    return render_template(\n        'index.html',\n        title=&quot;Here are your views.&quot;,\n        template=&quot;home-template&quot;,\n        views=views,\n        token=token,\n        xml=xml,\n        site=site\n    )\n\n\n@home_blueprint.route('/view', methods=['GET', 'POST'])\ndef view():\n    &quot;&quot;&quot;Displays a preview of a selected view.&quot;&quot;&quot;\n    site = request.args.get('site')\n    xml = request.args.get('xml')\n    view = request.args.get('view')\n    token = request.args.get('token')\n    tableau_view_extractor = tableau.ExtractTableauView()\n    view_df = tableau_view_extractor.get_view(site, xml, view, token)\n    view_df.to_csv('application/static/data/view.csv')\n    return render_template(\n        'view.html',\n        title='Your View',\n        template=&quot;home-template&quot;,\n        view=view,\n        token=token,\n        xml=xml,\n        site=site,\n        view_df=Markup(view_df.to_html(index=False))\n    )\n\n\n@home_blueprint.route('/export', methods=['GET', 'POST'])\ndef export():\n    &quot;&quot;&quot;Exports view to external database.&quot;&quot;&quot;\n    view_df = pd.read_csv('application/static/data/view.csv')\n    view_df.to_sql(name='temp', con=database.engine, if_exists='replace', chunksize=50, index=True)\n    return render_template(\n        'export.html',\n        title='Success!',\n        template=&quot;success-template&quot;,\n    )\n</code></pre>\n<p>We only have 3 pages to our application. They include our list of views, a preview of a single view, and a success page for when said view is exported. This is all core Flask logic.</p><h2 id=\"putting-it-on-display\">Putting it On Display</h2><p>We build our pages dynamically based on the values we pass our Jinja templates. The homepage utilizes some nested loops to list the views we returned from <code>tableau.py</code>, and also makes use of query strings to pass values on to other templates.</p><pre><code class=\"language-html\">{% extends &quot;layout.html&quot; %}\n\n{% block content %}\n&lt;div class=&quot;extended-container {{template}}&quot;&gt;\n  &lt;div class=&quot;container&quot;&gt;\n    &lt;div class=&quot;row&quot;&gt;\n      &lt;div class=&quot;col s12&quot;&gt;\n        &lt;h1&gt;{{title}}&lt;/h1&gt;\n      &lt;/div&gt;\n      &lt;div class=&quot;col s12 flex-container&quot;&gt;\n        {% for view in views %}\n        &lt;div class=&quot;download&quot;&gt;\n          &lt;a href=&quot;{{ url_for('home.view') }}?token={{token}}&amp;site={{site}}&amp;view={{view.id}}&amp;xml={{xml}}&quot;&gt;\n            &lt;ul&gt;\n              {% for key, value in view.items() %}\n              &lt;li&gt;&lt;span class=&quot;key {{key}}&quot;&gt;{{key}}&lt;/span&gt; {{ value }}&lt;/li&gt;\n              {% endfor %}\n            &lt;/ul&gt;\n          &lt;/a&gt;\n        &lt;/div&gt;\n        {% endfor %}\n      &lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n  {% endblock %}\n</code></pre>\n<p>Moving on: our humble <code>view.html</code> page has two purposes: display the selected view, and export it in the name of justice.</p><pre><code class=\"language-html\">{% extends &quot;layout.html&quot; %}\n\n{% block content %}\n&lt;div class=&quot;extended-container {{template}}&quot;&gt;\n  &lt;div class=&quot;container&quot;&gt;\n    &lt;div class=&quot;row&quot;&gt;\n      &lt;div class=&quot;col s12&quot;&gt;\n        &lt;h1&gt;{{title}}&lt;/h1&gt;\n        &lt;a href=&quot;{{ url_for('home.export') }}&quot; class=&quot;export&quot;&gt;&lt;i class=&quot;far fa-file-export&quot;&gt;&lt;/i&gt;&lt;/a&gt;\n        {{view_df}}\n      &lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n  {% endblock %}\n</code></pre>\n<h2 id=\"the-war-is-not-over\">The War is Not Over</h2><p>This repository is open to the public and can be found <a href=\"https://github.com/toddbirchard/tableau-extraction\">here</a>. There are still crusades left ahead of us: for instance, building out this interface to accept credentials via login as opposed to a config file, and the scheduling of view exports, as opposed to on-demand.</p><p>Where we go from here depends on what we the people decide. For all I know, I could be shouting to an empty room here (I'm almost positive anybody who pays for enterprise software prefers the blind eye of denial). If the opposite holds true, I dare say the revolution is only getting started.</p>","url":"https://hackersandslackers.com/hostile-extraction-of-tableau-server-data/","uuid":"23914fde-b90e-4496-9a7d-56d6ae3765d9","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5c3fc99b89c81d4ccc3f64b1"}},{"node":{"id":"Ghost__Post__5c27630bda392c696eab97de","title":"Tableau's REST API: Turning Tableau into an ETL Pipeline GUI","slug":"tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/hacktaleau-4@2x.jpg","excerpt":"Organizing a heist on Tableau Server to reclaim workbook data.","custom_excerpt":"Organizing a heist on Tableau Server to reclaim workbook data.","created_at_pretty":"29 December, 2018","published_at_pretty":"29 December, 2018","updated_at_pretty":"13 March, 2019","created_at":"2018-12-29T07:05:31.000-05:00","published_at":"2018-12-29T07:18:53.000-05:00","updated_at":"2019-03-13T05:53:25.000-04:00","meta_title":"Tableau's View Extraction REST API | Hackers and Slackers","meta_description":"Our siege on Tableau Server continues as we organize a heist to reclaim our workbook data","og_description":"Our siege on Tableau Server continues as we organize a heist to reclaim our workbook data","og_image":"https://hackersandslackers.com/content/images/2018/12/hacktaleau-4@2x.jpg","og_title":"Tableau's REST API: Turning Tableau into an ETL Pipeline GUI","twitter_description":"Our siege on Tableau Server continues as we organize a heist to reclaim our workbook data","twitter_image":"https://hackersandslackers.com/content/images/2018/12/hacktaleau-4@2x.jpg","twitter_title":"Tableau's REST API: Turning Tableau into an ETL Pipeline GUI","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Hacking Tableau Server","slug":"hacking-tableau-server","description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauseries-2.jpg","meta_description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","meta_title":"Hacking Tableau Server","visibility":"internal"}],"plaintext":"There's nothing I love more than exposing expensive enterprise software. \n\nIt may not seem obvious, but most SaaS products have an underlying core goal:\nshackle businesses to depend on proprietary, closed-source, costly software.\nWhen you pair a surplus of money with a reluctance to work, you've arrived at\nCorporate America: a prime victim yearning to marry itself to any vendor with a\nnice pitch deck and a vague promise.\n\nIn the case of Tableau, this becomes obvious when you attempt to do anything\nbesides create visuals. I don't like spending hours of my time cleaning data to\nbe rewarded with a shitty iframe embed: I want my data. As we've already seen by\nexposing Tableau's hidden Superadmin access\n[\thttps://hackersandslackers.com/hacking-linux-tableu-server/], it's pretty\nclear Tableau doesn't want you to do this. \n\nI realize Tableau is a BI tool, and some might argue we're barking up the wrong\ntree, and all data should be clean before reaching Tableau. My sentiment is\nthis: fuck that. If a single license costs one thousand dollars, and we have the\npower to manipulate data faster  as we visualize it, we should at least be able\nto own  that data: and by \"own,\" I don't mean a CSV export. I want it in my own \ndatabase of choice, not a locked down and hidden Postgres database living on a\nVPS filled with Tableau stuff.\n\nHere's how we'd do that.\n\n\"You Expect us to Just Walk out the Casino with Millions of Dollars on us?\"\nYou're looking at a Boeski, a Jim Brown, a Miss Daisy, two Jethros and a Leon\nSpinks, not to mention the biggest Ella Fitzgerald ever.You're here because\nyou're the best of the best. If you're feeling scared, feel free to back out\nnow.\n\nThis tutorial assumes you have a Tableau Server instance, with a workbook\npublished to a site within said instance. We're going to take a page out of that\nworkbook and turn the raw data into a database table. FAIR  WARNING: We're about\nto dive deep into the obscure world of the Tableau Server REST API\n[https://onlinehelp.tableau.com/current/api/rest_api/en-us/REST/rest_api_ref.htm]\n. It's clunky, it's ugly, and it returns XML. Strap yourself in. \n\nWe're going to be working with 3 core endpoints. Let's walk through them, and\nI'll show you how to exploit said endpoints to create a ruthless data mining\nmachine in Python.\n\n'Tableau Authorization' Endpoint\nLike all obnoxious (aka useful) APIs, we need to authorize each API call with a\ntemporary token. Of course, we'll just have Python generate said token for every\ncall we make.\n\nPOST: http://[MyTaleauServerURL]/api/3.0/auth/signin\n\nHitting this endpoint successfully will result in an XML response (ugh). The\nresponse should look something like this:\n\n<?xml version='1.0' encoding='UTF-8'?>\n<tsResponse xmlns=\"http://tableau.com/api\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd\">\n    <credentials token=\"KBIuvu6FTViuyivuTUR^yfvgTUycvjGubgc\">\n        <site id=\"09Hiugv-345-45d0-b48b-34543giuyvg\" contentUrl=\"hackers\"/>\n        <user id=\"Uohiiyu-3455-8675-9b42-bugvdr876gv\"/>\n    </credentials>\n</tsResponse>\n\n\nThere are a number of things going on here that we should take note of. The\nfirst being a marvel of modern technology: this is perhaps the shittiest\nresponse to a token API call in modern history. Other than that, we need two\nthings from this response:\n\n * The token  is required for every API call from here on out. It is intended to\n   be passed as a header value with the key X-Tableau-Auth.\n * The site ID  is what we'll be using to look up the location of our workbooks\n   in our server instance. This is added to the URL of future API calls (again,\n   impressively shitty design here).\n\n'List All Views by Site' Endpoint\nThere are actually a number of methods we could use to retrieve views, but we're\nspecifically settling on listing our views by 'site,' in the Tableau sense of\nthe word. If you're unfamiliar, a Tableau site  is not a site at all: it's more\nof project within a greater Tableau instance. They probably should've named them\nthat.\n\nGET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views\n\nAs mentioned, we use the site ID  from step 1 to construct this endpoint. In my\nparticular instance, I've only saved a single workbook for simplicity's sake.\nThe response for such a case is as follows:\n\n<?xml version='1.0' encoding='UTF-8'?>\n<tsResponse xmlns=\"http://tableau.com/api\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd\">\n    <pagination pageNumber=\"1\" pageSize=\"100\" totalAvailable=\"1\"/>\n    <views>\n        <view id=\"9a4a1de9-b7af-4a4a-8556-fd5ac82f92bd\" name=\"Jira\" contentUrl=\"JiraIssues/sheets/Jira\" createdAt=\"2018-12-21T09:11:39Z\" updatedAt=\"2018-12-21T09:11:39Z\">\n            <workbook id=\"208a0c4e-e1d9-4852-9d19-7a2fe2717191\"/>\n            <owner id=\"Uohiiyu-3455-8675-9b42-bugvdr876gv\"/>\n            <project id=\"4d1ca337-20b4-442c-aa7b-1dfd470b68bd\"/>\n            <tags/>\n        </view>\n    </views>\n</tsResponse>\n\n\nCheck out the views  node: when we make this API call, <views>  will contain a\nlist of every view saved to the specified site. Keep in mind that a view is\nequivalent to a \"sheet\" of a workbook: in almost any case, you will have many\nviews listed here. \n\nMy sheet happens to be called \"Jira,\" as stated by name=\"Jira\". The thing we\nreally need however is the view id attribute: this will be used in our third and\nfinal API call.\n\n'Get View Data' Endpoint\nNow let's get the raw data from a view of our choice.\n\nGET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views/[MyViewID]/data\n\n\nHere's where we hit pay dirt. This request will result in an output of\ncomma-separated values; I don't need to tell you what we can do with\ncomma-separated values. Here's what my response looks like after formatting it\nas a table:\n\nCurrent AssigneeCurrent StatusDay of Updatedepic_colorepic_nameIssue Type\nissuetype_colorissuetype_urlkeyPriorityprojectsummaryTodd BirchardDoneJune 7,\n2018#42526EWidgetsBug#db5d5dhttps://hackers.nyc3.digitaloceanspaces.com/bug.png\nHACK-96LowestHackers and Slackers\"Recent Posts\" widget does not have link\nrolloverTodd BirchardBacklogJune 15, 2018#57D9A3Page TemplatesTask#73B0E1\nhttps://hackers.nyc3.digitaloceanspaces.com/task.pngHACK-32LowestHackers and\nSlackers“Join” pageTodd BirchardDoneNovember 13, 2018#42526EWidgetsTask#73B0E1\nhttps://hackers.nyc3.digitaloceanspaces.com/task.pngHACK-543MediumHackers and\nSlackersAdd “pro tip” boxTodd BirchardTo DoDecember 14, 2018#679EEFSEOMajor\nFunctionality#93d171https://hackers.nyc3.digitaloceanspaces.com/story.png\nHACK-656LowHackers and SlackersAdd alt attributes to images vis clarifai Todd\nBirchardBacklogOctober 16, 2018#FDDA3EAccountsMajor Functionality#93d171\nhttps://hackers.nyc3.digitaloceanspaces.com/story.pngHACK-473MediumHackers and\nSlackersAdd avatar selection to signupTodd BirchardDoneNovember 13, 2018#57D9A3\nPage TemplatesSub-task#92BFE5\nhttps://hackers.nyc3.digitaloceanspaces.com/subtask.pngHACK-231MediumHackers and\nSlackersAdd blurb to each post page explaining what these areTodd BirchardDone\nDecember 10, 2018#291BA9Code snippetsTask#73B0E1\nhttps://hackers.nyc3.digitaloceanspaces.com/task.pngHACK-452MediumHackers and\nSlackersAdd color styles for json snippetsThat's right, a table.  Databases are comprised of tables. Perhaps you see where\nI'm going with this.\n\n\"There's a Ninety-five Pound Chinese Man with a Hundred Sixty Million Dollars\nBehind this Door.\"\nLet's get him out.We've got the goods, but calling all these individual\nendpoints manually does nothing for us. We don't want to steal a single view, we\nwant to systematically rob Tableau of it's views on a scheduler and Shanghai\nthem off to a database of our choosing.\n\nIt would be a crime not to automate this, so I've created a class containing all\nthe relevant methods we'd want when it comes to interacting with Tableau's REST\nAPI:\n\nimport requests\nimport xml.etree.ElementTree as ET\nfrom . import r\nimport pandas as pd\nimport io\n\n\nclass ExtractTableauView:\n    \"\"\"Class for with the Tableau server API.\"\"\"\n\n    __baseurl = r.get('baseurl')\n    __username = r.get('username')\n    __password = r.get('password')\n    __database = r.get('uri')\n    __contenturl = r.get('contenturl')\n\n    @classmethod\n    def get_view(cls, site, xml, view, token):\n        \"\"\"Extract contents of a single view.\"\"\"\n        headers = {'X-Tableau-Auth': token,\n                   'Content-Type': 'text/csv'\n                   }\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + str(site) +'/views/' + str(view) + '/data', headers=headers, stream=True)\n        csv_text = req.text\n        view_df = pd.read_csv(io.StringIO(csv_text), header=0)\n        return view_df\n\n    @classmethod\n    def list_views(cls, site, xml, token):\n        \"\"\"List all views belonging to a Tableau Site.\"\"\"\n        headers = {'X-Tableau-Auth': token}\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + site + '/views', auth=(cls.__username, cls.__password), headers=headers)\n        root = ET.fromstring(req.content)\n        views_arr = []\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}views':\n                for view in child:\n                    view_dict = {\n                        'name': view.attrib.get('name'),\n                        'id': view.attrib.get('id'),\n                        'url': cls.__baseurl + '/' + view.attrib.get('contentUrl'),\n                        'created': view.attrib.get('createdAt'),\n                        'updated': view.attrib.get('updatedAt')\n                    }\n                    views_arr.append(view_dict)\n        return views_arr\n\n    @classmethod\n    def get_token(cls, xml):\n        \"\"\"Receive Auth token to perform API requests.\"\"\"\n        for child in xml.iter('*'):\n            if child.tag == '{http://tableau.com/api}credentials':\n                token = child.attrib.get('token')\n                return token\n\n    @classmethod\n    def get_site(cls, xml):\n        \"\"\"Retrieve ID of Tableau 'site' instance.\"\"\"\n        root = xml\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}site':\n                site = child.attrib.get('id')\n                return site\n\n    @classmethod\n    def initialize_tableau_request(cls):\n        \"\"\"Retrieve core XML for interacting with Tableau.\"\"\"\n        headers = {'Content-Type': 'application/xml'}\n        body = '<tsRequest><credentials name=\"' + cls.__username + '\" password=\"' + cls.__password + '\" ><site contentUrl=\"' + cls.__contenturl + '\" /></credentials></tsRequest>'\n        req = requests.post(cls.__baseurl + '/api/3.2/auth/signin', auth=(cls.__username, cls.__password), headers=headers, data=body)\n        root = ET.fromstring(req.content)\n        return root\n\n\nThe above snippet is a Python class utilizing all the API endpoints we explored\nin a mostly effortless manner. Instantiating the class immediately covers the\ngrunt work of:\n\n *   Generating a token\n * Getting your (unfriendly) site ID\n * Listing all views belonging to the provided site\n * Retrieving data from a worksheet of choice\n\nGet a list of views in your Tableau site by using the list_views()  method. When\nyou see the view you want, pass the view ID  to the .get_view()  method. This\nwill result in response of all raw data in the view in the form of a CSV. \n\nHow to Pull a Heist (Final Chapter): Storing in Offshore Accounts\nTo earn your title as a true con artist, I'm leaving the final step up to you.\nYou've escaped with the loot, but you'll need to put all that data somewhere.\nThis should be a trivial matter of automating a simple database query, but the\nspecifics are up to you.\n\nIf you're ready to liberate your data, feel free to grab the source off of\nGithub [https://gist.github.com/toddbirchard/ad1386b4334e7b22b2f7b38edca3bd5c] \nand go nuts.","html":"<p>There's nothing I love more than exposing expensive enterprise software. </p><p>It may not seem obvious, but most SaaS products have an underlying core goal: shackle businesses to depend on proprietary, closed-source, costly software. When you pair a surplus of money with a reluctance to work, you've arrived at Corporate America: a prime victim yearning to marry itself to any vendor with a nice pitch deck and a vague promise.</p><p>In the case of Tableau, this becomes obvious when you attempt to do anything besides create visuals. I don't like spending hours of my time cleaning data to be rewarded with a shitty iframe embed: I want my <em>data</em>. As we've already seen by exposing Tableau's hidden <a href=\"\thttps://hackersandslackers.com/hacking-linux-tableu-server/\">Superadmin access</a>, it's pretty clear Tableau doesn't want you to do this. </p><p>I realize Tableau is a BI tool, and some might argue we're barking up the wrong tree, and all data should be clean before reaching Tableau. My sentiment is this: <em>fuck that</em>. If a single license costs <em><strong>one thousand dollars</strong></em>, and we have the power to manipulate data <em>faster</em> as we visualize it, we should at least be able to <em>own</em> that data: and by \"own,\" I don't mean a CSV export. I want it in my <em>own</em> database of choice, not a locked down and hidden Postgres database living on a VPS filled with Tableau stuff.</p><p>Here's how we'd do that.</p><h2 id=\"you-expect-us-to-just-walk-out-the-casino-with-millions-of-dollars-on-us\">\"You Expect us to Just Walk out the Casino with Millions of Dollars on us?\"</h2><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/oceans.gif\" class=\"kg-image\"><figcaption>You're looking at a Boeski, a Jim Brown, a Miss Daisy, two Jethros and a Leon Spinks, not to mention the biggest Ella Fitzgerald ever.</figcaption></figure><!--kg-card-end: image--><p>You're here because you're the best of the best. If you're feeling scared, feel free to back out now.</p><p>This tutorial assumes you have a Tableau Server instance, with a workbook published to a site within said instance. We're going to take a page out of that workbook and turn the raw data into a database table. <strong>FAIR</strong> <strong>WARNING</strong>: We're about to dive deep into the obscure world of the <a href=\"https://onlinehelp.tableau.com/current/api/rest_api/en-us/REST/rest_api_ref.htm\">Tableau Server REST API</a>. It's clunky, it's ugly, and it returns XML. Strap yourself in. </p><p>We're going to be working with 3 core endpoints. Let's walk through them, and I'll show you how to exploit said endpoints to create a ruthless data mining machine in Python.</p><h3 id=\"-tableau-authorization-endpoint\">'Tableau Authorization' Endpoint</h3><p>Like all obnoxious (aka useful) APIs, we need to authorize each API call with a temporary token. Of course, we'll just have Python generate said token for every call we make.</p><!--kg-card-begin: code--><pre><code>POST: http://[MyTaleauServerURL]/api/3.0/auth/signin</code></pre><!--kg-card-end: code--><p>Hitting this endpoint successfully will result in an XML response (ugh). The response should look something like this:</p><!--kg-card-begin: markdown--><pre><code class=\"language-xml\">&lt;?xml version='1.0' encoding='UTF-8'?&gt;\n&lt;tsResponse xmlns=&quot;http://tableau.com/api&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd&quot;&gt;\n    &lt;credentials token=&quot;KBIuvu6FTViuyivuTUR^yfvgTUycvjGubgc&quot;&gt;\n        &lt;site id=&quot;09Hiugv-345-45d0-b48b-34543giuyvg&quot; contentUrl=&quot;hackers&quot;/&gt;\n        &lt;user id=&quot;Uohiiyu-3455-8675-9b42-bugvdr876gv&quot;/&gt;\n    &lt;/credentials&gt;\n&lt;/tsResponse&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>There are a number of things going on here that we should take note of. The first being a marvel of modern technology: this is perhaps the shittiest response to a token API call in modern history. Other than that, we need two things from this response:</p><ul><li>The <strong>token</strong> is required for every API call from here on out. It is intended to be passed as a header value with the key <code>X-Tableau-Auth</code>.</li><li>The <strong>site ID</strong> is what we'll be using to look up the location of our workbooks in our server instance. This is added to the URL of future API calls (again, impressively shitty design here).</li></ul><h3 id=\"-list-all-views-by-site-endpoint\">'List All Views by Site' Endpoint</h3><p>There are actually a number of methods we could use to retrieve views, but we're specifically settling on listing our views by '<em>site,' </em>in the Tableau sense of the word<em>. </em>If you're unfamiliar, a Tableau <em>site</em> is not a site at all: it's more of project within a greater Tableau instance. They probably should've named them that.</p><!--kg-card-begin: code--><pre><code>GET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views</code></pre><!--kg-card-end: code--><p>As mentioned, we use the <strong>site ID</strong> from step 1 to construct this endpoint. In my particular instance, I've only saved a single workbook for simplicity's sake. The response for such a case is as follows:</p><!--kg-card-begin: markdown--><pre><code class=\"language-xml\">&lt;?xml version='1.0' encoding='UTF-8'?&gt;\n&lt;tsResponse xmlns=&quot;http://tableau.com/api&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tableau.com/api http://tableau.com/api/ts-api-3.0.xsd&quot;&gt;\n    &lt;pagination pageNumber=&quot;1&quot; pageSize=&quot;100&quot; totalAvailable=&quot;1&quot;/&gt;\n    &lt;views&gt;\n        &lt;view id=&quot;9a4a1de9-b7af-4a4a-8556-fd5ac82f92bd&quot; name=&quot;Jira&quot; contentUrl=&quot;JiraIssues/sheets/Jira&quot; createdAt=&quot;2018-12-21T09:11:39Z&quot; updatedAt=&quot;2018-12-21T09:11:39Z&quot;&gt;\n            &lt;workbook id=&quot;208a0c4e-e1d9-4852-9d19-7a2fe2717191&quot;/&gt;\n            &lt;owner id=&quot;Uohiiyu-3455-8675-9b42-bugvdr876gv&quot;/&gt;\n            &lt;project id=&quot;4d1ca337-20b4-442c-aa7b-1dfd470b68bd&quot;/&gt;\n            &lt;tags/&gt;\n        &lt;/view&gt;\n    &lt;/views&gt;\n&lt;/tsResponse&gt;\n</code></pre>\n<!--kg-card-end: markdown--><p>Check out the <strong>views</strong> node: when we make this API call, <code>&lt;views&gt;</code> will contain a list of every view saved to the specified site. Keep in mind that a view is equivalent to a \"sheet\" of a workbook: in almost any case, you will have many views listed here. </p><p>My sheet happens to be called \"Jira,\" as stated by <code>name=\"Jira\"</code>. The thing we really need however is the <strong>view id </strong>attribute: this will be used in our third and final API call.</p><h3 id=\"-get-view-data-endpoint\">'Get View Data' Endpoint</h3><p>Now let's get the raw data from a view of our choice.</p><!--kg-card-begin: code--><pre><code>GET: http://[MyTaleauServerURL]/api/3.0/sites/[MySiteID]/views/[MyViewID]/data\n</code></pre><!--kg-card-end: code--><p>Here's where we hit pay dirt. This request will result in an output of comma-separated values; I don't need to tell you what we can do with comma-separated values. Here's what my response looks like after formatting it as a table:</p><!--kg-card-begin: html--><div class=\"tableContainer\">\n<table class=\"table table-bordered table-hover table-condensed\">\n<thead><tr><th title=\"Field #1\">Current Assignee</th>\n<th title=\"Field #2\">Current Status</th>\n<th title=\"Field #3\">Day of Updated</th>\n<th title=\"Field #4\">epic_color</th>\n<th title=\"Field #5\">epic_name</th>\n<th title=\"Field #6\">Issue Type</th>\n<th title=\"Field #7\">issuetype_color</th>\n<th title=\"Field #8\">issuetype_url</th>\n<th title=\"Field #9\">key</th>\n<th title=\"Field #10\">Priority</th>\n<th title=\"Field #11\">project</th>\n<th title=\"Field #12\">summary</th>\n</tr></thead>\n<tbody><tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>June 7, 2018</td>\n<td>#42526E</td>\n<td>Widgets</td>\n<td>Bug</td>\n<td>#db5d5d</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/bug.png</td>\n<td>HACK-96</td>\n<td>Lowest</td>\n<td>Hackers and Slackers</td>\n<td>&quot;Recent Posts&quot; widget does not have link rollover</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Backlog</td>\n<td>June 15, 2018</td>\n<td>#57D9A3</td>\n<td>Page Templates</td>\n<td>Task</td>\n<td>#73B0E1</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/task.png</td>\n<td>HACK-32</td>\n<td>Lowest</td>\n<td>Hackers and Slackers</td>\n<td>“Join” page</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>November 13, 2018</td>\n<td>#42526E</td>\n<td>Widgets</td>\n<td>Task</td>\n<td>#73B0E1</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/task.png</td>\n<td>HACK-543</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add “pro tip” box</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>To Do</td>\n<td>December 14, 2018</td>\n<td>#679EEF</td>\n<td>SEO</td>\n<td>Major Functionality</td>\n<td>#93d171</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/story.png</td>\n<td>HACK-656</td>\n<td>Low</td>\n<td>Hackers and Slackers</td>\n<td>Add alt attributes to images vis clarifai </td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Backlog</td>\n<td>October 16, 2018</td>\n<td>#FDDA3E</td>\n<td>Accounts</td>\n<td>Major Functionality</td>\n<td>#93d171</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/story.png</td>\n<td>HACK-473</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add avatar selection to signup</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>November 13, 2018</td>\n<td>#57D9A3</td>\n<td>Page Templates</td>\n<td>Sub-task</td>\n<td>#92BFE5</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/subtask.png</td>\n<td>HACK-231</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add blurb to each post page explaining what these are</td>\n</tr>\n<tr>\n<td>Todd Birchard</td>\n<td>Done</td>\n<td>December 10, 2018</td>\n<td>#291BA9</td>\n<td>Code snippets</td>\n<td>Task</td>\n<td>#73B0E1</td>\n<td>https://hackers.nyc3.digitaloceanspaces.com/task.png</td>\n<td>HACK-452</td>\n<td>Medium</td>\n<td>Hackers and Slackers</td>\n<td>Add color styles for json snippets</td>\n</tr>\n</tbody></table>\n</div><!--kg-card-end: html--><p>That's right, a <em>table.</em> Databases are comprised of tables. Perhaps you see where I'm going with this.</p><h2 id=\"there-s-a-ninety-five-pound-chinese-man-with-a-hundred-sixty-million-dollars-behind-this-door-\">\"There's a Ninety-five Pound Chinese Man with a Hundred Sixty Million Dollars Behind this Door.\"</h2><!--kg-card-begin: image--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/1379892761308689767.jpg\" class=\"kg-image\"><figcaption>Let's get him out.</figcaption></figure><!--kg-card-end: image--><p>We've got the goods, but calling all these individual endpoints manually does nothing for us. We don't want to steal a single view, we want to systematically rob Tableau of it's views on a scheduler and Shanghai them off to a database of our choosing.</p><p>It would be a crime not to automate this, so I've created a class containing all the relevant methods we'd want when it comes to interacting with Tableau's REST API:</p><!--kg-card-begin: markdown--><pre><code class=\"language-python\">import requests\nimport xml.etree.ElementTree as ET\nfrom . import r\nimport pandas as pd\nimport io\n\n\nclass ExtractTableauView:\n    &quot;&quot;&quot;Class for with the Tableau server API.&quot;&quot;&quot;\n\n    __baseurl = r.get('baseurl')\n    __username = r.get('username')\n    __password = r.get('password')\n    __database = r.get('uri')\n    __contenturl = r.get('contenturl')\n\n    @classmethod\n    def get_view(cls, site, xml, view, token):\n        &quot;&quot;&quot;Extract contents of a single view.&quot;&quot;&quot;\n        headers = {'X-Tableau-Auth': token,\n                   'Content-Type': 'text/csv'\n                   }\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + str(site) +'/views/' + str(view) + '/data', headers=headers, stream=True)\n        csv_text = req.text\n        view_df = pd.read_csv(io.StringIO(csv_text), header=0)\n        return view_df\n\n    @classmethod\n    def list_views(cls, site, xml, token):\n        &quot;&quot;&quot;List all views belonging to a Tableau Site.&quot;&quot;&quot;\n        headers = {'X-Tableau-Auth': token}\n        req = requests.get(cls.__baseurl + '/api/3.2/sites/' + site + '/views', auth=(cls.__username, cls.__password), headers=headers)\n        root = ET.fromstring(req.content)\n        views_arr = []\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}views':\n                for view in child:\n                    view_dict = {\n                        'name': view.attrib.get('name'),\n                        'id': view.attrib.get('id'),\n                        'url': cls.__baseurl + '/' + view.attrib.get('contentUrl'),\n                        'created': view.attrib.get('createdAt'),\n                        'updated': view.attrib.get('updatedAt')\n                    }\n                    views_arr.append(view_dict)\n        return views_arr\n\n    @classmethod\n    def get_token(cls, xml):\n        &quot;&quot;&quot;Receive Auth token to perform API requests.&quot;&quot;&quot;\n        for child in xml.iter('*'):\n            if child.tag == '{http://tableau.com/api}credentials':\n                token = child.attrib.get('token')\n                return token\n\n    @classmethod\n    def get_site(cls, xml):\n        &quot;&quot;&quot;Retrieve ID of Tableau 'site' instance.&quot;&quot;&quot;\n        root = xml\n        for child in root.iter('*'):\n            if child.tag == '{http://tableau.com/api}site':\n                site = child.attrib.get('id')\n                return site\n\n    @classmethod\n    def initialize_tableau_request(cls):\n        &quot;&quot;&quot;Retrieve core XML for interacting with Tableau.&quot;&quot;&quot;\n        headers = {'Content-Type': 'application/xml'}\n        body = '&lt;tsRequest&gt;&lt;credentials name=&quot;' + cls.__username + '&quot; password=&quot;' + cls.__password + '&quot; &gt;&lt;site contentUrl=&quot;' + cls.__contenturl + '&quot; /&gt;&lt;/credentials&gt;&lt;/tsRequest&gt;'\n        req = requests.post(cls.__baseurl + '/api/3.2/auth/signin', auth=(cls.__username, cls.__password), headers=headers, data=body)\n        root = ET.fromstring(req.content)\n        return root\n</code></pre>\n<!--kg-card-end: markdown--><p>The above snippet is a Python class utilizing all the API endpoints we explored in a mostly effortless manner. Instantiating the class immediately covers the grunt work of:</p><ul><li> Generating a token</li><li>Getting your (unfriendly) site ID</li><li>Listing all views belonging to the provided site</li><li>Retrieving data from a worksheet of choice</li></ul><p>Get a list of views in your Tableau site by using the <code>list_views()</code> method. When you see the view you want, pass the <strong>view ID</strong> to the <code>.get_view()</code> method. This will result in response of all raw data in the view in the form of a CSV. </p><h3 id=\"how-to-pull-a-heist-final-chapter-storing-in-offshore-accounts\">How to Pull a Heist (Final Chapter): Storing in Offshore Accounts</h3><p>To earn your title as a true con artist, I'm leaving the final step up to you. You've escaped with the loot, but you'll need to put all that data somewhere. This should be a trivial matter of automating a simple database query, but the specifics are up to you.</p><p>If you're ready to liberate your data, feel free to <a href=\"https://gist.github.com/toddbirchard/ad1386b4334e7b22b2f7b38edca3bd5c\">grab the source off of Github</a> and go nuts.</p>","url":"https://hackersandslackers.com/tableaus-rest-api-turning-tableau-into-an-etl-pipeline-gui/","uuid":"77d21a34-e5c1-4582-aade-ff92d8596387","page":false,"codeinjection_foot":null,"codeinjection_head":"<style>\n  .post-template .post-content img {\n    width: 100% !important;\n  }\n\n  figcaption {\n    width: -webkit-fill-available !important;\n    width: -moz-available !important;\n    margin: 0 auto 0;\n    margin-top: -10px;\n    padding: 10px !important;\n    background-color: rgba(33, 69, 138, .04);\n    color: #5e6167;\n    font-size: .8em !important;\n    font-style: italic;\n    text-align: center !important;\n    white-space: normal !important;\n    line-height: 1.5 !important;\n  }\n\n  .language-xml::before {\n    content: \"XML\" !important;\n  }\n\n  .language-html::before {\n    content: \"XML\" !important;\n  }\n\n  td {\n    display: table-cell;\n    padding: 15px 10px !important;\n    font-size: .7em !important;\n    line-height: 1.2 !important;\n    text-align: left !important;\n    text-align: center !important;\n    vertical-align: middle !important;\n    max-width: 150px !important;\n    overflow: hidden !important;\n    white-space: nowrap !important;\n  }\n\n  th {\n    padding: 10px !important;\n    font-size: .7em !important;\n    text-align: center !important;\n    min-width: none !important;\n  }\n\n  .tableContainer {\n    margin-top: 30px;\n    overflow: hidden;\n  }\n</style>","comment_id":"5c27630bda392c696eab97de"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673758","title":"Complex Features in MongoDB Cloud: Add Image Tags with AI","slug":"complex-features-in-mongodb-cloud","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/12/mongowebhooks@2x.jpg","excerpt":"Using functions, webhooks, and values to utilize external APIs.","custom_excerpt":"Using functions, webhooks, and values to utilize external APIs.","created_at_pretty":"12 December, 2018","published_at_pretty":"14 December, 2018","updated_at_pretty":"01 January, 2019","created_at":"2018-12-12T18:26:09.000-05:00","published_at":"2018-12-14T08:00:00.000-05:00","updated_at":"2019-01-01T09:36:10.000-05:00","meta_title":"Building Complex Features in MongoDB Cloud | Hackers and Slackers","meta_description":"Using functions, webhooks, and values to utilize external APIs. Today’s challenge: auto-tagging images using AI.","og_description":"Using functions, webhooks, and values to utilize external APIs. Today’s challenge: auto-tagging images using AI.","og_image":"https://hackersandslackers.com/content/images/2018/12/mongowebhooks@2x.jpg","og_title":"Complex Features in MongoDB Cloud: Add Image Tags with AI","twitter_description":"Using functions, webhooks, and values to utilize external APIs. Today’s challenge: auto-tagging images using AI.","twitter_image":"https://hackersandslackers.com/content/images/2018/12/mongowebhooks@2x.jpg","twitter_title":"Complex Features in MongoDB Cloud: Add Image Tags with AI","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},"tags":[{"name":"NoSQL","slug":"nosql","description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","feature_image":null,"meta_description":"Schemaless data for gunslingers. Heavily focused on databases such as MongoDB, as well as hosting said databases as cloud instances.","meta_title":"NoSQL | Hackers and Slackers","visibility":"public"},{"name":"JavaScript","slug":"javascript","description":"JavaScript covering both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","feature_image":null,"meta_description":"JavaScript topics, both Frontend and NodeJS. Build bundles with Webpack or Parcel, create task runners, or endure our criticism of the JavaScript ecosystem.","meta_title":"Javascript Tutorials | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#MongoDB Cloud","slug":"mongodb-cloud","description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","feature_image":"https://hackersandslackers.com/content/images/2019/03/mongodbcloudseries.jpg","meta_description":"All you need to know about MongoDB’s official cloud offering. Dive into MongoDB Atlas, or the architecture & microservices provided by MongoDB Stitch.","meta_title":"MongoDB Cloud","visibility":"internal"}],"plaintext":"Friends, family, and most importantly, strangers: I approach you today with a\ntale of renewed inspiration. After loudly broadcasting my own confusion and\nmediocre ability to actually implement an effective cloud via MongoDB Stitch, my\nineptitude has been answered with an early Christmas gift. \n\nMy incessant complaining gained some acknowledgement from a couple of folks over\nat MongoDB. Perhaps the timing is simply by chance, but since then I've begun\nnoticing something some subtleties in the Stitch documentation; namely that if\nyou look hard enough, some of it begins to make sense. Either way, I'm chalking\nthis one up as a Christmas Miracle.\n\nLet's Automate Stuff: More Webhooks, Less Labor\nTo demonstrate what building an end-to-end sexy feature looks like in MongoDB\nStitch, I'm going to borrow some help from some old friends: the team behind \nClarifai. \n\nClarifai is one of the early players in the field of what I'm sure we'll\ncreatively refer to as AI as a service. More specifically, they provide an API\nfor image recognition which returns impressive metadata simply by passing an\nimage URL. Best part is, unless you're abusing the shit out of 5000 requests per\nmonth, the API is essentially free:\n\nPredict\n Search\n Custom Model Training\n Add or Edit Input Images\n 5,000  free operations\n 5,000  free operations\n 5,000  free operations\n 5,000  free operations\n Pre-Built Models: \n$1.20 / 1,000  operations\n\nCustom Models:\n$3.20 / 1,000  operations\n$1.20 / 1,000  operations\n $1.20 / 1,000  operations\n $1.20 / 1,000  operations\n If we were to try to fit any more instances of the words \"AI\" and \"Cloud\" into\nthis post, things could quickly derail into a shitty  IBM Watson commercial.\n\n(PS: Blockchain.)\n\nStoring Our Clarifai API Key\nIf you're following along, hit up Clarifai [https://clarifai.com/]  to grab your\nAPI key, no strings attached.\n\nAnd no, nobody is paying me to me to write about their SaaS products.Copy and\npaste your brand new key and head over to the MongoDB Stitch Console\n[https://stitch.mongodb.com]. In our Stitch project, we're going to store our\nkey as a value (you might recall this as being a convenient way to store\nsecrets).\n\nCopy and paste your key as a string in a new value. The only catch is we'll be\nformatting our key as Key #####################, simply because this is the\nformat the API expects to receive when we pass our key as a header to the\nClarifai API.\n\nWarning: Mild Architecting Ahead\nBefore going too far into code, let's recap how this functionality will probably\nwork.\n\nIn our actual application, we'll be identifying images needing alt  tags (either\nvia frontend or backend logic). At that point, we should find the src  attribute\nof said <img>  tags and pass it to a Stitch function; preferably one that makes\na post request to Clarifai. \n\nThis is in fact too simple to be true, as there is one gotcha: Stitch functions \ncannot make http requests on their own. They can,  however, invoke Stitch \nWebhooks. These webhooks share nearly identical syntax and structure to \nfunctions, with a few exceptions:\n\n * Webhooks have endpoints (duh).\n * They have explicit inbound/outbound rules restricting what can invoke them.\n * There are options to set authorization via key or otherwise.\n\nWith all that in mind, our end-to-end flow will end up looking something like\nthis:\n\n 1. Our application identifies an image needing tags an invokes a serverless \n    function.\n 2. The function  constructs the body of the request we'll be making to Clarifai \n     with containing the URL of the image.\n 3. As crazy as it sounds, we then POST to a Stitch endpoint, which in turns\n    makes the actual  POST request to Clarifai. The request is made with the\n    body passed from our function, as well as the API key we stored earlier.\n 4. We'll receive a response of tags which we can do something with on the\n    application-side.\n\nWriting our Function\nWe'll start by writing a simple function as our go-between for our app and our\nservice:\n\nexports = function(img){\n   const http = context.services.get(\"GetClarifaiTags\");\n   var data = {\n        \"inputs\": [\n          {\n            \"data\": {\n              \"image\": {\n                \"url\": img\n              }\n            }\n          }\n        ]\n      };\n      \n    var header_data = {\"Content-Type\": [ \"application/json\" ]};\n   \n    return http.post({\n        url: \"https://webhooks.mongodb-stitch.com/api/client/v2.0/app/hackers-uangn/service/GetClarifaiTags/incoming_webhook/GetTagsForNewImage\",\n        headers: header_data,\n        body: JSON.stringify(data)\n      })\n      .then(response => {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n\n\nThe first thing we do is reference our webhook (which we haven't created yet)\nwith this line:\n\nconst http = context.services.get(\"GetClarifaiTags\");\n\n\nIn the context of a function, context.services.get()  allows us to reference and\ninteract with other services we've created in Stitch. It's important to note\nthat we pass the user-created name of service we want to interact with. This is\none of the reasons why Stitch's documentation is so confusing - they\nconsistently use \"http\"  as an example service name. This seems to imply that\nwe'd want to import a type  of service as opposed to an instance  of a service,\nwhich is wrong.  \n\ndata  is the body of our request, which abides by Clarifai's documentation on\nhow to user their predict API. We need to pass this as a string to our webhook,\nthus we use JSON.stringify(data).\n\nIt's also important to note the structure of Mongo's headers when making\nrequests; notice that the value of each key pair is a list, as exemplified by \n\"Content-Type\": [ \"application/json\" ].\n\nAs you might imagine, these things in combination can cause a whole lot of\nconfusion. Hopefully you know a good blog to point these things out to you\nbeforehand.\n\nCreate a Webhook via 'HTTP Services'\nMove into the \"Services\" tab to create our webhook. Select HTTP  from the list\nof options:\n\nKind of a weird mix of services imho.Set your webhook to be a POST request.\nAuthentication shouldn't be a problem for us since we're only exposing this hook\nto our function, plus there are other ways to handle this.\n\nTIP: Don't post screenshots of sensitive endpoint URLs on the internet.The\nsyntax and methods available for writing a webhook are almost exactly the same\nas when writing regular functions. The one thing to note would be the presence\nof payload  being passed into the function; this object contains both the\nparameters and the body of requests being received by this endpoint. \npayload.body  gives us the body, whereas payload.query.arg  will give us the\nparameters.\n\nexports = function(payload){\n  const http = context.services.get(\"GetClarifaiTags\");\n  const token = context.values.get(\"clarifai_key\");\n  \n  var data = {};\n  if (payload.body) {\n    data = payload.body;\n  }\n  var header_data = {\n    \"Authorization\": [token], \n    \"Content-Type\": [\"application/json\"]\n  };\n\n    return http.post({\n        url: \"https://api.clarifai.com/v2/models/aaa03c23b3724a16a56b629203edc62c/versions/aa7f35c01e0642fda5cf400f543e7c40/outputs\",\n        body: data,\n        headers: header_data\n      })\n      .then(response => {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n\n\nJust as we can access services within functions, we can similarly access values\nvia context.values.get(\"myValue\").\n\nNow that we have both the body and our API key ready, we can actually go ahead\nand construct a valid request to Clarifai. The syntax should be\nself-explanatory, but here's the Stitch http service documentation\n[https://docs.mongodb.com/stitch/services/http-actions/http.post/]  just in\ncase.\n\nWhy Did we Have to Make a Weird Webhook which is both Receiving and Posting\nInformation?\nThis is an excellent question and served to be a huge source of confusion for\nwhat must have been months. Go back to the \"Services\" tab, and pay close\nattention: for each service we create, a set of Rules  are automatically created\nand attached to our service. HTTP services have all functionality disabled room\ndefault, with little to no mention of the existence of rules in the first place. \n This is important for two reasons:\n\n 1. It's a silly UI hiccup that can waste the majority of your waking life.\n 2. This means that only  services can do things like post to external APIs.\n    This is why we didn't simply keep our logic in one function.\n\nOur Workflow in Practice\nAssuming you've added some logic to your app to pick out image URLs needing\ntags, our chain of events should be complete and return results to our\napplication. The POST request we make will return a response to the POST request\nof our function, and our function will return the results to our application.\nWe've successfully created a complex, albeit confusing, cloud architecture or\nexternal services.\n\nThis is where your imagination should hopefully kick in. You'll notice I have a\nfew services such as the endpoints which receive updates every time a JIRA issue\nis created or updated. This is what powers our public-facing kanban board.\n[https://hackersandslackers.com/projects/]","html":"<p>Friends, family, and most importantly, strangers: I approach you today with a tale of renewed inspiration. After loudly broadcasting my own confusion and mediocre ability to actually implement an effective cloud via MongoDB Stitch, my ineptitude has been answered with an early Christmas gift. </p><p>My incessant complaining gained some acknowledgement from a couple of folks over at MongoDB. Perhaps the timing is simply by chance, but since then I've begun noticing something some subtleties in the Stitch documentation; namely that if you look hard enough, some of it begins to make sense. Either way, I'm chalking this one up as a Christmas Miracle.</p><h2 id=\"let-s-automate-stuff-more-webhooks-less-labor\">Let's Automate Stuff: More Webhooks, Less Labor</h2><p>To demonstrate what building an end-to-end sexy feature looks like in MongoDB Stitch, I'm going to borrow some help from some old friends: the team behind <strong>Clarifai</strong>. </p><p>Clarifai is one of the early players in the field of what I'm sure we'll creatively refer to as <em>AI as a service. </em>More specifically, they provide an API for image recognition which returns impressive metadata simply by passing an image URL. Best part is, unless you're abusing the shit out of 5000 requests per month, the API is essentially free:</p><style>\n    table td {\n        text-align:left;\n        font-size: .95em;\n    }\n</style>\n\n<div class=\"tableContainer\">\n  <table>\n    <thead>\n      <th>Predict</th>\n      <th>Search</th>\n      <th>Custom Model Training</th>\n      <th>Add or Edit Input Images</th>\n    </thead>\n    <tbody>\n      <tr>\n        <td><strong>5,000</strong> free operations</td>\n        <td><strong>5,000</strong> free operations</td>\n        <td><strong>5,000</strong> free operations</td>\n        <td><strong>5,000</strong> free operations</td>\n      </tr>\n      <tr>\n        <td>\n          <strong>Pre-Built Models: </strong><br>\n          <small><strong>$1.20 / 1,000</strong> operations</small><br><br>\n          <strong>Custom Models:</strong><br>\n          <small><strong>$3.20 / 1,000</strong> operations</small><br>\n        </td>\n        <td><strong>$1.20 / 1,000</strong> operations</td>\n        <td><strong>$1.20 / 1,000</strong> operations</td>\n        <td><strong>$1.20 / 1,000</strong> operations</td>\n      </tr>\n    </tbody>\n  </table>\n</div>\n<p>If we were to try to fit any more instances of the words \"AI\" and \"Cloud\" into this post, things could quickly derail into a shitty  IBM Watson commercial.</p><p><em>(PS: Blockchain.)</em></p><h2 id=\"storing-our-clarifai-api-key\">Storing Our Clarifai API Key</h2><p>If you're following along, hit up <a href=\"https://clarifai.com/\">Clarifai</a> to grab your API key, no strings attached.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-1.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/clarifaiapi_o.png\" class=\"kg-image\"><figcaption>And no, nobody is paying me to me to write about their SaaS products.</figcaption></figure><p>Copy and paste your brand new key and head over to the <a href=\"https://stitch.mongodb.com\">MongoDB Stitch Console</a>. In our Stitch project, we're going to store our key as a <strong>value </strong>(you might recall this as being a convenient way to store secrets).</p><p>Copy and paste your key as a string in a new value. The only catch is we'll be formatting our key as <code>Key #####################</code>, simply because this is the format the API expects to receive when we pass our key as a header to the Clarifai API.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-2.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/mongovalues_o-1.png\" class=\"kg-image\"></figure><h2 id=\"warning-mild-architecting-ahead\">Warning: Mild Architecting Ahead</h2><p>Before going too far into code, let's recap how this functionality will probably work.</p><p>In our actual application, we'll be identifying images needing <code>alt</code> tags (either via frontend or backend logic). At that point, we should find the <code>src</code> attribute of said <code>&lt;img&gt;</code> tags and pass it to a Stitch function; preferably one that makes a post request to <strong>Clarifai</strong>. </p><p>This is in fact too simple to be true, as there is one gotcha: Stitch <strong>functions</strong> cannot make http requests on their own. They <em>can,</em> however, invoke Stitch <strong>Webhooks. </strong>These webhooks share nearly identical syntax and structure to <strong>functions</strong>, with a few exceptions:</p><ul><li>Webhooks have endpoints (duh).</li><li>They have explicit inbound/outbound rules restricting what can invoke them.</li><li>There are options to set authorization via key or otherwise.</li></ul><p>With all that in mind, our end-to-end flow will end up looking something like this:</p><ol><li>Our application identifies an image needing tags an invokes a serverless <strong>function.</strong></li><li>The <strong>function</strong> constructs the body of the request we'll be making to <strong>Clarifai</strong> with containing the URL of the image.</li><li>As crazy as it sounds, we then POST to a Stitch endpoint, which in turns makes the <em>actual</em> POST request to Clarifai. The request is made with the body passed from our function, as well as the API key we stored earlier.</li><li>We'll receive a response of tags which we can do something with on the application-side.</li></ol><h2 id=\"writing-our-function\">Writing our Function</h2><p>We'll start by writing a simple function as our go-between for our app and our service:</p><pre><code class=\"language-javascript\">exports = function(img){\n   const http = context.services.get(&quot;GetClarifaiTags&quot;);\n   var data = {\n        &quot;inputs&quot;: [\n          {\n            &quot;data&quot;: {\n              &quot;image&quot;: {\n                &quot;url&quot;: img\n              }\n            }\n          }\n        ]\n      };\n      \n    var header_data = {&quot;Content-Type&quot;: [ &quot;application/json&quot; ]};\n   \n    return http.post({\n        url: &quot;https://webhooks.mongodb-stitch.com/api/client/v2.0/app/hackers-uangn/service/GetClarifaiTags/incoming_webhook/GetTagsForNewImage&quot;,\n        headers: header_data,\n        body: JSON.stringify(data)\n      })\n      .then(response =&gt; {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n</code></pre>\n<p>The first thing we do is reference our webhook (which we haven't created yet) with this line:</p><pre><code class=\"language-javascript\">const http = context.services.get(&quot;GetClarifaiTags&quot;);\n</code></pre>\n<p>In the context of a function, <code>context.services.get()</code> allows us to reference and interact with other services we've created in Stitch. It's important to note that we pass <strong>the user-created name of service </strong>we want to interact with. This is one of the reasons why Stitch's documentation is so confusing - they consistently use <em>\"http\"</em> as an example service name. This seems to imply that we'd want to import a <em>type</em> of service as opposed to an <em>instance</em> of a service, which is <strong>wrong.</strong> </p><p><code>data</code> is the body of our request, which abides by <a href=\"https://clarifai.com/developer/guide/predict#predict\">Clarifai's documentation on how to user their <em>predict</em> API</a>. We need to pass this as a string to our webhook, thus we use <code>JSON.stringify(data)</code>.</p><p>It's also important to note the structure of Mongo's headers when making requests; notice that the value of each key pair is a <strong>list, </strong>as exemplified by <code>\"Content-Type\": [ \"application/json\" ]</code>.</p><p>As you might imagine, these things in combination can cause a whole lot of confusion. Hopefully you know a good blog to point these things out to you beforehand.</p><h2 id=\"create-a-webhook-via-http-services-\">Create a Webhook via 'HTTP Services'</h2><p>Move into the \"Services\" tab to create our webhook. Select <strong>HTTP</strong> from the list of options:</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/mongoservices.png\" class=\"kg-image\"><figcaption>Kind of a weird mix of services imho.</figcaption></figure><p>Set your webhook to be a POST request. Authentication shouldn't be a problem for us since we're only exposing this hook to our function, plus there are other ways to handle this.</p><figure class=\"kg-card kg-image-card\"><img src=\"http://res-3.cloudinary.com/hackers-and-slackers/image/upload/q_auto/v1/images/Screen-Shot-2018-12-13-at-4.23.27-PM_o.png\" class=\"kg-image\"><figcaption>TIP: Don't post screenshots of sensitive endpoint URLs on the internet.</figcaption></figure><p>The syntax and methods available for writing a webhook are almost exactly the same as when writing regular functions. The one thing to note would be the presence of <strong>payload</strong> being passed into the function; this object contains <em><strong>both the parameters and the body </strong></em>of requests being received by this endpoint. <code>payload.body</code> gives us the body, whereas <code>payload.query.arg</code> will give us the parameters.</p><pre><code class=\"language-javascript\">exports = function(payload){\n  const http = context.services.get(&quot;GetClarifaiTags&quot;);\n  const token = context.values.get(&quot;clarifai_key&quot;);\n  \n  var data = {};\n  if (payload.body) {\n    data = payload.body;\n  }\n  var header_data = {\n    &quot;Authorization&quot;: [token], \n    &quot;Content-Type&quot;: [&quot;application/json&quot;]\n  };\n\n    return http.post({\n        url: &quot;https://api.clarifai.com/v2/models/aaa03c23b3724a16a56b629203edc62c/versions/aa7f35c01e0642fda5cf400f543e7c40/outputs&quot;,\n        body: data,\n        headers: header_data\n      })\n      .then(response =&gt; {\n      // The response body is encoded as raw BSON.Binary. Parse it to JSON.\n      const ejson_body = EJSON.parse(response.body.text());\n      return ejson_body;\n    });\n};\n</code></pre>\n<p>Just as we can access services within functions, we can similarly access values via <code>context.values.get(\"myValue\")</code>.</p><p>Now that we have both the body and our API key ready, we can actually go ahead and construct a valid request to Clarifai. The syntax should be self-explanatory, but here's the <a href=\"https://docs.mongodb.com/stitch/services/http-actions/http.post/\">Stitch http service documentation</a> just in case.</p><h3 id=\"why-did-we-have-to-make-a-weird-webhook-which-is-both-receiving-and-posting-information\">Why Did we Have to Make a Weird Webhook which is both Receiving and Posting Information?</h3><p>This is an excellent question and served to be a huge source of confusion for what must have been months. Go back to the \"Services\" tab, and pay close attention: for each service we create, a set of <strong>Rules</strong> are automatically created and attached to our service. <strong>HTTP services have all functionality disabled room default, with little to no mention of the existence of rules in the first place.</strong> This is important for two reasons:</p><ol><li>It's a silly UI hiccup that can waste the majority of your waking life.</li><li>This means that <em>only</em> services can do things like post to external APIs. This is why we didn't simply keep our logic in one function.</li></ol><h2 id=\"our-workflow-in-practice\">Our Workflow in Practice</h2><p>Assuming you've added some logic to your app to pick out image URLs needing tags, our chain of events should be complete and return results to our application. The POST request we make will return a response to the POST request of our function, and our function will return the results to our application. We've successfully created a complex, albeit confusing, cloud architecture or external services.</p><p>This is where your imagination should hopefully kick in. You'll notice I have a few services such as the endpoints which receive updates every time a <strong>JIRA </strong>issue is created or updated. This is what powers our <a href=\"https://hackersandslackers.com/projects/\">public-facing kanban board.</a></p>","url":"https://hackersandslackers.com/complex-features-in-mongodb-cloud/","uuid":"91acc3b3-88c2-4313-aedd-adf1eac1dc36","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5c1199114b9896120b3c1b34"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673733","title":"Python-Lambda: The Essential Library for AWS Cloud Functions","slug":"improve-your-aws-lambda-workflow-with-python-lambda","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/11/pythonlambda3@2x.jpg","excerpt":"Deploy AWS Lambda functions with ease with the help of a single Python library.","custom_excerpt":"Deploy AWS Lambda functions with ease with the help of a single Python library.","created_at_pretty":"07 November, 2018","published_at_pretty":"08 November, 2018","updated_at_pretty":"05 January, 2019","created_at":"2018-11-07T16:01:48.000-05:00","published_at":"2018-11-07T19:13:20.000-05:00","updated_at":"2019-01-05T13:22:03.000-05:00","meta_title":"Simplify Lambda Deployment with python-lambda | Hackers and Slackers","meta_description":"Create and deploy AWS Lambda functions with ease in Python. Use python-lambda to initialize your lambdas, run locally, and automate deployment. ","og_description":"Create and deploy AWS Lambda functions with ease in Python. Use python-lambda to initialize your lambdas, run locally, and automate deployment. ","og_image":"https://hackersandslackers.com/content/images/2018/11/pythonlambda3@2x.jpg","og_title":"Improve your AWS Lambda Workflow with python-lambda | Hackers and Slackers","twitter_description":"Create and deploy AWS Lambda functions with ease in Python. Use python-lambda to initialize your lambdas, run locally, and automate deployment. ","twitter_image":"https://hackersandslackers.com/content/images/2018/11/pythonlambda3@2x.jpg","twitter_title":"Improve your AWS Lambda Workflow with python-lambda | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Creating APIs in AWS","slug":"create-an-aws-api","description":"Create a REST API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pythonlambda.jpg","meta_description":"Create an API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","meta_title":"Create a REST API in AWS","visibility":"internal"}],"plaintext":"In our series about building AWS APIs\n[https://hackersandslackers.com/tag/aws-api/], we've covered a lot of ground\naround learning the AWS ecosystem. Now that we're all feeling a bit more\ncomfortable, it may be time to let everybody in on the world's worst-kept\nsecret: Almost nobody builds architecture by interacting with the AWS UI\ndirectly. There are plenty examples of how this is done, with the main example\nbeing HashiCorp:  an entire business model based around the premise that AWS has\na shitty UI, to the point where it's easier to write code to make things which\nwill host your code. What a world.\n\nIn the case of creating Python Lambda functions, the \"official\" (aka: manual)\nworkflow of deploying your code to AWS is something horrible like this:\n\n * You start a project locally and begin development.\n * You opt to use virtualenv, because you're well aware that you're going to\n   need the source for any packages you use available.\n * When you're ready to 'deploy' to AWS, you copy all your dependencies from \n   /site-packages  and move them into your root directory, temporarily creating\n   an abomination of a project structure.\n * With your project fully bloated and confused, you cherry pick the files\n   needed to zip into an archive.\n * Finally, you upload your code via zip either to Lambda directory or to S3,\n   only to run your code, realize its broken, and need to start all over.\n\nThere Must be a Better Way\nIndeed there is, and surprisingly enough the solution is 100% Python (sorry\nHashiCorp, we'll talk another time). This \"better way\" is my personal method of\nleveraging the following:\n\n * The official AWS CLI\n   [https://docs.aws.amazon.com/cli/latest/userguide/installing.html].\n * Pipenv [https://pipenv.readthedocs.io/en/latest/]  as an environment manager.\n * Python's python-lambda [https://github.com/nficano/python-lambda]  package:\n   the magic behind it all.\n\nObligatory \"Installing the CLI\" Recap\nFirst off, make sure you're using a compatible version of Python on your system,\nas AWS is still stuck on version 3.6. Look, we can't all be Google Cloud (and by\nthe way, Python 2.7 doesn't count as compatible - let it die before your career\ndoes).\n\n$ pip3 install awscli --upgrade --user\n\n\nIf you're working off an EC2 instance, it has come to my attention pip3 does not\ncome preinstalled. Remember to run: * $ apt update\n * $ apt upgrade\n * $ apt install python3-pip\n\nYou may be prompted to run apt install awscli  as well.Awesome, now that we have\nthe CLI installed on the real  version of Python, we need to store your\ncredentials. Your Access Key ID and Secret Access Key can be found in your IAM\npolicy manager.\n\n$ aws configure\nAWS Access Key ID [None]: YOURKEY76458454535\nAWS Secret Access Key [None]: SECRETKEY*^R(*$76458397045609365493\nDefault region name [None]:\nDefault output format [None]:\n\nOn both Linux and OSX, this should generate files found under cd ~/.aws  which\nwill be referenced by default whenever you use an AWS service moving forward.\n\nSet Up Your Environment\nAs mentioned, we'll use pipenv  for easy environment management. We'll create an\nenvironment using Lambda's preferred Python version:\n\n$ pip3 install pipenv\n$ pipenv shell --python 3.6\n\nCreating a virtualenv for this project…\nPipfile: /home/example/Pipfile\nUsing /usr/bin/python3 (3.6.6) to create virtualenv…\n⠇Already using interpreter /usr/bin/python3\nUsing base prefix '/usr'\nNew python executable in /root/.local/share/virtualenvs/example-RnlD17kd/bin/python3\nAlso creating executable in /root/.local/share/virtualenvs/example-RnlD17kd/bin/python\nInstalling setuptools, pip, wheel...done.\n\n\nSomething you should be aware of at the time of writing: Pip's latest version,\n18.1, is actually a breaking change  for Pipenv. Thus, the first thing we should\ndo is force usage of pip 18.0 (is there even a fix for this yet?). This is\nsolved by typing pip3 install pip==18.0  with the Pipenv shell activated. Now\nlet's get to the easy part.\n\npython-lambda: The Savior of AWS\nSo far we've made our lives easier in two ways: we're keeping our AWS\ncredentials safe and far away from ourselves, and we have what is by far the\nsuperior Python package management solution. But this is all foreplay leading up\nto python-lambda:\n\n$ pip3 install python-lambda\n\n\nThis library alone is about to do you the following favors:\n\n * Initiate your Lambda project structure for you.\n * Isolate Lambda configuration to a  config.yaml  file, covering everything\n   from the name of your entry point, handler function, and even\n   program-specific variables.\n * Allow you to run tests locally, where a test.json  file simulates a request\n   being made to your function locally.\n * Build a production-ready zip file with all dependencies completely separated \n   from your beautiful file structure.\n * The ability to deploy directly  to S3 or Lambda with said zip file from\n   command-line.\n\nCheck out the commands for yourself:\n\nCommands:\n  build      Bundles package for deployment.\n  cleanup    Delete old versions of your functions\n  deploy     Register and deploy your code to lambda.\n  deploy-s3  Deploy your lambda via S3.\n  init       Create a new function for Lambda.\n  invoke     Run a local test of your function.\n  upload     Upload your lambda to S3.\n\n\nInitiate your project\nRunning lambda init  will generate the following file structure:\n\n.\n├── Pipfile\n├── config.yaml\n├── event.json\n└── service.py\n\n\nChecking out the entry point: service.py\npython-lambda starts you off with a basic handler as an example of a working\nproject. Feel free to rename service.py  and its handler function to whatever\nyou please, as we can configure that in a bit.\n\n# -*- coding: utf-8 -*-\n\ndef handler(event, context):\n    # Your code goes here!\n    e = event.get('e')\n    pi = event.get('pi')\n    return e + pi\n\n\nEasy configuration via configure.yaml\nThe base config generated by lambda init  looks like this:\n\nregion: us-east-1\n\nfunction_name: my_lambda_function\nhandler: service.handler\ndescription: My first lambda function\nruntime: python3.6\n# role: lambda_basic_execution\n\n# S3 upload requires appropriate role with s3:PutObject permission\n# (ex. basic_s3_upload), a destination bucket, and the key prefix\n# bucket_name: 'example-bucket'\n# s3_key_prefix: 'path/to/file/'\n\n# if access key and secret are left blank, boto will use the credentials\n# defined in the [default] section of ~/.aws/credentials.\naws_access_key_id:\naws_secret_access_key:\n\n# dist_directory: dist\n# timeout: 15\n# memory_size: 512\n# concurrency: 500\n#\n\n# Experimental Environment variables\nenvironment_variables:\n    env_1: foo\n    env_2: baz\n\n# If `tags` is uncommented then tags will be set at creation or update\n# time.  During an update all other tags will be removed except the tags\n# listed here.\n#tags:\n#    tag_1: foo\n#    tag_2: bar\n\n\nLook familiar? These are all the properties you would normally have to set up\nvia the UI. As an added bonus, you can store values (such as S3 bucket names for\nboto3) in this file as well. That's dope.\n\nSetting up event.json\nThe default event.json  is about as simplistic as you can get, and naturally not\nvery helpful at first (it isn't meant to be). These are the contents:\n\n{\n  \"pi\": 3.14,\n  \"e\": 2.718\n}\n\n\nWe can replace this a real test JSON which we can grab from Lambda itself.\nHere's an example of a Cloudwatch event we can use instead:\n\n{\n  \"id\": \"cdc73f9d-aea9-11e3-9d5a-835b769c0d9c\",\n  \"detail-type\": \"Scheduled Event\",\n  \"source\": \"aws.events\",\n  \"account\": \"{{account-id}}\",\n  \"time\": \"1970-01-01T00:00:00Z\",\n  \"region\": \"us-east-1\",\n  \"resources\": [\n    \"arn:aws:events:us-east-1:123456789012:rule/ExampleRule\"\n  ],\n  \"pi\": 3.14,\n  \"e\": 2.718\n  \"detail\": {}\n}\n\n\nRemember that event.json  is what is being passed to our handler as the event \nparameter. Thus, now we can run our Lambda function locally  to see if it works:\n\n$ lambda invoke\n5.8580000000000005\n\n\nPretty cool if you ask me.\n\nDeploy it, Ship it, Roll Credits\nAfter you express your coding genius, remember to output pip freeze >\nrequirements.txt. python-lambda  will use this as a reference for which packages\nneed to be included. This is neat because we can use Pipenv and the benefits of\nthe workflow it provides while still easily outputting what we need to deploy. \n\nBecause we already specified which Lambda we're going to deploy to in \nconfig.yaml, we can deploy to that Lambda immediately. lambda deploy  will use\nthe zip upload method, whereas lambda deploy-s3  will store your source on S3.\n\nIf you'd like to deploy the function yourself, run with lambda build  which will\nzip your source code plus dependencies  neatly into a /dist  directory. Suddenly\nwe never have to compromise our project structure, and now we can easily source\ncontrol our Lambdas by .gitignoring our build folders while hanging on to our\nPipfiles.\n\nHere's to hoping you never need to deploy Lambdas using any other method ever\nagain. Cheers.","html":"<p>In our series about building <a href=\"https://hackersandslackers.com/tag/aws-api/\">AWS APIs</a>, we've covered a lot of ground around learning the AWS ecosystem. Now that we're all feeling a bit more comfortable, it may be time to let everybody in on the world's worst-kept secret: Almost nobody builds architecture by interacting with the AWS UI directly. There are plenty examples of how this is done, with the main example being <strong>HashiCorp:</strong> an entire business model based around the premise that AWS has a shitty UI, to the point where it's easier to write code to make things which will host your code. What a world.</p><p>In the case of creating Python Lambda functions, the \"official\" (aka: manual) workflow of deploying your code to AWS is something horrible like this:</p><ul><li>You start a project locally and begin development.</li><li>You opt to use <strong>virtualenv, </strong>because you're well aware that you're going to need the source for any packages you use available.</li><li>When you're ready to 'deploy' to AWS, you <em>copy all your dependencies from </em><code>/site-packages</code> <em>and move them into your root directory</em>, temporarily creating an abomination of a project structure.</li><li>With your project fully bloated and confused, you cherry pick the files needed to zip into an archive.</li><li>Finally, you upload your code via zip either to Lambda directory or to S3, only to run your code, realize its broken, and need to start all over.</li></ul><h2 id=\"there-must-be-a-better-way\">There Must be a Better Way</h2><p>Indeed there is, and surprisingly enough the solution is 100% Python (sorry HashiCorp, we'll talk another time). This \"better way\" is my personal method of leveraging the following:</p><ul><li>The official <a href=\"https://docs.aws.amazon.com/cli/latest/userguide/installing.html\">AWS CLI</a>.</li><li><a href=\"https://pipenv.readthedocs.io/en/latest/\">Pipenv</a> as an environment manager.</li><li>Python's <strong><a href=\"https://github.com/nficano/python-lambda\">python-lambda</a></strong> package: the magic behind it all.</li></ul><h3 id=\"obligatory-installing-the-cli-recap\">Obligatory \"Installing the CLI\" Recap</h3><p>First off, make sure you're using a compatible version of Python on your system, as AWS is still stuck on version 3.6. Look, we can't all be Google Cloud (and by the way, <em>Python 2.7 </em>doesn't count as compatible - let it die before your career does).</p><pre><code class=\"language-python\">$ pip3 install awscli --upgrade --user\n</code></pre>\n<div class=\"protip\">\n    If you're working off an EC2 instance, it has come to my attention pip3 does not come preinstalled. Remember to run:\n<ul>\n    <li><code>$ apt update</code></li>\n    <li><code>$ apt upgrade</code></li>\n    <li><code>$ apt install python3-pip</code></li>\n</ul>\n    \n    You may be prompted to run <code>apt install awscli</code> as well.\n</div><p>Awesome, now that we have the CLI installed on the <em>real</em> version of Python, we need to store your credentials. Your Access Key ID and Secret Access Key can be found in your IAM policy manager.</p><pre><code>$ aws configure\nAWS Access Key ID [None]: YOURKEY76458454535\nAWS Secret Access Key [None]: SECRETKEY*^R(*$76458397045609365493\nDefault region name [None]:\nDefault output format [None]:</code></pre><p>On both Linux and OSX, this should generate files found under <code>cd ~/.aws</code> which will be referenced by default whenever you use an AWS service moving forward.</p><h2 id=\"set-up-your-environment\">Set Up Your Environment</h2><p>As mentioned, we'll use <code>pipenv</code> for easy environment management. We'll create an environment using Lambda's preferred Python version:</p><pre><code class=\"language-python\">$ pip3 install pipenv\n$ pipenv shell --python 3.6\n\nCreating a virtualenv for this project…\nPipfile: /home/example/Pipfile\nUsing /usr/bin/python3 (3.6.6) to create virtualenv…\n⠇Already using interpreter /usr/bin/python3\nUsing base prefix '/usr'\nNew python executable in /root/.local/share/virtualenvs/example-RnlD17kd/bin/python3\nAlso creating executable in /root/.local/share/virtualenvs/example-RnlD17kd/bin/python\nInstalling setuptools, pip, wheel...done.\n</code></pre>\n<p>Something you should be aware of at the time of writing: Pip's latest version, 18.1, is actually a <em>breaking change</em> for Pipenv. Thus, the first thing we should do is force usage of pip 18.0 (is there even a fix for this yet?). This is solved by typing <code>pip3 install pip==18.0</code> with the Pipenv shell activated. Now let's get to the easy part.</p><h2 id=\"python-lambda-the-savior-of-aws\">python-lambda: The Savior of AWS</h2><p>So far we've made our lives easier in two ways: we're keeping our AWS credentials safe and far away from ourselves, and we have what is by far the superior Python package management solution. But this is all foreplay leading up to <code>python-lambda</code>:</p><pre><code class=\"language-bash\">$ pip3 install python-lambda\n</code></pre>\n<p>This library alone is about to do you the following favors:</p><ul><li>Initiate your Lambda project structure for you.</li><li>Isolate Lambda configuration to a<em> config.yaml</em> file, covering everything from the name of your entry point, handler function, and even program-specific variables.</li><li>Allow you to run tests locally, where a <em>test.json</em> file simulates a request being made to your function locally.</li><li>Build a production-ready zip file with all dependencies <em>completely separated </em>from your beautiful file structure.</li><li>The ability to deploy <em>directly</em> to S3 or Lambda with said zip file from command-line.</li></ul><p>Check out the commands for yourself:</p><pre><code class=\"language-bash\">Commands:\n  build      Bundles package for deployment.\n  cleanup    Delete old versions of your functions\n  deploy     Register and deploy your code to lambda.\n  deploy-s3  Deploy your lambda via S3.\n  init       Create a new function for Lambda.\n  invoke     Run a local test of your function.\n  upload     Upload your lambda to S3.\n</code></pre>\n<h3 id=\"initiate-your-project\">Initiate your project</h3><p>Running <code>lambda init</code> will generate the following file structure:</p><pre><code class=\"language-bash\">.\n├── Pipfile\n├── config.yaml\n├── event.json\n└── service.py\n</code></pre>\n<h3 id=\"checking-out-the-entry-point-service-py\">Checking out the entry point: service.py</h3><p>python-lambda starts you off with a basic handler as an example of a working project. Feel free to rename <code>service.py</code> and its handler function to whatever you please, as we can configure that in a bit.</p><pre><code class=\"language-python\"># -*- coding: utf-8 -*-\n\ndef handler(event, context):\n    # Your code goes here!\n    e = event.get('e')\n    pi = event.get('pi')\n    return e + pi\n</code></pre>\n<h3 id=\"easy-configuration-via-configure-yaml\">Easy configuration via configure.yaml</h3><p>The base config generated by <code>lambda init</code> looks like this:</p><pre><code class=\"language-yaml\">region: us-east-1\n\nfunction_name: my_lambda_function\nhandler: service.handler\ndescription: My first lambda function\nruntime: python3.6\n# role: lambda_basic_execution\n\n# S3 upload requires appropriate role with s3:PutObject permission\n# (ex. basic_s3_upload), a destination bucket, and the key prefix\n# bucket_name: 'example-bucket'\n# s3_key_prefix: 'path/to/file/'\n\n# if access key and secret are left blank, boto will use the credentials\n# defined in the [default] section of ~/.aws/credentials.\naws_access_key_id:\naws_secret_access_key:\n\n# dist_directory: dist\n# timeout: 15\n# memory_size: 512\n# concurrency: 500\n#\n\n# Experimental Environment variables\nenvironment_variables:\n    env_1: foo\n    env_2: baz\n\n# If `tags` is uncommented then tags will be set at creation or update\n# time.  During an update all other tags will be removed except the tags\n# listed here.\n#tags:\n#    tag_1: foo\n#    tag_2: bar\n</code></pre>\n<p>Look familiar? These are all the properties you would normally have to set up via the UI. As an added bonus, you can store values (such as S3 bucket names for boto3) in this file as well. That's dope.</p><h3 id=\"setting-up-event-json\">Setting up event.json</h3><p>The default <code>event.json</code> is about as simplistic as you can get, and naturally not very helpful at first (it isn't meant to be). These are the contents:</p><pre><code class=\"language-json\">{\n  &quot;pi&quot;: 3.14,\n  &quot;e&quot;: 2.718\n}\n</code></pre>\n<p>We can replace this a real test JSON which we can grab from Lambda itself. Here's an example of a Cloudwatch event we can use instead:</p><pre><code class=\"language-json\">{\n  &quot;id&quot;: &quot;cdc73f9d-aea9-11e3-9d5a-835b769c0d9c&quot;,\n  &quot;detail-type&quot;: &quot;Scheduled Event&quot;,\n  &quot;source&quot;: &quot;aws.events&quot;,\n  &quot;account&quot;: &quot;{{account-id}}&quot;,\n  &quot;time&quot;: &quot;1970-01-01T00:00:00Z&quot;,\n  &quot;region&quot;: &quot;us-east-1&quot;,\n  &quot;resources&quot;: [\n    &quot;arn:aws:events:us-east-1:123456789012:rule/ExampleRule&quot;\n  ],\n  &quot;pi&quot;: 3.14,\n  &quot;e&quot;: 2.718\n  &quot;detail&quot;: {}\n}\n</code></pre>\n<p>Remember that <code>event.json</code> is what is being passed to our handler as the <code>event</code> parameter. Thus, now we can run our Lambda function <em>locally</em> to see if it works:</p><pre><code class=\"language-bash\">$ lambda invoke\n5.8580000000000005\n</code></pre>\n<p>Pretty cool if you ask me.</p><h2 id=\"deploy-it-ship-it-roll-credits\">Deploy it, Ship it, Roll Credits</h2><p>After you express your coding genius, remember to output <code>pip freeze &gt; requirements.txt</code>. <strong>python-lambda</strong> will use this as a reference for which packages need to be included. This is neat because we can use Pipenv and the benefits of the workflow it provides while still easily outputting what we need to deploy. </p><p>Because we already specified which Lambda we're going to deploy to in <code>config.yaml</code>, we can deploy to that Lambda immediately. <code>lambda deploy</code> will use the zip upload method, whereas <code>lambda deploy-s3</code> will store your source on S3.</p><p>If you'd like to deploy the function yourself, run with <code>lambda build</code> which will zip your source code <em>plus dependencies</em> neatly into a /<em>dist</em> directory. Suddenly we never have to compromise our project structure, and now we can easily source control our Lambdas by <em>.gitignoring </em>our build folders while hanging on to our Pipfiles.</p><p>Here's to hoping you never need to deploy Lambdas using any other method ever again. Cheers.</p>","url":"https://hackersandslackers.com/improve-your-aws-lambda-workflow-with-python-lambda/","uuid":"08ad7706-8dd7-4475-875e-880c017de8d5","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5be352bc2aa81b1606ab77a7"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb8673651","title":"Building an API with Amazon's API Gateway","slug":"creating-apis-with-api-gateway","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/05/apigateway2@2x.jpg","excerpt":"Building APIs: The final frontier of cool-stuff-to-do-in-AWS.","custom_excerpt":"Building APIs: The final frontier of cool-stuff-to-do-in-AWS.","created_at_pretty":"13 May, 2018","published_at_pretty":"29 October, 2018","updated_at_pretty":"05 January, 2019","created_at":"2018-05-13T17:29:07.000-04:00","published_at":"2018-10-29T19:41:00.000-04:00","updated_at":"2019-01-05T13:28:10.000-05:00","meta_title":"Building an API with Amazon's API Gateway | Hackers and Slackers","meta_description":"Use Amazon's API Gateway to design powerful APIs to interact with other AWS services.","og_description":"Use Amazon's API Gateway to design powerful APIs to interact with other AWS services.","og_image":"https://hackersandslackers.com/content/images/2018/05/apigateway2@2x.jpg","og_title":"Building an API with Amazon's API Gateway | Hackers and Slackers","twitter_description":"Use Amazon's API Gateway to design powerful APIs to interact with other AWS services.","twitter_image":"https://hackersandslackers.com/content/images/2018/05/apigateway2@2x.jpg","twitter_title":"Building an API with Amazon's API Gateway | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},"tags":[{"name":"AWS","slug":"aws","description":"Monolithic cloud architecture via microservices. Become familiar with AWS products, account administration, security practices, and tips to make it all easier.","feature_image":null,"meta_description":"Become familiar with AWS services, account administration, security practices, and tips to make it all easier.","meta_title":"Learn AWS | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"Architecture","slug":"architecture","description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to Lambda functions, Docker containers, Google Cloud functions,  Kubernetes, Heroku, etc.","feature_image":null,"meta_description":"Advancements in software architecture, serverless and beyond. Examples include equivalents to cloud functions, Docker containers, Kubernetes, Heroku, etc.","meta_title":"Software Architecture | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Creating APIs in AWS","slug":"create-an-aws-api","description":"Create a REST API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pythonlambda.jpg","meta_description":"Create an API in AWS with industry-standard services such as Lambda Functions, RDS, and API Gateway.","meta_title":"Create a REST API in AWS","visibility":"internal"}],"plaintext":"In our last adventure, we ventured off to create our very own cloud database\n[https://hackersandslackers.com/setting-up-mysql-on-aws/]  by using Amazon's RDS \n service. We've also briefly covered\n[https://hackersandslackers.com/building-an-api-using-aws/]  the general concept\nbehind what Lambda functions. In case you've already forgotten, Lambdas are\nbasically just chunks of code in the cloud; think of them as tiny virtual\nservers, which have already been configured (and locked down) to serve one\nspecific purpose. Because that's literally what it is.\n\nThe data being stored in RDS is ultimately what we're targeting, and Lambdas \nserve as the in-between logic to serve up, modify, or add to the proper data.\nThe only piece missing from the picture is API Gateway. \n\nAs the name suggests, API Gateway  is the, uh, gateway  that users or systems\ninteract with to obtain what they're seeking. It is (hopefully) the only part of\nthis VPC structure an external user can interact with:\n\nSimple API to interact with RDS.Serving as a \"gateway\" is obviously what all\nAPIs so, but the term is also true in the sense that API Gateway  is completely\nconfigured via UI, thus engineers of any programming background can safely\nmodify endpoints, methods,  CORs  configurations, or any of the high-level API\nstructure without being locked into a programming language. API Gateway  is\ntherefore very much an enterprise-geared product: it lends itself to large teams\nand scaling. That said, if it were to be compared to building an API via a\nframework designed to do such things (such as Express or Flask) the experience\nis undoubtedly more clunky. The trade-off being made for speed is immediate\nvisibility, assurance, and a higher chance for collaboration.\n\nThe Challenge of Building a \"Well-Designed\" API\nGood APIs are premeditated. A complex API might accept multiple methods per\nendpoint, allow advanced filtering of results, or handle advanced\nAuthentication. Neither of us have the time to attempt covering all of those\nthings in detail, but I will  leave you with the knowledge that all these\nfeatures are very much possible.\n\nThe API Gateway  interface is where you'd get started. Let's blow through the\nworld's most inappropriately fast explanation of building APIs ever ,and check\nout the UI:\n\nIt ain't pretty, but it works. * Your APIs are listed on the left. You can create more than one, if you're\n   some sort of sadist.\n * The Resources pane is the full structure of your API. At the highest level,\n   'resources' refers to Endpoints,  which are the URLs your API will ultimately\n   expose.\n * Every Endpoint  can contain whichever Methods  you choose to associate with\n   them (GET, POST, PUT, etc). Even if they belong to the same endpoint, a POST\n   method could contain entirely unrelated logic from a PUT method: its your\n   responsibility to make sure your API design makes sense.\n * Finally, each Method has their expected Request and Response  structures\n   defined individually, which what the horribly designed box diagram is\n   attempting to explain on the right. The box on the left labeled CLIENT refers\n   to the requester, where the box on the right represents the triggered action.\n\nThis UI is your bread and butter. I hope you're strapped in, because walking\nthrough this interface is going to be hella boring for all of us.\n\nCreating a Method Request\nThe first step to creating an endpoint (let's say a GET endpoint) is to set the\nexpectation for what the user will send to us:\n\nAwe yea, authorization. 1. Authorization  allows you to restrict users from using your API unless they\n    follow your IAM policy.\n 2. Request Validator  lets you chose if you'd like this validation to happen\n    via the body, query string parameters, headers, or all of the above.\n 3. API Keys  are useful if you're creating an API to sell commercially or\n    enforce limited access. If your business model revolves around selling an\n    API, you can realistically do this.\n 4. Query String Parameters  are... actually forget it, you know this by now.\n 5. See above.\n 6. If preferred, the Request Body can be assigned a model,  which is\n    essentially a JSON schema. If a request is made to your endpoint which does\n    not match the request body model, it is a malformed request. We'll cover \n    models  in the advanced course, once somebody actually starts paying me to\n    write this stuff.\n\nMethod Execution: AKA \"What do we do with this?\"\nSet the game plan. 1. Integration Type  specifies which AWS service will be accepting or affected\n    by this request. The vast majority of the time, this will be Lambda. If\n    you're wondering why other AWS Services aren't present, this has been made\n    intentional over time as just about any AWS service you can interact with\n    will still need logic to do anything useful: you can't just shove a JSON\n    object in a database's face and expect to get results. Unless you're using\n    MongoDB or something.\n 2. Lambda Proxies  are generally a bad idea. They auto-format your Lambda's \n    request  and response  body to follow a very  specific structure, which is\n    presumably intended to help speed up or standardize development. The\n    downside is these structures are bloated and most likely contain useless\n    information. To get an idea of what these structures look like, check them\n    out here.\n 3. The Region  your Lambda hosted lives in.\n 4. Name of the Lamba Function  your request will be directed to.\n 5. Execution role  refers to the IAM role your Lambda policy will be a part of.\n    This is kind of an obnoxious concept, but your function has permissions as\n    though it were a user. This is presumably Amazon's way of thinking ahead to\n    extending human rights to robots.\n 6. Caller Credentials  refers to API keys, assuming you chose to use them. If\n    this is checked, the API will not be usable without an API key, thus making\n    it difficult to test\n 7. Credentials Cache  probably refers to expiring credentials or something, I'm\n    sure you'll figure it out.\n 8. Timeout  can be increased if you're dealing with an API call that takes a\n    lot of time to respond, such as occasions with heavy data sets.\n 9. URL Paths probably do something, I don't know. Who really cares?\n\nINTERMISSION: The Part Where Things Happen\nThe next step in the flow would be where the AWS service we selected to handle\nthe request would do its thing. We'll get into that next time.\n\nResponse Codes and Headers\nKeep it 200 baby. 1. While AWS provides users with standard error codes  and generic errors, you\n    can add your own specific error/success messages. Props to whoever puts in\n    the effort.\n 2. Header Mappings  are the headings returned with the response. For example,\n    this is where you might solve cross-domain issues via the \n    Access-Control-Allow-Origin  header.\n\n3. Mapping Templates  are the Content-Type  of the response returned, most\ncommonly application/json.\n\nMethod Response\nI almost never spend time hereThis step is a continuation of the previous step.\nI'm not entirely sure what the point in splitting this into two screens is, but\nI'm guessing its not important.\n\nReap Your Rewards\nAt long last, this brings us to the end of our journey. This is presumably where\n you've executed a successful AWS test or something. However, there's a final\nstep before you go live; deploying your API:\n\nDeploy your API to a live \"stage\" and retire.Next time we'll cover the logical,\nless boring part of writing actual code behind these endpoints.","html":"<p>In our last adventure, we ventured off to create our very own cloud <a href=\"https://hackersandslackers.com/setting-up-mysql-on-aws/\">database</a> by using Amazon's <strong>RDS</strong> service. We've also <a href=\"https://hackersandslackers.com/building-an-api-using-aws/\">briefly covered</a> the general concept behind what <strong>Lambda functions</strong>. In case you've already forgotten, Lambdas are basically just chunks of code in the cloud; think of them as tiny virtual servers, which have already been configured (and locked down) to serve one specific purpose. Because that's literally what it is.</p><p>The data being stored in <strong>RDS </strong>is ultimately what we're targeting, and <strong>Lambdas</strong> serve as the in-between logic to serve up, modify, or add to the proper data. The only piece missing from the picture is <strong>API Gateway</strong>. </p><p>As the name suggests, <strong>API Gateway</strong> is the, uh, <em>gateway</em> that users or systems interact with to obtain what they're seeking. It is (hopefully) the only part of this VPC structure an external user can interact with:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/apigateway_o-1.jpg\" class=\"kg-image\"><figcaption>Simple API to interact with RDS.</figcaption></figure><p>Serving as a \"gateway\" is obviously what all APIs so, but the term is also true in the sense that <strong>API Gateway</strong> is completely configured via UI, thus engineers of any programming background can safely modify <em>endpoints</em>, <em>methods,</em> <em>CORs</em> configurations, or any of the high-level API structure without being locked into a programming language. <strong>API Gateway</strong> is therefore very much an enterprise-geared product: it lends itself to large teams and scaling. That said, if it were to be compared to building an API via a framework designed to do such things (such as Express or Flask) the experience is undoubtedly more clunky. The trade-off being made for speed is immediate visibility, assurance, and a higher chance for collaboration.</p><h2 id=\"the-challenge-of-building-a-well-designed-api\">The Challenge of Building a \"Well-Designed\" API</h2><p>Good APIs are premeditated. A complex API might accept multiple methods per endpoint, allow advanced filtering of results, or handle advanced Authentication. Neither of us have the time to attempt covering all of those things in detail, but I <em>will</em> leave you with the knowledge that all these features are very much possible.  </p><p>The <strong>API Gateway</strong> interface is where you'd get started. Let's blow through the world's most inappropriately fast explanation of building APIs ever ,and check out the UI:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-5.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/apigateway_overview3.png\" class=\"kg-image\"><figcaption>It ain't pretty, but it works.</figcaption></figure><ul><li>Your <strong>APIs </strong>are listed on the left. You can create more than one, if you're some sort of sadist.</li><li>The <strong>Resources </strong>pane is the full structure of your API. At the highest level, 'resources' refers to <strong>Endpoints,</strong> which are the URLs your API will ultimately expose.</li><li>Every <strong>Endpoint</strong> can contain whichever <strong>Methods</strong> you choose to associate with them (GET, POST, PUT, etc). Even if they belong to the same endpoint, a POST method could contain entirely unrelated logic from a PUT method: its your responsibility to make sure your API design makes sense.</li><li>Finally, each <strong>Method </strong>has their expected <strong>Request </strong>and <strong>Response</strong> structures defined individually, which what the horribly designed box diagram is attempting to explain on the right. The box on the left labeled CLIENT refers to the requester, where the box on the right represents the triggered action.</li></ul><p>This UI is your bread and butter. I hope you're strapped in, because walking through this interface is going to be hella boring for all of us.</p><h3 id=\"creating-a-method-request\">Creating a Method Request</h3><p>The first step to creating an endpoint (let's say a GET endpoint) is to set the expectation for what the user will send to us:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/methodrequest_o.jpg\" class=\"kg-image\"><figcaption>Awe yea, authorization.</figcaption></figure><ol><li><strong>Authorization</strong> allows you to restrict users from using your API unless they follow your IAM policy.</li><li><strong>Request Validator</strong> lets you chose if you'd like this validation to happen via the body, query string parameters, headers, or all of the above.</li><li><strong>API Keys</strong> are useful if you're creating an API to sell commercially or enforce limited access. If your business model revolves around selling an API, you can realistically do this.</li><li><strong>Query String Parameters</strong> are... actually forget it, you know this by now.</li><li>See above.</li><li>If preferred, the <strong>Request Body </strong>can be assigned a <strong>model,</strong> which is essentially a JSON schema. If a request is made to your endpoint which does not match the request body model, it is a malformed request. We'll cover <strong>models</strong> in the advanced course, once somebody actually starts paying me to write this stuff.</li></ol><h3 id=\"method-execution-aka-what-do-we-do-with-this\">Method Execution: AKA \"What do we do with this?\"</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/methodexecution_o.jpg\" class=\"kg-image\"><figcaption>Set the game plan.</figcaption></figure><ol><li><strong>Integration Type</strong> specifies which AWS service will be accepting or affected by this request. The vast majority of the time, this will be Lambda. If you're wondering why other AWS Services aren't present, this has been made intentional over time as just about any AWS service you can interact with will still need logic to do anything useful: you can't just shove a JSON object in a database's face and expect to get results. Unless you're using MongoDB or something.</li><li><strong>Lambda Proxies</strong> are generally a bad idea. They auto-format your Lambda's <em>request</em> and <em>response</em> body to follow a very  specific structure, which is presumably intended to help speed up or standardize development. The downside is these structures are bloated and most likely contain useless information. To get an idea of what these structures look like, check them out <a href=\"https://github.com/bbilger/jrestless/tree/master/aws/gateway/jrestless-aws-gateway-handler#response-schema\">here</a>.</li><li>The <strong>Region</strong> your Lambda hosted lives in.</li><li>Name of the <strong>Lamba Function</strong> your request will be directed to.</li><li><strong>Execution role</strong> refers to the IAM role your Lambda policy will be a part of. This is kind of an obnoxious concept, but your function has permissions as though it were a user. This is presumably Amazon's way of thinking ahead to extending human rights to robots.</li><li><strong>Caller Credentials</strong> refers to API keys, assuming you chose to use them. If this is checked, the API will not be usable without an API key, thus making it difficult to test</li><li><strong>Credentials Cache</strong> probably refers to expiring credentials or something, I'm sure you'll figure it out.</li><li><strong>Timeout</strong> can be increased if you're dealing with an API call that takes a lot of time to respond, such as occasions with heavy data sets.</li><li><strong>URL Paths </strong>probably do something, I don't know. Who really cares?</li></ol><h3 id=\"intermission-the-part-where-things-happen\">INTERMISSION: The Part Where Things Happen</h3><p>The next step in the flow would be where the AWS service we selected to handle the request would do its thing. We'll get into that next time.</p><h3 id=\"response-codes-and-headers\">Response Codes and Headers</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/response_o.jpg\" class=\"kg-image\"><figcaption>Keep it 200 baby.</figcaption></figure><ol><li>While AWS provides users with standard <strong>error codes</strong> and generic errors, you can add your own specific error/success messages. Props to whoever puts in the effort.</li><li><strong>Header Mappings</strong> are the headings returned with the response. For example, this is where you might solve cross-domain issues via the <em>Access-Control-Allow-Origin</em> header.</li></ol><p>3. <strong>Mapping Templates</strong> are the <em>Content-Type</em> of the response returned, most commonly <em>application/json.</em></p><h3 id=\"method-response\">Method Response</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-10-29-at-8.54.51-PM_o.png\" class=\"kg-image\"><figcaption>I almost never spend time here</figcaption></figure><p>This step is a continuation of the previous step. I'm not entirely sure what the point in splitting this into two screens is, but I'm guessing its not important.</p><h2 id=\"reap-your-rewards\">Reap Your Rewards</h2><p>At long last, this brings us to the end of our journey. This is presumably where  you've executed a successful AWS test or something. However, there's a final step before you go live; deploying your API:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-4.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/Screen-Shot-2018-10-29-at-9.02.52-PM_o.png\" class=\"kg-image\"><figcaption>Deploy your API to a live \"stage\" and retire.</figcaption></figure><p>Next time we'll cover the logical, less boring part of writing actual code behind these endpoints.</p>","url":"https://hackersandslackers.com/creating-apis-with-api-gateway/","uuid":"ce9c1023-431b-4580-b3ca-1a3e2074f9c5","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5af8ae23092feb404eb9981e"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb867371b","title":"Extract Nested Data From Complex JSON","slug":"extract-data-from-complex-json-python","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/10/107@2x.jpg","excerpt":"Never manually walk through complex JSON objects again by using this function.","custom_excerpt":"Never manually walk through complex JSON objects again by using this function.","created_at_pretty":"10 October, 2018","published_at_pretty":"10 October, 2018","updated_at_pretty":"22 January, 2019","created_at":"2018-10-10T00:15:29.000-04:00","published_at":"2018-10-10T08:00:00.000-04:00","updated_at":"2019-01-22T15:20:23.000-05:00","meta_title":"Extract Nested Data From Complex JSON Trees | Hackers and Slackers","meta_description":"Never manually walk through complex JSON objects again by using this function","og_description":"Never manually walk through complex JSON objects again by using this function","og_image":"https://hackersandslackers.com/content/images/2018/10/107@2x.jpg","og_title":"Extract Nested Data From Complex JSON Trees | Hackers and Slackers","twitter_description":"Never manually walk through complex JSON objects again by using this function","twitter_image":"https://hackersandslackers.com/content/images/2018/10/107@2x.jpg","twitter_title":"Extract Nested Data From Complex JSON Trees | Hackers and Slackers","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"Data Engineering","slug":"dataengineering","description":"The systematic collection and transformation of data via the creation of tools and pipelines.","feature_image":null,"meta_description":null,"meta_title":"Data Engineering | Hackers and Slackers","visibility":"public"}],"plaintext":"We're all data people here, so you already know the scenario: it happens perhaps\nonce a day, perhaps 5, or even more. There's an API you're working with, and\nit's great. It contains all the information you're looking for, but there's just\none problem: the complexity of nested JSON objects is endless, and suddenly the\njob you love needs to be put on hold to painstakingly retrieve the data you\nactually want, and it's 5 levels deep in a nested JSON hell. Nobody feels like\nmuch of a \"scientist\" or an \"engineer\" when half their day becomes dealing with\nkey value errors.\n\nLuckily, we code in Python!  (okay fine, language doesn't make much of a\ndifference here. It felt like a rallying call at the time).\n\nUsing Google Maps API as an Example\nTo visualize the problem, let's take an example somebody might actually want to\nuse.  I think the  Google Maps API is a good candidate to fit the bill here.\n\nWhile Google Maps is actually a collection of APIs, the Google Maps Distance\nMatrix [https://developers.google.com/maps/documentation/distance-matrix/start].\nThe idea is that with a single API call, a user can calculate the distance and\ntime traveled between an origin and an infinite number of destinations. It's a\ngreat full-featured API, but as you might imagine the resulting JSON for\ncalculating commute time between where you stand and every location in the\nconceivable universe  makes an awfully complex JSON structure.\n\nGetting a Taste of JSON Hell\nReal quick, here's an example of the types of parameters this request accepts:\n\nimport requests\nimport API_KEY\n\ndef google_api_matrix():\n    \"\"\"Example Google Distance Matrix function.\"\"\"\n    endpoint = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': 'New York City, NY',\n       'destinations': 'Philadelphia,PA',\n       'transit_mode': 'car'\n    }\n    r = requests.get(endpoint, params=params)\n    return r.json\n\n\nOne origin, one destination. The JSON response for a request this\nstraightforward is quite simple:\n\n{\n    \"destination_addresses\": [\n        \"Philadelphia, PA, USA\"\n    ],\n    \"origin_addresses\": [\n        \"New York, NY, USA\"\n    ],\n    \"rows\": [\n        {\n            \"elements\": [\n                {\n                    \"distance\": {\n                        \"text\": \"94.6 mi\",\n                        \"value\": 152193\n                    },\n                    \"duration\": {\n                        \"text\": \"1 hour 44 mins\",\n                        \"value\": 6227\n                    },\n                    \"status\": \"OK\"\n                }\n            ]\n        }\n    ],\n    \"status\": \"OK\"\n}\n\n\nFor each destination, we're getting two data points: the commute distance, and \nestimated duration. If we hypothetically wanted to extract those values, typing \nresponse['rows'][0]['elements']['distance']['test']  isn't too  crazy. I mean,\nit's somewhat awful and brings on casual thoughts of suicide, but nothing out of\nthe ordinary\n\nNow let's make things interesting by adding a few more stops on our trip:\n\nimport requests \nimport API_KEY\n\ndef google_api_matrix():\n    \"\"\"Example Google Distance Matrix function.\"\"\"\n    endpoint = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': 'New York City, NY',\n       'destinations': 'Washington,DC|Philadelphia,PA|Santa Barbara,CA|Miami,FL|Austin,TX|Napa County,CA',\n       'transit_mode': 'car'\n    }\n    r = requests.get(endpoint, params=params)\n    return r.json\n\n\nOh fuuucckkkk:\n\n{\n  \"destination_addresses\": [\n    \"Washington, DC, USA\",\n    \"Philadelphia, PA, USA\",\n    \"Santa Barbara, CA, USA\",\n    \"Miami, FL, USA\",\n    \"Austin, TX, USA\",\n    \"Napa County, CA, USA\"\n  ],\n  \"origin_addresses\": [\n    \"New York, NY, USA\"\n  ],\n  \"rows\": [\n    {\n      \"elements\": [\n        {\n          \"distance\": {\n            \"text\": \"227 mi\",\n            \"value\": 365468\n          },\n          \"duration\": {\n            \"text\": \"3 hours 54 mins\",\n            \"value\": 14064\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"94.6 mi\",\n            \"value\": 152193\n          },\n          \"duration\": {\n            \"text\": \"1 hour 44 mins\",\n            \"value\": 6227\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"2,878 mi\",\n            \"value\": 4632197\n          },\n          \"duration\": {\n            \"text\": \"1 day 18 hours\",\n            \"value\": 151772\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"1,286 mi\",\n            \"value\": 2069031\n          },\n          \"duration\": {\n            \"text\": \"18 hours 43 mins\",\n            \"value\": 67405\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"1,742 mi\",\n            \"value\": 2802972\n          },\n          \"duration\": {\n            \"text\": \"1 day 2 hours\",\n            \"value\": 93070\n          },\n          \"status\": \"OK\"\n        },\n        {\n          \"distance\": {\n            \"text\": \"2,871 mi\",\n            \"value\": 4620514\n          },\n          \"duration\": {\n            \"text\": \"1 day 18 hours\",\n            \"value\": 152913\n          },\n          \"status\": \"OK\"\n        }\n      ]\n    }\n  ],\n  \"status\": \"OK\"\n}\n\n\nA lot is happening here. There are objects. There are lists. There are lists of\nobjects which are part of an object. The last thing I'd want to deal with is\ntrying to parse this data only to accidentally get a useless key:value pair like\n \"status\": \"OK\".\n\nCode Snippet To The Rescue\nLet's say we only want the human-readable data from this JSON, which is labeled \n\"text\"  for both distance and duration. We've created a function below dubbed \nextract_values()  to help us resolve this very issue. The idea is that \nextract_values()  is flexible and agnostic, therefore can be imported as a\nmodule into any project you might need.\n\n# recursivejson.py\n\ndef extract_values(obj, key):\n    \"\"\"Pull all values of specified key from nested JSON.\"\"\"\n    arr = []\n\n    def extract(obj, arr, key):\n        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n        if isinstance(obj, dict):\n            for k, v in obj.items():\n                if isinstance(v, (dict, list)):\n                    extract(v, arr, key)\n                elif k == key:\n                    arr.append(v)\n        elif isinstance(obj, list):\n            for item in obj:\n                extract(item, arr, key)\n        return arr\n\n    results = extract(obj, arr, key)\n    return results\n\n\nWe need to pass this function two values:\n\n * A JSON object, such as r.json()  from an API request.\n * The name of the key  we're looking to extract values from.\n\nnames = extract_values('myjson.json', 'name')\nprint(names)\n\n\nRegardless of where the key \"text\"  lives in the JSON, this function returns\nevery value for the instance of \"key.\" Here's our function in action:\n\nimport requests\nimport API_KEY\nfrom recursivejson import extract_values\n\n\ndef google_api_matrix():\n    \"\"\"Example Google Distance Matrix function.\"\"\"\n    endpoint = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': \"New York City,NY\",\n       'destinations': \"Washington,DC|Philadelphia,PA|Santa Barbara,CA|Miami,FL|Austin,TX|Napa Valley,CA\",\n       'transit_mode': 'car',\n    }\n\n   r = requests.get(endpoint, params=params)\n   travel_values = extract_values(r.json(), 'text')\n   return travel_values\n\n\nRunning this function will result in the following output:\n\n['227 mi', '3 hours 54 mins', '94.6 mi', '1 hour 44 mins', '2,878 mi', '1 day 18 hours', '1,286 mi', '18 hours 43 mins', '1,742 mi', '1 day 2 hours', '2,871 mi', '1 day 18 hours']\n\n\nOh fiddle me timbers! Because the Google API alternates between distance and \ntrip duration, every other value alternates between distance and time (can we\npause to appreciate this horrible design? There are infinitely better ways to\nstructure this response). Never fear, some simple Python can help us split this\nlist into two lists:\n\nmy_values = extract_values(r.json(), 'text')\n\ndurations = my_values[1::2]\ndistances = my_values[2::1]\n\nprint('DURATIONS = ', durations)\nprint('DISTANCES = ', distances)\n\n\nThis will take our one list and split it in to two  lists, alternating between\neven and odd:\n\nDURATIONS = ['3 hours 54 mins', '1 hour 44 mins', '1 day 18 hours', '18 hours 43 mins', '1 day 2 hours', '1 day 18 hours']\nDISTANCES = ['94.6 mi', '1 hour 44 mins', '2,878 mi', '1 day 18 hours', '1,286 mi', '18 hours 43 mins', '1,742 mi', '1 day 2 hours', '2,871 mi', '1 day 18 hours']\n\n\nGetting Creative With Lists\nA common theme I run in to while extracting lists of values from JSON objects\nlike these is that the lists of values I extract are very much related.  In the\nabove example, for every duration  we have an accompanying distance, which is a\none-to-one basis. Imagine if we wanted to associate these values somehow?\n\nTo use a better example, I recently I used this exact_values()  function to\nextract lists of column names and their data types from a database schema. As\nseparate lists, the data looked something like this:\n\ncolumn_names = ['index', 'first_name', 'last_name', 'join_date']\ncolumn_datatypes = ['integer', 'string', 'string', 'date']\n\n\nClearly these two lists are directly related; the latter is describing the\nformer. How can this be useful? By using Python's zip  method!\n\nschema_dict = dict(zip(column_names, column_datatypes))\nprint(schema_dict)\n\n\nI like to think they call it zip  because it's like zipping up a zipper, where\neach side of the zipper is a list. This output a dictionary where list 1 serves\nas the keys, and list 2 serves as values:\n\n{\n'index': 'integer', \n'first_name': 'string', \n'last_name':'string',\n'join_date': 'date'\n}\n\n\nAnd there you have it folks: a free code snippet to copy and secretly pretend\nyou wrote forever. I've thrown the function up on Github Gists\n[https://gist.github.com/toddbirchard/b6f86f03f6cf4fc9492ad4349ee7ff8b], if such\na thing pleases you.\n\nIn the meantime, zip it up and zip it out. Zippity-do-da, buh bye.","html":"<p>We're all data people here, so you already know the scenario: it happens perhaps once a day, perhaps 5, or even more. There's an API you're working with, and it's great. It contains all the information you're looking for, but there's just one problem: the complexity of nested JSON objects is endless, and suddenly the job you love needs to be put on hold to painstakingly retrieve the data you actually want, and it's 5 levels deep in a nested JSON hell. Nobody feels like much of a \"scientist\" or an \"engineer\" when half their day becomes dealing with key value errors.</p><p>Luckily, we code in <strong><em>Python!</em></strong> (okay fine, language doesn't make much of a difference here. It felt like a rallying call at the time).</p><h2 id=\"using-google-maps-api-as-an-example\">Using Google Maps API as an Example</h2><p>To visualize the problem, let's take an example somebody might actually want to use.  I think the<strong> Google Maps API </strong>is a good candidate to fit the bill here.</p><p>While Google Maps is actually a collection of APIs, the <a href=\"https://developers.google.com/maps/documentation/distance-matrix/start\">Google Maps Distance Matrix</a>. The idea is that with a single API call, a user can calculate the distance and time traveled between an origin and an infinite number of destinations. It's a great full-featured API, but as you might imagine the resulting JSON for calculating commute time between where you stand and <em>every location in the conceivable universe</em> makes an awfully complex JSON structure.</p><h3 id=\"getting-a-taste-of-json-hell\">Getting a Taste of JSON Hell</h3><p>Real quick, here's an example of the types of parameters this request accepts:</p><pre><code class=\"language-python\">import requests\nimport API_KEY\n\ndef google_api_matrix():\n    &quot;&quot;&quot;Example Google Distance Matrix function.&quot;&quot;&quot;\n    endpoint = &quot;https://maps.googleapis.com/maps/api/distancematrix/json&quot;\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': 'New York City, NY',\n       'destinations': 'Philadelphia,PA',\n       'transit_mode': 'car'\n    }\n    r = requests.get(endpoint, params=params)\n    return r.json\n</code></pre>\n<p>One origin, one destination. The JSON response for a request this straightforward is quite simple:</p><pre><code class=\"language-json\">{\n    &quot;destination_addresses&quot;: [\n        &quot;Philadelphia, PA, USA&quot;\n    ],\n    &quot;origin_addresses&quot;: [\n        &quot;New York, NY, USA&quot;\n    ],\n    &quot;rows&quot;: [\n        {\n            &quot;elements&quot;: [\n                {\n                    &quot;distance&quot;: {\n                        &quot;text&quot;: &quot;94.6 mi&quot;,\n                        &quot;value&quot;: 152193\n                    },\n                    &quot;duration&quot;: {\n                        &quot;text&quot;: &quot;1 hour 44 mins&quot;,\n                        &quot;value&quot;: 6227\n                    },\n                    &quot;status&quot;: &quot;OK&quot;\n                }\n            ]\n        }\n    ],\n    &quot;status&quot;: &quot;OK&quot;\n}\n</code></pre>\n<p>For each destination, we're getting two data points: the <em>commute distance</em>, and <em>estimated duration</em>. If we hypothetically wanted to extract those values, typing <code>response['rows'][0]['elements']['distance']['test']</code> isn't <em>too</em> crazy. I mean, it's somewhat awful and brings on casual thoughts of suicide, but nothing out of the ordinary</p><p>Now let's make things interesting by adding a few more stops on our trip:</p><pre><code class=\"language-python\">import requests \nimport API_KEY\n\ndef google_api_matrix():\n    &quot;&quot;&quot;Example Google Distance Matrix function.&quot;&quot;&quot;\n    endpoint = &quot;https://maps.googleapis.com/maps/api/distancematrix/json&quot;\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': 'New York City, NY',\n       'destinations': 'Washington,DC|Philadelphia,PA|Santa Barbara,CA|Miami,FL|Austin,TX|Napa County,CA',\n       'transit_mode': 'car'\n    }\n    r = requests.get(endpoint, params=params)\n    return r.json\n</code></pre>\n<p>Oh fuuucckkkk:</p><pre><code class=\"language-json\">{\n  &quot;destination_addresses&quot;: [\n    &quot;Washington, DC, USA&quot;,\n    &quot;Philadelphia, PA, USA&quot;,\n    &quot;Santa Barbara, CA, USA&quot;,\n    &quot;Miami, FL, USA&quot;,\n    &quot;Austin, TX, USA&quot;,\n    &quot;Napa County, CA, USA&quot;\n  ],\n  &quot;origin_addresses&quot;: [\n    &quot;New York, NY, USA&quot;\n  ],\n  &quot;rows&quot;: [\n    {\n      &quot;elements&quot;: [\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;227 mi&quot;,\n            &quot;value&quot;: 365468\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;3 hours 54 mins&quot;,\n            &quot;value&quot;: 14064\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;94.6 mi&quot;,\n            &quot;value&quot;: 152193\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;1 hour 44 mins&quot;,\n            &quot;value&quot;: 6227\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;2,878 mi&quot;,\n            &quot;value&quot;: 4632197\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;1 day 18 hours&quot;,\n            &quot;value&quot;: 151772\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;1,286 mi&quot;,\n            &quot;value&quot;: 2069031\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;18 hours 43 mins&quot;,\n            &quot;value&quot;: 67405\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;1,742 mi&quot;,\n            &quot;value&quot;: 2802972\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;1 day 2 hours&quot;,\n            &quot;value&quot;: 93070\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        },\n        {\n          &quot;distance&quot;: {\n            &quot;text&quot;: &quot;2,871 mi&quot;,\n            &quot;value&quot;: 4620514\n          },\n          &quot;duration&quot;: {\n            &quot;text&quot;: &quot;1 day 18 hours&quot;,\n            &quot;value&quot;: 152913\n          },\n          &quot;status&quot;: &quot;OK&quot;\n        }\n      ]\n    }\n  ],\n  &quot;status&quot;: &quot;OK&quot;\n}\n</code></pre>\n<p>A lot is happening here. There are objects. There are lists. There are lists of objects which are part of an object. The last thing I'd want to deal with is trying to parse this data only to accidentally get a useless key:value pair like <strong>\"status\": \"OK\".</strong></p><h2 id=\"code-snippet-to-the-rescue\">Code Snippet To The Rescue</h2><p>Let's say we only want the human-readable data from this JSON, which is labeled <em>\"text\"</em> for both distance and duration. We've created a function below dubbed <code>extract_values()</code> to help us resolve this very issue. The idea is that <code>extract_values()</code> is flexible and agnostic, therefore can be imported as a module into any project you might need.</p><pre><code class=\"language-python\"># recursivejson.py\n\ndef extract_values(obj, key):\n    &quot;&quot;&quot;Pull all values of specified key from nested JSON.&quot;&quot;&quot;\n    arr = []\n\n    def extract(obj, arr, key):\n        &quot;&quot;&quot;Recursively search for values of key in JSON tree.&quot;&quot;&quot;\n        if isinstance(obj, dict):\n            for k, v in obj.items():\n                if isinstance(v, (dict, list)):\n                    extract(v, arr, key)\n                elif k == key:\n                    arr.append(v)\n        elif isinstance(obj, list):\n            for item in obj:\n                extract(item, arr, key)\n        return arr\n\n    results = extract(obj, arr, key)\n    return results\n</code></pre>\n<p>We need to pass this function two values:</p><ul><li>A JSON object, such as <code>r.json()</code> from an API request.</li><li>The name of the <strong>key</strong> we're looking to extract values from.</li></ul><pre><code class=\"language-python\">names = extract_values('myjson.json', 'name')\nprint(names)\n</code></pre>\n<p>Regardless of where the key <strong>\"text\"</strong> lives in the JSON, this function returns every value for the instance of <strong>\"key.\" </strong>Here's our function in action:</p><pre><code class=\"language-python\">import requests\nimport API_KEY\nfrom recursivejson import extract_values\n\n\ndef google_api_matrix():\n    &quot;&quot;&quot;Example Google Distance Matrix function.&quot;&quot;&quot;\n    endpoint = &quot;https://maps.googleapis.com/maps/api/distancematrix/json&quot;\n    params = {\n       'units': 'imperial',\n       'key': API_KEY,\n       'origins': &quot;New York City,NY&quot;,\n       'destinations': &quot;Washington,DC|Philadelphia,PA|Santa Barbara,CA|Miami,FL|Austin,TX|Napa Valley,CA&quot;,\n       'transit_mode': 'car',\n    }\n\n   r = requests.get(endpoint, params=params)\n   travel_values = extract_values(r.json(), 'text')\n   return travel_values\n</code></pre>\n<p>Running this function will result in the following output:</p><pre><code class=\"language-python\">['227 mi', '3 hours 54 mins', '94.6 mi', '1 hour 44 mins', '2,878 mi', '1 day 18 hours', '1,286 mi', '18 hours 43 mins', '1,742 mi', '1 day 2 hours', '2,871 mi', '1 day 18 hours']\n</code></pre>\n<p>Oh <em>fiddle me timbers</em>! Because the Google API alternates between <strong>distance </strong>and <strong>trip duration</strong>, every other value alternates between distance and time (can we pause to appreciate this horrible design? There are infinitely better ways to structure this response). Never fear, some simple Python can help us split this list into two lists:</p><pre><code class=\"language-python\">my_values = extract_values(r.json(), 'text')\n\ndurations = my_values[1::2]\ndistances = my_values[2::1]\n\nprint('DURATIONS = ', durations)\nprint('DISTANCES = ', distances)\n</code></pre>\n<p>This will take our one list and split it in to <em>two</em> lists, alternating between even and odd:</p><pre><code class=\"language-python\">DURATIONS = ['3 hours 54 mins', '1 hour 44 mins', '1 day 18 hours', '18 hours 43 mins', '1 day 2 hours', '1 day 18 hours']\nDISTANCES = ['94.6 mi', '1 hour 44 mins', '2,878 mi', '1 day 18 hours', '1,286 mi', '18 hours 43 mins', '1,742 mi', '1 day 2 hours', '2,871 mi', '1 day 18 hours']\n</code></pre>\n<h2 id=\"getting-creative-with-lists\">Getting Creative With Lists</h2><p>A common theme I run in to while extracting lists of values from JSON objects like these is that the lists of values I extract are very much related.  In the above example, for every <em>duration</em> we have an accompanying <em>distance, </em>which is a one-to-one basis. Imagine if we wanted to associate these values somehow?</p><p>To use a better example, I recently I used this <code>exact_values()</code> function to extract lists of column names and their data types from a database schema. As separate lists, the data looked something like this:</p><pre><code class=\"language-python\">column_names = ['index', 'first_name', 'last_name', 'join_date']\ncolumn_datatypes = ['integer', 'string', 'string', 'date']\n</code></pre>\n<p>Clearly these two lists are directly related; the latter is describing the former. How can this be useful? By using Python's <code>zip</code> method!</p><pre><code class=\"language-python\">schema_dict = dict(zip(column_names, column_datatypes))\nprint(schema_dict)\n</code></pre>\n<p>I like to think they call it <em>zip</em> because it's like zipping up a zipper, where each side of the zipper is a list. This output a dictionary where list 1 serves as the keys, and list 2 serves as values:</p><pre><code class=\"language-python\">{\n'index': 'integer', \n'first_name': 'string', \n'last_name':'string',\n'join_date': 'date'\n}\n</code></pre>\n<p>And there you have it folks: a free code snippet to copy and secretly pretend you wrote forever. I've thrown the function up on <a href=\"https://gist.github.com/toddbirchard/b6f86f03f6cf4fc9492ad4349ee7ff8b\">Github Gists</a>, if such a thing pleases you.</p><p>In the meantime, zip it up and zip it out. Zippity-do-da, buh bye.</p>","url":"https://hackersandslackers.com/extract-data-from-complex-json-python/","uuid":"9a494df4-9e13-45ed-8648-efdda21c55a4","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5bbd7ce1b936605163ece407"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736d2","title":"Recreate JIRA Service Desk in Python & Flask","slug":"building-a-better-jira","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/jsd@2x.jpg","excerpt":"When SaaS doesn't cut it, beat it down and take everything its got.","custom_excerpt":"When SaaS doesn't cut it, beat it down and take everything its got.","created_at_pretty":"11 August, 2018","published_at_pretty":"31 August, 2018","updated_at_pretty":"02 February, 2019","created_at":"2018-08-11T14:02:52.000-04:00","published_at":"2018-08-31T10:25:00.000-04:00","updated_at":"2019-02-02T05:11:05.000-05:00","meta_title":"When SaaS doesn't cut it, beat it down and take everything its got | Hackers And Slackers","meta_description":"Vanilla helpdesks tend to dehumanize customers. We all think we're special, but a cold support queue reminds us otherwise. We can build something  better.","og_description":"Vanilla helpdesks tend to dehumanize customers. We all think we're special, but a cold support queue reminds us otherwise. We can build something  better.","og_image":"https://hackersandslackers.com/content/images/2018/08/jsd@2x.jpg","og_title":"Recreate JIRA Service Desk in Python & Flask","twitter_description":"Vanilla helpdesks tend to dehumanize customers. We all think we're special, but a cold support queue reminds us otherwise. We can build something  better.","twitter_image":"https://hackersandslackers.com/content/images/2018/08/jsd@2x.jpg","twitter_title":"Recreate JIRA Service Desk in Python & Flask","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Atlassian","slug":"atlassian","description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","feature_image":null,"meta_description":"Beef up JIRA and Confluence by scripting and automating nearly anything. Empower teams with customized workflows and philosophies.","meta_title":"Atlassian Development for JIRA and Confluence. | Hackers and Slackers","visibility":"public"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"Flask","slug":"flask","description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/flaskroutes-2-1_o.jpg","meta_description":"All things Flask ranging from core framework to all conceivable libraries. Tips on how to utilize Flask’s flexibility to create expressive applications.","meta_title":"Building Python Apps in Flask | Hackers and Slackers","visibility":"public"},{"name":"Software Development","slug":"software-development","description":"General software development principals and tools. Receive insights applicable to building any application.","feature_image":null,"meta_description":"General software development principals and tools. Receive insights applicable to building any application.","meta_title":"Software Development | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"}],"plaintext":"When it comes to SaaS products in the realm of Service desks, JIRA Service Desk\nis at the very least, just as powerful as the next solution (Zendesk comes to\nmind). This naturally begs the question: Why is JIRA Service Desk's pricing\nmodel roughly 1/10th of that of it's competitor?\n\nThe answer lies within ease of use,  but more importantly, presentation. While\nAtlassian's cloud offering is slowly playing catchup, Atlassian as a company has\nnever quite seemed to nail down the importance of a friendly user interface, nor\nthe importance of this when it comes to worldwide adoption. To see what I mean,\nhere's an example that Atlassian themselves tout on their own documentation as a\n\"ready for production\" customer portal:\n\nI'm convinced this is purposefully hideous to force the purchase of plugins.To\nyour average software developer (Atlassian's core demographic for years), one\nmight see nothing wrong with this interface, but as somebody `who has rolled out\nover 30 of these desks for over 6 thousand people, layouts such as these commit\nnumerous UI atrocities which simply are not acceptable for top enterprise\nsoftware.\n\nWhat do we do about this? We build an alternative, of course.\n\nMethod to This Madness\nOur focus is not on JIRA as a product,  but rather an API. Instead of attempting\nto work within JIRA’s boundaries via customization or add-ons, we can take\nmatters into our own hands by owning the application that users use to interact\nwith a JIRA instance. By using the JIRA API, we can not only extend features but\nactually ‘rebuild’ the application to gain full control over the UI or\nadditional logic. JIRA is a hideous yet entirely necessary Java application,\nwhich makes it a perfect candidate for recreation.\n\nWe're going to use Flask for this. Shocking, I know. Here's the obligatory file\nstructure of our project:\n\nmyproject\n├─ app.py\n├─ jira.py\n├─ /static\n│  └─ js\n│  └─ less\n│  └─ img\n└─ /templates\n   └─ layout.html\n   └─ index.html\n\n\nThis tutorial will be working against the JIRA Server  API for Service Desk -\nthat said, Cloud users should still find this applicable.\n\nPulling Your Service Desk Form\nBefore we get nuts building our application, we’ll need to be sure that a\nService Desk already exists in JIRA with our expected intake form. Remember: our\nend goal is to simply consume JIRA as an API, but that entails interacting with\nsomething that exists in the first place.\n\nWith your Service Desk created, there’s one annoyance we need to resolve before\ngetting into code: determining your Service Desk’s ID number. Like most things\nin JIRA, Service Desks are identified by an ID which is simply an arbitrary\ngrouping of integers in some way. What is the official way to find this ID, you\nmight ask? Why, by extracting it from the portal’s URL or by inspecting your XHR\nrequests, of course! Remember: JIRA hates you, that’s why we’re doing this in\nthe first place.\n\nWith your Service Desk ID handy, we can finally break into retrieving our desk\nvia the Service Desk API:\n\nimport requests\nfrom jira_config import jira_username, jira_password\n\nrequest_types_endpoint = \"https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/\"\n\nheaders = {'Content-Type': 'application/json'}\n\ndef fieldsPerRequest(id):\n    \"\"\"Get form fields per request type.\"\"\"\n    r = requests.get(request_types_endpoint + id + '/field', auth=(jira_username, jira_password), headers=headers)\n    form = r.json()\n    return form\n\n\ndef serviceDeskRequestTypes():\n    \"\"\"Get request types.\"\"\"\n    request_array = []\n    r = requests.get(request_types_endpoint, auth=(jira_username, jira_password), headers=headers)\n    for requesttype in r.json()['values']:\n        id = requesttype['id']\n        request_dict = {\n            'name': requesttype['name'],\n            'description': requesttype['description'],\n            'icon': requesttype['icon']['_links']['iconUrls']['32x32'],\n            'fields': fieldsPerRequest(id)\n        }\n        request_array.append(request_dict)\n    return request_array\n\n\nserviceDeskRequestTypes()\nBy using the request_types_endpoint  URL, our function serviceDeskRequestTypes() \n returns the request types  of a given JIRA service desk; or in other words, the\n types of requests users can submit.  This alone only gives us high-level\ninformation about the types of requests we allow but doesn't go into further\ndetail such as the actual resulting form. That's where our next function comes\nin.\n\nfieldsPerRequest()\nThis function gets passed the ID of each request type. With that, we extend our\nendpoint to look like \n'https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/[REQUESTID]/field'\n. Looping through each request type gives up exactly what we need: every request\ntype and every form field per request type.\n\nuserSession()\nThere's another thing left to consider: what if the user isn't currently logged\nin to JIRA? At the very least, we need to check to see if a JIRA session is\nactive:\n\nuser_session_endpoint = 'https://jira.we.co/rest/auth/1/session'\n\ndef getUserSession():\n    \"\"\"Get logged-in user.\"\"\"\n    r = requests.get(user_session_endpoint, headers=headers)\n    if r.status_code == 200:\n        return r.json()\n    else:\n        return False\n\n\nIf the user is logged in to JIRA, we'll receive a 200 code letting us know\neverything is alright. The body of the response will also contain the name of\nthe user plus some extra metadata. What if the user isn't  logged in? Let's get\nto that in a bit.\n\nEasy Routing\nOur view will be nice and simple:\n\nfrom jira import request_forms, user_details\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    \"\"\"Landing page.\"\"\"\n    if user_details == False:\n        return redirect('https://example.com')\n    else:\n        return render_template('/index.html', requests=request_forms)\n\n\nNotice that all we're doing is making sure the user is signed in to JIRA. But\nwhat's with the example.com, you ask? Well, because I'm leaving this part up to\nyou, dear friend. There's really a number of things we can do, but it depends\nentirely on your situation. For instance:\n\n * You can handle basic auth on your own\n * Register an OAuth application to handle sign-ins (perhaps the most robust\n   solution)\n * If your JIRA instance is behind SSO, you may want to send users to your\n   company's  SAML partner\n * Simply throw an error message\n\nWhatever you decide to do, it's not really my problem. Obligatory smiley face\nemoji :).\n\nThe Template\nRemember: the main reason most of you are probably doing this is to control the\npresentation layer as you see fit. That said, here comes a call of presentation\nlayer text, in the form of a Jinja template:\n\n{% block form %}\n  <div>\n    <h3 class=\"subtitle\">Submit new requests here</h3>\n    <ul class=\"collapsible\">\n      {% for request in requests %}\n      <li class=\"{{request.name}}\">\n        <div class=\"collapsible-header\">\n          <img src=\"{{request.icon}}\">\n          <div class=\"info\">\n            <h5>{{request.name}}</h5>\n            <p>{{request.description}}</p>\n          </div>\n        </div>\n        <div class=\"collapsible-body\">\n          <div class=\"row\">\n            <form method=\"post\">\n              <div>\n                {% for field in request.fields.requestTypeFields %}\n                  {% if field.name in ('Category', 'Product') %}\n                    <div class=\"input-field\">\n                      <select id=\"{{request.name}} {{field.name}}\">\n                        <option value=\"Choose your option\" disabled selected>Choose your option</option>\n                        {% for option in field.validValues %}\n                          <option value=\"{{option.label}}\">{{option.label}}</option>\n                        {% endfor %}\n                      </select>\n                      <label>{{field.name}}</label>\n                    </div>\n                  {% elif field.name == 'Description' %}\n                    <div class=\"input-field\">\n                      <textarea id=\"{{field.name}}\" class=\"materialize-textarea\" placeholder=\"{{field.description}}\"></textarea>\n                      <label for=\"{{request.name}} {{field.name}}\">{{field.name}}</label>\n                    </div>\n                  {% else %}\n                    <div class=\"input-field\">\n                      <input placeholder=\"{{field.description}}\" id=\"{{request.name}} {{field.name}}\" type=\"text\" class=\"validate\">\n                      <label for=\"{{request.name}} {{field.name}}\">{{field.name}}</label>\n                    </div>\n                  {% endif %}\n                {% endfor %}\n                <input type=\"button\" value=\"Submit\" class=\"btn cyan lighten-3 formsubmit\">\n              </div>\n            </form>\n          </div>\n        </div>\n      </li>\n      {% endfor %}\n    </ul>\n  </div>\n{% endblock %}\n\n\nBecause we passed the Service Desk JSON we extracted from the JIRA API to our\nform, we can go crazy setting our labels, placeholder text, or whatever,\nanywhere we please. In my example, I utilize Material Design\n[https://materializecss.com/]'s pretty package of pre-made frontend elements,\nbecause God knows nobody wants to deal with designing that shit. Sorry, I was\njust having a brief flashback to Frontend dev.\n\nThe code above explicitly looks for fields we know are dropdowns, so that we may\nfill the select options accordingly. Same goes for textarea fields. That said,\nthe way I've handled this above is, well, stupid. Instead of hardcoding if\nstatements to look for certain fields, leverage our JSON to determine the type\nof each field as you iterate over them. Do as I say, not as I do.\n\nGoing Further\nThere's so much more we can add here. Take a list of the user's opened tickets,\nfor instance. The great thing about controlling your own portal UI is that you\ncan now control the narrative of your own workload: perhaps the person in\nmarketing who started 2 weeks ago could benefit from seeing the 200 tickets\nbeing addressed before her, thus second-guessing the urge to type URGENT across\na subject line only to be violently shoved down your throat.\n\nIn all seriousness, nobody likes the experience of a vanilla helpdesk because it\ndehumanizes the customer. While our personal beliefs reassure us that we are\nspecial, entering a cold support queue is a stark suggestion that we may not be\nso special after all, which isn't exactly a fact Millennials or Executives like\nto ponder on. If nothing else, take this as a chance to build software friendly\ntowards humans with full transparency, and both parties will surely benefit.\nRemember: happy humans bides times for the inevitable robot revolution on the\nhorizon destined to eradicate mankind. Do your part!","html":"<p>When it comes to SaaS products in the realm of Service desks, JIRA Service Desk is at the very <em>least</em>, just as powerful as the next solution (Zendesk comes to mind). This naturally begs the question: Why is JIRA Service Desk's pricing model roughly 1/10th of that of it's competitor?</p><p>The answer lies within <em>ease of use,</em> but more importantly, <em>presentation</em>. While Atlassian's cloud offering is slowly playing catchup, Atlassian as a company has never quite seemed to nail down the importance of a friendly user interface, nor the importance of this when it comes to worldwide adoption. To see what I mean, here's an example that Atlassian themselves tout on their own documentation as a \"ready for production\" customer portal:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-2.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/customer-portal.png\" class=\"kg-image\"><figcaption>I'm convinced this is purposefully hideous to force the purchase of plugins.</figcaption></figure><p>To your average software developer (Atlassian's core demographic for years), one might see nothing wrong with this interface, but as somebody `who has rolled out over 30 of these desks for over 6 thousand people, layouts such as these commit numerous UI atrocities which simply are not acceptable for top enterprise software.</p><p>What do we do about this? We build an alternative, of course.</p><h2 id=\"method-to-this-madness\">Method to This Madness</h2><p>Our focus is not on JIRA as a <em>product,</em> but rather an <em>API. </em>Instead of attempting to work within JIRA’s boundaries via customization or add-ons, we can take matters into our own hands by owning the application that users use to interact with a JIRA instance. By using the JIRA API, we can not only extend features but actually ‘rebuild’ the application to gain full control over the UI or additional logic. JIRA is a hideous yet entirely necessary Java application, which makes it a perfect candidate for recreation.</p><p>We're going to use Flask for this. Shocking, I know. Here's the obligatory file structure of our project:</p><pre><code class=\"language-bash\">myproject\n├─ app.py\n├─ jira.py\n├─ /static\n│  └─ js\n│  └─ less\n│  └─ img\n└─ /templates\n   └─ layout.html\n   └─ index.html\n</code></pre>\n<p>This tutorial will be working against the JIRA <em>Server</em> API for Service Desk - that said, Cloud users should still find this applicable.</p><h2 id=\"pulling-your-service-desk-form\">Pulling Your Service Desk Form</h2><p>Before we get nuts building our application, we’ll need to be sure that a Service Desk already exists in JIRA with our expected intake form. Remember: our end goal is to simply consume JIRA as an API, but that entails interacting with something that exists in the first place.</p><p>With your Service Desk created, there’s one annoyance we need to resolve before getting into code: determining your Service Desk’s ID number. Like most things in JIRA, Service Desks are identified by an ID which is simply an arbitrary grouping of integers in some way. What is the official way to find this ID, you might ask? Why, by extracting it from the portal’s URL or by inspecting your XHR requests, of course! Remember: JIRA hates you, that’s why we’re doing this in the first place.</p><p>With your Service Desk ID handy, we can finally break into retrieving our desk via the Service Desk API:</p><pre><code class=\"language-python\">import requests\nfrom jira_config import jira_username, jira_password\n\nrequest_types_endpoint = &quot;https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/&quot;\n\nheaders = {'Content-Type': 'application/json'}\n\ndef fieldsPerRequest(id):\n    &quot;&quot;&quot;Get form fields per request type.&quot;&quot;&quot;\n    r = requests.get(request_types_endpoint + id + '/field', auth=(jira_username, jira_password), headers=headers)\n    form = r.json()\n    return form\n\n\ndef serviceDeskRequestTypes():\n    &quot;&quot;&quot;Get request types.&quot;&quot;&quot;\n    request_array = []\n    r = requests.get(request_types_endpoint, auth=(jira_username, jira_password), headers=headers)\n    for requesttype in r.json()['values']:\n        id = requesttype['id']\n        request_dict = {\n            'name': requesttype['name'],\n            'description': requesttype['description'],\n            'icon': requesttype['icon']['_links']['iconUrls']['32x32'],\n            'fields': fieldsPerRequest(id)\n        }\n        request_array.append(request_dict)\n    return request_array\n</code></pre>\n<h3 id=\"servicedeskrequesttypes-\">serviceDeskRequestTypes()</h3><p>By using the <em>request_types_endpoint</em> URL, our function <code>serviceDeskRequestTypes()</code> returns the <strong>request types</strong> of a given JIRA service desk; or in other words, the <em>types of requests users can submit.</em> This alone only gives us high-level information about the types of requests we allow but doesn't go into further detail such as the actual resulting form. That's where our next function comes in.</p><h3 id=\"fieldsperrequest-\">fieldsPerRequest()</h3><p>This function gets passed the ID of each request type. With that, we extend our endpoint to look like <code>'https://yourjirainstance.com/rest/servicedeskapi/servicedesk/[SERVICEDESKID]/requesttype/[REQUESTID]/field'</code>. Looping through each request type gives up exactly what we need: every request type and every form field per request type.</p><h3 id=\"usersession-\">userSession()</h3><p>There's another thing left to consider: what if the user isn't currently logged in to JIRA? At the very least, we need to check to see if a JIRA session is active:</p><pre><code class=\"language-python\">user_session_endpoint = 'https://jira.we.co/rest/auth/1/session'\n\ndef getUserSession():\n    &quot;&quot;&quot;Get logged-in user.&quot;&quot;&quot;\n    r = requests.get(user_session_endpoint, headers=headers)\n    if r.status_code == 200:\n        return r.json()\n    else:\n        return False\n</code></pre>\n<p>If the user is logged in to JIRA, we'll receive a 200 code letting us know everything is alright. The body of the response will also contain the name of the user plus some extra metadata. What if the user <em>isn't</em> logged in? Let's get to that in a bit.</p><h2 id=\"easy-routing\">Easy Routing</h2><p>Our view will be nice and simple:</p><pre><code class=\"language-python\">from jira import request_forms, user_details\n\n@app.route('/', methods=['GET', 'POST', 'OPTIONS'])\ndef home():\n    &quot;&quot;&quot;Landing page.&quot;&quot;&quot;\n    if user_details == False:\n        return redirect('https://example.com')\n    else:\n        return render_template('/index.html', requests=request_forms)\n</code></pre>\n<p>Notice that all we're doing is making sure the user is signed in to JIRA. But what's with the <em>example.com</em>, you ask? Well, because I'm leaving this part up to you, dear friend. There's really a number of things we can do, but it depends entirely on your situation. For instance:</p><ul><li>You can handle basic auth on your own</li><li>Register an OAuth application to handle sign-ins (perhaps the most robust solution)</li><li>If your JIRA instance is behind SSO, you may want to send users to your company's  SAML partner</li><li>Simply throw an error message</li></ul><p>Whatever you decide to do, it's not really my problem. Obligatory smiley face emoji :).</p><h2 id=\"the-template\">The Template</h2><p>Remember: the main reason most of you are probably doing this is to control the presentation layer as you see fit. That said, here comes a call of presentation layer text, in the form of a Jinja template:</p><pre><code class=\"language-jinja\">{% block form %}\n  &lt;div&gt;\n    &lt;h3 class=&quot;subtitle&quot;&gt;Submit new requests here&lt;/h3&gt;\n    &lt;ul class=&quot;collapsible&quot;&gt;\n      {% for request in requests %}\n      &lt;li class=&quot;{{request.name}}&quot;&gt;\n        &lt;div class=&quot;collapsible-header&quot;&gt;\n          &lt;img src=&quot;{{request.icon}}&quot;&gt;\n          &lt;div class=&quot;info&quot;&gt;\n            &lt;h5&gt;{{request.name}}&lt;/h5&gt;\n            &lt;p&gt;{{request.description}}&lt;/p&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div class=&quot;collapsible-body&quot;&gt;\n          &lt;div class=&quot;row&quot;&gt;\n            &lt;form method=&quot;post&quot;&gt;\n              &lt;div&gt;\n                {% for field in request.fields.requestTypeFields %}\n                  {% if field.name in ('Category', 'Product') %}\n                    &lt;div class=&quot;input-field&quot;&gt;\n                      &lt;select id=&quot;{{request.name}} {{field.name}}&quot;&gt;\n                        &lt;option value=&quot;Choose your option&quot; disabled selected&gt;Choose your option&lt;/option&gt;\n                        {% for option in field.validValues %}\n                          &lt;option value=&quot;{{option.label}}&quot;&gt;{{option.label}}&lt;/option&gt;\n                        {% endfor %}\n                      &lt;/select&gt;\n                      &lt;label&gt;{{field.name}}&lt;/label&gt;\n                    &lt;/div&gt;\n                  {% elif field.name == 'Description' %}\n                    &lt;div class=&quot;input-field&quot;&gt;\n                      &lt;textarea id=&quot;{{field.name}}&quot; class=&quot;materialize-textarea&quot; placeholder=&quot;{{field.description}}&quot;&gt;&lt;/textarea&gt;\n                      &lt;label for=&quot;{{request.name}} {{field.name}}&quot;&gt;{{field.name}}&lt;/label&gt;\n                    &lt;/div&gt;\n                  {% else %}\n                    &lt;div class=&quot;input-field&quot;&gt;\n                      &lt;input placeholder=&quot;{{field.description}}&quot; id=&quot;{{request.name}} {{field.name}}&quot; type=&quot;text&quot; class=&quot;validate&quot;&gt;\n                      &lt;label for=&quot;{{request.name}} {{field.name}}&quot;&gt;{{field.name}}&lt;/label&gt;\n                    &lt;/div&gt;\n                  {% endif %}\n                {% endfor %}\n                &lt;input type=&quot;button&quot; value=&quot;Submit&quot; class=&quot;btn cyan lighten-3 formsubmit&quot;&gt;\n              &lt;/div&gt;\n            &lt;/form&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/li&gt;\n      {% endfor %}\n    &lt;/ul&gt;\n  &lt;/div&gt;\n{% endblock %}\n</code></pre>\n<p>Because we passed the Service Desk JSON we extracted from the JIRA API to our form, we can go crazy setting our labels, placeholder text, or whatever, anywhere we please. In my example, I utilize <a href=\"https://materializecss.com/\">Material Design</a>'s pretty package of pre-made frontend elements, because God knows nobody wants to deal with designing that shit. Sorry, I was just having a brief flashback to Frontend dev.</p><p>The code above explicitly looks for fields we know are dropdowns, so that we may fill the select options accordingly. Same goes for textarea fields. That said, the way I've handled this above is, well, stupid. Instead of hardcoding if statements to look for certain fields, leverage our JSON to determine the type of each field as you iterate over them. Do as I say, not as I do.</p><h2 id=\"going-further\">Going Further</h2><p>There's so much more we can add here. Take a list of the user's opened tickets, for instance. The great thing about controlling your own portal UI is that you can now control the narrative of your own workload: perhaps the person in marketing who started 2 weeks ago could benefit from seeing the 200 tickets being addressed before her, thus second-guessing the urge to type <strong>URGENT </strong>across a subject line only to be violently shoved down your throat.</p><p>In all seriousness, nobody likes the experience of a vanilla helpdesk because it dehumanizes the customer. While our personal beliefs reassure us that we are special, entering a cold support queue is a stark suggestion that we may not be so special after all, which isn't exactly a fact Millennials or Executives like to ponder on. If nothing else, take this as a chance to build software friendly towards humans with full transparency, and both parties will surely benefit. Remember: happy humans bides times for the inevitable robot revolution on the horizon destined to eradicate mankind. Do your part!</p>","url":"https://hackersandslackers.com/building-a-better-jira/","uuid":"789d1406-0dbf-432e-aaa0-32d10f7d6337","page":false,"codeinjection_foot":"","codeinjection_head":"","comment_id":"5b6f24cc0cd9b8583e46ab5b"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736ea","title":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","slug":"add-db-variables-to-match-new-input-python-pandas","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/apidata@2x.jpg","excerpt":"Python, Pandas, & Functional Programming!","custom_excerpt":"Python, Pandas, & Functional Programming!","created_at_pretty":"22 August, 2018","published_at_pretty":"27 August, 2018","updated_at_pretty":"14 February, 2019","created_at":"2018-08-22T18:04:53.000-04:00","published_at":"2018-08-27T07:30:00.000-04:00","updated_at":"2019-02-13T22:48:04.000-05:00","meta_title":"Python, Pandas, & Functional Programming! | Hackers And Slackers","meta_description":"Python, Pandas, & Functional Programming!","og_description":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","og_image":"https://hackersandslackers.com/content/images/2018/08/apidata@2x.jpg","og_title":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","twitter_description":"Python, Pandas, & Functional Programming!","twitter_image":"https://hackersandslackers.com/content/images/2018/08/apidata@2x.jpg","twitter_title":"More API Columns, More Problems: Easily Adding DB Variables To Match New Input","authors":[{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null}],"primary_author":{"name":"Matthew Alhonte","slug":"matt","bio":"Super villain in somebody's action hero movie. Experienced a radioactive freak accident at a young age, which rendered him part-snake and strangely adept at Python.\n\n","profile_image":"https://hackersandslackers.com/content/images/2019/03/matt.jpg","twitter":"@MattAlhonte","facebook":null,"website":null},"primary_tag":{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"}],"plaintext":"APIs.  They're wonderful.  For every headache they've given me, I'm glad I live\nin the age where hitting an API endpoint is a standard way of retrieving data -\nI recently had to crawl a bunch of records from the Brazilian census in 200, and\nthat was an ordeal (but this isn't about that!).\n\nThe thing about APIs is that you generally shouldn't be hitting them all day\nlong - generally you should be doing regular imports to a database (or\nwhatever).  And the other thing about APIs is that they're not quite as fussy\nabout names as databases.  There's nothing stopping you from having the first\nrow of your API's output include field names like \"Account Canceled?\", which a\ntypical SQL RDBMS will not care for one bit.\n\nHow do we translate them?  Well, simple enough - we just have to think of\neverything that might be in our input string that won't be allowed in our\ndatabase, and change that!  I'm going to use the pipe  function from my beloved \ntoolz  library, provider of Functional Programming goodies for Python.\n\nfrom toolz import pipe\nimport string\n\ndef dbReady(toConvert):\n    return pipe(toConvert,\n                lambda x: x.lower(),\n                lambda x: filter(lambda y: \n                                y in string.ascii_lowercase + \" \",\n                                x),\n                lambda x: \"\".join(x),\n                lambda x: x.split(),\n                lambda x: \"_\".join(x))\n\n\n 1. We made it lowercase.\n 2. We filtered everything that wasn't a lowercase letter or a space.\n 3. We joined the filter back into a string.\n 4. We split the resulting string (in case we wound up with any double spaces,\n    such as from deleting a &.\n 5. We joined the list of strings with underscores.\n\ndbReady(\"Account Canceled?\")\n'account_canceled'\n\n\nFor comparison's sake, here's what that same function looks like without pipe\n\ndef dbReady(toConvert):\n    return '_'.join(\n               \"\".join(\n                   filter(lambda x:\n                          x in string.ascii_lowercase + \" \",\n                          (toConvert\n                           .lower()))\n                   ).split())\n\n\nBut wait!  There's more!\n\nWhat if your API changes?  Oh no, that could break your import!\n\nWell, if you don't care about the new columns, you could just filter them out.\n Let's say we have a list of lists called latestResponse  that came from a\nrequest to our API, with the first row as the labels.\n\nimport pymysql\nfrom sqlalchemy import create_engine\nimport sqlalchemy\nimport pandas as pd\n\nlatestCols = latestResponse[0]\n\n#Change to what they'll be in the database\ndbReadies = [dbReady(x) for x in latestCols] \n\n#Grab the columns currently in the database\ncnx = create_engine('mysql+pymysql://root:cracked1@localhost/appointments', echo=False)\ndbCols = pd.io.sql.read_sql_table(\"appointments_tableau\", \n                                  cnx).columns\n\n#Make a dataframe with what the columns would be named in a database\ndf = pd.DataFrame(latestResponse[1:], columns = dbReady)\n\n#Only select the columns that are currently in the db, and upload\ndf[dbCols].to_sql(name=\"my_table\",\n                  con=cnx, \n                  if_exists='append')\n\n\n\nBut what if you DO want the new columns from now on?  But you're already in the\nzone, don't feel like manually searching for which columns are new, and opening\na new terminal window to add the new variables?  What if you are, in a word,\nlazy?  And what if it's sorta important to preserve the order of the fields, and\nthe new ones are in the middle?\n\nNever fear!\n\nFirst, let's cook up a little function to produce an SQL ALTER TABLE  statement\n(standard disclaimers apply: do NOT do this blindly, or automatically).  Oh, and\nfor our purposes let's say these new columns all have the same type ( \nVARCHAR(255)), because if that's not the case then we have to be slightly less\nlazy. \n\ndef alterStatement(existingCol, newCol):\n    return (f\"ALTER TABLE appointments_tableau \"\n            f\"ADD COLUMN {newCol} VARCHAR(255) AFTER {existingCol};\")\n\n\nLet's use the wonderful sliding_window  function from toolz  to feed us a bunch\nof column names. \n\nExample from the official docs:\n\nlist(sliding_window(2, [1, 2, 3, 4]))\n[(1, 2), (2, 3), (3, 4)]\n\n\nBack to the show!\n\nfrom toolz.itertoolz import sliding_window\n\n#Get the variables that aren't currently in the db\nnewVars = [x for x in dbReadies if x not in dbCols]\n\n#Get a list where each entry is a tuple that has every new variable, and the existing preceding one\ntuples = list(sliding_window(2, dbReadies))\nnewVarTups = [x for x in tuples if x[1] in newVars]\n\n\nAnd, finally, let's set up our statements, and have Pandas execute them!  I know\nI promised I was going to start using SQLAlchemy for this kind of thing instead\nof unsanitized raw SQL, but I'm back on my bullshit again.\n\nfor x in newVarTups:\n    pd.io.sql.execute(alterStatement(*x), cnx)","html":"<p>APIs.  They're wonderful.  For every headache they've given me, I'm glad I live in the age where hitting an API endpoint is a standard way of retrieving data - I recently had to crawl a bunch of records from the Brazilian census in 200, and that was an ordeal (but this isn't about that!).</p><p>The thing about APIs is that you generally shouldn't be hitting them all day long - generally you should be doing regular imports to a database (or whatever).  And the other thing about APIs is that they're not quite as fussy about names as databases.  There's nothing stopping you from having the first row of your API's output include field names like \"Account Canceled?\", which a typical SQL RDBMS will not care for one bit.</p><p>How do we translate them?  Well, simple enough - we just have to think of everything that might be in our input string that won't be allowed in our database, and change that!  I'm going to use the <code>pipe</code> function from my beloved <code>toolz</code> library, provider of Functional Programming goodies for Python.</p><pre><code class=\"language-python\">from toolz import pipe\nimport string\n\ndef dbReady(toConvert):\n    return pipe(toConvert,\n                lambda x: x.lower(),\n                lambda x: filter(lambda y: \n                                y in string.ascii_lowercase + &quot; &quot;,\n                                x),\n                lambda x: &quot;&quot;.join(x),\n                lambda x: x.split(),\n                lambda x: &quot;_&quot;.join(x))\n</code></pre>\n<ol><li>We made it lowercase.</li><li>We filtered everything that wasn't a lowercase letter or a space.</li><li>We joined the filter back into a string.</li><li>We split the resulting string (in case we wound up with any double spaces, such as from deleting a <code>&amp;</code>.</li><li>We joined the list of strings with underscores.</li></ol><pre><code class=\"language-python\">dbReady(&quot;Account Canceled?&quot;)\n'account_canceled'\n</code></pre>\n<p>For comparison's sake, here's what that same function looks like without <code>pipe</code></p><pre><code class=\"language-python\">def dbReady(toConvert):\n    return '_'.join(\n               &quot;&quot;.join(\n                   filter(lambda x:\n                          x in string.ascii_lowercase + &quot; &quot;,\n                          (toConvert\n                           .lower()))\n                   ).split())\n</code></pre>\n<p>But wait!  There's more!</p><p>What if your API changes?  Oh no, that could break your import!</p><p>Well, if you don't care about the new columns, you could just filter them out.  Let's say we have a list of lists called <code>latestResponse</code> that came from a request to our API, with the first row as the labels.</p><pre><code class=\"language-python\">import pymysql\nfrom sqlalchemy import create_engine\nimport sqlalchemy\nimport pandas as pd\n\nlatestCols = latestResponse[0]\n\n#Change to what they'll be in the database\ndbReadies = [dbReady(x) for x in latestCols] \n\n#Grab the columns currently in the database\ncnx = create_engine('mysql+pymysql://root:cracked1@localhost/appointments', echo=False)\ndbCols = pd.io.sql.read_sql_table(&quot;appointments_tableau&quot;, \n                                  cnx).columns\n\n#Make a dataframe with what the columns would be named in a database\ndf = pd.DataFrame(latestResponse[1:], columns = dbReady)\n\n#Only select the columns that are currently in the db, and upload\ndf[dbCols].to_sql(name=&quot;my_table&quot;,\n                  con=cnx, \n                  if_exists='append')\n\n</code></pre>\n<p>But what if you DO want the new columns from now on?  But you're already in the zone, don't feel like manually searching for which columns are new, and opening a new terminal window to add the new variables?  What if you are, in a word, lazy?  And what if it's sorta important to preserve the order of the fields, and the new ones are in the middle?  </p><p>Never fear!</p><p>First, let's cook up a little function to produce an SQL <code>ALTER TABLE</code> statement (standard disclaimers apply: do NOT do this blindly, or automatically).  Oh, and for our purposes let's say these new columns all have the same type ( <code>VARCHAR(255)</code>), because if that's not the case then we have to be slightly less lazy. </p><pre><code class=\"language-python\">def alterStatement(existingCol, newCol):\n    return (f&quot;ALTER TABLE appointments_tableau &quot;\n            f&quot;ADD COLUMN {newCol} VARCHAR(255) AFTER {existingCol};&quot;)\n</code></pre>\n<p>Let's use the wonderful <code>sliding_window</code> function from <code>toolz</code> to feed us a bunch of column names. </p><p>Example from the <a href=\"https://toolz.readthedocs.io/en/latest/api.html#toolz.itertoolz.sliding_window\">official docs</a>:</p><pre><code class=\"language-python\">list(sliding_window(2, [1, 2, 3, 4]))\n[(1, 2), (2, 3), (3, 4)]\n</code></pre>\n<p>Back to the show!</p><pre><code class=\"language-python\">from toolz.itertoolz import sliding_window\n\n#Get the variables that aren't currently in the db\nnewVars = [x for x in dbReadies if x not in dbCols]\n\n#Get a list where each entry is a tuple that has every new variable, and the existing preceding one\ntuples = list(sliding_window(2, dbReadies))\nnewVarTups = [x for x in tuples if x[1] in newVars]\n</code></pre>\n<p>And, finally, let's set up our statements, and have Pandas execute them!  I know I promised I was going to start using SQLAlchemy for this kind of thing instead of unsanitized raw SQL, but I'm back on my bullshit again.</p><pre><code class=\"language-python\">for x in newVarTups:\n    pd.io.sql.execute(alterStatement(*x), cnx)\n</code></pre>\n","url":"https://hackersandslackers.com/add-db-variables-to-match-new-input-python-pandas/","uuid":"8c2a6558-0216-46bc-aaef-ef2ab08342a3","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b7dde05a2743b50f2e9edeb"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c7","title":"Hacking Tableau to Handle ETL Workflows","slug":"turning-tableau-into-an-etl-tool-using-the-rest-api","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/08/fucktableau@2x.jpg","excerpt":"Weaponizing APIs against tyrannical software.","custom_excerpt":"Weaponizing APIs against tyrannical software.","created_at_pretty":"01 August, 2018","published_at_pretty":"03 August, 2018","updated_at_pretty":"28 February, 2019","created_at":"2018-08-01T08:49:36.000-04:00","published_at":"2018-08-03T08:57:00.000-04:00","updated_at":"2019-02-28T03:18:22.000-05:00","meta_title":"Hacking Tableau to Handle ETL Workflows | Hackers and Slackers","meta_description":"The presence of ETL as an acronym is a perfect reflection of where we are in data engineering's growth trajectory. ","og_description":"The presence of ETL as an acronym is a perfect reflection of where we are in data engineering's growth trajectory. The lack of effective Extract, Transform, and Load workflow products tell us a couple things: we have too many data sources (whether they be APIs or private data sets), and the raw data is virtually unusable until cleaned.","og_image":"https://hackersandslackers.com/content/images/2018/08/fucktableau@2x.jpg","og_title":"Hacking Tableau to Handle ETL Workflows","twitter_description":"The lack of effective Extract, Transform, and Load workflow products tell us a couple things: we have too many data sources, and the raw data is virtually unusable until cleaned.","twitter_image":"https://hackersandslackers.com/content/images/2018/08/fucktableau@2x.jpg","twitter_title":"Hacking Tableau to Handle ETL Workflows","authors":[{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"}],"primary_author":{"name":"Todd Birchard","slug":"todd","bio":"Product manager turned engineer with an ongoing identity crisis. Breaks everything before learning best practices. Completely normal and emotionally stable.","profile_image":"https://hackersandslackers.com/content/images/2019/03/todd3.jpg","twitter":"@ToddRBirchard","facebook":null,"website":"https://toddbirchard.com"},"primary_tag":{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Tableau","slug":"tableau","description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","feature_image":null,"meta_description":"Dissect Tableau server and implement hacks to improve your workflow, or simply become familiar with the Tableau desktop user interface.","meta_title":"Tableau Desktop & Server | Hackers and Slackers","visibility":"public"},{"name":"BI","slug":"business-intelligence","description":"Business Intelligence, otherwise known as \"making nice reports for executives to ignore.\"","feature_image":null,"meta_description":null,"meta_title":"Business Intelligence Tools | Hackers and Slackers","visibility":"public"},{"name":"DevOps","slug":"devops","description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","feature_image":null,"meta_description":"Configuring server-side infrastructure, cloud architecture, and sometimes networking. Even automate your DevOps workflow with products from Hashicorp.","meta_title":"DevOps: Networking And Server Configuration | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Hacking Tableau Server","slug":"hacking-tableau-server","description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","feature_image":"https://hackersandslackers.com/content/images/2019/03/tableauseries-2.jpg","meta_description":"Break free from the constraints of the TSM CLI to bend Tableau Server to your will. Uncover Superadmin privileges, or even rewire Tableau to handle ETL.","meta_title":"Hacking Tableau Server","visibility":"internal"}],"plaintext":"Before we get into the specifics of how to sadistically abuse Tableau, let's\nclear the air: there's something about inaccessible, expensive, proprietary\nenterprise software that tends to put me in a touchy mood. As we know, B2B\nsoftware pricing has nothing to do with code quality or even value-add, but\nrather the tendency of businesses to create time-based urgencies without\nwarning; the kinds of urgencies which may be solved by, say, a tool of sorts.\n\nMy first interaction with Tableau actually took place after I had committed\nmyself to the cult of Python's Pandas library and all that comes with it.\nTableau does little to hide the fact that it is a GUI for data manipulation and\nSQL queries; in most cases, the calculation syntax is exactly the same. From my\nperspective, Tableau could be a tool to save time: instead of rewriting\nvariations of the same scripts over and over, I could use Tableau to do these\ntasks visually for both speed and transparency's sake. It was a win-win for\ntrivial tasks, except for one: the ability to write back to a database. You'd\nthink I wouldn't think that far ahead before purchasing my own Tableau server\nand license, conveniently billed upfront annually.\n\nThe Rise of ETL\nThe presence of ETL as an acronym is a perfect reflection of where we are in\ndata engineering's growth trajectory. The lack of effective Extract, Transform,\nand Load  workflow products tell us a couple things: we have too many data\nsources (whether they be APIs or private data sets), and the raw data is\nvirtually unusable until cleaned. This process could be relatively trivial with\nthe right software. There are plenty of contenders to make this process simple,\nand I'd like to express in unadulterated astonishment that they are all  failing\nmiserably  at solving this task effectively, mostly thanks to poor decision\nmaking and human error alone.\n\nThe ETL Market\nAs it stands, Parabola.io  tops my list of ETL products. Parabola hits the nail\non the head when it comes to UI and ease of use. This begs the question: why,\nthen, are their latest releases focused on support for extraction to garbage\nproducts like Smartsheet? Currently the only extract location which is actually\na database  is MySQL. As much as I want Parabola to succeed, nothing has\nimproved if our workflow still involves manually setting up a third party DB\nwith a schema which perfectly matches our output.\n\nGoogle Cloud is doing its best to somehow tie separate products together such as\n Dataprep  and Bigquery. We'll see how that goes- there's no mention of data\nextraction from APIs in this flow just yet. We might be waiting for some time\nfor Google's perfect answer to mature.\n\nGithub Labs supposedly just announced recent efforts to tackle this space as\nwell with the upcoming Melatano\n[https://about.gitlab.com/2018/08/01/hey-data-teams-we-are-working-on-a-tool-just-for-you/]\n. Hopefully they have their heads on straight.\n\nAnyway, since the world has failed us, we'll just exploit a Tableau backdoor to\ndo this while humanity catches up.\n\nTableau's Rest API\nAs hard as Tableau tries to obfuscate anything and everything, their REST API\ngets us exactly what we want after a bit of red tape. We need to run 3 API\ncalls:\n\n * POST /api/[api-version]/auth/signin: Generate a token so we can actually use\n   the API\n * GET /api/3.0/sites/[site-id]/views:  List all view metadata in a Tableau\n   \"site.\"\n * GET /api/3.0/sites/[site-id]/views/[view-id]/data: Receive a comma\n   delimitated response of the content of your target view\n\nWhat R U Token about\nTo receive our token, we'll use basic auth to hit this simple endpoint via POST:\n \n\nPOST http://mywebsite/api/3.0/auth/signin\n\n\nThe response will come in the form of XML and give us two critical items: our \ntoken, and our site ID:\n\nClearly a user-friendly experience.List Views by Site\nNext up we're GETing the following endpoint:\n\nhttp://mywebsite/api/3.0/sites/543fc0-4123572-483276-9345d8c-96005d532b2fb33/views\n\n\nNote that Tableau asks for the site ID from the previous response to be part of\nthe URL string.\n\nWe'll also need to set headers, so do that.\n\nX-Tableau-Auth: SPMJsdfgHIDUFihdwPqf-5k8GCZJA|sXhFBHzzqksB6K567fsQvtCfTtakqrJLuQ6Cf\n\n\nThe motherload of views.Reap your Reward\nPick the notebook ID you're looking to extract data from. Chose wisely. Your\ntime now. Enter that view into the final endpoint URL:\n\nhttp://mysite/api/3.0/sites/983445c0-4172-4876-9d8c-96005db2gfdgdfb33/views/c0357db9-71b1-4besdfgd1-a14e-5a5f7a36d410/data\n\n\nWhoa mama.Well, Well, Well.\nSo now you know how to generate a Tableau REST API token at will. You also know\nall your view IDs, and how to extract the data from any of those views in a\nfriendly CSV format which happens to play nice with databases. There's a Pandas\nscript waiting to be written here somewhere.\n\nAt this point, you know have all the tools you need to automate the systematic\npillaging of your Tableau Server data. Take a brief moment to remember the days\nwhen Tableau would wave their flags through the countryside as a sign of\ntaunting warfare. They've collected your company's checks and gave you iFrames\nin return.\n\nGo onwards my brethren. For one chance, discover the lands of Plot.ly and D3 as\nFree Men. They may take our paychecks, but they will never take our data.","html":"<p>Before we get into the specifics of how to sadistically abuse Tableau, let's clear the air: there's something about inaccessible, expensive, proprietary enterprise software that tends to put me in a touchy mood. As we know, B2B software pricing has nothing to do with code quality or even value-add, but rather the tendency of businesses to create time-based urgencies without warning; the kinds of urgencies which may be solved by, say, a tool of sorts.</p><p>My first interaction with Tableau actually took place after I had committed myself to the cult of Python's Pandas library and all that comes with it. Tableau does little to hide the fact that it is a GUI for data manipulation and SQL queries; in most cases, the calculation syntax is exactly the same. From my perspective, Tableau could be a tool to save time: instead of rewriting variations of the same scripts over and over, I could use Tableau to do these tasks visually for both speed and transparency's sake. It was a win-win for trivial tasks, except for one: the ability to write back to a database. You'd think I wouldn't think that far ahead before purchasing my own Tableau server and license, conveniently billed upfront annually.</p><h2 id=\"the-rise-of-etl\">The Rise of ETL</h2><p>The presence of ETL as an acronym is a perfect reflection of where we are in data engineering's growth trajectory. The lack of effective <strong>Extract, Transform, and Load</strong> workflow products tell us a couple things: we have too many data sources (whether they be APIs or private data sets), and the raw data is virtually unusable until cleaned. This process could be relatively trivial with the right software. There are plenty of contenders to make this process simple, and I'd like to express in unadulterated astonishment that they are all<strong> failing miserably</strong> at solving this task effectively, mostly thanks to poor decision making and human error alone.</p><h3 id=\"the-etl-market\">The ETL Market</h3><p>As it stands, <a href=\"Parabola.io\">Parabola.io</a> tops my list of ETL products. Parabola hits the nail on the head when it comes to UI and ease of use. This begs the question: why, then, are their latest releases focused on support for extraction to garbage products like <strong>Smartsheet</strong>? Currently the only extract location which is <em>actually a database</em> is MySQL. As much as I want Parabola to succeed, nothing has improved if our workflow still involves manually setting up a third party DB with a schema which perfectly matches our output.</p><p>Google Cloud is doing its best to somehow tie separate products together such as <strong>Dataprep</strong> and <strong>Bigquery</strong>. We'll see how that goes- there's no mention of data extraction from APIs in this flow just yet. We might be waiting for some time for Google's perfect answer to mature.</p><p>Github Labs supposedly just announced recent efforts to tackle this space as well with the upcoming <a href=\"https://about.gitlab.com/2018/08/01/hey-data-teams-we-are-working-on-a-tool-just-for-you/\">Melatano</a>. Hopefully they have their heads on straight.</p><p>Anyway, since the world has failed us, we'll just exploit a Tableau backdoor to do this while humanity catches up.</p><h2 id=\"tableau-s-rest-api\">Tableau's Rest API</h2><p>As hard as Tableau tries to obfuscate anything and everything, their REST API gets us exactly what we want after a bit of red tape. We need to run 3 API calls:</p><ul><li><strong>POST /api/[<em>api-version]</em>/auth/signin</strong>: Generate a token so we can actually use the API</li><li><strong>GET /api/3.0/sites/[site-id]/views</strong>:<strong> </strong>List all view metadata in a Tableau \"site.\"</li><li><strong>GET /api/3.0/sites/[site-id]/views/[view-id]/data</strong>: Receive a comma delimitated response of the content of your target view</li></ul><h3 id=\"what-r-u-token-about\">What R U Token about</h3><p>To receive our token, we'll use basic auth to hit this simple endpoint via POST: </p><pre><code class=\"language-shell\">POST http://mywebsite/api/3.0/auth/signin\n</code></pre>\n<p>The response will come in the form of XML and give us two critical items: our <strong>token</strong>, and our <strong>site ID</strong>:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-08-03-at-7.50.59-AM.png\" class=\"kg-image\"><figcaption>Clearly a user-friendly experience.</figcaption></figure><h3 id=\"list-views-by-site\">List Views by Site</h3><p>Next up we're GETing the following endpoint:</p><pre><code class=\"language-shell\">http://mywebsite/api/3.0/sites/543fc0-4123572-483276-9345d8c-96005d532b2fb33/views\n</code></pre>\n<p>Note that Tableau asks for the <strong>site ID </strong>from the previous response to be part of the URL string.</p><p>We'll also need to set headers, so do that.</p><pre><code class=\"language-shell\">X-Tableau-Auth: SPMJsdfgHIDUFihdwPqf-5k8GCZJA|sXhFBHzzqksB6K567fsQvtCfTtakqrJLuQ6Cf\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-08-03-at-7.57.47-AM.png\" class=\"kg-image\"><figcaption>The motherload of views.</figcaption></figure><h3 id=\"reap-your-reward\">Reap your Reward</h3><p>Pick the notebook ID you're looking to extract data from. Chose wisely. Your time now. Enter that view into the final endpoint URL:</p><pre><code class=\"language-shell\">http://mysite/api/3.0/sites/983445c0-4172-4876-9d8c-96005db2gfdgdfb33/views/c0357db9-71b1-4besdfgd1-a14e-5a5f7a36d410/data\n</code></pre>\n<figure class=\"kg-card kg-image-card\"><img src=\"https://hackersandslackers.com/content/images/2019/02/Screen-Shot-2018-08-03-at-8.01.24-AM.png\" class=\"kg-image\"><figcaption>Whoa mama.</figcaption></figure><h2 id=\"well-well-well-\">Well, Well, Well.</h2><p>So now you know how to generate a Tableau REST API token at will. You also know all your view IDs, and how to extract the data from any of those views in a friendly CSV format which happens to play nice with databases. There's a Pandas script waiting to be written here somewhere.</p><p>At this point, you know have all the tools you need to automate the systematic pillaging of your Tableau Server data. Take a brief moment to remember the days when Tableau would wave their flags through the countryside as a sign of taunting warfare. They've collected your company's checks and gave you iFrames in return.</p><p>Go onwards my brethren. For one chance, discover the lands of Plot.ly and D3 as Free Men. They may take our paychecks, but they will <strong>never </strong>take our data.</p>","url":"https://hackersandslackers.com/turning-tableau-into-an-etl-tool-using-the-rest-api/","uuid":"7b86dd9c-7d93-4518-8f3a-b593a6cdb7f0","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b61ac60d2852c0dc51d9217"}},{"node":{"id":"Ghost__Post__5c12d7bfe875ad7bb86736c3","title":"Automagically Turn JSON into Pandas DataFrames","slug":"json-into-pandas-dataframes","featured":false,"feature_image":"https://hackersandslackers.com/content/images/2018/07/json@2x.jpg","excerpt":"Let Pandas do the heavy lifting for you when turning JSON into a DataFrame.","custom_excerpt":"Let Pandas do the heavy lifting for you when turning JSON into a DataFrame.","created_at_pretty":"25 July, 2018","published_at_pretty":"28 July, 2018","updated_at_pretty":"21 February, 2019","created_at":"2018-07-25T10:52:35.000-04:00","published_at":"2018-07-28T08:00:00.000-04:00","updated_at":"2019-02-20T21:35:53.000-05:00","meta_title":"Turn JSON into Pandas DataFrames | Hackers And Slackers","meta_description":"Let Pandas do the heavy lifting for you when turning JSON into a DataFrame, especially when that JSON is heavily nested.","og_description":"Let Pandas do the heavy lifting for you when turning JSON into a DataFrame, especially when that JSON is heavily nested.","og_image":"https://hackersandslackers.com/content/images/2018/07/json@2x.jpg","og_title":"Automagically Turn JSON into Pandas DataFrames","twitter_description":"Let Pandas do the heavy lifting for you when turning JSON into a DataFrame, especially when that JSON is heavily nested.","twitter_image":"https://hackersandslackers.com/content/images/2018/07/json@2x.jpg","twitter_title":"Automagically Turn JSON into Pandas DataFrames","authors":[{"name":"Graham Beckley","slug":"graham","bio":"Loves Python; loves pandas; leaves every project more Pythonic than he found it.","profile_image":"https://hackersandslackers.com/content/images/2019/03/graham2.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Graham Beckley","slug":"graham","bio":"Loves Python; loves pandas; leaves every project more Pythonic than he found it.","profile_image":"https://hackersandslackers.com/content/images/2019/03/graham2.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},"tags":[{"name":"Pandas","slug":"pandas","description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","feature_image":"https://res-3.cloudinary.com/hackers-and-slackers/image/upload/f_auto,q_auto/v1/images/pandasmerge.jpg","meta_description":"Analyze data with the Pandas data analysis library for Python. Start from the basics or see real-life examples of pros using Pandas to solve problems.","meta_title":"Pythons and Pandas | Hackers and Slackers","visibility":"public"},{"name":"Data Science","slug":"datascience","description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","feature_image":null,"meta_description":"Watch as we attempt to maintain a delicate harmony of math, engineering, and intuition to solve larger-than-life problems.","meta_title":"Data Science | Hackers and Slackers","visibility":"public"},{"name":"REST APIs","slug":"restapis","description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","feature_image":null,"meta_description":"Get the most out of REST APIs by example, or build your own. Discover new APIs and how to interact with them, regardless of proffered programming language.","meta_title":"Consuming and Building REST APIs | Hackers and Slackers","visibility":"public"},{"name":"#Data Analysis with Pandas","slug":"data-analysis-pandas","description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","feature_image":"https://res.cloudinary.com/hackers-and-slackers/image/upload/q_auto:good/v1/images/pandasseries-1.jpg","meta_description":"Analyze data with Python's Pandas. Start from the basics or see real-life examples of using Pandas to solve problems.","meta_title":"Data Analysis with Pandas","visibility":"internal"},{"name":"Python","slug":"python","description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold.","feature_image":null,"meta_description":"Let us feed your endless Python addiction! Regardless of where you stand as a Pythonista, our team of pros are constantly teaching and sharing pythonic gold","meta_title":"Python Tricks, Hacks, and Snippets | Hackers and Slackers","visibility":"public"}],"plaintext":"In his post about extracting data from APIs\n[https://hackersandslackers.com/extracting-massive-datasets-from-apis/], Todd\n[https://hackersandslackers.com/author/todd/]  demonstrated a nice way to\nmassage JSON into a pandas DataFrame. This method works great when our JSON\nresponse is flat, because dict.keys()  only gets the keys on the first \"level\"\nof a dictionary. It gets a little trickier when our JSON starts to become nested\nthough, as I experienced when working with Spotify's API\n[https://developer.spotify.com/documentation/web-api/]  via the Spotipy\n[https://spotipy.readthedocs.io/en/latest/]  library. For example, take a look\nat a response from their https://api.spotify.com/v1/tracks/{id}  endpoint:\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\n\nspotify_client_id = 'YOUR_ID'\nspotify_client_secret  = 'YOUR_SECRET'\nclient_credentials_manager = SpotifyClientCredentials(client_id=spotify_client_id, client_secret=spotify_client_secret)\nsp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n\n\ntrack_response = sp.track('0BDYBajZydY54OTgQsH940')\ntrack_response\n\n\nOutput:\n{\n  \"album\": {\n    \"album_type\": \"album\",\n    \"artists\": [{\n        \"external_urls\": {\n          \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n        },\n        \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n        \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n        \"name\": \"Stephen Malkmus & The Jicks\",\n        \"type\": \"artist\",\n        \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n      },\n      {\n        \"external_urls\": {\n          \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n        },\n        \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n        \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n        \"name\": \"Stephen Malkmus\",\n        \"type\": \"artist\",\n        \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n      },\n      {\n        \"external_urls\": {\n          \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n        },\n        \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n        \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n        \"name\": \"The Jicks\",\n        \"type\": \"artist\",\n        \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n      }\n    ],\n    \"available_markets\": [\"AR\",\n      \"BO\",\n      \"BR\",\n      \"CA\",\n      \"...\",\n      \"US\",\n      \"UY\",\n      \"VN\"\n    ],\n    \"external_urls\": {\n      \"spotify\": \"https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY\"\n    },\n    \"href\": \"https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY\",\n    \"id\": \"6pWpb4IdPu9vp9mOdh5DjY\",\n    \"images\": [{\n        \"height\": 640,\n        \"url\": \"https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3\",\n        \"width\": 640\n      },\n      {\n        \"height\": 300,\n        \"url\": \"https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88\",\n        \"width\": 300\n      },\n      {\n        \"height\": 64,\n        \"url\": \"https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4\",\n        \"width\": 64\n      }\n    ],\n    \"name\": \"Real Emotional Trash\",\n    \"release_date\": \"2008-03-04\",\n    \"release_date_precision\": \"day\",\n    \"type\": \"album\",\n    \"uri\": \"spotify:album:6pWpb4IdPu9vp9mOdh5DjY\"\n  },\n  \"artists\": [{\n      \"external_urls\": {\n        \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n      },\n      \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n      \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n      \"name\": \"Stephen Malkmus & The Jicks\",\n      \"type\": \"artist\",\n      \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n    },\n    {\n      \"external_urls\": {\n        \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n      },\n      \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n      \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n      \"name\": \"Stephen Malkmus\",\n      \"type\": \"artist\",\n      \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n    },\n    {\n      \"external_urls\": {\n        \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n      },\n      \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n      \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n      \"name\": \"The Jicks\",\n      \"type\": \"artist\",\n      \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n    }\n  ],\n  \"available_markets\": [\"AR\",\n    \"BO\",\n    \"BR\",\n    \"CA\",\n    \"...\",\n    \"US\",\n    \"UY\",\n    \"VN\"\n  ],\n  \"disc_number\": 1,\n  \"duration_ms\": 608826,\n  \"explicit\": False,\n  \"external_ids\": {\n    \"isrc\": \"USMTD0877204\"\n  },\n  \"external_urls\": {\n    \"spotify\": \"https://open.spotify.com/track/0BDYBajZydY54OTgQsH940\"\n  },\n  \"href\": \"https://api.spotify.com/v1/tracks/0BDYBajZydY54OTgQsH940\",\n  \"id\": \"0BDYBajZydY54OTgQsH940\",\n  \"is_local\": False,\n  \"name\": \"Real Emotional Trash\",\n  \"popularity\": 21,\n  \"preview_url\": \"https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590d5819849e1aad3eff981dc75?cid=be22fd00039241bc96d161a63876b54c\",\n  \"track_number\": 4,\n  \"type\": \"track\",\n  \"uri\": \"spotify:track:0BDYBajZydY54OTgQsH940\"\n}\n\n\nIn addition to plenty of information about the track, Spotify also includes\ninformation about the album that contains the track. If we were to just use the \ndict.keys()  method to turn this response into a DataFrame, we'd be missing out\non all that extra album information. Well, it would be there, just not readily\naccessible.\n\ntrack_response.keys()\n\n\nOutput:\ndict_keys(['album', 'artists', 'available_markets', 'disc_number', 'duration_ms', 'explicit', 'external_ids', 'external_urls', 'href', 'id', 'is_local', 'name', 'popularity', 'preview_url', 'track_number', 'type', 'uri'])\n\n\nSo how do we get around this? Well, we could write our own function, but because\npandas is amazing, it already has a built in tool that takes care of this for\nus.\n\nData Normalization\nMeet json_normalize():\n\nimport pandas as pd\nfrom pandas.io.json import json_normalize\njson_normalize(track_response)\n\n\nOutput:\nalbum.album_type\n album.artists\n album.available_markets\n album.external_urls.spotify\n album.href\n album.id\n album.images\n album.name\n album.release_date\n album.release_date_precision\n ...\n external_urls.spotify\n href\n id\n is_local\n name\n popularity\n preview_url\n track_number\n type\n uri\n 0\n album\n [{'external_urls': {'spotify': 'https://open.s...\n [AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...\n https://open.spotify.com/album/6pWpb4IdPu9vp9m...\n https://api.spotify.com/v1/albums/6pWpb4IdPu9v...\n 6pWpb4IdPu9vp9mOdh5DjY\n [{'height': 640, 'url': 'https://i.scdn.co/ima...\n Real Emotional Trash\n 2008-03-04\n day\n ...\n https://open.spotify.com/track/0BDYBajZydY54OT...\n https://api.spotify.com/v1/tracks/0BDYBajZydY5...\n 0BDYBajZydY54OTgQsH940\n False\n Real Emotional Trash\n 21\n https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590...\n 4\n track\n spotify:track:0BDYBajZydY54OTgQsH940\n Yep – it's that easy. pandas takes our nested JSON object, flattens it out, and\nturns it into a DataFrame.\n\nThis makes our life easier when we're dealing with one record, but it really \ncomes in handy when we're dealing with a response that contains multiple\nrecords.\n\ntracks_response = sp.tracks(\n    ['0BDYBajZydY54OTgQsH940',\n     '7fdUqrzb8oCcIoKvFuzMrs',\n     '0islTY4Fw6lhYbfqi8Qtdj',\n     '3jyFLbljUTKjE13nIWXchH',\n     '6dNmC2YWtWbVOFOdTuRDQs']\n)\ntracks_response\n\n\nOutput:\n{\n  \"tracks\": [{\n      \"album\": {\n        \"album_type\": \"album\",\n        \"artists\": [{\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n            \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n            \"name\": \"Stephen Malkmus & The Jicks\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n          },\n          {\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n            \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n            \"name\": \"Stephen Malkmus\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n          },\n          {\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n            \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n            \"name\": \"The Jicks\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n          }\n        ],\n        \"available_markets\": [\"AR\",\n          \"BO\",\n          \"BR\",\n          \"CA\",\n          \"CL\",\n          \"CO\",\n          \"CR\",\n          \"EC\",\n          \"GT\",\n          \"HK\",\n          \"HN\",\n          \"ID\",\n          \"MX\",\n          \"MY\",\n          \"NI\",\n          \"PA\",\n          \"PE\",\n          \"PH\",\n          \"PY\",\n          \"SG\",\n          \"SV\",\n          \"TH\",\n          \"TW\",\n          \"US\",\n          \"UY\",\n          \"VN\"\n        ],\n        \"external_urls\": {\n          \"spotify\": \"https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY\"\n        },\n        \"href\": \"https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY\",\n        \"id\": \"6pWpb4IdPu9vp9mOdh5DjY\",\n        \"images\": [{\n            \"height\": 640,\n            \"url\": \"https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3\",\n            \"width\": 640\n          },\n          {\n            \"height\": 300,\n            \"url\": \"https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88\",\n            \"width\": 300\n          },\n          {\n            \"height\": 64,\n            \"url\": \"https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4\",\n            \"width\": 64\n          }\n        ],\n        \"name\": \"Real Emotional Trash\",\n        \"release_date\": \"2008-03-04\",\n        \"release_date_precision\": \"day\",\n        \"type\": \"album\",\n        \"uri\": \"spotify:album:6pWpb4IdPu9vp9mOdh5DjY\"\n      },\n      \"artists\": [{\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n          \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n          \"name\": \"Stephen Malkmus & The Jicks\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n        },\n        {\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n          \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n          \"name\": \"Stephen Malkmus\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n        },\n        {\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n          \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n          \"name\": \"The Jicks\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n        }\n      ],\n      \"available_markets\": [\"AR\",\n        \"BO\",\n        \"BR\",\n        \"CA\",\n        \"CL\",\n        \"CO\",\n        \"CR\",\n        \"EC\",\n        \"GT\",\n        \"HK\",\n        \"HN\",\n        \"ID\",\n        \"MX\",\n        \"MY\",\n        \"NI\",\n        \"PA\",\n        \"PE\",\n        \"PH\",\n        \"PY\",\n        \"SG\",\n        \"SV\",\n        \"TH\",\n        \"TW\",\n        \"US\",\n        \"UY\",\n        \"VN\"\n      ],\n      \"disc_number\": 1,\n      \"duration_ms\": 608826,\n      \"explicit\": False,\n      \"external_ids\": {\n        \"isrc\": \"USMTD0877204\"\n      },\n      \"external_urls\": {\n        \"spotify\": \"https://open.spotify.com/track/0BDYBajZydY54OTgQsH940\"\n      },\n      \"href\": \"https://api.spotify.com/v1/tracks/0BDYBajZydY54OTgQsH940\",\n      \"id\": \"0BDYBajZydY54OTgQsH940\",\n      \"is_local\": False,\n      \"name\": \"Real Emotional Trash\",\n      \"popularity\": 21,\n      \"preview_url\": \"https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590d5819849e1aad3eff981dc75?cid=be22fd00039241bc96d161a63876b54c\",\n      \"track_number\": 4,\n      \"type\": \"track\",\n      \"uri\": \"spotify:track:0BDYBajZydY54OTgQsH940\"\n    },\n    {\n      \"album\": {\n        \"album_type\": \"album\",\n        \"artists\": [{\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n            \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n            \"name\": \"Stephen Malkmus & The Jicks\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n          },\n          {\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n            \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n            \"name\": \"Stephen Malkmus\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n          },\n          {\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n            \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n            \"name\": \"The Jicks\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n          }\n        ],\n        \"available_markets\": [\"AR\",\n          \"BO\",\n          \"BR\",\n          \"CA\",\n          \"CL\",\n          \"CO\",\n          \"CR\",\n          \"EC\",\n          \"GT\",\n          \"HK\",\n          \"HN\",\n          \"ID\",\n          \"MX\",\n          \"MY\",\n          \"NI\",\n          \"PA\",\n          \"PE\",\n          \"PH\",\n          \"PY\",\n          \"SG\",\n          \"SV\",\n          \"TH\",\n          \"TW\",\n          \"US\",\n          \"UY\",\n          \"VN\"\n        ],\n        \"external_urls\": {\n          \"spotify\": \"https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY\"\n        },\n        \"href\": \"https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY\",\n        \"id\": \"6pWpb4IdPu9vp9mOdh5DjY\",\n        \"images\": [{\n            \"height\": 640,\n            \"url\": \"https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3\",\n            \"width\": 640\n          },\n          {\n            \"height\": 300,\n            \"url\": \"https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88\",\n            \"width\": 300\n          },\n          {\n            \"height\": 64,\n            \"url\": \"https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4\",\n            \"width\": 64\n          }\n        ],\n        \"name\": \"Real Emotional Trash\",\n        \"release_date\": \"2008-03-04\",\n        \"release_date_precision\": \"day\",\n        \"type\": \"album\",\n        \"uri\": \"spotify:album:6pWpb4IdPu9vp9mOdh5DjY\"\n      },\n      \"artists\": [{\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n          \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n          \"name\": \"Stephen Malkmus & The Jicks\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n        },\n        {\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n          \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n          \"name\": \"Stephen Malkmus\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n        },\n        {\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n          \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n          \"name\": \"The Jicks\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n        }\n      ],\n      \"available_markets\": [\"AR\",\n        \"BO\",\n        \"BR\",\n        \"CA\",\n        \"CL\",\n        \"CO\",\n        \"CR\",\n        \"EC\",\n        \"GT\",\n        \"HK\",\n        \"HN\",\n        \"ID\",\n        \"MX\",\n        \"MY\",\n        \"NI\",\n        \"PA\",\n        \"PE\",\n        \"PH\",\n        \"PY\",\n        \"SG\",\n        \"SV\",\n        \"TH\",\n        \"TW\",\n        \"US\",\n        \"UY\",\n        \"VN\"\n      ],\n      \"disc_number\": 1,\n      \"duration_ms\": 222706,\n      \"explicit\": False,\n      \"external_ids\": {\n        \"isrc\": \"USMTD0877203\"\n      },\n      \"external_urls\": {\n        \"spotify\": \"https://open.spotify.com/track/7fdUqrzb8oCcIoKvFuzMrs\"\n      },\n      \"href\": \"https://api.spotify.com/v1/tracks/7fdUqrzb8oCcIoKvFuzMrs\",\n      \"id\": \"7fdUqrzb8oCcIoKvFuzMrs\",\n      \"is_local\": False,\n      \"name\": \"Cold Son\",\n      \"popularity\": 25,\n      \"preview_url\": \"https://p.scdn.co/mp3-preview/4cf4e21727def47097e27d30de16ffe9f99b7774?cid=be22fd00039241bc96d161a63876b54c\",\n      \"track_number\": 3,\n      \"type\": \"track\",\n      \"uri\": \"spotify:track:7fdUqrzb8oCcIoKvFuzMrs\"\n    },\n    {\n      \"album\": {\n        \"album_type\": \"album\",\n        \"artists\": [{\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n            \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n            \"name\": \"Stephen Malkmus & The Jicks\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n          },\n          {\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n            \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n            \"name\": \"Stephen Malkmus\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n          },\n          {\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n            \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n            \"name\": \"The Jicks\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n          }\n        ],\n        \"available_markets\": [\"AR\",\n          \"BO\",\n          \"BR\",\n          \"CA\",\n          \"CL\",\n          \"CO\",\n          \"CR\",\n          \"EC\",\n          \"GT\",\n          \"HK\",\n          \"HN\",\n          \"ID\",\n          \"MX\",\n          \"MY\",\n          \"NI\",\n          \"PA\",\n          \"PE\",\n          \"PH\",\n          \"PY\",\n          \"SG\",\n          \"SV\",\n          \"TH\",\n          \"TW\",\n          \"US\",\n          \"UY\",\n          \"VN\"\n        ],\n        \"external_urls\": {\n          \"spotify\": \"https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY\"\n        },\n        \"href\": \"https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY\",\n        \"id\": \"6pWpb4IdPu9vp9mOdh5DjY\",\n        \"images\": [{\n            \"height\": 640,\n            \"url\": \"https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3\",\n            \"width\": 640\n          },\n          {\n            \"height\": 300,\n            \"url\": \"https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88\",\n            \"width\": 300\n          },\n          {\n            \"height\": 64,\n            \"url\": \"https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4\",\n            \"width\": 64\n          }\n        ],\n        \"name\": \"Real Emotional Trash\",\n        \"release_date\": \"2008-03-04\",\n        \"release_date_precision\": \"day\",\n        \"type\": \"album\",\n        \"uri\": \"spotify:album:6pWpb4IdPu9vp9mOdh5DjY\"\n      },\n      \"artists\": [{\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n          \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n          \"name\": \"Stephen Malkmus & The Jicks\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n        },\n        {\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n          \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n          \"name\": \"Stephen Malkmus\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n        },\n        {\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n          \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n          \"name\": \"The Jicks\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n        }\n      ],\n      \"available_markets\": [\"AR\",\n        \"BO\",\n        \"BR\",\n        \"CA\",\n        \"CL\",\n        \"CO\",\n        \"CR\",\n        \"EC\",\n        \"GT\",\n        \"HK\",\n        \"HN\",\n        \"ID\",\n        \"MX\",\n        \"MY\",\n        \"NI\",\n        \"PA\",\n        \"PE\",\n        \"PH\",\n        \"PY\",\n        \"SG\",\n        \"SV\",\n        \"TH\",\n        \"TW\",\n        \"US\",\n        \"UY\",\n        \"VN\"\n      ],\n      \"disc_number\": 1,\n      \"duration_ms\": 416173,\n      \"explicit\": False,\n      \"external_ids\": {\n        \"isrc\": \"USMTD0877202\"\n      },\n      \"external_urls\": {\n        \"spotify\": \"https://open.spotify.com/track/0islTY4Fw6lhYbfqi8Qtdj\"\n      },\n      \"href\": \"https://api.spotify.com/v1/tracks/0islTY4Fw6lhYbfqi8Qtdj\",\n      \"id\": \"0islTY4Fw6lhYbfqi8Qtdj\",\n      \"is_local\": False,\n      \"name\": \"Hopscotch Willie\",\n      \"popularity\": 24,\n      \"preview_url\": \"https://p.scdn.co/mp3-preview/c7782dc6d7c0bb12159db4f90fba8388af034d60?cid=be22fd00039241bc96d161a63876b54c\",\n      \"track_number\": 2,\n      \"type\": \"track\",\n      \"uri\": \"spotify:track:0islTY4Fw6lhYbfqi8Qtdj\"\n    },\n    {\n      \"album\": {\n        \"album_type\": \"album\",\n        \"artists\": [{\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n            \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n            \"name\": \"Stephen Malkmus & The Jicks\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n          },\n          {\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n            \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n            \"name\": \"Stephen Malkmus\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n          },\n          {\n            \"external_urls\": {\n              \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n            },\n            \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n            \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n            \"name\": \"The Jicks\",\n            \"type\": \"artist\",\n            \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n          }\n        ],\n        \"available_markets\": [\"AR\",\n          \"BO\",\n          \"BR\",\n          \"CA\",\n          \"CL\",\n          \"CO\",\n          \"CR\",\n          \"EC\",\n          \"GT\",\n          \"HK\",\n          \"HN\",\n          \"ID\",\n          \"MX\",\n          \"MY\",\n          \"NI\",\n          \"PA\",\n          \"PE\",\n          \"PH\",\n          \"PY\",\n          \"SG\",\n          \"SV\",\n          \"TH\",\n          \"TW\",\n          \"US\",\n          \"UY\",\n          \"VN\"\n        ],\n        \"external_urls\": {\n          \"spotify\": \"https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY\"\n        },\n        \"href\": \"https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY\",\n        \"id\": \"6pWpb4IdPu9vp9mOdh5DjY\",\n        \"images\": [{\n            \"height\": 640,\n            \"url\": \"https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3\",\n            \"width\": 640\n          },\n          {\n            \"height\": 300,\n            \"url\": \"https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88\",\n            \"width\": 300\n          },\n          {\n            \"height\": 64,\n            \"url\": \"https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4\",\n            \"width\": 64\n          }\n        ],\n        \"name\": \"Real Emotional Trash\",\n        \"release_date\": \"2008-03-04\",\n        \"release_date_precision\": \"day\",\n        \"type\": \"album\",\n        \"uri\": \"spotify:album:6pWpb4IdPu9vp9mOdh5DjY\"\n      },\n      \"artists\": [{\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n          \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n          \"name\": \"Stephen Malkmus & The Jicks\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n        },\n        {\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n          \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n          \"name\": \"Stephen Malkmus\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n        },\n        {\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n          \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n          \"name\": \"The Jicks\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n        }\n      ],\n      \"available_markets\": [\"AR\",\n        \"BO\",\n        \"BR\",\n        \"CA\",\n        \"CL\",\n        \"CO\",\n        \"CR\",\n        \"EC\",\n        \"GT\",\n        \"HK\",\n        \"HN\",\n        \"ID\",\n        \"MX\",\n        \"MY\",\n        \"NI\",\n        \"PA\",\n        \"PE\",\n        \"PH\",\n        \"PY\",\n        \"SG\",\n        \"SV\",\n        \"TH\",\n        \"TW\",\n        \"US\",\n        \"UY\",\n        \"VN\"\n      ],\n      \"disc_number\": 1,\n      \"duration_ms\": 308146,\n      \"explicit\": False,\n      \"external_ids\": {\n        \"isrc\": \"USMTD0877201\"\n      },\n      \"external_urls\": {\n        \"spotify\": \"https://open.spotify.com/track/3jyFLbljUTKjE13nIWXchH\"\n      },\n      \"href\": \"https://api.spotify.com/v1/tracks/3jyFLbljUTKjE13nIWXchH\",\n      \"id\": \"3jyFLbljUTKjE13nIWXchH\",\n      \"is_local\": False,\n      \"name\": \"Dragonfly Pie\",\n      \"popularity\": 26,\n      \"preview_url\": \"https://p.scdn.co/mp3-preview/50f419e7d3e8a6a771515068622250ab06d1cc86?cid=be22fd00039241bc96d161a63876b54c\",\n      \"track_number\": 1,\n      \"type\": \"track\",\n      \"uri\": \"spotify:track:3jyFLbljUTKjE13nIWXchH\"\n    },\n    {\n      \"album\": {\n        \"album_type\": \"album\",\n        \"artists\": [{\n          \"external_urls\": {\n            \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n          },\n          \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n          \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n          \"name\": \"Stephen Malkmus & The Jicks\",\n          \"type\": \"artist\",\n          \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n        }],\n        \"available_markets\": [\"AR\",\n          \"AU\",\n          \"BO\",\n          \"BR\",\n          \"CA\",\n          \"CL\",\n          \"CO\",\n          \"CR\",\n          \"DO\",\n          \"EC\",\n          \"GT\",\n          \"HK\",\n          \"HN\",\n          \"ID\",\n          \"JP\",\n          \"MX\",\n          \"MY\",\n          \"NI\",\n          \"NZ\",\n          \"PA\",\n          \"PE\",\n          \"PH\",\n          \"PY\",\n          \"SG\",\n          \"SV\",\n          \"TH\",\n          \"TW\",\n          \"US\",\n          \"UY\",\n          \"VN\",\n          \"ZA\"\n        ],\n        \"external_urls\": {\n          \"spotify\": \"https://open.spotify.com/album/5DMvSCwRqfNVlMB5LjHOwG\"\n        },\n        \"href\": \"https://api.spotify.com/v1/albums/5DMvSCwRqfNVlMB5LjHOwG\",\n        \"id\": \"5DMvSCwRqfNVlMB5LjHOwG\",\n        \"images\": [{\n            \"height\": 640,\n            \"url\": \"https://i.scdn.co/image/bc96e20fa6b42c765db2fb904d3a70b6ef57b0bb\",\n            \"width\": 640\n          },\n          {\n            \"height\": 300,\n            \"url\": \"https://i.scdn.co/image/c7a31ed50b9c704ec066f4aac669cfb9013effb1\",\n            \"width\": 300\n          },\n          {\n            \"height\": 64,\n            \"url\": \"https://i.scdn.co/image/8551e108d0950dd62724ff2703e8c13ce7324114\",\n            \"width\": 64\n          }\n        ],\n        \"name\": \"Sparkle Hard\",\n        \"release_date\": \"2018-05-18\",\n        \"release_date_precision\": \"day\",\n        \"type\": \"album\",\n        \"uri\": \"spotify:album:5DMvSCwRqfNVlMB5LjHOwG\"\n      },\n      \"artists\": [{\n        \"external_urls\": {\n          \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n        },\n        \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n        \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n        \"name\": \"Stephen Malkmus & The Jicks\",\n        \"type\": \"artist\",\n        \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n      }],\n      \"available_markets\": [\"AR\",\n        \"AU\",\n        \"BO\",\n        \"BR\",\n        \"CA\",\n        \"CL\",\n        \"CO\",\n        \"CR\",\n        \"DO\",\n        \"EC\",\n        \"GT\",\n        \"HK\",\n        \"HN\",\n        \"ID\",\n        \"JP\",\n        \"MX\",\n        \"MY\",\n        \"NI\",\n        \"NZ\",\n        \"PA\",\n        \"PE\",\n        \"PH\",\n        \"PY\",\n        \"SG\",\n        \"SV\",\n        \"TH\",\n        \"TW\",\n        \"US\",\n        \"UY\",\n        \"VN\",\n        \"ZA\"\n      ],\n      \"disc_number\": 1,\n      \"duration_ms\": 423275,\n      \"explicit\": False,\n      \"external_ids\": {\n        \"isrc\": \"USMTD1710380\"\n      },\n      \"external_urls\": {\n        \"spotify\": \"https://open.spotify.com/track/6dNmC2YWtWbVOFOdTuRDQs\"\n      },\n      \"href\": \"https://api.spotify.com/v1/tracks/6dNmC2YWtWbVOFOdTuRDQs\",\n      \"id\": \"6dNmC2YWtWbVOFOdTuRDQs\",\n      \"is_local\": False,\n      \"name\": \"Difficulties - Let Them Eat Vowels\",\n      \"popularity\": 35,\n      \"preview_url\": \"https://p.scdn.co/mp3-preview/787be9d1bbebcd845d0793476de843fa0a4fff79?cid=be22fd00039241bc96d161a63876b54c\",\n      \"track_number\": 11,\n      \"type\": \"track\",\n      \"uri\": \"spotify:track:6dNmC2YWtWbVOFOdTuRDQs\"\n    }\n  ]\n}\n\n\n\njson_normalise(tracks_response)\n\n\nOutput:\nalbum.album_typealbum.artistsalbum.available_marketsalbum.external_urls.spotify\nalbum.hrefalbum.idalbum.imagesalbum.namealbum.release_date\nalbum.release_date_precision...external_urls.spotifyhrefidis_localnamepopularity\npreview_urltrack_numbertypeuri\n 0album[{'external_urls': {'spotify': 'https://open.s...[AR, BO, BR, CA, CL, CO,\nCR, EC, GT, HK, HN, I...https://open.spotify.com/album/6pWpb4IdPu9vp9m...\nhttps://api.spotify.com/v1/albums/6pWpb4IdPu9v...6pWpb4IdPu9vp9mOdh5DjY\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Real Emotional Trash3/4/2008day\n...https://open.spotify.com/track/0BDYBajZydY54OT...\nhttps://api.spotify.com/v1/tracks/0BDYBajZydY5...0BDYBajZydY54OTgQsH940FALSEReal\nEmotional Trash21https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590...4track\nspotify:track:0BDYBajZydY54OTgQsH940\n 1album[{'external_urls': {'spotify': 'https://open.s...[AR, BO, BR, CA, CL, CO,\nCR, EC, GT, HK, HN, I...https://open.spotify.com/album/6pWpb4IdPu9vp9m...\nhttps://api.spotify.com/v1/albums/6pWpb4IdPu9v...6pWpb4IdPu9vp9mOdh5DjY\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Real Emotional Trash3/4/2008day\n...https://open.spotify.com/track/7fdUqrzb8oCcIoK...\nhttps://api.spotify.com/v1/tracks/7fdUqrzb8oCc...7fdUqrzb8oCcIoKvFuzMrsFALSECold\nSon25https://p.scdn.co/mp3-preview/4cf4e21727def470...3track\nspotify:track:7fdUqrzb8oCcIoKvFuzMrs\n 2album[{'external_urls': {'spotify': 'https://open.s...[AR, BO, BR, CA, CL, CO,\nCR, EC, GT, HK, HN, I...https://open.spotify.com/album/6pWpb4IdPu9vp9m...\nhttps://api.spotify.com/v1/albums/6pWpb4IdPu9v...6pWpb4IdPu9vp9mOdh5DjY\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Real Emotional Trash3/4/2008day\n...https://open.spotify.com/track/0islTY4Fw6lhYbf...\nhttps://api.spotify.com/v1/tracks/0islTY4Fw6lh...0islTY4Fw6lhYbfqi8QtdjFALSE\nHopscotch Willie24https://p.scdn.co/mp3-preview/c7782dc6d7c0bb12...2track\nspotify:track:0islTY4Fw6lhYbfqi8Qtdj\n 3album[{'external_urls': {'spotify': 'https://open.s...[AR, BO, BR, CA, CL, CO,\nCR, EC, GT, HK, HN, I...https://open.spotify.com/album/6pWpb4IdPu9vp9m...\nhttps://api.spotify.com/v1/albums/6pWpb4IdPu9v...6pWpb4IdPu9vp9mOdh5DjY\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Real Emotional Trash3/4/2008day\n...https://open.spotify.com/track/3jyFLbljUTKjE13...\nhttps://api.spotify.com/v1/tracks/3jyFLbljUTKj...3jyFLbljUTKjE13nIWXchHFALSE\nDragonfly Pie26https://p.scdn.co/mp3-preview/50f419e7d3e8a6a7...1track\nspotify:track:3jyFLbljUTKjE13nIWXchH\n 4album[{'external_urls': {'spotify': 'https://open.s...[AR, AU, BO, BR, CA, CL,\nCO, CR, DO, EC, GT, H...https://open.spotify.com/album/5DMvSCwRqfNVlMB...\nhttps://api.spotify.com/v1/albums/5DMvSCwRqfNV...5DMvSCwRqfNVlMB5LjHOwG\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Sparkle Hard5/18/2018day...\nhttps://open.spotify.com/track/6dNmC2YWtWbVOFO...\nhttps://api.spotify.com/v1/tracks/6dNmC2YWtWbV...6dNmC2YWtWbVOFOdTuRDQsFALSE\nDifficulties - Let Them Eat Vowels35\nhttps://p.scdn.co/mp3-preview/787be9d1bbebcd84...11track\nspotify:track:6dNmC2YWtWbVOFOdTuRDQsSeparate Ways (Worlds Apart)\nBy default, json_normalize()  uses periods .  to indicate nested levels of the\nJSON object (which is actually converted to a Python dict  by Spotipy). In our\ncase, the album id is found in track['album']['id'], hence the period between\nalbum and id in the DataFrame. This makes things slightly annoying if we want to\ngrab a Series from our new DataFrame. In pandas, we can grab a Series from a\nDataFrame in many ways. To grab the album.id  column, for example:\n\ntracks_df['album.id']\n\n\nOutput:\n0    6pWpb4IdPu9vp9mOdh5DjY\n1    6pWpb4IdPu9vp9mOdh5DjY\n2    6pWpb4IdPu9vp9mOdh5DjY\n3    6pWpb4IdPu9vp9mOdh5DjY\n4    5DMvSCwRqfNVlMB5LjHOwG\nName: album.id, dtype: object\n\n\nor\n\ntracks_df.loc[:,'album.id']\n\n\n\nOutput:\n0    6pWpb4IdPu9vp9mOdh5DjY\n1    6pWpb4IdPu9vp9mOdh5DjY\n2    6pWpb4IdPu9vp9mOdh5DjY\n3    6pWpb4IdPu9vp9mOdh5DjY\n4    5DMvSCwRqfNVlMB5LjHOwG\nName: album.id, dtype: object\n\n\npandas also allows us to use dot notation (i.e. dataframe.column_name) to grab a\ncolumn as a Series, but only if our column name doesn't include a period\nalready. Since json_normalize()  uses a period as a separator by default, this\nruins that method. Never fear though – overriding this behavior is as simple as\noverriding the default argument in the function call:\n\ntracks_df = json_normalize(tracks_response['tracks'],sep=\"_\")\ntracks_df\n\n\nOutput:\nalbum_album_typealbum_artistsalbum_available_marketsalbum_external_urls_spotify\nalbum_hrefalbum_idalbum_imagesalbum_namealbum_release_date\nalbum_release_date_precision...external_urls_spotifyhrefidis_localnamepopularity\npreview_urltrack_numbertypeuri\n 0album[{'external_urls': {'spotify': 'https://open.s...[AR, BO, BR, CA, CL, CO,\nCR, EC, GT, HK, HN, I...https://open.spotify.com/album/6pWpb4IdPu9vp9m...\nhttps://api.spotify.com/v1/albums/6pWpb4IdPu9v...6pWpb4IdPu9vp9mOdh5DjY\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Real Emotional Trash3/4/2008day\n...https://open.spotify.com/track/0BDYBajZydY54OT...\nhttps://api.spotify.com/v1/tracks/0BDYBajZydY5...0BDYBajZydY54OTgQsH940FALSEReal\nEmotional Trash21https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590...4track\nspotify:track:0BDYBajZydY54OTgQsH940\n 1album[{'external_urls': {'spotify': 'https://open.s...[AR, BO, BR, CA, CL, CO,\nCR, EC, GT, HK, HN, I...https://open.spotify.com/album/6pWpb4IdPu9vp9m...\nhttps://api.spotify.com/v1/albums/6pWpb4IdPu9v...6pWpb4IdPu9vp9mOdh5DjY\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Real Emotional Trash3/4/2008day\n...https://open.spotify.com/track/7fdUqrzb8oCcIoK...\nhttps://api.spotify.com/v1/tracks/7fdUqrzb8oCc...7fdUqrzb8oCcIoKvFuzMrsFALSECold\nSon25https://p.scdn.co/mp3-preview/4cf4e21727def470...3track\nspotify:track:7fdUqrzb8oCcIoKvFuzMrs\n 2album[{'external_urls': {'spotify': 'https://open.s...[AR, BO, BR, CA, CL, CO,\nCR, EC, GT, HK, HN, I...https://open.spotify.com/album/6pWpb4IdPu9vp9m...\nhttps://api.spotify.com/v1/albums/6pWpb4IdPu9v...6pWpb4IdPu9vp9mOdh5DjY\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Real Emotional Trash3/4/2008day\n...https://open.spotify.com/track/0islTY4Fw6lhYbf...\nhttps://api.spotify.com/v1/tracks/0islTY4Fw6lh...0islTY4Fw6lhYbfqi8QtdjFALSE\nHopscotch Willie24https://p.scdn.co/mp3-preview/c7782dc6d7c0bb12...2track\nspotify:track:0islTY4Fw6lhYbfqi8Qtdj\n 3album[{'external_urls': {'spotify': 'https://open.s...[AR, BO, BR, CA, CL, CO,\nCR, EC, GT, HK, HN, I...https://open.spotify.com/album/6pWpb4IdPu9vp9m...\nhttps://api.spotify.com/v1/albums/6pWpb4IdPu9v...6pWpb4IdPu9vp9mOdh5DjY\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Real Emotional Trash3/4/2008day\n...https://open.spotify.com/track/3jyFLbljUTKjE13...\nhttps://api.spotify.com/v1/tracks/3jyFLbljUTKj...3jyFLbljUTKjE13nIWXchHFALSE\nDragonfly Pie26https://p.scdn.co/mp3-preview/50f419e7d3e8a6a7...1track\nspotify:track:3jyFLbljUTKjE13nIWXchH\n 4album[{'external_urls': {'spotify': 'https://open.s...[AR, AU, BO, BR, CA, CL,\nCO, CR, DO, EC, GT, H...https://open.spotify.com/album/5DMvSCwRqfNVlMB...\nhttps://api.spotify.com/v1/albums/5DMvSCwRqfNV...5DMvSCwRqfNVlMB5LjHOwG\n[{'height': 640, 'url': 'https://i.scdn.co/ima...Sparkle Hard5/18/2018day...\nhttps://open.spotify.com/track/6dNmC2YWtWbVOFO...\nhttps://api.spotify.com/v1/tracks/6dNmC2YWtWbV...6dNmC2YWtWbVOFOdTuRDQsFALSE\nDifficulties - Let Them Eat Vowels35\nhttps://p.scdn.co/mp3-preview/787be9d1bbebcd84...11track\nspotify:track:6dNmC2YWtWbVOFOdTuRDQsNow we can go back to using dot notation to\naccess a column as a Series. This saves us some typing every time we want to\ngrab a column, and it looks a bit nicer (to me, at least). I say worth it.\n\ntracks_df.album_id\n\n\nOutput:\n0    6pWpb4IdPu9vp9mOdh5DjY\n1    6pWpb4IdPu9vp9mOdh5DjY\n2    6pWpb4IdPu9vp9mOdh5DjY\n3    6pWpb4IdPu9vp9mOdh5DjY\n4    5DMvSCwRqfNVlMB5LjHOwG\nName: album_id, dtype: object\n\n\nI Need That Record\nBy including more parameters when we use json_normlize(), we can really extract\njust the data that we want from our API response.\n\nFrom our responses above, we can see that the artist  property contains a list\nof artists that are associated with a track:\n\ntracks_response['tracks'][0]['artists']\n\n\nOutput:\n[{\n    \"external_urls\": {\n      \"spotify\": \"https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe\"\n    },\n    \"href\": \"https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe\",\n    \"id\": \"7wyRA7deGRxozTyBc6QXPe\",\n    \"name\": \"Stephen Malkmus & The Jicks\",\n    \"type\": \"artist\",\n    \"uri\": \"spotify:artist:7wyRA7deGRxozTyBc6QXPe\"\n  },\n  {\n    \"external_urls\": {\n      \"spotify\": \"https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8\"\n    },\n    \"href\": \"https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8\",\n    \"id\": \"0WISkx0PwT6lYWdPqKUJY8\",\n    \"name\": \"Stephen Malkmus\",\n    \"type\": \"artist\",\n    \"uri\": \"spotify:artist:0WISkx0PwT6lYWdPqKUJY8\"\n  },\n  {\n    \"external_urls\": {\n      \"spotify\": \"https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7\"\n    },\n    \"href\": \"https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7\",\n    \"id\": \"7uStwCeP54Za8gXUFCf5L7\",\n    \"name\": \"The Jicks\",\n    \"type\": \"artist\",\n    \"uri\": \"spotify:artist:7uStwCeP54Za8gXUFCf5L7\"\n  }\n]\n\n\nLet's say I want to load this data into a database later. It would be nice to\nhave a join table that maps each of the artists that are associated with each\ntrack. Luckily, this is possible with json_normalize()'s record_path  and meta \nparameters.\n\nrecord_path  tells json_normalize()  what path of keys leads to each individual\nrecord in the JSON object. In our case, we want to grab every artist id, so our\nfunction call will look like:\n\njson_normalize(tracks_response['tracks'],record_path=['artists'],sep=\"_\")\n\n\n\nexternal_urls href id name type uri\n 1 {'spotify': 'https://open.spotify.com/artist/7... \nhttps://api.spotify.com/v1/artists/7wyRA7deGRx... 7wyRA7deGRxozTyBc6QXPe Stephen\nMalkmus & The Jicks artist spotify:artist:7wyRA7deGRxozTyBc6QXPe\n 1 {'spotify': 'https://open.spotify.com/artist/0... \nhttps://api.spotify.com/v1/artists/0WISkx0PwT6... 0WISkx0PwT6lYWdPqKUJY8 Stephen\nMalkmus artist spotify:artist:0WISkx0PwT6lYWdPqKUJY8\n 2 {'spotify': 'https://open.spotify.com/artist/7... \nhttps://api.spotify.com/v1/artists/7uStwCeP54Z... 7uStwCeP54Za8gXUFCf5L7 The\nJicks artist spotify:artist:7uStwCeP54Za8gXUFCf5L7\n 3 {'spotify': 'https://open.spotify.com/artist/7... \nhttps://api.spotify.com/v1/artists/7wyRA7deGRx... 7wyRA7deGRxozTyBc6QXPe Stephen\nMalkmus & The Jicks artist spotify:artist:7wyRA7deGRxozTyBc6QXPe\n 4 {'spotify': 'https://open.spotify.com/artist/0... \nhttps://api.spotify.com/v1/artists/0WISkx0PwT6... 0WISkx0PwT6lYWdPqKUJY8 Stephen\nMalkmus artist spotify:artist:0WISkx0PwT6lYWdPqKUJY8\n 5 {'spotify': 'https://open.spotify.com/artist/7... \nhttps://api.spotify.com/v1/artists/7uStwCeP54Z... 7uStwCeP54Za8gXUFCf5L7 The\nJicks artist spotify:artist:7uStwCeP54Za8gXUFCf5L7\n 6 {'spotify': 'https://open.spotify.com/artist/7... \nhttps://api.spotify.com/v1/artists/7wyRA7deGRx... 7wyRA7deGRxozTyBc6QXPe Stephen\nMalkmus & The Jicks artist spotify:artist:7wyRA7deGRxozTyBc6QXPe\n 7 {'spotify': 'https://open.spotify.com/artist/0... \nhttps://api.spotify.com/v1/artists/0WISkx0PwT6... 0WISkx0PwT6lYWdPqKUJY8 Stephen\nMalkmus artist spotify:artist:0WISkx0PwT6lYWdPqKUJY8\n 8 {'spotify': 'https://open.spotify.com/artist/7... \nhttps://api.spotify.com/v1/artists/7uStwCeP54Z... 7uStwCeP54Za8gXUFCf5L7 The\nJicks artist spotify:artist:7uStwCeP54Za8gXUFCf5L7\n 9 {'spotify': 'https://open.spotify.com/artist/7... \nhttps://api.spotify.com/v1/artists/7wyRA7deGRx... 7wyRA7deGRxozTyBc6QXPe Stephen\nMalkmus & The Jicks artist spotify:artist:7wyRA7deGRxozTyBc6QXPe\n 10 {'spotify': 'https://open.spotify.com/artist/0... \nhttps://api.spotify.com/v1/artists/0WISkx0PwT6... 0WISkx0PwT6lYWdPqKUJY8 Stephen\nMalkmus artist spotify:artist:0WISkx0PwT6lYWdPqKUJY8\n 11 {'spotify': 'https://open.spotify.com/artist/7... \nhttps://api.spotify.com/v1/artists/7uStwCeP54Z... 7uStwCeP54Za8gXUFCf5L7 The\nJicks artist spotify:artist:7uStwCeP54Za8gXUFCf5L7\n 12 {'spotify': 'https://open.spotify.com/artist/7... \nhttps://api.spotify.com/v1/artists/7wyRA7deGRx... 7wyRA7deGRxozTyBc6QXPe Stephen\nMalkmus & The Jicks artist spotify:artist:7wyRA7deGRxozTyBc6QXPeCool – we're\nalmost there. Now we want to use the meta  parameter to specify what data we\nwant to include from the rest of the JSON object. In our case, we want to keep\nthe track id and map it to the artist id. If we look back at our API response,\nthe name of the column that included the track is is called, appropriately, id,\nso our full function call should look like this:\n\njson_normalize(tracks_response['tracks'],record_path=['artists'],meta=['id'],sep=\"_\")\n\n\nOutput:\n-----------------------------------------\nValueError                             Traceback (most recent call last)\n\n    <ipython-input-14-77e00a98c3c0> in <module>()\n    ----> 1 json_normalize(tracks_response['tracks'],record_path=['artists'],meta=['id'],sep=\"_\")\n\n    ~/anaconda3/envs/music_data/lib/python3.6/site-packages/pandas/io/json/normalize.py in json_normalize(data, record_path, meta, meta_prefix, record_prefix, errors, sep)\n        268         if k in result:\n        269             raise ValueError('Conflicting metadata name {name}, '\n    --> 270                              'need distinguishing prefix '.format(name=k))\n        271 \n        272         result[k] = np.array(v).repeat(lengths)\n    \nValueError: Conflicting metadata name id, need distinguishing prefix \n\n\nUh oh – an error! What's going on? Well, it turns out that both the album id and\ntrack id were given the key id. pandas doesn't like that, and it gives us a\nhelpful error to tell us so: ValueError: Conflicting metadata name id, need\ndistinguishing prefix.\n\nThere are two more parameters we can use to overcome this error: record_prefix \nand meta_prefix. These are strings we'll add to the beginning of our records and\nmetadata to prevent these naming conflicts. Since we're dealing with Spotify\nartist ids for our records and Spotify track ids as the metadata, I'll use \nsp_artist_  and sp_track_  respectively. When that's done, I'll select only the\ncolumns that we're interested in.\n\nartist_and_track = json_normalize(\n    data=tracks_response['tracks'],\n    record_path='artists',\n    meta=['id'],\n    record_prefix='sp_artist_',\n    meta_prefix='sp_track_',\n    sep=\"_\"\n)\nartist_and_track = artist_and_track[['sp_track_id','sp_artist_id']]\nartist_and_track\n\n\nOutput:\nsp_track_id sp_artist_id\n 00BDYBajZydY54OTgQsH940 7wyRA7deGRxozTyBc6QXPe\n 10BDYBajZydY54OTgQsH940 0WISkx0PwT6lYWdPqKUJY8\n 20BDYBajZydY54OTgQsH940 7uStwCeP54Za8gXUFCf5L7\n 37fdUqrzb8oCcIoKvFuzMrs 7wyRA7deGRxozTyBc6QXPe\n 47fdUqrzb8oCcIoKvFuzMrs 0WISkx0PwT6lYWdPqKUJY8\n 57fdUqrzb8oCcIoKvFuzMrs 7uStwCeP54Za8gXUFCf5L7\n 60islTY4Fw6lhYbfqi8Qtdj 7wyRA7deGRxozTyBc6QXPe\n 70islTY4Fw6lhYbfqi8Qtdj 0WISkx0PwT6lYWdPqKUJY8\n 80islTY4Fw6lhYbfqi8Qtdj 7uStwCeP54Za8gXUFCf5L7\n 93jyFLbljUTKjE13nIWXchH 7wyRA7deGRxozTyBc6QXPe\n 103jyFLbljUTKjE13nIWXchH 0WISkx0PwT6lYWdPqKUJY8\n 113jyFLbljUTKjE13nIWXchH 7uStwCeP54Za8gXUFCf5L7\n 126dNmC2YWtWbVOFOdTuRDQs 7wyRA7deGRxozTyBc6QXPeTL;DR\n * Use pd.io.json.json_normalize()  to automagically flatten a nested JSON\n   object into a DataFrame\n * Make your life slightly easier when it comes to selecting columns by\n   overriding the default sep  parameter\n * Specify what data constitutes a record with the record_path  parameter\n * Include data from outside of the record path with the meta  parameter\n * Fix naming conflicts if they arise with the record_prefix  and meta_prefix \n   parameters","html":"<p>In his post about <a href=\"https://hackersandslackers.com/extracting-massive-datasets-from-apis/\">extracting data from APIs</a>, <a href=\"https://hackersandslackers.com/author/todd/\">Todd</a> demonstrated a nice way to massage JSON into a pandas DataFrame. This method works great when our JSON response is flat, because <code>dict.keys()</code> only gets the keys on the first \"level\" of a dictionary. It gets a little trickier when our JSON starts to become nested though, as I experienced when working with <a href=\"https://developer.spotify.com/documentation/web-api/\">Spotify's API</a> via the <a href=\"https://spotipy.readthedocs.io/en/latest/\">Spotipy</a> library. For example, take a look at a response from their <code>https://api.spotify.com/v1/tracks/{id}</code> endpoint:</p><pre><code class=\"language-python\">import spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\n\nspotify_client_id = 'YOUR_ID'\nspotify_client_secret  = 'YOUR_SECRET'\nclient_credentials_manager = SpotifyClientCredentials(client_id=spotify_client_id, client_secret=spotify_client_secret)\nsp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n</code></pre>\n<pre><code class=\"language-python\">track_response = sp.track('0BDYBajZydY54OTgQsH940')\ntrack_response\n</code></pre>\n<h3 id=\"output-\">Output:</h3><pre><code class=\"language-json\">{\n  &quot;album&quot;: {\n    &quot;album_type&quot;: &quot;album&quot;,\n    &quot;artists&quot;: [{\n        &quot;external_urls&quot;: {\n          &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n        },\n        &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n        &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n        &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n        &quot;type&quot;: &quot;artist&quot;,\n        &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n      },\n      {\n        &quot;external_urls&quot;: {\n          &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n        },\n        &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n        &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n        &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n        &quot;type&quot;: &quot;artist&quot;,\n        &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n      },\n      {\n        &quot;external_urls&quot;: {\n          &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n        },\n        &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n        &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n        &quot;name&quot;: &quot;The Jicks&quot;,\n        &quot;type&quot;: &quot;artist&quot;,\n        &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n      }\n    ],\n    &quot;available_markets&quot;: [&quot;AR&quot;,\n      &quot;BO&quot;,\n      &quot;BR&quot;,\n      &quot;CA&quot;,\n      &quot;...&quot;,\n      &quot;US&quot;,\n      &quot;UY&quot;,\n      &quot;VN&quot;\n    ],\n    &quot;external_urls&quot;: {\n      &quot;spotify&quot;: &quot;https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY&quot;\n    },\n    &quot;href&quot;: &quot;https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY&quot;,\n    &quot;id&quot;: &quot;6pWpb4IdPu9vp9mOdh5DjY&quot;,\n    &quot;images&quot;: [{\n        &quot;height&quot;: 640,\n        &quot;url&quot;: &quot;https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3&quot;,\n        &quot;width&quot;: 640\n      },\n      {\n        &quot;height&quot;: 300,\n        &quot;url&quot;: &quot;https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88&quot;,\n        &quot;width&quot;: 300\n      },\n      {\n        &quot;height&quot;: 64,\n        &quot;url&quot;: &quot;https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4&quot;,\n        &quot;width&quot;: 64\n      }\n    ],\n    &quot;name&quot;: &quot;Real Emotional Trash&quot;,\n    &quot;release_date&quot;: &quot;2008-03-04&quot;,\n    &quot;release_date_precision&quot;: &quot;day&quot;,\n    &quot;type&quot;: &quot;album&quot;,\n    &quot;uri&quot;: &quot;spotify:album:6pWpb4IdPu9vp9mOdh5DjY&quot;\n  },\n  &quot;artists&quot;: [{\n      &quot;external_urls&quot;: {\n        &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n      },\n      &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n      &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n      &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n      &quot;type&quot;: &quot;artist&quot;,\n      &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n    },\n    {\n      &quot;external_urls&quot;: {\n        &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n      },\n      &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n      &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n      &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n      &quot;type&quot;: &quot;artist&quot;,\n      &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n    },\n    {\n      &quot;external_urls&quot;: {\n        &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n      },\n      &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n      &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n      &quot;name&quot;: &quot;The Jicks&quot;,\n      &quot;type&quot;: &quot;artist&quot;,\n      &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n    }\n  ],\n  &quot;available_markets&quot;: [&quot;AR&quot;,\n    &quot;BO&quot;,\n    &quot;BR&quot;,\n    &quot;CA&quot;,\n    &quot;...&quot;,\n    &quot;US&quot;,\n    &quot;UY&quot;,\n    &quot;VN&quot;\n  ],\n  &quot;disc_number&quot;: 1,\n  &quot;duration_ms&quot;: 608826,\n  &quot;explicit&quot;: False,\n  &quot;external_ids&quot;: {\n    &quot;isrc&quot;: &quot;USMTD0877204&quot;\n  },\n  &quot;external_urls&quot;: {\n    &quot;spotify&quot;: &quot;https://open.spotify.com/track/0BDYBajZydY54OTgQsH940&quot;\n  },\n  &quot;href&quot;: &quot;https://api.spotify.com/v1/tracks/0BDYBajZydY54OTgQsH940&quot;,\n  &quot;id&quot;: &quot;0BDYBajZydY54OTgQsH940&quot;,\n  &quot;is_local&quot;: False,\n  &quot;name&quot;: &quot;Real Emotional Trash&quot;,\n  &quot;popularity&quot;: 21,\n  &quot;preview_url&quot;: &quot;https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590d5819849e1aad3eff981dc75?cid=be22fd00039241bc96d161a63876b54c&quot;,\n  &quot;track_number&quot;: 4,\n  &quot;type&quot;: &quot;track&quot;,\n  &quot;uri&quot;: &quot;spotify:track:0BDYBajZydY54OTgQsH940&quot;\n}\n</code></pre>\n<p>In addition to plenty of information about the track, Spotify also includes information about the album that contains the track. If we were to just use the <code>dict.keys()</code> method to turn this response into a DataFrame, we'd be missing out on all that extra album information. Well, it would be there, just not readily accessible.</p><pre><code class=\"language-python\">track_response.keys()\n</code></pre>\n<h3 id=\"output--1\">Output:</h3><pre><code class=\"language-python\">dict_keys(['album', 'artists', 'available_markets', 'disc_number', 'duration_ms', 'explicit', 'external_ids', 'external_urls', 'href', 'id', 'is_local', 'name', 'popularity', 'preview_url', 'track_number', 'type', 'uri'])\n</code></pre>\n<p>So how do we get around this? Well, we could write our own function, but because pandas is amazing, it already has a built in tool that takes care of this for us.</p><h2 id=\"data-normalization\">Data Normalization</h2><p>Meet <code>json_normalize()</code>:</p><pre><code class=\"language-python\">import pandas as pd\nfrom pandas.io.json import json_normalize\njson_normalize(track_response)\n</code></pre>\n<h3 id=\"output--2\">Output:</h3><div class=\"tableshadow tableContainer\" data-simplebar=\"\">\n<table class=\"responsive-table\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>album.album_type</th>\n      <th>album.artists</th>\n      <th>album.available_markets</th>\n      <th>album.external_urls.spotify</th>\n      <th>album.href</th>\n      <th>album.id</th>\n      <th>album.images</th>\n      <th>album.name</th>\n      <th>album.release_date</th>\n      <th>album.release_date_precision</th>\n      <th>...</th>\n      <th>external_urls.spotify</th>\n      <th>href</th>\n      <th>id</th>\n      <th>is_local</th>\n      <th>name</th>\n      <th>popularity</th>\n      <th>preview_url</th>\n      <th>track_number</th>\n      <th>type</th>\n      <th>uri</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>album</td>\n      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n      <td>[AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...</td>\n      <td>https://open.spotify.com/album/6pWpb4IdPu9vp9m...</td>\n      <td>https://api.spotify.com/v1/albums/6pWpb4IdPu9v...</td>\n      <td>6pWpb4IdPu9vp9mOdh5DjY</td>\n      <td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td>\n      <td>Real Emotional Trash</td>\n      <td>2008-03-04</td>\n      <td>day</td>\n      <td>...</td>\n      <td>https://open.spotify.com/track/0BDYBajZydY54OT...</td>\n      <td>https://api.spotify.com/v1/tracks/0BDYBajZydY5...</td>\n      <td>0BDYBajZydY54OTgQsH940</td>\n      <td>False</td>\n      <td>Real Emotional Trash</td>\n      <td>21</td>\n      <td>https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590...</td>\n      <td>4</td>\n      <td>track</td>\n      <td>spotify:track:0BDYBajZydY54OTgQsH940</td>\n    </tr>\n  </tbody>\n</table>\n</div><p>Yep – it's that easy. pandas takes our nested JSON object, flattens it out, and turns it into a DataFrame.</p><p>This makes our life easier when we're dealing with one record, but it <em>really</em> comes in handy when we're dealing with a response that contains multiple records.</p><pre><code class=\"language-python\">tracks_response = sp.tracks(\n    ['0BDYBajZydY54OTgQsH940',\n     '7fdUqrzb8oCcIoKvFuzMrs',\n     '0islTY4Fw6lhYbfqi8Qtdj',\n     '3jyFLbljUTKjE13nIWXchH',\n     '6dNmC2YWtWbVOFOdTuRDQs']\n)\ntracks_response\n</code></pre>\n<h3 id=\"output--3\">Output:</h3><pre><code class=\"language-json\">{\n  &quot;tracks&quot;: [{\n      &quot;album&quot;: {\n        &quot;album_type&quot;: &quot;album&quot;,\n        &quot;artists&quot;: [{\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n            &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n            &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n          },\n          {\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n            &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n            &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n          },\n          {\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n            &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n            &quot;name&quot;: &quot;The Jicks&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n          }\n        ],\n        &quot;available_markets&quot;: [&quot;AR&quot;,\n          &quot;BO&quot;,\n          &quot;BR&quot;,\n          &quot;CA&quot;,\n          &quot;CL&quot;,\n          &quot;CO&quot;,\n          &quot;CR&quot;,\n          &quot;EC&quot;,\n          &quot;GT&quot;,\n          &quot;HK&quot;,\n          &quot;HN&quot;,\n          &quot;ID&quot;,\n          &quot;MX&quot;,\n          &quot;MY&quot;,\n          &quot;NI&quot;,\n          &quot;PA&quot;,\n          &quot;PE&quot;,\n          &quot;PH&quot;,\n          &quot;PY&quot;,\n          &quot;SG&quot;,\n          &quot;SV&quot;,\n          &quot;TH&quot;,\n          &quot;TW&quot;,\n          &quot;US&quot;,\n          &quot;UY&quot;,\n          &quot;VN&quot;\n        ],\n        &quot;external_urls&quot;: {\n          &quot;spotify&quot;: &quot;https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY&quot;\n        },\n        &quot;href&quot;: &quot;https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY&quot;,\n        &quot;id&quot;: &quot;6pWpb4IdPu9vp9mOdh5DjY&quot;,\n        &quot;images&quot;: [{\n            &quot;height&quot;: 640,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3&quot;,\n            &quot;width&quot;: 640\n          },\n          {\n            &quot;height&quot;: 300,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88&quot;,\n            &quot;width&quot;: 300\n          },\n          {\n            &quot;height&quot;: 64,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4&quot;,\n            &quot;width&quot;: 64\n          }\n        ],\n        &quot;name&quot;: &quot;Real Emotional Trash&quot;,\n        &quot;release_date&quot;: &quot;2008-03-04&quot;,\n        &quot;release_date_precision&quot;: &quot;day&quot;,\n        &quot;type&quot;: &quot;album&quot;,\n        &quot;uri&quot;: &quot;spotify:album:6pWpb4IdPu9vp9mOdh5DjY&quot;\n      },\n      &quot;artists&quot;: [{\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n        },\n        {\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n          &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n          &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n        },\n        {\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n          &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n          &quot;name&quot;: &quot;The Jicks&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n        }\n      ],\n      &quot;available_markets&quot;: [&quot;AR&quot;,\n        &quot;BO&quot;,\n        &quot;BR&quot;,\n        &quot;CA&quot;,\n        &quot;CL&quot;,\n        &quot;CO&quot;,\n        &quot;CR&quot;,\n        &quot;EC&quot;,\n        &quot;GT&quot;,\n        &quot;HK&quot;,\n        &quot;HN&quot;,\n        &quot;ID&quot;,\n        &quot;MX&quot;,\n        &quot;MY&quot;,\n        &quot;NI&quot;,\n        &quot;PA&quot;,\n        &quot;PE&quot;,\n        &quot;PH&quot;,\n        &quot;PY&quot;,\n        &quot;SG&quot;,\n        &quot;SV&quot;,\n        &quot;TH&quot;,\n        &quot;TW&quot;,\n        &quot;US&quot;,\n        &quot;UY&quot;,\n        &quot;VN&quot;\n      ],\n      &quot;disc_number&quot;: 1,\n      &quot;duration_ms&quot;: 608826,\n      &quot;explicit&quot;: False,\n      &quot;external_ids&quot;: {\n        &quot;isrc&quot;: &quot;USMTD0877204&quot;\n      },\n      &quot;external_urls&quot;: {\n        &quot;spotify&quot;: &quot;https://open.spotify.com/track/0BDYBajZydY54OTgQsH940&quot;\n      },\n      &quot;href&quot;: &quot;https://api.spotify.com/v1/tracks/0BDYBajZydY54OTgQsH940&quot;,\n      &quot;id&quot;: &quot;0BDYBajZydY54OTgQsH940&quot;,\n      &quot;is_local&quot;: False,\n      &quot;name&quot;: &quot;Real Emotional Trash&quot;,\n      &quot;popularity&quot;: 21,\n      &quot;preview_url&quot;: &quot;https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590d5819849e1aad3eff981dc75?cid=be22fd00039241bc96d161a63876b54c&quot;,\n      &quot;track_number&quot;: 4,\n      &quot;type&quot;: &quot;track&quot;,\n      &quot;uri&quot;: &quot;spotify:track:0BDYBajZydY54OTgQsH940&quot;\n    },\n    {\n      &quot;album&quot;: {\n        &quot;album_type&quot;: &quot;album&quot;,\n        &quot;artists&quot;: [{\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n            &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n            &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n          },\n          {\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n            &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n            &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n          },\n          {\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n            &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n            &quot;name&quot;: &quot;The Jicks&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n          }\n        ],\n        &quot;available_markets&quot;: [&quot;AR&quot;,\n          &quot;BO&quot;,\n          &quot;BR&quot;,\n          &quot;CA&quot;,\n          &quot;CL&quot;,\n          &quot;CO&quot;,\n          &quot;CR&quot;,\n          &quot;EC&quot;,\n          &quot;GT&quot;,\n          &quot;HK&quot;,\n          &quot;HN&quot;,\n          &quot;ID&quot;,\n          &quot;MX&quot;,\n          &quot;MY&quot;,\n          &quot;NI&quot;,\n          &quot;PA&quot;,\n          &quot;PE&quot;,\n          &quot;PH&quot;,\n          &quot;PY&quot;,\n          &quot;SG&quot;,\n          &quot;SV&quot;,\n          &quot;TH&quot;,\n          &quot;TW&quot;,\n          &quot;US&quot;,\n          &quot;UY&quot;,\n          &quot;VN&quot;\n        ],\n        &quot;external_urls&quot;: {\n          &quot;spotify&quot;: &quot;https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY&quot;\n        },\n        &quot;href&quot;: &quot;https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY&quot;,\n        &quot;id&quot;: &quot;6pWpb4IdPu9vp9mOdh5DjY&quot;,\n        &quot;images&quot;: [{\n            &quot;height&quot;: 640,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3&quot;,\n            &quot;width&quot;: 640\n          },\n          {\n            &quot;height&quot;: 300,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88&quot;,\n            &quot;width&quot;: 300\n          },\n          {\n            &quot;height&quot;: 64,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4&quot;,\n            &quot;width&quot;: 64\n          }\n        ],\n        &quot;name&quot;: &quot;Real Emotional Trash&quot;,\n        &quot;release_date&quot;: &quot;2008-03-04&quot;,\n        &quot;release_date_precision&quot;: &quot;day&quot;,\n        &quot;type&quot;: &quot;album&quot;,\n        &quot;uri&quot;: &quot;spotify:album:6pWpb4IdPu9vp9mOdh5DjY&quot;\n      },\n      &quot;artists&quot;: [{\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n        },\n        {\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n          &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n          &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n        },\n        {\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n          &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n          &quot;name&quot;: &quot;The Jicks&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n        }\n      ],\n      &quot;available_markets&quot;: [&quot;AR&quot;,\n        &quot;BO&quot;,\n        &quot;BR&quot;,\n        &quot;CA&quot;,\n        &quot;CL&quot;,\n        &quot;CO&quot;,\n        &quot;CR&quot;,\n        &quot;EC&quot;,\n        &quot;GT&quot;,\n        &quot;HK&quot;,\n        &quot;HN&quot;,\n        &quot;ID&quot;,\n        &quot;MX&quot;,\n        &quot;MY&quot;,\n        &quot;NI&quot;,\n        &quot;PA&quot;,\n        &quot;PE&quot;,\n        &quot;PH&quot;,\n        &quot;PY&quot;,\n        &quot;SG&quot;,\n        &quot;SV&quot;,\n        &quot;TH&quot;,\n        &quot;TW&quot;,\n        &quot;US&quot;,\n        &quot;UY&quot;,\n        &quot;VN&quot;\n      ],\n      &quot;disc_number&quot;: 1,\n      &quot;duration_ms&quot;: 222706,\n      &quot;explicit&quot;: False,\n      &quot;external_ids&quot;: {\n        &quot;isrc&quot;: &quot;USMTD0877203&quot;\n      },\n      &quot;external_urls&quot;: {\n        &quot;spotify&quot;: &quot;https://open.spotify.com/track/7fdUqrzb8oCcIoKvFuzMrs&quot;\n      },\n      &quot;href&quot;: &quot;https://api.spotify.com/v1/tracks/7fdUqrzb8oCcIoKvFuzMrs&quot;,\n      &quot;id&quot;: &quot;7fdUqrzb8oCcIoKvFuzMrs&quot;,\n      &quot;is_local&quot;: False,\n      &quot;name&quot;: &quot;Cold Son&quot;,\n      &quot;popularity&quot;: 25,\n      &quot;preview_url&quot;: &quot;https://p.scdn.co/mp3-preview/4cf4e21727def47097e27d30de16ffe9f99b7774?cid=be22fd00039241bc96d161a63876b54c&quot;,\n      &quot;track_number&quot;: 3,\n      &quot;type&quot;: &quot;track&quot;,\n      &quot;uri&quot;: &quot;spotify:track:7fdUqrzb8oCcIoKvFuzMrs&quot;\n    },\n    {\n      &quot;album&quot;: {\n        &quot;album_type&quot;: &quot;album&quot;,\n        &quot;artists&quot;: [{\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n            &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n            &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n          },\n          {\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n            &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n            &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n          },\n          {\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n            &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n            &quot;name&quot;: &quot;The Jicks&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n          }\n        ],\n        &quot;available_markets&quot;: [&quot;AR&quot;,\n          &quot;BO&quot;,\n          &quot;BR&quot;,\n          &quot;CA&quot;,\n          &quot;CL&quot;,\n          &quot;CO&quot;,\n          &quot;CR&quot;,\n          &quot;EC&quot;,\n          &quot;GT&quot;,\n          &quot;HK&quot;,\n          &quot;HN&quot;,\n          &quot;ID&quot;,\n          &quot;MX&quot;,\n          &quot;MY&quot;,\n          &quot;NI&quot;,\n          &quot;PA&quot;,\n          &quot;PE&quot;,\n          &quot;PH&quot;,\n          &quot;PY&quot;,\n          &quot;SG&quot;,\n          &quot;SV&quot;,\n          &quot;TH&quot;,\n          &quot;TW&quot;,\n          &quot;US&quot;,\n          &quot;UY&quot;,\n          &quot;VN&quot;\n        ],\n        &quot;external_urls&quot;: {\n          &quot;spotify&quot;: &quot;https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY&quot;\n        },\n        &quot;href&quot;: &quot;https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY&quot;,\n        &quot;id&quot;: &quot;6pWpb4IdPu9vp9mOdh5DjY&quot;,\n        &quot;images&quot;: [{\n            &quot;height&quot;: 640,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3&quot;,\n            &quot;width&quot;: 640\n          },\n          {\n            &quot;height&quot;: 300,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88&quot;,\n            &quot;width&quot;: 300\n          },\n          {\n            &quot;height&quot;: 64,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4&quot;,\n            &quot;width&quot;: 64\n          }\n        ],\n        &quot;name&quot;: &quot;Real Emotional Trash&quot;,\n        &quot;release_date&quot;: &quot;2008-03-04&quot;,\n        &quot;release_date_precision&quot;: &quot;day&quot;,\n        &quot;type&quot;: &quot;album&quot;,\n        &quot;uri&quot;: &quot;spotify:album:6pWpb4IdPu9vp9mOdh5DjY&quot;\n      },\n      &quot;artists&quot;: [{\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n        },\n        {\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n          &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n          &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n        },\n        {\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n          &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n          &quot;name&quot;: &quot;The Jicks&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n        }\n      ],\n      &quot;available_markets&quot;: [&quot;AR&quot;,\n        &quot;BO&quot;,\n        &quot;BR&quot;,\n        &quot;CA&quot;,\n        &quot;CL&quot;,\n        &quot;CO&quot;,\n        &quot;CR&quot;,\n        &quot;EC&quot;,\n        &quot;GT&quot;,\n        &quot;HK&quot;,\n        &quot;HN&quot;,\n        &quot;ID&quot;,\n        &quot;MX&quot;,\n        &quot;MY&quot;,\n        &quot;NI&quot;,\n        &quot;PA&quot;,\n        &quot;PE&quot;,\n        &quot;PH&quot;,\n        &quot;PY&quot;,\n        &quot;SG&quot;,\n        &quot;SV&quot;,\n        &quot;TH&quot;,\n        &quot;TW&quot;,\n        &quot;US&quot;,\n        &quot;UY&quot;,\n        &quot;VN&quot;\n      ],\n      &quot;disc_number&quot;: 1,\n      &quot;duration_ms&quot;: 416173,\n      &quot;explicit&quot;: False,\n      &quot;external_ids&quot;: {\n        &quot;isrc&quot;: &quot;USMTD0877202&quot;\n      },\n      &quot;external_urls&quot;: {\n        &quot;spotify&quot;: &quot;https://open.spotify.com/track/0islTY4Fw6lhYbfqi8Qtdj&quot;\n      },\n      &quot;href&quot;: &quot;https://api.spotify.com/v1/tracks/0islTY4Fw6lhYbfqi8Qtdj&quot;,\n      &quot;id&quot;: &quot;0islTY4Fw6lhYbfqi8Qtdj&quot;,\n      &quot;is_local&quot;: False,\n      &quot;name&quot;: &quot;Hopscotch Willie&quot;,\n      &quot;popularity&quot;: 24,\n      &quot;preview_url&quot;: &quot;https://p.scdn.co/mp3-preview/c7782dc6d7c0bb12159db4f90fba8388af034d60?cid=be22fd00039241bc96d161a63876b54c&quot;,\n      &quot;track_number&quot;: 2,\n      &quot;type&quot;: &quot;track&quot;,\n      &quot;uri&quot;: &quot;spotify:track:0islTY4Fw6lhYbfqi8Qtdj&quot;\n    },\n    {\n      &quot;album&quot;: {\n        &quot;album_type&quot;: &quot;album&quot;,\n        &quot;artists&quot;: [{\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n            &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n            &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n          },\n          {\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n            &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n            &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n          },\n          {\n            &quot;external_urls&quot;: {\n              &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n            },\n            &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n            &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n            &quot;name&quot;: &quot;The Jicks&quot;,\n            &quot;type&quot;: &quot;artist&quot;,\n            &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n          }\n        ],\n        &quot;available_markets&quot;: [&quot;AR&quot;,\n          &quot;BO&quot;,\n          &quot;BR&quot;,\n          &quot;CA&quot;,\n          &quot;CL&quot;,\n          &quot;CO&quot;,\n          &quot;CR&quot;,\n          &quot;EC&quot;,\n          &quot;GT&quot;,\n          &quot;HK&quot;,\n          &quot;HN&quot;,\n          &quot;ID&quot;,\n          &quot;MX&quot;,\n          &quot;MY&quot;,\n          &quot;NI&quot;,\n          &quot;PA&quot;,\n          &quot;PE&quot;,\n          &quot;PH&quot;,\n          &quot;PY&quot;,\n          &quot;SG&quot;,\n          &quot;SV&quot;,\n          &quot;TH&quot;,\n          &quot;TW&quot;,\n          &quot;US&quot;,\n          &quot;UY&quot;,\n          &quot;VN&quot;\n        ],\n        &quot;external_urls&quot;: {\n          &quot;spotify&quot;: &quot;https://open.spotify.com/album/6pWpb4IdPu9vp9mOdh5DjY&quot;\n        },\n        &quot;href&quot;: &quot;https://api.spotify.com/v1/albums/6pWpb4IdPu9vp9mOdh5DjY&quot;,\n        &quot;id&quot;: &quot;6pWpb4IdPu9vp9mOdh5DjY&quot;,\n        &quot;images&quot;: [{\n            &quot;height&quot;: 640,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/918fdb6fdffccf2bd2dd1a1a93136000f8cf9bd3&quot;,\n            &quot;width&quot;: 640\n          },\n          {\n            &quot;height&quot;: 300,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/fb39290ebca6fac424d4a40611a7e0d1146c5f88&quot;,\n            &quot;width&quot;: 300\n          },\n          {\n            &quot;height&quot;: 64,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/873da4a0a21acd96e4a0036c9ecd0580b62652d4&quot;,\n            &quot;width&quot;: 64\n          }\n        ],\n        &quot;name&quot;: &quot;Real Emotional Trash&quot;,\n        &quot;release_date&quot;: &quot;2008-03-04&quot;,\n        &quot;release_date_precision&quot;: &quot;day&quot;,\n        &quot;type&quot;: &quot;album&quot;,\n        &quot;uri&quot;: &quot;spotify:album:6pWpb4IdPu9vp9mOdh5DjY&quot;\n      },\n      &quot;artists&quot;: [{\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n        },\n        {\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n          &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n          &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n        },\n        {\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n          &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n          &quot;name&quot;: &quot;The Jicks&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n        }\n      ],\n      &quot;available_markets&quot;: [&quot;AR&quot;,\n        &quot;BO&quot;,\n        &quot;BR&quot;,\n        &quot;CA&quot;,\n        &quot;CL&quot;,\n        &quot;CO&quot;,\n        &quot;CR&quot;,\n        &quot;EC&quot;,\n        &quot;GT&quot;,\n        &quot;HK&quot;,\n        &quot;HN&quot;,\n        &quot;ID&quot;,\n        &quot;MX&quot;,\n        &quot;MY&quot;,\n        &quot;NI&quot;,\n        &quot;PA&quot;,\n        &quot;PE&quot;,\n        &quot;PH&quot;,\n        &quot;PY&quot;,\n        &quot;SG&quot;,\n        &quot;SV&quot;,\n        &quot;TH&quot;,\n        &quot;TW&quot;,\n        &quot;US&quot;,\n        &quot;UY&quot;,\n        &quot;VN&quot;\n      ],\n      &quot;disc_number&quot;: 1,\n      &quot;duration_ms&quot;: 308146,\n      &quot;explicit&quot;: False,\n      &quot;external_ids&quot;: {\n        &quot;isrc&quot;: &quot;USMTD0877201&quot;\n      },\n      &quot;external_urls&quot;: {\n        &quot;spotify&quot;: &quot;https://open.spotify.com/track/3jyFLbljUTKjE13nIWXchH&quot;\n      },\n      &quot;href&quot;: &quot;https://api.spotify.com/v1/tracks/3jyFLbljUTKjE13nIWXchH&quot;,\n      &quot;id&quot;: &quot;3jyFLbljUTKjE13nIWXchH&quot;,\n      &quot;is_local&quot;: False,\n      &quot;name&quot;: &quot;Dragonfly Pie&quot;,\n      &quot;popularity&quot;: 26,\n      &quot;preview_url&quot;: &quot;https://p.scdn.co/mp3-preview/50f419e7d3e8a6a771515068622250ab06d1cc86?cid=be22fd00039241bc96d161a63876b54c&quot;,\n      &quot;track_number&quot;: 1,\n      &quot;type&quot;: &quot;track&quot;,\n      &quot;uri&quot;: &quot;spotify:track:3jyFLbljUTKjE13nIWXchH&quot;\n    },\n    {\n      &quot;album&quot;: {\n        &quot;album_type&quot;: &quot;album&quot;,\n        &quot;artists&quot;: [{\n          &quot;external_urls&quot;: {\n            &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n          },\n          &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n          &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n          &quot;type&quot;: &quot;artist&quot;,\n          &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n        }],\n        &quot;available_markets&quot;: [&quot;AR&quot;,\n          &quot;AU&quot;,\n          &quot;BO&quot;,\n          &quot;BR&quot;,\n          &quot;CA&quot;,\n          &quot;CL&quot;,\n          &quot;CO&quot;,\n          &quot;CR&quot;,\n          &quot;DO&quot;,\n          &quot;EC&quot;,\n          &quot;GT&quot;,\n          &quot;HK&quot;,\n          &quot;HN&quot;,\n          &quot;ID&quot;,\n          &quot;JP&quot;,\n          &quot;MX&quot;,\n          &quot;MY&quot;,\n          &quot;NI&quot;,\n          &quot;NZ&quot;,\n          &quot;PA&quot;,\n          &quot;PE&quot;,\n          &quot;PH&quot;,\n          &quot;PY&quot;,\n          &quot;SG&quot;,\n          &quot;SV&quot;,\n          &quot;TH&quot;,\n          &quot;TW&quot;,\n          &quot;US&quot;,\n          &quot;UY&quot;,\n          &quot;VN&quot;,\n          &quot;ZA&quot;\n        ],\n        &quot;external_urls&quot;: {\n          &quot;spotify&quot;: &quot;https://open.spotify.com/album/5DMvSCwRqfNVlMB5LjHOwG&quot;\n        },\n        &quot;href&quot;: &quot;https://api.spotify.com/v1/albums/5DMvSCwRqfNVlMB5LjHOwG&quot;,\n        &quot;id&quot;: &quot;5DMvSCwRqfNVlMB5LjHOwG&quot;,\n        &quot;images&quot;: [{\n            &quot;height&quot;: 640,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/bc96e20fa6b42c765db2fb904d3a70b6ef57b0bb&quot;,\n            &quot;width&quot;: 640\n          },\n          {\n            &quot;height&quot;: 300,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/c7a31ed50b9c704ec066f4aac669cfb9013effb1&quot;,\n            &quot;width&quot;: 300\n          },\n          {\n            &quot;height&quot;: 64,\n            &quot;url&quot;: &quot;https://i.scdn.co/image/8551e108d0950dd62724ff2703e8c13ce7324114&quot;,\n            &quot;width&quot;: 64\n          }\n        ],\n        &quot;name&quot;: &quot;Sparkle Hard&quot;,\n        &quot;release_date&quot;: &quot;2018-05-18&quot;,\n        &quot;release_date_precision&quot;: &quot;day&quot;,\n        &quot;type&quot;: &quot;album&quot;,\n        &quot;uri&quot;: &quot;spotify:album:5DMvSCwRqfNVlMB5LjHOwG&quot;\n      },\n      &quot;artists&quot;: [{\n        &quot;external_urls&quot;: {\n          &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n        },\n        &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n        &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n        &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n        &quot;type&quot;: &quot;artist&quot;,\n        &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n      }],\n      &quot;available_markets&quot;: [&quot;AR&quot;,\n        &quot;AU&quot;,\n        &quot;BO&quot;,\n        &quot;BR&quot;,\n        &quot;CA&quot;,\n        &quot;CL&quot;,\n        &quot;CO&quot;,\n        &quot;CR&quot;,\n        &quot;DO&quot;,\n        &quot;EC&quot;,\n        &quot;GT&quot;,\n        &quot;HK&quot;,\n        &quot;HN&quot;,\n        &quot;ID&quot;,\n        &quot;JP&quot;,\n        &quot;MX&quot;,\n        &quot;MY&quot;,\n        &quot;NI&quot;,\n        &quot;NZ&quot;,\n        &quot;PA&quot;,\n        &quot;PE&quot;,\n        &quot;PH&quot;,\n        &quot;PY&quot;,\n        &quot;SG&quot;,\n        &quot;SV&quot;,\n        &quot;TH&quot;,\n        &quot;TW&quot;,\n        &quot;US&quot;,\n        &quot;UY&quot;,\n        &quot;VN&quot;,\n        &quot;ZA&quot;\n      ],\n      &quot;disc_number&quot;: 1,\n      &quot;duration_ms&quot;: 423275,\n      &quot;explicit&quot;: False,\n      &quot;external_ids&quot;: {\n        &quot;isrc&quot;: &quot;USMTD1710380&quot;\n      },\n      &quot;external_urls&quot;: {\n        &quot;spotify&quot;: &quot;https://open.spotify.com/track/6dNmC2YWtWbVOFOdTuRDQs&quot;\n      },\n      &quot;href&quot;: &quot;https://api.spotify.com/v1/tracks/6dNmC2YWtWbVOFOdTuRDQs&quot;,\n      &quot;id&quot;: &quot;6dNmC2YWtWbVOFOdTuRDQs&quot;,\n      &quot;is_local&quot;: False,\n      &quot;name&quot;: &quot;Difficulties - Let Them Eat Vowels&quot;,\n      &quot;popularity&quot;: 35,\n      &quot;preview_url&quot;: &quot;https://p.scdn.co/mp3-preview/787be9d1bbebcd845d0793476de843fa0a4fff79?cid=be22fd00039241bc96d161a63876b54c&quot;,\n      &quot;track_number&quot;: 11,\n      &quot;type&quot;: &quot;track&quot;,\n      &quot;uri&quot;: &quot;spotify:track:6dNmC2YWtWbVOFOdTuRDQs&quot;\n    }\n  ]\n}\n\n</code></pre>\n<pre><code class=\"language-python\">json_normalise(tracks_response)\n</code></pre>\n<h3 id=\"output--4\">Output:</h3><div class=\"tableshadow tableContainer\" data-simplebar=\"\">\n<table class=\"responsive-table\">\n<thead><tr class=\"tableizer-firstrow\"><th></th><th>album.album_type</th><th>album.artists</th><th>album.available_markets</th><th>album.external_urls.spotify</th><th>album.href</th><th>album.id</th><th>album.images</th><th>album.name</th><th>album.release_date</th><th>album.release_date_precision</th><th>...</th><th>external_urls.spotify</th><th>href</th><th>id</th><th>is_local</th><th>name</th><th>popularity</th><th>preview_url</th><th>track_number</th><th>type</th><th>uri</th></tr></thead><tbody>\n <tr><td>0</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...</td><td>https://open.spotify.com/album/6pWpb4IdPu9vp9m...</td><td>https://api.spotify.com/v1/albums/6pWpb4IdPu9v...</td><td>6pWpb4IdPu9vp9mOdh5DjY</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Real Emotional Trash</td><td>3/4/2008</td><td>day</td><td>...</td><td>https://open.spotify.com/track/0BDYBajZydY54OT...</td><td>https://api.spotify.com/v1/tracks/0BDYBajZydY5...</td><td>0BDYBajZydY54OTgQsH940</td><td>FALSE</td><td>Real Emotional Trash</td><td>21</td><td>https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590...</td><td>4</td><td>track</td><td>spotify:track:0BDYBajZydY54OTgQsH940</td></tr>\n <tr><td>1</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...</td><td>https://open.spotify.com/album/6pWpb4IdPu9vp9m...</td><td>https://api.spotify.com/v1/albums/6pWpb4IdPu9v...</td><td>6pWpb4IdPu9vp9mOdh5DjY</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Real Emotional Trash</td><td>3/4/2008</td><td>day</td><td>...</td><td>https://open.spotify.com/track/7fdUqrzb8oCcIoK...</td><td>https://api.spotify.com/v1/tracks/7fdUqrzb8oCc...</td><td>7fdUqrzb8oCcIoKvFuzMrs</td><td>FALSE</td><td>Cold Son</td><td>25</td><td>https://p.scdn.co/mp3-preview/4cf4e21727def470...</td><td>3</td><td>track</td><td>spotify:track:7fdUqrzb8oCcIoKvFuzMrs</td></tr>\n <tr><td>2</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...</td><td>https://open.spotify.com/album/6pWpb4IdPu9vp9m...</td><td>https://api.spotify.com/v1/albums/6pWpb4IdPu9v...</td><td>6pWpb4IdPu9vp9mOdh5DjY</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Real Emotional Trash</td><td>3/4/2008</td><td>day</td><td>...</td><td>https://open.spotify.com/track/0islTY4Fw6lhYbf...</td><td>https://api.spotify.com/v1/tracks/0islTY4Fw6lh...</td><td>0islTY4Fw6lhYbfqi8Qtdj</td><td>FALSE</td><td>Hopscotch Willie</td><td>24</td><td>https://p.scdn.co/mp3-preview/c7782dc6d7c0bb12...</td><td>2</td><td>track</td><td>spotify:track:0islTY4Fw6lhYbfqi8Qtdj</td></tr>\n <tr><td>3</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...</td><td>https://open.spotify.com/album/6pWpb4IdPu9vp9m...</td><td>https://api.spotify.com/v1/albums/6pWpb4IdPu9v...</td><td>6pWpb4IdPu9vp9mOdh5DjY</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Real Emotional Trash</td><td>3/4/2008</td><td>day</td><td>...</td><td>https://open.spotify.com/track/3jyFLbljUTKjE13...</td><td>https://api.spotify.com/v1/tracks/3jyFLbljUTKj...</td><td>3jyFLbljUTKjE13nIWXchH</td><td>FALSE</td><td>Dragonfly Pie</td><td>26</td><td>https://p.scdn.co/mp3-preview/50f419e7d3e8a6a7...</td><td>1</td><td>track</td><td>spotify:track:3jyFLbljUTKjE13nIWXchH</td></tr>\n <tr><td>4</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, AU, BO, BR, CA, CL, CO, CR, DO, EC, GT, H...</td><td>https://open.spotify.com/album/5DMvSCwRqfNVlMB...</td><td>https://api.spotify.com/v1/albums/5DMvSCwRqfNV...</td><td>5DMvSCwRqfNVlMB5LjHOwG</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Sparkle Hard</td><td>5/18/2018</td><td>day</td><td>...</td><td>https://open.spotify.com/track/6dNmC2YWtWbVOFO...</td><td>https://api.spotify.com/v1/tracks/6dNmC2YWtWbV...</td><td>6dNmC2YWtWbVOFOdTuRDQs</td><td>FALSE</td><td>Difficulties - Let Them Eat Vowels</td><td>35</td><td>https://p.scdn.co/mp3-preview/787be9d1bbebcd84...</td><td>11</td><td>track</td><td>spotify:track:6dNmC2YWtWbVOFOdTuRDQs</td></tr>\n</tbody></table>\n</div><h2 id=\"separate-ways-worlds-apart-\">Separate Ways (Worlds Apart)</h2><p>By default, <code>json_normalize()</code> uses periods <code>.</code> to indicate nested levels of the JSON object (which is actually converted to a Python <code>dict</code> by Spotipy). In our case, the album id is found in <code>track['album']['id']</code>, hence the period between album and id in the DataFrame. This makes things slightly annoying if we want to grab a Series from our new DataFrame. In pandas, we can grab a Series from a DataFrame in many ways. To grab the <code>album.id</code> column, for example:</p><pre><code class=\"language-python\">tracks_df['album.id']\n</code></pre>\n<h3 id=\"output--5\">Output:</h3><pre><code class=\"language-python\">0    6pWpb4IdPu9vp9mOdh5DjY\n1    6pWpb4IdPu9vp9mOdh5DjY\n2    6pWpb4IdPu9vp9mOdh5DjY\n3    6pWpb4IdPu9vp9mOdh5DjY\n4    5DMvSCwRqfNVlMB5LjHOwG\nName: album.id, dtype: object\n</code></pre>\n<p>or</p><pre><code class=\"language-python\">tracks_df.loc[:,'album.id']\n\n</code></pre>\n<h3 id=\"output--6\">Output:</h3><pre><code class=\"language-python\">0    6pWpb4IdPu9vp9mOdh5DjY\n1    6pWpb4IdPu9vp9mOdh5DjY\n2    6pWpb4IdPu9vp9mOdh5DjY\n3    6pWpb4IdPu9vp9mOdh5DjY\n4    5DMvSCwRqfNVlMB5LjHOwG\nName: album.id, dtype: object\n</code></pre>\n<p>pandas also allows us to use dot notation (i.e. <code>dataframe.column_name</code>) to grab a column as a Series, but only if our column name doesn't include a period already. Since <code>json_normalize()</code> uses a period as a separator by default, this ruins that method. Never fear though – overriding this behavior is as simple as overriding the default argument in the function call:</p><pre><code class=\"language-python\">tracks_df = json_normalize(tracks_response['tracks'],sep=&quot;_&quot;)\ntracks_df\n</code></pre>\n<h3 id=\"output--7\">Output:</h3><div class=\"tableshadow tableContainer\" data-simplebar=\"\">\n<table class=\"responsive-table\">\n<thead><tr class=\"tableizer-firstrow\"><th></th><th>album_album_type</th><th>album_artists</th><th>album_available_markets</th><th>album_external_urls_spotify</th><th>album_href</th><th>album_id</th><th>album_images</th><th>album_name</th><th>album_release_date</th><th>album_release_date_precision</th><th>...</th><th>external_urls_spotify</th><th>href</th><th>id</th><th>is_local</th><th>name</th><th>popularity</th><th>preview_url</th><th>track_number</th><th>type</th><th>uri</th></tr></thead><tbody>\n <tr><td>0</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...</td><td>https://open.spotify.com/album/6pWpb4IdPu9vp9m...</td><td>https://api.spotify.com/v1/albums/6pWpb4IdPu9v...</td><td>6pWpb4IdPu9vp9mOdh5DjY</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Real Emotional Trash</td><td>3/4/2008</td><td>day</td><td>...</td><td>https://open.spotify.com/track/0BDYBajZydY54OT...</td><td>https://api.spotify.com/v1/tracks/0BDYBajZydY5...</td><td>0BDYBajZydY54OTgQsH940</td><td>FALSE</td><td>Real Emotional Trash</td><td>21</td><td>https://p.scdn.co/mp3-preview/4fcbcd5a99fc7590...</td><td>4</td><td>track</td><td>spotify:track:0BDYBajZydY54OTgQsH940</td></tr>\n <tr><td>1</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...</td><td>https://open.spotify.com/album/6pWpb4IdPu9vp9m...</td><td>https://api.spotify.com/v1/albums/6pWpb4IdPu9v...</td><td>6pWpb4IdPu9vp9mOdh5DjY</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Real Emotional Trash</td><td>3/4/2008</td><td>day</td><td>...</td><td>https://open.spotify.com/track/7fdUqrzb8oCcIoK...</td><td>https://api.spotify.com/v1/tracks/7fdUqrzb8oCc...</td><td>7fdUqrzb8oCcIoKvFuzMrs</td><td>FALSE</td><td>Cold Son</td><td>25</td><td>https://p.scdn.co/mp3-preview/4cf4e21727def470...</td><td>3</td><td>track</td><td>spotify:track:7fdUqrzb8oCcIoKvFuzMrs</td></tr>\n <tr><td>2</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...</td><td>https://open.spotify.com/album/6pWpb4IdPu9vp9m...</td><td>https://api.spotify.com/v1/albums/6pWpb4IdPu9v...</td><td>6pWpb4IdPu9vp9mOdh5DjY</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Real Emotional Trash</td><td>3/4/2008</td><td>day</td><td>...</td><td>https://open.spotify.com/track/0islTY4Fw6lhYbf...</td><td>https://api.spotify.com/v1/tracks/0islTY4Fw6lh...</td><td>0islTY4Fw6lhYbfqi8Qtdj</td><td>FALSE</td><td>Hopscotch Willie</td><td>24</td><td>https://p.scdn.co/mp3-preview/c7782dc6d7c0bb12...</td><td>2</td><td>track</td><td>spotify:track:0islTY4Fw6lhYbfqi8Qtdj</td></tr>\n <tr><td>3</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, BO, BR, CA, CL, CO, CR, EC, GT, HK, HN, I...</td><td>https://open.spotify.com/album/6pWpb4IdPu9vp9m...</td><td>https://api.spotify.com/v1/albums/6pWpb4IdPu9v...</td><td>6pWpb4IdPu9vp9mOdh5DjY</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Real Emotional Trash</td><td>3/4/2008</td><td>day</td><td>...</td><td>https://open.spotify.com/track/3jyFLbljUTKjE13...</td><td>https://api.spotify.com/v1/tracks/3jyFLbljUTKj...</td><td>3jyFLbljUTKjE13nIWXchH</td><td>FALSE</td><td>Dragonfly Pie</td><td>26</td><td>https://p.scdn.co/mp3-preview/50f419e7d3e8a6a7...</td><td>1</td><td>track</td><td>spotify:track:3jyFLbljUTKjE13nIWXchH</td></tr>\n <tr><td>4</td><td>album</td><td>[{'external_urls': {'spotify': 'https://open.s...</td><td>[AR, AU, BO, BR, CA, CL, CO, CR, DO, EC, GT, H...</td><td>https://open.spotify.com/album/5DMvSCwRqfNVlMB...</td><td>https://api.spotify.com/v1/albums/5DMvSCwRqfNV...</td><td>5DMvSCwRqfNVlMB5LjHOwG</td><td>[{'height': 640, 'url': 'https://i.scdn.co/ima...</td><td>Sparkle Hard</td><td>5/18/2018</td><td>day</td><td>...</td><td>https://open.spotify.com/track/6dNmC2YWtWbVOFO...</td><td>https://api.spotify.com/v1/tracks/6dNmC2YWtWbV...</td><td>6dNmC2YWtWbVOFOdTuRDQs</td><td>FALSE</td><td>Difficulties - Let Them Eat Vowels</td><td>35</td><td>https://p.scdn.co/mp3-preview/787be9d1bbebcd84...</td><td>11</td><td>track</td><td>spotify:track:6dNmC2YWtWbVOFOdTuRDQs</td></tr>\n</tbody></table>\n</div><p>Now we can go back to using dot notation to access a column as a Series. This saves us some typing every time we want to grab a column, and it looks a bit nicer (to me, at least). I say worth it.</p><pre><code class=\"language-python\">tracks_df.album_id\n</code></pre>\n<h3 id=\"output--8\">Output:</h3><pre><code class=\"language-shell\">0    6pWpb4IdPu9vp9mOdh5DjY\n1    6pWpb4IdPu9vp9mOdh5DjY\n2    6pWpb4IdPu9vp9mOdh5DjY\n3    6pWpb4IdPu9vp9mOdh5DjY\n4    5DMvSCwRqfNVlMB5LjHOwG\nName: album_id, dtype: object\n</code></pre>\n<h2 id=\"i-need-that-record\">I Need That Record</h2><p>By including more parameters when we use <code>json_normlize()</code>, we can really extract just the data that we want from our API response.</p><p>From our responses above, we can see that the <code>artist</code> property contains a list of artists that are associated with a track:</p><pre><code class=\"language-python\">tracks_response['tracks'][0]['artists']\n</code></pre>\n<h3 id=\"output--9\">Output:</h3><pre><code class=\"language-json\">[{\n    &quot;external_urls&quot;: {\n      &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7wyRA7deGRxozTyBc6QXPe&quot;\n    },\n    &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7wyRA7deGRxozTyBc6QXPe&quot;,\n    &quot;id&quot;: &quot;7wyRA7deGRxozTyBc6QXPe&quot;,\n    &quot;name&quot;: &quot;Stephen Malkmus &amp; The Jicks&quot;,\n    &quot;type&quot;: &quot;artist&quot;,\n    &quot;uri&quot;: &quot;spotify:artist:7wyRA7deGRxozTyBc6QXPe&quot;\n  },\n  {\n    &quot;external_urls&quot;: {\n      &quot;spotify&quot;: &quot;https://open.spotify.com/artist/0WISkx0PwT6lYWdPqKUJY8&quot;\n    },\n    &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/0WISkx0PwT6lYWdPqKUJY8&quot;,\n    &quot;id&quot;: &quot;0WISkx0PwT6lYWdPqKUJY8&quot;,\n    &quot;name&quot;: &quot;Stephen Malkmus&quot;,\n    &quot;type&quot;: &quot;artist&quot;,\n    &quot;uri&quot;: &quot;spotify:artist:0WISkx0PwT6lYWdPqKUJY8&quot;\n  },\n  {\n    &quot;external_urls&quot;: {\n      &quot;spotify&quot;: &quot;https://open.spotify.com/artist/7uStwCeP54Za8gXUFCf5L7&quot;\n    },\n    &quot;href&quot;: &quot;https://api.spotify.com/v1/artists/7uStwCeP54Za8gXUFCf5L7&quot;,\n    &quot;id&quot;: &quot;7uStwCeP54Za8gXUFCf5L7&quot;,\n    &quot;name&quot;: &quot;The Jicks&quot;,\n    &quot;type&quot;: &quot;artist&quot;,\n    &quot;uri&quot;: &quot;spotify:artist:7uStwCeP54Za8gXUFCf5L7&quot;\n  }\n]\n</code></pre>\n<p>Let's say I want to load this data into a database later. It would be nice to have a join table that maps each of the artists that are associated with each track. Luckily, this is possible with <code>json_normalize()</code>'s <code>record_path</code> and <code>meta</code> parameters.</p><p><code>record_path</code> tells <code>json_normalize()</code> what path of keys leads to each individual record in the JSON object. In our case, we want to grab every artist id, so our function call will look like:</p><pre><code class=\"language-python\">json_normalize(tracks_response['tracks'],record_path=['artists'],sep=&quot;_&quot;)\n</code></pre>\n<h3></h3><div class=\"tableshadow tableContainer\" data-simplebar=\"\">\n<table class=\"responsive-table\">\n<thead><tr class=\"tableizer-firstrow\"><th> </th><th>external_urls </th><th>href </th><th>id </th><th>name </th><th>type </th><th>uri</th></tr></thead><tbody>\n <tr><td>1 </td><td>{'spotify': 'https://open.spotify.com/artist/7... </td><td>https://api.spotify.com/v1/artists/7wyRA7deGRx... </td><td>7wyRA7deGRxozTyBc6QXPe </td><td>Stephen Malkmus & The Jicks </td><td>artist </td><td>spotify:artist:7wyRA7deGRxozTyBc6QXPe</td></tr>\n <tr><td>1 </td><td>{'spotify': 'https://open.spotify.com/artist/0... </td><td>https://api.spotify.com/v1/artists/0WISkx0PwT6... </td><td>0WISkx0PwT6lYWdPqKUJY8 </td><td>Stephen Malkmus </td><td>artist </td><td>spotify:artist:0WISkx0PwT6lYWdPqKUJY8</td></tr>\n <tr><td>2 </td><td>{'spotify': 'https://open.spotify.com/artist/7... </td><td>https://api.spotify.com/v1/artists/7uStwCeP54Z... </td><td>7uStwCeP54Za8gXUFCf5L7 </td><td>The Jicks </td><td>artist </td><td>spotify:artist:7uStwCeP54Za8gXUFCf5L7</td></tr>\n <tr><td>3 </td><td>{'spotify': 'https://open.spotify.com/artist/7... </td><td>https://api.spotify.com/v1/artists/7wyRA7deGRx... </td><td>7wyRA7deGRxozTyBc6QXPe </td><td>Stephen Malkmus & The Jicks </td><td>artist </td><td>spotify:artist:7wyRA7deGRxozTyBc6QXPe</td></tr>\n <tr><td>4 </td><td>{'spotify': 'https://open.spotify.com/artist/0... </td><td>https://api.spotify.com/v1/artists/0WISkx0PwT6... </td><td>0WISkx0PwT6lYWdPqKUJY8 </td><td>Stephen Malkmus </td><td>artist </td><td>spotify:artist:0WISkx0PwT6lYWdPqKUJY8</td></tr>\n <tr><td>5 </td><td>{'spotify': 'https://open.spotify.com/artist/7... </td><td>https://api.spotify.com/v1/artists/7uStwCeP54Z... </td><td>7uStwCeP54Za8gXUFCf5L7 </td><td>The Jicks </td><td>artist </td><td>spotify:artist:7uStwCeP54Za8gXUFCf5L7</td></tr>\n <tr><td>6 </td><td>{'spotify': 'https://open.spotify.com/artist/7... </td><td>https://api.spotify.com/v1/artists/7wyRA7deGRx... </td><td>7wyRA7deGRxozTyBc6QXPe </td><td>Stephen Malkmus & The Jicks </td><td>artist </td><td>spotify:artist:7wyRA7deGRxozTyBc6QXPe</td></tr>\n <tr><td>7 </td><td>{'spotify': 'https://open.spotify.com/artist/0... </td><td>https://api.spotify.com/v1/artists/0WISkx0PwT6... </td><td>0WISkx0PwT6lYWdPqKUJY8 </td><td>Stephen Malkmus </td><td>artist </td><td>spotify:artist:0WISkx0PwT6lYWdPqKUJY8</td></tr>\n <tr><td>8 </td><td>{'spotify': 'https://open.spotify.com/artist/7... </td><td>https://api.spotify.com/v1/artists/7uStwCeP54Z... </td><td>7uStwCeP54Za8gXUFCf5L7 </td><td>The Jicks </td><td>artist </td><td>spotify:artist:7uStwCeP54Za8gXUFCf5L7</td></tr>\n <tr><td>9 </td><td>{'spotify': 'https://open.spotify.com/artist/7... </td><td>https://api.spotify.com/v1/artists/7wyRA7deGRx... </td><td>7wyRA7deGRxozTyBc6QXPe </td><td>Stephen Malkmus & The Jicks </td><td>artist </td><td>spotify:artist:7wyRA7deGRxozTyBc6QXPe</td></tr>\n <tr><td>10 </td><td>{'spotify': 'https://open.spotify.com/artist/0... </td><td>https://api.spotify.com/v1/artists/0WISkx0PwT6... </td><td>0WISkx0PwT6lYWdPqKUJY8 </td><td>Stephen Malkmus </td><td>artist </td><td>spotify:artist:0WISkx0PwT6lYWdPqKUJY8</td></tr>\n <tr><td>11 </td><td>{'spotify': 'https://open.spotify.com/artist/7... </td><td>https://api.spotify.com/v1/artists/7uStwCeP54Z... </td><td>7uStwCeP54Za8gXUFCf5L7 </td><td>The Jicks </td><td>artist </td><td>spotify:artist:7uStwCeP54Za8gXUFCf5L7</td></tr>\n <tr><td>12 </td><td>{'spotify': 'https://open.spotify.com/artist/7... </td><td>https://api.spotify.com/v1/artists/7wyRA7deGRx... </td><td>7wyRA7deGRxozTyBc6QXPe </td><td>Stephen Malkmus & The Jicks </td><td>artist </td><td>spotify:artist:7wyRA7deGRxozTyBc6QXPe</td></tr>\n</tbody></table>\n</div><p>Cool – we're almost there. Now we want to use the <code>meta</code> parameter to specify what data we want to include from the rest of the JSON object. In our case, we want to keep the track id and map it to the artist id. If we look back at our API response, the name of the column that included the track is is called, appropriately, <code>id</code>, so our full function call should look like this:</p><pre><code class=\"language-python\">json_normalize(tracks_response['tracks'],record_path=['artists'],meta=['id'],sep=&quot;_&quot;)\n</code></pre>\n<h3 id=\"output--10\">Output:</h3><pre><code class=\"language-python\">-----------------------------------------\nValueError                             Traceback (most recent call last)\n\n    &lt;ipython-input-14-77e00a98c3c0&gt; in &lt;module&gt;()\n    ----&gt; 1 json_normalize(tracks_response['tracks'],record_path=['artists'],meta=['id'],sep=&quot;_&quot;)\n\n    ~/anaconda3/envs/music_data/lib/python3.6/site-packages/pandas/io/json/normalize.py in json_normalize(data, record_path, meta, meta_prefix, record_prefix, errors, sep)\n        268         if k in result:\n        269             raise ValueError('Conflicting metadata name {name}, '\n    --&gt; 270                              'need distinguishing prefix '.format(name=k))\n        271 \n        272         result[k] = np.array(v).repeat(lengths)\n    \nValueError: Conflicting metadata name id, need distinguishing prefix \n</code></pre>\n<p>Uh oh – an error! What's going on? Well, it turns out that both the album id and track id were given the key <code>id</code>. pandas doesn't like that, and it gives us a helpful error to tell us so: <code>ValueError: Conflicting metadata name id, need distinguishing prefix</code>.</p><p>There are two more parameters we can use to overcome this error: <code>record_prefix</code> and <code>meta_prefix</code>. These are strings we'll add to the beginning of our records and metadata to prevent these naming conflicts. Since we're dealing with Spotify artist ids for our records and Spotify track ids as the metadata, I'll use <code>sp_artist_</code> and <code>sp_track_</code> respectively. When that's done, I'll select only the columns that we're interested in.</p><pre><code class=\"language-python\">artist_and_track = json_normalize(\n    data=tracks_response['tracks'],\n    record_path='artists',\n    meta=['id'],\n    record_prefix='sp_artist_',\n    meta_prefix='sp_track_',\n    sep=&quot;_&quot;\n)\nartist_and_track = artist_and_track[['sp_track_id','sp_artist_id']]\nartist_and_track\n</code></pre>\n<h3 id=\"output--11\">Output:</h3><div class=\"tableshadow tableContainer\">\n<table>\n<thead><tr class=\"tableizer-firstrow\"><th></th><th>sp_track_id </th><th>sp_artist_id</th></tr></thead><tbody>\n <tr><td>0</td><td>0BDYBajZydY54OTgQsH940 </td><td>7wyRA7deGRxozTyBc6QXPe</td></tr>\n <tr><td>1</td><td>0BDYBajZydY54OTgQsH940 </td><td>0WISkx0PwT6lYWdPqKUJY8</td></tr>\n <tr><td>2</td><td>0BDYBajZydY54OTgQsH940 </td><td>7uStwCeP54Za8gXUFCf5L7</td></tr>\n <tr><td>3</td><td>7fdUqrzb8oCcIoKvFuzMrs </td><td>7wyRA7deGRxozTyBc6QXPe</td></tr>\n <tr><td>4</td><td>7fdUqrzb8oCcIoKvFuzMrs </td><td>0WISkx0PwT6lYWdPqKUJY8</td></tr>\n <tr><td>5</td><td>7fdUqrzb8oCcIoKvFuzMrs </td><td>7uStwCeP54Za8gXUFCf5L7</td></tr>\n <tr><td>6</td><td>0islTY4Fw6lhYbfqi8Qtdj </td><td>7wyRA7deGRxozTyBc6QXPe</td></tr>\n <tr><td>7</td><td>0islTY4Fw6lhYbfqi8Qtdj </td><td>0WISkx0PwT6lYWdPqKUJY8</td></tr>\n <tr><td>8</td><td>0islTY4Fw6lhYbfqi8Qtdj </td><td>7uStwCeP54Za8gXUFCf5L7</td></tr>\n <tr><td>9</td><td>3jyFLbljUTKjE13nIWXchH </td><td>7wyRA7deGRxozTyBc6QXPe</td></tr>\n <tr><td>10</td><td>3jyFLbljUTKjE13nIWXchH </td><td>0WISkx0PwT6lYWdPqKUJY8</td></tr>\n <tr><td>11</td><td>3jyFLbljUTKjE13nIWXchH </td><td>7uStwCeP54Za8gXUFCf5L7</td></tr>\n <tr><td>12</td><td>6dNmC2YWtWbVOFOdTuRDQs </td><td>7wyRA7deGRxozTyBc6QXPe</td></tr>\n</tbody></table>\n</div><h2 id=\"tl-dr\">TL;DR</h2><ul><li>Use <code>pd.io.json.json_normalize()</code> to automagically flatten a nested JSON object into a DataFrame</li><li>Make your life slightly easier when it comes to selecting columns by overriding the default <code>sep</code> parameter</li><li>Specify what data constitutes a record with the <code>record_path</code> parameter</li><li>Include data from outside of the record path with the <code>meta</code> parameter</li><li>Fix naming conflicts if they arise with the <code>record_prefix</code> and <code>meta_prefix</code> parameters</li></ul>","url":"https://hackersandslackers.com/json-into-pandas-dataframes/","uuid":"172cef40-4545-4c14-8488-a86a891ef47d","page":false,"codeinjection_foot":null,"codeinjection_head":null,"comment_id":"5b588eb363c4cc21a000cf51"}}]}},"pageContext":{"slug":"restapis","limit":12,"skip":0,"numberOfPages":2,"humanPageNumber":1,"prevPageNumber":null,"nextPageNumber":2,"previousPagePath":null,"nextPagePath":"/tag/restapis/page/2/"}}